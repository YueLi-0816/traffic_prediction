{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "tKUGmv5cn6GV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import random\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs:\n",
      " - /physical_device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# List all physical devices\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Available GPUs:\")\n",
    "for gpu in gpus:\n",
    "    print(f\" - {gpu.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory growth enabled for GPUs.\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"Memory growth enabled for GPUs.\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8uafyjo7odXA"
   },
   "outputs": [],
   "source": [
    "traffic_data = pd.read_csv('../Traffic data/SCOOT/data_470_hourly/flows/GD030A_S.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KZRSO8dF_Sik"
   },
   "source": [
    "## 1. Recover timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "4TWZuMkMiYtJ"
   },
   "outputs": [],
   "source": [
    "# Define the recover_timestamp function\n",
    "def recover_timestamp(data):\n",
    "    # Combine 'date' and 'time' to form a datetime column\n",
    "    data['datetime'] = pd.to_datetime(data['date'] + ' ' + data['time'].astype(str) + ':00', format='%Y-%m-%d %H:%M')\n",
    "\n",
    "    # Set 'datetime' as index\n",
    "    data = data.set_index('datetime')\n",
    "\n",
    "    # Create a complete range of timestamps with hourly frequency\n",
    "    full_time_range = pd.date_range(start=data.index.min(), end=data.index.max(), freq='H')\n",
    "\n",
    "    # Reindex the data to include all timestamps, filling missing rows with NaN\n",
    "    data_full = data.reindex(full_time_range)\n",
    "\n",
    "    return data_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "rwy81CAA_Y4r",
    "outputId": "9d3c3f5e-37fd-40f5-e31f-060efe8ee18d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>flow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-10-01 00:00:00</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01 01:00:00</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01 02:00:00</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01 03:00:00</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01 04:00:00</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-30 19:00:00</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>19.0</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-30 20:00:00</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>20.0</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-30 21:00:00</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>21.0</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-30 22:00:00</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>22.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-30 23:00:00</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>23.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35064 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           date  time   flow\n",
       "2019-10-01 00:00:00  2019-10-01   0.0   15.0\n",
       "2019-10-01 01:00:00  2019-10-01   1.0    9.0\n",
       "2019-10-01 02:00:00  2019-10-01   2.0    9.0\n",
       "2019-10-01 03:00:00  2019-10-01   3.0    7.0\n",
       "2019-10-01 04:00:00  2019-10-01   4.0    9.0\n",
       "...                         ...   ...    ...\n",
       "2023-09-30 19:00:00  2023-09-30  19.0  129.0\n",
       "2023-09-30 20:00:00  2023-09-30  20.0  119.0\n",
       "2023-09-30 21:00:00  2023-09-30  21.0  106.0\n",
       "2023-09-30 22:00:00  2023-09-30  22.0   88.0\n",
       "2023-09-30 23:00:00  2023-09-30  23.0   88.0\n",
       "\n",
       "[35064 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the recover_timestamp function to recover the full time series\n",
    "traffic_full = recover_timestamp(traffic_data)\n",
    "traffic_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8z-mdqKewzjt"
   },
   "source": [
    "## 2. Train, validate, test data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h60qTUKvwzCb",
    "outputId": "682cc0ab-b2ed-48a1-df5d-6168064efd78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of train_set : 0.6227\n",
      "Proportion of valid_set : 0.1876\n",
      "Proportion of test_set : 0.1897\n"
     ]
    }
   ],
   "source": [
    "# train_set = traffic_full[:'2022-02-28 23:00:00']\n",
    "# valid_set = traffic_full['2022-03-01 00:00:00':'2022-12-31 23:00:00']\n",
    "# test_set = traffic_full['2023-01-01 00:00:00':]\n",
    "train_set = traffic_full['2022-06-03 00:00:00':'2023-03-31 23:00:00']\n",
    "valid_set = traffic_full['2023-04-01 00:00:00':'2023-06-30 23:00:00']\n",
    "test_set = traffic_full['2023-07-01 00:00:00':]\n",
    "print('Proportion of train_set : {:.4f}'.format(len(train_set)/len(traffic_full['2022-06-03 00:00:00':])))\n",
    "print('Proportion of valid_set : {:.4f}'.format(len(valid_set)/len(traffic_full['2022-06-03 00:00:00':])))\n",
    "print('Proportion of test_set : {:.4f}'.format(len(test_set)/len(traffic_full['2022-06-03 00:00:00':])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date    16\n",
      "time    16\n",
      "flow    16\n",
      "dtype: int64 7248\n",
      "date    61\n",
      "time    61\n",
      "flow    61\n",
      "dtype: int64 2184\n",
      "date    342\n",
      "time    342\n",
      "flow    342\n",
      "dtype: int64 2208\n"
     ]
    }
   ],
   "source": [
    "print(train_set.isnull().sum(), len(train_set))\n",
    "print(valid_set.isnull().sum(),len(valid_set))\n",
    "print(test_set.isnull().sum(),len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bd0hRLpW9gJs"
   },
   "source": [
    "## 3. Normalise the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amanda\\AppData\\Local\\Temp\\ipykernel_22452\\1100395100.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_set.loc[:, 'flow_scaled'] = scaler.transform(train_set[['flow']])\n",
      "C:\\Users\\Amanda\\AppData\\Local\\Temp\\ipykernel_22452\\1100395100.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  valid_set.loc[:, 'flow_scaled'] = scaler.transform(valid_set[['flow']])\n",
      "C:\\Users\\Amanda\\AppData\\Local\\Temp\\ipykernel_22452\\1100395100.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_set.loc[:, 'flow_scaled'] = scaler.transform(test_set[['flow']])\n"
     ]
    }
   ],
   "source": [
    "# Initialize the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler on the training data's 'flow' feature\n",
    "scaler.fit(train_set[['flow']])\n",
    "\n",
    "# Transform the 'flow' feature in all datasets\n",
    "train_set.loc[:, 'flow_scaled'] = scaler.transform(train_set[['flow']])\n",
    "valid_set.loc[:, 'flow_scaled'] = scaler.transform(valid_set[['flow']])\n",
    "test_set.loc[:, 'flow_scaled'] = scaler.transform(test_set[['flow']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xak17ms1uZ-6"
   },
   "source": [
    "## 4. Split the data into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, input_length, forecast_horizon):\n",
    "    \"\"\"\n",
    "    Creates input-output sequences for time series data, excluding any sequences containing NaN values.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: pandas DataFrame containing the data. Must include the 'flow_scaled' column.\n",
    "    - input_length: int, number of past time steps to include in each input sequence.\n",
    "    - forecast_horizon: int, number of future steps to predict.\n",
    "    \n",
    "    Returns:\n",
    "    - X: numpy array of shape (num_valid_samples, input_length, num_features)\n",
    "    - y: numpy array of shape (num_valid_samples, forecast_horizon)\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    num_features = data.shape[1]\n",
    "    total_length = input_length + forecast_horizon\n",
    "    \n",
    "    for i in range(input_length, len(data) - forecast_horizon + 1):\n",
    "        # Extract the input sequence\n",
    "        X_seq = data.iloc[i - input_length:i]['flow_scaled'].values\n",
    "        # Extract the target sequence\n",
    "        y_seq = data.iloc[i:i + forecast_horizon]['flow_scaled'].values\n",
    "        \n",
    "        # Check for NaN values in the input sequence and target sequence\n",
    "        if not np.isnan(X_seq).any() and not np.isnan(y_seq).any():\n",
    "            X.append(X_seq)\n",
    "            y.append(y_seq)\n",
    "        else:\n",
    "            # Optionally, log or count the skipped sequences\n",
    "            pass  # Simply skip sequences with NaNs\n",
    "        \n",
    "    # Convert to numpy arrays and reshape X to match LSTM expected input (samples, timesteps, features)\n",
    "    X = np.array(X).reshape(-1, input_length, 1)\n",
    "    y = np.array(y).reshape(-1, forecast_horizon)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create X and y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will use\n",
    "* the last 24*N steps\n",
    "\n",
    "*  to forecast current (0 step) and 5 steps ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Input Sequence Lengths\n",
    "input_lengths = [24 * i for i in range(1, 22)]  # [24, 48, ..., 168]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing input length: 24\n",
      "  X_train shape: (7145, 24, 1), y_train shape: (7145, 6)\n",
      "  X_val shape: (2007, 24, 1), y_val shape: (2007, 6)\n",
      "  X_test shape: (1719, 24, 1), y_test shape: (1719, 6)\n",
      "\n",
      "Processing input length: 48\n",
      "  X_train shape: (7073, 48, 1), y_train shape: (7073, 6)\n",
      "  X_val shape: (1911, 48, 1), y_val shape: (1911, 6)\n",
      "  X_test shape: (1604, 48, 1), y_test shape: (1604, 6)\n",
      "\n",
      "Processing input length: 72\n",
      "  X_train shape: (7001, 72, 1), y_train shape: (7001, 6)\n",
      "  X_val shape: (1815, 72, 1), y_val shape: (1815, 6)\n",
      "  X_test shape: (1508, 72, 1), y_test shape: (1508, 6)\n",
      "\n",
      "Processing input length: 96\n",
      "  X_train shape: (6929, 96, 1), y_train shape: (6929, 6)\n",
      "  X_val shape: (1719, 96, 1), y_val shape: (1719, 6)\n",
      "  X_test shape: (1412, 96, 1), y_test shape: (1412, 6)\n",
      "\n",
      "Processing input length: 120\n",
      "  X_train shape: (6857, 120, 1), y_train shape: (6857, 6)\n",
      "  X_val shape: (1623, 120, 1), y_val shape: (1623, 6)\n",
      "  X_test shape: (1316, 120, 1), y_test shape: (1316, 6)\n",
      "\n",
      "Processing input length: 144\n",
      "  X_train shape: (6785, 144, 1), y_train shape: (6785, 6)\n",
      "  X_val shape: (1527, 144, 1), y_val shape: (1527, 6)\n",
      "  X_test shape: (1220, 144, 1), y_test shape: (1220, 6)\n",
      "\n",
      "Processing input length: 168\n",
      "  X_train shape: (6713, 168, 1), y_train shape: (6713, 6)\n",
      "  X_val shape: (1431, 168, 1), y_val shape: (1431, 6)\n",
      "  X_test shape: (1124, 168, 1), y_test shape: (1124, 6)\n",
      "\n",
      "Processing input length: 192\n",
      "  X_train shape: (6641, 192, 1), y_train shape: (6641, 6)\n",
      "  X_val shape: (1335, 192, 1), y_val shape: (1335, 6)\n",
      "  X_test shape: (1028, 192, 1), y_test shape: (1028, 6)\n",
      "\n",
      "Processing input length: 216\n",
      "  X_train shape: (6569, 216, 1), y_train shape: (6569, 6)\n",
      "  X_val shape: (1239, 216, 1), y_val shape: (1239, 6)\n",
      "  X_test shape: (932, 216, 1), y_test shape: (932, 6)\n",
      "\n",
      "Processing input length: 240\n",
      "  X_train shape: (6497, 240, 1), y_train shape: (6497, 6)\n",
      "  X_val shape: (1143, 240, 1), y_val shape: (1143, 6)\n",
      "  X_test shape: (836, 240, 1), y_test shape: (836, 6)\n",
      "\n",
      "Processing input length: 264\n",
      "  X_train shape: (6425, 264, 1), y_train shape: (6425, 6)\n",
      "  X_val shape: (1047, 264, 1), y_val shape: (1047, 6)\n",
      "  X_test shape: (740, 264, 1), y_test shape: (740, 6)\n",
      "\n",
      "Processing input length: 288\n",
      "  X_train shape: (6353, 288, 1), y_train shape: (6353, 6)\n",
      "  X_val shape: (963, 288, 1), y_val shape: (963, 6)\n",
      "  X_test shape: (660, 288, 1), y_test shape: (660, 6)\n",
      "\n",
      "Processing input length: 312\n",
      "  X_train shape: (6281, 312, 1), y_train shape: (6281, 6)\n",
      "  X_val shape: (891, 312, 1), y_val shape: (891, 6)\n",
      "  X_test shape: (588, 312, 1), y_test shape: (588, 6)\n",
      "\n",
      "Processing input length: 336\n",
      "  X_train shape: (6209, 336, 1), y_train shape: (6209, 6)\n",
      "  X_val shape: (819, 336, 1), y_val shape: (819, 6)\n",
      "  X_test shape: (516, 336, 1), y_test shape: (516, 6)\n",
      "\n",
      "Processing input length: 360\n",
      "  X_train shape: (6137, 360, 1), y_train shape: (6137, 6)\n",
      "  X_val shape: (747, 360, 1), y_val shape: (747, 6)\n",
      "  X_test shape: (444, 360, 1), y_test shape: (444, 6)\n",
      "\n",
      "Processing input length: 384\n",
      "  X_train shape: (6065, 384, 1), y_train shape: (6065, 6)\n",
      "  X_val shape: (675, 384, 1), y_val shape: (675, 6)\n",
      "  X_test shape: (390, 384, 1), y_test shape: (390, 6)\n",
      "\n",
      "Processing input length: 408\n",
      "  X_train shape: (5993, 408, 1), y_train shape: (5993, 6)\n",
      "  X_val shape: (603, 408, 1), y_val shape: (603, 6)\n",
      "  X_test shape: (342, 408, 1), y_test shape: (342, 6)\n",
      "\n",
      "Processing input length: 432\n",
      "  X_train shape: (5921, 432, 1), y_train shape: (5921, 6)\n",
      "  X_val shape: (531, 432, 1), y_val shape: (531, 6)\n",
      "  X_test shape: (311, 432, 1), y_test shape: (311, 6)\n",
      "\n",
      "Processing input length: 456\n",
      "  X_train shape: (5849, 456, 1), y_train shape: (5849, 6)\n",
      "  X_val shape: (459, 456, 1), y_val shape: (459, 6)\n",
      "  X_test shape: (287, 456, 1), y_test shape: (287, 6)\n",
      "\n",
      "Processing input length: 480\n",
      "  X_train shape: (5777, 480, 1), y_train shape: (5777, 6)\n",
      "  X_val shape: (387, 480, 1), y_val shape: (387, 6)\n",
      "  X_test shape: (263, 480, 1), y_test shape: (263, 6)\n",
      "\n",
      "Processing input length: 504\n",
      "  X_train shape: (5705, 504, 1), y_train shape: (5705, 6)\n",
      "  X_val shape: (333, 504, 1), y_val shape: (333, 6)\n",
      "  X_test shape: (239, 504, 1), y_test shape: (239, 6)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "data_dict = defaultdict(dict)\n",
    "\n",
    "for length in input_lengths:\n",
    "    print(f\"Processing input length: {length}\")\n",
    "    \n",
    "    # Create sequences with forecast_horizon=6\n",
    "    X_train, y_train = create_sequences(train_set, length, forecast_horizon=6)\n",
    "    X_val, y_val = create_sequences(valid_set, length, forecast_horizon=6)\n",
    "    X_test, y_test = create_sequences(test_set, length, forecast_horizon=6)\n",
    "    \n",
    "    # Store in the dictionary\n",
    "    data_dict[length]['X_train'] = X_train\n",
    "    data_dict[length]['y_train'] = y_train\n",
    "    data_dict[length]['X_val'] = X_val\n",
    "    data_dict[length]['y_val'] = y_val\n",
    "    data_dict[length]['X_test'] = X_test\n",
    "    data_dict[length]['y_test'] = y_test\n",
    "    \n",
    "    # Print shapes and ensure no NaNs\n",
    "    print(f\"  X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "    print(f\"  X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
    "    print(f\"  X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Build LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(hyperparams, input_length):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=hyperparams['units'], activation='relu', input_shape=(input_length, 1)))\n",
    "    model.add(Dropout(rate=hyperparams['dropout']))\n",
    "    model.add(Dense(6))  # Output layer for multi-step forecasting\n",
    "\n",
    "    # Compile the model with MSE as the loss function\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=hyperparams['learning_rate'])\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mse'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Define the hyperparameter grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter options\n",
    "units_list = [32, 64, 128, 256]\n",
    "dropout_rates = [0.0, 0.1, 0.2, 0.3, 0.4]\n",
    "learning_rates = [0.01, 0.001, 0.0005]\n",
    "batch_sizes = [32, 64, 128]\n",
    "\n",
    "# Create all possible combinations\n",
    "all_combinations = list(product(units_list, dropout_rates, learning_rates, batch_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(32, 0.0, 0.01, 32),\n",
       " (32, 0.0, 0.01, 64),\n",
       " (32, 0.0, 0.01, 128),\n",
       " (32, 0.0, 0.001, 32),\n",
       " (32, 0.0, 0.001, 64),\n",
       " (32, 0.0, 0.001, 128),\n",
       " (32, 0.0, 0.0005, 32),\n",
       " (32, 0.0, 0.0005, 64),\n",
       " (32, 0.0, 0.0005, 128),\n",
       " (32, 0.1, 0.01, 32),\n",
       " (32, 0.1, 0.01, 64),\n",
       " (32, 0.1, 0.01, 128),\n",
       " (32, 0.1, 0.001, 32),\n",
       " (32, 0.1, 0.001, 64),\n",
       " (32, 0.1, 0.001, 128),\n",
       " (32, 0.1, 0.0005, 32),\n",
       " (32, 0.1, 0.0005, 64),\n",
       " (32, 0.1, 0.0005, 128),\n",
       " (32, 0.2, 0.01, 32),\n",
       " (32, 0.2, 0.01, 64),\n",
       " (32, 0.2, 0.01, 128),\n",
       " (32, 0.2, 0.001, 32),\n",
       " (32, 0.2, 0.001, 64),\n",
       " (32, 0.2, 0.001, 128),\n",
       " (32, 0.2, 0.0005, 32),\n",
       " (32, 0.2, 0.0005, 64),\n",
       " (32, 0.2, 0.0005, 128),\n",
       " (32, 0.3, 0.01, 32),\n",
       " (32, 0.3, 0.01, 64),\n",
       " (32, 0.3, 0.01, 128),\n",
       " (32, 0.3, 0.001, 32),\n",
       " (32, 0.3, 0.001, 64),\n",
       " (32, 0.3, 0.001, 128),\n",
       " (32, 0.3, 0.0005, 32),\n",
       " (32, 0.3, 0.0005, 64),\n",
       " (32, 0.3, 0.0005, 128),\n",
       " (32, 0.4, 0.01, 32),\n",
       " (32, 0.4, 0.01, 64),\n",
       " (32, 0.4, 0.01, 128),\n",
       " (32, 0.4, 0.001, 32),\n",
       " (32, 0.4, 0.001, 64),\n",
       " (32, 0.4, 0.001, 128),\n",
       " (32, 0.4, 0.0005, 32),\n",
       " (32, 0.4, 0.0005, 64),\n",
       " (32, 0.4, 0.0005, 128),\n",
       " (64, 0.0, 0.01, 32),\n",
       " (64, 0.0, 0.01, 64),\n",
       " (64, 0.0, 0.01, 128),\n",
       " (64, 0.0, 0.001, 32),\n",
       " (64, 0.0, 0.001, 64),\n",
       " (64, 0.0, 0.001, 128),\n",
       " (64, 0.0, 0.0005, 32),\n",
       " (64, 0.0, 0.0005, 64),\n",
       " (64, 0.0, 0.0005, 128),\n",
       " (64, 0.1, 0.01, 32),\n",
       " (64, 0.1, 0.01, 64),\n",
       " (64, 0.1, 0.01, 128),\n",
       " (64, 0.1, 0.001, 32),\n",
       " (64, 0.1, 0.001, 64),\n",
       " (64, 0.1, 0.001, 128),\n",
       " (64, 0.1, 0.0005, 32),\n",
       " (64, 0.1, 0.0005, 64),\n",
       " (64, 0.1, 0.0005, 128),\n",
       " (64, 0.2, 0.01, 32),\n",
       " (64, 0.2, 0.01, 64),\n",
       " (64, 0.2, 0.01, 128),\n",
       " (64, 0.2, 0.001, 32),\n",
       " (64, 0.2, 0.001, 64),\n",
       " (64, 0.2, 0.001, 128),\n",
       " (64, 0.2, 0.0005, 32),\n",
       " (64, 0.2, 0.0005, 64),\n",
       " (64, 0.2, 0.0005, 128),\n",
       " (64, 0.3, 0.01, 32),\n",
       " (64, 0.3, 0.01, 64),\n",
       " (64, 0.3, 0.01, 128),\n",
       " (64, 0.3, 0.001, 32),\n",
       " (64, 0.3, 0.001, 64),\n",
       " (64, 0.3, 0.001, 128),\n",
       " (64, 0.3, 0.0005, 32),\n",
       " (64, 0.3, 0.0005, 64),\n",
       " (64, 0.3, 0.0005, 128),\n",
       " (64, 0.4, 0.01, 32),\n",
       " (64, 0.4, 0.01, 64),\n",
       " (64, 0.4, 0.01, 128),\n",
       " (64, 0.4, 0.001, 32),\n",
       " (64, 0.4, 0.001, 64),\n",
       " (64, 0.4, 0.001, 128),\n",
       " (64, 0.4, 0.0005, 32),\n",
       " (64, 0.4, 0.0005, 64),\n",
       " (64, 0.4, 0.0005, 128),\n",
       " (128, 0.0, 0.01, 32),\n",
       " (128, 0.0, 0.01, 64),\n",
       " (128, 0.0, 0.01, 128),\n",
       " (128, 0.0, 0.001, 32),\n",
       " (128, 0.0, 0.001, 64),\n",
       " (128, 0.0, 0.001, 128),\n",
       " (128, 0.0, 0.0005, 32),\n",
       " (128, 0.0, 0.0005, 64),\n",
       " (128, 0.0, 0.0005, 128),\n",
       " (128, 0.1, 0.01, 32),\n",
       " (128, 0.1, 0.01, 64),\n",
       " (128, 0.1, 0.01, 128),\n",
       " (128, 0.1, 0.001, 32),\n",
       " (128, 0.1, 0.001, 64),\n",
       " (128, 0.1, 0.001, 128),\n",
       " (128, 0.1, 0.0005, 32),\n",
       " (128, 0.1, 0.0005, 64),\n",
       " (128, 0.1, 0.0005, 128),\n",
       " (128, 0.2, 0.01, 32),\n",
       " (128, 0.2, 0.01, 64),\n",
       " (128, 0.2, 0.01, 128),\n",
       " (128, 0.2, 0.001, 32),\n",
       " (128, 0.2, 0.001, 64),\n",
       " (128, 0.2, 0.001, 128),\n",
       " (128, 0.2, 0.0005, 32),\n",
       " (128, 0.2, 0.0005, 64),\n",
       " (128, 0.2, 0.0005, 128),\n",
       " (128, 0.3, 0.01, 32),\n",
       " (128, 0.3, 0.01, 64),\n",
       " (128, 0.3, 0.01, 128),\n",
       " (128, 0.3, 0.001, 32),\n",
       " (128, 0.3, 0.001, 64),\n",
       " (128, 0.3, 0.001, 128),\n",
       " (128, 0.3, 0.0005, 32),\n",
       " (128, 0.3, 0.0005, 64),\n",
       " (128, 0.3, 0.0005, 128),\n",
       " (128, 0.4, 0.01, 32),\n",
       " (128, 0.4, 0.01, 64),\n",
       " (128, 0.4, 0.01, 128),\n",
       " (128, 0.4, 0.001, 32),\n",
       " (128, 0.4, 0.001, 64),\n",
       " (128, 0.4, 0.001, 128),\n",
       " (128, 0.4, 0.0005, 32),\n",
       " (128, 0.4, 0.0005, 64),\n",
       " (128, 0.4, 0.0005, 128),\n",
       " (256, 0.0, 0.01, 32),\n",
       " (256, 0.0, 0.01, 64),\n",
       " (256, 0.0, 0.01, 128),\n",
       " (256, 0.0, 0.001, 32),\n",
       " (256, 0.0, 0.001, 64),\n",
       " (256, 0.0, 0.001, 128),\n",
       " (256, 0.0, 0.0005, 32),\n",
       " (256, 0.0, 0.0005, 64),\n",
       " (256, 0.0, 0.0005, 128),\n",
       " (256, 0.1, 0.01, 32),\n",
       " (256, 0.1, 0.01, 64),\n",
       " (256, 0.1, 0.01, 128),\n",
       " (256, 0.1, 0.001, 32),\n",
       " (256, 0.1, 0.001, 64),\n",
       " (256, 0.1, 0.001, 128),\n",
       " (256, 0.1, 0.0005, 32),\n",
       " (256, 0.1, 0.0005, 64),\n",
       " (256, 0.1, 0.0005, 128),\n",
       " (256, 0.2, 0.01, 32),\n",
       " (256, 0.2, 0.01, 64),\n",
       " (256, 0.2, 0.01, 128),\n",
       " (256, 0.2, 0.001, 32),\n",
       " (256, 0.2, 0.001, 64),\n",
       " (256, 0.2, 0.001, 128),\n",
       " (256, 0.2, 0.0005, 32),\n",
       " (256, 0.2, 0.0005, 64),\n",
       " (256, 0.2, 0.0005, 128),\n",
       " (256, 0.3, 0.01, 32),\n",
       " (256, 0.3, 0.01, 64),\n",
       " (256, 0.3, 0.01, 128),\n",
       " (256, 0.3, 0.001, 32),\n",
       " (256, 0.3, 0.001, 64),\n",
       " (256, 0.3, 0.001, 128),\n",
       " (256, 0.3, 0.0005, 32),\n",
       " (256, 0.3, 0.0005, 64),\n",
       " (256, 0.3, 0.0005, 128),\n",
       " (256, 0.4, 0.01, 32),\n",
       " (256, 0.4, 0.01, 64),\n",
       " (256, 0.4, 0.01, 128),\n",
       " (256, 0.4, 0.001, 32),\n",
       " (256, 0.4, 0.001, 64),\n",
       " (256, 0.4, 0.001, 128),\n",
       " (256, 0.4, 0.0005, 32),\n",
       " (256, 0.4, 0.0005, 64),\n",
       " (256, 0.4, 0.0005, 128)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Defining manual grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting grid search for input length: 360\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1729247188.981079 2088033 service.cc:146] XLA service 0x74a0800b7a60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1729247188.981111 2088033 service.cc:154]   StreamExecutor device (0): NVIDIA A30, Compute Capability 8.0\n",
      "2024-10-18 11:26:29.014304: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-18 11:26:29.408747: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "I0000 00:00:1729247190.328027 2088033 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0140\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0113\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.0126\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.0129\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.0126\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.0118\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0142\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0138\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0128\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.0131\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0102\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0151\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0119\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.0132\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.0113\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0124\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0137\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.0126\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0125\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.0127\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0137\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.0122\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-18 15:04:04.793294: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_19', 40 bytes spill stores, 40 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0138\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0129\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0067\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-18 16:23:13.458963: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_19', 40 bytes spill stores, 40 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-18 16:27:28.002051: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_19', 48 bytes spill stores, 48 bytes spill loads\n",
      "\n",
      "2024-10-18 16:27:34.447173: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_19', 84 bytes spill stores, 84 bytes spill loads\n",
      "\n",
      "2024-10-18 16:27:34.800840: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_19', 84 bytes spill stores, 84 bytes spill loads\n",
      "\n",
      "2024-10-18 16:27:34.871980: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_19', 36 bytes spill stores, 36 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-18 16:28:21.691443: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_19', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "2024-10-18 16:28:21.999422: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_19', 84 bytes spill stores, 84 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0128\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0119\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0039\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Completed grid search for input length: 360\n",
      "  Best Validation MSE: 0.0036\n",
      "  Best Hyperparameters: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "\n",
      "Starting grid search for input length: 384\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0035\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.0142\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.0127\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0297\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0089\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0131\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0141\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.0134\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0139\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0132\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0123\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0130\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.0122\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0132\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0126\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0120\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0132\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0129\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0140\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0136\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.0123\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.0141\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-18 21:38:46.794978: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_19', 40 bytes spill stores, 40 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.0140\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0035\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0149\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0121\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0137\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0135\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-18 23:01:57.368045: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_19', 40 bytes spill stores, 40 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-18 23:03:19.187186: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_19', 76 bytes spill stores, 76 bytes spill loads\n",
      "\n",
      "2024-10-18 23:03:19.221955: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_19', 84 bytes spill stores, 84 bytes spill loads\n",
      "\n",
      "2024-10-18 23:03:19.299471: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_828', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-10-18 23:03:19.546313: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_19', 36 bytes spill stores, 36 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-18 23:18:44.523371: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1202', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0039\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Completed grid search for input length: 384\n",
      "  Best Validation MSE: 0.0035\n",
      "  Best Hyperparameters: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "\n",
      "Starting grid search for input length: 408\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.0125\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.0121\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0120\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.0137\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0144\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0129\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0122\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.0145\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0133\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0134\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.0122\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0130\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.0134\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.0117\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0141\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0067\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0124\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0122\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-19 06:11:00.964765: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_19', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "2024-10-19 06:11:01.009034: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_19', 84 bytes spill stores, 84 bytes spill loads\n",
      "\n",
      "2024-10-19 06:11:01.451119: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_19', 36 bytes spill stores, 36 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-19 06:11:49.985114: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_19', 64 bytes spill stores, 64 bytes spill loads\n",
      "\n",
      "2024-10-19 06:11:50.465340: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_19', 84 bytes spill stores, 84 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0041\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Completed grid search for input length: 408\n",
      "  Best Validation MSE: 0.0036\n",
      "  Best Hyperparameters: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "\n",
      "Starting grid search for input length: 432\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0141\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.0127\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0133\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0135\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0143\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0143\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.0124\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.0121\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.0139\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0141\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0127\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0112\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.0124\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.0125\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0143\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0127\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.0129\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.0137\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0140\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0074\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0119\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-19 13:14:01.250446: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_19', 36 bytes spill stores, 36 bytes spill loads\n",
      "\n",
      "2024-10-19 13:14:01.489110: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_19', 84 bytes spill stores, 84 bytes spill loads\n",
      "\n",
      "2024-10-19 13:14:01.746002: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_19', 48 bytes spill stores, 48 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0041\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Completed grid search for input length: 432\n",
      "  Best Validation MSE: 0.0036\n",
      "  Best Hyperparameters: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "\n",
      "Starting grid search for input length: 456\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0134\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.0122\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0121\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.0055\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0133\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0080\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0110\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0128\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0139\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.0137\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0126\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.0122\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0123\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.0128\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0139\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0129\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0118\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.0134\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0132\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0133\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.0132\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0128\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0125\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-19 18:33:42.165243: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_19', 28 bytes spill stores, 28 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.0126\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0131\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0134\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-19 20:01:32.856896: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_19', 148 bytes spill stores, 264 bytes spill loads\n",
      "\n",
      "2024-10-19 20:01:32.925534: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_19', 208 bytes spill stores, 324 bytes spill loads\n",
      "\n",
      "2024-10-19 20:01:33.631125: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_19', 28 bytes spill stores, 28 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0044\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Completed grid search for input length: 456\n",
      "  Best Validation MSE: 0.0039\n",
      "  Best Hyperparameters: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "\n",
      "Starting grid search for input length: 480\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0064\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.0141\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.0141\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.0131\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.0138\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.0141\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.0110\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.0136\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0145\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0129\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0137\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0143\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.0119\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0129\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0153\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0049\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Completed grid search for input length: 480\n",
      "  Best Validation MSE: 0.0043\n",
      "  Best Hyperparameters: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "\n",
      "Starting grid search for input length: 504\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0142\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.0055\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0130\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0152\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.0147\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0140\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0055\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.0141\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.0057\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0056\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.0143\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0055\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0142\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0055\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0143\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.0150\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0121\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0055\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.0129\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.0134\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0059\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0154\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0055\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0147\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0146\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0056\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0055\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.0141\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0146\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-20 08:47:18.156298: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_19', 28 bytes spill stores, 28 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0152\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-20 10:37:33.788415: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_19', 212 bytes spill stores, 316 bytes spill loads\n",
      "\n",
      "2024-10-20 10:37:33.849223: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_19', 152 bytes spill stores, 248 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0055\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0054\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Completed grid search for input length: 504\n",
      "  Best Validation MSE: 0.0048\n",
      "  Best Hyperparameters: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "for length in input_lengths:\n",
    "    print(f\"Starting grid search for input length: {length}\")\n",
    "    \n",
    "    X_train = data_dict[length]['X_train']\n",
    "    y_train = data_dict[length]['y_train']\n",
    "    X_val = data_dict[length]['X_val']\n",
    "    y_val = data_dict[length]['y_val']\n",
    "    \n",
    "    best_mse = float('inf')\n",
    "    best_params = {}\n",
    "    best_model = None\n",
    "    \n",
    "    for idx, combination in enumerate(all_combinations):\n",
    "        # Extract hyperparameters\n",
    "        hyperparams = {\n",
    "            'units': combination[0],\n",
    "            'dropout': combination[1],\n",
    "            'learning_rate': combination[2],\n",
    "            'batch_size': combination[3]\n",
    "        }\n",
    "        \n",
    "        print(f\"  Evaluating combination {idx + 1}/{len(all_combinations)}: {hyperparams}\")\n",
    "        \n",
    "        model = build_lstm_model(hyperparams, length)\n",
    "        \n",
    "        # Early Stopping Callback\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True,verbose=1)\n",
    "        \n",
    "        # Train the model\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=50,\n",
    "            batch_size=hyperparams['batch_size'],\n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=[early_stop],\n",
    "            verbose=0  # Set to 1 to see training progress\n",
    "        )\n",
    "        \n",
    "        # Retrieve the best validation MSE from the history\n",
    "        current_best_mse = min(history.history['val_loss'])\n",
    "        print(f\"Validation loss: {current_best_mse:.4f}\")\n",
    "        \n",
    "        # Check if this is the best model so far\n",
    "        if current_best_mse < best_mse:\n",
    "            best_mse = current_best_mse\n",
    "            best_params = hyperparams.copy()\n",
    "            best_model = model  # Optionally, save the model if needed\n",
    "    \n",
    "    # After evaluating all combinations, store the best results\n",
    "    results.append({\n",
    "        'Input_Length': length,\n",
    "        'Best_MSE': best_mse,\n",
    "        'Validation_MSE': mean_squared_error(y_val, best_model.predict(X_val)),\n",
    "        'Validation_MAE': mean_absolute_error(y_val, best_model.predict(X_val)),\n",
    "        'Validation_MAPE': mean_absolute_percentage_error(y_val, best_model.predict(X_val)) * 100,  # In percentage\n",
    "        'Validation_RMSE': np.sqrt(mean_squared_error(y_val, best_model.predict(X_val))),\n",
    "        'Best_Hyperparameters': best_params\n",
    "    })\n",
    "    \n",
    "    print(f\"Completed grid search for input length: {length}\")\n",
    "    print(f\"  Best Validation MSE: {best_mse:.4f}\")\n",
    "    print(f\"  Best Hyperparameters: {best_params}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 192\n",
    "  Best Validation MSE: 0.0040\n",
    "  Best Hyperparameters: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 216\n",
    "  Best Validation MSE: 0.0035\n",
    "  Best Hyperparameters: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 240\n",
    "  Best Validation MSE: 0.0036\n",
    "  Best Hyperparameters: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 264\n",
    "  Best Validation MSE: 0.0038\n",
    "  Best Hyperparameters: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 288\n",
    "  Best Validation MSE: 0.0036\n",
    "  Best Hyperparameters: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 312\n",
    "  Best Validation MSE: 0.0035\n",
    "  Best Hyperparameters: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 336\n",
    "  Best Validation MSE: 0.0035\n",
    "  Best Hyperparameters: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 360\n",
    "  Best Validation MSE: 0.0036\n",
    "  Best Hyperparameters: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 384\n",
    "  Best Validation MSE: 0.0035\n",
    "  Best Hyperparameters: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 408\n",
    "  Best Validation MSE: 0.0036\n",
    "  Best Hyperparameters: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 432\n",
    "  Best Validation MSE: 0.0036\n",
    "  Best Hyperparameters: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 456\n",
    "  Best Validation MSE: 0.0039\n",
    "  Best Hyperparameters: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 480\n",
    "  Best Validation MSE: 0.0043\n",
    "  Best Hyperparameters: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 504\n",
    "  Best Validation MSE: 0.0048\n",
    "  Best Hyperparameters: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Storing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Results DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input_Length</th>\n",
       "      <th>Best_MSE</th>\n",
       "      <th>Validation_MSE</th>\n",
       "      <th>Validation_MAE</th>\n",
       "      <th>Validation_MAPE</th>\n",
       "      <th>Validation_RMSE</th>\n",
       "      <th>units</th>\n",
       "      <th>dropout</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>360</td>\n",
       "      <td>0.003563</td>\n",
       "      <td>0.003563</td>\n",
       "      <td>0.042866</td>\n",
       "      <td>40.809849</td>\n",
       "      <td>0.059695</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>384</td>\n",
       "      <td>0.003470</td>\n",
       "      <td>0.003470</td>\n",
       "      <td>0.042129</td>\n",
       "      <td>38.756887</td>\n",
       "      <td>0.058907</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>408</td>\n",
       "      <td>0.003573</td>\n",
       "      <td>0.003573</td>\n",
       "      <td>0.043253</td>\n",
       "      <td>50.933360</td>\n",
       "      <td>0.059774</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>432</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>0.003649</td>\n",
       "      <td>0.042154</td>\n",
       "      <td>41.099230</td>\n",
       "      <td>0.060411</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>456</td>\n",
       "      <td>0.003933</td>\n",
       "      <td>0.003933</td>\n",
       "      <td>0.044870</td>\n",
       "      <td>46.098188</td>\n",
       "      <td>0.062716</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>480</td>\n",
       "      <td>0.004323</td>\n",
       "      <td>0.004323</td>\n",
       "      <td>0.046985</td>\n",
       "      <td>47.611384</td>\n",
       "      <td>0.065748</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>504</td>\n",
       "      <td>0.004754</td>\n",
       "      <td>0.004754</td>\n",
       "      <td>0.049175</td>\n",
       "      <td>51.245178</td>\n",
       "      <td>0.068949</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Input_Length  Best_MSE  Validation_MSE  Validation_MAE  Validation_MAPE  \\\n",
       "0           360  0.003563        0.003563        0.042866        40.809849   \n",
       "1           384  0.003470        0.003470        0.042129        38.756887   \n",
       "2           408  0.003573        0.003573        0.043253        50.933360   \n",
       "3           432  0.003650        0.003649        0.042154        41.099230   \n",
       "4           456  0.003933        0.003933        0.044870        46.098188   \n",
       "5           480  0.004323        0.004323        0.046985        47.611384   \n",
       "6           504  0.004754        0.004754        0.049175        51.245178   \n",
       "\n",
       "   Validation_RMSE  units  dropout  learning_rate  batch_size  \n",
       "0         0.059695  256.0      0.0           0.01        32.0  \n",
       "1         0.058907   32.0      0.0           0.01        32.0  \n",
       "2         0.059774  256.0      0.4           0.01        64.0  \n",
       "3         0.060411   64.0      0.1           0.01        64.0  \n",
       "4         0.062716   64.0      0.3           0.01        64.0  \n",
       "5         0.065748   64.0      0.3           0.01        64.0  \n",
       "6         0.068949  128.0      0.3           0.01        64.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the results list to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Expand the hyperparameters dictionary into separate columns for clarity\n",
    "hyperparams_df = results_df['Best_Hyperparameters'].apply(pd.Series)\n",
    "\n",
    "# Combine the main dataframe with hyperparameters\n",
    "final_results_df = pd.concat([results_df.drop('Best_Hyperparameters', axis=1), hyperparams_df], axis=1)\n",
    "\n",
    "# Display the final dataframe\n",
    "print(\"Final Results DataFrame:\")\n",
    "final_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Results\n",
    "\n",
    "| Input_Length | Best Validation MSE | units | dropout | learning_rate | batch_size |\n",
    "|--------------|---------------------|-------|---------|---------------|------------|\n",
    "| 24           | 0.004132            | 256   | 0.4     | 0.001         | 32         |\n",
    "| 48           | 0.004258            | 32    | 0.1     | 0.010         | 64         |\n",
    "| 72           | 0.004136            | 64    | 0.1     | 0.010         | 64         |\n",
    "| 96           | 0.004128            | 64    | 0.1     | 0.010         | 64         |\n",
    "| 120          | 0.003844            | 128   | 0.2     | 0.010         | 64         |\n",
    "| 144          | 0.003995            | 32    | 0.0     | 0.010         | 64         |\n",
    "| 168          | 0.004008            | 32    | 0.0     | 0.001         | 32         |\n",
    "| 192          | 0.0040              | 32    | 0.2     | 0.01          | 32         |\n",
    "| 216          | 0.0035              | 32    | 0.2     | 0.01          | 128        |\n",
    "| 240          | 0.0036              | 32    | 0.0     | 0.01          | 128        |\n",
    "| 264          | 0.0038              | 256   | 0.3     | 0.001         | 32         |\n",
    "| 288          | 0.0036              | 256   | 0.0     | 0.01          | 128        |\n",
    "| 312          | 0.0035              | 128   | 0.2     | 0.01          | 128        |\n",
    "| 336          | 0.0035              | 64    | 0.2     | 0.01          | 64         |\n",
    "| 360          | 0.0036              | 256   | 0.0     | 0.01          | 32         |\n",
    "| 384          | 0.0035              | 32    | 0.0     | 0.01          | 32         |\n",
    "| 408          | 0.0036              | 256   | 0.4     | 0.01          | 64         |\n",
    "| 432          | 0.0036              | 64    | 0.1     | 0.01          | 64         |\n",
    "| 456          | 0.0039              | 64    | 0.3     | 0.01          | 64         |\n",
    "| 480          | 0.0043              | 64    | 0.3     | 0.01          | 64         |\n",
    "| 504          | 0.0048              | 128   | 0.3     | 0.01          | 64         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Retrain the model after getting the best hyperparameters of each input length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparameters = {\n",
    "    24: {\n",
    "        'units': 256,\n",
    "        'dropout': 0.4,\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    48: {\n",
    "        'units': 32,\n",
    "        'dropout': 0.1,\n",
    "        'learning_rate': 0.01,\n",
    "        'batch_size': 64\n",
    "    },\n",
    "    72: {\n",
    "        'units': 64.0,\n",
    "        'dropout': 0.1,\n",
    "        'learning_rate': 0.01,\n",
    "        'batch_size': 64.0\n",
    "    },\n",
    "    96: {\n",
    "        'units': 64,\n",
    "        'dropout': 0.1,\n",
    "        'learning_rate': 0.01,\n",
    "        'batch_size': 64\n",
    "    },\n",
    "    120: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.01,\n",
    "        'batch_size': 64\n",
    "    },\n",
    "    144: {\n",
    "        'units': 32,\n",
    "        'dropout': 0.0,\n",
    "        'learning_rate': 0.01,\n",
    "        'batch_size': 64\n",
    "    },\n",
    "    168: {\n",
    "        'units': 32,\n",
    "        'dropout': 0.0,\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    192: {\n",
    "        'units': 32,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.01,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    216: {\n",
    "        'units': 32,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.01,\n",
    "        'batch_size': 128\n",
    "    },\n",
    "    240: {\n",
    "        'units': 32,\n",
    "        'dropout': 0.0,\n",
    "        'learning_rate': 0.01,\n",
    "        'batch_size': 128\n",
    "    },\n",
    "    264: {\n",
    "        'units': 256,\n",
    "        'dropout': 0.3,\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    288: {\n",
    "        'units': 256,\n",
    "        'dropout': 0.0,\n",
    "        'learning_rate': 0.01,\n",
    "        'batch_size': 128\n",
    "    },\n",
    "    312: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.01,\n",
    "        'batch_size': 128\n",
    "    },\n",
    "    336: {\n",
    "        'units': 64,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.01,\n",
    "        'batch_size': 64\n",
    "    },\n",
    "    360: {\n",
    "        'units': 256,\n",
    "        'dropout': 0.0,\n",
    "        'learning_rate': 0.01,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    384: {\n",
    "        'units': 32,\n",
    "        'dropout': 0.0,\n",
    "        'learning_rate': 0.01,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    408: {\n",
    "        'units': 256,\n",
    "        'dropout': 0.4,\n",
    "        'learning_rate': 0.01,\n",
    "        'batch_size': 64\n",
    "    },\n",
    "    432: {\n",
    "        'units': 64,\n",
    "        'dropout': 0.1,\n",
    "        'learning_rate': 0.01,\n",
    "        'batch_size': 64\n",
    "    },\n",
    "    456: {\n",
    "        'units': 64,\n",
    "        'dropout': 0.3,\n",
    "        'learning_rate': 0.01,\n",
    "        'batch_size': 64\n",
    "    },\n",
    "    480: {\n",
    "        'units': 64,\n",
    "        'dropout': 0.3,\n",
    "        'learning_rate': 0.01,\n",
    "        'batch_size': 64\n",
    "    },\n",
    "    504: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.3,\n",
    "        'learning_rate': 0.01,\n",
    "        'batch_size': 64\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(hyperparams,data_dict,length, seed=None):  # add seed\n",
    "    if seed is not None:\n",
    "        set_seed(seed)\n",
    "    \n",
    "    #get the data of each length\n",
    "    X_train = data_dict[length]['X_train']\n",
    "    y_train = data_dict[length]['y_train']\n",
    "    X_val = data_dict[length]['X_val']\n",
    "    y_val = data_dict[length]['y_val']\n",
    "    \n",
    "    # Train the model\n",
    "    model = build_lstm_model(hyperparams, length)    \n",
    "    # Early Stopping Callback\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True,verbose=1)    \n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=100,\n",
    "        batch_size=hyperparams['batch_size'],\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[early_stop],\n",
    "        verbose=0  # Set to 1 to see training progress\n",
    "    )\n",
    "    \n",
    "    # Retrieve the best validation MSE from the history\n",
    "    best_mse = min(history.history['val_loss'])\n",
    "    print(f\"Validation loss: {best_mse:.5f}\")\n",
    "    \n",
    "    return model, best_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "def make_prediction(model, X_obs, y_obs):\n",
    "    y_pred = model.predict(X_obs,verbose=0)\n",
    "    n_samples = X_obs.shape[0]\n",
    "    output_len = y_obs.shape[1]\n",
    "\n",
    "    # Reshape for inverse scaling\n",
    "    y_pred_reshaped = y_pred.reshape(-1, 1)\n",
    "    y_obs_reshaped = y_obs.reshape(-1, 1)\n",
    "\n",
    "    # Inverse transform\n",
    "    y_pred_inverse = scaler.inverse_transform(y_pred_reshaped).reshape(n_samples, output_len)\n",
    "    y_obs_inverse = scaler.inverse_transform(y_obs_reshaped).reshape(n_samples, output_len)\n",
    "\n",
    "    return y_pred_inverse, y_obs_inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Metrics for Each Time Step\n",
    "def evaluation(y_pred_inverse, y_obs_inverse):\n",
    "    \n",
    "    output_len = y_pred_inverse.shape[1]\n",
    "    metrics_list = []  # To store metrics for each time step\n",
    "    \n",
    "    for i in range(output_len):\n",
    "        y_true = y_obs_inverse[:, i]\n",
    "        y_pred = y_pred_inverse[:, i]\n",
    "\n",
    "        # Mean Absolute Error (MAE)\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "        # Mean Squared Error (MSE)\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "        # Root Mean Squared Error (RMSE)\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        # Mean Absolute Percentage Error (MAPE)\n",
    "        # Avoid division by zero by adding a small epsilon to y_test_flat if necessary\n",
    "        epsilon = 1e-10\n",
    "        y_true_safe = np.where(y_true == 0, epsilon, y_true)\n",
    "        mape = np.mean(np.abs((y_true - y_pred) / y_true_safe)) * 100\n",
    "\n",
    "                # Append the metrics for the current time step to the list\n",
    "        metrics_list.append({\n",
    "            'Time Step': i + 1,\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse,\n",
    "            'MAPE (%)': mape\n",
    "        })\n",
    "\n",
    "    # Create a DataFrame from the list of metrics\n",
    "    metrics_df = pd.DataFrame(metrics_list)\n",
    "    metrics_df.set_index('Time Step', inplace=True)\n",
    "\n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "\n",
      "--- Run 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\program\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00422\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\program\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00439\n",
      "\n",
      "--- Run 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\program\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m seed \u001b[38;5;241m=\u001b[39m run  \n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m model, mse \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhyperparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m X_train \u001b[38;5;241m=\u001b[39m data_dict[length][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_train\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     23\u001b[0m y_train \u001b[38;5;241m=\u001b[39m data_dict[length][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_train\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[1;32mIn[20], line 16\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(hyperparams, data_dict, length, seed)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Early Stopping Callback\u001b[39;00m\n\u001b[0;32m     14\u001b[0m early_stop \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)    \n\u001b[1;32m---> 16\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Set to 1 to see training progress\u001b[39;49;00m\n\u001b[0;32m     23\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Retrieve the best validation MSE from the history\u001b[39;00m\n\u001b[0;32m     26\u001b[0m best_mse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mE:\\program\\anaconda\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mE:\\program\\anaconda\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    322\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32mE:\\program\\anaconda\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mE:\\program\\anaconda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mE:\\program\\anaconda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mE:\\program\\anaconda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\program\\anaconda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mE:\\program\\anaconda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mE:\\program\\anaconda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mE:\\program\\anaconda\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1567\u001b[0m   )\n",
      "File \u001b[1;32mE:\\program\\anaconda\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mean_metrics_list=[]\n",
    "for length in best_hyperparameters.keys():\n",
    "    print(length)\n",
    "    \n",
    "    # Number of runs\n",
    "    n_runs = 10\n",
    "    \n",
    "    # get the best hyperparameter of each length\n",
    "    hyperparams = best_hyperparameters[length]\n",
    "    # Initialize lists to store mean metrics and all metrics from each run\n",
    "    mean_metrics_rows = []\n",
    "    df_all_metrics_list = []\n",
    "\n",
    "    for run in range(1, n_runs + 1):\n",
    "        print(f\"\\n--- Run {run} ---\")\n",
    "\n",
    "        # Optionally set a unique seed for each run to ensure variability\n",
    "        seed = run  \n",
    "        # Train the model\n",
    "        model, mse = train_model(hyperparams, data_dict, length, seed=seed)\n",
    "        \n",
    "        X_train = data_dict[length]['X_train']\n",
    "        y_train = data_dict[length]['y_train']\n",
    "        X_val = data_dict[length]['X_val']\n",
    "        y_val = data_dict[length]['y_val']\n",
    "        X_test = data_dict[length]['X_test']\n",
    "        y_test = data_dict[length]['y_test']\n",
    "\n",
    "        #get the true flow and predicted flow\n",
    "        y_pred_train, y_obs_train = make_prediction(model, X_train, y_train)\n",
    "        y_pred_val, y_obs_val = make_prediction(model, X_val, y_val)\n",
    "        y_pred_test, y_obs_test = make_prediction(model, X_test, y_test)\n",
    "\n",
    "        #calculate the evaluation metrics of each output step\n",
    "        df_train = evaluation(y_pred_train, y_obs_train).add_suffix('_train')\n",
    "        df_val = evaluation(y_pred_val, y_obs_val).add_suffix('_val')\n",
    "        df_test = evaluation(y_pred_test, y_obs_test).add_suffix('_test')\n",
    "\n",
    "        df_all_metrics = pd.concat([df_train, df_val, df_test], axis=1)\n",
    "        df_all_metrics.index.name = length\n",
    "        \n",
    "        # Append df_all_metrics to the list\n",
    "        df_all_metrics_list.append(df_all_metrics)\n",
    "\n",
    "        # Calculate mean for all output step\n",
    "        mean_metrics = df_val.mean()\n",
    "        mean_metrics_row = pd.DataFrame(mean_metrics).T\n",
    "        mean_metrics_row['MSE_val(loss)'] = mse\n",
    "        mean_metrics_row['input_len'] = length\n",
    "        mean_metrics_row = mean_metrics_row[['input_len','MSE_val(loss)', 'MAE_val', 'RMSE_val', 'MAPE (%)_val']]\n",
    "        \n",
    "        # Append to the list\n",
    "        mean_metrics_rows.append(mean_metrics_row)\n",
    "        \n",
    "    # Concatenate all df_all_metrics into a single DataFrame with a new level for runs\n",
    "    concatenated_all_metrics = pd.concat(df_all_metrics_list, keys=range(1, n_runs + 1), names=['Run', 'Time Step'])\n",
    "\n",
    "    # Calculate the mean across runs for each metric and time step\n",
    "    # This will group by 'Time Step' and calculate the mean of each metric across all runs\n",
    "    aggregated_all_metrics_mean = concatenated_all_metrics.groupby('Time Step').mean()\n",
    "    aggregated_all_metrics_mean.index.name = length\n",
    "\n",
    "    print(\"\\n--- Aggregated Mean of All Metrics Across 10 Runs ---\")\n",
    "    display(aggregated_all_metrics_mean)\n",
    "\n",
    "    # After all runs, create a DataFrame of mean metrics\n",
    "    mean_metrics_df = pd.concat(mean_metrics_rows, ignore_index=True)\n",
    "    # Calculate the mean of each metric across the 10 runs\n",
    "    final_mean_metrics = mean_metrics_df.mean()\n",
    "\n",
    "    # Create a DataFrame for the final mean metrics\n",
    "    final_mean_metrics_df = pd.DataFrame(final_mean_metrics).T\n",
    "    \n",
    "    mean_metrics_list.append(final_mean_metrics_df)\n",
    "\n",
    "mean_metrics_df = pd.concat(mean_metrics_list).reset_index(drop=True)\n",
    "print(\"\\n--- Final Mean Metrics Across 10 Runs ---\")\n",
    "mean_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to predict next 6 steps simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will use\n",
    "* the last 12 steps\n",
    "\n",
    "* previous one week (24 steps)\n",
    "\n",
    "* previous one month  (168 steps)\n",
    "\n",
    "*  to forecast current (0 step) and 5 steps ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1141040 into shape (168,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create input-output sequences with the provided function\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_train, y_train, X_train_df, y_train_df \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_multi_step_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_n_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mday_lag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweek_lag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_future_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m X_valid, y_valid, X_valid_df, y_valid_df \u001b[38;5;241m=\u001b[39m create_multi_step_sequence(valid_set, last_n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m7\u001b[39m, day_lag\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, week_lag\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, n_future_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)\n\u001b[0;32m      4\u001b[0m X_test, y_test, X_test_df, y_test_df \u001b[38;5;241m=\u001b[39m create_multi_step_sequence(test_set, last_n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m7\u001b[39m, day_lag\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, week_lag\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, n_future_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)\n",
      "Cell \u001b[1;32mIn[10], line 40\u001b[0m, in \u001b[0;36mcreate_multi_step_sequence\u001b[1;34m(data, last_n_steps, day_lag, week_lag, n_future_steps)\u001b[0m\n\u001b[0;32m     37\u001b[0m         y\u001b[38;5;241m.\u001b[39mappend(output_seq)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Convert to numpy arrays and reshape X to match CNN expected input (samples, timesteps, features)\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_n_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Add the 2 additional features (last_day_value, last_week_value)\u001b[39;00m\n\u001b[0;32m     41\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(y)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, n_future_steps)  \u001b[38;5;66;03m# Multiple output steps\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Convert the entire input and output into a pandas DataFrame with appropriate column names for multi-step prediction\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Define column names for the input DataFrame\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 1141040 into shape (168,1)"
     ]
    }
   ],
   "source": [
    "# Create input-output sequences with the provided function\n",
    "X_train, y_train, X_train_df, y_train_df = create_multi_step_sequence(train_set, last_n_steps=12, day_lag=24, week_lag=168, n_future_steps=6)\n",
    "X_valid, y_valid, X_valid_df, y_valid_df = create_multi_step_sequence(valid_set, last_n_steps=12, day_lag=24, week_lag=168, n_future_steps=6)\n",
    "X_test, y_test, X_test_df, y_test_df = create_multi_step_sequence(test_set, last_n_steps=12, day_lag=24, week_lag=168, n_future_steps=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model_multi_step(input_shape, n_outputs, units, dropout_rate, learning_rate):\n",
    "    model = keras.Sequential()\n",
    "    model.add(LSTM(units=units, activation='tanh', input_shape=input_shape))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(n_outputs))\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        loss='mse',  # Mean Squared Error loss for regression\n",
    "        optimizer=optimizer,\n",
    "        metrics=['mae']  # Mean Absolute Error as a metric\n",
    "    )\n",
    "    return model\n",
    "\n",
    "input_shape = (x_train_scaled.shape[1], x_train_scaled.shape[2])\n",
    "n_outputs = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCIZFe1MAx-X"
   },
   "source": [
    "## 6. Set Up Hyperparameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter options\n",
    "units_list = [50, 100, 200]\n",
    "dropout_rates = [0, 0.3, 0.5]\n",
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "batch_sizes = [32, 64, 128]\n",
    "\n",
    "# Create all possible combinations\n",
    "hyperparameter_combinations = list(product(units_list, dropout_rates, learning_rates, batch_sizes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ixRU8sQA8NW"
   },
   "source": [
    "## 7. Train the Model with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination 1/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.01, batch_size=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\program\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation MAE: 0.0602\n",
      "\n",
      "Combination 2/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.01, batch_size=64\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation MAE: 0.0600\n",
      "\n",
      "Combination 3/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.01, batch_size=128\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation MAE: 0.0600\n",
      "\n",
      "Combination 4/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0618\n",
      "\n",
      "Combination 5/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation MAE: 0.0634\n",
      "\n",
      "Combination 6/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0644\n",
      "\n",
      "Combination 7/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.0001, batch_size=32\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation MAE: 0.0685\n",
      "\n",
      "Combination 8/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0685\n",
      "\n",
      "Combination 9/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0700\n",
      "\n",
      "Combination 10/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.01, batch_size=32\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation MAE: 0.0610\n",
      "\n",
      "Combination 11/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.01, batch_size=64\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation MAE: 0.0604\n",
      "\n",
      "Combination 12/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.01, batch_size=128\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation MAE: 0.0611\n",
      "\n",
      "Combination 13/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0619\n",
      "\n",
      "Combination 14/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0640\n",
      "\n",
      "Combination 15/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0652\n",
      "\n",
      "Combination 16/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0688\n",
      "\n",
      "Combination 17/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0711\n",
      "\n",
      "Combination 18/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0740\n",
      "\n",
      "Combination 19/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.01, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation MAE: 0.0610\n",
      "\n",
      "Combination 20/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.01, batch_size=64\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation MAE: 0.0614\n",
      "\n",
      "Combination 21/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.01, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0603\n",
      "\n",
      "Combination 22/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation MAE: 0.0630\n",
      "\n",
      "Combination 23/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.001, batch_size=64\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation MAE: 0.0658\n",
      "\n",
      "Combination 24/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0657\n",
      "\n",
      "Combination 25/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0686\n",
      "\n",
      "Combination 26/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0720\n",
      "\n",
      "Combination 27/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0745\n",
      "\n",
      "Combination 28/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.01, batch_size=32\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation MAE: 0.0608\n",
      "\n",
      "Combination 29/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.01, batch_size=64\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation MAE: 0.0608\n",
      "\n",
      "Combination 30/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.01, batch_size=128\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation MAE: 0.0606\n",
      "\n",
      "Combination 31/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation MAE: 0.0603\n",
      "\n",
      "Combination 32/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0616\n",
      "\n",
      "Combination 33/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation MAE: 0.0633\n",
      "\n",
      "Combination 34/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0669\n",
      "\n",
      "Combination 35/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0679\n",
      "\n",
      "Combination 36/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0682\n",
      "\n",
      "Combination 37/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.01, batch_size=32\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation MAE: 0.0606\n",
      "\n",
      "Combination 38/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.01, batch_size=64\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation MAE: 0.0607\n",
      "\n",
      "Combination 39/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.01, batch_size=128\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation MAE: 0.0595\n",
      "\n",
      "Combination 40/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation MAE: 0.0610\n",
      "\n",
      "Combination 41/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0618\n",
      "\n",
      "Combination 42/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0643\n",
      "\n",
      "Combination 43/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation MAE: 0.0675\n",
      "\n",
      "Combination 44/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation MAE: 0.0687\n",
      "\n",
      "Combination 45/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.0001, batch_size=128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0708\n",
      "\n",
      "Combination 46/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.01, batch_size=32\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation MAE: 0.0605\n",
      "\n",
      "Combination 47/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.01, batch_size=64\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation MAE: 0.0606\n",
      "\n",
      "Combination 48/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.01, batch_size=128\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation MAE: 0.0608\n",
      "\n",
      "Combination 49/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0616\n",
      "\n",
      "Combination 50/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0632\n",
      "\n",
      "Combination 51/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.001, batch_size=128\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation MAE: 0.0654\n",
      "\n",
      "Combination 52/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0672\n",
      "\n",
      "Combination 53/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0690\n",
      "\n",
      "Combination 54/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0712\n",
      "\n",
      "Combination 55/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.01, batch_size=32\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation MAE: 0.0600\n",
      "\n",
      "Combination 56/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.01, batch_size=64\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation MAE: 0.0604\n",
      "\n",
      "Combination 57/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.01, batch_size=128\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation MAE: 0.0605\n",
      "\n",
      "Combination 58/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.001, batch_size=32\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation MAE: 0.0605\n",
      "\n",
      "Combination 59/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0601\n",
      "\n",
      "Combination 60/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0618\n",
      "\n",
      "Combination 61/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0658\n",
      "\n",
      "Combination 62/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0672\n",
      "\n",
      "Combination 63/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.0001, batch_size=128\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation MAE: 0.0688\n",
      "\n",
      "Combination 64/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.01, batch_size=32\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation MAE: 0.0612\n",
      "\n",
      "Combination 65/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.01, batch_size=64\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation MAE: 0.0612\n",
      "\n",
      "Combination 66/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.01, batch_size=128\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation MAE: 0.0607\n",
      "\n",
      "Combination 67/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0603\n",
      "\n",
      "Combination 68/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0607\n",
      "\n",
      "Combination 69/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation MAE: 0.0631\n",
      "\n",
      "Combination 70/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0659\n",
      "\n",
      "Combination 71/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0682\n",
      "\n",
      "Combination 72/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0688\n",
      "\n",
      "Combination 73/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.01, batch_size=32\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation MAE: 0.0596\n",
      "\n",
      "Combination 74/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.01, batch_size=64\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation MAE: 0.0595\n",
      "\n",
      "Combination 75/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.01, batch_size=128\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation MAE: 0.0605\n",
      "\n",
      "Combination 76/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0607\n",
      "\n",
      "Combination 77/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0612\n",
      "\n",
      "Combination 78/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0635\n",
      "\n",
      "Combination 79/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0661\n",
      "\n",
      "Combination 80/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0679\n",
      "\n",
      "Combination 81/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0689\n",
      "\n",
      "Best Hyperparameters:\n",
      "units: 100\n",
      "dropout_rate: 0.3\n",
      "learning_rate: 0.01\n",
      "batch_size: 128\n",
      "Best Validation MAE: 0.0595\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables to store the best model and hyperparameters\n",
    "best_val_mae = np.inf\n",
    "best_hyperparams = None\n",
    "best_model = None\n",
    "\n",
    "for idx, (units, dropout_rate, learning_rate, batch_size) in enumerate(hyperparameter_combinations):\n",
    "    print(f\"\\nCombination {idx+1}/{len(hyperparameter_combinations)}\")\n",
    "    print(f\"Training with units={units}, dropout_rate={dropout_rate}, learning_rate={learning_rate}, batch_size={batch_size}\")\n",
    "\n",
    "    # Create the LSTM model with the current hyperparameters\n",
    "    model = create_lstm_model_multi_step(\n",
    "        input_shape=input_shape,\n",
    "        n_outputs=n_outputs,\n",
    "        units=units,\n",
    "        dropout_rate=dropout_rate,\n",
    "        learning_rate=learning_rate\n",
    "    )\n",
    "\n",
    "    # Initialize EarlyStopping\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_mae',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        x_train_scaled, y_train_scaled,\n",
    "        epochs=50,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_val_scaled, y_val_scaled),\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Get the best validation MAE from this training run\n",
    "    val_mae = min(history.history['val_mae'])\n",
    "    print(f\"Validation MAE: {val_mae:.4f}\")\n",
    "\n",
    "    # Update best model if current one is better\n",
    "    if val_mae < best_val_mae:\n",
    "        best_val_mae = val_mae\n",
    "        best_model = model\n",
    "        best_hyperparams = {\n",
    "            'units': units,\n",
    "            'dropout_rate': dropout_rate,\n",
    "            'learning_rate': learning_rate,\n",
    "            'batch_size': batch_size\n",
    "        }\n",
    "\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "for param, value in best_hyperparams.items():\n",
    "    print(f\"{param}: {value}\")\n",
    "print(f\"Best Validation MAE: {best_val_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "13:33"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Hyperparameters for full time:\n",
    "units: 200\n",
    "dropout_rate: 0.5\n",
    "learning_rate: 0.01\n",
    "batch_size: 32\n",
    "Best Validation MAE: 0.0503\n",
    "\n",
    "Best Hyperparameters for after covid:\n",
    "units: 100\n",
    "dropout_rate: 0.3\n",
    "learning_rate: 0.01\n",
    "batch_size: 128\n",
    "Best Validation MAE: 0.0595"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred_scaled = best_model.predict(x_test_scaled)\n",
    "\n",
    "# Reshape for inverse scaling\n",
    "y_pred_reshaped = y_pred_scaled.reshape(-1, 1)\n",
    "y_test_reshaped = y_test_scaled.reshape(-1, 1)\n",
    "\n",
    "# Inverse transform\n",
    "y_pred_inverse = y_scaler.inverse_transform(y_pred_reshaped).reshape(n_test_samples, n_outputs)\n",
    "y_test_inverse = y_scaler.inverse_transform(y_test_reshaped).reshape(n_test_samples, n_outputs)\n",
    "\n",
    "y_test_flat = y_test_inverse.flatten()\n",
    "y_pred_flat = y_pred_inverse.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9SREwnRqxMN1"
   },
   "source": [
    "## 9. Evaluating the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time Step 1 Evaluation Metrics:\n",
      "RMSE: 28.4454\n",
      "MAE: 20.8450\n",
      "MAPE: 19.44%\n",
      "\n",
      "Time Step 2 Evaluation Metrics:\n",
      "RMSE: 36.2563\n",
      "MAE: 26.7673\n",
      "MAPE: 25.02%\n",
      "\n",
      "Time Step 3 Evaluation Metrics:\n",
      "RMSE: 43.7203\n",
      "MAE: 33.1341\n",
      "MAPE: 29.97%\n",
      "\n",
      "Time Step 4 Evaluation Metrics:\n",
      "RMSE: 49.3573\n",
      "MAE: 38.0972\n",
      "MAPE: 35.19%\n",
      "\n",
      "Time Step 5 Evaluation Metrics:\n",
      "RMSE: 53.2812\n",
      "MAE: 41.5888\n",
      "MAPE: 39.42%\n",
      "\n",
      "Time Step 6 Evaluation Metrics:\n",
      "RMSE: 53.3926\n",
      "MAE: 42.0135\n",
      "MAPE: 44.19%\n"
     ]
    }
   ],
   "source": [
    "# Compute Metrics for Each Time Step\n",
    "\n",
    "for i in range(n_outputs):\n",
    "    y_true = y_test_inverse[:, i]\n",
    "    y_pred = y_pred_inverse[:, i]\n",
    "\n",
    "    # Mean Absolute Error (MAE)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "    # Mean Squared Error (MSE)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "    # Root Mean Squared Error (RMSE)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # Mean Absolute Percentage Error (MAPE)\n",
    "    # Avoid division by zero by adding a small epsilon to y_test_flat if necessary\n",
    "    epsilon = 1e-10\n",
    "    y_true_safe = np.where(y_true == 0, epsilon, y_true)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true_safe)) * 100\n",
    "\n",
    "    print(f\"\\nTime Step {i+1} Evaluation Metrics:\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"MAPE: {mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyYn2XL2GUxw"
   },
   "source": [
    "# Code to predict next 6 steps step-by-step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vavf9D4-lc6E"
   },
   "source": [
    "#### We will use\n",
    "* the last 12 steps\n",
    "\n",
    "* previous one week (24 steps)\n",
    "\n",
    "* previous one month  (168 steps)\n",
    "\n",
    "*  to forecast current (0 step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OfV8VwesmXS3"
   },
   "source": [
    "## 4. Create input and output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "PJaM65dTlc6E"
   },
   "outputs": [],
   "source": [
    "# Create input-output sequences with the provided function\n",
    "X_train, y_train, X_train_df, y_train_df = create_multi_step_sequence(train_set, last_n_steps=12, day_lag=24, week_lag=168, n_future_steps=1)\n",
    "X_valid, y_valid, X_valid_df, y_valid_df = create_multi_step_sequence(valid_set, last_n_steps=12, day_lag=24, week_lag=168, n_future_steps=1)\n",
    "X_test, y_test, X_test_df, y_test_df = create_multi_step_sequence(test_set, last_n_steps=12, day_lag=24, week_lag=168, n_future_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ipA2bPAcm2L1",
    "outputId": "687db2e3-3f26-4cc3-c15b-0d8066617ff8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19570, 14, 1), (6907, 14, 1), (5623, 14, 1))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0GNpslqvlx5_"
   },
   "source": [
    "## 5. Normalise the data after split (step-by-step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_Co01Aflx6B"
   },
   "source": [
    "Normalise X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Z7YuPxvRlx6C"
   },
   "outputs": [],
   "source": [
    "# Separate scalers for inputs and outputs\n",
    "x_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "y_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Reshape x_train to 2D for scaling\n",
    "n_samples, n_timesteps, n_features = X_train.shape\n",
    "x_train_reshaped = X_train.reshape(-1, n_features)  # Shape: (n_samples * n_timesteps, n_features)\n",
    "# Fit the scaler on the training data\n",
    "x_scaler.fit(x_train_reshaped)\n",
    "# Transform the training data\n",
    "x_train_scaled = x_scaler.transform(x_train_reshaped)\n",
    "# Reshape back to original shape\n",
    "x_train_scaled = x_train_scaled.reshape(n_samples, n_timesteps, n_features)\n",
    "\n",
    "# x_val\n",
    "n_val_samples = X_valid.shape[0]\n",
    "x_val_reshaped = X_valid.reshape(-1, n_features)\n",
    "x_val_scaled = x_scaler.transform(x_val_reshaped)\n",
    "x_val_scaled = x_val_scaled.reshape(n_val_samples, n_timesteps, n_features)\n",
    "\n",
    "# x_test\n",
    "n_test_samples = X_test.shape[0]\n",
    "x_test_reshaped = X_test.reshape(-1, n_features)\n",
    "x_test_scaled = x_scaler.transform(x_test_reshaped)\n",
    "x_test_scaled = x_test_scaled.reshape(n_test_samples, n_timesteps, n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rw7rcIWPlx6D"
   },
   "source": [
    "Normalise y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "azSWFgFmlx6D"
   },
   "outputs": [],
   "source": [
    "# Reshape y_train to 2D for scaling\n",
    "y_train_reshaped = y_train.reshape(-1, 1)  # Shape: (n_samples * n_outputs, 1)\n",
    "# Fit the scaler on the training data\n",
    "y_scaler.fit(y_train_reshaped)\n",
    "# Transform the training data\n",
    "y_train_scaled = y_scaler.transform(y_train_reshaped)\n",
    "# Reshape back to original shape\n",
    "y_train_scaled = y_train_scaled.reshape(n_samples, y_train.shape[1])\n",
    "\n",
    "# y_val\n",
    "y_val_reshaped = y_valid.reshape(-1, 1)\n",
    "y_val_scaled = y_scaler.transform(y_val_reshaped)\n",
    "y_val_scaled = y_val_scaled.reshape(n_val_samples, y_valid.shape[1])\n",
    "\n",
    "# y_test\n",
    "y_test_reshaped = y_test.reshape(-1, 1)\n",
    "y_test_scaled = y_scaler.transform(y_test_reshaped)\n",
    "y_test_scaled = y_test_scaled.reshape(n_test_samples, y_test.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJ7sNErrpc9O"
   },
   "source": [
    "## 6. Build LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "eE7DAUCIoVSt"
   },
   "outputs": [],
   "source": [
    "def create_lstm_model(input_shape, units, dropout_rate, learning_rate):\n",
    "    model = keras.Sequential()\n",
    "    model.add(LSTM(units=units, activation='tanh', input_shape=input_shape))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1)) # Output layer for one-step prediction\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        loss='mse',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "input_shape = (x_train_scaled.shape[1], x_train_scaled.shape[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYD8kk0NpzNp"
   },
   "source": [
    "## 7. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u4zCXOAo9tN"
   },
   "outputs": [],
   "source": [
    "# Hyperparameter options\n",
    "units_list = [50, 100, 200]\n",
    "dropout_rates = [0, 0.3, 0.5]\n",
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "batch_sizes = [32, 64, 128]\n",
    "\n",
    "# Create all possible combinations\n",
    "hyperparameter_combinations = list(product(units_list, dropout_rates, learning_rates, batch_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "5d-_-jwBp45_",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "e551e47c-fc12-4b0c-d237-39b9eb0d4f7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination 1/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.01, batch_size=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\program\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation MAE: 0.0452\n",
      "\n",
      "Combination 2/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.01, batch_size=64\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation MAE: 0.0452\n",
      "\n",
      "Combination 3/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.01, batch_size=128\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation MAE: 0.0466\n",
      "\n",
      "Combination 4/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0450\n",
      "\n",
      "Combination 5/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0463\n",
      "\n",
      "Combination 6/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0492\n",
      "\n",
      "Combination 7/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0496\n",
      "\n",
      "Combination 8/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0506\n",
      "\n",
      "Combination 9/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0512\n",
      "\n",
      "Combination 10/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.01, batch_size=32\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation MAE: 0.0464\n",
      "\n",
      "Combination 11/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.01, batch_size=64\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation MAE: 0.0467\n",
      "\n",
      "Combination 12/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.01, batch_size=128\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation MAE: 0.0457\n",
      "\n",
      "Combination 13/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0466\n",
      "\n",
      "Combination 14/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.001, batch_size=64\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation MAE: 0.0498\n",
      "\n",
      "Combination 15/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0493\n",
      "\n",
      "Combination 16/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0508\n",
      "\n",
      "Combination 17/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0516\n",
      "\n",
      "Combination 18/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0517\n",
      "\n",
      "Combination 19/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.01, batch_size=32\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation MAE: 0.0459\n",
      "\n",
      "Combination 20/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.01, batch_size=64\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation MAE: 0.0461\n",
      "\n",
      "Combination 21/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.01, batch_size=128\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation MAE: 0.0463\n",
      "\n",
      "Combination 22/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0471\n",
      "\n",
      "Combination 23/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0489\n",
      "\n",
      "Combination 24/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0501\n",
      "\n",
      "Combination 25/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0510\n",
      "\n",
      "Combination 26/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation MAE: 0.0514\n",
      "\n",
      "Combination 27/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0522\n",
      "\n",
      "Combination 28/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.01, batch_size=32\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation MAE: 0.0463\n",
      "\n",
      "Combination 29/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.01, batch_size=64\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation MAE: 0.0461\n",
      "\n",
      "Combination 30/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.01, batch_size=128\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation MAE: 0.0453\n",
      "\n",
      "Combination 31/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation MAE: 0.0450\n",
      "\n",
      "Combination 32/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation MAE: 0.0458\n",
      "\n",
      "Combination 33/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.001, batch_size=128\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation MAE: 0.0496\n",
      "\n",
      "Combination 34/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0494\n",
      "\n",
      "Combination 35/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0502\n",
      "\n",
      "Combination 36/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation MAE: 0.0512\n",
      "\n",
      "Combination 37/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.01, batch_size=32\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation MAE: 0.0463\n",
      "\n",
      "Combination 38/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.01, batch_size=64\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation MAE: 0.0459\n",
      "\n",
      "Combination 39/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.01, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0457\n",
      "\n",
      "Combination 40/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0456\n",
      "\n",
      "Combination 41/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0469\n",
      "\n",
      "Combination 42/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation MAE: 0.0494\n",
      "\n",
      "Combination 43/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.0001, batch_size=32\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation MAE: 0.0502\n",
      "\n",
      "Combination 44/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0509\n",
      "\n",
      "Combination 45/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.0001, batch_size=128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation MAE: 0.0513\n",
      "\n",
      "Combination 46/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.01, batch_size=32\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation MAE: 0.0466\n",
      "\n",
      "Combination 47/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.01, batch_size=64\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation MAE: 0.0460\n",
      "\n",
      "Combination 48/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.01, batch_size=128\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation MAE: 0.0458\n",
      "\n",
      "Combination 49/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0463\n",
      "\n",
      "Combination 50/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.001, batch_size=64\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation MAE: 0.0496\n",
      "\n",
      "Combination 51/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation MAE: 0.0496\n",
      "\n",
      "Combination 52/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0505\n",
      "\n",
      "Combination 53/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0511\n",
      "\n",
      "Combination 54/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0514\n",
      "\n",
      "Combination 55/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.01, batch_size=32\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation MAE: 0.0464\n",
      "\n",
      "Combination 56/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.01, batch_size=64\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation MAE: 0.0452\n",
      "\n",
      "Combination 57/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.01, batch_size=128\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation MAE: 0.0455\n",
      "\n",
      "Combination 58/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0452\n",
      "\n",
      "Combination 59/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation MAE: 0.0459\n",
      "\n",
      "Combination 60/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation MAE: 0.0470\n",
      "\n",
      "Combination 61/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0492\n",
      "\n",
      "Combination 62/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0497\n",
      "\n",
      "Combination 63/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0503\n",
      "\n",
      "Combination 64/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.01, batch_size=32\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation MAE: 0.0460\n",
      "\n",
      "Combination 65/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.01, batch_size=64\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation MAE: 0.0461\n",
      "\n",
      "Combination 66/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.01, batch_size=128\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation MAE: 0.0486\n",
      "\n",
      "Combination 67/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation MAE: 0.0460\n",
      "\n",
      "Combination 68/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0460\n",
      "\n",
      "Combination 69/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0471\n",
      "\n",
      "Combination 70/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0495\n",
      "\n",
      "Combination 71/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0499\n",
      "\n",
      "Combination 72/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0504\n",
      "\n",
      "Combination 73/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.01, batch_size=32\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation MAE: 0.0455\n",
      "\n",
      "Combination 74/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.01, batch_size=64\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation MAE: 0.0466\n",
      "\n",
      "Combination 75/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.01, batch_size=128\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation MAE: 0.0465\n",
      "\n",
      "Combination 76/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.001, batch_size=32\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation MAE: 0.0467\n",
      "\n",
      "Combination 77/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.001, batch_size=64\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation MAE: 0.0478\n",
      "\n",
      "Combination 78/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation MAE: 0.0477\n",
      "\n",
      "Combination 79/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0496\n",
      "\n",
      "Combination 80/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0502\n",
      "\n",
      "Combination 81/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation MAE: 0.0508\n",
      "\n",
      "Best Hyperparameters:\n",
      "units: 100\n",
      "dropout_rate: 0\n",
      "learning_rate: 0.001\n",
      "batch_size: 32\n",
      "Best Validation MAE: 0.0450\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables to store the best model and hyperparameters\n",
    "best_val_mae = np.inf\n",
    "best_hyperparams = None\n",
    "best_model = None\n",
    "\n",
    "for idx, (units, dropout_rate, learning_rate, batch_size) in enumerate(hyperparameter_combinations):\n",
    "    print(f\"\\nCombination {idx+1}/{len(hyperparameter_combinations)}\")\n",
    "    print(f\"Training with units={units}, dropout_rate={dropout_rate}, learning_rate={learning_rate}, batch_size={batch_size}\")\n",
    "\n",
    "    # Create the LSTM model with the current hyperparameters\n",
    "    model = create_lstm_model(\n",
    "        input_shape=input_shape,\n",
    "        units=units,\n",
    "        dropout_rate=dropout_rate,\n",
    "        learning_rate=learning_rate\n",
    "    )\n",
    "\n",
    "    # Initialize EarlyStopping\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_mae',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        x_train_scaled, y_train_scaled,\n",
    "        epochs=50,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_val_scaled, y_val_scaled),\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Get the best validation MAE from this training run\n",
    "    val_mae = min(history.history['val_mae'])\n",
    "    print(f\"Validation MAE: {val_mae:.4f}\")\n",
    "\n",
    "    # Update best model if current one is better\n",
    "    if val_mae < best_val_mae:\n",
    "        best_val_mae = val_mae\n",
    "        best_model = model\n",
    "        best_hyperparams = {\n",
    "            'units': units,\n",
    "            'dropout_rate': dropout_rate,\n",
    "            'learning_rate': learning_rate,\n",
    "            'batch_size': batch_size\n",
    "        }\n",
    "\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "for param, value in best_hyperparams.items():\n",
    "    print(f\"{param}: {value}\")\n",
    "print(f\"Best Validation MAE: {best_val_mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Hyperparameters full time:\n",
    "units: 50\n",
    "dropout_rate: 0\n",
    "learning_rate: 0.01\n",
    "batch_size: 128\n",
    "Best Validation MAE: 0.0388\n",
    "\n",
    "Best Hyperparameters after covid:\n",
    "units: 100\n",
    "dropout_rate: 0\n",
    "learning_rate: 0.001\n",
    "batch_size: 32\n",
    "Best Validation MAE: 0.0450"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recreate the model¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_lstm_model(input_shape, units, dropout_rate, learning_rate):\n",
    "    model = keras.Sequential()\n",
    "    model.add(LSTM(units=units, activation='tanh', input_shape=input_shape))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1)) # Output layer for one-step prediction\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        loss='mse',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (x_train_scaled.shape[1], x_train_scaled.shape[2])\n",
    "units=50\n",
    "dropout_rate=0\n",
    "learning_rate=0.01\n",
    "batch_size=128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrain the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize EarlyStopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_mae',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0044 - mae: 0.0474 - val_loss: 0.0039 - val_mae: 0.0405\n",
      "Epoch 2/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0043 - mae: 0.0465 - val_loss: 0.0039 - val_mae: 0.0406\n",
      "Epoch 3/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0043 - mae: 0.0467 - val_loss: 0.0040 - val_mae: 0.0432\n",
      "Epoch 4/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0044 - mae: 0.0472 - val_loss: 0.0039 - val_mae: 0.0401\n",
      "Epoch 5/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0043 - mae: 0.0469 - val_loss: 0.0040 - val_mae: 0.0430\n",
      "Epoch 6/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0044 - mae: 0.0473 - val_loss: 0.0039 - val_mae: 0.0399\n",
      "Epoch 7/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0043 - mae: 0.0464 - val_loss: 0.0039 - val_mae: 0.0406\n",
      "Epoch 8/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0045 - mae: 0.0475 - val_loss: 0.0039 - val_mae: 0.0416\n",
      "Epoch 9/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0043 - mae: 0.0464 - val_loss: 0.0039 - val_mae: 0.0411\n",
      "Epoch 10/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - loss: 0.0044 - mae: 0.0468 - val_loss: 0.0039 - val_mae: 0.0406\n",
      "Epoch 11/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0043 - mae: 0.0463 - val_loss: 0.0039 - val_mae: 0.0404\n",
      "Epoch 12/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0042 - mae: 0.0459 - val_loss: 0.0041 - val_mae: 0.0421\n",
      "Epoch 13/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0043 - mae: 0.0464 - val_loss: 0.0039 - val_mae: 0.0400\n",
      "Epoch 14/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0041 - mae: 0.0459 - val_loss: 0.0039 - val_mae: 0.0394\n",
      "Epoch 15/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0043 - mae: 0.0466 - val_loss: 0.0039 - val_mae: 0.0411\n",
      "Epoch 16/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0042 - mae: 0.0460 - val_loss: 0.0039 - val_mae: 0.0401\n",
      "Epoch 17/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0042 - mae: 0.0459 - val_loss: 0.0039 - val_mae: 0.0399\n",
      "Epoch 18/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0042 - mae: 0.0462 - val_loss: 0.0040 - val_mae: 0.0411\n",
      "Epoch 19/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.0041 - mae: 0.0456 - val_loss: 0.0039 - val_mae: 0.0394\n",
      "Epoch 20/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0040 - mae: 0.0454 - val_loss: 0.0039 - val_mae: 0.0405\n",
      "Epoch 21/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0044 - mae: 0.0467 - val_loss: 0.0040 - val_mae: 0.0409\n",
      "Epoch 22/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.0042 - mae: 0.0461 - val_loss: 0.0041 - val_mae: 0.0421\n",
      "Epoch 23/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0042 - mae: 0.0464 - val_loss: 0.0040 - val_mae: 0.0409\n",
      "Epoch 24/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0042 - mae: 0.0462 - val_loss: 0.0040 - val_mae: 0.0396\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = best_model.fit(\n",
    "    x_train_scaled, y_train_scaled,\n",
    "    epochs=50,  # You can adjust this as needed\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(x_val_scaled, y_val_scaled),\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1  # Set to 1 to see detailed training output\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27LXIyi-w0th"
   },
   "source": [
    "## 8. Recursive Forecasting with LSTM (step-by-step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "O5eKQOi8dLQ-"
   },
   "outputs": [],
   "source": [
    "def recursive_forecast(model, x_test_scaled, start_index, n_steps, x_scaler, y_scaler):\n",
    "    \"\"\"\n",
    "    Perform recursive forecasting using the trained model.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained model\n",
    "    - x_test_scaled: The scaled test input data (shape: n_samples, n_timesteps, n_features)\n",
    "    - start_index: The starting index in the test data\n",
    "    - n_steps: Number of future steps to predict\n",
    "    - x_scaler: Scaler used for input features\n",
    "    - y_scaler: Scaler used for target variable\n",
    "\n",
    "    Returns:\n",
    "    - predictions: List of predicted values (in original scale)\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    scaled_predictions = []\n",
    "    current_input = x_test_scaled[start_index].copy()  # Shape: (n_timesteps, n_features)\n",
    "\n",
    "    for step in range(n_steps):\n",
    "        # Reshape to (1, n_timesteps, n_features) for prediction\n",
    "        input_seq = current_input.reshape((1, current_input.shape[0], current_input.shape[1]))\n",
    "\n",
    "        # Predict the next time step (scaled)\n",
    "        yhat_scaled = model.predict(input_seq, verbose=0)  # Shape: (1, 1)\n",
    "\n",
    "        # Inverse transform the prediction to original scale\n",
    "        yhat = y_scaler.inverse_transform(yhat_scaled)[0, 0]\n",
    "        \n",
    "        # Transform the prediction back to input feature scale for lag features\n",
    "        yhat_for_input = x_scaler.transform(yhat.reshape(-1, 1))[0, 0]\n",
    "\n",
    "        # Append predictions\n",
    "        predictions.append(yhat)\n",
    "        scaled_predictions.append(yhat_for_input)\n",
    "\n",
    "        # Move to the next time step in x_test_scaled\n",
    "        next_index = start_index + step + 1\n",
    "        if next_index < len(x_test_scaled):\n",
    "            # Use features from the next time step\n",
    "            next_input = x_test_scaled[next_index].copy()\n",
    "        else:\n",
    "            # Reached the end of x_test_scaled\n",
    "            break\n",
    "\n",
    "        # Update lag features with available scaled predictions\n",
    "        for lag in range(1, min(step + 1, 6) + 1):\n",
    "            feature_index = 12 - lag  # lag1 is at index 11\n",
    "            next_input[feature_index, 0] = scaled_predictions[-lag]\n",
    "\n",
    "        # Keep lag24 and lag168 as they are, or update if necessary\n",
    "\n",
    "        # Set current_input for next iteration\n",
    "        current_input = next_input\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBK2TyUSxCQ-"
   },
   "source": [
    "## 9. Make step-by-step prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "79gLJQDkdNBl"
   },
   "outputs": [],
   "source": [
    "# Number of steps to predict\n",
    "n_steps = 6\n",
    "\n",
    "# Initialize lists to store predictions and actual values\n",
    "all_predictions = []\n",
    "all_actuals = []\n",
    "\n",
    "# Ensure we have enough data for recursive predictions\n",
    "n_test_samples = x_test_scaled.shape[0]\n",
    "\n",
    "for i in range(n_test_samples - n_steps):\n",
    "    # Perform recursive forecasting\n",
    "    predictions = recursive_forecast(\n",
    "        model=best_model,\n",
    "        x_test_scaled=x_test_scaled,\n",
    "        start_index=i,\n",
    "        n_steps=n_steps,\n",
    "        x_scaler=x_scaler,\n",
    "        y_scaler=y_scaler\n",
    "    )\n",
    "\n",
    "    # Get the actual future values (in original scale)\n",
    "    actual_values = y_test[i+1:i + len(predictions) + 1].flatten()\n",
    "\n",
    "    # Store the predictions and actual values\n",
    "    all_predictions.append(predictions)\n",
    "    all_actuals.append(actual_values)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_actuals = np.array(all_actuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9SREwnRqxMN1"
   },
   "source": [
    "## 10. Evaluating the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xw9n5yNExAkJ",
    "outputId": "4f5b2721-8d8e-4871-eb56-dfd1b17ab14c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time Step 1 Evaluation Metrics:\n",
      "RMSE: 41.4159\n",
      "MAE: 29.8309\n",
      "MAPE: 32.89%\n",
      "\n",
      "Time Step 2 Evaluation Metrics:\n",
      "RMSE: 44.7596\n",
      "MAE: 31.9444\n",
      "MAPE: 36.16%\n",
      "\n",
      "Time Step 3 Evaluation Metrics:\n",
      "RMSE: 47.2820\n",
      "MAE: 33.4781\n",
      "MAPE: 39.15%\n",
      "\n",
      "Time Step 4 Evaluation Metrics:\n",
      "RMSE: 49.5900\n",
      "MAE: 34.8770\n",
      "MAPE: 41.75%\n",
      "\n",
      "Time Step 5 Evaluation Metrics:\n",
      "RMSE: 51.5312\n",
      "MAE: 35.9326\n",
      "MAPE: 43.32%\n",
      "\n",
      "Time Step 6 Evaluation Metrics:\n",
      "RMSE: 53.2142\n",
      "MAE: 36.6299\n",
      "MAPE: 44.43%\n"
     ]
    }
   ],
   "source": [
    "# Compute evaluation metrics\n",
    "epsilon = 1e-10  # To avoid division by zero in MAPE\n",
    "\n",
    "for i in range(n_steps):\n",
    "    y_true = all_actuals[:, i]\n",
    "    y_pred = all_predictions[:, i]\n",
    "\n",
    "    # Mean Absolute Error (MAE)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "    # Root Mean Squared Error (RMSE)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "    # Mean Absolute Percentage Error (MAPE)\n",
    "    y_true_safe = np.where(y_true == 0, epsilon, y_true)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true_safe)) * 100\n",
    "\n",
    "    print(f\"\\nTime Step {i+1} Evaluation Metrics:\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"MAPE: {mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k9VMIQUvBZ3q"
   },
   "outputs": [],
   "source": [
    "step-by-step full date"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
