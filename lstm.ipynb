{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tKUGmv5cn6GV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:00:56.141811: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-30 16:00:56.154136: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-09-30 16:00:56.172571: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-09-30 16:00:56.176742: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-09-30 16:00:56.195932: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-30 16:00:57.118375: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import random\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs:\n",
      " - /physical_device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# List all physical devices\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Available GPUs:\")\n",
    "for gpu in gpus:\n",
    "    print(f\" - {gpu.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory growth enabled for GPUs.\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"Memory growth enabled for GPUs.\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8uafyjo7odXA"
   },
   "outputs": [],
   "source": [
    "traffic_data = pd.read_csv('GD030A_S.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KZRSO8dF_Sik"
   },
   "source": [
    "## 1. Recover timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "4TWZuMkMiYtJ"
   },
   "outputs": [],
   "source": [
    "# Define the recover_timestamp function\n",
    "def recover_timestamp(data):\n",
    "    # Combine 'date' and 'time' to form a datetime column\n",
    "    data['datetime'] = pd.to_datetime(data['date'] + ' ' + data['time'].astype(str) + ':00', format='%Y-%m-%d %H:%M')\n",
    "\n",
    "    # Set 'datetime' as index\n",
    "    data = data.set_index('datetime')\n",
    "\n",
    "    # Create a complete range of timestamps with hourly frequency\n",
    "    full_time_range = pd.date_range(start=data.index.min(), end=data.index.max(), freq='H')\n",
    "\n",
    "    # Reindex the data to include all timestamps, filling missing rows with NaN\n",
    "    data_full = data.reindex(full_time_range)\n",
    "\n",
    "    return data_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "rwy81CAA_Y4r",
    "outputId": "9d3c3f5e-37fd-40f5-e31f-060efe8ee18d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>flow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-10-01 00:00:00</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01 01:00:00</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01 02:00:00</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01 03:00:00</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01 04:00:00</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-30 19:00:00</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>19.0</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-30 20:00:00</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>20.0</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-30 21:00:00</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>21.0</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-30 22:00:00</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>22.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-30 23:00:00</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>23.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35064 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           date  time   flow\n",
       "2019-10-01 00:00:00  2019-10-01   0.0   15.0\n",
       "2019-10-01 01:00:00  2019-10-01   1.0    9.0\n",
       "2019-10-01 02:00:00  2019-10-01   2.0    9.0\n",
       "2019-10-01 03:00:00  2019-10-01   3.0    7.0\n",
       "2019-10-01 04:00:00  2019-10-01   4.0    9.0\n",
       "...                         ...   ...    ...\n",
       "2023-09-30 19:00:00  2023-09-30  19.0  129.0\n",
       "2023-09-30 20:00:00  2023-09-30  20.0  119.0\n",
       "2023-09-30 21:00:00  2023-09-30  21.0  106.0\n",
       "2023-09-30 22:00:00  2023-09-30  22.0   88.0\n",
       "2023-09-30 23:00:00  2023-09-30  23.0   88.0\n",
       "\n",
       "[35064 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the recover_timestamp function to recover the full time series\n",
    "traffic_full = recover_timestamp(traffic_data)\n",
    "traffic_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8z-mdqKewzjt"
   },
   "source": [
    "## 2. Train, validate, test data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h60qTUKvwzCb",
    "outputId": "682cc0ab-b2ed-48a1-df5d-6168064efd78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of train_set : 0.6227\n",
      "Proportion of valid_set : 0.1876\n",
      "Proportion of test_set : 0.1897\n"
     ]
    }
   ],
   "source": [
    "# train_set = traffic_full[:'2022-02-28 23:00:00']\n",
    "# valid_set = traffic_full['2022-03-01 00:00:00':'2022-12-31 23:00:00']\n",
    "# test_set = traffic_full['2023-01-01 00:00:00':]\n",
    "train_set = traffic_full['2022-06-03 00:00:00':'2023-03-31 23:00:00']\n",
    "valid_set = traffic_full['2023-04-01 00:00:00':'2023-06-30 23:00:00']\n",
    "test_set = traffic_full['2023-07-01 00:00:00':]\n",
    "print('Proportion of train_set : {:.4f}'.format(len(train_set)/len(traffic_full['2022-06-03 00:00:00':])))\n",
    "print('Proportion of valid_set : {:.4f}'.format(len(valid_set)/len(traffic_full['2022-06-03 00:00:00':])))\n",
    "print('Proportion of test_set : {:.4f}'.format(len(test_set)/len(traffic_full['2022-06-03 00:00:00':])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date    16\n",
      "time    16\n",
      "flow    16\n",
      "dtype: int64 7248\n",
      "date    61\n",
      "time    61\n",
      "flow    61\n",
      "dtype: int64 2184\n",
      "date    342\n",
      "time    342\n",
      "flow    342\n",
      "dtype: int64 2208\n"
     ]
    }
   ],
   "source": [
    "print(train_set.isnull().sum(), len(train_set))\n",
    "print(valid_set.isnull().sum(),len(valid_set))\n",
    "print(test_set.isnull().sum(),len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bd0hRLpW9gJs"
   },
   "source": [
    "## 3. Normalise the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3019437/1100395100.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_set.loc[:, 'flow_scaled'] = scaler.transform(train_set[['flow']])\n",
      "/tmp/ipykernel_3019437/1100395100.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  valid_set.loc[:, 'flow_scaled'] = scaler.transform(valid_set[['flow']])\n",
      "/tmp/ipykernel_3019437/1100395100.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_set.loc[:, 'flow_scaled'] = scaler.transform(test_set[['flow']])\n"
     ]
    }
   ],
   "source": [
    "# Initialize the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler on the training data's 'flow' feature\n",
    "scaler.fit(train_set[['flow']])\n",
    "\n",
    "# Transform the 'flow' feature in all datasets\n",
    "train_set.loc[:, 'flow_scaled'] = scaler.transform(train_set[['flow']])\n",
    "valid_set.loc[:, 'flow_scaled'] = scaler.transform(valid_set[['flow']])\n",
    "test_set.loc[:, 'flow_scaled'] = scaler.transform(test_set[['flow']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xak17ms1uZ-6"
   },
   "source": [
    "## 4. Split the data into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, input_length, forecast_horizon):\n",
    "    \"\"\"\n",
    "    Creates input-output sequences for time series data, excluding any sequences containing NaN values.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: pandas DataFrame containing the data. Must include the 'flow_scaled' column.\n",
    "    - input_length: int, number of past time steps to include in each input sequence.\n",
    "    - forecast_horizon: int, number of future steps to predict.\n",
    "    \n",
    "    Returns:\n",
    "    - X: numpy array of shape (num_valid_samples, input_length, num_features)\n",
    "    - y: numpy array of shape (num_valid_samples, forecast_horizon)\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    num_features = data.shape[1]\n",
    "    total_length = input_length + forecast_horizon\n",
    "    \n",
    "    for i in range(input_length, len(data) - forecast_horizon + 1):\n",
    "        # Extract the input sequence\n",
    "        X_seq = data.iloc[i - input_length:i]['flow_scaled'].values\n",
    "        # Extract the target sequence\n",
    "        y_seq = data.iloc[i:i + forecast_horizon]['flow_scaled'].values\n",
    "        \n",
    "        # Check for NaN values in the input sequence and target sequence\n",
    "        if not np.isnan(X_seq).any() and not np.isnan(y_seq).any():\n",
    "            X.append(X_seq)\n",
    "            y.append(y_seq)\n",
    "        else:\n",
    "            # Optionally, log or count the skipped sequences\n",
    "            pass  # Simply skip sequences with NaNs\n",
    "        \n",
    "    # Convert to numpy arrays and reshape X to match LSTM expected input (samples, timesteps, features)\n",
    "    X = np.array(X).reshape(-1, input_length, 1)\n",
    "    y = np.array(y).reshape(-1, forecast_horizon)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create X and y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will use\n",
    "* the last 24*N steps\n",
    "\n",
    "*  to forecast current (0 step) and 5 steps ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Input Sequence Lengths\n",
    "input_lengths = [24 * i for i in range(1, 22)]  # [24, 48, ..., 168]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing input length: 24\n",
      "  X_train shape: (7145, 24, 1), y_train shape: (7145, 6)\n",
      "  X_val shape: (2007, 24, 1), y_val shape: (2007, 6)\n",
      "  X_test shape: (1719, 24, 1), y_test shape: (1719, 6)\n",
      "\n",
      "Processing input length: 48\n",
      "  X_train shape: (7073, 48, 1), y_train shape: (7073, 6)\n",
      "  X_val shape: (1911, 48, 1), y_val shape: (1911, 6)\n",
      "  X_test shape: (1604, 48, 1), y_test shape: (1604, 6)\n",
      "\n",
      "Processing input length: 72\n",
      "  X_train shape: (7001, 72, 1), y_train shape: (7001, 6)\n",
      "  X_val shape: (1815, 72, 1), y_val shape: (1815, 6)\n",
      "  X_test shape: (1508, 72, 1), y_test shape: (1508, 6)\n",
      "\n",
      "Processing input length: 96\n",
      "  X_train shape: (6929, 96, 1), y_train shape: (6929, 6)\n",
      "  X_val shape: (1719, 96, 1), y_val shape: (1719, 6)\n",
      "  X_test shape: (1412, 96, 1), y_test shape: (1412, 6)\n",
      "\n",
      "Processing input length: 120\n",
      "  X_train shape: (6857, 120, 1), y_train shape: (6857, 6)\n",
      "  X_val shape: (1623, 120, 1), y_val shape: (1623, 6)\n",
      "  X_test shape: (1316, 120, 1), y_test shape: (1316, 6)\n",
      "\n",
      "Processing input length: 144\n",
      "  X_train shape: (6785, 144, 1), y_train shape: (6785, 6)\n",
      "  X_val shape: (1527, 144, 1), y_val shape: (1527, 6)\n",
      "  X_test shape: (1220, 144, 1), y_test shape: (1220, 6)\n",
      "\n",
      "Processing input length: 168\n",
      "  X_train shape: (6713, 168, 1), y_train shape: (6713, 6)\n",
      "  X_val shape: (1431, 168, 1), y_val shape: (1431, 6)\n",
      "  X_test shape: (1124, 168, 1), y_test shape: (1124, 6)\n",
      "\n",
      "Processing input length: 192\n",
      "  X_train shape: (6641, 192, 1), y_train shape: (6641, 6)\n",
      "  X_val shape: (1335, 192, 1), y_val shape: (1335, 6)\n",
      "  X_test shape: (1028, 192, 1), y_test shape: (1028, 6)\n",
      "\n",
      "Processing input length: 216\n",
      "  X_train shape: (6569, 216, 1), y_train shape: (6569, 6)\n",
      "  X_val shape: (1239, 216, 1), y_val shape: (1239, 6)\n",
      "  X_test shape: (932, 216, 1), y_test shape: (932, 6)\n",
      "\n",
      "Processing input length: 240\n",
      "  X_train shape: (6497, 240, 1), y_train shape: (6497, 6)\n",
      "  X_val shape: (1143, 240, 1), y_val shape: (1143, 6)\n",
      "  X_test shape: (836, 240, 1), y_test shape: (836, 6)\n",
      "\n",
      "Processing input length: 264\n",
      "  X_train shape: (6425, 264, 1), y_train shape: (6425, 6)\n",
      "  X_val shape: (1047, 264, 1), y_val shape: (1047, 6)\n",
      "  X_test shape: (740, 264, 1), y_test shape: (740, 6)\n",
      "\n",
      "Processing input length: 288\n",
      "  X_train shape: (6353, 288, 1), y_train shape: (6353, 6)\n",
      "  X_val shape: (963, 288, 1), y_val shape: (963, 6)\n",
      "  X_test shape: (660, 288, 1), y_test shape: (660, 6)\n",
      "\n",
      "Processing input length: 312\n",
      "  X_train shape: (6281, 312, 1), y_train shape: (6281, 6)\n",
      "  X_val shape: (891, 312, 1), y_val shape: (891, 6)\n",
      "  X_test shape: (588, 312, 1), y_test shape: (588, 6)\n",
      "\n",
      "Processing input length: 336\n",
      "  X_train shape: (6209, 336, 1), y_train shape: (6209, 6)\n",
      "  X_val shape: (819, 336, 1), y_val shape: (819, 6)\n",
      "  X_test shape: (516, 336, 1), y_test shape: (516, 6)\n",
      "\n",
      "Processing input length: 360\n",
      "  X_train shape: (6137, 360, 1), y_train shape: (6137, 6)\n",
      "  X_val shape: (747, 360, 1), y_val shape: (747, 6)\n",
      "  X_test shape: (444, 360, 1), y_test shape: (444, 6)\n",
      "\n",
      "Processing input length: 384\n",
      "  X_train shape: (6065, 384, 1), y_train shape: (6065, 6)\n",
      "  X_val shape: (675, 384, 1), y_val shape: (675, 6)\n",
      "  X_test shape: (390, 384, 1), y_test shape: (390, 6)\n",
      "\n",
      "Processing input length: 408\n",
      "  X_train shape: (5993, 408, 1), y_train shape: (5993, 6)\n",
      "  X_val shape: (603, 408, 1), y_val shape: (603, 6)\n",
      "  X_test shape: (342, 408, 1), y_test shape: (342, 6)\n",
      "\n",
      "Processing input length: 432\n",
      "  X_train shape: (5921, 432, 1), y_train shape: (5921, 6)\n",
      "  X_val shape: (531, 432, 1), y_val shape: (531, 6)\n",
      "  X_test shape: (311, 432, 1), y_test shape: (311, 6)\n",
      "\n",
      "Processing input length: 456\n",
      "  X_train shape: (5849, 456, 1), y_train shape: (5849, 6)\n",
      "  X_val shape: (459, 456, 1), y_val shape: (459, 6)\n",
      "  X_test shape: (287, 456, 1), y_test shape: (287, 6)\n",
      "\n",
      "Processing input length: 480\n",
      "  X_train shape: (5777, 480, 1), y_train shape: (5777, 6)\n",
      "  X_val shape: (387, 480, 1), y_val shape: (387, 6)\n",
      "  X_test shape: (263, 480, 1), y_test shape: (263, 6)\n",
      "\n",
      "Processing input length: 504\n",
      "  X_train shape: (5705, 504, 1), y_train shape: (5705, 6)\n",
      "  X_val shape: (333, 504, 1), y_val shape: (333, 6)\n",
      "  X_test shape: (239, 504, 1), y_test shape: (239, 6)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "data_dict = defaultdict(dict)\n",
    "\n",
    "for length in input_lengths:\n",
    "    print(f\"Processing input length: {length}\")\n",
    "    \n",
    "    # Create sequences with forecast_horizon=6\n",
    "    X_train, y_train = create_sequences(train_set, length, forecast_horizon=6)\n",
    "    X_val, y_val = create_sequences(valid_set, length, forecast_horizon=6)\n",
    "    X_test, y_test = create_sequences(test_set, length, forecast_horizon=6)\n",
    "    \n",
    "    # Store in the dictionary\n",
    "    data_dict[length]['X_train'] = X_train\n",
    "    data_dict[length]['y_train'] = y_train\n",
    "    data_dict[length]['X_val'] = X_val\n",
    "    data_dict[length]['y_val'] = y_val\n",
    "    data_dict[length]['X_test'] = X_test\n",
    "    data_dict[length]['y_test'] = y_test\n",
    "    \n",
    "    # Print shapes and ensure no NaNs\n",
    "    print(f\"  X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "    print(f\"  X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
    "    print(f\"  X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Build LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(hyperparams, input_length):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=hyperparams['units'], activation='tanh', input_shape=(input_length, 1)))\n",
    "    model.add(Dropout(rate=hyperparams['dropout']))\n",
    "    model.add(Dense(6))  # Output layer for multi-step forecasting\n",
    "\n",
    "    # Compile the model with MSE as the loss function\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=hyperparams['learning_rate'])\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mse'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_improved_lstm_model(hyperparams, input_length):\n",
    "    \"\"\"\n",
    "    Builds an improved LSTM model based on provided hyperparameters and input length.\n",
    "\n",
    "    Parameters:\n",
    "    - hyperparams: dict containing 'units', 'dropout', 'learning_rate', and optionally 'recurrent_dropout'.\n",
    "    - input_length: int, length of the input sequences.\n",
    "\n",
    "    Returns:\n",
    "    - model: compiled Keras model ready for training.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    # First LSTM layer with return_sequences=True to stack another LSTM layer\n",
    "    model.add(LSTM(\n",
    "        units=hyperparams['units'], \n",
    "        activation='tanh', \n",
    "        input_shape=(input_length, 1), \n",
    "        return_sequences=True, \n",
    "        #recurrent_dropout=hyperparams.get('recurrent_dropout', 0.0)\n",
    "    ))\n",
    "    model.add(Dropout(rate=hyperparams['dropout']))\n",
    "    \n",
    "    # Second LSTM layer\n",
    "    model.add(LSTM(\n",
    "        units=hyperparams['units'], \n",
    "        activation='tanh',\n",
    "        #recurrent_dropout=hyperparams.get('recurrent_dropout', 0.0)\n",
    "    ))\n",
    "    model.add(Dropout(rate=hyperparams['dropout']))\n",
    "    \n",
    "    # Output layer for multi-step forecasting\n",
    "    model.add(Dense(6))\n",
    "    \n",
    "    # Compile the model with MSE as the loss function\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=hyperparams['learning_rate'])\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mse'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Define the hyperparameter grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter options\n",
    "units_list = [32, 64, 128, 256]\n",
    "dropout_rates = [0.0, 0.1, 0.2, 0.3, 0.4]\n",
    "learning_rates = [0.01, 0.005, 0.001]\n",
    "batch_sizes = [32, 64, 128]\n",
    "\n",
    "# Create all possible combinations\n",
    "all_combinations = list(product(units_list, dropout_rates, learning_rates, batch_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(32, 0.0, 0.01, 32),\n",
       " (32, 0.0, 0.01, 64),\n",
       " (32, 0.0, 0.01, 128),\n",
       " (32, 0.0, 0.005, 32),\n",
       " (32, 0.0, 0.005, 64),\n",
       " (32, 0.0, 0.005, 128),\n",
       " (32, 0.0, 0.001, 32),\n",
       " (32, 0.0, 0.001, 64),\n",
       " (32, 0.0, 0.001, 128),\n",
       " (32, 0.1, 0.01, 32),\n",
       " (32, 0.1, 0.01, 64),\n",
       " (32, 0.1, 0.01, 128),\n",
       " (32, 0.1, 0.005, 32),\n",
       " (32, 0.1, 0.005, 64),\n",
       " (32, 0.1, 0.005, 128),\n",
       " (32, 0.1, 0.001, 32),\n",
       " (32, 0.1, 0.001, 64),\n",
       " (32, 0.1, 0.001, 128),\n",
       " (32, 0.2, 0.01, 32),\n",
       " (32, 0.2, 0.01, 64),\n",
       " (32, 0.2, 0.01, 128),\n",
       " (32, 0.2, 0.005, 32),\n",
       " (32, 0.2, 0.005, 64),\n",
       " (32, 0.2, 0.005, 128),\n",
       " (32, 0.2, 0.001, 32),\n",
       " (32, 0.2, 0.001, 64),\n",
       " (32, 0.2, 0.001, 128),\n",
       " (32, 0.3, 0.01, 32),\n",
       " (32, 0.3, 0.01, 64),\n",
       " (32, 0.3, 0.01, 128),\n",
       " (32, 0.3, 0.005, 32),\n",
       " (32, 0.3, 0.005, 64),\n",
       " (32, 0.3, 0.005, 128),\n",
       " (32, 0.3, 0.001, 32),\n",
       " (32, 0.3, 0.001, 64),\n",
       " (32, 0.3, 0.001, 128),\n",
       " (32, 0.4, 0.01, 32),\n",
       " (32, 0.4, 0.01, 64),\n",
       " (32, 0.4, 0.01, 128),\n",
       " (32, 0.4, 0.005, 32),\n",
       " (32, 0.4, 0.005, 64),\n",
       " (32, 0.4, 0.005, 128),\n",
       " (32, 0.4, 0.001, 32),\n",
       " (32, 0.4, 0.001, 64),\n",
       " (32, 0.4, 0.001, 128),\n",
       " (64, 0.0, 0.01, 32),\n",
       " (64, 0.0, 0.01, 64),\n",
       " (64, 0.0, 0.01, 128),\n",
       " (64, 0.0, 0.005, 32),\n",
       " (64, 0.0, 0.005, 64),\n",
       " (64, 0.0, 0.005, 128),\n",
       " (64, 0.0, 0.001, 32),\n",
       " (64, 0.0, 0.001, 64),\n",
       " (64, 0.0, 0.001, 128),\n",
       " (64, 0.1, 0.01, 32),\n",
       " (64, 0.1, 0.01, 64),\n",
       " (64, 0.1, 0.01, 128),\n",
       " (64, 0.1, 0.005, 32),\n",
       " (64, 0.1, 0.005, 64),\n",
       " (64, 0.1, 0.005, 128),\n",
       " (64, 0.1, 0.001, 32),\n",
       " (64, 0.1, 0.001, 64),\n",
       " (64, 0.1, 0.001, 128),\n",
       " (64, 0.2, 0.01, 32),\n",
       " (64, 0.2, 0.01, 64),\n",
       " (64, 0.2, 0.01, 128),\n",
       " (64, 0.2, 0.005, 32),\n",
       " (64, 0.2, 0.005, 64),\n",
       " (64, 0.2, 0.005, 128),\n",
       " (64, 0.2, 0.001, 32),\n",
       " (64, 0.2, 0.001, 64),\n",
       " (64, 0.2, 0.001, 128),\n",
       " (64, 0.3, 0.01, 32),\n",
       " (64, 0.3, 0.01, 64),\n",
       " (64, 0.3, 0.01, 128),\n",
       " (64, 0.3, 0.005, 32),\n",
       " (64, 0.3, 0.005, 64),\n",
       " (64, 0.3, 0.005, 128),\n",
       " (64, 0.3, 0.001, 32),\n",
       " (64, 0.3, 0.001, 64),\n",
       " (64, 0.3, 0.001, 128),\n",
       " (64, 0.4, 0.01, 32),\n",
       " (64, 0.4, 0.01, 64),\n",
       " (64, 0.4, 0.01, 128),\n",
       " (64, 0.4, 0.005, 32),\n",
       " (64, 0.4, 0.005, 64),\n",
       " (64, 0.4, 0.005, 128),\n",
       " (64, 0.4, 0.001, 32),\n",
       " (64, 0.4, 0.001, 64),\n",
       " (64, 0.4, 0.001, 128),\n",
       " (128, 0.0, 0.01, 32),\n",
       " (128, 0.0, 0.01, 64),\n",
       " (128, 0.0, 0.01, 128),\n",
       " (128, 0.0, 0.005, 32),\n",
       " (128, 0.0, 0.005, 64),\n",
       " (128, 0.0, 0.005, 128),\n",
       " (128, 0.0, 0.001, 32),\n",
       " (128, 0.0, 0.001, 64),\n",
       " (128, 0.0, 0.001, 128),\n",
       " (128, 0.1, 0.01, 32),\n",
       " (128, 0.1, 0.01, 64),\n",
       " (128, 0.1, 0.01, 128),\n",
       " (128, 0.1, 0.005, 32),\n",
       " (128, 0.1, 0.005, 64),\n",
       " (128, 0.1, 0.005, 128),\n",
       " (128, 0.1, 0.001, 32),\n",
       " (128, 0.1, 0.001, 64),\n",
       " (128, 0.1, 0.001, 128),\n",
       " (128, 0.2, 0.01, 32),\n",
       " (128, 0.2, 0.01, 64),\n",
       " (128, 0.2, 0.01, 128),\n",
       " (128, 0.2, 0.005, 32),\n",
       " (128, 0.2, 0.005, 64),\n",
       " (128, 0.2, 0.005, 128),\n",
       " (128, 0.2, 0.001, 32),\n",
       " (128, 0.2, 0.001, 64),\n",
       " (128, 0.2, 0.001, 128),\n",
       " (128, 0.3, 0.01, 32),\n",
       " (128, 0.3, 0.01, 64),\n",
       " (128, 0.3, 0.01, 128),\n",
       " (128, 0.3, 0.005, 32),\n",
       " (128, 0.3, 0.005, 64),\n",
       " (128, 0.3, 0.005, 128),\n",
       " (128, 0.3, 0.001, 32),\n",
       " (128, 0.3, 0.001, 64),\n",
       " (128, 0.3, 0.001, 128),\n",
       " (128, 0.4, 0.01, 32),\n",
       " (128, 0.4, 0.01, 64),\n",
       " (128, 0.4, 0.01, 128),\n",
       " (128, 0.4, 0.005, 32),\n",
       " (128, 0.4, 0.005, 64),\n",
       " (128, 0.4, 0.005, 128),\n",
       " (128, 0.4, 0.001, 32),\n",
       " (128, 0.4, 0.001, 64),\n",
       " (128, 0.4, 0.001, 128),\n",
       " (256, 0.0, 0.01, 32),\n",
       " (256, 0.0, 0.01, 64),\n",
       " (256, 0.0, 0.01, 128),\n",
       " (256, 0.0, 0.005, 32),\n",
       " (256, 0.0, 0.005, 64),\n",
       " (256, 0.0, 0.005, 128),\n",
       " (256, 0.0, 0.001, 32),\n",
       " (256, 0.0, 0.001, 64),\n",
       " (256, 0.0, 0.001, 128),\n",
       " (256, 0.1, 0.01, 32),\n",
       " (256, 0.1, 0.01, 64),\n",
       " (256, 0.1, 0.01, 128),\n",
       " (256, 0.1, 0.005, 32),\n",
       " (256, 0.1, 0.005, 64),\n",
       " (256, 0.1, 0.005, 128),\n",
       " (256, 0.1, 0.001, 32),\n",
       " (256, 0.1, 0.001, 64),\n",
       " (256, 0.1, 0.001, 128),\n",
       " (256, 0.2, 0.01, 32),\n",
       " (256, 0.2, 0.01, 64),\n",
       " (256, 0.2, 0.01, 128),\n",
       " (256, 0.2, 0.005, 32),\n",
       " (256, 0.2, 0.005, 64),\n",
       " (256, 0.2, 0.005, 128),\n",
       " (256, 0.2, 0.001, 32),\n",
       " (256, 0.2, 0.001, 64),\n",
       " (256, 0.2, 0.001, 128),\n",
       " (256, 0.3, 0.01, 32),\n",
       " (256, 0.3, 0.01, 64),\n",
       " (256, 0.3, 0.01, 128),\n",
       " (256, 0.3, 0.005, 32),\n",
       " (256, 0.3, 0.005, 64),\n",
       " (256, 0.3, 0.005, 128),\n",
       " (256, 0.3, 0.001, 32),\n",
       " (256, 0.3, 0.001, 64),\n",
       " (256, 0.3, 0.001, 128),\n",
       " (256, 0.4, 0.01, 32),\n",
       " (256, 0.4, 0.01, 64),\n",
       " (256, 0.4, 0.01, 128),\n",
       " (256, 0.4, 0.005, 32),\n",
       " (256, 0.4, 0.005, 64),\n",
       " (256, 0.4, 0.005, 128),\n",
       " (256, 0.4, 0.001, 32),\n",
       " (256, 0.4, 0.001, 64),\n",
       " (256, 0.4, 0.001, 128)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Defining manual grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a log file (do not need to run when log file already created)\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Set the logging level to INFO\n",
    "    format='%(message)s',  # Customize the log message format\n",
    "    handlers=[\n",
    "        logging.FileHandler('lstm.log'),  # Log messages to 'output.log'\n",
    "        logging.StreamHandler()             # Also output to console/notebook\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Properly close handlers to ensure flushing to the file\n",
    "for handler in logger.handlers:\n",
    "    handler.close()\n",
    "    logger.removeHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Create a custom logger\n",
    "logger = logging.getLogger('my_logger')\n",
    "\n",
    "if not logger.handlers:\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    c_handler = logging.StreamHandler()\n",
    "    f_handler = logging.FileHandler('lstm.log')\n",
    "\n",
    "    formatter = logging.Formatter('%(asctime)s - %(message)s')\n",
    "    c_handler.setFormatter(formatter)\n",
    "    f_handler.setFormatter(formatter)\n",
    "\n",
    "    logger.addHandler(c_handler)\n",
    "    logger.addHandler(f_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-17 11:18:33,892 - Starting grid search for input length: 480\n",
      "2024-12-17 11:18:33,893 -   Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "2024-12-17 11:18:34.136425: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22263 MB memory:  -> device: 0, name: NVIDIA A30, pci bus id: 276f:00:00.0, compute capability: 8.0\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-12-17 11:18:37.651045: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-17 11:29:45,955 - Validation loss: 0.00607\n",
      "2024-12-17 11:29:45,957 -   Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-17 11:34:25,787 - Validation loss: 0.00608\n",
      "2024-12-17 11:34:25,790 -   Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-17 11:38:18,823 - Validation loss: 0.00601\n",
      "2024-12-17 11:38:18,825 -   Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.005, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-17 11:48:46,573 - Validation loss: 0.00605\n",
      "2024-12-17 11:48:46,574 -   Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.005, 'batch_size': 64}\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "for length in input_lengths:\n",
    "    logger.info(f\"Starting grid search for input length: {length}\")\n",
    "    \n",
    "    X_train = data_dict[length]['X_train']\n",
    "    y_train = data_dict[length]['y_train']\n",
    "    X_val = data_dict[length]['X_val']\n",
    "    y_val = data_dict[length]['y_val']\n",
    "    \n",
    "    best_mse = float('inf')\n",
    "    best_params = {}\n",
    "    best_model = None\n",
    "    \n",
    "    for idx, combination in enumerate(all_combinations):\n",
    "        # Extract hyperparameters\n",
    "        hyperparams = {\n",
    "            'units': combination[0],\n",
    "            'dropout': combination[1],\n",
    "            'learning_rate': combination[2],\n",
    "            'batch_size': combination[3]\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"  Evaluating combination {idx + 1}/{len(all_combinations)}: {hyperparams}\")\n",
    "        \n",
    "        #model = build_lstm_model(hyperparams, length)\n",
    "        model = build_improved_lstm_model(hyperparams, length)\n",
    "        \n",
    "        # Early Stopping Callback\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True,verbose=1)\n",
    "        \n",
    "        # Train the model\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=100,\n",
    "            batch_size=hyperparams['batch_size'],\n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=[early_stop],\n",
    "            verbose=0  # Set to 1 to see training progress\n",
    "        )\n",
    "        \n",
    "        # Retrieve the best validation MSE from the history\n",
    "        current_best_mse = min(history.history['val_loss'])\n",
    "        logger.info(f\"Validation loss: {current_best_mse:.5f}\")\n",
    "        \n",
    "        # Check if this is the best model so far\n",
    "        if current_best_mse < best_mse:\n",
    "            best_mse = current_best_mse\n",
    "            best_params = hyperparams.copy()\n",
    "            best_model = model  # Optionally, save the model if needed\n",
    "    \n",
    "    # After evaluating all combinations, store the best results\n",
    "    results.append({\n",
    "        'Input_Length': length,\n",
    "        'Best_MSE': best_mse,\n",
    "        'Validation_MSE': mean_squared_error(y_val, best_model.predict(X_val)),\n",
    "        'Validation_MAE': mean_absolute_error(y_val, best_model.predict(X_val)),\n",
    "        'Validation_MAPE': mean_absolute_percentage_error(y_val, best_model.predict(X_val)) * 100,  # In percentage\n",
    "        'Validation_RMSE': np.sqrt(mean_squared_error(y_val, best_model.predict(X_val))),\n",
    "        'Best_Hyperparameters': best_params\n",
    "    })\n",
    "    \n",
    "    logger.info(f\"Completed grid search for input length: {length}\")\n",
    "    logger.info(f\"  Best Validation MSE: {best_mse:.5f}\")\n",
    "    logger.info(f\"  Best Hyperparameters: {best_params}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 24\n",
    "  Best Validation MSE: 0.00553\n",
    "  Best Hyperparameters: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 48\n",
    "  Best Validation MSE: 0.00546\n",
    "  Best Hyperparameters: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 72\n",
    "  Best Validation MSE: 0.00531\n",
    "  Best Hyperparameters: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 96\n",
    "Best Validation MSE: 0.00535\n",
    "Best Hyperparameters: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 120 Best Validation MSE: 0.00528 Best Hyperparameters: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 144 Best Validation MSE: 0.00528 Best Hyperparameters: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 168 Best Validation MSE: 0.00526 Best Hyperparameters: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 192 Best Validation MSE: 0.00524 Best Hyperparameters: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 216 Best Validation MSE: 0.00537 Best Hyperparameters: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 240 Best Validation MSE: 0.00541 Best Hyperparameters: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.005, 'batch_size': 64}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 264 Best Validation MSE: 0.00546 Best Hyperparameters: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 288 Best Validation MSE: 0.00547 Best Hyperparameters: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 312\n",
    "Best Validation MSE: 0.00555\n",
    "Best Hyperparameters: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 336\n",
    "Best Validation MSE: 0.00556\n",
    "Best Hyperparameters: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 360\n",
    "Best Validation MSE: 0.00570\n",
    "Best Hyperparameters: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 384\n",
    "Best Validation MSE: 0.00574\n",
    "Best Hyperparameters: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 408\n",
    "Best Validation MSE: 0.00565\n",
    "Best Hyperparameters: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 432\n",
    "Best Validation MSE: 0.00568\n",
    "Best Hyperparameters: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 456\n",
    "Best Validation MSE: 0.00572\n",
    "Best Hyperparameters: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 480\n",
    "Best Validation MSE: 0.00585\n",
    "Best Hyperparameters: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 504\n",
    "Best Validation MSE: 0.00596\n",
    "Best Hyperparameters: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Storing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Results DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input_Length</th>\n",
       "      <th>Best_MSE</th>\n",
       "      <th>Validation_MSE</th>\n",
       "      <th>Validation_MAE</th>\n",
       "      <th>Validation_MAPE</th>\n",
       "      <th>Validation_RMSE</th>\n",
       "      <th>units</th>\n",
       "      <th>dropout</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>480</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>0.045123</td>\n",
       "      <td>35.583115</td>\n",
       "      <td>0.076475</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>504</td>\n",
       "      <td>0.005963</td>\n",
       "      <td>0.005963</td>\n",
       "      <td>0.046769</td>\n",
       "      <td>39.908860</td>\n",
       "      <td>0.077220</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Input_Length  Best_MSE  Validation_MSE  Validation_MAE  Validation_MAPE  \\\n",
       "0           480  0.005848        0.005848        0.045123        35.583115   \n",
       "1           504  0.005963        0.005963        0.046769        39.908860   \n",
       "\n",
       "   Validation_RMSE  units  dropout  learning_rate  batch_size  \n",
       "0         0.076475  256.0      0.1          0.001        64.0  \n",
       "1         0.077220  128.0      0.0          0.001        32.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the results list to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Expand the hyperparameters dictionary into separate columns for clarity\n",
    "hyperparams_df = results_df['Best_Hyperparameters'].apply(pd.Series)\n",
    "\n",
    "# Combine the main dataframe with hyperparameters\n",
    "final_results_df = pd.concat([results_df.drop('Best_Hyperparameters', axis=1), hyperparams_df], axis=1)\n",
    "\n",
    "# Display the final dataframe\n",
    "print(\"Final Results DataFrame:\")\n",
    "final_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Retrain the model after getting the best hyperparameters of each input length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparameters = {\n",
    "    24: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.1,\n",
    "        'learning_rate': 0.0010,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    48: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.1,\n",
    "        'learning_rate': 0.0010,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    72: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 128\n",
    "    },\n",
    "    96: {\n",
    "        'units': 32,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    120: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.1,\n",
    "        'learning_rate': 0.0010,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    144: {\n",
    "        'units': 256,\n",
    "        'dropout': 0.0,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 64\n",
    "    },\n",
    "    168: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.1,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 128\n",
    "    },\n",
    "    192: {\n",
    "        'units': 64,\n",
    "        'dropout': 0.0,\n",
    "        'learning_rate': 0.0005,\n",
    "        'batch_size': 64\n",
    "    },\n",
    "    216: {\n",
    "        'units': 32,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    240: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.3,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    264: {\n",
    "        'units': 64,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 64\n",
    "    },\n",
    "    288: {\n",
    "        'units': 32,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    312: {\n",
    "        'units': 256,\n",
    "        'dropout': 0.3,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    336: {\n",
    "        'units': 64,\n",
    "        'dropout': 0.3,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    360: {\n",
    "        'units': 64,\n",
    "        'dropout': 0.0,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 128\n",
    "    },\n",
    "    384: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    408: {\n",
    "        'units': 64,\n",
    "        'dropout': 0.1,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    432: {\n",
    "        'units': 256,\n",
    "        'dropout': 0.0,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 64\n",
    "    },\n",
    "    456: {\n",
    "        'units': 32,\n",
    "        'dropout': 0.3,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    480: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.4,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    504: {\n",
    "        'units': 64,\n",
    "        'dropout': 0.3,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 32\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparameters_improved_model = {\n",
    "    24: {\n",
    "        'units': 32,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    48: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.01,\n",
    "        'batch_size': 64\n",
    "    },\n",
    "    72: {\n",
    "        'units': 256,\n",
    "        'dropout': 0.0,\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    96: {\n",
    "        'units': 64,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.01,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    120: {\n",
    "        'units': 32,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    144: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.3,\n",
    "        'learning_rate': 0.01,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    168: {\n",
    "        'units': 32,\n",
    "        'dropout': 0.0,\n",
    "        'learning_rate': 0.0005,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    192: {\n",
    "        'units': 64,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.01,\n",
    "        'batch_size': 128\n",
    "    },\n",
    "    216: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.1,\n",
    "        'learning_rate': 0.01,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    240: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.1,\n",
    "        'learning_rate': 0.01,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    264: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.3,\n",
    "        'learning_rate': 0.01,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    288: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.0,\n",
    "        'learning_rate': 0.01,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    312: {\n",
    "        'units': 64,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.01,\n",
    "        'batch_size': 64\n",
    "    },\n",
    "    336: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.3,\n",
    "        'learning_rate': 0.01,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    360: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    384: {\n",
    "        'units': 64,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.01,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    408: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.01,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    432: {\n",
    "        'units': 64,\n",
    "        'dropout': 0.3,\n",
    "        'learning_rate': 0.01,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    456: {\n",
    "        'units': 64,\n",
    "        'dropout': 0.3,\n",
    "        'learning_rate': 0.01,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    480: {\n",
    "        'units': 32,\n",
    "        'dropout': 0.4,\n",
    "        'learning_rate': 0.01,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    504: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.4,\n",
    "        'learning_rate': 0.01,\n",
    "        'batch_size': 32\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparameters_improved_model_lstm = {\n",
    "    24: {\n",
    "        'units': 64,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    48: {\n",
    "        'units': 256,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.01,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    72: {\n",
    "        'units': 256,\n",
    "        'dropout': 0.1,\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': 128\n",
    "    },\n",
    "    96: {\n",
    "        'units': 256,\n",
    "        'dropout': 0.4,\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    120: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.1,\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': 64\n",
    "    },\n",
    "    144: {\n",
    "        'units': 256,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': 64\n",
    "    },\n",
    "    168: {\n",
    "        'units': 256,\n",
    "        'dropout': 0.3,\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': 64\n",
    "    },\n",
    "    192: {\n",
    "        'units': 256,\n",
    "        'dropout': 0.4,\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    216: {\n",
    "        'units': 256,\n",
    "        'dropout': 0.4,\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    240: {\n",
    "        'units': 64,\n",
    "        'dropout': 0.4,\n",
    "        'learning_rate': 0.005,\n",
    "        'batch_size': 64\n",
    "    },\n",
    "    264: {\n",
    "        'units': 256,\n",
    "        'dropout': 0.4,\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    288: {\n",
    "        'units': 64,\n",
    "        'dropout': 0.3,\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': 64\n",
    "    },\n",
    "    312: {\n",
    "        'units': 32,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    336: {\n",
    "        'units': 256,\n",
    "        'dropout': 0.1,\n",
    "        'learning_rate': 0.01,\n",
    "        'batch_size': 64\n",
    "    },\n",
    "    360: {\n",
    "        'units': 32,\n",
    "        'dropout': 0.1,\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    384: {\n",
    "        'units': 256,\n",
    "        'dropout': 0.3,\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': 64\n",
    "    },\n",
    "    408: {\n",
    "        'units': 256,\n",
    "        'dropout': 0.4,\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': 64\n",
    "    },\n",
    "    432: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.4,\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': 64\n",
    "    },\n",
    "    456: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.0,\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    480: {\n",
    "        'units': 256,\n",
    "        'dropout': 0.1,\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': 64\n",
    "    },\n",
    "    504: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.0,\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': 32\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "# Custom callback to record time per epoch\n",
    "class TimeHistory(Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.times = []\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.epoch_time_start = time.time()\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(hyperparams,data_dict,length, seed=None):  # add seed\n",
    "    if seed is not None:\n",
    "        set_seed(seed)\n",
    "    \n",
    "    #get the data of each length\n",
    "    X_train = data_dict[length]['X_train']\n",
    "    y_train = data_dict[length]['y_train']\n",
    "    X_val = data_dict[length]['X_val']\n",
    "    y_val = data_dict[length]['y_val']\n",
    "    \n",
    "    # Train the model\n",
    "    #model = build_lstm_model(hyperparams, length)    \n",
    "    model = build_improved_lstm_model(hyperparams, length)\n",
    "    # Early Stopping Callback\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True,verbose=1) \n",
    "    # Time history callback to record training time per epoch\n",
    "    time_callback = TimeHistory()\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=100,\n",
    "        batch_size=hyperparams['batch_size'],\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[early_stop, time_callback],\n",
    "        verbose=0  # Set to 1 to see training progress\n",
    "    )\n",
    "    \n",
    "    # Retrieve the best validation MSE from the history\n",
    "    best_mse = min(history.history['val_loss'])\n",
    "    logger.info(f\"Validation loss: {best_mse:.5f}\")\n",
    "\n",
    "    # Calculate the average training time per epoch based on the actual epochs run\n",
    "    avg_epoch_time = sum(time_callback.times) / len(time_callback.times)\n",
    "    logger.info(f\"Average training time per epoch: {avg_epoch_time:.6f} seconds over {len(time_callback.times)} epochs\")\n",
    "    \n",
    "    return model, best_mse, avg_epoch_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "def make_prediction(model, X_obs, y_obs):\n",
    "    # Record start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    y_pred = model.predict(X_obs,verbose=0)\n",
    "\n",
    "    # Record end time and compute the inference time\n",
    "    inference_time = time.time() - start_time\n",
    "    logger.info(f\"\\nInference time: {inference_time:.6f} seconds\")\n",
    "    \n",
    "    n_samples = X_obs.shape[0]\n",
    "    output_len = y_obs.shape[1]\n",
    "\n",
    "    # Reshape for inverse scaling\n",
    "    y_pred_reshaped = y_pred.reshape(-1, 1)\n",
    "    y_obs_reshaped = y_obs.reshape(-1, 1)\n",
    "\n",
    "    # Inverse transform\n",
    "    y_pred_inverse = scaler.inverse_transform(y_pred_reshaped).reshape(n_samples, output_len)\n",
    "    y_obs_inverse = scaler.inverse_transform(y_obs_reshaped).reshape(n_samples, output_len)\n",
    "\n",
    "    return y_pred_inverse, y_obs_inverse, inference_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Metrics for Each Time Step\n",
    "def evaluation(y_pred_inverse, y_obs_inverse):\n",
    "    \n",
    "    output_len = y_pred_inverse.shape[1]\n",
    "    metrics_list = []  # To store metrics for each time step\n",
    "    \n",
    "    for i in range(output_len):\n",
    "        y_true = y_obs_inverse[:, i]\n",
    "        y_pred = y_pred_inverse[:, i]\n",
    "\n",
    "        # Mean Absolute Error (MAE)\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "        # Mean Squared Error (MSE)\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "        # Root Mean Squared Error (RMSE)\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        # Mean Absolute Percentage Error (MAPE)\n",
    "        # Avoid division by zero by adding a small epsilon to y_test_flat if necessary\n",
    "        epsilon = 1e-10\n",
    "        y_true_safe = np.where(y_true == 0, epsilon, y_true)\n",
    "        mape = np.mean(np.abs((y_true - y_pred) / y_true_safe)) * 100\n",
    "\n",
    "                # Append the metrics for the current time step to the list\n",
    "        metrics_list.append({\n",
    "            'Time Step': i + 1,\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse,\n",
    "            'MAPE (%)': mape\n",
    "        })\n",
    "\n",
    "    # Create a DataFrame from the list of metrics\n",
    "    metrics_df = pd.DataFrame(metrics_list)\n",
    "    metrics_df.set_index('Time Step', inplace=True)\n",
    "\n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 04:19:07,192 - 24\n",
      "2025-01-09 04:19:07,198 - \n",
      "--- Run 1 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 04:22:41,418 - Validation loss: 0.00428\n",
      "2025-01-09 04:22:43,581 - \n",
      "--- Run 2 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 83.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 04:27:35,335 - Validation loss: 0.00431\n",
      "2025-01-09 04:27:37,561 - \n",
      "--- Run 3 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 04:30:25,634 - Validation loss: 0.00446\n",
      "2025-01-09 04:30:27,300 - \n",
      "--- Run 4 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 87.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 04:34:52,683 - Validation loss: 0.00431\n",
      "2025-01-09 04:34:54,728 - \n",
      "--- Run 5 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 97.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 04:39:36,714 - Validation loss: 0.00413\n",
      "2025-01-09 04:39:38,884 - \n",
      "--- Run 6 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 96.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 04:44:52,710 - Validation loss: 0.00423\n",
      "2025-01-09 04:44:54,774 - \n",
      "--- Run 7 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82: early stopping\n",
      "Restoring model weights from the end of the best epoch: 62.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 04:49:11,638 - Validation loss: 0.00428\n",
      "2025-01-09 04:49:13,757 - \n",
      "--- Run 8 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92: early stopping\n",
      "Restoring model weights from the end of the best epoch: 72.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 04:54:04,645 - Validation loss: 0.00429\n",
      "2025-01-09 04:54:06,696 - \n",
      "--- Run 9 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 04:57:09,555 - Validation loss: 0.00439\n",
      "2025-01-09 04:57:11,607 - \n",
      "--- Run 10 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 05:01:05,447 - Validation loss: 0.00434\n",
      "2025-01-09 05:01:07,389 - \n",
      "--- Aggregated Mean of All Metrics Across 10(Successful) Runs ---\n",
      "2025-01-09 05:01:07,392 - \n",
      " MAE_train  RMSE_train  MAPE (%)_train   MAE_val  RMSE_val  MAPE (%)_val  MAE_test  RMSE_test  MAPE (%)_test\n",
      " 23.319324   35.393232       34.722900 21.461975 29.922466     29.409415 19.773479  25.927172      17.540808\n",
      " 26.398690   40.125043       41.156406 24.757724 34.434669     34.648160 23.248536  31.171034      20.438729\n",
      " 27.949766   42.330590       45.599030 26.394201 36.500148     38.967689 25.817147  33.960645      22.844209\n",
      " 29.132539   43.731385       49.927175 27.707263 38.034035     43.161614 27.233769  35.405983      24.451480\n",
      " 30.049947   44.978163       53.265915 28.707956 39.187988     46.844485 28.058766  36.043855      25.263217\n",
      " 30.996292   46.384660       56.927294 29.395200 40.168584     50.028294 27.923971  35.999681      25.304520\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.319324</td>\n",
       "      <td>35.393232</td>\n",
       "      <td>34.722900</td>\n",
       "      <td>21.461975</td>\n",
       "      <td>29.922466</td>\n",
       "      <td>29.409415</td>\n",
       "      <td>19.773479</td>\n",
       "      <td>25.927172</td>\n",
       "      <td>17.540808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.398690</td>\n",
       "      <td>40.125043</td>\n",
       "      <td>41.156406</td>\n",
       "      <td>24.757724</td>\n",
       "      <td>34.434669</td>\n",
       "      <td>34.648160</td>\n",
       "      <td>23.248536</td>\n",
       "      <td>31.171034</td>\n",
       "      <td>20.438729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.949766</td>\n",
       "      <td>42.330590</td>\n",
       "      <td>45.599030</td>\n",
       "      <td>26.394201</td>\n",
       "      <td>36.500148</td>\n",
       "      <td>38.967689</td>\n",
       "      <td>25.817147</td>\n",
       "      <td>33.960645</td>\n",
       "      <td>22.844209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.132539</td>\n",
       "      <td>43.731385</td>\n",
       "      <td>49.927175</td>\n",
       "      <td>27.707263</td>\n",
       "      <td>38.034035</td>\n",
       "      <td>43.161614</td>\n",
       "      <td>27.233769</td>\n",
       "      <td>35.405983</td>\n",
       "      <td>24.451480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.049947</td>\n",
       "      <td>44.978163</td>\n",
       "      <td>53.265915</td>\n",
       "      <td>28.707956</td>\n",
       "      <td>39.187988</td>\n",
       "      <td>46.844485</td>\n",
       "      <td>28.058766</td>\n",
       "      <td>36.043855</td>\n",
       "      <td>25.263217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30.996292</td>\n",
       "      <td>46.384660</td>\n",
       "      <td>56.927294</td>\n",
       "      <td>29.395200</td>\n",
       "      <td>40.168584</td>\n",
       "      <td>50.028294</td>\n",
       "      <td>27.923971</td>\n",
       "      <td>35.999681</td>\n",
       "      <td>25.304520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  MAPE (%)_val  \\\n",
       "24                                                                              \n",
       "1   23.319324   35.393232       34.722900  21.461975  29.922466     29.409415   \n",
       "2   26.398690   40.125043       41.156406  24.757724  34.434669     34.648160   \n",
       "3   27.949766   42.330590       45.599030  26.394201  36.500148     38.967689   \n",
       "4   29.132539   43.731385       49.927175  27.707263  38.034035     43.161614   \n",
       "5   30.049947   44.978163       53.265915  28.707956  39.187988     46.844485   \n",
       "6   30.996292   46.384660       56.927294  29.395200  40.168584     50.028294   \n",
       "\n",
       "     MAE_test  RMSE_test  MAPE (%)_test  \n",
       "24                                       \n",
       "1   19.773479  25.927172      17.540808  \n",
       "2   23.248536  31.171034      20.438729  \n",
       "3   25.817147  33.960645      22.844209  \n",
       "4   27.233769  35.405983      24.451480  \n",
       "5   28.058766  36.043855      25.263217  \n",
       "6   27.923971  35.999681      25.304520  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 05:01:07,400 - 48\n",
      "2025-01-09 05:01:07,401 - \n",
      "--- Run 1 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 05:01:51,530 - Validation loss: 0.00453\n",
      "2025-01-09 05:01:53,181 - \n",
      "--- Run 2 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 05:03:10,601 - Validation loss: 0.00469\n",
      "2025-01-09 05:03:12,843 - \n",
      "--- Run 3 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 05:04:18,456 - Validation loss: 0.00472\n",
      "2025-01-09 05:04:20,529 - \n",
      "--- Run 4 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 05:05:16,329 - Validation loss: 0.00441\n",
      "2025-01-09 05:05:18,630 - \n",
      "--- Run 5 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 05:07:04,565 - Validation loss: 0.00422\n",
      "2025-01-09 05:07:06,892 - \n",
      "--- Run 6 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 05:08:11,066 - Validation loss: 0.00427\n",
      "2025-01-09 05:08:13,393 - \n",
      "--- Run 7 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 05:09:31,706 - Validation loss: 0.00453\n",
      "2025-01-09 05:09:33,966 - \n",
      "--- Run 8 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 05:11:13,128 - Validation loss: 0.00437\n",
      "2025-01-09 05:11:15,524 - \n",
      "--- Run 9 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 05:12:12,531 - Validation loss: 0.00441\n",
      "2025-01-09 05:12:14,672 - \n",
      "--- Run 10 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 05:13:03,236 - Validation loss: 0.00455\n",
      "2025-01-09 05:13:05,449 - \n",
      "--- Aggregated Mean of All Metrics Across 10(Successful) Runs ---\n",
      "2025-01-09 05:13:05,453 - \n",
      " MAE_train  RMSE_train  MAPE (%)_train   MAE_val  RMSE_val  MAPE (%)_val  MAE_test  RMSE_test  MAPE (%)_test\n",
      " 24.004519   35.800250       39.280719 22.069542 30.519630     32.887651 20.114955  25.870559      18.140619\n",
      " 26.876212   40.540088       44.419869 25.354890 35.191830     37.334879 23.205208  30.691103      20.770368\n",
      " 28.659176   42.835339       48.909021 27.267773 37.521479     41.799525 25.563278  33.073065      22.809695\n",
      " 29.911444   44.181642       54.644406 28.519597 38.889729     47.330138 26.821116  34.693665      23.866100\n",
      " 30.464459   45.411812       56.176281 29.124743 39.835037     49.488311 27.297013  35.436543      23.809598\n",
      " 31.363427   46.828082       59.660947 29.616107 40.508585     52.563094 27.318637  35.668878      23.929350\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.004519</td>\n",
       "      <td>35.800250</td>\n",
       "      <td>39.280719</td>\n",
       "      <td>22.069542</td>\n",
       "      <td>30.519630</td>\n",
       "      <td>32.887651</td>\n",
       "      <td>20.114955</td>\n",
       "      <td>25.870559</td>\n",
       "      <td>18.140619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.876212</td>\n",
       "      <td>40.540088</td>\n",
       "      <td>44.419869</td>\n",
       "      <td>25.354890</td>\n",
       "      <td>35.191830</td>\n",
       "      <td>37.334879</td>\n",
       "      <td>23.205208</td>\n",
       "      <td>30.691103</td>\n",
       "      <td>20.770368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.659176</td>\n",
       "      <td>42.835339</td>\n",
       "      <td>48.909021</td>\n",
       "      <td>27.267773</td>\n",
       "      <td>37.521479</td>\n",
       "      <td>41.799525</td>\n",
       "      <td>25.563278</td>\n",
       "      <td>33.073065</td>\n",
       "      <td>22.809695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.911444</td>\n",
       "      <td>44.181642</td>\n",
       "      <td>54.644406</td>\n",
       "      <td>28.519597</td>\n",
       "      <td>38.889729</td>\n",
       "      <td>47.330138</td>\n",
       "      <td>26.821116</td>\n",
       "      <td>34.693665</td>\n",
       "      <td>23.866100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.464459</td>\n",
       "      <td>45.411812</td>\n",
       "      <td>56.176281</td>\n",
       "      <td>29.124743</td>\n",
       "      <td>39.835037</td>\n",
       "      <td>49.488311</td>\n",
       "      <td>27.297013</td>\n",
       "      <td>35.436543</td>\n",
       "      <td>23.809598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31.363427</td>\n",
       "      <td>46.828082</td>\n",
       "      <td>59.660947</td>\n",
       "      <td>29.616107</td>\n",
       "      <td>40.508585</td>\n",
       "      <td>52.563094</td>\n",
       "      <td>27.318637</td>\n",
       "      <td>35.668878</td>\n",
       "      <td>23.929350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  MAPE (%)_val  \\\n",
       "48                                                                              \n",
       "1   24.004519   35.800250       39.280719  22.069542  30.519630     32.887651   \n",
       "2   26.876212   40.540088       44.419869  25.354890  35.191830     37.334879   \n",
       "3   28.659176   42.835339       48.909021  27.267773  37.521479     41.799525   \n",
       "4   29.911444   44.181642       54.644406  28.519597  38.889729     47.330138   \n",
       "5   30.464459   45.411812       56.176281  29.124743  39.835037     49.488311   \n",
       "6   31.363427   46.828082       59.660947  29.616107  40.508585     52.563094   \n",
       "\n",
       "     MAE_test  RMSE_test  MAPE (%)_test  \n",
       "48                                       \n",
       "1   20.114955  25.870559      18.140619  \n",
       "2   23.205208  30.691103      20.770368  \n",
       "3   25.563278  33.073065      22.809695  \n",
       "4   26.821116  34.693665      23.866100  \n",
       "5   27.297013  35.436543      23.809598  \n",
       "6   27.318637  35.668878      23.929350  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 05:13:05,468 - 72\n",
      "2025-01-09 05:13:05,470 - \n",
      "--- Run 1 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 05:15:27,452 - Validation loss: 0.00477\n",
      "2025-01-09 05:15:29,846 - \n",
      "--- Run 2 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 05:17:36,773 - Validation loss: 0.00434\n",
      "2025-01-09 05:17:39,441 - \n",
      "--- Run 3 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 05:20:15,001 - Validation loss: 0.00442\n",
      "2025-01-09 05:20:17,403 - \n",
      "--- Run 4 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 05:22:48,974 - Validation loss: 0.00438\n",
      "2025-01-09 05:22:51,354 - \n",
      "--- Run 5 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 05:25:29,149 - Validation loss: 0.00441\n",
      "2025-01-09 05:25:31,067 - \n",
      "--- Run 6 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 05:28:12,413 - Validation loss: 0.00441\n",
      "2025-01-09 05:28:14,852 - \n",
      "--- Run 7 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 05:30:12,214 - Validation loss: 0.00466\n",
      "2025-01-09 05:30:14,622 - \n",
      "--- Run 8 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 05:32:04,886 - Validation loss: 0.00448\n",
      "2025-01-09 05:32:07,213 - \n",
      "--- Run 9 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 05:34:16,244 - Validation loss: 0.00445\n",
      "2025-01-09 05:34:18,845 - \n",
      "--- Run 10 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 05:36:06,242 - Validation loss: 0.00457\n",
      "2025-01-09 05:36:08,743 - \n",
      "--- Aggregated Mean of All Metrics Across 10(Successful) Runs ---\n",
      "2025-01-09 05:36:08,746 - \n",
      " MAE_train  RMSE_train  MAPE (%)_train   MAE_val  RMSE_val  MAPE (%)_val  MAE_test  RMSE_test  MAPE (%)_test\n",
      " 24.006618   36.081495       37.804458 22.098526 30.433646     32.107789 20.007506  25.848940      17.451189\n",
      " 27.104215   41.220797       44.142979 25.423703 35.172539     36.592853 23.526815  31.150559      20.373676\n",
      " 28.381145   43.329417       46.979580 26.917509 37.246894     39.684425 26.109756  33.924741      22.178219\n",
      " 29.172032   44.509917       49.475819 28.222688 38.910690     43.195866 27.760205  35.974698      23.342485\n",
      " 29.912974   45.665475       52.258432 29.151814 39.959211     46.320107 28.635954  36.738711      24.127196\n",
      " 31.027874   47.217858       54.924079 29.814936 41.139229     48.562423 29.770156  38.013815      24.956545\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.006618</td>\n",
       "      <td>36.081495</td>\n",
       "      <td>37.804458</td>\n",
       "      <td>22.098526</td>\n",
       "      <td>30.433646</td>\n",
       "      <td>32.107789</td>\n",
       "      <td>20.007506</td>\n",
       "      <td>25.848940</td>\n",
       "      <td>17.451189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.104215</td>\n",
       "      <td>41.220797</td>\n",
       "      <td>44.142979</td>\n",
       "      <td>25.423703</td>\n",
       "      <td>35.172539</td>\n",
       "      <td>36.592853</td>\n",
       "      <td>23.526815</td>\n",
       "      <td>31.150559</td>\n",
       "      <td>20.373676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.381145</td>\n",
       "      <td>43.329417</td>\n",
       "      <td>46.979580</td>\n",
       "      <td>26.917509</td>\n",
       "      <td>37.246894</td>\n",
       "      <td>39.684425</td>\n",
       "      <td>26.109756</td>\n",
       "      <td>33.924741</td>\n",
       "      <td>22.178219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.172032</td>\n",
       "      <td>44.509917</td>\n",
       "      <td>49.475819</td>\n",
       "      <td>28.222688</td>\n",
       "      <td>38.910690</td>\n",
       "      <td>43.195866</td>\n",
       "      <td>27.760205</td>\n",
       "      <td>35.974698</td>\n",
       "      <td>23.342485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29.912974</td>\n",
       "      <td>45.665475</td>\n",
       "      <td>52.258432</td>\n",
       "      <td>29.151814</td>\n",
       "      <td>39.959211</td>\n",
       "      <td>46.320107</td>\n",
       "      <td>28.635954</td>\n",
       "      <td>36.738711</td>\n",
       "      <td>24.127196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31.027874</td>\n",
       "      <td>47.217858</td>\n",
       "      <td>54.924079</td>\n",
       "      <td>29.814936</td>\n",
       "      <td>41.139229</td>\n",
       "      <td>48.562423</td>\n",
       "      <td>29.770156</td>\n",
       "      <td>38.013815</td>\n",
       "      <td>24.956545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  MAPE (%)_val  \\\n",
       "72                                                                              \n",
       "1   24.006618   36.081495       37.804458  22.098526  30.433646     32.107789   \n",
       "2   27.104215   41.220797       44.142979  25.423703  35.172539     36.592853   \n",
       "3   28.381145   43.329417       46.979580  26.917509  37.246894     39.684425   \n",
       "4   29.172032   44.509917       49.475819  28.222688  38.910690     43.195866   \n",
       "5   29.912974   45.665475       52.258432  29.151814  39.959211     46.320107   \n",
       "6   31.027874   47.217858       54.924079  29.814936  41.139229     48.562423   \n",
       "\n",
       "     MAE_test  RMSE_test  MAPE (%)_test  \n",
       "72                                       \n",
       "1   20.007506  25.848940      17.451189  \n",
       "2   23.526815  31.150559      20.373676  \n",
       "3   26.109756  33.924741      22.178219  \n",
       "4   27.760205  35.974698      23.342485  \n",
       "5   28.635954  36.738711      24.127196  \n",
       "6   29.770156  38.013815      24.956545  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 05:36:08,756 - 96\n",
      "2025-01-09 05:36:08,758 - \n",
      "--- Run 1 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 05:38:31,060 - Validation loss: 0.00427\n",
      "2025-01-09 05:38:33,407 - \n",
      "--- Run 2 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 05:40:58,267 - Validation loss: 0.00432\n",
      "2025-01-09 05:41:00,405 - \n",
      "--- Run 3 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 05:44:30,418 - Validation loss: 0.00435\n",
      "2025-01-09 05:44:32,759 - \n",
      "--- Run 4 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 05:46:43,055 - Validation loss: 0.00437\n",
      "2025-01-09 05:46:45,382 - \n",
      "--- Run 5 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 05:48:51,387 - Validation loss: 0.00430\n",
      "2025-01-09 05:48:53,957 - \n",
      "--- Run 6 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 05:51:38,327 - Validation loss: 0.00428\n",
      "2025-01-09 05:51:40,440 - \n",
      "--- Run 7 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 05:53:36,118 - Validation loss: 0.00432\n",
      "2025-01-09 05:53:38,221 - \n",
      "--- Run 8 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 05:56:42,631 - Validation loss: 0.00455\n",
      "2025-01-09 05:56:45,249 - \n",
      "--- Run 9 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 05:59:50,541 - Validation loss: 0.00445\n",
      "2025-01-09 05:59:53,114 - \n",
      "--- Run 10 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 06:01:44,213 - Validation loss: 0.00449\n",
      "2025-01-09 06:01:46,542 - \n",
      "--- Aggregated Mean of All Metrics Across 10(Successful) Runs ---\n",
      "2025-01-09 06:01:46,546 - \n",
      " MAE_train  RMSE_train  MAPE (%)_train   MAE_val  RMSE_val  MAPE (%)_val  MAE_test  RMSE_test  MAPE (%)_test\n",
      " 24.432135   36.367174       42.144961 22.250586 30.603012     34.417996 20.010501  25.863982      17.258941\n",
      " 27.602732   41.018121       49.544897 25.618979 35.033720     41.229382 22.659775  30.199129      19.644195\n",
      " 28.870721   42.955321       53.770281 27.027926 36.861955     45.598515 25.142232  32.874812      21.708757\n",
      " 29.670262   44.147899       55.244201 28.062766 38.341284     47.694316 26.765000  34.777294      23.128044\n",
      " 29.873489   45.203847       54.633113 28.436031 39.127053     48.067051 28.301155  36.477874      24.217989\n",
      " 30.612883   46.311154       55.473189 29.195223 40.101881     50.120561 28.303966  36.685671      24.234613\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.432135</td>\n",
       "      <td>36.367174</td>\n",
       "      <td>42.144961</td>\n",
       "      <td>22.250586</td>\n",
       "      <td>30.603012</td>\n",
       "      <td>34.417996</td>\n",
       "      <td>20.010501</td>\n",
       "      <td>25.863982</td>\n",
       "      <td>17.258941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.602732</td>\n",
       "      <td>41.018121</td>\n",
       "      <td>49.544897</td>\n",
       "      <td>25.618979</td>\n",
       "      <td>35.033720</td>\n",
       "      <td>41.229382</td>\n",
       "      <td>22.659775</td>\n",
       "      <td>30.199129</td>\n",
       "      <td>19.644195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.870721</td>\n",
       "      <td>42.955321</td>\n",
       "      <td>53.770281</td>\n",
       "      <td>27.027926</td>\n",
       "      <td>36.861955</td>\n",
       "      <td>45.598515</td>\n",
       "      <td>25.142232</td>\n",
       "      <td>32.874812</td>\n",
       "      <td>21.708757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.670262</td>\n",
       "      <td>44.147899</td>\n",
       "      <td>55.244201</td>\n",
       "      <td>28.062766</td>\n",
       "      <td>38.341284</td>\n",
       "      <td>47.694316</td>\n",
       "      <td>26.765000</td>\n",
       "      <td>34.777294</td>\n",
       "      <td>23.128044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29.873489</td>\n",
       "      <td>45.203847</td>\n",
       "      <td>54.633113</td>\n",
       "      <td>28.436031</td>\n",
       "      <td>39.127053</td>\n",
       "      <td>48.067051</td>\n",
       "      <td>28.301155</td>\n",
       "      <td>36.477874</td>\n",
       "      <td>24.217989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30.612883</td>\n",
       "      <td>46.311154</td>\n",
       "      <td>55.473189</td>\n",
       "      <td>29.195223</td>\n",
       "      <td>40.101881</td>\n",
       "      <td>50.120561</td>\n",
       "      <td>28.303966</td>\n",
       "      <td>36.685671</td>\n",
       "      <td>24.234613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  MAPE (%)_val  \\\n",
       "96                                                                              \n",
       "1   24.432135   36.367174       42.144961  22.250586  30.603012     34.417996   \n",
       "2   27.602732   41.018121       49.544897  25.618979  35.033720     41.229382   \n",
       "3   28.870721   42.955321       53.770281  27.027926  36.861955     45.598515   \n",
       "4   29.670262   44.147899       55.244201  28.062766  38.341284     47.694316   \n",
       "5   29.873489   45.203847       54.633113  28.436031  39.127053     48.067051   \n",
       "6   30.612883   46.311154       55.473189  29.195223  40.101881     50.120561   \n",
       "\n",
       "     MAE_test  RMSE_test  MAPE (%)_test  \n",
       "96                                       \n",
       "1   20.010501  25.863982      17.258941  \n",
       "2   22.659775  30.199129      19.644195  \n",
       "3   25.142232  32.874812      21.708757  \n",
       "4   26.765000  34.777294      23.128044  \n",
       "5   28.301155  36.477874      24.217989  \n",
       "6   28.303966  36.685671      24.234613  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 06:01:46,553 - 120\n",
      "2025-01-09 06:01:46,554 - \n",
      "--- Run 1 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 06:07:14,665 - Validation loss: 0.00423\n",
      "2025-01-09 06:07:17,613 - \n",
      "--- Run 2 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87: early stopping\n",
      "Restoring model weights from the end of the best epoch: 67.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 06:14:27,445 - Validation loss: 0.00419\n",
      "2025-01-09 06:14:30,070 - \n",
      "--- Run 3 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85: early stopping\n",
      "Restoring model weights from the end of the best epoch: 65.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 06:21:27,142 - Validation loss: 0.00412\n",
      "2025-01-09 06:21:29,890 - \n",
      "--- Run 4 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88: early stopping\n",
      "Restoring model weights from the end of the best epoch: 68.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 06:28:47,180 - Validation loss: 0.00416\n",
      "2025-01-09 06:28:50,075 - \n",
      "--- Run 5 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82: early stopping\n",
      "Restoring model weights from the end of the best epoch: 62.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 06:35:30,349 - Validation loss: 0.00416\n",
      "2025-01-09 06:35:33,008 - \n",
      "--- Run 6 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91: early stopping\n",
      "Restoring model weights from the end of the best epoch: 71.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 06:42:55,727 - Validation loss: 0.00417\n",
      "2025-01-09 06:42:58,315 - \n",
      "--- Run 7 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 06:49:01,506 - Validation loss: 0.00413\n",
      "2025-01-09 06:49:04,217 - \n",
      "--- Run 8 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 06:54:26,971 - Validation loss: 0.00413\n",
      "2025-01-09 06:54:29,673 - \n",
      "--- Run 9 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82: early stopping\n",
      "Restoring model weights from the end of the best epoch: 62.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 07:01:12,933 - Validation loss: 0.00422\n",
      "2025-01-09 07:01:15,548 - \n",
      "--- Run 10 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 07:06:09,291 - Validation loss: 0.00427\n",
      "2025-01-09 07:06:12,147 - \n",
      "--- Aggregated Mean of All Metrics Across 10(Successful) Runs ---\n",
      "2025-01-09 07:06:12,155 - \n",
      " MAE_train  RMSE_train  MAPE (%)_train   MAE_val  RMSE_val  MAPE (%)_val  MAE_test  RMSE_test  MAPE (%)_test\n",
      " 23.258680   35.202015       36.493788 21.365420 29.029812     30.655687 19.493063  25.270460      16.861443\n",
      " 25.868876   39.514702       41.059006 24.276464 33.429321     35.132739 22.542779  29.732167      19.212193\n",
      " 27.156662   41.423835       44.377678 26.139465 36.029120     39.459677 24.696217  32.033346      20.867582\n",
      " 27.804158   42.453050       47.019224 27.465931 37.738119     43.147635 25.850495  33.372449      21.723156\n",
      " 28.462778   43.394308       50.562629 28.459276 38.833091     47.252845 26.348485  33.956572      22.201589\n",
      " 29.342240   44.606010       54.037393 29.147326 39.815643     50.269461 26.437979  34.327186      22.186208\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.258680</td>\n",
       "      <td>35.202015</td>\n",
       "      <td>36.493788</td>\n",
       "      <td>21.365420</td>\n",
       "      <td>29.029812</td>\n",
       "      <td>30.655687</td>\n",
       "      <td>19.493063</td>\n",
       "      <td>25.270460</td>\n",
       "      <td>16.861443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.868876</td>\n",
       "      <td>39.514702</td>\n",
       "      <td>41.059006</td>\n",
       "      <td>24.276464</td>\n",
       "      <td>33.429321</td>\n",
       "      <td>35.132739</td>\n",
       "      <td>22.542779</td>\n",
       "      <td>29.732167</td>\n",
       "      <td>19.212193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.156662</td>\n",
       "      <td>41.423835</td>\n",
       "      <td>44.377678</td>\n",
       "      <td>26.139465</td>\n",
       "      <td>36.029120</td>\n",
       "      <td>39.459677</td>\n",
       "      <td>24.696217</td>\n",
       "      <td>32.033346</td>\n",
       "      <td>20.867582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.804158</td>\n",
       "      <td>42.453050</td>\n",
       "      <td>47.019224</td>\n",
       "      <td>27.465931</td>\n",
       "      <td>37.738119</td>\n",
       "      <td>43.147635</td>\n",
       "      <td>25.850495</td>\n",
       "      <td>33.372449</td>\n",
       "      <td>21.723156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28.462778</td>\n",
       "      <td>43.394308</td>\n",
       "      <td>50.562629</td>\n",
       "      <td>28.459276</td>\n",
       "      <td>38.833091</td>\n",
       "      <td>47.252845</td>\n",
       "      <td>26.348485</td>\n",
       "      <td>33.956572</td>\n",
       "      <td>22.201589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29.342240</td>\n",
       "      <td>44.606010</td>\n",
       "      <td>54.037393</td>\n",
       "      <td>29.147326</td>\n",
       "      <td>39.815643</td>\n",
       "      <td>50.269461</td>\n",
       "      <td>26.437979</td>\n",
       "      <td>34.327186</td>\n",
       "      <td>22.186208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  \\\n",
       "120                                                                \n",
       "1    23.258680   35.202015       36.493788  21.365420  29.029812   \n",
       "2    25.868876   39.514702       41.059006  24.276464  33.429321   \n",
       "3    27.156662   41.423835       44.377678  26.139465  36.029120   \n",
       "4    27.804158   42.453050       47.019224  27.465931  37.738119   \n",
       "5    28.462778   43.394308       50.562629  28.459276  38.833091   \n",
       "6    29.342240   44.606010       54.037393  29.147326  39.815643   \n",
       "\n",
       "     MAPE (%)_val   MAE_test  RMSE_test  MAPE (%)_test  \n",
       "120                                                     \n",
       "1       30.655687  19.493063  25.270460      16.861443  \n",
       "2       35.132739  22.542779  29.732167      19.212193  \n",
       "3       39.459677  24.696217  32.033346      20.867582  \n",
       "4       43.147635  25.850495  33.372449      21.723156  \n",
       "5       47.252845  26.348485  33.956572      22.201589  \n",
       "6       50.269461  26.437979  34.327186      22.186208  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 07:06:12,166 - 144\n",
      "2025-01-09 07:06:12,168 - \n",
      "--- Run 1 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 07:09:44,952 - Validation loss: 0.00449\n",
      "2025-01-09 07:09:48,021 - \n",
      "--- Run 2 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 07:12:35,907 - Validation loss: 0.00437\n",
      "2025-01-09 07:12:39,076 - \n",
      "--- Run 3 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 07:15:54,626 - Validation loss: 0.00463\n",
      "2025-01-09 07:15:57,830 - \n",
      "--- Run 4 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 07:19:13,054 - Validation loss: 0.00425\n",
      "2025-01-09 07:19:16,308 - \n",
      "--- Run 5 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 07:22:23,780 - Validation loss: 0.00439\n",
      "2025-01-09 07:22:26,820 - \n",
      "--- Run 6 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 07:25:13,823 - Validation loss: 0.00437\n",
      "2025-01-09 07:25:17,061 - \n",
      "--- Run 7 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 07:27:36,466 - Validation loss: 0.00446\n",
      "2025-01-09 07:27:39,544 - \n",
      "--- Run 8 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 07:33:00,367 - Validation loss: 0.00435\n",
      "2025-01-09 07:33:03,476 - \n",
      "--- Run 9 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 07:37:15,813 - Validation loss: 0.00433\n",
      "2025-01-09 07:37:18,887 - \n",
      "--- Run 10 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 07:41:18,811 - Validation loss: 0.00431\n",
      "2025-01-09 07:41:21,995 - \n",
      "--- Aggregated Mean of All Metrics Across 10(Successful) Runs ---\n",
      "2025-01-09 07:41:22,006 - \n",
      " MAE_train  RMSE_train  MAPE (%)_train   MAE_val  RMSE_val  MAPE (%)_val  MAE_test  RMSE_test  MAPE (%)_test\n",
      " 24.045300   36.288377       36.427012 21.936280 29.875416     30.441613 21.247453  27.390956      17.894521\n",
      " 27.264689   41.339586       42.869943 25.051671 34.444629     35.717254 24.312731  32.302220      20.307395\n",
      " 28.559131   43.278416       47.176728 26.781048 36.922374     40.712471 26.514601  34.579159      22.242829\n",
      " 28.971393   44.291713       47.397779 27.822531 38.615568     42.424907 28.610088  36.988680      23.872629\n",
      " 29.918683   45.624758       49.106444 29.040399 39.957078     45.414394 29.713424  38.073705      24.722841\n",
      " 30.999726   46.847114       54.641551 29.708202 40.588280     50.053708 29.362119  37.840135      24.484477\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.045300</td>\n",
       "      <td>36.288377</td>\n",
       "      <td>36.427012</td>\n",
       "      <td>21.936280</td>\n",
       "      <td>29.875416</td>\n",
       "      <td>30.441613</td>\n",
       "      <td>21.247453</td>\n",
       "      <td>27.390956</td>\n",
       "      <td>17.894521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.264689</td>\n",
       "      <td>41.339586</td>\n",
       "      <td>42.869943</td>\n",
       "      <td>25.051671</td>\n",
       "      <td>34.444629</td>\n",
       "      <td>35.717254</td>\n",
       "      <td>24.312731</td>\n",
       "      <td>32.302220</td>\n",
       "      <td>20.307395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.559131</td>\n",
       "      <td>43.278416</td>\n",
       "      <td>47.176728</td>\n",
       "      <td>26.781048</td>\n",
       "      <td>36.922374</td>\n",
       "      <td>40.712471</td>\n",
       "      <td>26.514601</td>\n",
       "      <td>34.579159</td>\n",
       "      <td>22.242829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.971393</td>\n",
       "      <td>44.291713</td>\n",
       "      <td>47.397779</td>\n",
       "      <td>27.822531</td>\n",
       "      <td>38.615568</td>\n",
       "      <td>42.424907</td>\n",
       "      <td>28.610088</td>\n",
       "      <td>36.988680</td>\n",
       "      <td>23.872629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29.918683</td>\n",
       "      <td>45.624758</td>\n",
       "      <td>49.106444</td>\n",
       "      <td>29.040399</td>\n",
       "      <td>39.957078</td>\n",
       "      <td>45.414394</td>\n",
       "      <td>29.713424</td>\n",
       "      <td>38.073705</td>\n",
       "      <td>24.722841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30.999726</td>\n",
       "      <td>46.847114</td>\n",
       "      <td>54.641551</td>\n",
       "      <td>29.708202</td>\n",
       "      <td>40.588280</td>\n",
       "      <td>50.053708</td>\n",
       "      <td>29.362119</td>\n",
       "      <td>37.840135</td>\n",
       "      <td>24.484477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  \\\n",
       "144                                                                \n",
       "1    24.045300   36.288377       36.427012  21.936280  29.875416   \n",
       "2    27.264689   41.339586       42.869943  25.051671  34.444629   \n",
       "3    28.559131   43.278416       47.176728  26.781048  36.922374   \n",
       "4    28.971393   44.291713       47.397779  27.822531  38.615568   \n",
       "5    29.918683   45.624758       49.106444  29.040399  39.957078   \n",
       "6    30.999726   46.847114       54.641551  29.708202  40.588280   \n",
       "\n",
       "     MAPE (%)_val   MAE_test  RMSE_test  MAPE (%)_test  \n",
       "144                                                     \n",
       "1       30.441613  21.247453  27.390956      17.894521  \n",
       "2       35.717254  24.312731  32.302220      20.307395  \n",
       "3       40.712471  26.514601  34.579159      22.242829  \n",
       "4       42.424907  28.610088  36.988680      23.872629  \n",
       "5       45.414394  29.713424  38.073705      24.722841  \n",
       "6       50.053708  29.362119  37.840135      24.484477  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 07:41:22,018 - 168\n",
      "2025-01-09 07:41:22,020 - \n",
      "--- Run 1 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91: early stopping\n",
      "Restoring model weights from the end of the best epoch: 71.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 07:49:42,057 - Validation loss: 0.00455\n",
      "2025-01-09 07:49:45,264 - \n",
      "--- Run 2 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 84.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 07:58:58,775 - Validation loss: 0.00438\n",
      "2025-01-09 07:59:02,021 - \n",
      "--- Run 3 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 81.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 08:08:15,825 - Validation loss: 0.00418\n",
      "2025-01-09 08:08:19,040 - \n",
      "--- Run 4 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 08:15:16,282 - Validation loss: 0.00445\n",
      "2025-01-09 08:15:19,396 - \n",
      "--- Run 5 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86: early stopping\n",
      "Restoring model weights from the end of the best epoch: 66.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 08:23:18,110 - Validation loss: 0.00434\n",
      "2025-01-09 08:23:21,273 - \n",
      "--- Run 6 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77: early stopping\n",
      "Restoring model weights from the end of the best epoch: 57.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 08:30:27,671 - Validation loss: 0.00442\n",
      "2025-01-09 08:30:30,734 - \n",
      "--- Run 7 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 08:35:52,393 - Validation loss: 0.00460\n",
      "2025-01-09 08:35:55,451 - \n",
      "--- Run 8 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 97.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 08:45:01,415 - Validation loss: 0.00446\n",
      "2025-01-09 08:45:04,607 - \n",
      "--- Run 9 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77: early stopping\n",
      "Restoring model weights from the end of the best epoch: 57.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 08:52:11,239 - Validation loss: 0.00428\n",
      "2025-01-09 08:52:14,403 - \n",
      "--- Run 10 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 81.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 09:01:30,055 - Validation loss: 0.00426\n",
      "2025-01-09 09:01:33,238 - \n",
      "--- Aggregated Mean of All Metrics Across 10(Successful) Runs ---\n",
      "2025-01-09 09:01:33,242 - \n",
      " MAE_train  RMSE_train  MAPE (%)_train   MAE_val  RMSE_val  MAPE (%)_val  MAE_test  RMSE_test  MAPE (%)_test\n",
      " 23.367218   35.490055       34.221198 22.036282 29.667932     31.526453 20.647045  26.776784      17.462661\n",
      " 25.993776   39.952771       38.119720 25.157737 34.466454     35.872230 24.565619  32.191614      20.607123\n",
      " 27.464783   41.720627       43.692629 27.286786 37.138144     42.865126 27.174248  35.024078      22.982156\n",
      " 27.889366   42.529420       45.527924 28.339992 38.735901     45.729228 28.949137  36.959188      24.286629\n",
      " 28.478884   43.417724       48.291731 29.221175 39.825340     49.319581 29.207131  37.026360      24.597500\n",
      " 29.142362   44.350107       50.461236 29.748788 40.504261     51.537037 29.066012  36.989413      24.514378\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.367218</td>\n",
       "      <td>35.490055</td>\n",
       "      <td>34.221198</td>\n",
       "      <td>22.036282</td>\n",
       "      <td>29.667932</td>\n",
       "      <td>31.526453</td>\n",
       "      <td>20.647045</td>\n",
       "      <td>26.776784</td>\n",
       "      <td>17.462661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.993776</td>\n",
       "      <td>39.952771</td>\n",
       "      <td>38.119720</td>\n",
       "      <td>25.157737</td>\n",
       "      <td>34.466454</td>\n",
       "      <td>35.872230</td>\n",
       "      <td>24.565619</td>\n",
       "      <td>32.191614</td>\n",
       "      <td>20.607123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.464783</td>\n",
       "      <td>41.720627</td>\n",
       "      <td>43.692629</td>\n",
       "      <td>27.286786</td>\n",
       "      <td>37.138144</td>\n",
       "      <td>42.865126</td>\n",
       "      <td>27.174248</td>\n",
       "      <td>35.024078</td>\n",
       "      <td>22.982156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.889366</td>\n",
       "      <td>42.529420</td>\n",
       "      <td>45.527924</td>\n",
       "      <td>28.339992</td>\n",
       "      <td>38.735901</td>\n",
       "      <td>45.729228</td>\n",
       "      <td>28.949137</td>\n",
       "      <td>36.959188</td>\n",
       "      <td>24.286629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28.478884</td>\n",
       "      <td>43.417724</td>\n",
       "      <td>48.291731</td>\n",
       "      <td>29.221175</td>\n",
       "      <td>39.825340</td>\n",
       "      <td>49.319581</td>\n",
       "      <td>29.207131</td>\n",
       "      <td>37.026360</td>\n",
       "      <td>24.597500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29.142362</td>\n",
       "      <td>44.350107</td>\n",
       "      <td>50.461236</td>\n",
       "      <td>29.748788</td>\n",
       "      <td>40.504261</td>\n",
       "      <td>51.537037</td>\n",
       "      <td>29.066012</td>\n",
       "      <td>36.989413</td>\n",
       "      <td>24.514378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  \\\n",
       "168                                                                \n",
       "1    23.367218   35.490055       34.221198  22.036282  29.667932   \n",
       "2    25.993776   39.952771       38.119720  25.157737  34.466454   \n",
       "3    27.464783   41.720627       43.692629  27.286786  37.138144   \n",
       "4    27.889366   42.529420       45.527924  28.339992  38.735901   \n",
       "5    28.478884   43.417724       48.291731  29.221175  39.825340   \n",
       "6    29.142362   44.350107       50.461236  29.748788  40.504261   \n",
       "\n",
       "     MAPE (%)_val   MAE_test  RMSE_test  MAPE (%)_test  \n",
       "168                                                     \n",
       "1       31.526453  20.647045  26.776784      17.462661  \n",
       "2       35.872230  24.565619  32.191614      20.607123  \n",
       "3       42.865126  27.174248  35.024078      22.982156  \n",
       "4       45.729228  28.949137  36.959188      24.286629  \n",
       "5       49.319581  29.207131  37.026360      24.597500  \n",
       "6       51.537037  29.066012  36.989413      24.514378  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 09:01:33,254 - 192\n",
      "2025-01-09 09:01:33,255 - \n",
      "--- Run 1 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 09:03:01,039 - Validation loss: 0.00432\n",
      "2025-01-09 09:03:04,178 - \n",
      "--- Run 2 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 09:04:29,253 - Validation loss: 0.00428\n",
      "2025-01-09 09:04:32,378 - \n",
      "--- Run 3 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 09:06:02,764 - Validation loss: 0.00440\n",
      "2025-01-09 09:06:06,161 - \n",
      "--- Run 4 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 09:06:53,649 - Validation loss: 0.00458\n",
      "2025-01-09 09:06:56,947 - \n",
      "--- Run 5 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 09:08:23,747 - Validation loss: 0.00417\n",
      "2025-01-09 09:08:26,986 - \n",
      "--- Run 6 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 09:09:15,376 - Validation loss: 0.00465\n",
      "2025-01-09 09:09:18,647 - \n",
      "--- Run 7 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 09:10:15,245 - Validation loss: 0.00429\n",
      "2025-01-09 09:10:18,466 - \n",
      "--- Run 8 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 09:11:23,683 - Validation loss: 0.00424\n",
      "2025-01-09 09:11:26,943 - \n",
      "--- Run 9 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 09:12:27,358 - Validation loss: 0.00446\n",
      "2025-01-09 09:12:30,487 - \n",
      "--- Run 10 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 09:13:43,280 - Validation loss: 0.00430\n",
      "2025-01-09 09:13:46,477 - \n",
      "--- Aggregated Mean of All Metrics Across 10(Successful) Runs ---\n",
      "2025-01-09 09:13:46,481 - \n",
      " MAE_train  RMSE_train  MAPE (%)_train   MAE_val  RMSE_val  MAPE (%)_val  MAE_test  RMSE_test  MAPE (%)_test\n",
      " 23.930660   36.302538       35.961602 22.146141 30.027991     31.490034 19.725099  25.647725      16.494463\n",
      " 26.984251   41.245435       41.305645 25.211674 34.593539     36.228868 22.954907  30.562380      19.166024\n",
      " 28.758259   43.405748       46.942074 27.258745 37.137540     42.721650 25.523402  33.067317      21.279038\n",
      " 29.411796   44.497308       49.572023 28.269345 38.533363     46.232008 26.856311  34.718520      22.212821\n",
      " 30.048418   45.628503       51.116663 29.227758 39.572023     49.160016 28.155583  36.120209      23.173677\n",
      " 31.073280   46.750129       55.179846 29.697127 40.019998     52.936402 27.962133  36.282634      23.123144\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.930660</td>\n",
       "      <td>36.302538</td>\n",
       "      <td>35.961602</td>\n",
       "      <td>22.146141</td>\n",
       "      <td>30.027991</td>\n",
       "      <td>31.490034</td>\n",
       "      <td>19.725099</td>\n",
       "      <td>25.647725</td>\n",
       "      <td>16.494463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.984251</td>\n",
       "      <td>41.245435</td>\n",
       "      <td>41.305645</td>\n",
       "      <td>25.211674</td>\n",
       "      <td>34.593539</td>\n",
       "      <td>36.228868</td>\n",
       "      <td>22.954907</td>\n",
       "      <td>30.562380</td>\n",
       "      <td>19.166024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.758259</td>\n",
       "      <td>43.405748</td>\n",
       "      <td>46.942074</td>\n",
       "      <td>27.258745</td>\n",
       "      <td>37.137540</td>\n",
       "      <td>42.721650</td>\n",
       "      <td>25.523402</td>\n",
       "      <td>33.067317</td>\n",
       "      <td>21.279038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.411796</td>\n",
       "      <td>44.497308</td>\n",
       "      <td>49.572023</td>\n",
       "      <td>28.269345</td>\n",
       "      <td>38.533363</td>\n",
       "      <td>46.232008</td>\n",
       "      <td>26.856311</td>\n",
       "      <td>34.718520</td>\n",
       "      <td>22.212821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.048418</td>\n",
       "      <td>45.628503</td>\n",
       "      <td>51.116663</td>\n",
       "      <td>29.227758</td>\n",
       "      <td>39.572023</td>\n",
       "      <td>49.160016</td>\n",
       "      <td>28.155583</td>\n",
       "      <td>36.120209</td>\n",
       "      <td>23.173677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31.073280</td>\n",
       "      <td>46.750129</td>\n",
       "      <td>55.179846</td>\n",
       "      <td>29.697127</td>\n",
       "      <td>40.019998</td>\n",
       "      <td>52.936402</td>\n",
       "      <td>27.962133</td>\n",
       "      <td>36.282634</td>\n",
       "      <td>23.123144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  \\\n",
       "192                                                                \n",
       "1    23.930660   36.302538       35.961602  22.146141  30.027991   \n",
       "2    26.984251   41.245435       41.305645  25.211674  34.593539   \n",
       "3    28.758259   43.405748       46.942074  27.258745  37.137540   \n",
       "4    29.411796   44.497308       49.572023  28.269345  38.533363   \n",
       "5    30.048418   45.628503       51.116663  29.227758  39.572023   \n",
       "6    31.073280   46.750129       55.179846  29.697127  40.019998   \n",
       "\n",
       "     MAPE (%)_val   MAE_test  RMSE_test  MAPE (%)_test  \n",
       "192                                                     \n",
       "1       31.490034  19.725099  25.647725      16.494463  \n",
       "2       36.228868  22.954907  30.562380      19.166024  \n",
       "3       42.721650  25.523402  33.067317      21.279038  \n",
       "4       46.232008  26.856311  34.718520      22.212821  \n",
       "5       49.160016  28.155583  36.120209      23.173677  \n",
       "6       52.936402  27.962133  36.282634      23.123144  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 09:13:46,490 - 216\n",
      "2025-01-09 09:13:46,492 - \n",
      "--- Run 1 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 09:17:53,250 - Validation loss: 0.00378\n",
      "2025-01-09 09:17:56,848 - \n",
      "--- Run 2 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 09:22:18,094 - Validation loss: 0.00391\n",
      "2025-01-09 09:22:21,301 - \n",
      "--- Run 3 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 09:26:03,895 - Validation loss: 0.00405\n",
      "2025-01-09 09:26:07,244 - \n",
      "--- Run 4 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 09:30:19,237 - Validation loss: 0.00389\n",
      "2025-01-09 09:30:22,795 - \n",
      "--- Run 5 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "mean_metrics_list=[]\n",
    "#for length in best_hyperparameters.keys():\n",
    "for length in best_hyperparameters_improved_model.keys():\n",
    "    logger.info(length)\n",
    "    \n",
    "    # Number of runs\n",
    "    n_runs = 10\n",
    "    \n",
    "    # get the best hyperparameter of each length\n",
    "    #hyperparams = best_hyperparameters[length]\n",
    "    hyperparams = best_hyperparameters_improved_model[length]\n",
    "    \n",
    "    # Initialize lists to store mean metrics and all metrics from each run\n",
    "    mean_metrics_rows = []\n",
    "    df_all_metrics_list = []\n",
    "    successful_runs = []  # To track runs with valid mse\n",
    "\n",
    "    for run in range(1, n_runs + 1):\n",
    "        logger.info(f\"\\n--- Run {run} ---\")\n",
    "\n",
    "        # Optionally set a unique seed for each run to ensure variability\n",
    "        seed = run\n",
    "        # Train the model\n",
    "        model, mse = train_model(hyperparams, data_dict, length, seed=seed)\n",
    "        \n",
    "        if not np.isnan(mse):  # Only proceed if mse is valid\n",
    "            successful_runs.append(run)\n",
    "        \n",
    "            X_train = data_dict[length]['X_train']\n",
    "            y_train = data_dict[length]['y_train']\n",
    "            X_val = data_dict[length]['X_val']\n",
    "            y_val = data_dict[length]['y_val']\n",
    "            X_test = data_dict[length]['X_test']\n",
    "            y_test = data_dict[length]['y_test']\n",
    "\n",
    "            #get the true flow and predicted flow\n",
    "            y_pred_train, y_obs_train = make_prediction(model, X_train, y_train)\n",
    "            y_pred_val, y_obs_val = make_prediction(model, X_val, y_val)\n",
    "            y_pred_test, y_obs_test = make_prediction(model, X_test, y_test)\n",
    "\n",
    "            #calculate the evaluation metrics of each output step\n",
    "            df_train = evaluation(y_pred_train, y_obs_train).add_suffix('_train')\n",
    "            df_val = evaluation(y_pred_val, y_obs_val).add_suffix('_val')\n",
    "            df_test = evaluation(y_pred_test, y_obs_test).add_suffix('_test')\n",
    "\n",
    "            df_all_metrics = pd.concat([df_train, df_val, df_test], axis=1)\n",
    "            df_all_metrics.index.name = length\n",
    "\n",
    "            # Append df_all_metrics to the list\n",
    "            df_all_metrics_list.append(df_all_metrics)\n",
    "\n",
    "            # Calculate mean for all output step\n",
    "            #mean_metrics = df_val.mean()\n",
    "            mean_metrics = pd.concat([df_train.mean(), df_val.mean(), df_test.mean()])\n",
    "            mean_metrics_row = pd.DataFrame(mean_metrics).T\n",
    "            mean_metrics_row['MSE_val(loss)'] = mse\n",
    "            mean_metrics_row['input_len'] = length\n",
    "            #mean_metrics_row = mean_metrics_row[['input_len','MSE_val(loss)', 'MAE_val', 'RMSE_val', 'MAPE (%)_val']]\n",
    "            mean_metrics_row = mean_metrics_row[['input_len', 'MSE_val(loss)', 'MAE_train', 'RMSE_train', 'MAPE (%)_train',\n",
    "                                             'MAE_val', 'RMSE_val', 'MAPE (%)_val',\n",
    "                                             'MAE_test', 'RMSE_test', 'MAPE (%)_test']]\n",
    "\n",
    "            # Append to the list\n",
    "            mean_metrics_rows.append(mean_metrics_row)\n",
    "        else:\n",
    "            logger.info(f\"Run {run} has mse=NaN, skipping.\")\n",
    "            \n",
    "    # Check if there are successful runs before proceeding\n",
    "    if successful_runs:       \n",
    "        # Concatenate all df_all_metrics into a single DataFrame with a new level for runs\n",
    "        concatenated_all_metrics = pd.concat(df_all_metrics_list, keys=successful_runs, names=['Run', 'Time Step'])\n",
    "\n",
    "        # Calculate the mean across runs for each metric and time step\n",
    "        # This will group by 'Time Step' and calculate the mean of each metric across all runs\n",
    "        aggregated_all_metrics_mean = concatenated_all_metrics.groupby('Time Step').mean()\n",
    "        aggregated_all_metrics_mean.index.name = length\n",
    "\n",
    "        logger.info(\"\\n--- Aggregated Mean of All Metrics Across 10(Successful) Runs ---\")\n",
    "        # Convert DataFrame to string\n",
    "        aggregated_all_metrics_mean_str = aggregated_all_metrics_mean.to_string(index=False)    \n",
    "        # Log the DataFrame\n",
    "        logger.info(\"\\n\" + aggregated_all_metrics_mean_str)\n",
    "        display(aggregated_all_metrics_mean)\n",
    "    else:\n",
    "        logger.info(f\"No successful runs for input length {length}.\")\n",
    "\n",
    "    # Check if mean metrics were calculated\n",
    "    if mean_metrics_rows:        \n",
    "        # After all runs, create a DataFrame of mean metrics\n",
    "        mean_metrics_df = pd.concat(mean_metrics_rows, ignore_index=True)\n",
    "        # Calculate the mean of each metric across the 10 runs\n",
    "        final_mean_metrics = mean_metrics_df.mean()\n",
    "\n",
    "        # Create a DataFrame for the final mean metrics\n",
    "        final_mean_metrics_df = pd.DataFrame(final_mean_metrics).T\n",
    "\n",
    "        mean_metrics_list.append(final_mean_metrics_df)\n",
    "    else:\n",
    "        logger.info(f\"No mean metrics calculated for input length {length}.\")\n",
    "\n",
    "mean_metrics_df = pd.concat(mean_metrics_list).reset_index(drop=True)\n",
    "logger.info(\"\\n--- Final Mean Metrics Across 10 Runs ---\")\n",
    "# Convert DataFrame to string\n",
    "mean_metrics_df_str = mean_metrics_df.to_string(index=False)    \n",
    "# Log the DataFrame\n",
    "logger.info(\"\\n\" + mean_metrics_df_str)\n",
    "mean_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_len</th>\n",
       "      <th>MSE_val(loss)</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0.004211</td>\n",
       "      <td>26.078336</td>\n",
       "      <td>36.003758</td>\n",
       "      <td>41.020640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.0</td>\n",
       "      <td>0.004374</td>\n",
       "      <td>26.549048</td>\n",
       "      <td>36.693637</td>\n",
       "      <td>43.406696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72.0</td>\n",
       "      <td>0.004357</td>\n",
       "      <td>26.776325</td>\n",
       "      <td>36.609731</td>\n",
       "      <td>43.280924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96.0</td>\n",
       "      <td>0.004264</td>\n",
       "      <td>26.375986</td>\n",
       "      <td>36.260495</td>\n",
       "      <td>43.298351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.004148</td>\n",
       "      <td>26.150845</td>\n",
       "      <td>35.685248</td>\n",
       "      <td>41.796633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>144.0</td>\n",
       "      <td>0.004185</td>\n",
       "      <td>25.876769</td>\n",
       "      <td>35.851591</td>\n",
       "      <td>39.127578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>168.0</td>\n",
       "      <td>0.004297</td>\n",
       "      <td>26.577252</td>\n",
       "      <td>36.321709</td>\n",
       "      <td>40.402273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>192.0</td>\n",
       "      <td>0.004218</td>\n",
       "      <td>26.435064</td>\n",
       "      <td>35.987619</td>\n",
       "      <td>42.069822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>216.0</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>25.147041</td>\n",
       "      <td>34.144567</td>\n",
       "      <td>40.511893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>240.0</td>\n",
       "      <td>0.003904</td>\n",
       "      <td>25.508670</td>\n",
       "      <td>34.659827</td>\n",
       "      <td>41.343390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>264.0</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>25.751140</td>\n",
       "      <td>34.950092</td>\n",
       "      <td>41.494442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>288.0</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>25.427336</td>\n",
       "      <td>34.495212</td>\n",
       "      <td>42.066286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>312.0</td>\n",
       "      <td>0.003761</td>\n",
       "      <td>24.715508</td>\n",
       "      <td>34.020234</td>\n",
       "      <td>40.378756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>336.0</td>\n",
       "      <td>0.003617</td>\n",
       "      <td>24.394507</td>\n",
       "      <td>33.347104</td>\n",
       "      <td>40.676652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>360.0</td>\n",
       "      <td>0.003680</td>\n",
       "      <td>24.395893</td>\n",
       "      <td>33.623093</td>\n",
       "      <td>39.693529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>384.0</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>23.911605</td>\n",
       "      <td>33.563746</td>\n",
       "      <td>38.169636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>408.0</td>\n",
       "      <td>0.003686</td>\n",
       "      <td>23.628119</td>\n",
       "      <td>33.678307</td>\n",
       "      <td>37.637592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>432.0</td>\n",
       "      <td>0.003743</td>\n",
       "      <td>23.737831</td>\n",
       "      <td>33.919032</td>\n",
       "      <td>38.142956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>456.0</td>\n",
       "      <td>0.004012</td>\n",
       "      <td>24.261658</td>\n",
       "      <td>35.123513</td>\n",
       "      <td>36.545006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>480.0</td>\n",
       "      <td>0.004417</td>\n",
       "      <td>25.968479</td>\n",
       "      <td>36.850241</td>\n",
       "      <td>41.098289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>504.0</td>\n",
       "      <td>0.004906</td>\n",
       "      <td>27.106920</td>\n",
       "      <td>38.796569</td>\n",
       "      <td>40.717816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    input_len  MSE_val(loss)    MAE_val   RMSE_val  MAPE (%)_val\n",
       "0        24.0       0.004211  26.078336  36.003758     41.020640\n",
       "1        48.0       0.004374  26.549048  36.693637     43.406696\n",
       "2        72.0       0.004357  26.776325  36.609731     43.280924\n",
       "3        96.0       0.004264  26.375986  36.260495     43.298351\n",
       "4       120.0       0.004148  26.150845  35.685248     41.796633\n",
       "5       144.0       0.004185  25.876769  35.851591     39.127578\n",
       "6       168.0       0.004297  26.577252  36.321709     40.402273\n",
       "7       192.0       0.004218  26.435064  35.987619     42.069822\n",
       "8       216.0       0.003788  25.147041  34.144567     40.511893\n",
       "9       240.0       0.003904  25.508670  34.659827     41.343390\n",
       "10      264.0       0.003968  25.751140  34.950092     41.494442\n",
       "11      288.0       0.003870  25.427336  34.495212     42.066286\n",
       "12      312.0       0.003761  24.715508  34.020234     40.378756\n",
       "13      336.0       0.003617  24.394507  33.347104     40.676652\n",
       "14      360.0       0.003680  24.395893  33.623093     39.693529\n",
       "15      384.0       0.003659  23.911605  33.563746     38.169636\n",
       "16      408.0       0.003686  23.628119  33.678307     37.637592\n",
       "17      432.0       0.003743  23.737831  33.919032     38.142956\n",
       "18      456.0       0.004012  24.261658  35.123513     36.545006\n",
       "19      480.0       0.004417  25.968479  36.850241     41.098289\n",
       "20      504.0       0.004906  27.106920  38.796569     40.717816"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Calculate the training and inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 20:32:37,118 - 24\n",
      "2025-02-20 20:32:37,126 - \n",
      "--- Run 1 ---\n",
      "2025-02-20 20:32:39.386180: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 20:36:10,995 - Validation loss: 0.00428\n",
      "2025-02-20 20:36:10,996 - Average training time per epoch: 2.887133 seconds over 74 epochs\n",
      "2025-02-20 20:36:11,493 - \n",
      "Inference time: 0.496591 seconds\n",
      "2025-02-20 20:36:11,494 - \n",
      "--- Run 2 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 83.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 20:41:07,496 - Validation loss: 0.00431\n",
      "2025-02-20 20:41:07,498 - Average training time per epoch: 2.957217 seconds over 100 epochs\n",
      "2025-02-20 20:41:08,039 - \n",
      "Inference time: 0.539059 seconds\n",
      "2025-02-20 20:41:08,041 - \n",
      "--- Run 3 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 20:44:02,622 - Validation loss: 0.00446\n",
      "2025-02-20 20:44:02,623 - Average training time per epoch: 2.858154 seconds over 61 epochs\n",
      "2025-02-20 20:44:03,102 - \n",
      "Inference time: 0.479203 seconds\n",
      "2025-02-20 20:44:03,104 - \n",
      "--- Run 4 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 87.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 20:48:59,143 - Validation loss: 0.00431\n",
      "2025-02-20 20:48:59,144 - Average training time per epoch: 2.957523 seconds over 100 epochs\n",
      "2025-02-20 20:48:59,634 - \n",
      "Inference time: 0.490515 seconds\n",
      "2025-02-20 20:48:59,636 - \n",
      "--- Run 5 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 97.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 20:53:45,133 - Validation loss: 0.00413\n",
      "2025-02-20 20:53:45,135 - Average training time per epoch: 2.852486 seconds over 100 epochs\n",
      "2025-02-20 20:53:45,675 - \n",
      "Inference time: 0.540100 seconds\n",
      "2025-02-20 20:53:45,677 - \n",
      "--- Run 6 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 96.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 20:58:43,705 - Validation loss: 0.00423\n",
      "2025-02-20 20:58:43,706 - Average training time per epoch: 2.977900 seconds over 100 epochs\n",
      "2025-02-20 20:58:44,183 - \n",
      "Inference time: 0.476666 seconds\n",
      "2025-02-20 20:58:44,185 - \n",
      "--- Run 7 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82: early stopping\n",
      "Restoring model weights from the end of the best epoch: 62.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 21:02:56,944 - Validation loss: 0.00428\n",
      "2025-02-20 21:02:56,945 - Average training time per epoch: 3.079476 seconds over 82 epochs\n",
      "2025-02-20 21:02:57,526 - \n",
      "Inference time: 0.580320 seconds\n",
      "2025-02-20 21:02:57,528 - \n",
      "--- Run 8 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92: early stopping\n",
      "Restoring model weights from the end of the best epoch: 72.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 21:07:55,659 - Validation loss: 0.00429\n",
      "2025-02-20 21:07:55,660 - Average training time per epoch: 3.237030 seconds over 92 epochs\n",
      "2025-02-20 21:07:56,263 - \n",
      "Inference time: 0.602425 seconds\n",
      "2025-02-20 21:07:56,265 - \n",
      "--- Run 9 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 21:11:02,084 - Validation loss: 0.00439\n",
      "2025-02-20 21:11:02,086 - Average training time per epoch: 3.313389 seconds over 56 epochs\n",
      "2025-02-20 21:11:02,717 - \n",
      "Inference time: 0.630155 seconds\n",
      "2025-02-20 21:11:02,720 - \n",
      "--- Run 10 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# List to collect average inference times for each length\n",
    "inference_results = []\n",
    "training_results = []\n",
    "\n",
    "#for length in best_hyperparameters.keys():\n",
    "for length in best_hyperparameters_improved_model.keys():\n",
    "    logger.info(length)\n",
    "    \n",
    "    # Number of runs\n",
    "    n_runs = 10\n",
    "    \n",
    "    # get the best hyperparameter of each length\n",
    "    #hyperparams = best_hyperparameters[length]\n",
    "    hyperparams = best_hyperparameters_improved_model[length]\n",
    "\n",
    "    # List to store inference times for each run\n",
    "    inference_times = []\n",
    "    training_times = []\n",
    "\n",
    "    for run in range(1, n_runs + 1):\n",
    "        logger.info(f\"\\n--- Run {run} ---\")\n",
    "\n",
    "        # Optionally set a unique seed for each run to ensure variability\n",
    "        seed = run\n",
    "        # Train the model\n",
    "        model, mse, run_training_time = train_model(hyperparams, data_dict, length, seed=seed)\n",
    "        \n",
    "        if not np.isnan(mse):  # Only proceed if mse is valid\n",
    "            training_times.append(run_training_time)\n",
    "            \n",
    "            X_test = data_dict[length]['X_test']\n",
    "            y_test = data_dict[length]['y_test']\n",
    "\n",
    "            y_pred_test, y_obs_test, run_inference_time = make_prediction(model, X_test, y_test)\n",
    "            \n",
    "            inference_times.append(run_inference_time)\n",
    "\n",
    "        else:\n",
    "            logger.info(f\"Run {run} has mse=NaN, skipping.\")\n",
    "            \n",
    "    # Calculate the average inference time across all runs\n",
    "    avg_inference_time = sum(inference_times) / len(inference_times)\n",
    "    logger.info(f\"\\nAverage inference time for {n_runs} runs: {avg_inference_time:.6f} seconds\")\n",
    "    # Compute the average training time over the 10 runs for the current length\n",
    "    avg_training_time = sum(training_times) / len(training_times)\n",
    "    logger.info(f\"\\nAverage training time for length {length}: {avg_training_time:.6f} seconds over {n_runs} runs\")\n",
    "\n",
    "    inference_results.append({\n",
    "        \"length\": length,\n",
    "        \"avg_inference_time\": avg_inference_time\n",
    "    })\n",
    "    training_results.append({\n",
    "        \"length\": length,\n",
    "        \"avg_training_time\": avg_training_time\n",
    "    })\n",
    "\n",
    "# Convert the results into a DataFrame\n",
    "df_inference = pd.DataFrame(inference_results)\n",
    "df_training = pd.DataFrame(training_results)\n",
    "df_inference_training = pd.merge(df_training, df_inference, on='length')\n",
    "logger.info(\"\\n\" + df_inference_training.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Calculate variance within runs and steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1 Get metrics of all input length, runs and steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Create a custom logger\n",
    "logger = logging.getLogger('my_logger')\n",
    "\n",
    "if not logger.handlers:\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    c_handler = logging.StreamHandler()\n",
    "    f_handler = logging.FileHandler('lstm_metrics.log')\n",
    "\n",
    "    formatter = logging.Formatter('%(asctime)s - %(message)s')\n",
    "    c_handler.setFormatter(formatter)\n",
    "    f_handler.setFormatter(formatter)\n",
    "\n",
    "    logger.addHandler(c_handler)\n",
    "    logger.addHandler(f_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:02:12,945 - 24\n",
      "2025-09-30 16:02:12,947 - \n",
      "--- Run 1 ---\n",
      "2025-09-30 16:02:13.326670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13927 MB memory:  -> device: 0, name: NVIDIA A30, pci bus id: 276f:00:00.0, compute capability: 8.0\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2025-09-30 16:02:17.080380: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:04:47,990 - Validation loss: 0.00428\n",
      "2025-09-30 16:04:47,991 - Average training time per epoch: 2.076496 seconds over 74 epochs\n",
      "2025-09-30 16:04:48,477 - \n",
      "Inference time: 0.485813 seconds\n",
      "2025-09-30 16:04:48,484 - \n",
      "--- Run 2 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 83.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:08:04,851 - Validation loss: 0.00431\n",
      "2025-09-30 16:08:04,852 - Average training time per epoch: 1.961530 seconds over 100 epochs\n",
      "2025-09-30 16:08:05,279 - \n",
      "Inference time: 0.426357 seconds\n",
      "2025-09-30 16:08:05,285 - \n",
      "--- Run 3 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:10:17,957 - Validation loss: 0.00446\n",
      "2025-09-30 16:10:17,958 - Average training time per epoch: 2.171935 seconds over 61 epochs\n",
      "2025-09-30 16:10:18,494 - \n",
      "Inference time: 0.535852 seconds\n",
      "2025-09-30 16:10:18,500 - \n",
      "--- Run 4 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 87.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:13:45,201 - Validation loss: 0.00431\n",
      "2025-09-30 16:13:45,202 - Average training time per epoch: 2.064511 seconds over 100 epochs\n",
      "2025-09-30 16:13:45,763 - \n",
      "Inference time: 0.560118 seconds\n",
      "2025-09-30 16:13:45,769 - \n",
      "--- Run 5 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 97.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:16:49,227 - Validation loss: 0.00413\n",
      "2025-09-30 16:16:49,228 - Average training time per epoch: 1.832478 seconds over 100 epochs\n",
      "2025-09-30 16:16:49,667 - \n",
      "Inference time: 0.438230 seconds\n",
      "2025-09-30 16:16:49,677 - \n",
      "--- Run 6 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 96.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:20:04,758 - Validation loss: 0.00423\n",
      "2025-09-30 16:20:04,760 - Average training time per epoch: 1.948231 seconds over 100 epochs\n",
      "2025-09-30 16:20:05,254 - \n",
      "Inference time: 0.492619 seconds\n",
      "2025-09-30 16:20:05,263 - \n",
      "--- Run 7 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82: early stopping\n",
      "Restoring model weights from the end of the best epoch: 62.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:22:51,952 - Validation loss: 0.00428\n",
      "2025-09-30 16:22:51,952 - Average training time per epoch: 2.030000 seconds over 82 epochs\n",
      "2025-09-30 16:22:52,570 - \n",
      "Inference time: 0.617044 seconds\n",
      "2025-09-30 16:22:52,584 - \n",
      "--- Run 8 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92: early stopping\n",
      "Restoring model weights from the end of the best epoch: 72.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:26:08,572 - Validation loss: 0.00429\n",
      "2025-09-30 16:26:08,573 - Average training time per epoch: 2.127850 seconds over 92 epochs\n",
      "2025-09-30 16:26:08,994 - \n",
      "Inference time: 0.420449 seconds\n",
      "2025-09-30 16:26:09,002 - \n",
      "--- Run 9 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:28:07,500 - Validation loss: 0.00439\n",
      "2025-09-30 16:28:07,501 - Average training time per epoch: 2.112472 seconds over 56 epochs\n",
      "2025-09-30 16:28:08,131 - \n",
      "Inference time: 0.627511 seconds\n",
      "2025-09-30 16:28:08,139 - \n",
      "--- Run 10 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:30:42,843 - Validation loss: 0.00434\n",
      "2025-09-30 16:30:42,844 - Average training time per epoch: 2.032727 seconds over 76 epochs\n",
      "2025-09-30 16:30:43,268 - \n",
      "Inference time: 0.422908 seconds\n",
      "2025-09-30 16:30:43,274 - \n",
      "--- All Metrics Across 10 Runs ---\n",
      "2025-09-30 16:30:43,278 - \n",
      " input_len  run_num  pre_step  MAE_test  RMSE_test  MAPE (%)_test\n",
      "        24        1         1 19.372736  25.360436      17.502771\n",
      "        24        1         2 22.507060  30.442453      19.876685\n",
      "        24        1         3 24.353955  32.267271      21.951909\n",
      "        24        1         4 25.417998  33.301285      23.258797\n",
      "        24        1         5 26.376636  34.155375      24.134985\n",
      "        24        1         6 26.658180  34.401999      24.588346\n",
      "        24        2         1 20.699965  27.089831      18.270521\n",
      "        24        2         2 24.493745  32.360837      21.401938\n",
      "        24        2         3 27.685549  36.126388      24.000067\n",
      "        24        2         4 29.103381  37.717294      25.568040\n",
      "        24        2         5 30.133249  38.670347      26.418629\n",
      "        24        2         6 29.700835  38.365950      26.481835\n",
      "        24        3         1 19.527103  25.828778      17.239466\n",
      "        24        3         2 22.676111  30.698868      19.738780\n",
      "        24        3         3 25.016436  33.520726      21.413260\n",
      "        24        3         4 26.248946  34.848112      22.600787\n",
      "        24        3         5 27.408070  35.897879      23.449721\n",
      "        24        3         6 27.589130  35.942852      23.656381\n",
      "        24        4         1 19.672281  26.044289      16.553580\n",
      "        24        4         2 23.213186  31.308224      19.665382\n",
      "        24        4         3 26.207778  34.498217      22.639329\n",
      "        24        4         4 27.512183  35.705686      24.350392\n",
      "        24        4         5 28.988422  37.303667      25.394303\n",
      "        24        4         6 29.290926  37.800706      25.567152\n",
      "        24        5         1 19.957845  26.204523      17.820865\n",
      "        24        5         2 22.817017  30.865064      20.119032\n",
      "        24        5         3 25.854157  34.069747      22.571869\n",
      "        24        5         4 27.307119  35.687257      24.152666\n",
      "        24        5         5 27.844008  35.935234      25.323356\n",
      "        24        5         6 27.696979  36.051030      25.390440\n",
      "        24        6         1 19.166470  24.969655      17.141692\n",
      "        24        6         2 23.436572  30.911523      20.778917\n",
      "        24        6         3 25.941254  33.289050      23.456184\n",
      "        24        6         4 28.018965  35.345405      25.581976\n",
      "        24        6         5 27.758420  34.886853      25.841295\n",
      "        24        6         6 26.628494  34.206697      24.857827\n",
      "        24        7         1 19.197327  25.008203      17.313960\n",
      "        24        7         2 22.556106  30.287928      20.254592\n",
      "        24        7         3 25.672904  33.779258      22.997206\n",
      "        24        7         4 27.593616  35.696718      24.944866\n",
      "        24        7         5 28.643636  36.436448      25.710790\n",
      "        24        7         6 28.772628  36.683898      25.775167\n",
      "        24        8         1 21.007082  27.210067      18.634660\n",
      "        24        8         2 25.934069  34.409644      22.653179\n",
      "        24        8         3 28.715560  37.574367      25.654408\n",
      "        24        8         4 30.638781  39.365728      27.785826\n",
      "        24        8         5 30.882881  39.192134      28.453898\n",
      "        24        8         6 29.894012  38.038232      28.034360\n",
      "        24        9         1 19.355793  25.452046      17.586771\n",
      "        24        9         2 22.284614  29.962190      19.971057\n",
      "        24        9         3 24.013928  31.823500      21.766254\n",
      "        24        9         4 24.658953  32.704669      22.767291\n",
      "        24        9         5 25.769208  33.560316      23.790344\n",
      "        24        9         6 26.494151  34.366805      24.479863\n",
      "        24       10         1 19.778184  26.103888      17.343797\n",
      "        24       10         2 22.566880  30.463613      19.927726\n",
      "        24       10         3 24.709945  32.657931      21.991600\n",
      "        24       10         4 25.837743  33.687671      23.504162\n",
      "        24       10         5 26.783128  34.400301      24.114848\n",
      "        24       10         6 26.514375  34.138640      24.213830\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_len</th>\n",
       "      <th>run_num</th>\n",
       "      <th>pre_step</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.372736</td>\n",
       "      <td>25.360436</td>\n",
       "      <td>17.502771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>22.507060</td>\n",
       "      <td>30.442453</td>\n",
       "      <td>19.876685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>24.353955</td>\n",
       "      <td>32.267271</td>\n",
       "      <td>21.951909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>25.417998</td>\n",
       "      <td>33.301285</td>\n",
       "      <td>23.258797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>26.376636</td>\n",
       "      <td>34.155375</td>\n",
       "      <td>24.134985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>26.658180</td>\n",
       "      <td>34.401999</td>\n",
       "      <td>24.588346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20.699965</td>\n",
       "      <td>27.089831</td>\n",
       "      <td>18.270521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>24.493745</td>\n",
       "      <td>32.360837</td>\n",
       "      <td>21.401938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>27.685549</td>\n",
       "      <td>36.126388</td>\n",
       "      <td>24.000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>29.103381</td>\n",
       "      <td>37.717294</td>\n",
       "      <td>25.568040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>30.133249</td>\n",
       "      <td>38.670347</td>\n",
       "      <td>26.418629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>29.700835</td>\n",
       "      <td>38.365950</td>\n",
       "      <td>26.481835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19.527103</td>\n",
       "      <td>25.828778</td>\n",
       "      <td>17.239466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>22.676111</td>\n",
       "      <td>30.698868</td>\n",
       "      <td>19.738780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>25.016436</td>\n",
       "      <td>33.520726</td>\n",
       "      <td>21.413260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>26.248946</td>\n",
       "      <td>34.848112</td>\n",
       "      <td>22.600787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>27.408070</td>\n",
       "      <td>35.897879</td>\n",
       "      <td>23.449721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>27.589130</td>\n",
       "      <td>35.942852</td>\n",
       "      <td>23.656381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>19.672281</td>\n",
       "      <td>26.044289</td>\n",
       "      <td>16.553580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23.213186</td>\n",
       "      <td>31.308224</td>\n",
       "      <td>19.665382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>26.207778</td>\n",
       "      <td>34.498217</td>\n",
       "      <td>22.639329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>27.512183</td>\n",
       "      <td>35.705686</td>\n",
       "      <td>24.350392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>28.988422</td>\n",
       "      <td>37.303667</td>\n",
       "      <td>25.394303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>29.290926</td>\n",
       "      <td>37.800706</td>\n",
       "      <td>25.567152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>19.957845</td>\n",
       "      <td>26.204523</td>\n",
       "      <td>17.820865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>22.817017</td>\n",
       "      <td>30.865064</td>\n",
       "      <td>20.119032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>25.854157</td>\n",
       "      <td>34.069747</td>\n",
       "      <td>22.571869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>27.307119</td>\n",
       "      <td>35.687257</td>\n",
       "      <td>24.152666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>27.844008</td>\n",
       "      <td>35.935234</td>\n",
       "      <td>25.323356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>27.696979</td>\n",
       "      <td>36.051030</td>\n",
       "      <td>25.390440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>19.166470</td>\n",
       "      <td>24.969655</td>\n",
       "      <td>17.141692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>23.436572</td>\n",
       "      <td>30.911523</td>\n",
       "      <td>20.778917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>25.941254</td>\n",
       "      <td>33.289050</td>\n",
       "      <td>23.456184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>28.018965</td>\n",
       "      <td>35.345405</td>\n",
       "      <td>25.581976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>27.758420</td>\n",
       "      <td>34.886853</td>\n",
       "      <td>25.841295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>26.628494</td>\n",
       "      <td>34.206697</td>\n",
       "      <td>24.857827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>19.197327</td>\n",
       "      <td>25.008203</td>\n",
       "      <td>17.313960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>22.556106</td>\n",
       "      <td>30.287928</td>\n",
       "      <td>20.254592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>25.672904</td>\n",
       "      <td>33.779258</td>\n",
       "      <td>22.997206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>27.593616</td>\n",
       "      <td>35.696718</td>\n",
       "      <td>24.944866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>28.643636</td>\n",
       "      <td>36.436448</td>\n",
       "      <td>25.710790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>28.772628</td>\n",
       "      <td>36.683898</td>\n",
       "      <td>25.775167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>21.007082</td>\n",
       "      <td>27.210067</td>\n",
       "      <td>18.634660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>25.934069</td>\n",
       "      <td>34.409644</td>\n",
       "      <td>22.653179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>28.715560</td>\n",
       "      <td>37.574367</td>\n",
       "      <td>25.654408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>30.638781</td>\n",
       "      <td>39.365728</td>\n",
       "      <td>27.785826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>30.882881</td>\n",
       "      <td>39.192134</td>\n",
       "      <td>28.453898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>29.894012</td>\n",
       "      <td>38.038232</td>\n",
       "      <td>28.034360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>19.355793</td>\n",
       "      <td>25.452046</td>\n",
       "      <td>17.586771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>22.284614</td>\n",
       "      <td>29.962190</td>\n",
       "      <td>19.971057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>24.013928</td>\n",
       "      <td>31.823500</td>\n",
       "      <td>21.766254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>24.658953</td>\n",
       "      <td>32.704669</td>\n",
       "      <td>22.767291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>25.769208</td>\n",
       "      <td>33.560316</td>\n",
       "      <td>23.790344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>26.494151</td>\n",
       "      <td>34.366805</td>\n",
       "      <td>24.479863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>19.778184</td>\n",
       "      <td>26.103888</td>\n",
       "      <td>17.343797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>22.566880</td>\n",
       "      <td>30.463613</td>\n",
       "      <td>19.927726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>24.709945</td>\n",
       "      <td>32.657931</td>\n",
       "      <td>21.991600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>25.837743</td>\n",
       "      <td>33.687671</td>\n",
       "      <td>23.504162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>26.783128</td>\n",
       "      <td>34.400301</td>\n",
       "      <td>24.114848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>26.514375</td>\n",
       "      <td>34.138640</td>\n",
       "      <td>24.213830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    input_len  run_num  pre_step   MAE_test  RMSE_test  MAPE (%)_test\n",
       "0          24        1         1  19.372736  25.360436      17.502771\n",
       "1          24        1         2  22.507060  30.442453      19.876685\n",
       "2          24        1         3  24.353955  32.267271      21.951909\n",
       "3          24        1         4  25.417998  33.301285      23.258797\n",
       "4          24        1         5  26.376636  34.155375      24.134985\n",
       "5          24        1         6  26.658180  34.401999      24.588346\n",
       "6          24        2         1  20.699965  27.089831      18.270521\n",
       "7          24        2         2  24.493745  32.360837      21.401938\n",
       "8          24        2         3  27.685549  36.126388      24.000067\n",
       "9          24        2         4  29.103381  37.717294      25.568040\n",
       "10         24        2         5  30.133249  38.670347      26.418629\n",
       "11         24        2         6  29.700835  38.365950      26.481835\n",
       "12         24        3         1  19.527103  25.828778      17.239466\n",
       "13         24        3         2  22.676111  30.698868      19.738780\n",
       "14         24        3         3  25.016436  33.520726      21.413260\n",
       "15         24        3         4  26.248946  34.848112      22.600787\n",
       "16         24        3         5  27.408070  35.897879      23.449721\n",
       "17         24        3         6  27.589130  35.942852      23.656381\n",
       "18         24        4         1  19.672281  26.044289      16.553580\n",
       "19         24        4         2  23.213186  31.308224      19.665382\n",
       "20         24        4         3  26.207778  34.498217      22.639329\n",
       "21         24        4         4  27.512183  35.705686      24.350392\n",
       "22         24        4         5  28.988422  37.303667      25.394303\n",
       "23         24        4         6  29.290926  37.800706      25.567152\n",
       "24         24        5         1  19.957845  26.204523      17.820865\n",
       "25         24        5         2  22.817017  30.865064      20.119032\n",
       "26         24        5         3  25.854157  34.069747      22.571869\n",
       "27         24        5         4  27.307119  35.687257      24.152666\n",
       "28         24        5         5  27.844008  35.935234      25.323356\n",
       "29         24        5         6  27.696979  36.051030      25.390440\n",
       "30         24        6         1  19.166470  24.969655      17.141692\n",
       "31         24        6         2  23.436572  30.911523      20.778917\n",
       "32         24        6         3  25.941254  33.289050      23.456184\n",
       "33         24        6         4  28.018965  35.345405      25.581976\n",
       "34         24        6         5  27.758420  34.886853      25.841295\n",
       "35         24        6         6  26.628494  34.206697      24.857827\n",
       "36         24        7         1  19.197327  25.008203      17.313960\n",
       "37         24        7         2  22.556106  30.287928      20.254592\n",
       "38         24        7         3  25.672904  33.779258      22.997206\n",
       "39         24        7         4  27.593616  35.696718      24.944866\n",
       "40         24        7         5  28.643636  36.436448      25.710790\n",
       "41         24        7         6  28.772628  36.683898      25.775167\n",
       "42         24        8         1  21.007082  27.210067      18.634660\n",
       "43         24        8         2  25.934069  34.409644      22.653179\n",
       "44         24        8         3  28.715560  37.574367      25.654408\n",
       "45         24        8         4  30.638781  39.365728      27.785826\n",
       "46         24        8         5  30.882881  39.192134      28.453898\n",
       "47         24        8         6  29.894012  38.038232      28.034360\n",
       "48         24        9         1  19.355793  25.452046      17.586771\n",
       "49         24        9         2  22.284614  29.962190      19.971057\n",
       "50         24        9         3  24.013928  31.823500      21.766254\n",
       "51         24        9         4  24.658953  32.704669      22.767291\n",
       "52         24        9         5  25.769208  33.560316      23.790344\n",
       "53         24        9         6  26.494151  34.366805      24.479863\n",
       "54         24       10         1  19.778184  26.103888      17.343797\n",
       "55         24       10         2  22.566880  30.463613      19.927726\n",
       "56         24       10         3  24.709945  32.657931      21.991600\n",
       "57         24       10         4  25.837743  33.687671      23.504162\n",
       "58         24       10         5  26.783128  34.400301      24.114848\n",
       "59         24       10         6  26.514375  34.138640      24.213830"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:30:43,287 - 48\n",
      "2025-09-30 16:30:43,287 - \n",
      "--- Run 1 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:31:18,036 - Validation loss: 0.00453\n",
      "2025-09-30 16:31:18,036 - Average training time per epoch: 1.382312 seconds over 25 epochs\n",
      "2025-09-30 16:31:18,533 - \n",
      "Inference time: 0.495824 seconds\n",
      "2025-09-30 16:31:18,538 - \n",
      "--- Run 2 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:32:11,543 - Validation loss: 0.00469\n",
      "2025-09-30 16:32:11,544 - Average training time per epoch: 1.320484 seconds over 40 epochs\n",
      "2025-09-30 16:32:12,037 - \n",
      "Inference time: 0.492218 seconds\n",
      "2025-09-30 16:32:12,043 - \n",
      "--- Run 3 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:32:55,905 - Validation loss: 0.00472\n",
      "2025-09-30 16:32:55,906 - Average training time per epoch: 1.322423 seconds over 33 epochs\n",
      "2025-09-30 16:32:56,433 - \n",
      "Inference time: 0.526885 seconds\n",
      "2025-09-30 16:32:56,439 - \n",
      "--- Run 4 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:33:35,372 - Validation loss: 0.00441\n",
      "2025-09-30 16:33:35,373 - Average training time per epoch: 1.383722 seconds over 28 epochs\n",
      "2025-09-30 16:33:35,878 - \n",
      "Inference time: 0.504277 seconds\n",
      "2025-09-30 16:33:35,886 - \n",
      "--- Run 5 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:34:47,992 - Validation loss: 0.00422\n",
      "2025-09-30 16:34:47,995 - Average training time per epoch: 1.330831 seconds over 54 epochs\n",
      "2025-09-30 16:34:48,486 - \n",
      "Inference time: 0.489756 seconds\n",
      "2025-09-30 16:34:48,492 - \n",
      "--- Run 6 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:35:30,720 - Validation loss: 0.00427\n",
      "2025-09-30 16:35:30,721 - Average training time per epoch: 1.313819 seconds over 32 epochs\n",
      "2025-09-30 16:35:31,331 - \n",
      "Inference time: 0.609094 seconds\n",
      "2025-09-30 16:35:31,336 - \n",
      "--- Run 7 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:36:24,144 - Validation loss: 0.00453\n",
      "2025-09-30 16:36:24,144 - Average training time per epoch: 1.349159 seconds over 39 epochs\n",
      "2025-09-30 16:36:24,605 - \n",
      "Inference time: 0.459917 seconds\n",
      "2025-09-30 16:36:24,610 - \n",
      "--- Run 8 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:37:34,437 - Validation loss: 0.00437\n",
      "2025-09-30 16:37:34,438 - Average training time per epoch: 1.365026 seconds over 51 epochs\n",
      "2025-09-30 16:37:35,080 - \n",
      "Inference time: 0.642004 seconds\n",
      "2025-09-30 16:37:35,087 - \n",
      "--- Run 9 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:38:19,666 - Validation loss: 0.00441\n",
      "2025-09-30 16:38:19,667 - Average training time per epoch: 1.431549 seconds over 31 epochs\n",
      "2025-09-30 16:38:20,147 - \n",
      "Inference time: 0.479231 seconds\n",
      "2025-09-30 16:38:20,154 - \n",
      "--- Run 10 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:38:57,280 - Validation loss: 0.00455\n",
      "2025-09-30 16:38:57,281 - Average training time per epoch: 1.477447 seconds over 25 epochs\n",
      "2025-09-30 16:38:57,747 - \n",
      "Inference time: 0.465127 seconds\n",
      "2025-09-30 16:38:57,753 - \n",
      "--- All Metrics Across 10 Runs ---\n",
      "2025-09-30 16:38:57,757 - \n",
      " input_len  run_num  pre_step  MAE_test  RMSE_test  MAPE (%)_test\n",
      "        48        1         1 18.588132  24.298416      17.161003\n",
      "        48        1         2 21.605278  28.444083      20.400965\n",
      "        48        1         3 24.074460  30.519764      22.243052\n",
      "        48        1         4 24.865521  31.552808      23.495381\n",
      "        48        1         5 26.291608  34.689079      22.107090\n",
      "        48        1         6 26.178777  34.776923      22.415600\n",
      "        48        2         1 19.878044  25.718198      17.289780\n",
      "        48        2         2 23.458186  31.439169      20.881432\n",
      "        48        2         3 25.374574  33.069529      22.582857\n",
      "        48        2         4 27.811265  36.311557      24.807337\n",
      "        48        2         5 27.726038  36.413021      24.857487\n",
      "        48        2         6 27.184252  36.402329      24.369962\n",
      "        48        3         1 19.744920  25.097798      18.059557\n",
      "        48        3         2 21.246492  28.044038      19.908304\n",
      "        48        3         3 24.331120  31.249816      22.564923\n",
      "        48        3         4 25.295913  32.668428      23.183514\n",
      "        48        3         5 25.744297  32.955342      23.643118\n",
      "        48        3         6 25.483299  32.697675      24.238634\n",
      "        48        4         1 19.182029  24.212106      18.894736\n",
      "        48        4         2 21.969401  28.842723      19.714017\n",
      "        48        4         3 25.403836  31.564264      23.346923\n",
      "        48        4         4 25.799912  32.729473      23.311564\n",
      "        48        4         5 25.980892  33.601462      22.960156\n",
      "        48        4         6 25.741944  33.918698      22.888905\n",
      "        48        5         1 20.097473  25.846657      18.055414\n",
      "        48        5         2 22.781589  30.177546      20.160950\n",
      "        48        5         3 24.991085  32.842062      22.067811\n",
      "        48        5         4 26.696254  34.964231      23.155439\n",
      "        48        5         5 27.840833  36.124513      23.539635\n",
      "        48        5         6 27.305889  35.254805      22.948630\n",
      "        48        6         1 18.897914  23.857178      18.728738\n",
      "        48        6         2 20.408891  27.672981      19.419159\n",
      "        48        6         3 21.554725  28.821799      20.788528\n",
      "        48        6         4 23.372943  30.657744      22.240156\n",
      "        48        6         5 23.875166  31.286470      22.058456\n",
      "        48        6         6 23.919940  31.704105      21.860673\n",
      "        48        7         1 23.426075  29.868206      19.393173\n",
      "        48        7         2 27.329642  35.545186      23.468841\n",
      "        48        7         3 27.818318  36.233259      23.290751\n",
      "        48        7         4 28.973101  37.936474      24.139616\n",
      "        48        7         5 30.332161  39.408973      25.037390\n",
      "        48        7         6 29.920356  38.625695      24.711730\n",
      "        48        8         1 19.743079  25.812502      17.600091\n",
      "        48        8         2 27.026692  35.117994      23.087902\n",
      "        48        8         3 30.532140  38.967716      26.245234\n",
      "        48        8         4 29.692281  37.988821      25.471243\n",
      "        48        8         5 28.466697  36.184676      24.799405\n",
      "        48        8         6 30.021336  38.018980      25.739105\n",
      "        48        9         1 20.254396  26.379473      17.907540\n",
      "        48        9         2 23.445141  31.422290      20.220574\n",
      "        48        9         3 26.028744  34.272932      22.712319\n",
      "        48        9         4 29.832917  38.524825      25.938884\n",
      "        48        9         5 29.749091  38.155311      25.953814\n",
      "        48        9         6 30.386814  39.573217      26.557305\n",
      "        48       10         1 21.337494  27.615058      18.316161\n",
      "        48       10         2 22.780766  30.205017      20.441532\n",
      "        48       10         3 25.523780  33.189514      22.254549\n",
      "        48       10         4 25.871048  33.602285      22.917868\n",
      "        48       10         5 26.963345  35.546585      23.139426\n",
      "        48       10         6 27.043761  35.716350      23.562958\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_len</th>\n",
       "      <th>run_num</th>\n",
       "      <th>pre_step</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.588132</td>\n",
       "      <td>24.298416</td>\n",
       "      <td>17.161003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>21.605278</td>\n",
       "      <td>28.444083</td>\n",
       "      <td>20.400965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>24.074460</td>\n",
       "      <td>30.519764</td>\n",
       "      <td>22.243052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>24.865521</td>\n",
       "      <td>31.552808</td>\n",
       "      <td>23.495381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>26.291608</td>\n",
       "      <td>34.689079</td>\n",
       "      <td>22.107090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>26.178777</td>\n",
       "      <td>34.776923</td>\n",
       "      <td>22.415600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19.878044</td>\n",
       "      <td>25.718198</td>\n",
       "      <td>17.289780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23.458186</td>\n",
       "      <td>31.439169</td>\n",
       "      <td>20.881432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>25.374574</td>\n",
       "      <td>33.069529</td>\n",
       "      <td>22.582857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>27.811265</td>\n",
       "      <td>36.311557</td>\n",
       "      <td>24.807337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>27.726038</td>\n",
       "      <td>36.413021</td>\n",
       "      <td>24.857487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>27.184252</td>\n",
       "      <td>36.402329</td>\n",
       "      <td>24.369962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19.744920</td>\n",
       "      <td>25.097798</td>\n",
       "      <td>18.059557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>21.246492</td>\n",
       "      <td>28.044038</td>\n",
       "      <td>19.908304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>24.331120</td>\n",
       "      <td>31.249816</td>\n",
       "      <td>22.564923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>25.295913</td>\n",
       "      <td>32.668428</td>\n",
       "      <td>23.183514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>25.744297</td>\n",
       "      <td>32.955342</td>\n",
       "      <td>23.643118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>25.483299</td>\n",
       "      <td>32.697675</td>\n",
       "      <td>24.238634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>19.182029</td>\n",
       "      <td>24.212106</td>\n",
       "      <td>18.894736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>21.969401</td>\n",
       "      <td>28.842723</td>\n",
       "      <td>19.714017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>25.403836</td>\n",
       "      <td>31.564264</td>\n",
       "      <td>23.346923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>25.799912</td>\n",
       "      <td>32.729473</td>\n",
       "      <td>23.311564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>25.980892</td>\n",
       "      <td>33.601462</td>\n",
       "      <td>22.960156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>25.741944</td>\n",
       "      <td>33.918698</td>\n",
       "      <td>22.888905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>20.097473</td>\n",
       "      <td>25.846657</td>\n",
       "      <td>18.055414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>22.781589</td>\n",
       "      <td>30.177546</td>\n",
       "      <td>20.160950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>24.991085</td>\n",
       "      <td>32.842062</td>\n",
       "      <td>22.067811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>26.696254</td>\n",
       "      <td>34.964231</td>\n",
       "      <td>23.155439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>27.840833</td>\n",
       "      <td>36.124513</td>\n",
       "      <td>23.539635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>27.305889</td>\n",
       "      <td>35.254805</td>\n",
       "      <td>22.948630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>48</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>18.897914</td>\n",
       "      <td>23.857178</td>\n",
       "      <td>18.728738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>48</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>20.408891</td>\n",
       "      <td>27.672981</td>\n",
       "      <td>19.419159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>48</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>21.554725</td>\n",
       "      <td>28.821799</td>\n",
       "      <td>20.788528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>48</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>23.372943</td>\n",
       "      <td>30.657744</td>\n",
       "      <td>22.240156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>48</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>23.875166</td>\n",
       "      <td>31.286470</td>\n",
       "      <td>22.058456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>48</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>23.919940</td>\n",
       "      <td>31.704105</td>\n",
       "      <td>21.860673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>23.426075</td>\n",
       "      <td>29.868206</td>\n",
       "      <td>19.393173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>27.329642</td>\n",
       "      <td>35.545186</td>\n",
       "      <td>23.468841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>27.818318</td>\n",
       "      <td>36.233259</td>\n",
       "      <td>23.290751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>28.973101</td>\n",
       "      <td>37.936474</td>\n",
       "      <td>24.139616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>30.332161</td>\n",
       "      <td>39.408973</td>\n",
       "      <td>25.037390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>29.920356</td>\n",
       "      <td>38.625695</td>\n",
       "      <td>24.711730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>48</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>19.743079</td>\n",
       "      <td>25.812502</td>\n",
       "      <td>17.600091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>48</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>27.026692</td>\n",
       "      <td>35.117994</td>\n",
       "      <td>23.087902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>48</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>30.532140</td>\n",
       "      <td>38.967716</td>\n",
       "      <td>26.245234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>48</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>29.692281</td>\n",
       "      <td>37.988821</td>\n",
       "      <td>25.471243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>48</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>28.466697</td>\n",
       "      <td>36.184676</td>\n",
       "      <td>24.799405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>30.021336</td>\n",
       "      <td>38.018980</td>\n",
       "      <td>25.739105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>20.254396</td>\n",
       "      <td>26.379473</td>\n",
       "      <td>17.907540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>48</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>23.445141</td>\n",
       "      <td>31.422290</td>\n",
       "      <td>20.220574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>48</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>26.028744</td>\n",
       "      <td>34.272932</td>\n",
       "      <td>22.712319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>48</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>29.832917</td>\n",
       "      <td>38.524825</td>\n",
       "      <td>25.938884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>48</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>29.749091</td>\n",
       "      <td>38.155311</td>\n",
       "      <td>25.953814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>48</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>30.386814</td>\n",
       "      <td>39.573217</td>\n",
       "      <td>26.557305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>48</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>21.337494</td>\n",
       "      <td>27.615058</td>\n",
       "      <td>18.316161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>48</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>22.780766</td>\n",
       "      <td>30.205017</td>\n",
       "      <td>20.441532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>48</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>25.523780</td>\n",
       "      <td>33.189514</td>\n",
       "      <td>22.254549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>48</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>25.871048</td>\n",
       "      <td>33.602285</td>\n",
       "      <td>22.917868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>48</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>26.963345</td>\n",
       "      <td>35.546585</td>\n",
       "      <td>23.139426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>48</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>27.043761</td>\n",
       "      <td>35.716350</td>\n",
       "      <td>23.562958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    input_len  run_num  pre_step   MAE_test  RMSE_test  MAPE (%)_test\n",
       "0          48        1         1  18.588132  24.298416      17.161003\n",
       "1          48        1         2  21.605278  28.444083      20.400965\n",
       "2          48        1         3  24.074460  30.519764      22.243052\n",
       "3          48        1         4  24.865521  31.552808      23.495381\n",
       "4          48        1         5  26.291608  34.689079      22.107090\n",
       "5          48        1         6  26.178777  34.776923      22.415600\n",
       "6          48        2         1  19.878044  25.718198      17.289780\n",
       "7          48        2         2  23.458186  31.439169      20.881432\n",
       "8          48        2         3  25.374574  33.069529      22.582857\n",
       "9          48        2         4  27.811265  36.311557      24.807337\n",
       "10         48        2         5  27.726038  36.413021      24.857487\n",
       "11         48        2         6  27.184252  36.402329      24.369962\n",
       "12         48        3         1  19.744920  25.097798      18.059557\n",
       "13         48        3         2  21.246492  28.044038      19.908304\n",
       "14         48        3         3  24.331120  31.249816      22.564923\n",
       "15         48        3         4  25.295913  32.668428      23.183514\n",
       "16         48        3         5  25.744297  32.955342      23.643118\n",
       "17         48        3         6  25.483299  32.697675      24.238634\n",
       "18         48        4         1  19.182029  24.212106      18.894736\n",
       "19         48        4         2  21.969401  28.842723      19.714017\n",
       "20         48        4         3  25.403836  31.564264      23.346923\n",
       "21         48        4         4  25.799912  32.729473      23.311564\n",
       "22         48        4         5  25.980892  33.601462      22.960156\n",
       "23         48        4         6  25.741944  33.918698      22.888905\n",
       "24         48        5         1  20.097473  25.846657      18.055414\n",
       "25         48        5         2  22.781589  30.177546      20.160950\n",
       "26         48        5         3  24.991085  32.842062      22.067811\n",
       "27         48        5         4  26.696254  34.964231      23.155439\n",
       "28         48        5         5  27.840833  36.124513      23.539635\n",
       "29         48        5         6  27.305889  35.254805      22.948630\n",
       "30         48        6         1  18.897914  23.857178      18.728738\n",
       "31         48        6         2  20.408891  27.672981      19.419159\n",
       "32         48        6         3  21.554725  28.821799      20.788528\n",
       "33         48        6         4  23.372943  30.657744      22.240156\n",
       "34         48        6         5  23.875166  31.286470      22.058456\n",
       "35         48        6         6  23.919940  31.704105      21.860673\n",
       "36         48        7         1  23.426075  29.868206      19.393173\n",
       "37         48        7         2  27.329642  35.545186      23.468841\n",
       "38         48        7         3  27.818318  36.233259      23.290751\n",
       "39         48        7         4  28.973101  37.936474      24.139616\n",
       "40         48        7         5  30.332161  39.408973      25.037390\n",
       "41         48        7         6  29.920356  38.625695      24.711730\n",
       "42         48        8         1  19.743079  25.812502      17.600091\n",
       "43         48        8         2  27.026692  35.117994      23.087902\n",
       "44         48        8         3  30.532140  38.967716      26.245234\n",
       "45         48        8         4  29.692281  37.988821      25.471243\n",
       "46         48        8         5  28.466697  36.184676      24.799405\n",
       "47         48        8         6  30.021336  38.018980      25.739105\n",
       "48         48        9         1  20.254396  26.379473      17.907540\n",
       "49         48        9         2  23.445141  31.422290      20.220574\n",
       "50         48        9         3  26.028744  34.272932      22.712319\n",
       "51         48        9         4  29.832917  38.524825      25.938884\n",
       "52         48        9         5  29.749091  38.155311      25.953814\n",
       "53         48        9         6  30.386814  39.573217      26.557305\n",
       "54         48       10         1  21.337494  27.615058      18.316161\n",
       "55         48       10         2  22.780766  30.205017      20.441532\n",
       "56         48       10         3  25.523780  33.189514      22.254549\n",
       "57         48       10         4  25.871048  33.602285      22.917868\n",
       "58         48       10         5  26.963345  35.546585      23.139426\n",
       "59         48       10         6  27.043761  35.716350      23.562958"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:38:57,765 - 72\n",
      "2025-09-30 16:38:57,766 - \n",
      "--- Run 1 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:40:50,811 - Validation loss: 0.00477\n",
      "2025-09-30 16:40:50,812 - Average training time per epoch: 3.133915 seconds over 36 epochs\n",
      "2025-09-30 16:40:51,538 - \n",
      "Inference time: 0.724933 seconds\n",
      "2025-09-30 16:40:51,544 - \n",
      "--- Run 2 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:42:30,226 - Validation loss: 0.00434\n",
      "2025-09-30 16:42:30,227 - Average training time per epoch: 3.175582 seconds over 31 epochs\n",
      "2025-09-30 16:42:30,851 - \n",
      "Inference time: 0.622684 seconds\n",
      "2025-09-30 16:42:30,857 - \n",
      "--- Run 3 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:44:31,739 - Validation loss: 0.00442\n",
      "2025-09-30 16:44:31,740 - Average training time per epoch: 3.094385 seconds over 39 epochs\n",
      "2025-09-30 16:44:32,272 - \n",
      "Inference time: 0.531386 seconds\n",
      "2025-09-30 16:44:32,280 - \n",
      "--- Run 4 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:46:34,544 - Validation loss: 0.00438\n",
      "2025-09-30 16:46:34,545 - Average training time per epoch: 3.211527 seconds over 38 epochs\n",
      "2025-09-30 16:46:35,343 - \n",
      "Inference time: 0.797190 seconds\n",
      "2025-09-30 16:46:35,351 - \n",
      "--- Run 5 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:48:47,315 - Validation loss: 0.00441\n",
      "2025-09-30 16:48:47,316 - Average training time per epoch: 3.212914 seconds over 41 epochs\n",
      "2025-09-30 16:48:47,929 - \n",
      "Inference time: 0.612019 seconds\n",
      "2025-09-30 16:48:47,940 - \n",
      "--- Run 6 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:50:57,951 - Validation loss: 0.00441\n",
      "2025-09-30 16:50:57,952 - Average training time per epoch: 3.165489 seconds over 41 epochs\n",
      "2025-09-30 16:50:58,470 - \n",
      "Inference time: 0.517914 seconds\n",
      "2025-09-30 16:50:58,475 - \n",
      "--- Run 7 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:52:30,770 - Validation loss: 0.00466\n",
      "2025-09-30 16:52:30,771 - Average training time per epoch: 3.175871 seconds over 29 epochs\n",
      "2025-09-30 16:52:31,337 - \n",
      "Inference time: 0.565825 seconds\n",
      "2025-09-30 16:52:31,344 - \n",
      "--- Run 8 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:53:56,635 - Validation loss: 0.00448\n",
      "2025-09-30 16:53:56,636 - Average training time per epoch: 3.151409 seconds over 27 epochs\n",
      "2025-09-30 16:53:57,329 - \n",
      "Inference time: 0.691647 seconds\n",
      "2025-09-30 16:53:57,335 - \n",
      "--- Run 9 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:55:40,362 - Validation loss: 0.00445\n",
      "2025-09-30 16:55:40,363 - Average training time per epoch: 3.115716 seconds over 33 epochs\n",
      "2025-09-30 16:55:40,926 - \n",
      "Inference time: 0.562488 seconds\n",
      "2025-09-30 16:55:40,933 - \n",
      "--- Run 10 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:57:03,942 - Validation loss: 0.00457\n",
      "2025-09-30 16:57:03,943 - Average training time per epoch: 3.066726 seconds over 27 epochs\n",
      "2025-09-30 16:57:04,479 - \n",
      "Inference time: 0.535323 seconds\n",
      "2025-09-30 16:57:04,485 - \n",
      "--- All Metrics Across 10 Runs ---\n",
      "2025-09-30 16:57:04,488 - \n",
      " input_len  run_num  pre_step  MAE_test  RMSE_test  MAPE (%)_test\n",
      "        72        1         1 24.650846  31.040155      20.077780\n",
      "        72        1         2 25.719442  33.547535      21.045080\n",
      "        72        1         3 30.098280  38.550256      23.758896\n",
      "        72        1         4 29.304791  37.830798      23.243257\n",
      "        72        1         5 30.992815  39.442860      24.497139\n",
      "        72        1         6 33.650537  42.085128      26.225540\n",
      "        72        2         1 19.114056  24.801817      17.095510\n",
      "        72        2         2 21.465711  28.873439      19.553469\n",
      "        72        2         3 23.307625  30.825531      20.996722\n",
      "        72        2         4 25.600484  33.563955      22.303092\n",
      "        72        2         5 26.622693  34.520655      22.884365\n",
      "        72        2         6 25.005269  32.815099      22.116687\n",
      "        72        3         1 19.327456  24.866441      17.287881\n",
      "        72        3         2 22.839987  30.641564      19.280902\n",
      "        72        3         3 26.448094  34.761276      21.645365\n",
      "        72        3         4 30.606957  39.544141      24.253162\n",
      "        72        3         5 31.248791  39.642751      25.098783\n",
      "        72        3         6 32.215311  40.201182      26.334110\n",
      "        72        4         1 20.997831  27.020231      18.168167\n",
      "        72        4         2 24.192170  32.202886      20.939534\n",
      "        72        4         3 25.334457  33.355840      21.084337\n",
      "        72        4         4 26.109387  34.439737      22.180242\n",
      "        72        4         5 27.262531  35.927664      22.865018\n",
      "        72        4         6 30.838799  39.678625      25.675262\n",
      "        72        5         1 19.496125  25.099817      18.055455\n",
      "        72        5         2 24.005215  31.556404      20.869408\n",
      "        72        5         3 26.716670  34.491315      22.401226\n",
      "        72        5         4 29.837563  37.880361      24.641646\n",
      "        72        5         5 29.003938  36.732719      24.032929\n",
      "        72        5         6 29.716000  37.800930      24.673637\n",
      "        72        6         1 19.072884  24.959942      16.373411\n",
      "        72        6         2 23.793464  31.717922      20.291613\n",
      "        72        6         3 27.447740  35.335509      23.284490\n",
      "        72        6         4 28.981423  37.140872      24.795868\n",
      "        72        6         5 30.272352  38.395947      25.739384\n",
      "        72        6         6 31.435298  39.704008      26.859601\n",
      "        72        7         1 18.567812  23.997067      16.915869\n",
      "        72        7         2 22.256824  28.613722      20.866334\n",
      "        72        7         3 24.185198  30.536013      22.035416\n",
      "        72        7         4 25.847597  33.549229      22.447154\n",
      "        72        7         5 26.081153  33.174428      23.902457\n",
      "        72        7         6 26.258800  34.259006      23.031335\n",
      "        72        8         1 18.760422  24.258182      16.804186\n",
      "        72        8         2 21.518319  29.314611      19.061989\n",
      "        72        8         3 23.898155  31.851609      21.129087\n",
      "        72        8         4 25.696956  33.636820      22.726208\n",
      "        72        8         5 26.380435  34.028351      23.407230\n",
      "        72        8         6 25.839496  33.518208      23.216220\n",
      "        72        9         1 20.008798  26.064912      16.898708\n",
      "        72        9         2 26.868187  34.478559      22.492769\n",
      "        72        9         3 29.847886  37.651852      24.914981\n",
      "        72        9         4 30.953570  39.375132      25.387291\n",
      "        72        9         5 32.597866  40.443898      26.982512\n",
      "        72        9         6 34.405398  42.214158      28.454246\n",
      "        72       10         1 20.078826  26.380840      16.834920\n",
      "        72       10         2 22.608826  30.558948      19.335665\n",
      "        72       10         3 23.813453  31.888206      20.531670\n",
      "        72       10         4 24.663320  32.785935      21.446934\n",
      "        72       10         5 25.896969  35.077835      21.862141\n",
      "        72       10         6 28.336653  37.861805      22.978808\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_len</th>\n",
       "      <th>run_num</th>\n",
       "      <th>pre_step</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24.650846</td>\n",
       "      <td>31.040155</td>\n",
       "      <td>20.077780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25.719442</td>\n",
       "      <td>33.547535</td>\n",
       "      <td>21.045080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>30.098280</td>\n",
       "      <td>38.550256</td>\n",
       "      <td>23.758896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>29.304791</td>\n",
       "      <td>37.830798</td>\n",
       "      <td>23.243257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>30.992815</td>\n",
       "      <td>39.442860</td>\n",
       "      <td>24.497139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>33.650537</td>\n",
       "      <td>42.085128</td>\n",
       "      <td>26.225540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19.114056</td>\n",
       "      <td>24.801817</td>\n",
       "      <td>17.095510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>21.465711</td>\n",
       "      <td>28.873439</td>\n",
       "      <td>19.553469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>23.307625</td>\n",
       "      <td>30.825531</td>\n",
       "      <td>20.996722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>25.600484</td>\n",
       "      <td>33.563955</td>\n",
       "      <td>22.303092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>26.622693</td>\n",
       "      <td>34.520655</td>\n",
       "      <td>22.884365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>25.005269</td>\n",
       "      <td>32.815099</td>\n",
       "      <td>22.116687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>72</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19.327456</td>\n",
       "      <td>24.866441</td>\n",
       "      <td>17.287881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>72</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>22.839987</td>\n",
       "      <td>30.641564</td>\n",
       "      <td>19.280902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>72</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>26.448094</td>\n",
       "      <td>34.761276</td>\n",
       "      <td>21.645365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>72</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>30.606957</td>\n",
       "      <td>39.544141</td>\n",
       "      <td>24.253162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>72</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>31.248791</td>\n",
       "      <td>39.642751</td>\n",
       "      <td>25.098783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>72</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>32.215311</td>\n",
       "      <td>40.201182</td>\n",
       "      <td>26.334110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>72</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>20.997831</td>\n",
       "      <td>27.020231</td>\n",
       "      <td>18.168167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>72</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>24.192170</td>\n",
       "      <td>32.202886</td>\n",
       "      <td>20.939534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>72</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>25.334457</td>\n",
       "      <td>33.355840</td>\n",
       "      <td>21.084337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>72</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>26.109387</td>\n",
       "      <td>34.439737</td>\n",
       "      <td>22.180242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>72</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>27.262531</td>\n",
       "      <td>35.927664</td>\n",
       "      <td>22.865018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>72</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>30.838799</td>\n",
       "      <td>39.678625</td>\n",
       "      <td>25.675262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>72</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>19.496125</td>\n",
       "      <td>25.099817</td>\n",
       "      <td>18.055455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>72</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>24.005215</td>\n",
       "      <td>31.556404</td>\n",
       "      <td>20.869408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>72</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>26.716670</td>\n",
       "      <td>34.491315</td>\n",
       "      <td>22.401226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>72</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>29.837563</td>\n",
       "      <td>37.880361</td>\n",
       "      <td>24.641646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>72</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>29.003938</td>\n",
       "      <td>36.732719</td>\n",
       "      <td>24.032929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>72</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>29.716000</td>\n",
       "      <td>37.800930</td>\n",
       "      <td>24.673637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>72</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>19.072884</td>\n",
       "      <td>24.959942</td>\n",
       "      <td>16.373411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>72</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>23.793464</td>\n",
       "      <td>31.717922</td>\n",
       "      <td>20.291613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>72</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>27.447740</td>\n",
       "      <td>35.335509</td>\n",
       "      <td>23.284490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>72</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>28.981423</td>\n",
       "      <td>37.140872</td>\n",
       "      <td>24.795868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>72</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>30.272352</td>\n",
       "      <td>38.395947</td>\n",
       "      <td>25.739384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>72</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>31.435298</td>\n",
       "      <td>39.704008</td>\n",
       "      <td>26.859601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>72</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>18.567812</td>\n",
       "      <td>23.997067</td>\n",
       "      <td>16.915869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>72</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>22.256824</td>\n",
       "      <td>28.613722</td>\n",
       "      <td>20.866334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>72</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>24.185198</td>\n",
       "      <td>30.536013</td>\n",
       "      <td>22.035416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>72</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>25.847597</td>\n",
       "      <td>33.549229</td>\n",
       "      <td>22.447154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>72</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>26.081153</td>\n",
       "      <td>33.174428</td>\n",
       "      <td>23.902457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>72</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>26.258800</td>\n",
       "      <td>34.259006</td>\n",
       "      <td>23.031335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>72</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>18.760422</td>\n",
       "      <td>24.258182</td>\n",
       "      <td>16.804186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>72</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>21.518319</td>\n",
       "      <td>29.314611</td>\n",
       "      <td>19.061989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>72</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>23.898155</td>\n",
       "      <td>31.851609</td>\n",
       "      <td>21.129087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>72</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>25.696956</td>\n",
       "      <td>33.636820</td>\n",
       "      <td>22.726208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>72</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>26.380435</td>\n",
       "      <td>34.028351</td>\n",
       "      <td>23.407230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>72</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>25.839496</td>\n",
       "      <td>33.518208</td>\n",
       "      <td>23.216220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>72</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>20.008798</td>\n",
       "      <td>26.064912</td>\n",
       "      <td>16.898708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>72</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>26.868187</td>\n",
       "      <td>34.478559</td>\n",
       "      <td>22.492769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>72</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>29.847886</td>\n",
       "      <td>37.651852</td>\n",
       "      <td>24.914981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>72</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>30.953570</td>\n",
       "      <td>39.375132</td>\n",
       "      <td>25.387291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>72</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>32.597866</td>\n",
       "      <td>40.443898</td>\n",
       "      <td>26.982512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>72</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>34.405398</td>\n",
       "      <td>42.214158</td>\n",
       "      <td>28.454246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>72</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>20.078826</td>\n",
       "      <td>26.380840</td>\n",
       "      <td>16.834920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>72</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>22.608826</td>\n",
       "      <td>30.558948</td>\n",
       "      <td>19.335665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>72</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>23.813453</td>\n",
       "      <td>31.888206</td>\n",
       "      <td>20.531670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>72</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>24.663320</td>\n",
       "      <td>32.785935</td>\n",
       "      <td>21.446934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>72</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>25.896969</td>\n",
       "      <td>35.077835</td>\n",
       "      <td>21.862141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>72</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>28.336653</td>\n",
       "      <td>37.861805</td>\n",
       "      <td>22.978808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    input_len  run_num  pre_step   MAE_test  RMSE_test  MAPE (%)_test\n",
       "0          72        1         1  24.650846  31.040155      20.077780\n",
       "1          72        1         2  25.719442  33.547535      21.045080\n",
       "2          72        1         3  30.098280  38.550256      23.758896\n",
       "3          72        1         4  29.304791  37.830798      23.243257\n",
       "4          72        1         5  30.992815  39.442860      24.497139\n",
       "5          72        1         6  33.650537  42.085128      26.225540\n",
       "6          72        2         1  19.114056  24.801817      17.095510\n",
       "7          72        2         2  21.465711  28.873439      19.553469\n",
       "8          72        2         3  23.307625  30.825531      20.996722\n",
       "9          72        2         4  25.600484  33.563955      22.303092\n",
       "10         72        2         5  26.622693  34.520655      22.884365\n",
       "11         72        2         6  25.005269  32.815099      22.116687\n",
       "12         72        3         1  19.327456  24.866441      17.287881\n",
       "13         72        3         2  22.839987  30.641564      19.280902\n",
       "14         72        3         3  26.448094  34.761276      21.645365\n",
       "15         72        3         4  30.606957  39.544141      24.253162\n",
       "16         72        3         5  31.248791  39.642751      25.098783\n",
       "17         72        3         6  32.215311  40.201182      26.334110\n",
       "18         72        4         1  20.997831  27.020231      18.168167\n",
       "19         72        4         2  24.192170  32.202886      20.939534\n",
       "20         72        4         3  25.334457  33.355840      21.084337\n",
       "21         72        4         4  26.109387  34.439737      22.180242\n",
       "22         72        4         5  27.262531  35.927664      22.865018\n",
       "23         72        4         6  30.838799  39.678625      25.675262\n",
       "24         72        5         1  19.496125  25.099817      18.055455\n",
       "25         72        5         2  24.005215  31.556404      20.869408\n",
       "26         72        5         3  26.716670  34.491315      22.401226\n",
       "27         72        5         4  29.837563  37.880361      24.641646\n",
       "28         72        5         5  29.003938  36.732719      24.032929\n",
       "29         72        5         6  29.716000  37.800930      24.673637\n",
       "30         72        6         1  19.072884  24.959942      16.373411\n",
       "31         72        6         2  23.793464  31.717922      20.291613\n",
       "32         72        6         3  27.447740  35.335509      23.284490\n",
       "33         72        6         4  28.981423  37.140872      24.795868\n",
       "34         72        6         5  30.272352  38.395947      25.739384\n",
       "35         72        6         6  31.435298  39.704008      26.859601\n",
       "36         72        7         1  18.567812  23.997067      16.915869\n",
       "37         72        7         2  22.256824  28.613722      20.866334\n",
       "38         72        7         3  24.185198  30.536013      22.035416\n",
       "39         72        7         4  25.847597  33.549229      22.447154\n",
       "40         72        7         5  26.081153  33.174428      23.902457\n",
       "41         72        7         6  26.258800  34.259006      23.031335\n",
       "42         72        8         1  18.760422  24.258182      16.804186\n",
       "43         72        8         2  21.518319  29.314611      19.061989\n",
       "44         72        8         3  23.898155  31.851609      21.129087\n",
       "45         72        8         4  25.696956  33.636820      22.726208\n",
       "46         72        8         5  26.380435  34.028351      23.407230\n",
       "47         72        8         6  25.839496  33.518208      23.216220\n",
       "48         72        9         1  20.008798  26.064912      16.898708\n",
       "49         72        9         2  26.868187  34.478559      22.492769\n",
       "50         72        9         3  29.847886  37.651852      24.914981\n",
       "51         72        9         4  30.953570  39.375132      25.387291\n",
       "52         72        9         5  32.597866  40.443898      26.982512\n",
       "53         72        9         6  34.405398  42.214158      28.454246\n",
       "54         72       10         1  20.078826  26.380840      16.834920\n",
       "55         72       10         2  22.608826  30.558948      19.335665\n",
       "56         72       10         3  23.813453  31.888206      20.531670\n",
       "57         72       10         4  24.663320  32.785935      21.446934\n",
       "58         72       10         5  25.896969  35.077835      21.862141\n",
       "59         72       10         6  28.336653  37.861805      22.978808"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:57:04,496 - 96\n",
      "2025-09-30 16:57:04,497 - \n",
      "--- Run 1 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:58:58,194 - Validation loss: 0.00427\n",
      "2025-09-30 16:58:58,194 - Average training time per epoch: 3.547529 seconds over 32 epochs\n",
      "2025-09-30 16:58:58,828 - \n",
      "Inference time: 0.632719 seconds\n",
      "2025-09-30 16:58:58,833 - \n",
      "--- Run 2 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 17:00:52,629 - Validation loss: 0.00432\n",
      "2025-09-30 17:00:52,630 - Average training time per epoch: 3.442195 seconds over 33 epochs\n",
      "2025-09-30 17:00:53,231 - \n",
      "Inference time: 0.600377 seconds\n",
      "2025-09-30 17:00:53,239 - \n",
      "--- Run 3 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 17:03:38,764 - Validation loss: 0.00435\n",
      "2025-09-30 17:03:38,765 - Average training time per epoch: 3.444240 seconds over 48 epochs\n",
      "2025-09-30 17:03:39,302 - \n",
      "Inference time: 0.534671 seconds\n",
      "2025-09-30 17:03:39,309 - \n",
      "--- Run 4 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 17:05:27,003 - Validation loss: 0.00437\n",
      "2025-09-30 17:05:27,004 - Average training time per epoch: 3.583385 seconds over 30 epochs\n",
      "2025-09-30 17:05:27,686 - \n",
      "Inference time: 0.681531 seconds\n",
      "2025-09-30 17:05:27,692 - \n",
      "--- Run 5 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 17:07:09,554 - Validation loss: 0.00430\n",
      "2025-09-30 17:07:09,559 - Average training time per epoch: 3.506414 seconds over 29 epochs\n",
      "2025-09-30 17:07:10,166 - \n",
      "Inference time: 0.607519 seconds\n",
      "2025-09-30 17:07:10,172 - \n",
      "--- Run 6 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 17:09:23,747 - Validation loss: 0.00428\n",
      "2025-09-30 17:09:23,748 - Average training time per epoch: 3.510057 seconds over 38 epochs\n",
      "2025-09-30 17:09:24,350 - \n",
      "Inference time: 0.601643 seconds\n",
      "2025-09-30 17:09:24,358 - \n",
      "--- Run 7 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 17:11:07,335 - Validation loss: 0.00432\n",
      "2025-09-30 17:11:07,336 - Average training time per epoch: 3.542971 seconds over 29 epochs\n",
      "2025-09-30 17:11:07,866 - \n",
      "Inference time: 0.529145 seconds\n",
      "2025-09-30 17:11:07,872 - \n",
      "--- Run 8 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 17:13:43,572 - Validation loss: 0.00455\n",
      "2025-09-30 17:13:43,573 - Average training time per epoch: 3.615875 seconds over 43 epochs\n",
      "2025-09-30 17:13:44,079 - \n",
      "Inference time: 0.505679 seconds\n",
      "2025-09-30 17:13:44,084 - \n",
      "--- Run 9 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 17:16:05,732 - Validation loss: 0.00445\n",
      "2025-09-30 17:16:05,733 - Average training time per epoch: 3.536310 seconds over 40 epochs\n",
      "2025-09-30 17:16:06,382 - \n",
      "Inference time: 0.649016 seconds\n",
      "2025-09-30 17:16:06,390 - \n",
      "--- Run 10 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 17:17:32,877 - Validation loss: 0.00449\n",
      "2025-09-30 17:17:32,877 - Average training time per epoch: 3.595508 seconds over 24 epochs\n",
      "2025-09-30 17:17:34,388 - \n",
      "Inference time: 1.509739 seconds\n",
      "2025-09-30 17:17:34,394 - \n",
      "--- All Metrics Across 10 Runs ---\n",
      "2025-09-30 17:17:34,398 - \n",
      " input_len  run_num  pre_step  MAE_test  RMSE_test  MAPE (%)_test\n",
      "        96        1         1 20.514355  26.288985      17.987859\n",
      "        96        1         2 21.981191  29.509111      19.713554\n",
      "        96        1         3 25.327860  32.853298      22.679759\n",
      "        96        1         4 27.682612  35.177938      24.639324\n",
      "        96        1         5 33.485048  41.304660      28.663662\n",
      "        96        1         6 32.585927  40.599515      28.295584\n",
      "        96        2         1 20.013543  25.632786      17.589213\n",
      "        96        2         2 21.889950  29.177429      19.352413\n",
      "        96        2         3 22.850120  30.282651      20.188573\n",
      "        96        2         4 26.452132  34.278464      22.217018\n",
      "        96        2         5 30.639145  38.790670      25.473843\n",
      "        96        2         6 28.394873  36.577558      23.456830\n",
      "        96        3         1 22.287558  29.070468      18.260979\n",
      "        96        3         2 26.531070  34.869231      21.670351\n",
      "        96        3         3 30.140272  38.847376      24.936284\n",
      "        96        3         4 30.342810  39.667646      25.800886\n",
      "        96        3         5 29.403433  37.807789      25.604248\n",
      "        96        3         6 29.384892  37.494445      25.342177\n",
      "        96        4         1 19.947212  25.564605      17.237568\n",
      "        96        4         2 22.659377  30.204282      19.509372\n",
      "        96        4         3 24.563249  32.420664      21.271520\n",
      "        96        4         4 26.069522  34.539000      22.562191\n",
      "        96        4         5 26.188515  34.868357      22.398880\n",
      "        96        4         6 28.034949  37.299326      23.545883\n",
      "        96        5         1 19.518641  25.341789      16.419265\n",
      "        96        5         2 22.132634  30.088952      18.659113\n",
      "        96        5         3 25.621651  33.568330      21.300502\n",
      "        96        5         4 26.799518  34.942940      22.301829\n",
      "        96        5         5 26.709200  34.388564      22.787808\n",
      "        96        5         6 27.912153  35.985262      23.777522\n",
      "        96        6         1 19.920134  25.962552      17.205554\n",
      "        96        6         2 21.321906  28.801109      18.921180\n",
      "        96        6         3 25.674615  33.471696      21.767524\n",
      "        96        6         4 25.761358  33.626542      22.123378\n",
      "        96        6         5 29.213638  37.440546      24.383701\n",
      "        96        6         6 28.132135  36.488477      23.528369\n",
      "        96        7         1 20.209995  25.845123      17.595759\n",
      "        96        7         2 22.448062  29.892184      19.346054\n",
      "        96        7         3 22.467018  29.783349      19.742476\n",
      "        96        7         4 24.843639  32.571167      21.562683\n",
      "        96        7         5 25.361214  33.479676      21.641631\n",
      "        96        7         6 28.008823  36.952012      23.473838\n",
      "        96        8         1 19.863513  25.483253      17.022163\n",
      "        96        8         2 22.802758  30.110585      19.801901\n",
      "        96        8         3 24.703390  32.477397      21.352309\n",
      "        96        8         4 26.736604  34.682556      22.924851\n",
      "        96        8         5 28.138472  36.279751      23.987269\n",
      "        96        8         6 28.024891  36.085294      24.800367\n",
      "        96        9         1 19.282825  25.396664      16.073829\n",
      "        96        9         2 22.843756  30.678056      18.998389\n",
      "        96        9         3 26.700038  34.619299      22.350827\n",
      "        96        9         4 28.928268  37.358005      24.232430\n",
      "        96        9         5 29.784755  38.844373      24.855236\n",
      "        96        9         6 28.521572  37.328363      24.097477\n",
      "        96       10         1 18.547236  24.053596      17.197217\n",
      "        96       10         2 21.987046  28.660352      20.469623\n",
      "        96       10         3 23.374102  30.424055      21.497801\n",
      "        96       10         4 24.033537  30.928684      22.915854\n",
      "        96       10         5 24.088128  31.574349      22.383611\n",
      "        96       10         6 24.039440  32.046453      22.028078\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_len</th>\n",
       "      <th>run_num</th>\n",
       "      <th>pre_step</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.514355</td>\n",
       "      <td>26.288985</td>\n",
       "      <td>17.987859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>21.981191</td>\n",
       "      <td>29.509111</td>\n",
       "      <td>19.713554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>25.327860</td>\n",
       "      <td>32.853298</td>\n",
       "      <td>22.679759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>27.682612</td>\n",
       "      <td>35.177938</td>\n",
       "      <td>24.639324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>33.485048</td>\n",
       "      <td>41.304660</td>\n",
       "      <td>28.663662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>32.585927</td>\n",
       "      <td>40.599515</td>\n",
       "      <td>28.295584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20.013543</td>\n",
       "      <td>25.632786</td>\n",
       "      <td>17.589213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>21.889950</td>\n",
       "      <td>29.177429</td>\n",
       "      <td>19.352413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>22.850120</td>\n",
       "      <td>30.282651</td>\n",
       "      <td>20.188573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>26.452132</td>\n",
       "      <td>34.278464</td>\n",
       "      <td>22.217018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>30.639145</td>\n",
       "      <td>38.790670</td>\n",
       "      <td>25.473843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>28.394873</td>\n",
       "      <td>36.577558</td>\n",
       "      <td>23.456830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>96</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.287558</td>\n",
       "      <td>29.070468</td>\n",
       "      <td>18.260979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>96</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>26.531070</td>\n",
       "      <td>34.869231</td>\n",
       "      <td>21.670351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>96</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>30.140272</td>\n",
       "      <td>38.847376</td>\n",
       "      <td>24.936284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>96</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>30.342810</td>\n",
       "      <td>39.667646</td>\n",
       "      <td>25.800886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>96</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>29.403433</td>\n",
       "      <td>37.807789</td>\n",
       "      <td>25.604248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>96</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>29.384892</td>\n",
       "      <td>37.494445</td>\n",
       "      <td>25.342177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>96</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>19.947212</td>\n",
       "      <td>25.564605</td>\n",
       "      <td>17.237568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>96</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>22.659377</td>\n",
       "      <td>30.204282</td>\n",
       "      <td>19.509372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>96</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>24.563249</td>\n",
       "      <td>32.420664</td>\n",
       "      <td>21.271520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>96</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>26.069522</td>\n",
       "      <td>34.539000</td>\n",
       "      <td>22.562191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>96</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>26.188515</td>\n",
       "      <td>34.868357</td>\n",
       "      <td>22.398880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>96</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>28.034949</td>\n",
       "      <td>37.299326</td>\n",
       "      <td>23.545883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>96</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>19.518641</td>\n",
       "      <td>25.341789</td>\n",
       "      <td>16.419265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>96</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>22.132634</td>\n",
       "      <td>30.088952</td>\n",
       "      <td>18.659113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>96</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>25.621651</td>\n",
       "      <td>33.568330</td>\n",
       "      <td>21.300502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>96</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>26.799518</td>\n",
       "      <td>34.942940</td>\n",
       "      <td>22.301829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>96</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>26.709200</td>\n",
       "      <td>34.388564</td>\n",
       "      <td>22.787808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>96</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>27.912153</td>\n",
       "      <td>35.985262</td>\n",
       "      <td>23.777522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>96</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>19.920134</td>\n",
       "      <td>25.962552</td>\n",
       "      <td>17.205554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>96</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>21.321906</td>\n",
       "      <td>28.801109</td>\n",
       "      <td>18.921180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>96</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>25.674615</td>\n",
       "      <td>33.471696</td>\n",
       "      <td>21.767524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>96</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>25.761358</td>\n",
       "      <td>33.626542</td>\n",
       "      <td>22.123378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>96</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>29.213638</td>\n",
       "      <td>37.440546</td>\n",
       "      <td>24.383701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>96</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>28.132135</td>\n",
       "      <td>36.488477</td>\n",
       "      <td>23.528369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>96</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>20.209995</td>\n",
       "      <td>25.845123</td>\n",
       "      <td>17.595759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>96</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>22.448062</td>\n",
       "      <td>29.892184</td>\n",
       "      <td>19.346054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>96</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>22.467018</td>\n",
       "      <td>29.783349</td>\n",
       "      <td>19.742476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>96</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>24.843639</td>\n",
       "      <td>32.571167</td>\n",
       "      <td>21.562683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>96</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>25.361214</td>\n",
       "      <td>33.479676</td>\n",
       "      <td>21.641631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>96</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>28.008823</td>\n",
       "      <td>36.952012</td>\n",
       "      <td>23.473838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>96</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>19.863513</td>\n",
       "      <td>25.483253</td>\n",
       "      <td>17.022163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>96</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>22.802758</td>\n",
       "      <td>30.110585</td>\n",
       "      <td>19.801901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>96</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>24.703390</td>\n",
       "      <td>32.477397</td>\n",
       "      <td>21.352309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>96</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>26.736604</td>\n",
       "      <td>34.682556</td>\n",
       "      <td>22.924851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>96</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>28.138472</td>\n",
       "      <td>36.279751</td>\n",
       "      <td>23.987269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>96</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>28.024891</td>\n",
       "      <td>36.085294</td>\n",
       "      <td>24.800367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>96</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>19.282825</td>\n",
       "      <td>25.396664</td>\n",
       "      <td>16.073829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>96</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>22.843756</td>\n",
       "      <td>30.678056</td>\n",
       "      <td>18.998389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>96</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>26.700038</td>\n",
       "      <td>34.619299</td>\n",
       "      <td>22.350827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>96</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>28.928268</td>\n",
       "      <td>37.358005</td>\n",
       "      <td>24.232430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>96</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>29.784755</td>\n",
       "      <td>38.844373</td>\n",
       "      <td>24.855236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>96</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>28.521572</td>\n",
       "      <td>37.328363</td>\n",
       "      <td>24.097477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>96</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>18.547236</td>\n",
       "      <td>24.053596</td>\n",
       "      <td>17.197217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>96</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>21.987046</td>\n",
       "      <td>28.660352</td>\n",
       "      <td>20.469623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>96</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>23.374102</td>\n",
       "      <td>30.424055</td>\n",
       "      <td>21.497801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>96</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>24.033537</td>\n",
       "      <td>30.928684</td>\n",
       "      <td>22.915854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>96</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>24.088128</td>\n",
       "      <td>31.574349</td>\n",
       "      <td>22.383611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>96</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>24.039440</td>\n",
       "      <td>32.046453</td>\n",
       "      <td>22.028078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    input_len  run_num  pre_step   MAE_test  RMSE_test  MAPE (%)_test\n",
       "0          96        1         1  20.514355  26.288985      17.987859\n",
       "1          96        1         2  21.981191  29.509111      19.713554\n",
       "2          96        1         3  25.327860  32.853298      22.679759\n",
       "3          96        1         4  27.682612  35.177938      24.639324\n",
       "4          96        1         5  33.485048  41.304660      28.663662\n",
       "5          96        1         6  32.585927  40.599515      28.295584\n",
       "6          96        2         1  20.013543  25.632786      17.589213\n",
       "7          96        2         2  21.889950  29.177429      19.352413\n",
       "8          96        2         3  22.850120  30.282651      20.188573\n",
       "9          96        2         4  26.452132  34.278464      22.217018\n",
       "10         96        2         5  30.639145  38.790670      25.473843\n",
       "11         96        2         6  28.394873  36.577558      23.456830\n",
       "12         96        3         1  22.287558  29.070468      18.260979\n",
       "13         96        3         2  26.531070  34.869231      21.670351\n",
       "14         96        3         3  30.140272  38.847376      24.936284\n",
       "15         96        3         4  30.342810  39.667646      25.800886\n",
       "16         96        3         5  29.403433  37.807789      25.604248\n",
       "17         96        3         6  29.384892  37.494445      25.342177\n",
       "18         96        4         1  19.947212  25.564605      17.237568\n",
       "19         96        4         2  22.659377  30.204282      19.509372\n",
       "20         96        4         3  24.563249  32.420664      21.271520\n",
       "21         96        4         4  26.069522  34.539000      22.562191\n",
       "22         96        4         5  26.188515  34.868357      22.398880\n",
       "23         96        4         6  28.034949  37.299326      23.545883\n",
       "24         96        5         1  19.518641  25.341789      16.419265\n",
       "25         96        5         2  22.132634  30.088952      18.659113\n",
       "26         96        5         3  25.621651  33.568330      21.300502\n",
       "27         96        5         4  26.799518  34.942940      22.301829\n",
       "28         96        5         5  26.709200  34.388564      22.787808\n",
       "29         96        5         6  27.912153  35.985262      23.777522\n",
       "30         96        6         1  19.920134  25.962552      17.205554\n",
       "31         96        6         2  21.321906  28.801109      18.921180\n",
       "32         96        6         3  25.674615  33.471696      21.767524\n",
       "33         96        6         4  25.761358  33.626542      22.123378\n",
       "34         96        6         5  29.213638  37.440546      24.383701\n",
       "35         96        6         6  28.132135  36.488477      23.528369\n",
       "36         96        7         1  20.209995  25.845123      17.595759\n",
       "37         96        7         2  22.448062  29.892184      19.346054\n",
       "38         96        7         3  22.467018  29.783349      19.742476\n",
       "39         96        7         4  24.843639  32.571167      21.562683\n",
       "40         96        7         5  25.361214  33.479676      21.641631\n",
       "41         96        7         6  28.008823  36.952012      23.473838\n",
       "42         96        8         1  19.863513  25.483253      17.022163\n",
       "43         96        8         2  22.802758  30.110585      19.801901\n",
       "44         96        8         3  24.703390  32.477397      21.352309\n",
       "45         96        8         4  26.736604  34.682556      22.924851\n",
       "46         96        8         5  28.138472  36.279751      23.987269\n",
       "47         96        8         6  28.024891  36.085294      24.800367\n",
       "48         96        9         1  19.282825  25.396664      16.073829\n",
       "49         96        9         2  22.843756  30.678056      18.998389\n",
       "50         96        9         3  26.700038  34.619299      22.350827\n",
       "51         96        9         4  28.928268  37.358005      24.232430\n",
       "52         96        9         5  29.784755  38.844373      24.855236\n",
       "53         96        9         6  28.521572  37.328363      24.097477\n",
       "54         96       10         1  18.547236  24.053596      17.197217\n",
       "55         96       10         2  21.987046  28.660352      20.469623\n",
       "56         96       10         3  23.374102  30.424055      21.497801\n",
       "57         96       10         4  24.033537  30.928684      22.915854\n",
       "58         96       10         5  24.088128  31.574349      22.383611\n",
       "59         96       10         6  24.039440  32.046453      22.028078"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 17:17:34,406 - 120\n",
      "2025-09-30 17:17:34,407 - \n",
      "--- Run 1 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 17:21:44,640 - Validation loss: 0.00423\n",
      "2025-09-30 17:21:44,641 - Average training time per epoch: 3.472024 seconds over 72 epochs\n",
      "2025-09-30 17:21:45,274 - \n",
      "Inference time: 0.632729 seconds\n",
      "2025-09-30 17:21:45,283 - \n",
      "--- Run 2 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87: early stopping\n",
      "Restoring model weights from the end of the best epoch: 67.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 17:26:53,247 - Validation loss: 0.00419\n",
      "2025-09-30 17:26:53,249 - Average training time per epoch: 3.536940 seconds over 87 epochs\n",
      "2025-09-30 17:26:53,862 - \n",
      "Inference time: 0.612666 seconds\n",
      "2025-09-30 17:26:53,871 - \n",
      "--- Run 3 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85: early stopping\n",
      "Restoring model weights from the end of the best epoch: 65.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 17:32:00,568 - Validation loss: 0.00412\n",
      "2025-09-30 17:32:00,570 - Average training time per epoch: 3.605540 seconds over 85 epochs\n",
      "2025-09-30 17:32:01,074 - \n",
      "Inference time: 0.502840 seconds\n",
      "2025-09-30 17:32:01,080 - \n",
      "--- Run 4 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88: early stopping\n",
      "Restoring model weights from the end of the best epoch: 68.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 17:37:17,622 - Validation loss: 0.00416\n",
      "2025-09-30 17:37:17,623 - Average training time per epoch: 3.594724 seconds over 88 epochs\n",
      "2025-09-30 17:37:18,277 - \n",
      "Inference time: 0.653352 seconds\n",
      "2025-09-30 17:37:18,282 - \n",
      "--- Run 5 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82: early stopping\n",
      "Restoring model weights from the end of the best epoch: 62.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 17:41:45,724 - Validation loss: 0.00416\n",
      "2025-09-30 17:41:45,725 - Average training time per epoch: 3.258626 seconds over 82 epochs\n",
      "2025-09-30 17:41:46,325 - \n",
      "Inference time: 0.599627 seconds\n",
      "2025-09-30 17:41:46,333 - \n",
      "--- Run 6 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91: early stopping\n",
      "Restoring model weights from the end of the best epoch: 71.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 17:47:24,335 - Validation loss: 0.00417\n",
      "2025-09-30 17:47:24,336 - Average training time per epoch: 3.711487 seconds over 91 epochs\n",
      "2025-09-30 17:47:24,836 - \n",
      "Inference time: 0.499698 seconds\n",
      "2025-09-30 17:47:24,843 - \n",
      "--- Run 7 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 17:51:36,414 - Validation loss: 0.00413\n",
      "2025-09-30 17:51:36,415 - Average training time per epoch: 3.396881 seconds over 74 epochs\n",
      "2025-09-30 17:51:36,957 - \n",
      "Inference time: 0.541605 seconds\n",
      "2025-09-30 17:51:36,970 - \n",
      "--- Run 8 ---\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "all_len_metrics_list=[]\n",
    "for length in best_hyperparameters_improved_model.keys():\n",
    "    logger.info(length)\n",
    "    \n",
    "    # Number of runs\n",
    "    n_runs = 10\n",
    "    \n",
    "    # get the best hyperparameter of each length\n",
    "    hyperparams = best_hyperparameters_improved_model[length] #after covid-19\n",
    "    # hyperparams = best_hyperparameters_cnn[length] #entire data\n",
    "    # Initialize lists to store mean metrics and all metrics from each run\n",
    "    mean_metrics_rows = []\n",
    "    df_each_run_list = []\n",
    "    successful_runs = []  # To track runs with valid mse\n",
    "\n",
    "    for run in range(1, n_runs + 1):\n",
    "        logger.info(f\"\\n--- Run {run} ---\")\n",
    "\n",
    "        # Optionally set a unique seed for each run to ensure variability\n",
    "        seed = run\n",
    "        # Train the model\n",
    "        model, mse, run_training_time = train_model(hyperparams, data_dict, length, seed=seed)\n",
    "        \n",
    "        if not np.isnan(mse):  # Only proceed if mse is valid\n",
    "            successful_runs.append(run)\n",
    "        \n",
    "            X_test = data_dict[length]['X_test']\n",
    "            y_test = data_dict[length]['y_test']\n",
    "\n",
    "            #get the true flow and predicted flow\n",
    "            y_pred_test, y_obs_test, run_inference_time = make_prediction(model, X_test, y_test)\n",
    "\n",
    "            #calculate the evaluation metrics of each output step\n",
    "            df_each_run = evaluation(y_pred_test, y_obs_test).add_suffix('_test')\n",
    "\n",
    "            #add a column to show prediction step\n",
    "            df_each_run.reset_index(inplace=True)  # moves 'Time Step' back to a column\n",
    "            df_each_run.rename(columns={'Time Step': 'pre_step'}, inplace=True)\n",
    "\n",
    "            #add columns of input length and run step\n",
    "            df_each_run.insert(0, \"input_len\", length)\n",
    "            df_each_run.insert(1, \"run_num\", run)\n",
    "\n",
    "            # Append df_each_run to the list\n",
    "            df_each_run_list.append(df_each_run)\n",
    "        else:\n",
    "            logger.info(f\"Run {run} has mse=NaN, skipping.\")\n",
    "            \n",
    "    # Check if there are successful runs before proceeding\n",
    "    if successful_runs:\n",
    "\n",
    "        concatenated_all_runs = pd.concat(df_each_run_list, ignore_index=True)\n",
    "\n",
    "        logger.info(\"\\n--- All Metrics Across 10 Runs ---\")\n",
    "        # Convert DataFrame to string\n",
    "        concatenated_all_runs_str = concatenated_all_runs.to_string(index=False)    \n",
    "        # Log the DataFrame\n",
    "        logger.info(\"\\n\" + concatenated_all_runs_str)\n",
    "        display(concatenated_all_runs)\n",
    "    \n",
    "        all_len_metrics_list.append(concatenated_all_runs)\n",
    "    else:\n",
    "        logger.info(f\"No successful runs for input length {length}.\")\n",
    "\n",
    "all_metrics_df = pd.concat(all_len_metrics_list).reset_index(drop=True)\n",
    "logger.info(\"\\n--- Final Mean Metrics Across 10 Runs ---\")\n",
    "# Convert DataFrame to string\n",
    "all_metrics_df_str = all_metrics_df.to_string(index=False)    \n",
    "# Log the DataFrame\n",
    "logger.info(\"\\n\" + all_metrics_df_str)\n",
    "all_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_df.to_csv(\"all_metrics_lstm_after_covid.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to predict next 6 steps simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will use\n",
    "* the last 12 steps\n",
    "\n",
    "* previous one week (24 steps)\n",
    "\n",
    "* previous one month  (168 steps)\n",
    "\n",
    "*  to forecast current (0 step) and 5 steps ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1141040 into shape (168,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create input-output sequences with the provided function\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_train, y_train, X_train_df, y_train_df \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_multi_step_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_n_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mday_lag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweek_lag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_future_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m X_valid, y_valid, X_valid_df, y_valid_df \u001b[38;5;241m=\u001b[39m create_multi_step_sequence(valid_set, last_n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m7\u001b[39m, day_lag\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, week_lag\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, n_future_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)\n\u001b[0;32m      4\u001b[0m X_test, y_test, X_test_df, y_test_df \u001b[38;5;241m=\u001b[39m create_multi_step_sequence(test_set, last_n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m7\u001b[39m, day_lag\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, week_lag\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, n_future_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)\n",
      "Cell \u001b[1;32mIn[10], line 40\u001b[0m, in \u001b[0;36mcreate_multi_step_sequence\u001b[1;34m(data, last_n_steps, day_lag, week_lag, n_future_steps)\u001b[0m\n\u001b[0;32m     37\u001b[0m         y\u001b[38;5;241m.\u001b[39mappend(output_seq)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Convert to numpy arrays and reshape X to match CNN expected input (samples, timesteps, features)\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_n_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Add the 2 additional features (last_day_value, last_week_value)\u001b[39;00m\n\u001b[0;32m     41\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(y)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, n_future_steps)  \u001b[38;5;66;03m# Multiple output steps\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Convert the entire input and output into a pandas DataFrame with appropriate column names for multi-step prediction\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Define column names for the input DataFrame\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 1141040 into shape (168,1)"
     ]
    }
   ],
   "source": [
    "# Create input-output sequences with the provided function\n",
    "X_train, y_train, X_train_df, y_train_df = create_multi_step_sequence(train_set, last_n_steps=12, day_lag=24, week_lag=168, n_future_steps=6)\n",
    "X_valid, y_valid, X_valid_df, y_valid_df = create_multi_step_sequence(valid_set, last_n_steps=12, day_lag=24, week_lag=168, n_future_steps=6)\n",
    "X_test, y_test, X_test_df, y_test_df = create_multi_step_sequence(test_set, last_n_steps=12, day_lag=24, week_lag=168, n_future_steps=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model_multi_step(input_shape, n_outputs, units, dropout_rate, learning_rate):\n",
    "    model = keras.Sequential()\n",
    "    model.add(LSTM(units=units, activation='tanh', input_shape=input_shape))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(n_outputs))\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        loss='mse',  # Mean Squared Error loss for regression\n",
    "        optimizer=optimizer,\n",
    "        metrics=['mae']  # Mean Absolute Error as a metric\n",
    "    )\n",
    "    return model\n",
    "\n",
    "input_shape = (x_train_scaled.shape[1], x_train_scaled.shape[2])\n",
    "n_outputs = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCIZFe1MAx-X"
   },
   "source": [
    "## 6. Set Up Hyperparameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter options\n",
    "units_list = [50, 100, 200]\n",
    "dropout_rates = [0, 0.3, 0.5]\n",
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "batch_sizes = [32, 64, 128]\n",
    "\n",
    "# Create all possible combinations\n",
    "hyperparameter_combinations = list(product(units_list, dropout_rates, learning_rates, batch_sizes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ixRU8sQA8NW"
   },
   "source": [
    "## 7. Train the Model with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination 1/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.01, batch_size=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\program\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation MAE: 0.0602\n",
      "\n",
      "Combination 2/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.01, batch_size=64\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation MAE: 0.0600\n",
      "\n",
      "Combination 3/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.01, batch_size=128\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation MAE: 0.0600\n",
      "\n",
      "Combination 4/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0618\n",
      "\n",
      "Combination 5/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation MAE: 0.0634\n",
      "\n",
      "Combination 6/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0644\n",
      "\n",
      "Combination 7/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.0001, batch_size=32\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation MAE: 0.0685\n",
      "\n",
      "Combination 8/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0685\n",
      "\n",
      "Combination 9/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0700\n",
      "\n",
      "Combination 10/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.01, batch_size=32\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation MAE: 0.0610\n",
      "\n",
      "Combination 11/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.01, batch_size=64\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation MAE: 0.0604\n",
      "\n",
      "Combination 12/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.01, batch_size=128\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation MAE: 0.0611\n",
      "\n",
      "Combination 13/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0619\n",
      "\n",
      "Combination 14/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0640\n",
      "\n",
      "Combination 15/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0652\n",
      "\n",
      "Combination 16/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0688\n",
      "\n",
      "Combination 17/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0711\n",
      "\n",
      "Combination 18/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0740\n",
      "\n",
      "Combination 19/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.01, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation MAE: 0.0610\n",
      "\n",
      "Combination 20/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.01, batch_size=64\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation MAE: 0.0614\n",
      "\n",
      "Combination 21/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.01, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0603\n",
      "\n",
      "Combination 22/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation MAE: 0.0630\n",
      "\n",
      "Combination 23/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.001, batch_size=64\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation MAE: 0.0658\n",
      "\n",
      "Combination 24/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0657\n",
      "\n",
      "Combination 25/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0686\n",
      "\n",
      "Combination 26/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0720\n",
      "\n",
      "Combination 27/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0745\n",
      "\n",
      "Combination 28/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.01, batch_size=32\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation MAE: 0.0608\n",
      "\n",
      "Combination 29/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.01, batch_size=64\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation MAE: 0.0608\n",
      "\n",
      "Combination 30/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.01, batch_size=128\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation MAE: 0.0606\n",
      "\n",
      "Combination 31/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation MAE: 0.0603\n",
      "\n",
      "Combination 32/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0616\n",
      "\n",
      "Combination 33/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation MAE: 0.0633\n",
      "\n",
      "Combination 34/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0669\n",
      "\n",
      "Combination 35/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0679\n",
      "\n",
      "Combination 36/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0682\n",
      "\n",
      "Combination 37/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.01, batch_size=32\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation MAE: 0.0606\n",
      "\n",
      "Combination 38/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.01, batch_size=64\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation MAE: 0.0607\n",
      "\n",
      "Combination 39/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.01, batch_size=128\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation MAE: 0.0595\n",
      "\n",
      "Combination 40/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation MAE: 0.0610\n",
      "\n",
      "Combination 41/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0618\n",
      "\n",
      "Combination 42/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0643\n",
      "\n",
      "Combination 43/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation MAE: 0.0675\n",
      "\n",
      "Combination 44/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation MAE: 0.0687\n",
      "\n",
      "Combination 45/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.0001, batch_size=128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0708\n",
      "\n",
      "Combination 46/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.01, batch_size=32\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation MAE: 0.0605\n",
      "\n",
      "Combination 47/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.01, batch_size=64\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation MAE: 0.0606\n",
      "\n",
      "Combination 48/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.01, batch_size=128\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation MAE: 0.0608\n",
      "\n",
      "Combination 49/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0616\n",
      "\n",
      "Combination 50/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0632\n",
      "\n",
      "Combination 51/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.001, batch_size=128\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation MAE: 0.0654\n",
      "\n",
      "Combination 52/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0672\n",
      "\n",
      "Combination 53/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0690\n",
      "\n",
      "Combination 54/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0712\n",
      "\n",
      "Combination 55/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.01, batch_size=32\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation MAE: 0.0600\n",
      "\n",
      "Combination 56/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.01, batch_size=64\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation MAE: 0.0604\n",
      "\n",
      "Combination 57/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.01, batch_size=128\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation MAE: 0.0605\n",
      "\n",
      "Combination 58/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.001, batch_size=32\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation MAE: 0.0605\n",
      "\n",
      "Combination 59/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0601\n",
      "\n",
      "Combination 60/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0618\n",
      "\n",
      "Combination 61/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0658\n",
      "\n",
      "Combination 62/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0672\n",
      "\n",
      "Combination 63/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.0001, batch_size=128\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation MAE: 0.0688\n",
      "\n",
      "Combination 64/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.01, batch_size=32\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation MAE: 0.0612\n",
      "\n",
      "Combination 65/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.01, batch_size=64\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation MAE: 0.0612\n",
      "\n",
      "Combination 66/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.01, batch_size=128\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation MAE: 0.0607\n",
      "\n",
      "Combination 67/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0603\n",
      "\n",
      "Combination 68/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0607\n",
      "\n",
      "Combination 69/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation MAE: 0.0631\n",
      "\n",
      "Combination 70/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0659\n",
      "\n",
      "Combination 71/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0682\n",
      "\n",
      "Combination 72/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0688\n",
      "\n",
      "Combination 73/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.01, batch_size=32\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation MAE: 0.0596\n",
      "\n",
      "Combination 74/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.01, batch_size=64\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation MAE: 0.0595\n",
      "\n",
      "Combination 75/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.01, batch_size=128\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation MAE: 0.0605\n",
      "\n",
      "Combination 76/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0607\n",
      "\n",
      "Combination 77/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0612\n",
      "\n",
      "Combination 78/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0635\n",
      "\n",
      "Combination 79/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0661\n",
      "\n",
      "Combination 80/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0679\n",
      "\n",
      "Combination 81/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0689\n",
      "\n",
      "Best Hyperparameters:\n",
      "units: 100\n",
      "dropout_rate: 0.3\n",
      "learning_rate: 0.01\n",
      "batch_size: 128\n",
      "Best Validation MAE: 0.0595\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables to store the best model and hyperparameters\n",
    "best_val_mae = np.inf\n",
    "best_hyperparams = None\n",
    "best_model = None\n",
    "\n",
    "for idx, (units, dropout_rate, learning_rate, batch_size) in enumerate(hyperparameter_combinations):\n",
    "    print(f\"\\nCombination {idx+1}/{len(hyperparameter_combinations)}\")\n",
    "    print(f\"Training with units={units}, dropout_rate={dropout_rate}, learning_rate={learning_rate}, batch_size={batch_size}\")\n",
    "\n",
    "    # Create the LSTM model with the current hyperparameters\n",
    "    model = create_lstm_model_multi_step(\n",
    "        input_shape=input_shape,\n",
    "        n_outputs=n_outputs,\n",
    "        units=units,\n",
    "        dropout_rate=dropout_rate,\n",
    "        learning_rate=learning_rate\n",
    "    )\n",
    "\n",
    "    # Initialize EarlyStopping\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_mae',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        x_train_scaled, y_train_scaled,\n",
    "        epochs=50,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_val_scaled, y_val_scaled),\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Get the best validation MAE from this training run\n",
    "    val_mae = min(history.history['val_mae'])\n",
    "    print(f\"Validation MAE: {val_mae:.4f}\")\n",
    "\n",
    "    # Update best model if current one is better\n",
    "    if val_mae < best_val_mae:\n",
    "        best_val_mae = val_mae\n",
    "        best_model = model\n",
    "        best_hyperparams = {\n",
    "            'units': units,\n",
    "            'dropout_rate': dropout_rate,\n",
    "            'learning_rate': learning_rate,\n",
    "            'batch_size': batch_size\n",
    "        }\n",
    "\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "for param, value in best_hyperparams.items():\n",
    "    print(f\"{param}: {value}\")\n",
    "print(f\"Best Validation MAE: {best_val_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "13:33"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Hyperparameters for full time:\n",
    "units: 200\n",
    "dropout_rate: 0.5\n",
    "learning_rate: 0.01\n",
    "batch_size: 32\n",
    "Best Validation MAE: 0.0503\n",
    "\n",
    "Best Hyperparameters for after covid:\n",
    "units: 100\n",
    "dropout_rate: 0.3\n",
    "learning_rate: 0.01\n",
    "batch_size: 128\n",
    "Best Validation MAE: 0.0595"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred_scaled = best_model.predict(x_test_scaled)\n",
    "\n",
    "# Reshape for inverse scaling\n",
    "y_pred_reshaped = y_pred_scaled.reshape(-1, 1)\n",
    "y_test_reshaped = y_test_scaled.reshape(-1, 1)\n",
    "\n",
    "# Inverse transform\n",
    "y_pred_inverse = y_scaler.inverse_transform(y_pred_reshaped).reshape(n_test_samples, n_outputs)\n",
    "y_test_inverse = y_scaler.inverse_transform(y_test_reshaped).reshape(n_test_samples, n_outputs)\n",
    "\n",
    "y_test_flat = y_test_inverse.flatten()\n",
    "y_pred_flat = y_pred_inverse.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9SREwnRqxMN1"
   },
   "source": [
    "## 9. Evaluating the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time Step 1 Evaluation Metrics:\n",
      "RMSE: 28.4454\n",
      "MAE: 20.8450\n",
      "MAPE: 19.44%\n",
      "\n",
      "Time Step 2 Evaluation Metrics:\n",
      "RMSE: 36.2563\n",
      "MAE: 26.7673\n",
      "MAPE: 25.02%\n",
      "\n",
      "Time Step 3 Evaluation Metrics:\n",
      "RMSE: 43.7203\n",
      "MAE: 33.1341\n",
      "MAPE: 29.97%\n",
      "\n",
      "Time Step 4 Evaluation Metrics:\n",
      "RMSE: 49.3573\n",
      "MAE: 38.0972\n",
      "MAPE: 35.19%\n",
      "\n",
      "Time Step 5 Evaluation Metrics:\n",
      "RMSE: 53.2812\n",
      "MAE: 41.5888\n",
      "MAPE: 39.42%\n",
      "\n",
      "Time Step 6 Evaluation Metrics:\n",
      "RMSE: 53.3926\n",
      "MAE: 42.0135\n",
      "MAPE: 44.19%\n"
     ]
    }
   ],
   "source": [
    "# Compute Metrics for Each Time Step\n",
    "\n",
    "for i in range(n_outputs):\n",
    "    y_true = y_test_inverse[:, i]\n",
    "    y_pred = y_pred_inverse[:, i]\n",
    "\n",
    "    # Mean Absolute Error (MAE)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "    # Mean Squared Error (MSE)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "    # Root Mean Squared Error (RMSE)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # Mean Absolute Percentage Error (MAPE)\n",
    "    # Avoid division by zero by adding a small epsilon to y_test_flat if necessary\n",
    "    epsilon = 1e-10\n",
    "    y_true_safe = np.where(y_true == 0, epsilon, y_true)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true_safe)) * 100\n",
    "\n",
    "    print(f\"\\nTime Step {i+1} Evaluation Metrics:\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"MAPE: {mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyYn2XL2GUxw"
   },
   "source": [
    "# Code to predict next 6 steps step-by-step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vavf9D4-lc6E"
   },
   "source": [
    "#### We will use\n",
    "* the last 12 steps\n",
    "\n",
    "* previous one week (24 steps)\n",
    "\n",
    "* previous one month  (168 steps)\n",
    "\n",
    "*  to forecast current (0 step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OfV8VwesmXS3"
   },
   "source": [
    "## 4. Create input and output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "PJaM65dTlc6E"
   },
   "outputs": [],
   "source": [
    "# Create input-output sequences with the provided function\n",
    "X_train, y_train, X_train_df, y_train_df = create_multi_step_sequence(train_set, last_n_steps=12, day_lag=24, week_lag=168, n_future_steps=1)\n",
    "X_valid, y_valid, X_valid_df, y_valid_df = create_multi_step_sequence(valid_set, last_n_steps=12, day_lag=24, week_lag=168, n_future_steps=1)\n",
    "X_test, y_test, X_test_df, y_test_df = create_multi_step_sequence(test_set, last_n_steps=12, day_lag=24, week_lag=168, n_future_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ipA2bPAcm2L1",
    "outputId": "687db2e3-3f26-4cc3-c15b-0d8066617ff8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19570, 14, 1), (6907, 14, 1), (5623, 14, 1))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0GNpslqvlx5_"
   },
   "source": [
    "## 5. Normalise the data after split (step-by-step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_Co01Aflx6B"
   },
   "source": [
    "Normalise X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Z7YuPxvRlx6C"
   },
   "outputs": [],
   "source": [
    "# Separate scalers for inputs and outputs\n",
    "x_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "y_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Reshape x_train to 2D for scaling\n",
    "n_samples, n_timesteps, n_features = X_train.shape\n",
    "x_train_reshaped = X_train.reshape(-1, n_features)  # Shape: (n_samples * n_timesteps, n_features)\n",
    "# Fit the scaler on the training data\n",
    "x_scaler.fit(x_train_reshaped)\n",
    "# Transform the training data\n",
    "x_train_scaled = x_scaler.transform(x_train_reshaped)\n",
    "# Reshape back to original shape\n",
    "x_train_scaled = x_train_scaled.reshape(n_samples, n_timesteps, n_features)\n",
    "\n",
    "# x_val\n",
    "n_val_samples = X_valid.shape[0]\n",
    "x_val_reshaped = X_valid.reshape(-1, n_features)\n",
    "x_val_scaled = x_scaler.transform(x_val_reshaped)\n",
    "x_val_scaled = x_val_scaled.reshape(n_val_samples, n_timesteps, n_features)\n",
    "\n",
    "# x_test\n",
    "n_test_samples = X_test.shape[0]\n",
    "x_test_reshaped = X_test.reshape(-1, n_features)\n",
    "x_test_scaled = x_scaler.transform(x_test_reshaped)\n",
    "x_test_scaled = x_test_scaled.reshape(n_test_samples, n_timesteps, n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rw7rcIWPlx6D"
   },
   "source": [
    "Normalise y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "azSWFgFmlx6D"
   },
   "outputs": [],
   "source": [
    "# Reshape y_train to 2D for scaling\n",
    "y_train_reshaped = y_train.reshape(-1, 1)  # Shape: (n_samples * n_outputs, 1)\n",
    "# Fit the scaler on the training data\n",
    "y_scaler.fit(y_train_reshaped)\n",
    "# Transform the training data\n",
    "y_train_scaled = y_scaler.transform(y_train_reshaped)\n",
    "# Reshape back to original shape\n",
    "y_train_scaled = y_train_scaled.reshape(n_samples, y_train.shape[1])\n",
    "\n",
    "# y_val\n",
    "y_val_reshaped = y_valid.reshape(-1, 1)\n",
    "y_val_scaled = y_scaler.transform(y_val_reshaped)\n",
    "y_val_scaled = y_val_scaled.reshape(n_val_samples, y_valid.shape[1])\n",
    "\n",
    "# y_test\n",
    "y_test_reshaped = y_test.reshape(-1, 1)\n",
    "y_test_scaled = y_scaler.transform(y_test_reshaped)\n",
    "y_test_scaled = y_test_scaled.reshape(n_test_samples, y_test.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJ7sNErrpc9O"
   },
   "source": [
    "## 6. Build LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "eE7DAUCIoVSt"
   },
   "outputs": [],
   "source": [
    "def create_lstm_model(input_shape, units, dropout_rate, learning_rate):\n",
    "    model = keras.Sequential()\n",
    "    model.add(LSTM(units=units, activation='tanh', input_shape=input_shape))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1)) # Output layer for one-step prediction\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        loss='mse',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "input_shape = (x_train_scaled.shape[1], x_train_scaled.shape[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYD8kk0NpzNp"
   },
   "source": [
    "## 7. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u4zCXOAo9tN"
   },
   "outputs": [],
   "source": [
    "# Hyperparameter options\n",
    "units_list = [50, 100, 200]\n",
    "dropout_rates = [0, 0.3, 0.5]\n",
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "batch_sizes = [32, 64, 128]\n",
    "\n",
    "# Create all possible combinations\n",
    "hyperparameter_combinations = list(product(units_list, dropout_rates, learning_rates, batch_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "5d-_-jwBp45_",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "e551e47c-fc12-4b0c-d237-39b9eb0d4f7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination 1/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.01, batch_size=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\program\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation MAE: 0.0452\n",
      "\n",
      "Combination 2/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.01, batch_size=64\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation MAE: 0.0452\n",
      "\n",
      "Combination 3/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.01, batch_size=128\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation MAE: 0.0466\n",
      "\n",
      "Combination 4/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0450\n",
      "\n",
      "Combination 5/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0463\n",
      "\n",
      "Combination 6/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0492\n",
      "\n",
      "Combination 7/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0496\n",
      "\n",
      "Combination 8/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0506\n",
      "\n",
      "Combination 9/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0512\n",
      "\n",
      "Combination 10/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.01, batch_size=32\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation MAE: 0.0464\n",
      "\n",
      "Combination 11/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.01, batch_size=64\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation MAE: 0.0467\n",
      "\n",
      "Combination 12/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.01, batch_size=128\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation MAE: 0.0457\n",
      "\n",
      "Combination 13/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0466\n",
      "\n",
      "Combination 14/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.001, batch_size=64\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation MAE: 0.0498\n",
      "\n",
      "Combination 15/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0493\n",
      "\n",
      "Combination 16/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0508\n",
      "\n",
      "Combination 17/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0516\n",
      "\n",
      "Combination 18/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0517\n",
      "\n",
      "Combination 19/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.01, batch_size=32\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation MAE: 0.0459\n",
      "\n",
      "Combination 20/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.01, batch_size=64\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation MAE: 0.0461\n",
      "\n",
      "Combination 21/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.01, batch_size=128\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation MAE: 0.0463\n",
      "\n",
      "Combination 22/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0471\n",
      "\n",
      "Combination 23/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0489\n",
      "\n",
      "Combination 24/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0501\n",
      "\n",
      "Combination 25/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0510\n",
      "\n",
      "Combination 26/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation MAE: 0.0514\n",
      "\n",
      "Combination 27/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0522\n",
      "\n",
      "Combination 28/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.01, batch_size=32\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation MAE: 0.0463\n",
      "\n",
      "Combination 29/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.01, batch_size=64\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation MAE: 0.0461\n",
      "\n",
      "Combination 30/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.01, batch_size=128\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation MAE: 0.0453\n",
      "\n",
      "Combination 31/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation MAE: 0.0450\n",
      "\n",
      "Combination 32/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation MAE: 0.0458\n",
      "\n",
      "Combination 33/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.001, batch_size=128\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation MAE: 0.0496\n",
      "\n",
      "Combination 34/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0494\n",
      "\n",
      "Combination 35/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0502\n",
      "\n",
      "Combination 36/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation MAE: 0.0512\n",
      "\n",
      "Combination 37/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.01, batch_size=32\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation MAE: 0.0463\n",
      "\n",
      "Combination 38/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.01, batch_size=64\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation MAE: 0.0459\n",
      "\n",
      "Combination 39/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.01, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0457\n",
      "\n",
      "Combination 40/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0456\n",
      "\n",
      "Combination 41/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0469\n",
      "\n",
      "Combination 42/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation MAE: 0.0494\n",
      "\n",
      "Combination 43/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.0001, batch_size=32\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation MAE: 0.0502\n",
      "\n",
      "Combination 44/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0509\n",
      "\n",
      "Combination 45/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.0001, batch_size=128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation MAE: 0.0513\n",
      "\n",
      "Combination 46/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.01, batch_size=32\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation MAE: 0.0466\n",
      "\n",
      "Combination 47/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.01, batch_size=64\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation MAE: 0.0460\n",
      "\n",
      "Combination 48/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.01, batch_size=128\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation MAE: 0.0458\n",
      "\n",
      "Combination 49/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0463\n",
      "\n",
      "Combination 50/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.001, batch_size=64\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation MAE: 0.0496\n",
      "\n",
      "Combination 51/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation MAE: 0.0496\n",
      "\n",
      "Combination 52/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0505\n",
      "\n",
      "Combination 53/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0511\n",
      "\n",
      "Combination 54/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0514\n",
      "\n",
      "Combination 55/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.01, batch_size=32\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation MAE: 0.0464\n",
      "\n",
      "Combination 56/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.01, batch_size=64\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation MAE: 0.0452\n",
      "\n",
      "Combination 57/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.01, batch_size=128\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation MAE: 0.0455\n",
      "\n",
      "Combination 58/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0452\n",
      "\n",
      "Combination 59/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation MAE: 0.0459\n",
      "\n",
      "Combination 60/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation MAE: 0.0470\n",
      "\n",
      "Combination 61/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0492\n",
      "\n",
      "Combination 62/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0497\n",
      "\n",
      "Combination 63/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0503\n",
      "\n",
      "Combination 64/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.01, batch_size=32\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation MAE: 0.0460\n",
      "\n",
      "Combination 65/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.01, batch_size=64\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation MAE: 0.0461\n",
      "\n",
      "Combination 66/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.01, batch_size=128\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation MAE: 0.0486\n",
      "\n",
      "Combination 67/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation MAE: 0.0460\n",
      "\n",
      "Combination 68/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0460\n",
      "\n",
      "Combination 69/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0471\n",
      "\n",
      "Combination 70/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0495\n",
      "\n",
      "Combination 71/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0499\n",
      "\n",
      "Combination 72/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0504\n",
      "\n",
      "Combination 73/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.01, batch_size=32\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation MAE: 0.0455\n",
      "\n",
      "Combination 74/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.01, batch_size=64\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation MAE: 0.0466\n",
      "\n",
      "Combination 75/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.01, batch_size=128\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation MAE: 0.0465\n",
      "\n",
      "Combination 76/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.001, batch_size=32\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation MAE: 0.0467\n",
      "\n",
      "Combination 77/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.001, batch_size=64\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation MAE: 0.0478\n",
      "\n",
      "Combination 78/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation MAE: 0.0477\n",
      "\n",
      "Combination 79/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0496\n",
      "\n",
      "Combination 80/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0502\n",
      "\n",
      "Combination 81/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation MAE: 0.0508\n",
      "\n",
      "Best Hyperparameters:\n",
      "units: 100\n",
      "dropout_rate: 0\n",
      "learning_rate: 0.001\n",
      "batch_size: 32\n",
      "Best Validation MAE: 0.0450\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables to store the best model and hyperparameters\n",
    "best_val_mae = np.inf\n",
    "best_hyperparams = None\n",
    "best_model = None\n",
    "\n",
    "for idx, (units, dropout_rate, learning_rate, batch_size) in enumerate(hyperparameter_combinations):\n",
    "    print(f\"\\nCombination {idx+1}/{len(hyperparameter_combinations)}\")\n",
    "    print(f\"Training with units={units}, dropout_rate={dropout_rate}, learning_rate={learning_rate}, batch_size={batch_size}\")\n",
    "\n",
    "    # Create the LSTM model with the current hyperparameters\n",
    "    model = create_lstm_model(\n",
    "        input_shape=input_shape,\n",
    "        units=units,\n",
    "        dropout_rate=dropout_rate,\n",
    "        learning_rate=learning_rate\n",
    "    )\n",
    "\n",
    "    # Initialize EarlyStopping\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_mae',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        x_train_scaled, y_train_scaled,\n",
    "        epochs=50,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_val_scaled, y_val_scaled),\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Get the best validation MAE from this training run\n",
    "    val_mae = min(history.history['val_mae'])\n",
    "    print(f\"Validation MAE: {val_mae:.4f}\")\n",
    "\n",
    "    # Update best model if current one is better\n",
    "    if val_mae < best_val_mae:\n",
    "        best_val_mae = val_mae\n",
    "        best_model = model\n",
    "        best_hyperparams = {\n",
    "            'units': units,\n",
    "            'dropout_rate': dropout_rate,\n",
    "            'learning_rate': learning_rate,\n",
    "            'batch_size': batch_size\n",
    "        }\n",
    "\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "for param, value in best_hyperparams.items():\n",
    "    print(f\"{param}: {value}\")\n",
    "print(f\"Best Validation MAE: {best_val_mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Hyperparameters full time:\n",
    "units: 50\n",
    "dropout_rate: 0\n",
    "learning_rate: 0.01\n",
    "batch_size: 128\n",
    "Best Validation MAE: 0.0388\n",
    "\n",
    "Best Hyperparameters after covid:\n",
    "units: 100\n",
    "dropout_rate: 0\n",
    "learning_rate: 0.001\n",
    "batch_size: 32\n",
    "Best Validation MAE: 0.0450"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recreate the model¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_lstm_model(input_shape, units, dropout_rate, learning_rate):\n",
    "    model = keras.Sequential()\n",
    "    model.add(LSTM(units=units, activation='tanh', input_shape=input_shape))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1)) # Output layer for one-step prediction\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        loss='mse',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (x_train_scaled.shape[1], x_train_scaled.shape[2])\n",
    "units=50\n",
    "dropout_rate=0\n",
    "learning_rate=0.01\n",
    "batch_size=128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrain the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize EarlyStopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_mae',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0044 - mae: 0.0474 - val_loss: 0.0039 - val_mae: 0.0405\n",
      "Epoch 2/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0043 - mae: 0.0465 - val_loss: 0.0039 - val_mae: 0.0406\n",
      "Epoch 3/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0043 - mae: 0.0467 - val_loss: 0.0040 - val_mae: 0.0432\n",
      "Epoch 4/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0044 - mae: 0.0472 - val_loss: 0.0039 - val_mae: 0.0401\n",
      "Epoch 5/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0043 - mae: 0.0469 - val_loss: 0.0040 - val_mae: 0.0430\n",
      "Epoch 6/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0044 - mae: 0.0473 - val_loss: 0.0039 - val_mae: 0.0399\n",
      "Epoch 7/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0043 - mae: 0.0464 - val_loss: 0.0039 - val_mae: 0.0406\n",
      "Epoch 8/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0045 - mae: 0.0475 - val_loss: 0.0039 - val_mae: 0.0416\n",
      "Epoch 9/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0043 - mae: 0.0464 - val_loss: 0.0039 - val_mae: 0.0411\n",
      "Epoch 10/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - loss: 0.0044 - mae: 0.0468 - val_loss: 0.0039 - val_mae: 0.0406\n",
      "Epoch 11/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0043 - mae: 0.0463 - val_loss: 0.0039 - val_mae: 0.0404\n",
      "Epoch 12/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0042 - mae: 0.0459 - val_loss: 0.0041 - val_mae: 0.0421\n",
      "Epoch 13/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0043 - mae: 0.0464 - val_loss: 0.0039 - val_mae: 0.0400\n",
      "Epoch 14/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0041 - mae: 0.0459 - val_loss: 0.0039 - val_mae: 0.0394\n",
      "Epoch 15/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0043 - mae: 0.0466 - val_loss: 0.0039 - val_mae: 0.0411\n",
      "Epoch 16/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0042 - mae: 0.0460 - val_loss: 0.0039 - val_mae: 0.0401\n",
      "Epoch 17/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0042 - mae: 0.0459 - val_loss: 0.0039 - val_mae: 0.0399\n",
      "Epoch 18/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0042 - mae: 0.0462 - val_loss: 0.0040 - val_mae: 0.0411\n",
      "Epoch 19/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.0041 - mae: 0.0456 - val_loss: 0.0039 - val_mae: 0.0394\n",
      "Epoch 20/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0040 - mae: 0.0454 - val_loss: 0.0039 - val_mae: 0.0405\n",
      "Epoch 21/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0044 - mae: 0.0467 - val_loss: 0.0040 - val_mae: 0.0409\n",
      "Epoch 22/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.0042 - mae: 0.0461 - val_loss: 0.0041 - val_mae: 0.0421\n",
      "Epoch 23/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0042 - mae: 0.0464 - val_loss: 0.0040 - val_mae: 0.0409\n",
      "Epoch 24/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0042 - mae: 0.0462 - val_loss: 0.0040 - val_mae: 0.0396\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = best_model.fit(\n",
    "    x_train_scaled, y_train_scaled,\n",
    "    epochs=50,  # You can adjust this as needed\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(x_val_scaled, y_val_scaled),\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1  # Set to 1 to see detailed training output\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27LXIyi-w0th"
   },
   "source": [
    "## 8. Recursive Forecasting with LSTM (step-by-step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "O5eKQOi8dLQ-"
   },
   "outputs": [],
   "source": [
    "def recursive_forecast(model, x_test_scaled, start_index, n_steps, x_scaler, y_scaler):\n",
    "    \"\"\"\n",
    "    Perform recursive forecasting using the trained model.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained model\n",
    "    - x_test_scaled: The scaled test input data (shape: n_samples, n_timesteps, n_features)\n",
    "    - start_index: The starting index in the test data\n",
    "    - n_steps: Number of future steps to predict\n",
    "    - x_scaler: Scaler used for input features\n",
    "    - y_scaler: Scaler used for target variable\n",
    "\n",
    "    Returns:\n",
    "    - predictions: List of predicted values (in original scale)\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    scaled_predictions = []\n",
    "    current_input = x_test_scaled[start_index].copy()  # Shape: (n_timesteps, n_features)\n",
    "\n",
    "    for step in range(n_steps):\n",
    "        # Reshape to (1, n_timesteps, n_features) for prediction\n",
    "        input_seq = current_input.reshape((1, current_input.shape[0], current_input.shape[1]))\n",
    "\n",
    "        # Predict the next time step (scaled)\n",
    "        yhat_scaled = model.predict(input_seq, verbose=0)  # Shape: (1, 1)\n",
    "\n",
    "        # Inverse transform the prediction to original scale\n",
    "        yhat = y_scaler.inverse_transform(yhat_scaled)[0, 0]\n",
    "        \n",
    "        # Transform the prediction back to input feature scale for lag features\n",
    "        yhat_for_input = x_scaler.transform(yhat.reshape(-1, 1))[0, 0]\n",
    "\n",
    "        # Append predictions\n",
    "        predictions.append(yhat)\n",
    "        scaled_predictions.append(yhat_for_input)\n",
    "\n",
    "        # Move to the next time step in x_test_scaled\n",
    "        next_index = start_index + step + 1\n",
    "        if next_index < len(x_test_scaled):\n",
    "            # Use features from the next time step\n",
    "            next_input = x_test_scaled[next_index].copy()\n",
    "        else:\n",
    "            # Reached the end of x_test_scaled\n",
    "            break\n",
    "\n",
    "        # Update lag features with available scaled predictions\n",
    "        for lag in range(1, min(step + 1, 6) + 1):\n",
    "            feature_index = 12 - lag  # lag1 is at index 11\n",
    "            next_input[feature_index, 0] = scaled_predictions[-lag]\n",
    "\n",
    "        # Keep lag24 and lag168 as they are, or update if necessary\n",
    "\n",
    "        # Set current_input for next iteration\n",
    "        current_input = next_input\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBK2TyUSxCQ-"
   },
   "source": [
    "## 9. Make step-by-step prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "79gLJQDkdNBl"
   },
   "outputs": [],
   "source": [
    "# Number of steps to predict\n",
    "n_steps = 6\n",
    "\n",
    "# Initialize lists to store predictions and actual values\n",
    "all_predictions = []\n",
    "all_actuals = []\n",
    "\n",
    "# Ensure we have enough data for recursive predictions\n",
    "n_test_samples = x_test_scaled.shape[0]\n",
    "\n",
    "for i in range(n_test_samples - n_steps):\n",
    "    # Perform recursive forecasting\n",
    "    predictions = recursive_forecast(\n",
    "        model=best_model,\n",
    "        x_test_scaled=x_test_scaled,\n",
    "        start_index=i,\n",
    "        n_steps=n_steps,\n",
    "        x_scaler=x_scaler,\n",
    "        y_scaler=y_scaler\n",
    "    )\n",
    "\n",
    "    # Get the actual future values (in original scale)\n",
    "    actual_values = y_test[i+1:i + len(predictions) + 1].flatten()\n",
    "\n",
    "    # Store the predictions and actual values\n",
    "    all_predictions.append(predictions)\n",
    "    all_actuals.append(actual_values)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_actuals = np.array(all_actuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9SREwnRqxMN1"
   },
   "source": [
    "## 10. Evaluating the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xw9n5yNExAkJ",
    "outputId": "4f5b2721-8d8e-4871-eb56-dfd1b17ab14c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time Step 1 Evaluation Metrics:\n",
      "RMSE: 41.4159\n",
      "MAE: 29.8309\n",
      "MAPE: 32.89%\n",
      "\n",
      "Time Step 2 Evaluation Metrics:\n",
      "RMSE: 44.7596\n",
      "MAE: 31.9444\n",
      "MAPE: 36.16%\n",
      "\n",
      "Time Step 3 Evaluation Metrics:\n",
      "RMSE: 47.2820\n",
      "MAE: 33.4781\n",
      "MAPE: 39.15%\n",
      "\n",
      "Time Step 4 Evaluation Metrics:\n",
      "RMSE: 49.5900\n",
      "MAE: 34.8770\n",
      "MAPE: 41.75%\n",
      "\n",
      "Time Step 5 Evaluation Metrics:\n",
      "RMSE: 51.5312\n",
      "MAE: 35.9326\n",
      "MAPE: 43.32%\n",
      "\n",
      "Time Step 6 Evaluation Metrics:\n",
      "RMSE: 53.2142\n",
      "MAE: 36.6299\n",
      "MAPE: 44.43%\n"
     ]
    }
   ],
   "source": [
    "# Compute evaluation metrics\n",
    "epsilon = 1e-10  # To avoid division by zero in MAPE\n",
    "\n",
    "for i in range(n_steps):\n",
    "    y_true = all_actuals[:, i]\n",
    "    y_pred = all_predictions[:, i]\n",
    "\n",
    "    # Mean Absolute Error (MAE)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "    # Root Mean Squared Error (RMSE)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "    # Mean Absolute Percentage Error (MAPE)\n",
    "    y_true_safe = np.where(y_true == 0, epsilon, y_true)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true_safe)) * 100\n",
    "\n",
    "    print(f\"\\nTime Step {i+1} Evaluation Metrics:\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"MAPE: {mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k9VMIQUvBZ3q"
   },
   "outputs": [],
   "source": [
    "step-by-step full date"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
