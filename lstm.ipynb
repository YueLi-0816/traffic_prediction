{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tKUGmv5cn6GV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-31 16:37:08.921565: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-31 16:37:09.742862: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-31 16:37:10.052844: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-31 16:37:10.126633: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-31 16:37:10.715388: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-31 16:37:13.117471: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import random\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs:\n",
      " - /physical_device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# List all physical devices\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Available GPUs:\")\n",
    "for gpu in gpus:\n",
    "    print(f\" - {gpu.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory growth enabled for GPUs.\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"Memory growth enabled for GPUs.\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8uafyjo7odXA"
   },
   "outputs": [],
   "source": [
    "traffic_data = pd.read_csv('GD030A_S.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KZRSO8dF_Sik"
   },
   "source": [
    "## 1. Recover timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "4TWZuMkMiYtJ"
   },
   "outputs": [],
   "source": [
    "# Define the recover_timestamp function\n",
    "def recover_timestamp(data):\n",
    "    # Combine 'date' and 'time' to form a datetime column\n",
    "    data['datetime'] = pd.to_datetime(data['date'] + ' ' + data['time'].astype(str) + ':00', format='%Y-%m-%d %H:%M')\n",
    "\n",
    "    # Set 'datetime' as index\n",
    "    data = data.set_index('datetime')\n",
    "\n",
    "    # Create a complete range of timestamps with hourly frequency\n",
    "    full_time_range = pd.date_range(start=data.index.min(), end=data.index.max(), freq='H')\n",
    "\n",
    "    # Reindex the data to include all timestamps, filling missing rows with NaN\n",
    "    data_full = data.reindex(full_time_range)\n",
    "\n",
    "    return data_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "rwy81CAA_Y4r",
    "outputId": "9d3c3f5e-37fd-40f5-e31f-060efe8ee18d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>flow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-10-01 00:00:00</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01 01:00:00</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01 02:00:00</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01 03:00:00</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01 04:00:00</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-30 19:00:00</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>19.0</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-30 20:00:00</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>20.0</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-30 21:00:00</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>21.0</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-30 22:00:00</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>22.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-30 23:00:00</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>23.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35064 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           date  time   flow\n",
       "2019-10-01 00:00:00  2019-10-01   0.0   15.0\n",
       "2019-10-01 01:00:00  2019-10-01   1.0    9.0\n",
       "2019-10-01 02:00:00  2019-10-01   2.0    9.0\n",
       "2019-10-01 03:00:00  2019-10-01   3.0    7.0\n",
       "2019-10-01 04:00:00  2019-10-01   4.0    9.0\n",
       "...                         ...   ...    ...\n",
       "2023-09-30 19:00:00  2023-09-30  19.0  129.0\n",
       "2023-09-30 20:00:00  2023-09-30  20.0  119.0\n",
       "2023-09-30 21:00:00  2023-09-30  21.0  106.0\n",
       "2023-09-30 22:00:00  2023-09-30  22.0   88.0\n",
       "2023-09-30 23:00:00  2023-09-30  23.0   88.0\n",
       "\n",
       "[35064 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the recover_timestamp function to recover the full time series\n",
    "traffic_full = recover_timestamp(traffic_data)\n",
    "traffic_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8z-mdqKewzjt"
   },
   "source": [
    "## 2. Train, validate, test data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h60qTUKvwzCb",
    "outputId": "682cc0ab-b2ed-48a1-df5d-6168064efd78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of train_set : 0.6227\n",
      "Proportion of valid_set : 0.1876\n",
      "Proportion of test_set : 0.1897\n"
     ]
    }
   ],
   "source": [
    "# train_set = traffic_full[:'2022-02-28 23:00:00']\n",
    "# valid_set = traffic_full['2022-03-01 00:00:00':'2022-12-31 23:00:00']\n",
    "# test_set = traffic_full['2023-01-01 00:00:00':]\n",
    "train_set = traffic_full['2022-06-03 00:00:00':'2023-03-31 23:00:00']\n",
    "valid_set = traffic_full['2023-04-01 00:00:00':'2023-06-30 23:00:00']\n",
    "test_set = traffic_full['2023-07-01 00:00:00':]\n",
    "print('Proportion of train_set : {:.4f}'.format(len(train_set)/len(traffic_full['2022-06-03 00:00:00':])))\n",
    "print('Proportion of valid_set : {:.4f}'.format(len(valid_set)/len(traffic_full['2022-06-03 00:00:00':])))\n",
    "print('Proportion of test_set : {:.4f}'.format(len(test_set)/len(traffic_full['2022-06-03 00:00:00':])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date    16\n",
      "time    16\n",
      "flow    16\n",
      "dtype: int64 7248\n",
      "date    61\n",
      "time    61\n",
      "flow    61\n",
      "dtype: int64 2184\n",
      "date    342\n",
      "time    342\n",
      "flow    342\n",
      "dtype: int64 2208\n"
     ]
    }
   ],
   "source": [
    "print(train_set.isnull().sum(), len(train_set))\n",
    "print(valid_set.isnull().sum(),len(valid_set))\n",
    "print(test_set.isnull().sum(),len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bd0hRLpW9gJs"
   },
   "source": [
    "## 3. Normalise the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_921063/1100395100.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_set.loc[:, 'flow_scaled'] = scaler.transform(train_set[['flow']])\n",
      "/tmp/ipykernel_921063/1100395100.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  valid_set.loc[:, 'flow_scaled'] = scaler.transform(valid_set[['flow']])\n",
      "/tmp/ipykernel_921063/1100395100.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_set.loc[:, 'flow_scaled'] = scaler.transform(test_set[['flow']])\n"
     ]
    }
   ],
   "source": [
    "# Initialize the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler on the training data's 'flow' feature\n",
    "scaler.fit(train_set[['flow']])\n",
    "\n",
    "# Transform the 'flow' feature in all datasets\n",
    "train_set.loc[:, 'flow_scaled'] = scaler.transform(train_set[['flow']])\n",
    "valid_set.loc[:, 'flow_scaled'] = scaler.transform(valid_set[['flow']])\n",
    "test_set.loc[:, 'flow_scaled'] = scaler.transform(test_set[['flow']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xak17ms1uZ-6"
   },
   "source": [
    "## 4. Split the data into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, input_length, forecast_horizon):\n",
    "    \"\"\"\n",
    "    Creates input-output sequences for time series data, excluding any sequences containing NaN values.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: pandas DataFrame containing the data. Must include the 'flow_scaled' column.\n",
    "    - input_length: int, number of past time steps to include in each input sequence.\n",
    "    - forecast_horizon: int, number of future steps to predict.\n",
    "    \n",
    "    Returns:\n",
    "    - X: numpy array of shape (num_valid_samples, input_length, num_features)\n",
    "    - y: numpy array of shape (num_valid_samples, forecast_horizon)\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    num_features = data.shape[1]\n",
    "    total_length = input_length + forecast_horizon\n",
    "    \n",
    "    for i in range(input_length, len(data) - forecast_horizon + 1):\n",
    "        # Extract the input sequence\n",
    "        X_seq = data.iloc[i - input_length:i]['flow_scaled'].values\n",
    "        # Extract the target sequence\n",
    "        y_seq = data.iloc[i:i + forecast_horizon]['flow_scaled'].values\n",
    "        \n",
    "        # Check for NaN values in the input sequence and target sequence\n",
    "        if not np.isnan(X_seq).any() and not np.isnan(y_seq).any():\n",
    "            X.append(X_seq)\n",
    "            y.append(y_seq)\n",
    "        else:\n",
    "            # Optionally, log or count the skipped sequences\n",
    "            pass  # Simply skip sequences with NaNs\n",
    "        \n",
    "    # Convert to numpy arrays and reshape X to match LSTM expected input (samples, timesteps, features)\n",
    "    X = np.array(X).reshape(-1, input_length, 1)\n",
    "    y = np.array(y).reshape(-1, forecast_horizon)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create X and y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will use\n",
    "* the last 24*N steps\n",
    "\n",
    "*  to forecast current (0 step) and 5 steps ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Input Sequence Lengths\n",
    "input_lengths = [24 * i for i in range(2, 22)]  # [24, 48, ..., 168]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing input length: 48\n",
      "  X_train shape: (7073, 48, 1), y_train shape: (7073, 6)\n",
      "  X_val shape: (1911, 48, 1), y_val shape: (1911, 6)\n",
      "  X_test shape: (1604, 48, 1), y_test shape: (1604, 6)\n",
      "\n",
      "Processing input length: 72\n",
      "  X_train shape: (7001, 72, 1), y_train shape: (7001, 6)\n",
      "  X_val shape: (1815, 72, 1), y_val shape: (1815, 6)\n",
      "  X_test shape: (1508, 72, 1), y_test shape: (1508, 6)\n",
      "\n",
      "Processing input length: 96\n",
      "  X_train shape: (6929, 96, 1), y_train shape: (6929, 6)\n",
      "  X_val shape: (1719, 96, 1), y_val shape: (1719, 6)\n",
      "  X_test shape: (1412, 96, 1), y_test shape: (1412, 6)\n",
      "\n",
      "Processing input length: 120\n",
      "  X_train shape: (6857, 120, 1), y_train shape: (6857, 6)\n",
      "  X_val shape: (1623, 120, 1), y_val shape: (1623, 6)\n",
      "  X_test shape: (1316, 120, 1), y_test shape: (1316, 6)\n",
      "\n",
      "Processing input length: 144\n",
      "  X_train shape: (6785, 144, 1), y_train shape: (6785, 6)\n",
      "  X_val shape: (1527, 144, 1), y_val shape: (1527, 6)\n",
      "  X_test shape: (1220, 144, 1), y_test shape: (1220, 6)\n",
      "\n",
      "Processing input length: 168\n",
      "  X_train shape: (6713, 168, 1), y_train shape: (6713, 6)\n",
      "  X_val shape: (1431, 168, 1), y_val shape: (1431, 6)\n",
      "  X_test shape: (1124, 168, 1), y_test shape: (1124, 6)\n",
      "\n",
      "Processing input length: 192\n",
      "  X_train shape: (6641, 192, 1), y_train shape: (6641, 6)\n",
      "  X_val shape: (1335, 192, 1), y_val shape: (1335, 6)\n",
      "  X_test shape: (1028, 192, 1), y_test shape: (1028, 6)\n",
      "\n",
      "Processing input length: 216\n",
      "  X_train shape: (6569, 216, 1), y_train shape: (6569, 6)\n",
      "  X_val shape: (1239, 216, 1), y_val shape: (1239, 6)\n",
      "  X_test shape: (932, 216, 1), y_test shape: (932, 6)\n",
      "\n",
      "Processing input length: 240\n",
      "  X_train shape: (6497, 240, 1), y_train shape: (6497, 6)\n",
      "  X_val shape: (1143, 240, 1), y_val shape: (1143, 6)\n",
      "  X_test shape: (836, 240, 1), y_test shape: (836, 6)\n",
      "\n",
      "Processing input length: 264\n",
      "  X_train shape: (6425, 264, 1), y_train shape: (6425, 6)\n",
      "  X_val shape: (1047, 264, 1), y_val shape: (1047, 6)\n",
      "  X_test shape: (740, 264, 1), y_test shape: (740, 6)\n",
      "\n",
      "Processing input length: 288\n",
      "  X_train shape: (6353, 288, 1), y_train shape: (6353, 6)\n",
      "  X_val shape: (963, 288, 1), y_val shape: (963, 6)\n",
      "  X_test shape: (660, 288, 1), y_test shape: (660, 6)\n",
      "\n",
      "Processing input length: 312\n",
      "  X_train shape: (6281, 312, 1), y_train shape: (6281, 6)\n",
      "  X_val shape: (891, 312, 1), y_val shape: (891, 6)\n",
      "  X_test shape: (588, 312, 1), y_test shape: (588, 6)\n",
      "\n",
      "Processing input length: 336\n",
      "  X_train shape: (6209, 336, 1), y_train shape: (6209, 6)\n",
      "  X_val shape: (819, 336, 1), y_val shape: (819, 6)\n",
      "  X_test shape: (516, 336, 1), y_test shape: (516, 6)\n",
      "\n",
      "Processing input length: 360\n",
      "  X_train shape: (6137, 360, 1), y_train shape: (6137, 6)\n",
      "  X_val shape: (747, 360, 1), y_val shape: (747, 6)\n",
      "  X_test shape: (444, 360, 1), y_test shape: (444, 6)\n",
      "\n",
      "Processing input length: 384\n",
      "  X_train shape: (6065, 384, 1), y_train shape: (6065, 6)\n",
      "  X_val shape: (675, 384, 1), y_val shape: (675, 6)\n",
      "  X_test shape: (390, 384, 1), y_test shape: (390, 6)\n",
      "\n",
      "Processing input length: 408\n",
      "  X_train shape: (5993, 408, 1), y_train shape: (5993, 6)\n",
      "  X_val shape: (603, 408, 1), y_val shape: (603, 6)\n",
      "  X_test shape: (342, 408, 1), y_test shape: (342, 6)\n",
      "\n",
      "Processing input length: 432\n",
      "  X_train shape: (5921, 432, 1), y_train shape: (5921, 6)\n",
      "  X_val shape: (531, 432, 1), y_val shape: (531, 6)\n",
      "  X_test shape: (311, 432, 1), y_test shape: (311, 6)\n",
      "\n",
      "Processing input length: 456\n",
      "  X_train shape: (5849, 456, 1), y_train shape: (5849, 6)\n",
      "  X_val shape: (459, 456, 1), y_val shape: (459, 6)\n",
      "  X_test shape: (287, 456, 1), y_test shape: (287, 6)\n",
      "\n",
      "Processing input length: 480\n",
      "  X_train shape: (5777, 480, 1), y_train shape: (5777, 6)\n",
      "  X_val shape: (387, 480, 1), y_val shape: (387, 6)\n",
      "  X_test shape: (263, 480, 1), y_test shape: (263, 6)\n",
      "\n",
      "Processing input length: 504\n",
      "  X_train shape: (5705, 504, 1), y_train shape: (5705, 6)\n",
      "  X_val shape: (333, 504, 1), y_val shape: (333, 6)\n",
      "  X_test shape: (239, 504, 1), y_test shape: (239, 6)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "data_dict = defaultdict(dict)\n",
    "\n",
    "for length in input_lengths:\n",
    "    print(f\"Processing input length: {length}\")\n",
    "    \n",
    "    # Create sequences with forecast_horizon=6\n",
    "    X_train, y_train = create_sequences(train_set, length, forecast_horizon=6)\n",
    "    X_val, y_val = create_sequences(valid_set, length, forecast_horizon=6)\n",
    "    X_test, y_test = create_sequences(test_set, length, forecast_horizon=6)\n",
    "    \n",
    "    # Store in the dictionary\n",
    "    data_dict[length]['X_train'] = X_train\n",
    "    data_dict[length]['y_train'] = y_train\n",
    "    data_dict[length]['X_val'] = X_val\n",
    "    data_dict[length]['y_val'] = y_val\n",
    "    data_dict[length]['X_test'] = X_test\n",
    "    data_dict[length]['y_test'] = y_test\n",
    "    \n",
    "    # Print shapes and ensure no NaNs\n",
    "    print(f\"  X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "    print(f\"  X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
    "    print(f\"  X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Build LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(hyperparams, input_length):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=hyperparams['units'], activation='tanh', input_shape=(input_length, 1)))\n",
    "    model.add(Dropout(rate=hyperparams['dropout']))\n",
    "    model.add(Dense(6))  # Output layer for multi-step forecasting\n",
    "\n",
    "    # Compile the model with MSE as the loss function\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=hyperparams['learning_rate'])\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mse'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_improved_lstm_model(hyperparams, input_length):\n",
    "    \"\"\"\n",
    "    Builds an improved LSTM model based on provided hyperparameters and input length.\n",
    "\n",
    "    Parameters:\n",
    "    - hyperparams: dict containing 'units', 'dropout', 'learning_rate', and optionally 'recurrent_dropout'.\n",
    "    - input_length: int, length of the input sequences.\n",
    "\n",
    "    Returns:\n",
    "    - model: compiled Keras model ready for training.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    # First LSTM layer with return_sequences=True to stack another LSTM layer\n",
    "    model.add(LSTM(\n",
    "        units=hyperparams['units'], \n",
    "        activation='tanh', \n",
    "        input_shape=(input_length, 1), \n",
    "        return_sequences=True, \n",
    "        #recurrent_dropout=hyperparams.get('recurrent_dropout', 0.0)\n",
    "    ))\n",
    "    model.add(Dropout(rate=hyperparams['dropout']))\n",
    "    \n",
    "    # Second LSTM layer\n",
    "    model.add(LSTM(\n",
    "        units=hyperparams['units'], \n",
    "        activation='tanh',\n",
    "        #recurrent_dropout=hyperparams.get('recurrent_dropout', 0.0)\n",
    "    ))\n",
    "    model.add(Dropout(rate=hyperparams['dropout']))\n",
    "    \n",
    "    # Output layer for multi-step forecasting\n",
    "    model.add(Dense(6))\n",
    "    \n",
    "    # Compile the model with MSE as the loss function\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=hyperparams['learning_rate'])\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mse'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Define the hyperparameter grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter options\n",
    "units_list = [32, 64, 128, 256]\n",
    "dropout_rates = [0.0, 0.1, 0.2, 0.3, 0.4]\n",
    "learning_rates = [0.01, 0.001, 0.0005]\n",
    "batch_sizes = [32, 64, 128]\n",
    "\n",
    "# Create all possible combinations\n",
    "all_combinations = list(product(units_list, dropout_rates, learning_rates, batch_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(32, 0.0, 0.01, 32),\n",
       " (32, 0.0, 0.01, 64),\n",
       " (32, 0.0, 0.01, 128),\n",
       " (32, 0.0, 0.001, 32),\n",
       " (32, 0.0, 0.001, 64),\n",
       " (32, 0.0, 0.001, 128),\n",
       " (32, 0.0, 0.0005, 32),\n",
       " (32, 0.0, 0.0005, 64),\n",
       " (32, 0.0, 0.0005, 128),\n",
       " (32, 0.1, 0.01, 32),\n",
       " (32, 0.1, 0.01, 64),\n",
       " (32, 0.1, 0.01, 128),\n",
       " (32, 0.1, 0.001, 32),\n",
       " (32, 0.1, 0.001, 64),\n",
       " (32, 0.1, 0.001, 128),\n",
       " (32, 0.1, 0.0005, 32),\n",
       " (32, 0.1, 0.0005, 64),\n",
       " (32, 0.1, 0.0005, 128),\n",
       " (32, 0.2, 0.01, 32),\n",
       " (32, 0.2, 0.01, 64),\n",
       " (32, 0.2, 0.01, 128),\n",
       " (32, 0.2, 0.001, 32),\n",
       " (32, 0.2, 0.001, 64),\n",
       " (32, 0.2, 0.001, 128),\n",
       " (32, 0.2, 0.0005, 32),\n",
       " (32, 0.2, 0.0005, 64),\n",
       " (32, 0.2, 0.0005, 128),\n",
       " (32, 0.3, 0.01, 32),\n",
       " (32, 0.3, 0.01, 64),\n",
       " (32, 0.3, 0.01, 128),\n",
       " (32, 0.3, 0.001, 32),\n",
       " (32, 0.3, 0.001, 64),\n",
       " (32, 0.3, 0.001, 128),\n",
       " (32, 0.3, 0.0005, 32),\n",
       " (32, 0.3, 0.0005, 64),\n",
       " (32, 0.3, 0.0005, 128),\n",
       " (32, 0.4, 0.01, 32),\n",
       " (32, 0.4, 0.01, 64),\n",
       " (32, 0.4, 0.01, 128),\n",
       " (32, 0.4, 0.001, 32),\n",
       " (32, 0.4, 0.001, 64),\n",
       " (32, 0.4, 0.001, 128),\n",
       " (32, 0.4, 0.0005, 32),\n",
       " (32, 0.4, 0.0005, 64),\n",
       " (32, 0.4, 0.0005, 128),\n",
       " (64, 0.0, 0.01, 32),\n",
       " (64, 0.0, 0.01, 64),\n",
       " (64, 0.0, 0.01, 128),\n",
       " (64, 0.0, 0.001, 32),\n",
       " (64, 0.0, 0.001, 64),\n",
       " (64, 0.0, 0.001, 128),\n",
       " (64, 0.0, 0.0005, 32),\n",
       " (64, 0.0, 0.0005, 64),\n",
       " (64, 0.0, 0.0005, 128),\n",
       " (64, 0.1, 0.01, 32),\n",
       " (64, 0.1, 0.01, 64),\n",
       " (64, 0.1, 0.01, 128),\n",
       " (64, 0.1, 0.001, 32),\n",
       " (64, 0.1, 0.001, 64),\n",
       " (64, 0.1, 0.001, 128),\n",
       " (64, 0.1, 0.0005, 32),\n",
       " (64, 0.1, 0.0005, 64),\n",
       " (64, 0.1, 0.0005, 128),\n",
       " (64, 0.2, 0.01, 32),\n",
       " (64, 0.2, 0.01, 64),\n",
       " (64, 0.2, 0.01, 128),\n",
       " (64, 0.2, 0.001, 32),\n",
       " (64, 0.2, 0.001, 64),\n",
       " (64, 0.2, 0.001, 128),\n",
       " (64, 0.2, 0.0005, 32),\n",
       " (64, 0.2, 0.0005, 64),\n",
       " (64, 0.2, 0.0005, 128),\n",
       " (64, 0.3, 0.01, 32),\n",
       " (64, 0.3, 0.01, 64),\n",
       " (64, 0.3, 0.01, 128),\n",
       " (64, 0.3, 0.001, 32),\n",
       " (64, 0.3, 0.001, 64),\n",
       " (64, 0.3, 0.001, 128),\n",
       " (64, 0.3, 0.0005, 32),\n",
       " (64, 0.3, 0.0005, 64),\n",
       " (64, 0.3, 0.0005, 128),\n",
       " (64, 0.4, 0.01, 32),\n",
       " (64, 0.4, 0.01, 64),\n",
       " (64, 0.4, 0.01, 128),\n",
       " (64, 0.4, 0.001, 32),\n",
       " (64, 0.4, 0.001, 64),\n",
       " (64, 0.4, 0.001, 128),\n",
       " (64, 0.4, 0.0005, 32),\n",
       " (64, 0.4, 0.0005, 64),\n",
       " (64, 0.4, 0.0005, 128),\n",
       " (128, 0.0, 0.01, 32),\n",
       " (128, 0.0, 0.01, 64),\n",
       " (128, 0.0, 0.01, 128),\n",
       " (128, 0.0, 0.001, 32),\n",
       " (128, 0.0, 0.001, 64),\n",
       " (128, 0.0, 0.001, 128),\n",
       " (128, 0.0, 0.0005, 32),\n",
       " (128, 0.0, 0.0005, 64),\n",
       " (128, 0.0, 0.0005, 128),\n",
       " (128, 0.1, 0.01, 32),\n",
       " (128, 0.1, 0.01, 64),\n",
       " (128, 0.1, 0.01, 128),\n",
       " (128, 0.1, 0.001, 32),\n",
       " (128, 0.1, 0.001, 64),\n",
       " (128, 0.1, 0.001, 128),\n",
       " (128, 0.1, 0.0005, 32),\n",
       " (128, 0.1, 0.0005, 64),\n",
       " (128, 0.1, 0.0005, 128),\n",
       " (128, 0.2, 0.01, 32),\n",
       " (128, 0.2, 0.01, 64),\n",
       " (128, 0.2, 0.01, 128),\n",
       " (128, 0.2, 0.001, 32),\n",
       " (128, 0.2, 0.001, 64),\n",
       " (128, 0.2, 0.001, 128),\n",
       " (128, 0.2, 0.0005, 32),\n",
       " (128, 0.2, 0.0005, 64),\n",
       " (128, 0.2, 0.0005, 128),\n",
       " (128, 0.3, 0.01, 32),\n",
       " (128, 0.3, 0.01, 64),\n",
       " (128, 0.3, 0.01, 128),\n",
       " (128, 0.3, 0.001, 32),\n",
       " (128, 0.3, 0.001, 64),\n",
       " (128, 0.3, 0.001, 128),\n",
       " (128, 0.3, 0.0005, 32),\n",
       " (128, 0.3, 0.0005, 64),\n",
       " (128, 0.3, 0.0005, 128),\n",
       " (128, 0.4, 0.01, 32),\n",
       " (128, 0.4, 0.01, 64),\n",
       " (128, 0.4, 0.01, 128),\n",
       " (128, 0.4, 0.001, 32),\n",
       " (128, 0.4, 0.001, 64),\n",
       " (128, 0.4, 0.001, 128),\n",
       " (128, 0.4, 0.0005, 32),\n",
       " (128, 0.4, 0.0005, 64),\n",
       " (128, 0.4, 0.0005, 128),\n",
       " (256, 0.0, 0.01, 32),\n",
       " (256, 0.0, 0.01, 64),\n",
       " (256, 0.0, 0.01, 128),\n",
       " (256, 0.0, 0.001, 32),\n",
       " (256, 0.0, 0.001, 64),\n",
       " (256, 0.0, 0.001, 128),\n",
       " (256, 0.0, 0.0005, 32),\n",
       " (256, 0.0, 0.0005, 64),\n",
       " (256, 0.0, 0.0005, 128),\n",
       " (256, 0.1, 0.01, 32),\n",
       " (256, 0.1, 0.01, 64),\n",
       " (256, 0.1, 0.01, 128),\n",
       " (256, 0.1, 0.001, 32),\n",
       " (256, 0.1, 0.001, 64),\n",
       " (256, 0.1, 0.001, 128),\n",
       " (256, 0.1, 0.0005, 32),\n",
       " (256, 0.1, 0.0005, 64),\n",
       " (256, 0.1, 0.0005, 128),\n",
       " (256, 0.2, 0.01, 32),\n",
       " (256, 0.2, 0.01, 64),\n",
       " (256, 0.2, 0.01, 128),\n",
       " (256, 0.2, 0.001, 32),\n",
       " (256, 0.2, 0.001, 64),\n",
       " (256, 0.2, 0.001, 128),\n",
       " (256, 0.2, 0.0005, 32),\n",
       " (256, 0.2, 0.0005, 64),\n",
       " (256, 0.2, 0.0005, 128),\n",
       " (256, 0.3, 0.01, 32),\n",
       " (256, 0.3, 0.01, 64),\n",
       " (256, 0.3, 0.01, 128),\n",
       " (256, 0.3, 0.001, 32),\n",
       " (256, 0.3, 0.001, 64),\n",
       " (256, 0.3, 0.001, 128),\n",
       " (256, 0.3, 0.0005, 32),\n",
       " (256, 0.3, 0.0005, 64),\n",
       " (256, 0.3, 0.0005, 128),\n",
       " (256, 0.4, 0.01, 32),\n",
       " (256, 0.4, 0.01, 64),\n",
       " (256, 0.4, 0.01, 128),\n",
       " (256, 0.4, 0.001, 32),\n",
       " (256, 0.4, 0.001, 64),\n",
       " (256, 0.4, 0.001, 128),\n",
       " (256, 0.4, 0.0005, 32),\n",
       " (256, 0.4, 0.0005, 64),\n",
       " (256, 0.4, 0.0005, 128)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Defining manual grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting grid search for input length: 48\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-31 16:40:16.972835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22266 MB memory:  -> device: 0, name: NVIDIA A30, pci bus id: 276f:00:00.0, compute capability: 8.0\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-10-31 16:40:20.616431: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00451\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00455\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00455\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00450\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 86: early stopping\n",
      "Restoring model weights from the end of the best epoch: 66.\n",
      "Validation loss: 0.00456\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00456\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 79: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Validation loss: 0.00457\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 93: early stopping\n",
      "Restoring model weights from the end of the best epoch: 73.\n",
      "Validation loss: 0.00469\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00443\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00443\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00454\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.00460\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 98.\n",
      "Validation loss: 0.00441\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 90: early stopping\n",
      "Restoring model weights from the end of the best epoch: 70.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 93: early stopping\n",
      "Restoring model weights from the end of the best epoch: 73.\n",
      "Validation loss: 0.00464\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00452\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 72: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.00447\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 87: early stopping\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "Validation loss: 0.00443\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 83: early stopping\n",
      "Restoring model weights from the end of the best epoch: 63.\n",
      "Validation loss: 0.00455\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 100.\n",
      "Validation loss: 0.00453\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00449\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00448\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.00443\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 75: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.00448\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.00450\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 84.\n",
      "Validation loss: 0.00457\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 92.\n",
      "Validation loss: 0.00459\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 79: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Validation loss: 0.00447\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 75: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 86.\n",
      "Validation loss: 0.00455\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 91.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 90.\n",
      "Validation loss: 0.00451\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 93.\n",
      "Validation loss: 0.00457\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00435\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00448\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00451\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.00458\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00450\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00457\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 79: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Validation loss: 0.00465\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00442\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.00440\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 85: early stopping\n",
      "Restoring model weights from the end of the best epoch: 65.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00451\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 89: early stopping\n",
      "Restoring model weights from the end of the best epoch: 69.\n",
      "Validation loss: 0.00450\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 100.\n",
      "Validation loss: 0.00456\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00441\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00447\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00441\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 77: early stopping\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "Validation loss: 0.00456\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 89.\n",
      "Validation loss: 0.00456\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00443\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00447\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 82: early stopping\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "Validation loss: 0.00447\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00448\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 90: early stopping\n",
      "Restoring model weights from the end of the best epoch: 70.\n",
      "Validation loss: 0.00450\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 89: early stopping\n",
      "Restoring model weights from the end of the best epoch: 69.\n",
      "Validation loss: 0.00451\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00441\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.00448\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 83: early stopping\n",
      "Restoring model weights from the end of the best epoch: 63.\n",
      "Validation loss: 0.00443\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 85: early stopping\n",
      "Restoring model weights from the end of the best epoch: 65.\n",
      "Validation loss: 0.00451\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 99: early stopping\n",
      "Restoring model weights from the end of the best epoch: 79.\n",
      "Validation loss: 0.00451\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00448\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00451\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00449\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00455\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00460\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00459\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00435\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00435\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00442\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00447\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00442\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 84: early stopping\n",
      "Restoring model weights from the end of the best epoch: 64.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.00443\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00441\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 85.\n",
      "Validation loss: 0.00453\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00449\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00440\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 78: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.00443\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 72: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.00441\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 87: early stopping\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00440\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00442\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00440\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 72: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.00443\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 86: early stopping\n",
      "Restoring model weights from the end of the best epoch: 66.\n",
      "Validation loss: 0.00447\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00450\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.01601\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.01589\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00441\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00443\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00447\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00451\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00454\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 96.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00442\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.00442\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00454\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00450\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.01386\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00440\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00451\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 79: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00455\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00451\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00447\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.01578\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00854\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00443\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00443\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00443\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00435\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00444\n",
      "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Completed grid search for input length: 48\n",
      "  Best Validation MSE: 0.00425\n",
      "  Best Hyperparameters: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "\n",
      "Starting grid search for input length: 72\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 71: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.00442\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 82.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 71: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.00452\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 84: early stopping\n",
      "Restoring model weights from the end of the best epoch: 64.\n",
      "Validation loss: 0.00448\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 89.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 93: early stopping\n",
      "Restoring model weights from the end of the best epoch: 73.\n",
      "Validation loss: 0.00442\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 80: early stopping\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00463\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 98: early stopping\n",
      "Restoring model weights from the end of the best epoch: 78.\n",
      "Validation loss: 0.00455\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00435\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 82: early stopping\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 91.\n",
      "Validation loss: 0.00452\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 83.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 86.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 100.\n",
      "Validation loss: 0.00448\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00435\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 79: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.00443\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 86.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00452\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 94.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 96.\n",
      "Validation loss: 0.00457\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00441\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00459\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 82.\n",
      "Validation loss: 0.00449\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 97.\n",
      "Validation loss: 0.00450\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 97: early stopping\n",
      "Restoring model weights from the end of the best epoch: 77.\n",
      "Validation loss: 0.00454\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 91.\n",
      "Validation loss: 0.00449\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00435\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00449\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00447\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 89: early stopping\n",
      "Restoring model weights from the end of the best epoch: 69.\n",
      "Validation loss: 0.00450\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00441\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00441\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 78: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 83: early stopping\n",
      "Restoring model weights from the end of the best epoch: 63.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 82: early stopping\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "Validation loss: 0.00462\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00442\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 75: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 81: early stopping\n",
      "Restoring model weights from the end of the best epoch: 61.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 86: early stopping\n",
      "Restoring model weights from the end of the best epoch: 66.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 83.\n",
      "Validation loss: 0.00456\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00443\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 75: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 94: early stopping\n",
      "Restoring model weights from the end of the best epoch: 74.\n",
      "Validation loss: 0.00441\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 81: early stopping\n",
      "Restoring model weights from the end of the best epoch: 61.\n",
      "Validation loss: 0.00447\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00466\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00448\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00454\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 71: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.00442\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 82.\n",
      "Validation loss: 0.00448\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00442\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00448\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00447\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00454\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.00442\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00435\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 77: early stopping\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "Validation loss: 0.00450\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00442\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 75: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.00441\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 78: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Validation loss: 0.00447\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00440\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 75: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.00442\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 77: early stopping\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 72: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00435\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 87.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 93.\n",
      "Validation loss: 0.00441\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00478\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.01654\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 72: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00419\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00449\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.01574\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.01609\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00440\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00435\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 96.\n",
      "Validation loss: 0.00462\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00443\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 84: early stopping\n",
      "Restoring model weights from the end of the best epoch: 64.\n",
      "Validation loss: 0.00435\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.01049\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00443\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 86.\n",
      "Validation loss: 0.00439\n",
      "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "Completed grid search for input length: 72\n",
      "  Best Validation MSE: 0.00419\n",
      "  Best Hyperparameters: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "\n",
      "Starting grid search for input length: 96\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.00442\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.00454\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 98: early stopping\n",
      "Restoring model weights from the end of the best epoch: 78.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 95.\n",
      "Validation loss: 0.00453\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 84: early stopping\n",
      "Restoring model weights from the end of the best epoch: 64.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 87.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 84: early stopping\n",
      "Restoring model weights from the end of the best epoch: 64.\n",
      "Validation loss: 0.00435\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 99.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 97.\n",
      "Validation loss: 0.00450\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 87: early stopping\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 98: early stopping\n",
      "Restoring model weights from the end of the best epoch: 78.\n",
      "Validation loss: 0.00443\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 89.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 92.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 98.\n",
      "Validation loss: 0.00456\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 98: early stopping\n",
      "Restoring model weights from the end of the best epoch: 78.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 94.\n",
      "Validation loss: 0.00435\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 84.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 100: early stopping\n",
      "Restoring model weights from the end of the best epoch: 80.\n",
      "Validation loss: 0.00447\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 95.\n",
      "Validation loss: 0.00460\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 79: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00450\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 97.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 84: early stopping\n",
      "Restoring model weights from the end of the best epoch: 64.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 88.\n",
      "Validation loss: 0.00453\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 94: early stopping\n",
      "Restoring model weights from the end of the best epoch: 74.\n",
      "Validation loss: 0.00462\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00442\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 100: early stopping\n",
      "Restoring model weights from the end of the best epoch: 80.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00443\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 82: early stopping\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 91: early stopping\n",
      "Restoring model weights from the end of the best epoch: 71.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 94.\n",
      "Validation loss: 0.00443\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00413\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00447\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00421\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 81.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 91: early stopping\n",
      "Restoring model weights from the end of the best epoch: 71.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 100: early stopping\n",
      "Restoring model weights from the end of the best epoch: 80.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00422\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 86: early stopping\n",
      "Restoring model weights from the end of the best epoch: 66.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 78: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Validation loss: 0.00443\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 85: early stopping\n",
      "Restoring model weights from the end of the best epoch: 65.\n",
      "Validation loss: 0.00448\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00460\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00441\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 79: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 99: early stopping\n",
      "Restoring model weights from the end of the best epoch: 79.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 90.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 85: early stopping\n",
      "Restoring model weights from the end of the best epoch: 65.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00455\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.00459\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00442\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00441\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 84: early stopping\n",
      "Restoring model weights from the end of the best epoch: 64.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00450\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 81: early stopping\n",
      "Restoring model weights from the end of the best epoch: 61.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 100.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00419\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 77: early stopping\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 80: early stopping\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 83: early stopping\n",
      "Restoring model weights from the end of the best epoch: 63.\n",
      "Validation loss: 0.00447\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 88: early stopping\n",
      "Restoring model weights from the end of the best epoch: 68.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00448\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00493\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 95.\n",
      "Validation loss: 0.01006\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.01596\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00435\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00441\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 97: early stopping\n",
      "Restoring model weights from the end of the best epoch: 77.\n",
      "Validation loss: 0.00435\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.01084\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 87: early stopping\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.01047\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.01539\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 84: early stopping\n",
      "Restoring model weights from the end of the best epoch: 64.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00435\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.01595\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 75: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.00443\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Completed grid search for input length: 96\n",
      "  Best Validation MSE: 0.00413\n",
      "  Best Hyperparameters: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "\n",
      "Starting grid search for input length: 120\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00414\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00410\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00419\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 78: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 97.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 90.\n",
      "Validation loss: 0.00422\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 83.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00419\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00410\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.00411\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 83: early stopping\n",
      "Restoring model weights from the end of the best epoch: 63.\n",
      "Validation loss: 0.00409\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 95.\n",
      "Validation loss: 0.00419\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 89.\n",
      "Validation loss: 0.00414\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 92.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 94.\n",
      "Validation loss: 0.00447\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00419\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00409\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00419\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 77: early stopping\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "Validation loss: 0.00404\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 84.\n",
      "Validation loss: 0.00405\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 81.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 96.\n",
      "Validation loss: 0.00409\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 95.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 90.\n",
      "Validation loss: 0.00440\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00409\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 85.\n",
      "Validation loss: 0.00404\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 94.\n",
      "Validation loss: 0.00409\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 88.\n",
      "Validation loss: 0.00421\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 97.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 86.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 95.\n",
      "Validation loss: 0.00440\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00415\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00414\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 82: early stopping\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 80: early stopping\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00469\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.00440\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 87.\n",
      "Validation loss: 0.00440\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 83.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 77: early stopping\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 78: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Validation loss: 0.00435\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 95: early stopping\n",
      "Restoring model weights from the end of the best epoch: 75.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00410\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00412\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 78: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Validation loss: 0.00422\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 94: early stopping\n",
      "Restoring model weights from the end of the best epoch: 74.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00413\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00413\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 97: early stopping\n",
      "Restoring model weights from the end of the best epoch: 77.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 85.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 95.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00412\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00414\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 77: early stopping\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 85: early stopping\n",
      "Restoring model weights from the end of the best epoch: 65.\n",
      "Validation loss: 0.00421\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 96.\n",
      "Validation loss: 0.00413\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 99.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00412\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00413\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00421\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 88: early stopping\n",
      "Restoring model weights from the end of the best epoch: 68.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 88.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 75: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 79: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 89.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00413\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00435\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 77: early stopping\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "Validation loss: 0.00421\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00406\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00422\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00415\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 72: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.00419\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 88: early stopping\n",
      "Restoring model weights from the end of the best epoch: 68.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00421\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00422\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00415\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00419\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 96: early stopping\n",
      "Restoring model weights from the end of the best epoch: 76.\n",
      "Validation loss: 0.00411\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 84: early stopping\n",
      "Restoring model weights from the end of the best epoch: 64.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00411\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00413\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 75: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00414\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 93.\n",
      "Validation loss: 0.00414\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00411\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00413\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00409\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00414\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 83.\n",
      "Validation loss: 0.00413\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 87: early stopping\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.00560\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 100.\n",
      "Validation loss: 0.00448\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00419\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00422\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00411\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.01624\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00408\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00413\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.00414\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00411\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00492\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.01556\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.01590\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.00414\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00419\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 81: early stopping\n",
      "Restoring model weights from the end of the best epoch: 61.\n",
      "Validation loss: 0.00413\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 99.\n",
      "Validation loss: 0.00450\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00422\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00413\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 84: early stopping\n",
      "Restoring model weights from the end of the best epoch: 64.\n",
      "Validation loss: 0.00411\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00414\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 79: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Validation loss: 0.00410\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 97: early stopping\n",
      "Restoring model weights from the end of the best epoch: 77.\n",
      "Validation loss: 0.00425\n",
      "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Completed grid search for input length: 120\n",
      "  Best Validation MSE: 0.00404\n",
      "  Best Hyperparameters: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "\n",
      "Starting grid search for input length: 144\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00415\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.00422\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 94.\n",
      "Validation loss: 0.00435\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 90: early stopping\n",
      "Restoring model weights from the end of the best epoch: 70.\n",
      "Validation loss: 0.00421\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 97.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 90: early stopping\n",
      "Restoring model weights from the end of the best epoch: 70.\n",
      "Validation loss: 0.00456\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00422\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00410\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 71: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 86.\n",
      "Validation loss: 0.00413\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 80: early stopping\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "Validation loss: 0.00443\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 81: early stopping\n",
      "Restoring model weights from the end of the best epoch: 61.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 95.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 94.\n",
      "Validation loss: 0.00454\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00422\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00414\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00421\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 85.\n",
      "Validation loss: 0.00421\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 94.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00447\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 89.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 88.\n",
      "Validation loss: 0.00453\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00414\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00414\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 86.\n",
      "Validation loss: 0.00421\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 97: early stopping\n",
      "Restoring model weights from the end of the best epoch: 77.\n",
      "Validation loss: 0.00440\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 98.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 100.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 93.\n",
      "Validation loss: 0.00462\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00415\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 98: early stopping\n",
      "Restoring model weights from the end of the best epoch: 78.\n",
      "Validation loss: 0.00422\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 95: early stopping\n",
      "Restoring model weights from the end of the best epoch: 75.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 92.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 86.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 94.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 90.\n",
      "Validation loss: 0.00464\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00413\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 96: early stopping\n",
      "Restoring model weights from the end of the best epoch: 76.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 85.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00407\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00422\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00421\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 71: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 85.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 92.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 85: early stopping\n",
      "Restoring model weights from the end of the best epoch: 65.\n",
      "Validation loss: 0.00422\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 75: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 99: early stopping\n",
      "Restoring model weights from the end of the best epoch: 79.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 95: early stopping\n",
      "Restoring model weights from the end of the best epoch: 75.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.00409\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00408\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 97.\n",
      "Validation loss: 0.00414\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.00447\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 84.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00449\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 87.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.00411\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.00422\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 96: early stopping\n",
      "Restoring model weights from the end of the best epoch: 76.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 98: early stopping\n",
      "Restoring model weights from the end of the best epoch: 78.\n",
      "Validation loss: 0.00414\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 100: early stopping\n",
      "Restoring model weights from the end of the best epoch: 80.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 98.\n",
      "Validation loss: 0.00454\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00458\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00413\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 82.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00461\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 89: early stopping\n",
      "Restoring model weights from the end of the best epoch: 69.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 84.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 100: early stopping\n",
      "Restoring model weights from the end of the best epoch: 80.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00452\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00404\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00421\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 99: early stopping\n",
      "Restoring model weights from the end of the best epoch: 79.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.00422\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 93: early stopping\n",
      "Restoring model weights from the end of the best epoch: 73.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 99: early stopping\n",
      "Restoring model weights from the end of the best epoch: 79.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00409\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00405\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 75: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.00414\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00435\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 88: early stopping\n",
      "Restoring model weights from the end of the best epoch: 68.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.01822\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.01103\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.01276\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00421\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00447\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00415\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00421\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 92: early stopping\n",
      "Restoring model weights from the end of the best epoch: 72.\n",
      "Validation loss: 0.00435\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.01589\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00472\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00421\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 86: early stopping\n",
      "Restoring model weights from the end of the best epoch: 66.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00415\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.01386\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.01176\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 71: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00419\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 71: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.00444\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Completed grid search for input length: 144\n",
      "  Best Validation MSE: 0.00404\n",
      "  Best Hyperparameters: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "\n",
      "Starting grid search for input length: 168\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00419\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 81.\n",
      "Validation loss: 0.00419\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 81.\n",
      "Validation loss: 0.00412\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 86.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 99.\n",
      "Validation loss: 0.00443\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 84: early stopping\n",
      "Restoring model weights from the end of the best epoch: 64.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 88: early stopping\n",
      "Restoring model weights from the end of the best epoch: 68.\n",
      "Validation loss: 0.00447\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 100: early stopping\n",
      "Restoring model weights from the end of the best epoch: 80.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 84: early stopping\n",
      "Restoring model weights from the end of the best epoch: 64.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 98.\n",
      "Validation loss: 0.00451\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 82: early stopping\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 84.\n",
      "Validation loss: 0.00421\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 97.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 98.\n",
      "Validation loss: 0.00422\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 82.\n",
      "Validation loss: 0.00447\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 98.\n",
      "Validation loss: 0.00452\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 82.\n",
      "Validation loss: 0.00415\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 95: early stopping\n",
      "Restoring model weights from the end of the best epoch: 75.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 98.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 77: early stopping\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "Validation loss: 0.00448\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 98.\n",
      "Validation loss: 0.00443\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.00468\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 86.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 88.\n",
      "Validation loss: 0.00442\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 90.\n",
      "Validation loss: 0.00441\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 94.\n",
      "Validation loss: 0.00443\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 97.\n",
      "Validation loss: 0.00447\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 87.\n",
      "Validation loss: 0.00464\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00448\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00440\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 79: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 95.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00413\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 99: early stopping\n",
      "Restoring model weights from the end of the best epoch: 79.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.00456\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00422\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 90.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 87.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 82: early stopping\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "Validation loss: 0.00449\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00421\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.00414\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 78: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Validation loss: 0.00415\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 83.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 75: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 75: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.00450\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00412\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 75: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 92: early stopping\n",
      "Restoring model weights from the end of the best epoch: 72.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.00441\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 88: early stopping\n",
      "Restoring model weights from the end of the best epoch: 68.\n",
      "Validation loss: 0.00451\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00442\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00442\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00448\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00421\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00421\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 89: early stopping\n",
      "Restoring model weights from the end of the best epoch: 69.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 71: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.00440\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00441\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 83: early stopping\n",
      "Restoring model weights from the end of the best epoch: 63.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00441\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 94.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00448\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 71: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 88.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00451\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 94: early stopping\n",
      "Restoring model weights from the end of the best epoch: 74.\n",
      "Validation loss: 0.00918\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00419\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00440\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00772\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.01676\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.01283\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00788\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 82: early stopping\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.01641\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00440\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.01647\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00435\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 93: early stopping\n",
      "Restoring model weights from the end of the best epoch: 73.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.01310\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00422\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 71: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 72: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.00441\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Completed grid search for input length: 168\n",
      "  Best Validation MSE: 0.00412\n",
      "  Best Hyperparameters: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "\n",
      "Starting grid search for input length: 192\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00411\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 89: early stopping\n",
      "Restoring model weights from the end of the best epoch: 69.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 91: early stopping\n",
      "Restoring model weights from the end of the best epoch: 71.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 96.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 100.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00410\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00419\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00422\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 80: early stopping\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "Validation loss: 0.00419\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 94.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 94.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 95.\n",
      "Validation loss: 0.00448\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00413\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00467\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 99.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00448\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 87.\n",
      "Validation loss: 0.00442\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00413\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 83: early stopping\n",
      "Restoring model weights from the end of the best epoch: 63.\n",
      "Validation loss: 0.00414\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 96.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 99.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00443\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.00462\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00414\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00414\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00415\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 80: early stopping\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00440\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 99.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00467\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00458\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 97.\n",
      "Validation loss: 0.00456\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00422\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 79: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 92.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00435\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00422\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 92: early stopping\n",
      "Restoring model weights from the end of the best epoch: 72.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00448\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 89.\n",
      "Validation loss: 0.00413\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 100.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00410\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00402\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 97: early stopping\n",
      "Restoring model weights from the end of the best epoch: 77.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.00414\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 83.\n",
      "Validation loss: 0.00410\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 94: early stopping\n",
      "Restoring model weights from the end of the best epoch: 74.\n",
      "Validation loss: 0.00441\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00405\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.00421\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 79: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Validation loss: 0.00441\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00457\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00408\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00411\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.00415\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00440\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00435\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 96: early stopping\n",
      "Restoring model weights from the end of the best epoch: 76.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 99: early stopping\n",
      "Restoring model weights from the end of the best epoch: 79.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00419\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00435\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00447\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 99.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00422\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00422\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00410\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00442\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 87: early stopping\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00414\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00421\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00411\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00413\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.00442\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00419\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.00412\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 75: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00534\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 71: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.00673\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-02 23:22:27.424657: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 4.00GiB (4294967296 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.01034\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00422\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 72: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.01040\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.01642\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.01077\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 72: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00415\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.01643\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.01042\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.01673\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00412\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00447\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 85: early stopping\n",
      "Restoring model weights from the end of the best epoch: 65.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00471\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.01642\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.01638\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00421\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00419\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.00415\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 72: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 99: early stopping\n",
      "Restoring model weights from the end of the best epoch: 79.\n",
      "Validation loss: 0.00431\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Completed grid search for input length: 192\n",
      "  Best Validation MSE: 0.00402\n",
      "  Best Hyperparameters: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "\n",
      "Starting grid search for input length: 216\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00379\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00386\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00385\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00392\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.00389\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 98.\n",
      "Validation loss: 0.00379\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 91: early stopping\n",
      "Restoring model weights from the end of the best epoch: 71.\n",
      "Validation loss: 0.00383\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 94.\n",
      "Validation loss: 0.00397\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 95.\n",
      "Validation loss: 0.00410\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00384\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00384\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00383\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00392\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00386\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 85.\n",
      "Validation loss: 0.00383\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 98: early stopping\n",
      "Restoring model weights from the end of the best epoch: 78.\n",
      "Validation loss: 0.00379\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 97.\n",
      "Validation loss: 0.00380\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 87.\n",
      "Validation loss: 0.00414\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00380\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00380\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00375\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.00375\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 85.\n",
      "Validation loss: 0.00394\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 95.\n",
      "Validation loss: 0.00391\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.00406\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 92.\n",
      "Validation loss: 0.00406\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00389\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00379\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 72: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.00383\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.00385\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 100: early stopping\n",
      "Restoring model weights from the end of the best epoch: 80.\n",
      "Validation loss: 0.00385\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 98.\n",
      "Validation loss: 0.00405\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.00399\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 92.\n",
      "Validation loss: 0.00405\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 90.\n",
      "Validation loss: 0.00414\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00388\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00376\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00387\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 90: early stopping\n",
      "Restoring model weights from the end of the best epoch: 70.\n",
      "Validation loss: 0.00381\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 77: early stopping\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "Validation loss: 0.00405\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 94.\n",
      "Validation loss: 0.00390\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 93.\n",
      "Validation loss: 0.00400\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00385\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00367\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00378\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00385\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00393\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.00386\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.00391\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00407\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 86: early stopping\n",
      "Restoring model weights from the end of the best epoch: 66.\n",
      "Validation loss: 0.00398\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00367\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00380\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00386\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00381\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00386\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.00392\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00379\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 86: early stopping\n",
      "Restoring model weights from the end of the best epoch: 66.\n",
      "Validation loss: 0.00384\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 93: early stopping\n",
      "Restoring model weights from the end of the best epoch: 73.\n",
      "Validation loss: 0.00407\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00371\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00371\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00376\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00374\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00387\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.00393\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.00390\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 91.\n",
      "Validation loss: 0.00385\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 87.\n",
      "Validation loss: 0.00397\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00368\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00360\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00383\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00380\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.00385\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00407\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00395\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 83: early stopping\n",
      "Restoring model weights from the end of the best epoch: 63.\n",
      "Validation loss: 0.00400\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 81.\n",
      "Validation loss: 0.00405\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00382\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00383\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00385\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00380\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 86: early stopping\n",
      "Restoring model weights from the end of the best epoch: 66.\n",
      "Validation loss: 0.00396\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 96: early stopping\n",
      "Restoring model weights from the end of the best epoch: 76.\n",
      "Validation loss: 0.00387\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.00387\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 88: early stopping\n",
      "Restoring model weights from the end of the best epoch: 68.\n",
      "Validation loss: 0.00394\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00378\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00377\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00385\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00395\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00391\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00398\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00398\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00398\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 83: early stopping\n",
      "Restoring model weights from the end of the best epoch: 63.\n",
      "Validation loss: 0.00400\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00358\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00368\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00387\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00384\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00392\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00388\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00392\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00394\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 84: early stopping\n",
      "Restoring model weights from the end of the best epoch: 64.\n",
      "Validation loss: 0.00402\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00374\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00378\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00378\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00369\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00378\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 75: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.00388\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00378\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.00391\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 78: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Validation loss: 0.00407\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00372\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00381\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00380\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00366\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00381\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.00389\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00392\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 80: early stopping\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "Validation loss: 0.00390\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 82: early stopping\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "Validation loss: 0.00403\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00377\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00366\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00398\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00374\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00391\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 90: early stopping\n",
      "Restoring model weights from the end of the best epoch: 70.\n",
      "Validation loss: 0.00389\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00402\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 80: early stopping\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "Validation loss: 0.00391\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 82: early stopping\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "Validation loss: 0.00401\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 100.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.01606\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.01605\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00387\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00394\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00390\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00397\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00392\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00403\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00389\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00372\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.01628\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00387\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00392\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00398\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00385\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00387\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.00385\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00383\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00369\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00372\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00372\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00378\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00391\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00377\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00393\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00384\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.01583\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.01582\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.01461\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00370\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.00376\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00394\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00373\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 81: early stopping\n",
      "Restoring model weights from the end of the best epoch: 61.\n",
      "Validation loss: 0.00383\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 99: early stopping\n",
      "Restoring model weights from the end of the best epoch: 79.\n",
      "Validation loss: 0.00386\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00380\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00374\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.01600\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00383\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00373\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00386\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00378\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 82: early stopping\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "Validation loss: 0.00382\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.00401\n",
      "\u001b[1m39/39\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "\u001b[1m39/39\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m39/39\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\u001b[1m39/39\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Completed grid search for input length: 216\n",
      "  Best Validation MSE: 0.00358\n",
      "  Best Hyperparameters: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "\n",
      "Starting grid search for input length: 240\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00397\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00402\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00389\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00408\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00406\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 90.\n",
      "Validation loss: 0.00402\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 81: early stopping\n",
      "Restoring model weights from the end of the best epoch: 61.\n",
      "Validation loss: 0.00397\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.00411\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 97.\n",
      "Validation loss: 0.00419\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00388\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00387\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00387\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00411\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 71: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.00402\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 88.\n",
      "Validation loss: 0.00399\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 93: early stopping\n",
      "Restoring model weights from the end of the best epoch: 73.\n",
      "Validation loss: 0.00399\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 81.\n",
      "Validation loss: 0.00402\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 81.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00383\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00385\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00384\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 77: early stopping\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "Validation loss: 0.00392\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 82: early stopping\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "Validation loss: 0.00412\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 91.\n",
      "Validation loss: 0.00402\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00414\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 96.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 81.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00404\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00390\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00401\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00405\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 86.\n",
      "Validation loss: 0.00400\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 87: early stopping\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "Validation loss: 0.00413\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 95.\n",
      "Validation loss: 0.00395\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 91.\n",
      "Validation loss: 0.00411\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00435\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00384\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00389\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.00390\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 99: early stopping\n",
      "Restoring model weights from the end of the best epoch: 79.\n",
      "Validation loss: 0.00391\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 85.\n",
      "Validation loss: 0.00402\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 86.\n",
      "Validation loss: 0.00404\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 96.\n",
      "Validation loss: 0.00407\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 94: early stopping\n",
      "Restoring model weights from the end of the best epoch: 74.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00385\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00385\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00383\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00405\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00394\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 81: early stopping\n",
      "Restoring model weights from the end of the best epoch: 61.\n",
      "Validation loss: 0.00411\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00402\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 77: early stopping\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "Validation loss: 0.00402\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 90.\n",
      "Validation loss: 0.00401\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00386\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00391\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00390\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00392\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00394\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00407\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.00404\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 85: early stopping\n",
      "Restoring model weights from the end of the best epoch: 65.\n",
      "Validation loss: 0.00393\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 95.\n",
      "Validation loss: 0.00400\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00380\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.00390\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00395\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00394\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00411\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 81: early stopping\n",
      "Restoring model weights from the end of the best epoch: 61.\n",
      "Validation loss: 0.00405\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 83: early stopping\n",
      "Restoring model weights from the end of the best epoch: 63.\n",
      "Validation loss: 0.00400\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 71: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.00406\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 97: early stopping\n",
      "Restoring model weights from the end of the best epoch: 77.\n",
      "Validation loss: 0.00412\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00396\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00382\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00386\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 79: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Validation loss: 0.00384\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.00393\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00412\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 85: early stopping\n",
      "Restoring model weights from the end of the best epoch: 65.\n",
      "Validation loss: 0.00388\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 96.\n",
      "Validation loss: 0.00399\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 81.\n",
      "Validation loss: 0.00413\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00378\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00386\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00392\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.00400\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 87: early stopping\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "Validation loss: 0.00387\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 99.\n",
      "Validation loss: 0.00400\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 99: early stopping\n",
      "Restoring model weights from the end of the best epoch: 79.\n",
      "Validation loss: 0.00394\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 79: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00386\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00393\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00401\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00386\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00396\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00397\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00401\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00392\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 79: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Validation loss: 0.00411\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00373\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00389\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00391\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00376\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00395\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.00401\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00394\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00405\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 96: early stopping\n",
      "Restoring model weights from the end of the best epoch: 76.\n",
      "Validation loss: 0.00404\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00392\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00381\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00381\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00391\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00392\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00398\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00389\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.00400\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 81: early stopping\n",
      "Restoring model weights from the end of the best epoch: 61.\n",
      "Validation loss: 0.00414\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00395\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00387\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00402\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00388\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00388\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 87: early stopping\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "Validation loss: 0.00394\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00392\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00406\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 83.\n",
      "Validation loss: 0.00400\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00384\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00392\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00393\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00384\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00399\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.00406\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.00383\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 75: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.00401\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 100: early stopping\n",
      "Restoring model weights from the end of the best epoch: 80.\n",
      "Validation loss: 0.00410\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 90: early stopping\n",
      "Restoring model weights from the end of the best epoch: 70.\n",
      "Validation loss: 0.01197\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 83.\n",
      "Validation loss: 0.00383\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.01619\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00394\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00395\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00403\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00395\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00398\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00402\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00392\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.01590\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00374\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00394\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00389\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00394\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00396\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.00406\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00400\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.01596\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00391\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00389\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00390\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.00386\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00396\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00400\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 99: early stopping\n",
      "Restoring model weights from the end of the best epoch: 79.\n",
      "Validation loss: 0.00383\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00404\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00392\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.01597\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00388\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.00386\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 72: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.00396\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.00387\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 87: early stopping\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "Validation loss: 0.00387\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00409\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.01597\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.01595\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 97: early stopping\n",
      "Restoring model weights from the end of the best epoch: 77.\n",
      "Validation loss: 0.00399\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00384\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00386\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00407\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.00387\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.00392\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 81: early stopping\n",
      "Restoring model weights from the end of the best epoch: 61.\n",
      "Validation loss: 0.00404\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "Completed grid search for input length: 240\n",
      "  Best Validation MSE: 0.00373\n",
      "  Best Hyperparameters: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "\n",
      "Starting grid search for input length: 264\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00388\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00391\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00406\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00407\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 80: early stopping\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "Validation loss: 0.00411\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 93: early stopping\n",
      "Restoring model weights from the end of the best epoch: 73.\n",
      "Validation loss: 0.00399\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00421\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 90: early stopping\n",
      "Restoring model weights from the end of the best epoch: 70.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 98.\n",
      "Validation loss: 0.00421\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00406\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00392\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00401\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00400\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 93: early stopping\n",
      "Restoring model weights from the end of the best epoch: 73.\n",
      "Validation loss: 0.00403\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 97: early stopping\n",
      "Restoring model weights from the end of the best epoch: 77.\n",
      "Validation loss: 0.00403\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 84: early stopping\n",
      "Restoring model weights from the end of the best epoch: 64.\n",
      "Validation loss: 0.00406\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 97.\n",
      "Validation loss: 0.00399\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 100.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00403\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00387\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00411\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 72: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.00404\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 85: early stopping\n",
      "Restoring model weights from the end of the best epoch: 65.\n",
      "Validation loss: 0.00414\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 97.\n",
      "Validation loss: 0.00409\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 83.\n",
      "Validation loss: 0.00407\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 93: early stopping\n",
      "Restoring model weights from the end of the best epoch: 73.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 90.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00392\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00394\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.00391\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00410\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 84.\n",
      "Validation loss: 0.00421\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 92.\n",
      "Validation loss: 0.00406\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 90.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 96.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00386\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00396\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00401\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 83.\n",
      "Validation loss: 0.00409\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 94.\n",
      "Validation loss: 0.00407\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00443\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 93.\n",
      "Validation loss: 0.00414\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 92.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00400\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00395\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00405\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00410\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 82: early stopping\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "Validation loss: 0.00409\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00408\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.00415\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 85: early stopping\n",
      "Restoring model weights from the end of the best epoch: 65.\n",
      "Validation loss: 0.00421\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00388\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00404\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00409\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00400\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00410\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 72: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.00413\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00410\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00421\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00386\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00401\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.00398\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00405\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00408\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 77: early stopping\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "Validation loss: 0.00410\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 71: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.00408\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 99: early stopping\n",
      "Restoring model weights from the end of the best epoch: 79.\n",
      "Validation loss: 0.00412\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 97.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00397\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00399\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00407\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00395\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 78: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Validation loss: 0.00406\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 75: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.00414\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 75: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.00405\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 99: early stopping\n",
      "Restoring model weights from the end of the best epoch: 79.\n",
      "Validation loss: 0.00411\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 94: early stopping\n",
      "Restoring model weights from the end of the best epoch: 74.\n",
      "Validation loss: 0.00422\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00389\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00384\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00403\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00408\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00414\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 98: early stopping\n",
      "Restoring model weights from the end of the best epoch: 78.\n",
      "Validation loss: 0.00412\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.00413\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 82: early stopping\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "Validation loss: 0.00419\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 99.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00391\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00402\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00407\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00407\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00403\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00404\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00411\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 87: early stopping\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00400\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00398\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00390\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00406\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00405\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00409\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00412\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00406\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00391\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00408\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00399\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00395\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00400\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00412\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 71: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.00402\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 78: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Validation loss: 0.00411\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 86: early stopping\n",
      "Restoring model weights from the end of the best epoch: 66.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00379\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00409\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00415\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00397\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.00398\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00402\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00412\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 88: early stopping\n",
      "Restoring model weights from the end of the best epoch: 68.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00392\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00401\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00399\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00394\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00402\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.00402\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 82.\n",
      "Validation loss: 0.00410\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 81: early stopping\n",
      "Restoring model weights from the end of the best epoch: 61.\n",
      "Validation loss: 0.00452\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 92: early stopping\n",
      "Restoring model weights from the end of the best epoch: 72.\n",
      "Validation loss: 0.00415\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 87: early stopping\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00407\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00399\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.00404\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00404\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00411\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00412\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00402\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00489\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00400\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00396\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00404\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00400\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00404\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.00407\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.01607\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00479\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00402\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00393\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.00395\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00397\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.00410\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 71: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.00413\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.01575\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00402\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00400\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00405\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 75: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.00401\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00399\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00403\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00415\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.01575\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.01601\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00394\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00397\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.00385\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 83: early stopping\n",
      "Restoring model weights from the end of the best epoch: 63.\n",
      "Validation loss: 0.00403\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.00391\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00402\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 90.\n",
      "Validation loss: 0.00409\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Completed grid search for input length: 264\n",
      "  Best Validation MSE: 0.00379\n",
      "  Best Hyperparameters: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "\n",
      "Starting grid search for input length: 288\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00391\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00389\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00388\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00409\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00402\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 89.\n",
      "Validation loss: 0.00405\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 72: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 92.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00386\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00400\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00391\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00383\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00406\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 95.\n",
      "Validation loss: 0.00400\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 87: early stopping\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "Validation loss: 0.00409\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 95.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00383\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00399\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00396\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 80: early stopping\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "Validation loss: 0.00399\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 95: early stopping\n",
      "Restoring model weights from the end of the best epoch: 75.\n",
      "Validation loss: 0.00395\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 84.\n",
      "Validation loss: 0.00405\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 85: early stopping\n",
      "Restoring model weights from the end of the best epoch: 65.\n",
      "Validation loss: 0.00408\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 96: early stopping\n",
      "Restoring model weights from the end of the best epoch: 76.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 95.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00387\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.00383\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00393\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00407\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 81: early stopping\n",
      "Restoring model weights from the end of the best epoch: 61.\n",
      "Validation loss: 0.00414\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 84.\n",
      "Validation loss: 0.00406\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 95.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 90.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00395\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00397\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00396\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 75: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.00405\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 91.\n",
      "Validation loss: 0.00411\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 99.\n",
      "Validation loss: 0.00412\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 92.\n",
      "Validation loss: 0.00411\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 92.\n",
      "Validation loss: 0.00419\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00391\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00405\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00394\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00404\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00406\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00402\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00402\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.00409\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 88.\n",
      "Validation loss: 0.00409\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00396\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00388\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00390\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.00397\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00399\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.00408\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00415\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 95: early stopping\n",
      "Restoring model weights from the end of the best epoch: 75.\n",
      "Validation loss: 0.00406\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 94.\n",
      "Validation loss: 0.00414\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00389\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00392\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00383\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 72: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.00386\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00399\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00410\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 94.\n",
      "Validation loss: 0.00410\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 87: early stopping\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00393\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00394\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00393\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00386\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 97: early stopping\n",
      "Restoring model weights from the end of the best epoch: 77.\n",
      "Validation loss: 0.00408\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 80: early stopping\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "Validation loss: 0.00411\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 99.\n",
      "Validation loss: 0.00400\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 90.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 81: early stopping\n",
      "Restoring model weights from the end of the best epoch: 61.\n",
      "Validation loss: 0.00385\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.00385\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00391\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00398\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 80: early stopping\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "Validation loss: 0.00398\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 81.\n",
      "Validation loss: 0.00401\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 78: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Validation loss: 0.00406\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 90: early stopping\n",
      "Restoring model weights from the end of the best epoch: 70.\n",
      "Validation loss: 0.00415\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 94.\n",
      "Validation loss: 0.00415\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00381\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00390\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00386\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00404\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00404\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.00407\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00398\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00401\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 77: early stopping\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "Validation loss: 0.00410\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00395\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00401\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00393\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00396\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00390\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.00403\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00399\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.00405\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 88: early stopping\n",
      "Restoring model weights from the end of the best epoch: 68.\n",
      "Validation loss: 0.00410\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00393\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00400\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00405\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00388\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00400\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.00401\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00397\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 80: early stopping\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "Validation loss: 0.00402\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00412\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00395\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00390\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00390\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00400\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 100: early stopping\n",
      "Restoring model weights from the end of the best epoch: 80.\n",
      "Validation loss: 0.00407\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00407\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 79: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Validation loss: 0.00400\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 87.\n",
      "Validation loss: 0.00405\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00397\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00389\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00394\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00402\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00407\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00411\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00412\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.00407\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 95.\n",
      "Validation loss: 0.00408\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.01575\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00400\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.01369\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00393\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00393\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00397\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00399\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00408\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00401\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.01514\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00397\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00407\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00397\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00394\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00387\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00399\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.00395\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.00606\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.01499\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00469\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00409\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00393\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00391\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00392\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 71: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.00396\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 89: early stopping\n",
      "Restoring model weights from the end of the best epoch: 69.\n",
      "Validation loss: 0.00404\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00392\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00398\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00396\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00406\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00383\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 84: early stopping\n",
      "Restoring model weights from the end of the best epoch: 64.\n",
      "Validation loss: 0.00401\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 72: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.00392\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00401\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.00404\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00405\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00397\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00406\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00392\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00412\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.00394\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 75: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.00397\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 85.\n",
      "Validation loss: 0.00405\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "Completed grid search for input length: 288\n",
      "  Best Validation MSE: 0.00381\n",
      "  Best Hyperparameters: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "\n",
      "Starting grid search for input length: 312\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00370\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00384\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00375\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.00389\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 75: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.00390\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 93.\n",
      "Validation loss: 0.00408\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 85.\n",
      "Validation loss: 0.00375\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 86: early stopping\n",
      "Restoring model weights from the end of the best epoch: 66.\n",
      "Validation loss: 0.00400\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00378\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00378\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00377\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 81: early stopping\n",
      "Restoring model weights from the end of the best epoch: 61.\n",
      "Validation loss: 0.00382\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.00383\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 79: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Validation loss: 0.00403\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 75: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.00398\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.00408\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 97.\n",
      "Validation loss: 0.00410\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00371\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.00379\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00366\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 80: early stopping\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "Validation loss: 0.00376\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 100: early stopping\n",
      "Restoring model weights from the end of the best epoch: 80.\n",
      "Validation loss: 0.00379\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 97.\n",
      "Validation loss: 0.00389\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 86.\n",
      "Validation loss: 0.00379\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 99.\n",
      "Validation loss: 0.00400\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 87.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00371\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00384\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 71: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.00370\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00404\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00409\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.00407\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 87: early stopping\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "Validation loss: 0.00400\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00422\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00364\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.00370\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.00380\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 87: early stopping\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "Validation loss: 0.00389\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00415\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 88.\n",
      "Validation loss: 0.00398\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 83: early stopping\n",
      "Restoring model weights from the end of the best epoch: 63.\n",
      "Validation loss: 0.00408\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 75: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.00419\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00375\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00369\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.00386\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00373\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00391\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00403\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00391\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 78: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Validation loss: 0.00392\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 87.\n",
      "Validation loss: 0.00402\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00373\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00378\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00388\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00374\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00390\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.00400\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00391\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 88: early stopping\n",
      "Restoring model weights from the end of the best epoch: 68.\n",
      "Validation loss: 0.00398\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 93: early stopping\n",
      "Restoring model weights from the end of the best epoch: 73.\n",
      "Validation loss: 0.00406\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00377\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.00354\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00372\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00398\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00380\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 82.\n",
      "Validation loss: 0.00381\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 83: early stopping\n",
      "Restoring model weights from the end of the best epoch: 63.\n",
      "Validation loss: 0.00377\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 100: early stopping\n",
      "Restoring model weights from the end of the best epoch: 80.\n",
      "Validation loss: 0.00386\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00415\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00366\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00373\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00379\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00379\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00385\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.00406\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00403\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 89.\n",
      "Validation loss: 0.00389\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 95: early stopping\n",
      "Restoring model weights from the end of the best epoch: 75.\n",
      "Validation loss: 0.00403\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00371\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00391\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00375\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00391\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00403\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00401\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 99: early stopping\n",
      "Restoring model weights from the end of the best epoch: 79.\n",
      "Validation loss: 0.00399\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00391\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00375\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00379\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00387\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00389\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00389\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00390\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00393\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 82: early stopping\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "Validation loss: 0.00387\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00381\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00377\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00379\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00379\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00387\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.00396\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00399\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00391\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 84.\n",
      "Validation loss: 0.00404\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00359\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00379\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00374\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00373\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00381\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00393\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00382\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.00380\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 82: early stopping\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "Validation loss: 0.00398\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00364\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00380\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00386\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00385\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 71: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.00384\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 97: early stopping\n",
      "Restoring model weights from the end of the best epoch: 77.\n",
      "Validation loss: 0.00387\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.00379\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 72: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.00396\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 84: early stopping\n",
      "Restoring model weights from the end of the best epoch: 64.\n",
      "Validation loss: 0.00401\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00377\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00379\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00381\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00381\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 85: early stopping\n",
      "Restoring model weights from the end of the best epoch: 65.\n",
      "Validation loss: 0.00379\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.00401\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.00390\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00395\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 100: early stopping\n",
      "Restoring model weights from the end of the best epoch: 80.\n",
      "Validation loss: 0.00400\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00373\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00371\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00386\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00384\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00381\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00378\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00397\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 71: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.00389\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00380\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.01461\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.01464\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00385\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00384\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00384\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.00384\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00396\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 71: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.00389\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.00398\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00404\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.01507\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00385\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00388\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 75: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.00383\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00378\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00392\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 80: early stopping\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "Validation loss: 0.00397\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00376\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.01473\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.01465\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00387\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.00377\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00386\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00379\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 77: early stopping\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "Validation loss: 0.00382\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00401\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.01454\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 72: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.00375\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00377\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00384\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00377\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 80: early stopping\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "Validation loss: 0.00384\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 72: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.00364\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.00383\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 85.\n",
      "Validation loss: 0.00388\n",
      "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Completed grid search for input length: 312\n",
      "  Best Validation MSE: 0.00354\n",
      "  Best Hyperparameters: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "\n",
      "Starting grid search for input length: 336\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00375\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00344\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00357\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00370\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.00372\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 89: early stopping\n",
      "Restoring model weights from the end of the best epoch: 69.\n",
      "Validation loss: 0.00378\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 78: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Validation loss: 0.00388\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 86.\n",
      "Validation loss: 0.00387\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 95.\n",
      "Validation loss: 0.00392\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00365\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00357\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00360\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 72: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.00360\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 99: early stopping\n",
      "Restoring model weights from the end of the best epoch: 79.\n",
      "Validation loss: 0.00362\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 99.\n",
      "Validation loss: 0.00374\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 97: early stopping\n",
      "Restoring model weights from the end of the best epoch: 77.\n",
      "Validation loss: 0.00372\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.00395\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 82.\n",
      "Validation loss: 0.00401\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00352\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00367\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.00365\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.00372\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 88.\n",
      "Validation loss: 0.00376\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 93.\n",
      "Validation loss: 0.00379\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "for length in input_lengths:\n",
    "    print(f\"Starting grid search for input length: {length}\")\n",
    "    \n",
    "    X_train = data_dict[length]['X_train']\n",
    "    y_train = data_dict[length]['y_train']\n",
    "    X_val = data_dict[length]['X_val']\n",
    "    y_val = data_dict[length]['y_val']\n",
    "    \n",
    "    best_mse = float('inf')\n",
    "    best_params = {}\n",
    "    best_model = None\n",
    "    \n",
    "    for idx, combination in enumerate(all_combinations):\n",
    "        # Extract hyperparameters\n",
    "        hyperparams = {\n",
    "            'units': combination[0],\n",
    "            'dropout': combination[1],\n",
    "            'learning_rate': combination[2],\n",
    "            'batch_size': combination[3]\n",
    "        }\n",
    "        \n",
    "        print(f\"  Evaluating combination {idx + 1}/{len(all_combinations)}: {hyperparams}\")\n",
    "        \n",
    "        #model = build_lstm_model(hyperparams, length)\n",
    "        model = build_improved_lstm_model(hyperparams, length)\n",
    "        \n",
    "        # Early Stopping Callback\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True,verbose=1)\n",
    "        \n",
    "        # Train the model\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=100,\n",
    "            batch_size=hyperparams['batch_size'],\n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=[early_stop],\n",
    "            verbose=0  # Set to 1 to see training progress\n",
    "        )\n",
    "        \n",
    "        # Retrieve the best validation MSE from the history\n",
    "        current_best_mse = min(history.history['val_loss'])\n",
    "        print(f\"Validation loss: {current_best_mse:.5f}\")\n",
    "        \n",
    "        # Check if this is the best model so far\n",
    "        if current_best_mse < best_mse:\n",
    "            best_mse = current_best_mse\n",
    "            best_params = hyperparams.copy()\n",
    "            best_model = model  # Optionally, save the model if needed\n",
    "    \n",
    "    # After evaluating all combinations, store the best results\n",
    "    results.append({\n",
    "        'Input_Length': length,\n",
    "        'Best_MSE': best_mse,\n",
    "        'Validation_MSE': mean_squared_error(y_val, best_model.predict(X_val)),\n",
    "        'Validation_MAE': mean_absolute_error(y_val, best_model.predict(X_val)),\n",
    "        'Validation_MAPE': mean_absolute_percentage_error(y_val, best_model.predict(X_val)) * 100,  # In percentage\n",
    "        'Validation_RMSE': np.sqrt(mean_squared_error(y_val, best_model.predict(X_val))),\n",
    "        'Best_Hyperparameters': best_params\n",
    "    })\n",
    "    \n",
    "    print(f\"Completed grid search for input length: {length}\")\n",
    "    print(f\"  Best Validation MSE: {best_mse:.5f}\")\n",
    "    print(f\"  Best Hyperparameters: {best_params}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 24\n",
    "  Best Validation MSE: 0.00417\n",
    "  Best Hyperparameters: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 48\n",
    "  Best Validation MSE: 0.00425\n",
    "  Best Hyperparameters: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 72\n",
    "  Best Validation MSE: 0.00419\n",
    "  Best Hyperparameters: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 96\n",
    "  Best Validation MSE: 0.00413\n",
    "  Best Hyperparameters: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 120\n",
    "  Best Validation MSE: 0.00404\n",
    "  Best Hyperparameters: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 144\n",
    "  Best Validation MSE: 0.00404\n",
    "  Best Hyperparameters: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 168\n",
    "  Best Validation MSE: 0.00412\n",
    "  Best Hyperparameters: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 192\n",
    "  Best Validation MSE: 0.00402\n",
    "  Best Hyperparameters: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 216\n",
    "  Best Validation MSE: 0.00358\n",
    "  Best Hyperparameters: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 240\n",
    "  Best Validation MSE: 0.00373\n",
    "  Best Hyperparameters: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 264\n",
    "  Best Validation MSE: 0.00379\n",
    "  Best Hyperparameters: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 288\n",
    "  Best Validation MSE: 0.00381\n",
    "  Best Hyperparameters: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 312\n",
    "  Best Validation MSE: 0.00354\n",
    "  Best Hyperparameters: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Storing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert the results list to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Expand the hyperparameters dictionary into separate columns for clarity\n",
    "hyperparams_df = results_df['Best_Hyperparameters'].apply(pd.Series)\n",
    "\n",
    "# Combine the main dataframe with hyperparameters\n",
    "final_results_df = pd.concat([results_df.drop('Best_Hyperparameters', axis=1), hyperparams_df], axis=1)\n",
    "\n",
    "# Display the final dataframe\n",
    "print(\"Final Results DataFrame:\")\n",
    "final_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Results\n",
    "| input_len | Best_MSE | units | dropout | learning_rate | batch_size |\n",
    "|-----------|---------:|------:|--------:|--------------:|-----------:|\n",
    "| 24        | 0.004180 | 128   | 0.1     | 0.0010        | 32         |\n",
    "| 48        | 0.004267 | 128   | 0.1     | 0.0010        | 32         |\n",
    "| 72        | 0.004178 | 128   | 0.2     | 0.0100        | 128        |\n",
    "| 96        | 0.004150 | 32    | 0.2     | 0.0100        | 32         |\n",
    "| 120       | 0.004057 | 128   | 0.1     | 0.0010        | 32         |\n",
    "| 144       | 0.003970 | 256   | 0.0     | 0.0100        | 64         |\n",
    "| 168       | 0.004064 | 128   | 0.1     | 0.0100        | 128        |\n",
    "| 192       | 0.004010 | 64    | 0.0     | 0.0005        | 64         |\n",
    "| 216       | 0.003580 | 32    | 0.2     | 0.0100        | 32         |\n",
    "| 240       | 0.003665 | 128   | 0.3     | 0.0100        | 32         |\n",
    "| 264       | 0.003876 | 64    | 0.2     | 0.0100        | 64         |\n",
    "| 288       | 0.003760 | 32    | 0.2     | 0.0100        | 32         |\n",
    "| 312       | 0.003517 | 256   | 0.3     | 0.0100        | 32         |\n",
    "| 336       | 0.003450 | 64    | 0.3     | 0.0100        | 32         |\n",
    "| 360       | 0.003580 | 64    | 0.0     | 0.0100        | 128        |\n",
    "| 384       | 0.003600 | 128   | 0.2     | 0.0100        | 32         |\n",
    "| 408       | 0.003686 | 64    | 0.1     | 0.0100        | 32         |\n",
    "| 432       | 0.003632 | 256   | 0.0     | 0.0100        | 64         |\n",
    "| 456       | 0.003925 | 32    | 0.3     | 0.0100        | 32         |\n",
    "| 480       | 0.004287 | 128   | 0.4     | 0.0100        | 32         |\n",
    "| 504       | 0.004693 | 64    | 0.3     | 0.0100        | 32         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Retrain the model after getting the best hyperparameters of each input length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparameters = {\n",
    "    24: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.1,\n",
    "        'learning_rate': 0.0010,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    48: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.1,\n",
    "        'learning_rate': 0.0010,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    72: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 128\n",
    "    },\n",
    "    96: {\n",
    "        'units': 32,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    120: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.1,\n",
    "        'learning_rate': 0.0010,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    144: {\n",
    "        'units': 256,\n",
    "        'dropout': 0.0,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 64\n",
    "    },\n",
    "    168: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.1,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 128\n",
    "    },\n",
    "    192: {\n",
    "        'units': 64,\n",
    "        'dropout': 0.0,\n",
    "        'learning_rate': 0.0005,\n",
    "        'batch_size': 64\n",
    "    },\n",
    "    216: {\n",
    "        'units': 32,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    240: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.3,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    264: {\n",
    "        'units': 64,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 64\n",
    "    },\n",
    "    288: {\n",
    "        'units': 32,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    312: {\n",
    "        'units': 256,\n",
    "        'dropout': 0.3,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    336: {\n",
    "        'units': 64,\n",
    "        'dropout': 0.3,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    360: {\n",
    "        'units': 64,\n",
    "        'dropout': 0.0,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 128\n",
    "    },\n",
    "    384: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    408: {\n",
    "        'units': 64,\n",
    "        'dropout': 0.1,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    432: {\n",
    "        'units': 256,\n",
    "        'dropout': 0.0,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 64\n",
    "    },\n",
    "    456: {\n",
    "        'units': 32,\n",
    "        'dropout': 0.3,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    480: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.4,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    504: {\n",
    "        'units': 64,\n",
    "        'dropout': 0.3,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 32\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(hyperparams,data_dict,length, seed=None):  # add seed\n",
    "    if seed is not None:\n",
    "        set_seed(seed)\n",
    "    \n",
    "    #get the data of each length\n",
    "    X_train = data_dict[length]['X_train']\n",
    "    y_train = data_dict[length]['y_train']\n",
    "    X_val = data_dict[length]['X_val']\n",
    "    y_val = data_dict[length]['y_val']\n",
    "    \n",
    "    # Train the model\n",
    "    model = build_lstm_model(hyperparams, length)    \n",
    "    # Early Stopping Callback\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True,verbose=1)    \n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=100,\n",
    "        batch_size=hyperparams['batch_size'],\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[early_stop],\n",
    "        verbose=0  # Set to 1 to see training progress\n",
    "    )\n",
    "    \n",
    "    # Retrieve the best validation MSE from the history\n",
    "    best_mse = min(history.history['val_loss'])\n",
    "    print(f\"Validation loss: {best_mse:.5f}\")\n",
    "    \n",
    "    return model, best_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "def make_prediction(model, X_obs, y_obs):\n",
    "    y_pred = model.predict(X_obs,verbose=0)\n",
    "    n_samples = X_obs.shape[0]\n",
    "    output_len = y_obs.shape[1]\n",
    "\n",
    "    # Reshape for inverse scaling\n",
    "    y_pred_reshaped = y_pred.reshape(-1, 1)\n",
    "    y_obs_reshaped = y_obs.reshape(-1, 1)\n",
    "\n",
    "    # Inverse transform\n",
    "    y_pred_inverse = scaler.inverse_transform(y_pred_reshaped).reshape(n_samples, output_len)\n",
    "    y_obs_inverse = scaler.inverse_transform(y_obs_reshaped).reshape(n_samples, output_len)\n",
    "\n",
    "    return y_pred_inverse, y_obs_inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Metrics for Each Time Step\n",
    "def evaluation(y_pred_inverse, y_obs_inverse):\n",
    "    \n",
    "    output_len = y_pred_inverse.shape[1]\n",
    "    metrics_list = []  # To store metrics for each time step\n",
    "    \n",
    "    for i in range(output_len):\n",
    "        y_true = y_obs_inverse[:, i]\n",
    "        y_pred = y_pred_inverse[:, i]\n",
    "\n",
    "        # Mean Absolute Error (MAE)\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "        # Mean Squared Error (MSE)\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "        # Root Mean Squared Error (RMSE)\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        # Mean Absolute Percentage Error (MAPE)\n",
    "        # Avoid division by zero by adding a small epsilon to y_test_flat if necessary\n",
    "        epsilon = 1e-10\n",
    "        y_true_safe = np.where(y_true == 0, epsilon, y_true)\n",
    "        mape = np.mean(np.abs((y_true - y_pred) / y_true_safe)) * 100\n",
    "\n",
    "                # Append the metrics for the current time step to the list\n",
    "        metrics_list.append({\n",
    "            'Time Step': i + 1,\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse,\n",
    "            'MAPE (%)': mape\n",
    "        })\n",
    "\n",
    "    # Create a DataFrame from the list of metrics\n",
    "    metrics_df = pd.DataFrame(metrics_list)\n",
    "    metrics_df.set_index('Time Step', inplace=True)\n",
    "\n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "\n",
      "--- Run 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.00439\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00440\n",
      "\n",
      "--- Run 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00439\n",
      "\n",
      "--- Run 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.00432\n",
      "\n",
      "--- Run 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.00438\n",
      "\n",
      "--- Run 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00434\n",
      "\n",
      "--- Run 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.00435\n",
      "\n",
      "--- Run 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00437\n",
      "\n",
      "--- Run 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Validation loss: 0.00430\n",
      "\n",
      "--- Run 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Validation loss: 0.00429\n",
      "\n",
      "--- Aggregated Mean of All Metrics Across 10(Successful) Runs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.664418</td>\n",
       "      <td>34.990096</td>\n",
       "      <td>31.575595</td>\n",
       "      <td>21.004060</td>\n",
       "      <td>29.877984</td>\n",
       "      <td>27.150286</td>\n",
       "      <td>20.354509</td>\n",
       "      <td>26.479924</td>\n",
       "      <td>17.786190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.620034</td>\n",
       "      <td>39.855065</td>\n",
       "      <td>36.407344</td>\n",
       "      <td>24.432011</td>\n",
       "      <td>34.554419</td>\n",
       "      <td>31.521403</td>\n",
       "      <td>24.255972</td>\n",
       "      <td>32.303520</td>\n",
       "      <td>21.127929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.342144</td>\n",
       "      <td>42.462641</td>\n",
       "      <td>40.524367</td>\n",
       "      <td>26.175485</td>\n",
       "      <td>36.742594</td>\n",
       "      <td>35.166883</td>\n",
       "      <td>27.341794</td>\n",
       "      <td>35.742781</td>\n",
       "      <td>23.694629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.823448</td>\n",
       "      <td>44.163346</td>\n",
       "      <td>43.984475</td>\n",
       "      <td>27.476899</td>\n",
       "      <td>38.360796</td>\n",
       "      <td>38.003215</td>\n",
       "      <td>29.541897</td>\n",
       "      <td>38.264675</td>\n",
       "      <td>25.839648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29.757288</td>\n",
       "      <td>45.662106</td>\n",
       "      <td>46.499078</td>\n",
       "      <td>28.604943</td>\n",
       "      <td>39.737260</td>\n",
       "      <td>40.816488</td>\n",
       "      <td>31.141750</td>\n",
       "      <td>39.843733</td>\n",
       "      <td>27.024925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30.387476</td>\n",
       "      <td>46.872554</td>\n",
       "      <td>49.991002</td>\n",
       "      <td>28.761006</td>\n",
       "      <td>40.177597</td>\n",
       "      <td>44.190348</td>\n",
       "      <td>30.088960</td>\n",
       "      <td>38.891788</td>\n",
       "      <td>26.660741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  MAPE (%)_val  \\\n",
       "24                                                                              \n",
       "1   22.664418   34.990096       31.575595  21.004060  29.877984     27.150286   \n",
       "2   25.620034   39.855065       36.407344  24.432011  34.554419     31.521403   \n",
       "3   27.342144   42.462641       40.524367  26.175485  36.742594     35.166883   \n",
       "4   28.823448   44.163346       43.984475  27.476899  38.360796     38.003215   \n",
       "5   29.757288   45.662106       46.499078  28.604943  39.737260     40.816488   \n",
       "6   30.387476   46.872554       49.991002  28.761006  40.177597     44.190348   \n",
       "\n",
       "     MAE_test  RMSE_test  MAPE (%)_test  \n",
       "24                                       \n",
       "1   20.354509  26.479924      17.786190  \n",
       "2   24.255972  32.303520      21.127929  \n",
       "3   27.341794  35.742781      23.694629  \n",
       "4   29.541897  38.264675      25.839648  \n",
       "5   31.141750  39.843733      27.024925  \n",
       "6   30.088960  38.891788      26.660741  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "\n",
      "--- Run 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00445\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00454\n",
      "\n",
      "--- Run 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00455\n",
      "\n",
      "--- Run 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00455\n",
      "\n",
      "--- Run 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00457\n",
      "\n",
      "--- Run 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00456\n",
      "\n",
      "--- Run 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00451\n",
      "\n",
      "--- Run 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00449\n",
      "\n",
      "--- Run 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00455\n",
      "\n",
      "--- Run 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00455\n",
      "\n",
      "--- Aggregated Mean of All Metrics Across 10(Successful) Runs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.086022</td>\n",
       "      <td>36.815400</td>\n",
       "      <td>35.106928</td>\n",
       "      <td>21.925747</td>\n",
       "      <td>30.928630</td>\n",
       "      <td>29.234419</td>\n",
       "      <td>19.706708</td>\n",
       "      <td>25.905800</td>\n",
       "      <td>16.975469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.898404</td>\n",
       "      <td>42.331372</td>\n",
       "      <td>44.360207</td>\n",
       "      <td>25.597486</td>\n",
       "      <td>35.773070</td>\n",
       "      <td>35.982766</td>\n",
       "      <td>22.971990</td>\n",
       "      <td>30.464873</td>\n",
       "      <td>19.983959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.463030</td>\n",
       "      <td>44.873460</td>\n",
       "      <td>46.611272</td>\n",
       "      <td>27.237416</td>\n",
       "      <td>38.005617</td>\n",
       "      <td>38.136751</td>\n",
       "      <td>25.382290</td>\n",
       "      <td>33.095573</td>\n",
       "      <td>21.966932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.289737</td>\n",
       "      <td>46.070031</td>\n",
       "      <td>50.306585</td>\n",
       "      <td>28.170702</td>\n",
       "      <td>39.105632</td>\n",
       "      <td>42.419830</td>\n",
       "      <td>26.219911</td>\n",
       "      <td>33.901012</td>\n",
       "      <td>22.883655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.805028</td>\n",
       "      <td>47.311205</td>\n",
       "      <td>51.230796</td>\n",
       "      <td>28.719563</td>\n",
       "      <td>39.825991</td>\n",
       "      <td>44.294572</td>\n",
       "      <td>27.065083</td>\n",
       "      <td>35.155545</td>\n",
       "      <td>23.224580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31.798134</td>\n",
       "      <td>48.734293</td>\n",
       "      <td>53.108009</td>\n",
       "      <td>29.311515</td>\n",
       "      <td>40.520823</td>\n",
       "      <td>46.025927</td>\n",
       "      <td>26.952362</td>\n",
       "      <td>35.293025</td>\n",
       "      <td>23.375984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  MAPE (%)_val  \\\n",
       "48                                                                              \n",
       "1   24.086022   36.815400       35.106928  21.925747  30.928630     29.234419   \n",
       "2   27.898404   42.331372       44.360207  25.597486  35.773070     35.982766   \n",
       "3   29.463030   44.873460       46.611272  27.237416  38.005617     38.136751   \n",
       "4   30.289737   46.070031       50.306585  28.170702  39.105632     42.419830   \n",
       "5   30.805028   47.311205       51.230796  28.719563  39.825991     44.294572   \n",
       "6   31.798134   48.734293       53.108009  29.311515  40.520823     46.025927   \n",
       "\n",
       "     MAE_test  RMSE_test  MAPE (%)_test  \n",
       "48                                       \n",
       "1   19.706708  25.905800      16.975469  \n",
       "2   22.971990  30.464873      19.983959  \n",
       "3   25.382290  33.095573      21.966932  \n",
       "4   26.219911  33.901012      22.883655  \n",
       "5   27.065083  35.155545      23.224580  \n",
       "6   26.952362  35.293025      23.375984  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "\n",
      "--- Run 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00426\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00435\n",
      "\n",
      "--- Run 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00433\n",
      "\n",
      "--- Run 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00432\n",
      "\n",
      "--- Run 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00426\n",
      "\n",
      "--- Run 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00440\n",
      "\n",
      "--- Run 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00429\n",
      "\n",
      "--- Run 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00432\n",
      "\n",
      "--- Run 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00445\n",
      "\n",
      "--- Run 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00448\n",
      "\n",
      "--- Aggregated Mean of All Metrics Across 10(Successful) Runs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.027517</td>\n",
       "      <td>36.588513</td>\n",
       "      <td>39.541292</td>\n",
       "      <td>21.812848</td>\n",
       "      <td>30.221025</td>\n",
       "      <td>32.388178</td>\n",
       "      <td>19.689914</td>\n",
       "      <td>25.750466</td>\n",
       "      <td>17.092972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.752916</td>\n",
       "      <td>41.735833</td>\n",
       "      <td>48.540932</td>\n",
       "      <td>25.424055</td>\n",
       "      <td>34.679882</td>\n",
       "      <td>39.634462</td>\n",
       "      <td>22.122465</td>\n",
       "      <td>29.692761</td>\n",
       "      <td>19.502437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.599560</td>\n",
       "      <td>43.696119</td>\n",
       "      <td>47.963695</td>\n",
       "      <td>26.739768</td>\n",
       "      <td>36.903225</td>\n",
       "      <td>40.911678</td>\n",
       "      <td>24.445819</td>\n",
       "      <td>32.282067</td>\n",
       "      <td>20.904281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.185092</td>\n",
       "      <td>44.643713</td>\n",
       "      <td>48.895162</td>\n",
       "      <td>27.806902</td>\n",
       "      <td>38.238439</td>\n",
       "      <td>42.780179</td>\n",
       "      <td>25.990311</td>\n",
       "      <td>34.059244</td>\n",
       "      <td>22.242686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.257327</td>\n",
       "      <td>45.831980</td>\n",
       "      <td>55.968788</td>\n",
       "      <td>28.965402</td>\n",
       "      <td>39.294421</td>\n",
       "      <td>50.089676</td>\n",
       "      <td>26.014420</td>\n",
       "      <td>34.004153</td>\n",
       "      <td>22.337487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31.312938</td>\n",
       "      <td>47.097132</td>\n",
       "      <td>58.367313</td>\n",
       "      <td>29.568636</td>\n",
       "      <td>40.011500</td>\n",
       "      <td>51.555921</td>\n",
       "      <td>26.709861</td>\n",
       "      <td>34.932546</td>\n",
       "      <td>22.990209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  MAPE (%)_val  \\\n",
       "72                                                                              \n",
       "1   24.027517   36.588513       39.541292  21.812848  30.221025     32.388178   \n",
       "2   27.752916   41.735833       48.540932  25.424055  34.679882     39.634462   \n",
       "3   28.599560   43.696119       47.963695  26.739768  36.903225     40.911678   \n",
       "4   29.185092   44.643713       48.895162  27.806902  38.238439     42.780179   \n",
       "5   30.257327   45.831980       55.968788  28.965402  39.294421     50.089676   \n",
       "6   31.312938   47.097132       58.367313  29.568636  40.011500     51.555921   \n",
       "\n",
       "     MAE_test  RMSE_test  MAPE (%)_test  \n",
       "72                                       \n",
       "1   19.689914  25.750466      17.092972  \n",
       "2   22.122465  29.692761      19.502437  \n",
       "3   24.445819  32.282067      20.904281  \n",
       "4   25.990311  34.059244      22.242686  \n",
       "5   26.014420  34.004153      22.337487  \n",
       "6   26.709861  34.932546      22.990209  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "\n",
      "--- Run 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00434\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00456\n",
      "\n",
      "--- Run 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00445\n",
      "\n",
      "--- Run 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00447\n",
      "\n",
      "--- Run 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00469\n",
      "\n",
      "--- Run 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00428\n",
      "\n",
      "--- Run 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00442\n",
      "\n",
      "--- Run 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00436\n",
      "\n",
      "--- Run 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00453\n",
      "\n",
      "--- Run 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00437\n",
      "\n",
      "--- Aggregated Mean of All Metrics Across 10(Successful) Runs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.015916</td>\n",
       "      <td>35.991973</td>\n",
       "      <td>38.563911</td>\n",
       "      <td>21.839465</td>\n",
       "      <td>29.948398</td>\n",
       "      <td>32.498625</td>\n",
       "      <td>19.549339</td>\n",
       "      <td>25.106252</td>\n",
       "      <td>17.306911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.249922</td>\n",
       "      <td>41.520686</td>\n",
       "      <td>50.122704</td>\n",
       "      <td>26.307357</td>\n",
       "      <td>35.374619</td>\n",
       "      <td>43.211200</td>\n",
       "      <td>23.124027</td>\n",
       "      <td>29.972347</td>\n",
       "      <td>20.965437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.626573</td>\n",
       "      <td>43.527264</td>\n",
       "      <td>53.395529</td>\n",
       "      <td>27.888723</td>\n",
       "      <td>37.478637</td>\n",
       "      <td>47.815652</td>\n",
       "      <td>24.346918</td>\n",
       "      <td>31.666940</td>\n",
       "      <td>21.858396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.015845</td>\n",
       "      <td>44.408844</td>\n",
       "      <td>56.706792</td>\n",
       "      <td>28.605894</td>\n",
       "      <td>38.472381</td>\n",
       "      <td>51.218617</td>\n",
       "      <td>24.698406</td>\n",
       "      <td>32.189849</td>\n",
       "      <td>22.064736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31.556050</td>\n",
       "      <td>45.829579</td>\n",
       "      <td>65.309380</td>\n",
       "      <td>30.059702</td>\n",
       "      <td>39.734734</td>\n",
       "      <td>59.001581</td>\n",
       "      <td>25.482501</td>\n",
       "      <td>32.975945</td>\n",
       "      <td>22.951689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31.625924</td>\n",
       "      <td>46.849204</td>\n",
       "      <td>60.591158</td>\n",
       "      <td>30.364283</td>\n",
       "      <td>40.777626</td>\n",
       "      <td>56.509158</td>\n",
       "      <td>26.299834</td>\n",
       "      <td>34.328461</td>\n",
       "      <td>23.066175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  MAPE (%)_val  \\\n",
       "96                                                                              \n",
       "1   24.015916   35.991973       38.563911  21.839465  29.948398     32.498625   \n",
       "2   28.249922   41.520686       50.122704  26.307357  35.374619     43.211200   \n",
       "3   29.626573   43.527264       53.395529  27.888723  37.478637     47.815652   \n",
       "4   30.015845   44.408844       56.706792  28.605894  38.472381     51.218617   \n",
       "5   31.556050   45.829579       65.309380  30.059702  39.734734     59.001581   \n",
       "6   31.625924   46.849204       60.591158  30.364283  40.777626     56.509158   \n",
       "\n",
       "     MAE_test  RMSE_test  MAPE (%)_test  \n",
       "96                                       \n",
       "1   19.549339  25.106252      17.306911  \n",
       "2   23.124027  29.972347      20.965437  \n",
       "3   24.346918  31.666940      21.858396  \n",
       "4   24.698406  32.189849      22.064736  \n",
       "5   25.482501  32.975945      22.951689  \n",
       "6   26.299834  34.328461      23.066175  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "\n",
      "--- Run 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00415\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00421\n",
      "\n",
      "--- Run 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00420\n",
      "\n",
      "--- Run 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00412\n",
      "\n",
      "--- Run 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00413\n",
      "\n",
      "--- Run 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00413\n",
      "\n",
      "--- Run 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00414\n",
      "\n",
      "--- Run 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00418\n",
      "\n",
      "--- Run 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00415\n",
      "\n",
      "--- Run 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00418\n",
      "\n",
      "--- Aggregated Mean of All Metrics Across 10(Successful) Runs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.203273</td>\n",
       "      <td>35.717009</td>\n",
       "      <td>33.878099</td>\n",
       "      <td>20.887243</td>\n",
       "      <td>28.872297</td>\n",
       "      <td>27.492440</td>\n",
       "      <td>18.953886</td>\n",
       "      <td>25.017784</td>\n",
       "      <td>16.071991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.639128</td>\n",
       "      <td>40.881839</td>\n",
       "      <td>42.853709</td>\n",
       "      <td>24.301375</td>\n",
       "      <td>33.518723</td>\n",
       "      <td>35.897790</td>\n",
       "      <td>21.615869</td>\n",
       "      <td>29.068954</td>\n",
       "      <td>18.519142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.071078</td>\n",
       "      <td>42.808310</td>\n",
       "      <td>47.053694</td>\n",
       "      <td>26.223273</td>\n",
       "      <td>36.035031</td>\n",
       "      <td>41.217865</td>\n",
       "      <td>23.344367</td>\n",
       "      <td>30.689970</td>\n",
       "      <td>19.931308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.483509</td>\n",
       "      <td>44.095940</td>\n",
       "      <td>47.647265</td>\n",
       "      <td>27.105018</td>\n",
       "      <td>37.566316</td>\n",
       "      <td>42.580248</td>\n",
       "      <td>25.249203</td>\n",
       "      <td>33.056390</td>\n",
       "      <td>21.077000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29.751859</td>\n",
       "      <td>44.880138</td>\n",
       "      <td>55.981223</td>\n",
       "      <td>28.524627</td>\n",
       "      <td>38.751102</td>\n",
       "      <td>50.691356</td>\n",
       "      <td>24.881568</td>\n",
       "      <td>32.547541</td>\n",
       "      <td>21.131024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30.559295</td>\n",
       "      <td>46.070723</td>\n",
       "      <td>59.813566</td>\n",
       "      <td>29.252291</td>\n",
       "      <td>39.670203</td>\n",
       "      <td>54.499723</td>\n",
       "      <td>24.356122</td>\n",
       "      <td>32.502785</td>\n",
       "      <td>20.553001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  \\\n",
       "120                                                                \n",
       "1    23.203273   35.717009       33.878099  20.887243  28.872297   \n",
       "2    26.639128   40.881839       42.853709  24.301375  33.518723   \n",
       "3    28.071078   42.808310       47.053694  26.223273  36.035031   \n",
       "4    28.483509   44.095940       47.647265  27.105018  37.566316   \n",
       "5    29.751859   44.880138       55.981223  28.524627  38.751102   \n",
       "6    30.559295   46.070723       59.813566  29.252291  39.670203   \n",
       "\n",
       "     MAPE (%)_val   MAE_test  RMSE_test  MAPE (%)_test  \n",
       "120                                                     \n",
       "1       27.492440  18.953886  25.017784      16.071991  \n",
       "2       35.897790  21.615869  29.068954      18.519142  \n",
       "3       41.217865  23.344367  30.689970      19.931308  \n",
       "4       42.580248  25.249203  33.056390      21.077000  \n",
       "5       50.691356  24.881568  32.547541      21.131024  \n",
       "6       54.499723  24.356122  32.502785      20.553001  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "\n",
      "--- Run 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00457\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.01768\n",
      "\n",
      "--- Run 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00543\n",
      "\n",
      "--- Run 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00466\n",
      "\n",
      "--- Run 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.03522\n",
      "\n",
      "--- Run 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00439\n",
      "\n",
      "--- Run 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00430\n",
      "\n",
      "--- Run 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.00439\n",
      "\n",
      "--- Run 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.00472\n",
      "\n",
      "--- Run 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00508\n",
      "\n",
      "--- Aggregated Mean of All Metrics Across 10(Successful) Runs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.928778</td>\n",
       "      <td>40.588194</td>\n",
       "      <td>53.976922</td>\n",
       "      <td>26.886340</td>\n",
       "      <td>34.756757</td>\n",
       "      <td>46.266339</td>\n",
       "      <td>23.764438</td>\n",
       "      <td>30.089928</td>\n",
       "      <td>20.406957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.794671</td>\n",
       "      <td>44.981659</td>\n",
       "      <td>64.687533</td>\n",
       "      <td>30.171804</td>\n",
       "      <td>39.524299</td>\n",
       "      <td>55.631658</td>\n",
       "      <td>26.910209</td>\n",
       "      <td>34.777741</td>\n",
       "      <td>23.556143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.136606</td>\n",
       "      <td>46.905892</td>\n",
       "      <td>67.993422</td>\n",
       "      <td>31.846784</td>\n",
       "      <td>41.911192</td>\n",
       "      <td>59.515295</td>\n",
       "      <td>28.315461</td>\n",
       "      <td>36.380579</td>\n",
       "      <td>24.478506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50.780364</td>\n",
       "      <td>64.049067</td>\n",
       "      <td>134.104357</td>\n",
       "      <td>49.263922</td>\n",
       "      <td>60.383025</td>\n",
       "      <td>117.835011</td>\n",
       "      <td>45.315458</td>\n",
       "      <td>53.922371</td>\n",
       "      <td>43.230681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>39.336806</td>\n",
       "      <td>53.799382</td>\n",
       "      <td>91.416296</td>\n",
       "      <td>38.142734</td>\n",
       "      <td>49.557994</td>\n",
       "      <td>80.834646</td>\n",
       "      <td>36.194960</td>\n",
       "      <td>44.932155</td>\n",
       "      <td>33.151089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>45.214649</td>\n",
       "      <td>60.122418</td>\n",
       "      <td>116.234807</td>\n",
       "      <td>43.808817</td>\n",
       "      <td>55.859702</td>\n",
       "      <td>101.989483</td>\n",
       "      <td>41.088949</td>\n",
       "      <td>50.327818</td>\n",
       "      <td>38.765724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  \\\n",
       "144                                                                \n",
       "1    28.928778   40.588194       53.976922  26.886340  34.756757   \n",
       "2    31.794671   44.981659       64.687533  30.171804  39.524299   \n",
       "3    33.136606   46.905892       67.993422  31.846784  41.911192   \n",
       "4    50.780364   64.049067      134.104357  49.263922  60.383025   \n",
       "5    39.336806   53.799382       91.416296  38.142734  49.557994   \n",
       "6    45.214649   60.122418      116.234807  43.808817  55.859702   \n",
       "\n",
       "     MAPE (%)_val   MAE_test  RMSE_test  MAPE (%)_test  \n",
       "144                                                     \n",
       "1       46.266339  23.764438  30.089928      20.406957  \n",
       "2       55.631658  26.910209  34.777741      23.556143  \n",
       "3       59.515295  28.315461  36.380579      24.478506  \n",
       "4      117.835011  45.315458  53.922371      43.230681  \n",
       "5       80.834646  36.194960  44.932155      33.151089  \n",
       "6      101.989483  41.088949  50.327818      38.765724  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\n",
      "\n",
      "--- Run 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00426\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00441\n",
      "\n",
      "--- Run 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00430\n",
      "\n",
      "--- Run 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00431\n",
      "\n",
      "--- Run 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00423\n",
      "\n",
      "--- Run 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00431\n",
      "\n",
      "--- Run 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00421\n",
      "\n",
      "--- Run 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00421\n",
      "\n",
      "--- Run 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00438\n",
      "\n",
      "--- Run 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00424\n",
      "\n",
      "--- Aggregated Mean of All Metrics Across 10(Successful) Runs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.878738</td>\n",
       "      <td>36.495712</td>\n",
       "      <td>40.352093</td>\n",
       "      <td>22.227837</td>\n",
       "      <td>29.416600</td>\n",
       "      <td>33.372899</td>\n",
       "      <td>19.254280</td>\n",
       "      <td>24.923579</td>\n",
       "      <td>16.559509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.236646</td>\n",
       "      <td>41.346282</td>\n",
       "      <td>43.194630</td>\n",
       "      <td>24.921340</td>\n",
       "      <td>33.775823</td>\n",
       "      <td>36.868582</td>\n",
       "      <td>22.605725</td>\n",
       "      <td>30.094968</td>\n",
       "      <td>19.116966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.979956</td>\n",
       "      <td>43.542094</td>\n",
       "      <td>49.282404</td>\n",
       "      <td>27.113461</td>\n",
       "      <td>36.572516</td>\n",
       "      <td>44.136973</td>\n",
       "      <td>24.733611</td>\n",
       "      <td>32.326870</td>\n",
       "      <td>20.893988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.084216</td>\n",
       "      <td>44.603988</td>\n",
       "      <td>47.059145</td>\n",
       "      <td>27.932915</td>\n",
       "      <td>38.219369</td>\n",
       "      <td>43.607328</td>\n",
       "      <td>26.790901</td>\n",
       "      <td>34.666288</td>\n",
       "      <td>22.427863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29.472903</td>\n",
       "      <td>45.583517</td>\n",
       "      <td>47.478517</td>\n",
       "      <td>28.810697</td>\n",
       "      <td>39.425091</td>\n",
       "      <td>45.365165</td>\n",
       "      <td>27.832736</td>\n",
       "      <td>35.725829</td>\n",
       "      <td>23.068990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30.534401</td>\n",
       "      <td>46.893743</td>\n",
       "      <td>50.558974</td>\n",
       "      <td>29.553473</td>\n",
       "      <td>40.212450</td>\n",
       "      <td>48.727158</td>\n",
       "      <td>29.174350</td>\n",
       "      <td>37.287686</td>\n",
       "      <td>24.083862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  \\\n",
       "168                                                                \n",
       "1    24.878738   36.495712       40.352093  22.227837  29.416600   \n",
       "2    27.236646   41.346282       43.194630  24.921340  33.775823   \n",
       "3    28.979956   43.542094       49.282404  27.113461  36.572516   \n",
       "4    29.084216   44.603988       47.059145  27.932915  38.219369   \n",
       "5    29.472903   45.583517       47.478517  28.810697  39.425091   \n",
       "6    30.534401   46.893743       50.558974  29.553473  40.212450   \n",
       "\n",
       "     MAPE (%)_val   MAE_test  RMSE_test  MAPE (%)_test  \n",
       "168                                                     \n",
       "1       33.372899  19.254280  24.923579      16.559509  \n",
       "2       36.868582  22.605725  30.094968      19.116966  \n",
       "3       44.136973  24.733611  32.326870      20.893988  \n",
       "4       43.607328  26.790901  34.666288      22.427863  \n",
       "5       45.365165  27.832736  35.725829      23.068990  \n",
       "6       48.727158  29.174350  37.287686      24.083862  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n",
      "\n",
      "--- Run 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.00446\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00455\n",
      "\n",
      "--- Run 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00444\n",
      "\n",
      "--- Run 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.00437\n",
      "\n",
      "--- Run 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 90.\n",
      "Validation loss: 0.00422\n",
      "\n",
      "--- Run 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85: early stopping\n",
      "Restoring model weights from the end of the best epoch: 65.\n",
      "Validation loss: 0.00442\n",
      "\n",
      "--- Run 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.00447\n",
      "\n",
      "--- Run 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 98.\n",
      "Validation loss: 0.00429\n",
      "\n",
      "--- Run 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00432\n",
      "\n",
      "--- Run 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 87.\n",
      "Validation loss: 0.00425\n",
      "\n",
      "--- Aggregated Mean of All Metrics Across 10(Successful) Runs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.210387</td>\n",
       "      <td>36.828511</td>\n",
       "      <td>47.117949</td>\n",
       "      <td>23.765929</td>\n",
       "      <td>30.725219</td>\n",
       "      <td>43.740974</td>\n",
       "      <td>19.557074</td>\n",
       "      <td>25.099175</td>\n",
       "      <td>17.594503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.626104</td>\n",
       "      <td>41.080854</td>\n",
       "      <td>38.956013</td>\n",
       "      <td>25.425860</td>\n",
       "      <td>34.669669</td>\n",
       "      <td>37.026273</td>\n",
       "      <td>23.760790</td>\n",
       "      <td>31.218188</td>\n",
       "      <td>20.501348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.234497</td>\n",
       "      <td>42.919078</td>\n",
       "      <td>46.586367</td>\n",
       "      <td>27.721807</td>\n",
       "      <td>37.196008</td>\n",
       "      <td>47.159191</td>\n",
       "      <td>25.120658</td>\n",
       "      <td>32.824461</td>\n",
       "      <td>21.673722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.839375</td>\n",
       "      <td>43.702788</td>\n",
       "      <td>47.037396</td>\n",
       "      <td>28.744973</td>\n",
       "      <td>38.393304</td>\n",
       "      <td>48.584533</td>\n",
       "      <td>26.494197</td>\n",
       "      <td>34.525335</td>\n",
       "      <td>22.887608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29.040121</td>\n",
       "      <td>44.676954</td>\n",
       "      <td>48.398415</td>\n",
       "      <td>29.306522</td>\n",
       "      <td>39.117117</td>\n",
       "      <td>51.428257</td>\n",
       "      <td>27.983849</td>\n",
       "      <td>35.993178</td>\n",
       "      <td>23.973631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30.530088</td>\n",
       "      <td>45.811500</td>\n",
       "      <td>56.772217</td>\n",
       "      <td>30.494591</td>\n",
       "      <td>40.189910</td>\n",
       "      <td>59.751002</td>\n",
       "      <td>28.977288</td>\n",
       "      <td>36.994144</td>\n",
       "      <td>24.860743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  \\\n",
       "192                                                                \n",
       "1    25.210387   36.828511       47.117949  23.765929  30.725219   \n",
       "2    26.626104   41.080854       38.956013  25.425860  34.669669   \n",
       "3    28.234497   42.919078       46.586367  27.721807  37.196008   \n",
       "4    28.839375   43.702788       47.037396  28.744973  38.393304   \n",
       "5    29.040121   44.676954       48.398415  29.306522  39.117117   \n",
       "6    30.530088   45.811500       56.772217  30.494591  40.189910   \n",
       "\n",
       "     MAPE (%)_val   MAE_test  RMSE_test  MAPE (%)_test  \n",
       "192                                                     \n",
       "1       43.740974  19.557074  25.099175      17.594503  \n",
       "2       37.026273  23.760790  31.218188      20.501348  \n",
       "3       47.159191  25.120658  32.824461      21.673722  \n",
       "4       48.584533  26.494197  34.525335      22.887608  \n",
       "5       51.428257  27.983849  35.993178      23.973631  \n",
       "6       59.751002  28.977288  36.994144      24.860743  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216\n",
      "\n",
      "--- Run 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00418\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00431\n",
      "\n",
      "--- Run 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00416\n",
      "\n",
      "--- Run 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00399\n",
      "\n",
      "--- Run 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00406\n",
      "\n",
      "--- Run 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00394\n",
      "\n",
      "--- Run 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00405\n",
      "\n",
      "--- Run 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00406\n",
      "\n",
      "--- Run 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00407\n",
      "\n",
      "--- Run 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00413\n",
      "\n",
      "--- Aggregated Mean of All Metrics Across 10(Successful) Runs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.081225</td>\n",
       "      <td>36.717977</td>\n",
       "      <td>44.500292</td>\n",
       "      <td>21.979756</td>\n",
       "      <td>28.578028</td>\n",
       "      <td>37.794310</td>\n",
       "      <td>20.142231</td>\n",
       "      <td>25.766112</td>\n",
       "      <td>17.110945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.852921</td>\n",
       "      <td>41.698850</td>\n",
       "      <td>46.651755</td>\n",
       "      <td>24.512147</td>\n",
       "      <td>32.311091</td>\n",
       "      <td>40.342915</td>\n",
       "      <td>22.266625</td>\n",
       "      <td>29.631173</td>\n",
       "      <td>18.853280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.584184</td>\n",
       "      <td>44.178833</td>\n",
       "      <td>50.565823</td>\n",
       "      <td>26.108841</td>\n",
       "      <td>34.581288</td>\n",
       "      <td>44.456823</td>\n",
       "      <td>24.377213</td>\n",
       "      <td>32.069804</td>\n",
       "      <td>20.512070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.503846</td>\n",
       "      <td>45.862868</td>\n",
       "      <td>61.922179</td>\n",
       "      <td>29.489078</td>\n",
       "      <td>37.825361</td>\n",
       "      <td>57.126277</td>\n",
       "      <td>26.638924</td>\n",
       "      <td>34.570898</td>\n",
       "      <td>22.787524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32.900855</td>\n",
       "      <td>46.888824</td>\n",
       "      <td>62.894097</td>\n",
       "      <td>30.430694</td>\n",
       "      <td>39.129998</td>\n",
       "      <td>58.856362</td>\n",
       "      <td>27.029367</td>\n",
       "      <td>34.690608</td>\n",
       "      <td>22.864455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33.243226</td>\n",
       "      <td>47.865245</td>\n",
       "      <td>63.276858</td>\n",
       "      <td>30.771300</td>\n",
       "      <td>40.037986</td>\n",
       "      <td>60.998972</td>\n",
       "      <td>27.614137</td>\n",
       "      <td>35.542351</td>\n",
       "      <td>23.274474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  \\\n",
       "216                                                                \n",
       "1    25.081225   36.717977       44.500292  21.979756  28.578028   \n",
       "2    27.852921   41.698850       46.651755  24.512147  32.311091   \n",
       "3    29.584184   44.178833       50.565823  26.108841  34.581288   \n",
       "4    32.503846   45.862868       61.922179  29.489078  37.825361   \n",
       "5    32.900855   46.888824       62.894097  30.430694  39.129998   \n",
       "6    33.243226   47.865245       63.276858  30.771300  40.037986   \n",
       "\n",
       "     MAPE (%)_val   MAE_test  RMSE_test  MAPE (%)_test  \n",
       "216                                                     \n",
       "1       37.794310  20.142231  25.766112      17.110945  \n",
       "2       40.342915  22.266625  29.631173      18.853280  \n",
       "3       44.456823  24.377213  32.069804      20.512070  \n",
       "4       57.126277  26.638924  34.570898      22.787524  \n",
       "5       58.856362  27.029367  34.690608      22.864455  \n",
       "6       60.998972  27.614137  35.542351      23.274474  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n",
      "\n",
      "--- Run 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00390\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00386\n",
      "\n",
      "--- Run 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00405\n",
      "\n",
      "--- Run 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00383\n",
      "\n",
      "--- Run 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00411\n",
      "\n",
      "--- Run 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00408\n",
      "\n",
      "--- Run 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.00405\n",
      "\n",
      "--- Run 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00396\n",
      "\n",
      "--- Run 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00417\n",
      "\n",
      "--- Run 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00389\n",
      "\n",
      "--- Aggregated Mean of All Metrics Across 10(Successful) Runs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.901785</td>\n",
       "      <td>35.917782</td>\n",
       "      <td>42.852761</td>\n",
       "      <td>21.583770</td>\n",
       "      <td>28.676641</td>\n",
       "      <td>36.300118</td>\n",
       "      <td>19.028684</td>\n",
       "      <td>24.644400</td>\n",
       "      <td>15.652826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.927106</td>\n",
       "      <td>40.459231</td>\n",
       "      <td>39.644342</td>\n",
       "      <td>23.763791</td>\n",
       "      <td>32.505060</td>\n",
       "      <td>33.752382</td>\n",
       "      <td>23.224608</td>\n",
       "      <td>30.846369</td>\n",
       "      <td>19.087334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.825014</td>\n",
       "      <td>42.183806</td>\n",
       "      <td>38.306159</td>\n",
       "      <td>25.228292</td>\n",
       "      <td>34.961526</td>\n",
       "      <td>34.447898</td>\n",
       "      <td>26.662915</td>\n",
       "      <td>34.269011</td>\n",
       "      <td>21.780487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.421739</td>\n",
       "      <td>43.628252</td>\n",
       "      <td>36.360576</td>\n",
       "      <td>26.566122</td>\n",
       "      <td>37.176027</td>\n",
       "      <td>34.592570</td>\n",
       "      <td>30.696413</td>\n",
       "      <td>38.579191</td>\n",
       "      <td>24.968789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27.928842</td>\n",
       "      <td>44.794311</td>\n",
       "      <td>40.030986</td>\n",
       "      <td>27.392017</td>\n",
       "      <td>38.046912</td>\n",
       "      <td>40.173671</td>\n",
       "      <td>30.690792</td>\n",
       "      <td>38.548902</td>\n",
       "      <td>24.545355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29.102082</td>\n",
       "      <td>45.839414</td>\n",
       "      <td>46.778760</td>\n",
       "      <td>27.921267</td>\n",
       "      <td>38.621886</td>\n",
       "      <td>46.058030</td>\n",
       "      <td>29.569962</td>\n",
       "      <td>37.773828</td>\n",
       "      <td>23.622415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  \\\n",
       "240                                                                \n",
       "1    23.901785   35.917782       42.852761  21.583770  28.676641   \n",
       "2    25.927106   40.459231       39.644342  23.763791  32.505060   \n",
       "3    26.825014   42.183806       38.306159  25.228292  34.961526   \n",
       "4    27.421739   43.628252       36.360576  26.566122  37.176027   \n",
       "5    27.928842   44.794311       40.030986  27.392017  38.046912   \n",
       "6    29.102082   45.839414       46.778760  27.921267  38.621886   \n",
       "\n",
       "     MAPE (%)_val   MAE_test  RMSE_test  MAPE (%)_test  \n",
       "240                                                     \n",
       "1       36.300118  19.028684  24.644400      15.652826  \n",
       "2       33.752382  23.224608  30.846369      19.087334  \n",
       "3       34.447898  26.662915  34.269011      21.780487  \n",
       "4       34.592570  30.696413  38.579191      24.968789  \n",
       "5       40.173671  30.690792  38.548902      24.545355  \n",
       "6       46.058030  29.569962  37.773828      23.622415  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264\n",
      "\n",
      "--- Run 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00410\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00415\n",
      "\n",
      "--- Run 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00397\n",
      "\n",
      "--- Run 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00413\n",
      "\n",
      "--- Run 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00412\n",
      "\n",
      "--- Run 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00419\n",
      "\n",
      "--- Run 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00425\n",
      "\n",
      "--- Run 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00387\n",
      "\n",
      "--- Run 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00418\n",
      "\n",
      "--- Run 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00426\n",
      "\n",
      "--- Aggregated Mean of All Metrics Across 10(Successful) Runs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.055495</td>\n",
       "      <td>35.368072</td>\n",
       "      <td>33.553321</td>\n",
       "      <td>21.369299</td>\n",
       "      <td>28.928182</td>\n",
       "      <td>29.223493</td>\n",
       "      <td>18.565440</td>\n",
       "      <td>23.853827</td>\n",
       "      <td>14.789835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.737273</td>\n",
       "      <td>40.336317</td>\n",
       "      <td>45.187036</td>\n",
       "      <td>24.824189</td>\n",
       "      <td>33.354689</td>\n",
       "      <td>38.279753</td>\n",
       "      <td>21.369247</td>\n",
       "      <td>28.603245</td>\n",
       "      <td>16.729506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.489926</td>\n",
       "      <td>42.593971</td>\n",
       "      <td>54.125087</td>\n",
       "      <td>26.617183</td>\n",
       "      <td>35.647356</td>\n",
       "      <td>46.376465</td>\n",
       "      <td>23.932338</td>\n",
       "      <td>31.409704</td>\n",
       "      <td>18.527901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.187350</td>\n",
       "      <td>43.445960</td>\n",
       "      <td>55.781443</td>\n",
       "      <td>28.102895</td>\n",
       "      <td>37.470855</td>\n",
       "      <td>50.580183</td>\n",
       "      <td>25.142101</td>\n",
       "      <td>32.719989</td>\n",
       "      <td>19.636529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29.315125</td>\n",
       "      <td>44.544306</td>\n",
       "      <td>53.893399</td>\n",
       "      <td>28.695581</td>\n",
       "      <td>38.644145</td>\n",
       "      <td>50.908211</td>\n",
       "      <td>26.206107</td>\n",
       "      <td>34.146895</td>\n",
       "      <td>20.148897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30.495811</td>\n",
       "      <td>45.784613</td>\n",
       "      <td>59.532982</td>\n",
       "      <td>29.299366</td>\n",
       "      <td>39.417848</td>\n",
       "      <td>55.089674</td>\n",
       "      <td>26.023566</td>\n",
       "      <td>34.250363</td>\n",
       "      <td>20.011168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  \\\n",
       "264                                                                \n",
       "1    23.055495   35.368072       33.553321  21.369299  28.928182   \n",
       "2    26.737273   40.336317       45.187036  24.824189  33.354689   \n",
       "3    28.489926   42.593971       54.125087  26.617183  35.647356   \n",
       "4    29.187350   43.445960       55.781443  28.102895  37.470855   \n",
       "5    29.315125   44.544306       53.893399  28.695581  38.644145   \n",
       "6    30.495811   45.784613       59.532982  29.299366  39.417848   \n",
       "\n",
       "     MAPE (%)_val   MAE_test  RMSE_test  MAPE (%)_test  \n",
       "264                                                     \n",
       "1       29.223493  18.565440  23.853827      14.789835  \n",
       "2       38.279753  21.369247  28.603245      16.729506  \n",
       "3       46.376465  23.932338  31.409704      18.527901  \n",
       "4       50.580183  25.142101  32.719989      19.636529  \n",
       "5       50.908211  26.206107  34.146895      20.148897  \n",
       "6       55.089674  26.023566  34.250363      20.011168  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288\n",
      "\n",
      "--- Run 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00419\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00419\n",
      "\n",
      "--- Run 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00423\n",
      "\n",
      "--- Run 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00411\n",
      "\n",
      "--- Run 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00420\n",
      "\n",
      "--- Run 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00391\n",
      "\n",
      "--- Run 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00420\n",
      "\n",
      "--- Run 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00390\n",
      "\n",
      "--- Run 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00429\n",
      "\n",
      "--- Run 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00415\n",
      "\n",
      "--- Aggregated Mean of All Metrics Across 10(Successful) Runs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.793842</td>\n",
       "      <td>36.208367</td>\n",
       "      <td>35.230678</td>\n",
       "      <td>21.572244</td>\n",
       "      <td>29.059412</td>\n",
       "      <td>30.116370</td>\n",
       "      <td>18.785271</td>\n",
       "      <td>24.212171</td>\n",
       "      <td>14.721254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.584257</td>\n",
       "      <td>41.701697</td>\n",
       "      <td>45.805224</td>\n",
       "      <td>24.706393</td>\n",
       "      <td>33.202770</td>\n",
       "      <td>38.482833</td>\n",
       "      <td>21.491050</td>\n",
       "      <td>28.845090</td>\n",
       "      <td>16.385449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.344112</td>\n",
       "      <td>44.269742</td>\n",
       "      <td>46.602777</td>\n",
       "      <td>26.818273</td>\n",
       "      <td>36.231504</td>\n",
       "      <td>40.436570</td>\n",
       "      <td>24.453409</td>\n",
       "      <td>31.699239</td>\n",
       "      <td>18.984093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.818543</td>\n",
       "      <td>45.402518</td>\n",
       "      <td>49.565995</td>\n",
       "      <td>27.289323</td>\n",
       "      <td>37.147401</td>\n",
       "      <td>43.530586</td>\n",
       "      <td>25.457981</td>\n",
       "      <td>33.068691</td>\n",
       "      <td>19.418722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.493245</td>\n",
       "      <td>46.778056</td>\n",
       "      <td>46.518042</td>\n",
       "      <td>28.749190</td>\n",
       "      <td>39.062396</td>\n",
       "      <td>41.558085</td>\n",
       "      <td>28.445560</td>\n",
       "      <td>35.909523</td>\n",
       "      <td>22.219434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31.573751</td>\n",
       "      <td>48.093631</td>\n",
       "      <td>52.959561</td>\n",
       "      <td>28.784191</td>\n",
       "      <td>39.155170</td>\n",
       "      <td>47.411815</td>\n",
       "      <td>28.579313</td>\n",
       "      <td>36.107342</td>\n",
       "      <td>22.122543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  \\\n",
       "288                                                                \n",
       "1    23.793842   36.208367       35.230678  21.572244  29.059412   \n",
       "2    27.584257   41.701697       45.805224  24.706393  33.202770   \n",
       "3    29.344112   44.269742       46.602777  26.818273  36.231504   \n",
       "4    29.818543   45.402518       49.565995  27.289323  37.147401   \n",
       "5    30.493245   46.778056       46.518042  28.749190  39.062396   \n",
       "6    31.573751   48.093631       52.959561  28.784191  39.155170   \n",
       "\n",
       "     MAPE (%)_val   MAE_test  RMSE_test  MAPE (%)_test  \n",
       "288                                                     \n",
       "1       30.116370  18.785271  24.212171      14.721254  \n",
       "2       38.482833  21.491050  28.845090      16.385449  \n",
       "3       40.436570  24.453409  31.699239      18.984093  \n",
       "4       43.530586  25.457981  33.068691      19.418722  \n",
       "5       41.558085  28.445560  35.909523      22.219434  \n",
       "6       47.411815  28.579313  36.107342      22.122543  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312\n",
      "\n",
      "--- Run 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.01346\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00453\n",
      "\n",
      "--- Run 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00464\n",
      "\n",
      "--- Run 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00867\n",
      "\n",
      "--- Run 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00368\n",
      "\n",
      "--- Run 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00395\n",
      "\n",
      "--- Run 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.00400\n",
      "\n",
      "--- Run 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.01400\n",
      "\n",
      "--- Run 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00356\n",
      "\n",
      "--- Run 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.01397\n",
      "\n",
      "--- Aggregated Mean of All Metrics Across 10(Successful) Runs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.741430</td>\n",
       "      <td>50.158134</td>\n",
       "      <td>83.592770</td>\n",
       "      <td>32.143454</td>\n",
       "      <td>40.085697</td>\n",
       "      <td>70.839052</td>\n",
       "      <td>27.752740</td>\n",
       "      <td>34.697609</td>\n",
       "      <td>20.966779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.470408</td>\n",
       "      <td>54.969288</td>\n",
       "      <td>95.522637</td>\n",
       "      <td>34.795894</td>\n",
       "      <td>44.225042</td>\n",
       "      <td>79.783376</td>\n",
       "      <td>31.795842</td>\n",
       "      <td>39.782816</td>\n",
       "      <td>24.801321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41.680223</td>\n",
       "      <td>57.114116</td>\n",
       "      <td>99.859528</td>\n",
       "      <td>36.390250</td>\n",
       "      <td>46.246590</td>\n",
       "      <td>82.792559</td>\n",
       "      <td>32.902194</td>\n",
       "      <td>41.151362</td>\n",
       "      <td>24.901066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42.443738</td>\n",
       "      <td>58.707794</td>\n",
       "      <td>98.027542</td>\n",
       "      <td>37.337276</td>\n",
       "      <td>47.697462</td>\n",
       "      <td>80.120345</td>\n",
       "      <td>36.159231</td>\n",
       "      <td>44.951097</td>\n",
       "      <td>26.984677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>43.755531</td>\n",
       "      <td>60.876618</td>\n",
       "      <td>98.208811</td>\n",
       "      <td>38.069587</td>\n",
       "      <td>48.758253</td>\n",
       "      <td>81.459784</td>\n",
       "      <td>37.591024</td>\n",
       "      <td>46.308594</td>\n",
       "      <td>27.785416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>43.783250</td>\n",
       "      <td>61.242096</td>\n",
       "      <td>96.409163</td>\n",
       "      <td>37.961884</td>\n",
       "      <td>48.661035</td>\n",
       "      <td>79.716354</td>\n",
       "      <td>39.039234</td>\n",
       "      <td>48.535581</td>\n",
       "      <td>28.124917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  \\\n",
       "312                                                                \n",
       "1    36.741430   50.158134       83.592770  32.143454  40.085697   \n",
       "2    39.470408   54.969288       95.522637  34.795894  44.225042   \n",
       "3    41.680223   57.114116       99.859528  36.390250  46.246590   \n",
       "4    42.443738   58.707794       98.027542  37.337276  47.697462   \n",
       "5    43.755531   60.876618       98.208811  38.069587  48.758253   \n",
       "6    43.783250   61.242096       96.409163  37.961884  48.661035   \n",
       "\n",
       "     MAPE (%)_val   MAE_test  RMSE_test  MAPE (%)_test  \n",
       "312                                                     \n",
       "1       70.839052  27.752740  34.697609      20.966779  \n",
       "2       79.783376  31.795842  39.782816      24.801321  \n",
       "3       82.792559  32.902194  41.151362      24.901066  \n",
       "4       80.120345  36.159231  44.951097      26.984677  \n",
       "5       81.459784  37.591024  46.308594      27.785416  \n",
       "6       79.716354  39.039234  48.535581      28.124917  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336\n",
      "\n",
      "--- Run 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00367\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00367\n",
      "\n",
      "--- Run 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00380\n",
      "\n",
      "--- Run 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00347\n",
      "\n",
      "--- Run 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00369\n",
      "\n",
      "--- Run 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00363\n",
      "\n",
      "--- Run 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00358\n",
      "\n",
      "--- Run 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00374\n",
      "\n",
      "--- Run 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.00371\n",
      "\n",
      "--- Run 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00365\n",
      "\n",
      "--- Aggregated Mean of All Metrics Across 10(Successful) Runs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.017589</td>\n",
       "      <td>36.578836</td>\n",
       "      <td>37.399108</td>\n",
       "      <td>20.846307</td>\n",
       "      <td>28.025933</td>\n",
       "      <td>31.768537</td>\n",
       "      <td>20.287743</td>\n",
       "      <td>26.235573</td>\n",
       "      <td>15.749606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.328093</td>\n",
       "      <td>41.746731</td>\n",
       "      <td>33.434861</td>\n",
       "      <td>23.396354</td>\n",
       "      <td>32.512713</td>\n",
       "      <td>29.057630</td>\n",
       "      <td>23.968659</td>\n",
       "      <td>31.607059</td>\n",
       "      <td>18.928345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.190905</td>\n",
       "      <td>42.850549</td>\n",
       "      <td>37.240778</td>\n",
       "      <td>24.421886</td>\n",
       "      <td>33.991608</td>\n",
       "      <td>33.278411</td>\n",
       "      <td>26.101502</td>\n",
       "      <td>33.369540</td>\n",
       "      <td>21.162712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.180589</td>\n",
       "      <td>43.655423</td>\n",
       "      <td>45.471073</td>\n",
       "      <td>25.212567</td>\n",
       "      <td>34.614309</td>\n",
       "      <td>39.886365</td>\n",
       "      <td>25.939112</td>\n",
       "      <td>33.128609</td>\n",
       "      <td>20.793604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28.674602</td>\n",
       "      <td>44.940884</td>\n",
       "      <td>45.278287</td>\n",
       "      <td>25.679224</td>\n",
       "      <td>35.651204</td>\n",
       "      <td>39.680740</td>\n",
       "      <td>27.542737</td>\n",
       "      <td>34.854515</td>\n",
       "      <td>22.222976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29.848642</td>\n",
       "      <td>46.047040</td>\n",
       "      <td>50.614557</td>\n",
       "      <td>26.515537</td>\n",
       "      <td>36.713644</td>\n",
       "      <td>45.173431</td>\n",
       "      <td>26.276441</td>\n",
       "      <td>33.973761</td>\n",
       "      <td>21.035802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  \\\n",
       "336                                                                \n",
       "1    24.017589   36.578836       37.399108  20.846307  28.025933   \n",
       "2    26.328093   41.746731       33.434861  23.396354  32.512713   \n",
       "3    27.190905   42.850549       37.240778  24.421886  33.991608   \n",
       "4    28.180589   43.655423       45.471073  25.212567  34.614309   \n",
       "5    28.674602   44.940884       45.278287  25.679224  35.651204   \n",
       "6    29.848642   46.047040       50.614557  26.515537  36.713644   \n",
       "\n",
       "     MAPE (%)_val   MAE_test  RMSE_test  MAPE (%)_test  \n",
       "336                                                     \n",
       "1       31.768537  20.287743  26.235573      15.749606  \n",
       "2       29.057630  23.968659  31.607059      18.928345  \n",
       "3       33.278411  26.101502  33.369540      21.162712  \n",
       "4       39.886365  25.939112  33.128609      20.793604  \n",
       "5       39.680740  27.542737  34.854515      22.222976  \n",
       "6       45.173431  26.276441  33.973761      21.035802  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360\n",
      "\n",
      "--- Run 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.00377\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00398\n",
      "\n",
      "--- Run 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00382\n",
      "\n",
      "--- Run 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00371\n",
      "\n",
      "--- Run 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00380\n",
      "\n",
      "--- Run 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00379\n",
      "\n",
      "--- Run 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00379\n",
      "\n",
      "--- Run 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00396\n",
      "\n",
      "--- Run 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00392\n",
      "\n",
      "--- Run 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Validation loss: 0.00360\n",
      "\n",
      "--- Aggregated Mean of All Metrics Across 10(Successful) Runs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.977679</td>\n",
       "      <td>35.283496</td>\n",
       "      <td>31.589174</td>\n",
       "      <td>20.444360</td>\n",
       "      <td>27.580114</td>\n",
       "      <td>28.442432</td>\n",
       "      <td>18.344509</td>\n",
       "      <td>23.645246</td>\n",
       "      <td>14.641298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.132492</td>\n",
       "      <td>39.561713</td>\n",
       "      <td>39.446994</td>\n",
       "      <td>23.442047</td>\n",
       "      <td>31.896756</td>\n",
       "      <td>35.003533</td>\n",
       "      <td>20.965492</td>\n",
       "      <td>28.029577</td>\n",
       "      <td>16.802465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.643646</td>\n",
       "      <td>41.437152</td>\n",
       "      <td>47.399241</td>\n",
       "      <td>25.063706</td>\n",
       "      <td>34.124409</td>\n",
       "      <td>43.834722</td>\n",
       "      <td>23.318269</td>\n",
       "      <td>30.455929</td>\n",
       "      <td>18.879941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.637438</td>\n",
       "      <td>42.349662</td>\n",
       "      <td>44.589688</td>\n",
       "      <td>25.687827</td>\n",
       "      <td>35.610657</td>\n",
       "      <td>42.672819</td>\n",
       "      <td>25.692351</td>\n",
       "      <td>33.073473</td>\n",
       "      <td>20.437703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28.140629</td>\n",
       "      <td>43.260718</td>\n",
       "      <td>41.421664</td>\n",
       "      <td>26.881949</td>\n",
       "      <td>37.552460</td>\n",
       "      <td>41.346436</td>\n",
       "      <td>28.536280</td>\n",
       "      <td>35.932118</td>\n",
       "      <td>22.921848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29.619809</td>\n",
       "      <td>44.738203</td>\n",
       "      <td>48.150484</td>\n",
       "      <td>27.726139</td>\n",
       "      <td>38.438204</td>\n",
       "      <td>48.280128</td>\n",
       "      <td>28.387027</td>\n",
       "      <td>36.067652</td>\n",
       "      <td>22.731905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  \\\n",
       "360                                                                \n",
       "1    22.977679   35.283496       31.589174  20.444360  27.580114   \n",
       "2    26.132492   39.561713       39.446994  23.442047  31.896756   \n",
       "3    27.643646   41.437152       47.399241  25.063706  34.124409   \n",
       "4    27.637438   42.349662       44.589688  25.687827  35.610657   \n",
       "5    28.140629   43.260718       41.421664  26.881949  37.552460   \n",
       "6    29.619809   44.738203       48.150484  27.726139  38.438204   \n",
       "\n",
       "     MAPE (%)_val   MAE_test  RMSE_test  MAPE (%)_test  \n",
       "360                                                     \n",
       "1       28.442432  18.344509  23.645246      14.641298  \n",
       "2       35.003533  20.965492  28.029577      16.802465  \n",
       "3       43.834722  23.318269  30.455929      18.879941  \n",
       "4       42.672819  25.692351  33.073473      20.437703  \n",
       "5       41.346436  28.536280  35.932118      22.921848  \n",
       "6       48.280128  28.387027  36.067652      22.731905  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n",
      "\n",
      "--- Run 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00394\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00367\n",
      "\n",
      "--- Run 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00365\n",
      "\n",
      "--- Run 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00374\n",
      "\n",
      "--- Run 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00391\n",
      "\n",
      "--- Run 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00386\n",
      "\n",
      "--- Run 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00371\n",
      "\n",
      "--- Run 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00375\n",
      "\n",
      "--- Run 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00383\n",
      "\n",
      "--- Run 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00394\n",
      "\n",
      "--- Aggregated Mean of All Metrics Across 10(Successful) Runs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.554154</td>\n",
       "      <td>37.557316</td>\n",
       "      <td>53.482610</td>\n",
       "      <td>22.582603</td>\n",
       "      <td>28.939275</td>\n",
       "      <td>43.004425</td>\n",
       "      <td>17.272020</td>\n",
       "      <td>21.741749</td>\n",
       "      <td>14.523074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.654648</td>\n",
       "      <td>42.605961</td>\n",
       "      <td>59.826092</td>\n",
       "      <td>24.943263</td>\n",
       "      <td>32.415872</td>\n",
       "      <td>46.880764</td>\n",
       "      <td>18.654437</td>\n",
       "      <td>24.647761</td>\n",
       "      <td>15.368607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.991060</td>\n",
       "      <td>45.357866</td>\n",
       "      <td>71.093066</td>\n",
       "      <td>26.790628</td>\n",
       "      <td>34.871550</td>\n",
       "      <td>55.554697</td>\n",
       "      <td>20.820174</td>\n",
       "      <td>27.096035</td>\n",
       "      <td>17.301018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.615775</td>\n",
       "      <td>45.805417</td>\n",
       "      <td>58.654270</td>\n",
       "      <td>25.986860</td>\n",
       "      <td>35.407572</td>\n",
       "      <td>47.104161</td>\n",
       "      <td>23.652781</td>\n",
       "      <td>30.358622</td>\n",
       "      <td>19.692243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31.049075</td>\n",
       "      <td>47.366677</td>\n",
       "      <td>57.822716</td>\n",
       "      <td>26.112042</td>\n",
       "      <td>36.241731</td>\n",
       "      <td>45.556694</td>\n",
       "      <td>24.791854</td>\n",
       "      <td>31.885084</td>\n",
       "      <td>20.819309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31.782567</td>\n",
       "      <td>48.997711</td>\n",
       "      <td>56.054943</td>\n",
       "      <td>26.466709</td>\n",
       "      <td>37.371695</td>\n",
       "      <td>45.053390</td>\n",
       "      <td>26.339262</td>\n",
       "      <td>34.224083</td>\n",
       "      <td>22.084627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  \\\n",
       "384                                                                \n",
       "1    26.554154   37.557316       53.482610  22.582603  28.939275   \n",
       "2    29.654648   42.605961       59.826092  24.943263  32.415872   \n",
       "3    31.991060   45.357866       71.093066  26.790628  34.871550   \n",
       "4    30.615775   45.805417       58.654270  25.986860  35.407572   \n",
       "5    31.049075   47.366677       57.822716  26.112042  36.241731   \n",
       "6    31.782567   48.997711       56.054943  26.466709  37.371695   \n",
       "\n",
       "     MAPE (%)_val   MAE_test  RMSE_test  MAPE (%)_test  \n",
       "384                                                     \n",
       "1       43.004425  17.272020  21.741749      14.523074  \n",
       "2       46.880764  18.654437  24.647761      15.368607  \n",
       "3       55.554697  20.820174  27.096035      17.301018  \n",
       "4       47.104161  23.652781  30.358622      19.692243  \n",
       "5       45.556694  24.791854  31.885084      20.819309  \n",
       "6       45.053390  26.339262  34.224083      22.084627  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408\n",
      "\n",
      "--- Run 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00408\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00395\n",
      "\n",
      "--- Run 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00390\n",
      "\n",
      "--- Run 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00385\n",
      "\n",
      "--- Run 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00394\n",
      "\n",
      "--- Run 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00387\n",
      "\n",
      "--- Run 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00403\n",
      "\n",
      "--- Run 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00389\n",
      "\n",
      "--- Run 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00378\n",
      "\n",
      "--- Run 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00395\n",
      "\n",
      "--- Aggregated Mean of All Metrics Across 10(Successful) Runs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.565126</td>\n",
       "      <td>36.873910</td>\n",
       "      <td>40.805449</td>\n",
       "      <td>22.212098</td>\n",
       "      <td>29.304551</td>\n",
       "      <td>35.758433</td>\n",
       "      <td>18.262441</td>\n",
       "      <td>23.093048</td>\n",
       "      <td>15.092710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.946071</td>\n",
       "      <td>40.837023</td>\n",
       "      <td>39.343543</td>\n",
       "      <td>23.286862</td>\n",
       "      <td>32.563373</td>\n",
       "      <td>33.364490</td>\n",
       "      <td>21.682196</td>\n",
       "      <td>28.733383</td>\n",
       "      <td>17.677449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.619125</td>\n",
       "      <td>42.840560</td>\n",
       "      <td>47.670359</td>\n",
       "      <td>24.697230</td>\n",
       "      <td>34.833005</td>\n",
       "      <td>39.780893</td>\n",
       "      <td>23.468588</td>\n",
       "      <td>30.572625</td>\n",
       "      <td>19.192711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.714795</td>\n",
       "      <td>44.972836</td>\n",
       "      <td>55.942461</td>\n",
       "      <td>26.345618</td>\n",
       "      <td>36.495583</td>\n",
       "      <td>44.910388</td>\n",
       "      <td>24.372954</td>\n",
       "      <td>31.443555</td>\n",
       "      <td>20.018952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.126260</td>\n",
       "      <td>46.091305</td>\n",
       "      <td>51.042127</td>\n",
       "      <td>25.935070</td>\n",
       "      <td>37.190000</td>\n",
       "      <td>41.240243</td>\n",
       "      <td>26.871671</td>\n",
       "      <td>34.396513</td>\n",
       "      <td>22.185663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31.140186</td>\n",
       "      <td>47.922021</td>\n",
       "      <td>55.276917</td>\n",
       "      <td>26.520516</td>\n",
       "      <td>38.147397</td>\n",
       "      <td>45.059312</td>\n",
       "      <td>27.410737</td>\n",
       "      <td>35.161710</td>\n",
       "      <td>22.499300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  \\\n",
       "408                                                                \n",
       "1    25.565126   36.873910       40.805449  22.212098  29.304551   \n",
       "2    26.946071   40.837023       39.343543  23.286862  32.563373   \n",
       "3    28.619125   42.840560       47.670359  24.697230  34.833005   \n",
       "4    30.714795   44.972836       55.942461  26.345618  36.495583   \n",
       "5    30.126260   46.091305       51.042127  25.935070  37.190000   \n",
       "6    31.140186   47.922021       55.276917  26.520516  38.147397   \n",
       "\n",
       "     MAPE (%)_val   MAE_test  RMSE_test  MAPE (%)_test  \n",
       "408                                                     \n",
       "1       35.758433  18.262441  23.093048      15.092710  \n",
       "2       33.364490  21.682196  28.733383      17.677449  \n",
       "3       39.780893  23.468588  30.572625      19.192711  \n",
       "4       44.910388  24.372954  31.443555      20.018952  \n",
       "5       41.240243  26.871671  34.396513      22.185663  \n",
       "6       45.059312  27.410737  35.161710      22.499300  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432\n",
      "\n",
      "--- Run 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00443\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00408\n",
      "\n",
      "--- Run 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00430\n",
      "\n",
      "--- Run 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00392\n",
      "\n",
      "--- Run 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00390\n",
      "\n",
      "--- Run 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00410\n",
      "\n",
      "--- Run 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00413\n",
      "\n",
      "--- Run 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 99.\n",
      "Validation loss: 0.01153\n",
      "\n",
      "--- Run 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00399\n",
      "\n",
      "--- Run 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00587\n",
      "\n",
      "--- Aggregated Mean of All Metrics Across 10(Successful) Runs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.078741</td>\n",
       "      <td>37.202099</td>\n",
       "      <td>38.420782</td>\n",
       "      <td>22.266586</td>\n",
       "      <td>29.649385</td>\n",
       "      <td>33.924273</td>\n",
       "      <td>19.111274</td>\n",
       "      <td>24.345586</td>\n",
       "      <td>15.606089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.529642</td>\n",
       "      <td>43.919688</td>\n",
       "      <td>46.551889</td>\n",
       "      <td>26.258396</td>\n",
       "      <td>35.550761</td>\n",
       "      <td>37.728502</td>\n",
       "      <td>25.512440</td>\n",
       "      <td>32.968776</td>\n",
       "      <td>21.038644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.481434</td>\n",
       "      <td>46.933801</td>\n",
       "      <td>51.870964</td>\n",
       "      <td>28.949553</td>\n",
       "      <td>38.916601</td>\n",
       "      <td>44.748128</td>\n",
       "      <td>26.954785</td>\n",
       "      <td>34.478749</td>\n",
       "      <td>21.457388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.790120</td>\n",
       "      <td>48.565520</td>\n",
       "      <td>65.657155</td>\n",
       "      <td>30.018013</td>\n",
       "      <td>40.290255</td>\n",
       "      <td>54.721975</td>\n",
       "      <td>26.628824</td>\n",
       "      <td>33.912470</td>\n",
       "      <td>21.915142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35.164589</td>\n",
       "      <td>50.578265</td>\n",
       "      <td>64.229944</td>\n",
       "      <td>31.017476</td>\n",
       "      <td>42.107496</td>\n",
       "      <td>51.993197</td>\n",
       "      <td>29.754327</td>\n",
       "      <td>37.568716</td>\n",
       "      <td>23.525294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>37.023187</td>\n",
       "      <td>52.821018</td>\n",
       "      <td>67.683549</td>\n",
       "      <td>32.271556</td>\n",
       "      <td>44.110325</td>\n",
       "      <td>52.074047</td>\n",
       "      <td>31.102400</td>\n",
       "      <td>39.506884</td>\n",
       "      <td>24.110985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  \\\n",
       "432                                                                \n",
       "1    25.078741   37.202099       38.420782  22.266586  29.649385   \n",
       "2    29.529642   43.919688       46.551889  26.258396  35.550761   \n",
       "3    32.481434   46.933801       51.870964  28.949553  38.916601   \n",
       "4    33.790120   48.565520       65.657155  30.018013  40.290255   \n",
       "5    35.164589   50.578265       64.229944  31.017476  42.107496   \n",
       "6    37.023187   52.821018       67.683549  32.271556  44.110325   \n",
       "\n",
       "     MAPE (%)_val   MAE_test  RMSE_test  MAPE (%)_test  \n",
       "432                                                     \n",
       "1       33.924273  19.111274  24.345586      15.606089  \n",
       "2       37.728502  25.512440  32.968776      21.038644  \n",
       "3       44.748128  26.954785  34.478749      21.457388  \n",
       "4       54.721975  26.628824  33.912470      21.915142  \n",
       "5       51.993197  29.754327  37.568716      23.525294  \n",
       "6       52.074047  31.102400  39.506884      24.110985  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456\n",
      "\n",
      "--- Run 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00395\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.00419\n",
      "\n",
      "--- Run 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.00413\n",
      "\n",
      "--- Run 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00409\n",
      "\n",
      "--- Run 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81: early stopping\n",
      "Restoring model weights from the end of the best epoch: 61.\n",
      "Validation loss: 0.00417\n",
      "\n",
      "--- Run 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00426\n",
      "\n",
      "--- Run 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00432\n",
      "\n",
      "--- Run 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00431\n",
      "\n",
      "--- Run 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00419\n",
      "\n",
      "--- Run 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00426\n",
      "\n",
      "--- Aggregated Mean of All Metrics Across 10(Successful) Runs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.124354</td>\n",
       "      <td>37.034229</td>\n",
       "      <td>38.328891</td>\n",
       "      <td>20.705802</td>\n",
       "      <td>29.120491</td>\n",
       "      <td>29.916736</td>\n",
       "      <td>19.549900</td>\n",
       "      <td>25.571666</td>\n",
       "      <td>15.056061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.645345</td>\n",
       "      <td>40.386788</td>\n",
       "      <td>36.457163</td>\n",
       "      <td>22.806453</td>\n",
       "      <td>32.975764</td>\n",
       "      <td>29.275083</td>\n",
       "      <td>22.819279</td>\n",
       "      <td>30.397785</td>\n",
       "      <td>18.201629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.016475</td>\n",
       "      <td>41.961595</td>\n",
       "      <td>51.547705</td>\n",
       "      <td>24.817072</td>\n",
       "      <td>35.224923</td>\n",
       "      <td>39.361090</td>\n",
       "      <td>24.072699</td>\n",
       "      <td>31.182509</td>\n",
       "      <td>19.425672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.646425</td>\n",
       "      <td>43.390364</td>\n",
       "      <td>60.364754</td>\n",
       "      <td>26.222132</td>\n",
       "      <td>36.761215</td>\n",
       "      <td>45.132369</td>\n",
       "      <td>24.715984</td>\n",
       "      <td>31.972549</td>\n",
       "      <td>19.813388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31.814546</td>\n",
       "      <td>45.159097</td>\n",
       "      <td>67.716151</td>\n",
       "      <td>28.282530</td>\n",
       "      <td>39.236608</td>\n",
       "      <td>49.908947</td>\n",
       "      <td>25.092982</td>\n",
       "      <td>32.211407</td>\n",
       "      <td>20.118385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33.845772</td>\n",
       "      <td>47.081584</td>\n",
       "      <td>75.484380</td>\n",
       "      <td>30.203234</td>\n",
       "      <td>41.562056</td>\n",
       "      <td>55.632470</td>\n",
       "      <td>25.342037</td>\n",
       "      <td>32.639716</td>\n",
       "      <td>20.098824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  \\\n",
       "456                                                                \n",
       "1    24.124354   37.034229       38.328891  20.705802  29.120491   \n",
       "2    25.645345   40.386788       36.457163  22.806453  32.975764   \n",
       "3    28.016475   41.961595       51.547705  24.817072  35.224923   \n",
       "4    29.646425   43.390364       60.364754  26.222132  36.761215   \n",
       "5    31.814546   45.159097       67.716151  28.282530  39.236608   \n",
       "6    33.845772   47.081584       75.484380  30.203234  41.562056   \n",
       "\n",
       "     MAPE (%)_val   MAE_test  RMSE_test  MAPE (%)_test  \n",
       "456                                                     \n",
       "1       29.916736  19.549900  25.571666      15.056061  \n",
       "2       29.275083  22.819279  30.397785      18.201629  \n",
       "3       39.361090  24.072699  31.182509      19.425672  \n",
       "4       45.132369  24.715984  31.972549      19.813388  \n",
       "5       49.908947  25.092982  32.211407      20.118385  \n",
       "6       55.632470  25.342037  32.639716      20.098824  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480\n",
      "\n",
      "--- Run 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00455\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00462\n",
      "\n",
      "--- Run 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00474\n",
      "\n",
      "--- Run 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00456\n",
      "\n",
      "--- Run 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00476\n",
      "\n",
      "--- Run 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00426\n",
      "\n",
      "--- Run 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00447\n",
      "\n",
      "--- Run 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00459\n",
      "\n",
      "--- Run 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00463\n",
      "\n",
      "--- Run 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00461\n",
      "\n",
      "--- Aggregated Mean of All Metrics Across 10(Successful) Runs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.335358</td>\n",
       "      <td>36.485292</td>\n",
       "      <td>40.151909</td>\n",
       "      <td>22.000830</td>\n",
       "      <td>29.803699</td>\n",
       "      <td>34.104047</td>\n",
       "      <td>18.275501</td>\n",
       "      <td>23.811042</td>\n",
       "      <td>14.576091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.311253</td>\n",
       "      <td>41.722027</td>\n",
       "      <td>51.699844</td>\n",
       "      <td>25.140067</td>\n",
       "      <td>34.228807</td>\n",
       "      <td>41.904762</td>\n",
       "      <td>19.748246</td>\n",
       "      <td>26.618970</td>\n",
       "      <td>15.809875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.679138</td>\n",
       "      <td>43.966837</td>\n",
       "      <td>55.422746</td>\n",
       "      <td>26.868776</td>\n",
       "      <td>37.425523</td>\n",
       "      <td>45.951627</td>\n",
       "      <td>21.472353</td>\n",
       "      <td>28.163492</td>\n",
       "      <td>17.275427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.971991</td>\n",
       "      <td>45.388001</td>\n",
       "      <td>53.118449</td>\n",
       "      <td>27.941086</td>\n",
       "      <td>39.545146</td>\n",
       "      <td>45.999619</td>\n",
       "      <td>23.367419</td>\n",
       "      <td>30.264661</td>\n",
       "      <td>18.686259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31.269519</td>\n",
       "      <td>46.448760</td>\n",
       "      <td>61.209413</td>\n",
       "      <td>28.847110</td>\n",
       "      <td>40.852489</td>\n",
       "      <td>50.578403</td>\n",
       "      <td>23.760041</td>\n",
       "      <td>30.546821</td>\n",
       "      <td>18.770599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33.527027</td>\n",
       "      <td>48.479822</td>\n",
       "      <td>71.767859</td>\n",
       "      <td>30.564468</td>\n",
       "      <td>42.771600</td>\n",
       "      <td>57.600401</td>\n",
       "      <td>24.392097</td>\n",
       "      <td>31.191181</td>\n",
       "      <td>19.520061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  \\\n",
       "480                                                                \n",
       "1    24.335358   36.485292       40.151909  22.000830  29.803699   \n",
       "2    28.311253   41.722027       51.699844  25.140067  34.228807   \n",
       "3    29.679138   43.966837       55.422746  26.868776  37.425523   \n",
       "4    29.971991   45.388001       53.118449  27.941086  39.545146   \n",
       "5    31.269519   46.448760       61.209413  28.847110  40.852489   \n",
       "6    33.527027   48.479822       71.767859  30.564468  42.771600   \n",
       "\n",
       "     MAPE (%)_val   MAE_test  RMSE_test  MAPE (%)_test  \n",
       "480                                                     \n",
       "1       34.104047  18.275501  23.811042      14.576091  \n",
       "2       41.904762  19.748246  26.618970      15.809875  \n",
       "3       45.951627  21.472353  28.163492      17.275427  \n",
       "4       45.999619  23.367419  30.264661      18.686259  \n",
       "5       50.578403  23.760041  30.546821      18.770599  \n",
       "6       57.600401  24.392097  31.191181      19.520061  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504\n",
      "\n",
      "--- Run 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00485\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00517\n",
      "\n",
      "--- Run 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00484\n",
      "\n",
      "--- Run 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00487\n",
      "\n",
      "--- Run 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00513\n",
      "\n",
      "--- Run 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00500\n",
      "\n",
      "--- Run 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.00470\n",
      "\n",
      "--- Run 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00508\n",
      "\n",
      "--- Run 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00483\n",
      "\n",
      "--- Run 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00498\n",
      "\n",
      "--- Aggregated Mean of All Metrics Across 10(Successful) Runs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.437523</td>\n",
       "      <td>36.895169</td>\n",
       "      <td>40.192395</td>\n",
       "      <td>21.869076</td>\n",
       "      <td>30.278837</td>\n",
       "      <td>31.954081</td>\n",
       "      <td>17.242091</td>\n",
       "      <td>22.192812</td>\n",
       "      <td>13.667913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.642632</td>\n",
       "      <td>42.160320</td>\n",
       "      <td>47.552446</td>\n",
       "      <td>25.281977</td>\n",
       "      <td>35.394933</td>\n",
       "      <td>37.764499</td>\n",
       "      <td>19.521691</td>\n",
       "      <td>27.085787</td>\n",
       "      <td>15.163745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.594327</td>\n",
       "      <td>44.322099</td>\n",
       "      <td>62.799457</td>\n",
       "      <td>28.732541</td>\n",
       "      <td>38.985483</td>\n",
       "      <td>50.600326</td>\n",
       "      <td>20.480774</td>\n",
       "      <td>27.080239</td>\n",
       "      <td>16.710727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.874488</td>\n",
       "      <td>45.291273</td>\n",
       "      <td>61.994854</td>\n",
       "      <td>29.704768</td>\n",
       "      <td>40.866318</td>\n",
       "      <td>51.571524</td>\n",
       "      <td>22.175583</td>\n",
       "      <td>29.272003</td>\n",
       "      <td>17.857529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31.399790</td>\n",
       "      <td>46.320179</td>\n",
       "      <td>62.112553</td>\n",
       "      <td>30.595776</td>\n",
       "      <td>42.986726</td>\n",
       "      <td>52.059590</td>\n",
       "      <td>24.373437</td>\n",
       "      <td>31.268802</td>\n",
       "      <td>19.683108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31.140285</td>\n",
       "      <td>47.365245</td>\n",
       "      <td>55.587253</td>\n",
       "      <td>30.811950</td>\n",
       "      <td>44.671681</td>\n",
       "      <td>49.329855</td>\n",
       "      <td>26.204565</td>\n",
       "      <td>33.793986</td>\n",
       "      <td>21.272511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  \\\n",
       "504                                                                \n",
       "1    24.437523   36.895169       40.192395  21.869076  30.278837   \n",
       "2    27.642632   42.160320       47.552446  25.281977  35.394933   \n",
       "3    30.594327   44.322099       62.799457  28.732541  38.985483   \n",
       "4    30.874488   45.291273       61.994854  29.704768  40.866318   \n",
       "5    31.399790   46.320179       62.112553  30.595776  42.986726   \n",
       "6    31.140285   47.365245       55.587253  30.811950  44.671681   \n",
       "\n",
       "     MAPE (%)_val   MAE_test  RMSE_test  MAPE (%)_test  \n",
       "504                                                     \n",
       "1       31.954081  17.242091  22.192812      13.667913  \n",
       "2       37.764499  19.521691  27.085787      15.163745  \n",
       "3       50.600326  20.480774  27.080239      16.710727  \n",
       "4       51.571524  22.175583  29.272003      17.857529  \n",
       "5       52.059590  24.373437  31.268802      19.683108  \n",
       "6       49.329855  26.204565  33.793986      21.272511  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Mean Metrics Across 10 Runs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_len</th>\n",
       "      <th>MSE_val(loss)</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0.004352</td>\n",
       "      <td>26.075734</td>\n",
       "      <td>36.575108</td>\n",
       "      <td>36.141437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.0</td>\n",
       "      <td>0.004533</td>\n",
       "      <td>26.827071</td>\n",
       "      <td>37.359961</td>\n",
       "      <td>39.349044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72.0</td>\n",
       "      <td>0.004344</td>\n",
       "      <td>26.719602</td>\n",
       "      <td>36.558082</td>\n",
       "      <td>42.893349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96.0</td>\n",
       "      <td>0.004446</td>\n",
       "      <td>27.510904</td>\n",
       "      <td>36.964399</td>\n",
       "      <td>48.375805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.004159</td>\n",
       "      <td>26.048971</td>\n",
       "      <td>35.735612</td>\n",
       "      <td>42.063237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>144.0</td>\n",
       "      <td>0.009042</td>\n",
       "      <td>36.686733</td>\n",
       "      <td>46.998828</td>\n",
       "      <td>77.012072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>168.0</td>\n",
       "      <td>0.004285</td>\n",
       "      <td>26.759954</td>\n",
       "      <td>36.270308</td>\n",
       "      <td>42.013017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>192.0</td>\n",
       "      <td>0.004378</td>\n",
       "      <td>27.576613</td>\n",
       "      <td>36.715205</td>\n",
       "      <td>47.948372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>216.0</td>\n",
       "      <td>0.004095</td>\n",
       "      <td>27.215303</td>\n",
       "      <td>35.410625</td>\n",
       "      <td>49.929277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>240.0</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>25.409210</td>\n",
       "      <td>34.998009</td>\n",
       "      <td>37.554112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>264.0</td>\n",
       "      <td>0.004122</td>\n",
       "      <td>26.484752</td>\n",
       "      <td>35.577179</td>\n",
       "      <td>45.076296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>288.0</td>\n",
       "      <td>0.004137</td>\n",
       "      <td>26.319936</td>\n",
       "      <td>35.643109</td>\n",
       "      <td>40.256043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>312.0</td>\n",
       "      <td>0.007445</td>\n",
       "      <td>36.116391</td>\n",
       "      <td>45.945680</td>\n",
       "      <td>79.118578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>336.0</td>\n",
       "      <td>0.003662</td>\n",
       "      <td>24.345313</td>\n",
       "      <td>33.584902</td>\n",
       "      <td>36.474186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>360.0</td>\n",
       "      <td>0.003814</td>\n",
       "      <td>24.874338</td>\n",
       "      <td>34.200433</td>\n",
       "      <td>39.930012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>384.0</td>\n",
       "      <td>0.003799</td>\n",
       "      <td>25.480351</td>\n",
       "      <td>34.207949</td>\n",
       "      <td>47.192355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>408.0</td>\n",
       "      <td>0.003924</td>\n",
       "      <td>24.832899</td>\n",
       "      <td>34.755651</td>\n",
       "      <td>40.018960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>432.0</td>\n",
       "      <td>0.005023</td>\n",
       "      <td>28.463597</td>\n",
       "      <td>38.437471</td>\n",
       "      <td>45.865020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>456.0</td>\n",
       "      <td>0.004188</td>\n",
       "      <td>25.506204</td>\n",
       "      <td>35.813509</td>\n",
       "      <td>41.537782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>480.0</td>\n",
       "      <td>0.004580</td>\n",
       "      <td>26.893723</td>\n",
       "      <td>37.437877</td>\n",
       "      <td>46.023143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>504.0</td>\n",
       "      <td>0.004945</td>\n",
       "      <td>27.832681</td>\n",
       "      <td>38.863996</td>\n",
       "      <td>45.546646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    input_len  MSE_val(loss)    MAE_val   RMSE_val  MAPE (%)_val\n",
       "0        24.0       0.004352  26.075734  36.575108     36.141437\n",
       "1        48.0       0.004533  26.827071  37.359961     39.349044\n",
       "2        72.0       0.004344  26.719602  36.558082     42.893349\n",
       "3        96.0       0.004446  27.510904  36.964399     48.375805\n",
       "4       120.0       0.004159  26.048971  35.735612     42.063237\n",
       "5       144.0       0.009042  36.686733  46.998828     77.012072\n",
       "6       168.0       0.004285  26.759954  36.270308     42.013017\n",
       "7       192.0       0.004378  27.576613  36.715205     47.948372\n",
       "8       216.0       0.004095  27.215303  35.410625     49.929277\n",
       "9       240.0       0.003989  25.409210  34.998009     37.554112\n",
       "10      264.0       0.004122  26.484752  35.577179     45.076296\n",
       "11      288.0       0.004137  26.319936  35.643109     40.256043\n",
       "12      312.0       0.007445  36.116391  45.945680     79.118578\n",
       "13      336.0       0.003662  24.345313  33.584902     36.474186\n",
       "14      360.0       0.003814  24.874338  34.200433     39.930012\n",
       "15      384.0       0.003799  25.480351  34.207949     47.192355\n",
       "16      408.0       0.003924  24.832899  34.755651     40.018960\n",
       "17      432.0       0.005023  28.463597  38.437471     45.865020\n",
       "18      456.0       0.004188  25.506204  35.813509     41.537782\n",
       "19      480.0       0.004580  26.893723  37.437877     46.023143\n",
       "20      504.0       0.004945  27.832681  38.863996     45.546646"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_metrics_list=[]\n",
    "for length in best_hyperparameters.keys():\n",
    "    print(length)\n",
    "    \n",
    "    # Number of runs\n",
    "    n_runs = 10\n",
    "    \n",
    "    # get the best hyperparameter of each length\n",
    "    hyperparams = best_hyperparameters[length]\n",
    "    \n",
    "    # Initialize lists to store mean metrics and all metrics from each run\n",
    "    mean_metrics_rows = []\n",
    "    df_all_metrics_list = []\n",
    "    successful_runs = []  # To track runs with valid mse\n",
    "\n",
    "    for run in range(1, n_runs + 1):\n",
    "        print(f\"\\n--- Run {run} ---\")\n",
    "\n",
    "        # Optionally set a unique seed for each run to ensure variability\n",
    "        seed = run  \n",
    "        # Train the model\n",
    "        model, mse = train_model(hyperparams, data_dict, length, seed=None)\n",
    "        \n",
    "        if not np.isnan(mse):  # Only proceed if mse is valid\n",
    "            successful_runs.append(run)\n",
    "        \n",
    "            X_train = data_dict[length]['X_train']\n",
    "            y_train = data_dict[length]['y_train']\n",
    "            X_val = data_dict[length]['X_val']\n",
    "            y_val = data_dict[length]['y_val']\n",
    "            X_test = data_dict[length]['X_test']\n",
    "            y_test = data_dict[length]['y_test']\n",
    "\n",
    "            #get the true flow and predicted flow\n",
    "            y_pred_train, y_obs_train = make_prediction(model, X_train, y_train)\n",
    "            y_pred_val, y_obs_val = make_prediction(model, X_val, y_val)\n",
    "            y_pred_test, y_obs_test = make_prediction(model, X_test, y_test)\n",
    "\n",
    "            #calculate the evaluation metrics of each output step\n",
    "            df_train = evaluation(y_pred_train, y_obs_train).add_suffix('_train')\n",
    "            df_val = evaluation(y_pred_val, y_obs_val).add_suffix('_val')\n",
    "            df_test = evaluation(y_pred_test, y_obs_test).add_suffix('_test')\n",
    "\n",
    "            df_all_metrics = pd.concat([df_train, df_val, df_test], axis=1)\n",
    "            df_all_metrics.index.name = length\n",
    "\n",
    "            # Append df_all_metrics to the list\n",
    "            df_all_metrics_list.append(df_all_metrics)\n",
    "\n",
    "            # Calculate mean for all output step\n",
    "            mean_metrics = df_val.mean()\n",
    "            mean_metrics_row = pd.DataFrame(mean_metrics).T\n",
    "            mean_metrics_row['MSE_val(loss)'] = mse\n",
    "            mean_metrics_row['input_len'] = length\n",
    "            mean_metrics_row = mean_metrics_row[['input_len','MSE_val(loss)', 'MAE_val', 'RMSE_val', 'MAPE (%)_val']]\n",
    "\n",
    "            # Append to the list\n",
    "            mean_metrics_rows.append(mean_metrics_row)\n",
    "        else:\n",
    "            print(f\"Run {run} has mse=NaN, skipping.\")\n",
    "            \n",
    "    # Check if there are successful runs before proceeding\n",
    "    if successful_runs:       \n",
    "        # Concatenate all df_all_metrics into a single DataFrame with a new level for runs\n",
    "        concatenated_all_metrics = pd.concat(df_all_metrics_list, keys=successful_runs, names=['Run', 'Time Step'])\n",
    "\n",
    "        # Calculate the mean across runs for each metric and time step\n",
    "        # This will group by 'Time Step' and calculate the mean of each metric across all runs\n",
    "        aggregated_all_metrics_mean = concatenated_all_metrics.groupby('Time Step').mean()\n",
    "        aggregated_all_metrics_mean.index.name = length\n",
    "\n",
    "        print(\"\\n--- Aggregated Mean of All Metrics Across 10(Successful) Runs ---\")\n",
    "        display(aggregated_all_metrics_mean)\n",
    "    else:\n",
    "        print(f\"No successful runs for input length {length}.\")\n",
    "\n",
    "    # Check if mean metrics were calculated\n",
    "    if mean_metrics_rows:        \n",
    "        # After all runs, create a DataFrame of mean metrics\n",
    "        mean_metrics_df = pd.concat(mean_metrics_rows, ignore_index=True)\n",
    "        # Calculate the mean of each metric across the 10 runs\n",
    "        final_mean_metrics = mean_metrics_df.mean()\n",
    "\n",
    "        # Create a DataFrame for the final mean metrics\n",
    "        final_mean_metrics_df = pd.DataFrame(final_mean_metrics).T\n",
    "\n",
    "        mean_metrics_list.append(final_mean_metrics_df)\n",
    "    else:\n",
    "        print(f\"No mean metrics calculated for input length {length}.\")\n",
    "\n",
    "mean_metrics_df = pd.concat(mean_metrics_list).reset_index(drop=True)\n",
    "print(\"\\n--- Final Mean Metrics Across 10 Runs ---\")\n",
    "mean_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_len</th>\n",
       "      <th>MSE_val(loss)</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0.004344</td>\n",
       "      <td>26.450901</td>\n",
       "      <td>36.539717</td>\n",
       "      <td>40.722890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.0</td>\n",
       "      <td>0.004478</td>\n",
       "      <td>26.931823</td>\n",
       "      <td>37.109859</td>\n",
       "      <td>42.989776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72.0</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>26.607962</td>\n",
       "      <td>36.727637</td>\n",
       "      <td>42.190481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96.0</td>\n",
       "      <td>0.004336</td>\n",
       "      <td>26.730271</td>\n",
       "      <td>36.506968</td>\n",
       "      <td>44.845428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.004108</td>\n",
       "      <td>25.808064</td>\n",
       "      <td>35.517040</td>\n",
       "      <td>40.255929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>144.0</td>\n",
       "      <td>0.004408</td>\n",
       "      <td>26.976205</td>\n",
       "      <td>36.725114</td>\n",
       "      <td>43.864890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>168.0</td>\n",
       "      <td>0.004302</td>\n",
       "      <td>26.657290</td>\n",
       "      <td>36.322715</td>\n",
       "      <td>41.410898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>192.0</td>\n",
       "      <td>0.004313</td>\n",
       "      <td>27.140338</td>\n",
       "      <td>36.399797</td>\n",
       "      <td>43.658197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>216.0</td>\n",
       "      <td>0.003907</td>\n",
       "      <td>25.701403</td>\n",
       "      <td>34.660854</td>\n",
       "      <td>40.941989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>240.0</td>\n",
       "      <td>0.003988</td>\n",
       "      <td>25.933874</td>\n",
       "      <td>35.003405</td>\n",
       "      <td>41.449988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>264.0</td>\n",
       "      <td>0.004070</td>\n",
       "      <td>26.118716</td>\n",
       "      <td>35.363539</td>\n",
       "      <td>41.230615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>288.0</td>\n",
       "      <td>0.004051</td>\n",
       "      <td>26.409709</td>\n",
       "      <td>35.281968</td>\n",
       "      <td>43.628376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>312.0</td>\n",
       "      <td>0.007058</td>\n",
       "      <td>35.321855</td>\n",
       "      <td>44.827733</td>\n",
       "      <td>77.083331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>336.0</td>\n",
       "      <td>0.003827</td>\n",
       "      <td>25.578705</td>\n",
       "      <td>34.294322</td>\n",
       "      <td>45.089553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>360.0</td>\n",
       "      <td>0.003780</td>\n",
       "      <td>24.765925</td>\n",
       "      <td>34.082825</td>\n",
       "      <td>39.811573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>384.0</td>\n",
       "      <td>0.003845</td>\n",
       "      <td>25.114309</td>\n",
       "      <td>34.355709</td>\n",
       "      <td>41.315591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>408.0</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>24.805567</td>\n",
       "      <td>34.906887</td>\n",
       "      <td>38.653941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>432.0</td>\n",
       "      <td>0.005409</td>\n",
       "      <td>29.581222</td>\n",
       "      <td>39.670503</td>\n",
       "      <td>52.209723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>456.0</td>\n",
       "      <td>0.004053</td>\n",
       "      <td>25.121623</td>\n",
       "      <td>35.245764</td>\n",
       "      <td>41.415108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>480.0</td>\n",
       "      <td>0.004539</td>\n",
       "      <td>26.236808</td>\n",
       "      <td>37.274812</td>\n",
       "      <td>38.471242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>504.0</td>\n",
       "      <td>0.005052</td>\n",
       "      <td>27.780734</td>\n",
       "      <td>39.300484</td>\n",
       "      <td>42.215525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    input_len  MSE_val(loss)    MAE_val   RMSE_val  MAPE (%)_val\n",
       "0        24.0       0.004344  26.450901  36.539717     40.722890\n",
       "1        48.0       0.004478  26.931823  37.109859     42.989776\n",
       "2        72.0       0.004387  26.607962  36.727637     42.190481\n",
       "3        96.0       0.004336  26.730271  36.506968     44.845428\n",
       "4       120.0       0.004108  25.808064  35.517040     40.255929\n",
       "5       144.0       0.004408  26.976205  36.725114     43.864890\n",
       "6       168.0       0.004302  26.657290  36.322715     41.410898\n",
       "7       192.0       0.004313  27.140338  36.399797     43.658197\n",
       "8       216.0       0.003907  25.701403  34.660854     40.941989\n",
       "9       240.0       0.003988  25.933874  35.003405     41.449988\n",
       "10      264.0       0.004070  26.118716  35.363539     41.230615\n",
       "11      288.0       0.004051  26.409709  35.281968     43.628376\n",
       "12      312.0       0.007058  35.321855  44.827733     77.083331\n",
       "13      336.0       0.003827  25.578705  34.294322     45.089553\n",
       "14      360.0       0.003780  24.765925  34.082825     39.811573\n",
       "15      384.0       0.003845  25.114309  34.355709     41.315591\n",
       "16      408.0       0.003972  24.805567  34.906887     38.653941\n",
       "17      432.0       0.005409  29.581222  39.670503     52.209723\n",
       "18      456.0       0.004053  25.121623  35.245764     41.415108\n",
       "19      480.0       0.004539  26.236808  37.274812     38.471242\n",
       "20      504.0       0.005052  27.780734  39.300484     42.215525"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to predict next 6 steps simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will use\n",
    "* the last 12 steps\n",
    "\n",
    "* previous one week (24 steps)\n",
    "\n",
    "* previous one month  (168 steps)\n",
    "\n",
    "*  to forecast current (0 step) and 5 steps ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1141040 into shape (168,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create input-output sequences with the provided function\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_train, y_train, X_train_df, y_train_df \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_multi_step_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_n_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mday_lag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweek_lag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_future_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m X_valid, y_valid, X_valid_df, y_valid_df \u001b[38;5;241m=\u001b[39m create_multi_step_sequence(valid_set, last_n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m7\u001b[39m, day_lag\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, week_lag\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, n_future_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)\n\u001b[0;32m      4\u001b[0m X_test, y_test, X_test_df, y_test_df \u001b[38;5;241m=\u001b[39m create_multi_step_sequence(test_set, last_n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m7\u001b[39m, day_lag\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, week_lag\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, n_future_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)\n",
      "Cell \u001b[1;32mIn[10], line 40\u001b[0m, in \u001b[0;36mcreate_multi_step_sequence\u001b[1;34m(data, last_n_steps, day_lag, week_lag, n_future_steps)\u001b[0m\n\u001b[0;32m     37\u001b[0m         y\u001b[38;5;241m.\u001b[39mappend(output_seq)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Convert to numpy arrays and reshape X to match CNN expected input (samples, timesteps, features)\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_n_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Add the 2 additional features (last_day_value, last_week_value)\u001b[39;00m\n\u001b[0;32m     41\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(y)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, n_future_steps)  \u001b[38;5;66;03m# Multiple output steps\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Convert the entire input and output into a pandas DataFrame with appropriate column names for multi-step prediction\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Define column names for the input DataFrame\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 1141040 into shape (168,1)"
     ]
    }
   ],
   "source": [
    "# Create input-output sequences with the provided function\n",
    "X_train, y_train, X_train_df, y_train_df = create_multi_step_sequence(train_set, last_n_steps=12, day_lag=24, week_lag=168, n_future_steps=6)\n",
    "X_valid, y_valid, X_valid_df, y_valid_df = create_multi_step_sequence(valid_set, last_n_steps=12, day_lag=24, week_lag=168, n_future_steps=6)\n",
    "X_test, y_test, X_test_df, y_test_df = create_multi_step_sequence(test_set, last_n_steps=12, day_lag=24, week_lag=168, n_future_steps=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model_multi_step(input_shape, n_outputs, units, dropout_rate, learning_rate):\n",
    "    model = keras.Sequential()\n",
    "    model.add(LSTM(units=units, activation='tanh', input_shape=input_shape))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(n_outputs))\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        loss='mse',  # Mean Squared Error loss for regression\n",
    "        optimizer=optimizer,\n",
    "        metrics=['mae']  # Mean Absolute Error as a metric\n",
    "    )\n",
    "    return model\n",
    "\n",
    "input_shape = (x_train_scaled.shape[1], x_train_scaled.shape[2])\n",
    "n_outputs = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCIZFe1MAx-X"
   },
   "source": [
    "## 6. Set Up Hyperparameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter options\n",
    "units_list = [50, 100, 200]\n",
    "dropout_rates = [0, 0.3, 0.5]\n",
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "batch_sizes = [32, 64, 128]\n",
    "\n",
    "# Create all possible combinations\n",
    "hyperparameter_combinations = list(product(units_list, dropout_rates, learning_rates, batch_sizes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ixRU8sQA8NW"
   },
   "source": [
    "## 7. Train the Model with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination 1/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.01, batch_size=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\program\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation MAE: 0.0602\n",
      "\n",
      "Combination 2/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.01, batch_size=64\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation MAE: 0.0600\n",
      "\n",
      "Combination 3/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.01, batch_size=128\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation MAE: 0.0600\n",
      "\n",
      "Combination 4/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0618\n",
      "\n",
      "Combination 5/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation MAE: 0.0634\n",
      "\n",
      "Combination 6/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0644\n",
      "\n",
      "Combination 7/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.0001, batch_size=32\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation MAE: 0.0685\n",
      "\n",
      "Combination 8/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0685\n",
      "\n",
      "Combination 9/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0700\n",
      "\n",
      "Combination 10/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.01, batch_size=32\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation MAE: 0.0610\n",
      "\n",
      "Combination 11/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.01, batch_size=64\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation MAE: 0.0604\n",
      "\n",
      "Combination 12/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.01, batch_size=128\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation MAE: 0.0611\n",
      "\n",
      "Combination 13/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0619\n",
      "\n",
      "Combination 14/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0640\n",
      "\n",
      "Combination 15/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0652\n",
      "\n",
      "Combination 16/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0688\n",
      "\n",
      "Combination 17/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0711\n",
      "\n",
      "Combination 18/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0740\n",
      "\n",
      "Combination 19/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.01, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation MAE: 0.0610\n",
      "\n",
      "Combination 20/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.01, batch_size=64\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation MAE: 0.0614\n",
      "\n",
      "Combination 21/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.01, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0603\n",
      "\n",
      "Combination 22/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation MAE: 0.0630\n",
      "\n",
      "Combination 23/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.001, batch_size=64\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation MAE: 0.0658\n",
      "\n",
      "Combination 24/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0657\n",
      "\n",
      "Combination 25/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0686\n",
      "\n",
      "Combination 26/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0720\n",
      "\n",
      "Combination 27/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0745\n",
      "\n",
      "Combination 28/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.01, batch_size=32\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation MAE: 0.0608\n",
      "\n",
      "Combination 29/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.01, batch_size=64\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation MAE: 0.0608\n",
      "\n",
      "Combination 30/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.01, batch_size=128\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation MAE: 0.0606\n",
      "\n",
      "Combination 31/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation MAE: 0.0603\n",
      "\n",
      "Combination 32/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0616\n",
      "\n",
      "Combination 33/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation MAE: 0.0633\n",
      "\n",
      "Combination 34/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0669\n",
      "\n",
      "Combination 35/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0679\n",
      "\n",
      "Combination 36/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0682\n",
      "\n",
      "Combination 37/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.01, batch_size=32\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation MAE: 0.0606\n",
      "\n",
      "Combination 38/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.01, batch_size=64\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation MAE: 0.0607\n",
      "\n",
      "Combination 39/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.01, batch_size=128\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation MAE: 0.0595\n",
      "\n",
      "Combination 40/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation MAE: 0.0610\n",
      "\n",
      "Combination 41/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0618\n",
      "\n",
      "Combination 42/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0643\n",
      "\n",
      "Combination 43/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation MAE: 0.0675\n",
      "\n",
      "Combination 44/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation MAE: 0.0687\n",
      "\n",
      "Combination 45/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.0001, batch_size=128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0708\n",
      "\n",
      "Combination 46/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.01, batch_size=32\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation MAE: 0.0605\n",
      "\n",
      "Combination 47/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.01, batch_size=64\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation MAE: 0.0606\n",
      "\n",
      "Combination 48/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.01, batch_size=128\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation MAE: 0.0608\n",
      "\n",
      "Combination 49/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0616\n",
      "\n",
      "Combination 50/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0632\n",
      "\n",
      "Combination 51/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.001, batch_size=128\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation MAE: 0.0654\n",
      "\n",
      "Combination 52/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0672\n",
      "\n",
      "Combination 53/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0690\n",
      "\n",
      "Combination 54/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0712\n",
      "\n",
      "Combination 55/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.01, batch_size=32\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation MAE: 0.0600\n",
      "\n",
      "Combination 56/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.01, batch_size=64\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation MAE: 0.0604\n",
      "\n",
      "Combination 57/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.01, batch_size=128\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation MAE: 0.0605\n",
      "\n",
      "Combination 58/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.001, batch_size=32\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation MAE: 0.0605\n",
      "\n",
      "Combination 59/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0601\n",
      "\n",
      "Combination 60/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0618\n",
      "\n",
      "Combination 61/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0658\n",
      "\n",
      "Combination 62/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0672\n",
      "\n",
      "Combination 63/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.0001, batch_size=128\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation MAE: 0.0688\n",
      "\n",
      "Combination 64/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.01, batch_size=32\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation MAE: 0.0612\n",
      "\n",
      "Combination 65/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.01, batch_size=64\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation MAE: 0.0612\n",
      "\n",
      "Combination 66/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.01, batch_size=128\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation MAE: 0.0607\n",
      "\n",
      "Combination 67/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0603\n",
      "\n",
      "Combination 68/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0607\n",
      "\n",
      "Combination 69/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation MAE: 0.0631\n",
      "\n",
      "Combination 70/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0659\n",
      "\n",
      "Combination 71/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0682\n",
      "\n",
      "Combination 72/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0688\n",
      "\n",
      "Combination 73/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.01, batch_size=32\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation MAE: 0.0596\n",
      "\n",
      "Combination 74/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.01, batch_size=64\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation MAE: 0.0595\n",
      "\n",
      "Combination 75/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.01, batch_size=128\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation MAE: 0.0605\n",
      "\n",
      "Combination 76/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0607\n",
      "\n",
      "Combination 77/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0612\n",
      "\n",
      "Combination 78/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0635\n",
      "\n",
      "Combination 79/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0661\n",
      "\n",
      "Combination 80/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0679\n",
      "\n",
      "Combination 81/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0689\n",
      "\n",
      "Best Hyperparameters:\n",
      "units: 100\n",
      "dropout_rate: 0.3\n",
      "learning_rate: 0.01\n",
      "batch_size: 128\n",
      "Best Validation MAE: 0.0595\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables to store the best model and hyperparameters\n",
    "best_val_mae = np.inf\n",
    "best_hyperparams = None\n",
    "best_model = None\n",
    "\n",
    "for idx, (units, dropout_rate, learning_rate, batch_size) in enumerate(hyperparameter_combinations):\n",
    "    print(f\"\\nCombination {idx+1}/{len(hyperparameter_combinations)}\")\n",
    "    print(f\"Training with units={units}, dropout_rate={dropout_rate}, learning_rate={learning_rate}, batch_size={batch_size}\")\n",
    "\n",
    "    # Create the LSTM model with the current hyperparameters\n",
    "    model = create_lstm_model_multi_step(\n",
    "        input_shape=input_shape,\n",
    "        n_outputs=n_outputs,\n",
    "        units=units,\n",
    "        dropout_rate=dropout_rate,\n",
    "        learning_rate=learning_rate\n",
    "    )\n",
    "\n",
    "    # Initialize EarlyStopping\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_mae',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        x_train_scaled, y_train_scaled,\n",
    "        epochs=50,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_val_scaled, y_val_scaled),\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Get the best validation MAE from this training run\n",
    "    val_mae = min(history.history['val_mae'])\n",
    "    print(f\"Validation MAE: {val_mae:.4f}\")\n",
    "\n",
    "    # Update best model if current one is better\n",
    "    if val_mae < best_val_mae:\n",
    "        best_val_mae = val_mae\n",
    "        best_model = model\n",
    "        best_hyperparams = {\n",
    "            'units': units,\n",
    "            'dropout_rate': dropout_rate,\n",
    "            'learning_rate': learning_rate,\n",
    "            'batch_size': batch_size\n",
    "        }\n",
    "\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "for param, value in best_hyperparams.items():\n",
    "    print(f\"{param}: {value}\")\n",
    "print(f\"Best Validation MAE: {best_val_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "13:33"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Hyperparameters for full time:\n",
    "units: 200\n",
    "dropout_rate: 0.5\n",
    "learning_rate: 0.01\n",
    "batch_size: 32\n",
    "Best Validation MAE: 0.0503\n",
    "\n",
    "Best Hyperparameters for after covid:\n",
    "units: 100\n",
    "dropout_rate: 0.3\n",
    "learning_rate: 0.01\n",
    "batch_size: 128\n",
    "Best Validation MAE: 0.0595"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred_scaled = best_model.predict(x_test_scaled)\n",
    "\n",
    "# Reshape for inverse scaling\n",
    "y_pred_reshaped = y_pred_scaled.reshape(-1, 1)\n",
    "y_test_reshaped = y_test_scaled.reshape(-1, 1)\n",
    "\n",
    "# Inverse transform\n",
    "y_pred_inverse = y_scaler.inverse_transform(y_pred_reshaped).reshape(n_test_samples, n_outputs)\n",
    "y_test_inverse = y_scaler.inverse_transform(y_test_reshaped).reshape(n_test_samples, n_outputs)\n",
    "\n",
    "y_test_flat = y_test_inverse.flatten()\n",
    "y_pred_flat = y_pred_inverse.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9SREwnRqxMN1"
   },
   "source": [
    "## 9. Evaluating the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time Step 1 Evaluation Metrics:\n",
      "RMSE: 28.4454\n",
      "MAE: 20.8450\n",
      "MAPE: 19.44%\n",
      "\n",
      "Time Step 2 Evaluation Metrics:\n",
      "RMSE: 36.2563\n",
      "MAE: 26.7673\n",
      "MAPE: 25.02%\n",
      "\n",
      "Time Step 3 Evaluation Metrics:\n",
      "RMSE: 43.7203\n",
      "MAE: 33.1341\n",
      "MAPE: 29.97%\n",
      "\n",
      "Time Step 4 Evaluation Metrics:\n",
      "RMSE: 49.3573\n",
      "MAE: 38.0972\n",
      "MAPE: 35.19%\n",
      "\n",
      "Time Step 5 Evaluation Metrics:\n",
      "RMSE: 53.2812\n",
      "MAE: 41.5888\n",
      "MAPE: 39.42%\n",
      "\n",
      "Time Step 6 Evaluation Metrics:\n",
      "RMSE: 53.3926\n",
      "MAE: 42.0135\n",
      "MAPE: 44.19%\n"
     ]
    }
   ],
   "source": [
    "# Compute Metrics for Each Time Step\n",
    "\n",
    "for i in range(n_outputs):\n",
    "    y_true = y_test_inverse[:, i]\n",
    "    y_pred = y_pred_inverse[:, i]\n",
    "\n",
    "    # Mean Absolute Error (MAE)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "    # Mean Squared Error (MSE)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "    # Root Mean Squared Error (RMSE)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # Mean Absolute Percentage Error (MAPE)\n",
    "    # Avoid division by zero by adding a small epsilon to y_test_flat if necessary\n",
    "    epsilon = 1e-10\n",
    "    y_true_safe = np.where(y_true == 0, epsilon, y_true)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true_safe)) * 100\n",
    "\n",
    "    print(f\"\\nTime Step {i+1} Evaluation Metrics:\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"MAPE: {mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyYn2XL2GUxw"
   },
   "source": [
    "# Code to predict next 6 steps step-by-step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vavf9D4-lc6E"
   },
   "source": [
    "#### We will use\n",
    "* the last 12 steps\n",
    "\n",
    "* previous one week (24 steps)\n",
    "\n",
    "* previous one month  (168 steps)\n",
    "\n",
    "*  to forecast current (0 step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OfV8VwesmXS3"
   },
   "source": [
    "## 4. Create input and output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "PJaM65dTlc6E"
   },
   "outputs": [],
   "source": [
    "# Create input-output sequences with the provided function\n",
    "X_train, y_train, X_train_df, y_train_df = create_multi_step_sequence(train_set, last_n_steps=12, day_lag=24, week_lag=168, n_future_steps=1)\n",
    "X_valid, y_valid, X_valid_df, y_valid_df = create_multi_step_sequence(valid_set, last_n_steps=12, day_lag=24, week_lag=168, n_future_steps=1)\n",
    "X_test, y_test, X_test_df, y_test_df = create_multi_step_sequence(test_set, last_n_steps=12, day_lag=24, week_lag=168, n_future_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ipA2bPAcm2L1",
    "outputId": "687db2e3-3f26-4cc3-c15b-0d8066617ff8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19570, 14, 1), (6907, 14, 1), (5623, 14, 1))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0GNpslqvlx5_"
   },
   "source": [
    "## 5. Normalise the data after split (step-by-step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_Co01Aflx6B"
   },
   "source": [
    "Normalise X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Z7YuPxvRlx6C"
   },
   "outputs": [],
   "source": [
    "# Separate scalers for inputs and outputs\n",
    "x_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "y_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Reshape x_train to 2D for scaling\n",
    "n_samples, n_timesteps, n_features = X_train.shape\n",
    "x_train_reshaped = X_train.reshape(-1, n_features)  # Shape: (n_samples * n_timesteps, n_features)\n",
    "# Fit the scaler on the training data\n",
    "x_scaler.fit(x_train_reshaped)\n",
    "# Transform the training data\n",
    "x_train_scaled = x_scaler.transform(x_train_reshaped)\n",
    "# Reshape back to original shape\n",
    "x_train_scaled = x_train_scaled.reshape(n_samples, n_timesteps, n_features)\n",
    "\n",
    "# x_val\n",
    "n_val_samples = X_valid.shape[0]\n",
    "x_val_reshaped = X_valid.reshape(-1, n_features)\n",
    "x_val_scaled = x_scaler.transform(x_val_reshaped)\n",
    "x_val_scaled = x_val_scaled.reshape(n_val_samples, n_timesteps, n_features)\n",
    "\n",
    "# x_test\n",
    "n_test_samples = X_test.shape[0]\n",
    "x_test_reshaped = X_test.reshape(-1, n_features)\n",
    "x_test_scaled = x_scaler.transform(x_test_reshaped)\n",
    "x_test_scaled = x_test_scaled.reshape(n_test_samples, n_timesteps, n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rw7rcIWPlx6D"
   },
   "source": [
    "Normalise y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "azSWFgFmlx6D"
   },
   "outputs": [],
   "source": [
    "# Reshape y_train to 2D for scaling\n",
    "y_train_reshaped = y_train.reshape(-1, 1)  # Shape: (n_samples * n_outputs, 1)\n",
    "# Fit the scaler on the training data\n",
    "y_scaler.fit(y_train_reshaped)\n",
    "# Transform the training data\n",
    "y_train_scaled = y_scaler.transform(y_train_reshaped)\n",
    "# Reshape back to original shape\n",
    "y_train_scaled = y_train_scaled.reshape(n_samples, y_train.shape[1])\n",
    "\n",
    "# y_val\n",
    "y_val_reshaped = y_valid.reshape(-1, 1)\n",
    "y_val_scaled = y_scaler.transform(y_val_reshaped)\n",
    "y_val_scaled = y_val_scaled.reshape(n_val_samples, y_valid.shape[1])\n",
    "\n",
    "# y_test\n",
    "y_test_reshaped = y_test.reshape(-1, 1)\n",
    "y_test_scaled = y_scaler.transform(y_test_reshaped)\n",
    "y_test_scaled = y_test_scaled.reshape(n_test_samples, y_test.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJ7sNErrpc9O"
   },
   "source": [
    "## 6. Build LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "eE7DAUCIoVSt"
   },
   "outputs": [],
   "source": [
    "def create_lstm_model(input_shape, units, dropout_rate, learning_rate):\n",
    "    model = keras.Sequential()\n",
    "    model.add(LSTM(units=units, activation='tanh', input_shape=input_shape))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1)) # Output layer for one-step prediction\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        loss='mse',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "input_shape = (x_train_scaled.shape[1], x_train_scaled.shape[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYD8kk0NpzNp"
   },
   "source": [
    "## 7. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u4zCXOAo9tN"
   },
   "outputs": [],
   "source": [
    "# Hyperparameter options\n",
    "units_list = [50, 100, 200]\n",
    "dropout_rates = [0, 0.3, 0.5]\n",
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "batch_sizes = [32, 64, 128]\n",
    "\n",
    "# Create all possible combinations\n",
    "hyperparameter_combinations = list(product(units_list, dropout_rates, learning_rates, batch_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "5d-_-jwBp45_",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "e551e47c-fc12-4b0c-d237-39b9eb0d4f7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination 1/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.01, batch_size=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\program\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation MAE: 0.0452\n",
      "\n",
      "Combination 2/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.01, batch_size=64\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation MAE: 0.0452\n",
      "\n",
      "Combination 3/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.01, batch_size=128\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation MAE: 0.0466\n",
      "\n",
      "Combination 4/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0450\n",
      "\n",
      "Combination 5/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0463\n",
      "\n",
      "Combination 6/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0492\n",
      "\n",
      "Combination 7/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0496\n",
      "\n",
      "Combination 8/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0506\n",
      "\n",
      "Combination 9/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0512\n",
      "\n",
      "Combination 10/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.01, batch_size=32\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation MAE: 0.0464\n",
      "\n",
      "Combination 11/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.01, batch_size=64\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation MAE: 0.0467\n",
      "\n",
      "Combination 12/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.01, batch_size=128\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation MAE: 0.0457\n",
      "\n",
      "Combination 13/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0466\n",
      "\n",
      "Combination 14/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.001, batch_size=64\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation MAE: 0.0498\n",
      "\n",
      "Combination 15/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0493\n",
      "\n",
      "Combination 16/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0508\n",
      "\n",
      "Combination 17/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0516\n",
      "\n",
      "Combination 18/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0517\n",
      "\n",
      "Combination 19/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.01, batch_size=32\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation MAE: 0.0459\n",
      "\n",
      "Combination 20/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.01, batch_size=64\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation MAE: 0.0461\n",
      "\n",
      "Combination 21/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.01, batch_size=128\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation MAE: 0.0463\n",
      "\n",
      "Combination 22/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0471\n",
      "\n",
      "Combination 23/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0489\n",
      "\n",
      "Combination 24/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0501\n",
      "\n",
      "Combination 25/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0510\n",
      "\n",
      "Combination 26/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation MAE: 0.0514\n",
      "\n",
      "Combination 27/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0522\n",
      "\n",
      "Combination 28/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.01, batch_size=32\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation MAE: 0.0463\n",
      "\n",
      "Combination 29/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.01, batch_size=64\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation MAE: 0.0461\n",
      "\n",
      "Combination 30/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.01, batch_size=128\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation MAE: 0.0453\n",
      "\n",
      "Combination 31/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation MAE: 0.0450\n",
      "\n",
      "Combination 32/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation MAE: 0.0458\n",
      "\n",
      "Combination 33/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.001, batch_size=128\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation MAE: 0.0496\n",
      "\n",
      "Combination 34/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0494\n",
      "\n",
      "Combination 35/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0502\n",
      "\n",
      "Combination 36/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation MAE: 0.0512\n",
      "\n",
      "Combination 37/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.01, batch_size=32\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation MAE: 0.0463\n",
      "\n",
      "Combination 38/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.01, batch_size=64\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation MAE: 0.0459\n",
      "\n",
      "Combination 39/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.01, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0457\n",
      "\n",
      "Combination 40/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0456\n",
      "\n",
      "Combination 41/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0469\n",
      "\n",
      "Combination 42/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation MAE: 0.0494\n",
      "\n",
      "Combination 43/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.0001, batch_size=32\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation MAE: 0.0502\n",
      "\n",
      "Combination 44/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0509\n",
      "\n",
      "Combination 45/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.0001, batch_size=128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation MAE: 0.0513\n",
      "\n",
      "Combination 46/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.01, batch_size=32\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation MAE: 0.0466\n",
      "\n",
      "Combination 47/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.01, batch_size=64\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation MAE: 0.0460\n",
      "\n",
      "Combination 48/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.01, batch_size=128\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation MAE: 0.0458\n",
      "\n",
      "Combination 49/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0463\n",
      "\n",
      "Combination 50/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.001, batch_size=64\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation MAE: 0.0496\n",
      "\n",
      "Combination 51/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation MAE: 0.0496\n",
      "\n",
      "Combination 52/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0505\n",
      "\n",
      "Combination 53/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0511\n",
      "\n",
      "Combination 54/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0514\n",
      "\n",
      "Combination 55/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.01, batch_size=32\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation MAE: 0.0464\n",
      "\n",
      "Combination 56/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.01, batch_size=64\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation MAE: 0.0452\n",
      "\n",
      "Combination 57/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.01, batch_size=128\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation MAE: 0.0455\n",
      "\n",
      "Combination 58/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0452\n",
      "\n",
      "Combination 59/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation MAE: 0.0459\n",
      "\n",
      "Combination 60/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation MAE: 0.0470\n",
      "\n",
      "Combination 61/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0492\n",
      "\n",
      "Combination 62/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0497\n",
      "\n",
      "Combination 63/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0503\n",
      "\n",
      "Combination 64/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.01, batch_size=32\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation MAE: 0.0460\n",
      "\n",
      "Combination 65/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.01, batch_size=64\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation MAE: 0.0461\n",
      "\n",
      "Combination 66/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.01, batch_size=128\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation MAE: 0.0486\n",
      "\n",
      "Combination 67/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation MAE: 0.0460\n",
      "\n",
      "Combination 68/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0460\n",
      "\n",
      "Combination 69/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0471\n",
      "\n",
      "Combination 70/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0495\n",
      "\n",
      "Combination 71/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0499\n",
      "\n",
      "Combination 72/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0504\n",
      "\n",
      "Combination 73/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.01, batch_size=32\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation MAE: 0.0455\n",
      "\n",
      "Combination 74/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.01, batch_size=64\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation MAE: 0.0466\n",
      "\n",
      "Combination 75/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.01, batch_size=128\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation MAE: 0.0465\n",
      "\n",
      "Combination 76/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.001, batch_size=32\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation MAE: 0.0467\n",
      "\n",
      "Combination 77/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.001, batch_size=64\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation MAE: 0.0478\n",
      "\n",
      "Combination 78/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation MAE: 0.0477\n",
      "\n",
      "Combination 79/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0496\n",
      "\n",
      "Combination 80/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0502\n",
      "\n",
      "Combination 81/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation MAE: 0.0508\n",
      "\n",
      "Best Hyperparameters:\n",
      "units: 100\n",
      "dropout_rate: 0\n",
      "learning_rate: 0.001\n",
      "batch_size: 32\n",
      "Best Validation MAE: 0.0450\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables to store the best model and hyperparameters\n",
    "best_val_mae = np.inf\n",
    "best_hyperparams = None\n",
    "best_model = None\n",
    "\n",
    "for idx, (units, dropout_rate, learning_rate, batch_size) in enumerate(hyperparameter_combinations):\n",
    "    print(f\"\\nCombination {idx+1}/{len(hyperparameter_combinations)}\")\n",
    "    print(f\"Training with units={units}, dropout_rate={dropout_rate}, learning_rate={learning_rate}, batch_size={batch_size}\")\n",
    "\n",
    "    # Create the LSTM model with the current hyperparameters\n",
    "    model = create_lstm_model(\n",
    "        input_shape=input_shape,\n",
    "        units=units,\n",
    "        dropout_rate=dropout_rate,\n",
    "        learning_rate=learning_rate\n",
    "    )\n",
    "\n",
    "    # Initialize EarlyStopping\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_mae',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        x_train_scaled, y_train_scaled,\n",
    "        epochs=50,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_val_scaled, y_val_scaled),\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Get the best validation MAE from this training run\n",
    "    val_mae = min(history.history['val_mae'])\n",
    "    print(f\"Validation MAE: {val_mae:.4f}\")\n",
    "\n",
    "    # Update best model if current one is better\n",
    "    if val_mae < best_val_mae:\n",
    "        best_val_mae = val_mae\n",
    "        best_model = model\n",
    "        best_hyperparams = {\n",
    "            'units': units,\n",
    "            'dropout_rate': dropout_rate,\n",
    "            'learning_rate': learning_rate,\n",
    "            'batch_size': batch_size\n",
    "        }\n",
    "\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "for param, value in best_hyperparams.items():\n",
    "    print(f\"{param}: {value}\")\n",
    "print(f\"Best Validation MAE: {best_val_mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Hyperparameters full time:\n",
    "units: 50\n",
    "dropout_rate: 0\n",
    "learning_rate: 0.01\n",
    "batch_size: 128\n",
    "Best Validation MAE: 0.0388\n",
    "\n",
    "Best Hyperparameters after covid:\n",
    "units: 100\n",
    "dropout_rate: 0\n",
    "learning_rate: 0.001\n",
    "batch_size: 32\n",
    "Best Validation MAE: 0.0450"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recreate the modelÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_lstm_model(input_shape, units, dropout_rate, learning_rate):\n",
    "    model = keras.Sequential()\n",
    "    model.add(LSTM(units=units, activation='tanh', input_shape=input_shape))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1)) # Output layer for one-step prediction\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        loss='mse',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (x_train_scaled.shape[1], x_train_scaled.shape[2])\n",
    "units=50\n",
    "dropout_rate=0\n",
    "learning_rate=0.01\n",
    "batch_size=128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrain the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize EarlyStopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_mae',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0044 - mae: 0.0474 - val_loss: 0.0039 - val_mae: 0.0405\n",
      "Epoch 2/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0043 - mae: 0.0465 - val_loss: 0.0039 - val_mae: 0.0406\n",
      "Epoch 3/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0043 - mae: 0.0467 - val_loss: 0.0040 - val_mae: 0.0432\n",
      "Epoch 4/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0044 - mae: 0.0472 - val_loss: 0.0039 - val_mae: 0.0401\n",
      "Epoch 5/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0043 - mae: 0.0469 - val_loss: 0.0040 - val_mae: 0.0430\n",
      "Epoch 6/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0044 - mae: 0.0473 - val_loss: 0.0039 - val_mae: 0.0399\n",
      "Epoch 7/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0043 - mae: 0.0464 - val_loss: 0.0039 - val_mae: 0.0406\n",
      "Epoch 8/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0045 - mae: 0.0475 - val_loss: 0.0039 - val_mae: 0.0416\n",
      "Epoch 9/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0043 - mae: 0.0464 - val_loss: 0.0039 - val_mae: 0.0411\n",
      "Epoch 10/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - loss: 0.0044 - mae: 0.0468 - val_loss: 0.0039 - val_mae: 0.0406\n",
      "Epoch 11/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0043 - mae: 0.0463 - val_loss: 0.0039 - val_mae: 0.0404\n",
      "Epoch 12/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0042 - mae: 0.0459 - val_loss: 0.0041 - val_mae: 0.0421\n",
      "Epoch 13/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0043 - mae: 0.0464 - val_loss: 0.0039 - val_mae: 0.0400\n",
      "Epoch 14/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0041 - mae: 0.0459 - val_loss: 0.0039 - val_mae: 0.0394\n",
      "Epoch 15/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0043 - mae: 0.0466 - val_loss: 0.0039 - val_mae: 0.0411\n",
      "Epoch 16/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0042 - mae: 0.0460 - val_loss: 0.0039 - val_mae: 0.0401\n",
      "Epoch 17/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0042 - mae: 0.0459 - val_loss: 0.0039 - val_mae: 0.0399\n",
      "Epoch 18/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0042 - mae: 0.0462 - val_loss: 0.0040 - val_mae: 0.0411\n",
      "Epoch 19/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.0041 - mae: 0.0456 - val_loss: 0.0039 - val_mae: 0.0394\n",
      "Epoch 20/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0040 - mae: 0.0454 - val_loss: 0.0039 - val_mae: 0.0405\n",
      "Epoch 21/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0044 - mae: 0.0467 - val_loss: 0.0040 - val_mae: 0.0409\n",
      "Epoch 22/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.0042 - mae: 0.0461 - val_loss: 0.0041 - val_mae: 0.0421\n",
      "Epoch 23/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0042 - mae: 0.0464 - val_loss: 0.0040 - val_mae: 0.0409\n",
      "Epoch 24/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0042 - mae: 0.0462 - val_loss: 0.0040 - val_mae: 0.0396\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = best_model.fit(\n",
    "    x_train_scaled, y_train_scaled,\n",
    "    epochs=50,  # You can adjust this as needed\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(x_val_scaled, y_val_scaled),\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1  # Set to 1 to see detailed training output\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27LXIyi-w0th"
   },
   "source": [
    "## 8. Recursive Forecasting with LSTM (step-by-step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "O5eKQOi8dLQ-"
   },
   "outputs": [],
   "source": [
    "def recursive_forecast(model, x_test_scaled, start_index, n_steps, x_scaler, y_scaler):\n",
    "    \"\"\"\n",
    "    Perform recursive forecasting using the trained model.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained model\n",
    "    - x_test_scaled: The scaled test input data (shape: n_samples, n_timesteps, n_features)\n",
    "    - start_index: The starting index in the test data\n",
    "    - n_steps: Number of future steps to predict\n",
    "    - x_scaler: Scaler used for input features\n",
    "    - y_scaler: Scaler used for target variable\n",
    "\n",
    "    Returns:\n",
    "    - predictions: List of predicted values (in original scale)\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    scaled_predictions = []\n",
    "    current_input = x_test_scaled[start_index].copy()  # Shape: (n_timesteps, n_features)\n",
    "\n",
    "    for step in range(n_steps):\n",
    "        # Reshape to (1, n_timesteps, n_features) for prediction\n",
    "        input_seq = current_input.reshape((1, current_input.shape[0], current_input.shape[1]))\n",
    "\n",
    "        # Predict the next time step (scaled)\n",
    "        yhat_scaled = model.predict(input_seq, verbose=0)  # Shape: (1, 1)\n",
    "\n",
    "        # Inverse transform the prediction to original scale\n",
    "        yhat = y_scaler.inverse_transform(yhat_scaled)[0, 0]\n",
    "        \n",
    "        # Transform the prediction back to input feature scale for lag features\n",
    "        yhat_for_input = x_scaler.transform(yhat.reshape(-1, 1))[0, 0]\n",
    "\n",
    "        # Append predictions\n",
    "        predictions.append(yhat)\n",
    "        scaled_predictions.append(yhat_for_input)\n",
    "\n",
    "        # Move to the next time step in x_test_scaled\n",
    "        next_index = start_index + step + 1\n",
    "        if next_index < len(x_test_scaled):\n",
    "            # Use features from the next time step\n",
    "            next_input = x_test_scaled[next_index].copy()\n",
    "        else:\n",
    "            # Reached the end of x_test_scaled\n",
    "            break\n",
    "\n",
    "        # Update lag features with available scaled predictions\n",
    "        for lag in range(1, min(step + 1, 6) + 1):\n",
    "            feature_index = 12 - lag  # lag1 is at index 11\n",
    "            next_input[feature_index, 0] = scaled_predictions[-lag]\n",
    "\n",
    "        # Keep lag24 and lag168 as they are, or update if necessary\n",
    "\n",
    "        # Set current_input for next iteration\n",
    "        current_input = next_input\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBK2TyUSxCQ-"
   },
   "source": [
    "## 9. Make step-by-step prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "79gLJQDkdNBl"
   },
   "outputs": [],
   "source": [
    "# Number of steps to predict\n",
    "n_steps = 6\n",
    "\n",
    "# Initialize lists to store predictions and actual values\n",
    "all_predictions = []\n",
    "all_actuals = []\n",
    "\n",
    "# Ensure we have enough data for recursive predictions\n",
    "n_test_samples = x_test_scaled.shape[0]\n",
    "\n",
    "for i in range(n_test_samples - n_steps):\n",
    "    # Perform recursive forecasting\n",
    "    predictions = recursive_forecast(\n",
    "        model=best_model,\n",
    "        x_test_scaled=x_test_scaled,\n",
    "        start_index=i,\n",
    "        n_steps=n_steps,\n",
    "        x_scaler=x_scaler,\n",
    "        y_scaler=y_scaler\n",
    "    )\n",
    "\n",
    "    # Get the actual future values (in original scale)\n",
    "    actual_values = y_test[i+1:i + len(predictions) + 1].flatten()\n",
    "\n",
    "    # Store the predictions and actual values\n",
    "    all_predictions.append(predictions)\n",
    "    all_actuals.append(actual_values)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_actuals = np.array(all_actuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9SREwnRqxMN1"
   },
   "source": [
    "## 10. Evaluating the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xw9n5yNExAkJ",
    "outputId": "4f5b2721-8d8e-4871-eb56-dfd1b17ab14c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time Step 1 Evaluation Metrics:\n",
      "RMSE: 41.4159\n",
      "MAE: 29.8309\n",
      "MAPE: 32.89%\n",
      "\n",
      "Time Step 2 Evaluation Metrics:\n",
      "RMSE: 44.7596\n",
      "MAE: 31.9444\n",
      "MAPE: 36.16%\n",
      "\n",
      "Time Step 3 Evaluation Metrics:\n",
      "RMSE: 47.2820\n",
      "MAE: 33.4781\n",
      "MAPE: 39.15%\n",
      "\n",
      "Time Step 4 Evaluation Metrics:\n",
      "RMSE: 49.5900\n",
      "MAE: 34.8770\n",
      "MAPE: 41.75%\n",
      "\n",
      "Time Step 5 Evaluation Metrics:\n",
      "RMSE: 51.5312\n",
      "MAE: 35.9326\n",
      "MAPE: 43.32%\n",
      "\n",
      "Time Step 6 Evaluation Metrics:\n",
      "RMSE: 53.2142\n",
      "MAE: 36.6299\n",
      "MAPE: 44.43%\n"
     ]
    }
   ],
   "source": [
    "# Compute evaluation metrics\n",
    "epsilon = 1e-10  # To avoid division by zero in MAPE\n",
    "\n",
    "for i in range(n_steps):\n",
    "    y_true = all_actuals[:, i]\n",
    "    y_pred = all_predictions[:, i]\n",
    "\n",
    "    # Mean Absolute Error (MAE)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "    # Root Mean Squared Error (RMSE)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "    # Mean Absolute Percentage Error (MAPE)\n",
    "    y_true_safe = np.where(y_true == 0, epsilon, y_true)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true_safe)) * 100\n",
    "\n",
    "    print(f\"\\nTime Step {i+1} Evaluation Metrics:\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"MAPE: {mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k9VMIQUvBZ3q"
   },
   "outputs": [],
   "source": [
    "step-by-step full date"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
