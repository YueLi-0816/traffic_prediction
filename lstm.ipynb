{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tKUGmv5cn6GV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 10:21:02.603687: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-23 10:21:02.618704: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-23 10:21:02.636448: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-23 10:21:02.641488: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-23 10:21:02.654655: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-23 10:21:03.798544: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import random\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs:\n",
      " - /physical_device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# List all physical devices\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Available GPUs:\")\n",
    "for gpu in gpus:\n",
    "    print(f\" - {gpu.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory growth enabled for GPUs.\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"Memory growth enabled for GPUs.\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8uafyjo7odXA"
   },
   "outputs": [],
   "source": [
    "traffic_data = pd.read_csv('GD030A_S.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KZRSO8dF_Sik"
   },
   "source": [
    "## 1. Recover timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "4TWZuMkMiYtJ"
   },
   "outputs": [],
   "source": [
    "# Define the recover_timestamp function\n",
    "def recover_timestamp(data):\n",
    "    # Combine 'date' and 'time' to form a datetime column\n",
    "    data['datetime'] = pd.to_datetime(data['date'] + ' ' + data['time'].astype(str) + ':00', format='%Y-%m-%d %H:%M')\n",
    "\n",
    "    # Set 'datetime' as index\n",
    "    data = data.set_index('datetime')\n",
    "\n",
    "    # Create a complete range of timestamps with hourly frequency\n",
    "    full_time_range = pd.date_range(start=data.index.min(), end=data.index.max(), freq='H')\n",
    "\n",
    "    # Reindex the data to include all timestamps, filling missing rows with NaN\n",
    "    data_full = data.reindex(full_time_range)\n",
    "\n",
    "    return data_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "rwy81CAA_Y4r",
    "outputId": "9d3c3f5e-37fd-40f5-e31f-060efe8ee18d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1144935/36863830.py:10: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  full_time_range = pd.date_range(start=data.index.min(), end=data.index.max(), freq='H')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>flow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-10-01 00:00:00</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01 01:00:00</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01 02:00:00</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01 03:00:00</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01 04:00:00</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-30 19:00:00</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>19.0</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-30 20:00:00</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>20.0</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-30 21:00:00</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>21.0</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-30 22:00:00</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>22.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-30 23:00:00</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>23.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35064 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           date  time   flow\n",
       "2019-10-01 00:00:00  2019-10-01   0.0   15.0\n",
       "2019-10-01 01:00:00  2019-10-01   1.0    9.0\n",
       "2019-10-01 02:00:00  2019-10-01   2.0    9.0\n",
       "2019-10-01 03:00:00  2019-10-01   3.0    7.0\n",
       "2019-10-01 04:00:00  2019-10-01   4.0    9.0\n",
       "...                         ...   ...    ...\n",
       "2023-09-30 19:00:00  2023-09-30  19.0  129.0\n",
       "2023-09-30 20:00:00  2023-09-30  20.0  119.0\n",
       "2023-09-30 21:00:00  2023-09-30  21.0  106.0\n",
       "2023-09-30 22:00:00  2023-09-30  22.0   88.0\n",
       "2023-09-30 23:00:00  2023-09-30  23.0   88.0\n",
       "\n",
       "[35064 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the recover_timestamp function to recover the full time series\n",
    "traffic_full = recover_timestamp(traffic_data)\n",
    "traffic_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8z-mdqKewzjt"
   },
   "source": [
    "## 2. Train, validate, test data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h60qTUKvwzCb",
    "outputId": "682cc0ab-b2ed-48a1-df5d-6168064efd78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of train_set : 0.6227\n",
      "Proportion of valid_set : 0.1876\n",
      "Proportion of test_set : 0.1897\n"
     ]
    }
   ],
   "source": [
    "# train_set = traffic_full[:'2022-02-28 23:00:00']\n",
    "# valid_set = traffic_full['2022-03-01 00:00:00':'2022-12-31 23:00:00']\n",
    "# test_set = traffic_full['2023-01-01 00:00:00':]\n",
    "train_set = traffic_full['2022-06-03 00:00:00':'2023-03-31 23:00:00']\n",
    "valid_set = traffic_full['2023-04-01 00:00:00':'2023-06-30 23:00:00']\n",
    "test_set = traffic_full['2023-07-01 00:00:00':]\n",
    "print('Proportion of train_set : {:.4f}'.format(len(train_set)/len(traffic_full['2022-06-03 00:00:00':])))\n",
    "print('Proportion of valid_set : {:.4f}'.format(len(valid_set)/len(traffic_full['2022-06-03 00:00:00':])))\n",
    "print('Proportion of test_set : {:.4f}'.format(len(test_set)/len(traffic_full['2022-06-03 00:00:00':])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date    16\n",
      "time    16\n",
      "flow    16\n",
      "dtype: int64 7248\n",
      "date    61\n",
      "time    61\n",
      "flow    61\n",
      "dtype: int64 2184\n",
      "date    342\n",
      "time    342\n",
      "flow    342\n",
      "dtype: int64 2208\n"
     ]
    }
   ],
   "source": [
    "print(train_set.isnull().sum(), len(train_set))\n",
    "print(valid_set.isnull().sum(),len(valid_set))\n",
    "print(test_set.isnull().sum(),len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bd0hRLpW9gJs"
   },
   "source": [
    "## 3. Normalise the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1144935/1100395100.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_set.loc[:, 'flow_scaled'] = scaler.transform(train_set[['flow']])\n",
      "/tmp/ipykernel_1144935/1100395100.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  valid_set.loc[:, 'flow_scaled'] = scaler.transform(valid_set[['flow']])\n",
      "/tmp/ipykernel_1144935/1100395100.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_set.loc[:, 'flow_scaled'] = scaler.transform(test_set[['flow']])\n"
     ]
    }
   ],
   "source": [
    "# Initialize the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler on the training data's 'flow' feature\n",
    "scaler.fit(train_set[['flow']])\n",
    "\n",
    "# Transform the 'flow' feature in all datasets\n",
    "train_set.loc[:, 'flow_scaled'] = scaler.transform(train_set[['flow']])\n",
    "valid_set.loc[:, 'flow_scaled'] = scaler.transform(valid_set[['flow']])\n",
    "test_set.loc[:, 'flow_scaled'] = scaler.transform(test_set[['flow']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xak17ms1uZ-6"
   },
   "source": [
    "## 4. Split the data into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, input_length, forecast_horizon):\n",
    "    \"\"\"\n",
    "    Creates input-output sequences for time series data, excluding any sequences containing NaN values.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: pandas DataFrame containing the data. Must include the 'flow_scaled' column.\n",
    "    - input_length: int, number of past time steps to include in each input sequence.\n",
    "    - forecast_horizon: int, number of future steps to predict.\n",
    "    \n",
    "    Returns:\n",
    "    - X: numpy array of shape (num_valid_samples, input_length, num_features)\n",
    "    - y: numpy array of shape (num_valid_samples, forecast_horizon)\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    num_features = data.shape[1]\n",
    "    total_length = input_length + forecast_horizon\n",
    "    \n",
    "    for i in range(input_length, len(data) - forecast_horizon + 1):\n",
    "        # Extract the input sequence\n",
    "        X_seq = data.iloc[i - input_length:i]['flow_scaled'].values\n",
    "        # Extract the target sequence\n",
    "        y_seq = data.iloc[i:i + forecast_horizon]['flow_scaled'].values\n",
    "        \n",
    "        # Check for NaN values in the input sequence and target sequence\n",
    "        if not np.isnan(X_seq).any() and not np.isnan(y_seq).any():\n",
    "            X.append(X_seq)\n",
    "            y.append(y_seq)\n",
    "        else:\n",
    "            # Optionally, log or count the skipped sequences\n",
    "            pass  # Simply skip sequences with NaNs\n",
    "        \n",
    "    # Convert to numpy arrays and reshape X to match LSTM expected input (samples, timesteps, features)\n",
    "    X = np.array(X).reshape(-1, input_length, 1)\n",
    "    y = np.array(y).reshape(-1, forecast_horizon)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create X and y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will use\n",
    "* the last 24*N steps\n",
    "\n",
    "*  to forecast current (0 step) and 5 steps ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Input Sequence Lengths\n",
    "input_lengths = [24 * i for i in range(1, 22)]  # [24, 48, ..., 168]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing input length: 24\n",
      "  X_train shape: (7145, 24, 1), y_train shape: (7145, 6)\n",
      "  X_val shape: (2007, 24, 1), y_val shape: (2007, 6)\n",
      "  X_test shape: (1719, 24, 1), y_test shape: (1719, 6)\n",
      "\n",
      "Processing input length: 48\n",
      "  X_train shape: (7073, 48, 1), y_train shape: (7073, 6)\n",
      "  X_val shape: (1911, 48, 1), y_val shape: (1911, 6)\n",
      "  X_test shape: (1604, 48, 1), y_test shape: (1604, 6)\n",
      "\n",
      "Processing input length: 72\n",
      "  X_train shape: (7001, 72, 1), y_train shape: (7001, 6)\n",
      "  X_val shape: (1815, 72, 1), y_val shape: (1815, 6)\n",
      "  X_test shape: (1508, 72, 1), y_test shape: (1508, 6)\n",
      "\n",
      "Processing input length: 96\n",
      "  X_train shape: (6929, 96, 1), y_train shape: (6929, 6)\n",
      "  X_val shape: (1719, 96, 1), y_val shape: (1719, 6)\n",
      "  X_test shape: (1412, 96, 1), y_test shape: (1412, 6)\n",
      "\n",
      "Processing input length: 120\n",
      "  X_train shape: (6857, 120, 1), y_train shape: (6857, 6)\n",
      "  X_val shape: (1623, 120, 1), y_val shape: (1623, 6)\n",
      "  X_test shape: (1316, 120, 1), y_test shape: (1316, 6)\n",
      "\n",
      "Processing input length: 144\n",
      "  X_train shape: (6785, 144, 1), y_train shape: (6785, 6)\n",
      "  X_val shape: (1527, 144, 1), y_val shape: (1527, 6)\n",
      "  X_test shape: (1220, 144, 1), y_test shape: (1220, 6)\n",
      "\n",
      "Processing input length: 168\n",
      "  X_train shape: (6713, 168, 1), y_train shape: (6713, 6)\n",
      "  X_val shape: (1431, 168, 1), y_val shape: (1431, 6)\n",
      "  X_test shape: (1124, 168, 1), y_test shape: (1124, 6)\n",
      "\n",
      "Processing input length: 192\n",
      "  X_train shape: (6641, 192, 1), y_train shape: (6641, 6)\n",
      "  X_val shape: (1335, 192, 1), y_val shape: (1335, 6)\n",
      "  X_test shape: (1028, 192, 1), y_test shape: (1028, 6)\n",
      "\n",
      "Processing input length: 216\n",
      "  X_train shape: (6569, 216, 1), y_train shape: (6569, 6)\n",
      "  X_val shape: (1239, 216, 1), y_val shape: (1239, 6)\n",
      "  X_test shape: (932, 216, 1), y_test shape: (932, 6)\n",
      "\n",
      "Processing input length: 240\n",
      "  X_train shape: (6497, 240, 1), y_train shape: (6497, 6)\n",
      "  X_val shape: (1143, 240, 1), y_val shape: (1143, 6)\n",
      "  X_test shape: (836, 240, 1), y_test shape: (836, 6)\n",
      "\n",
      "Processing input length: 264\n",
      "  X_train shape: (6425, 264, 1), y_train shape: (6425, 6)\n",
      "  X_val shape: (1047, 264, 1), y_val shape: (1047, 6)\n",
      "  X_test shape: (740, 264, 1), y_test shape: (740, 6)\n",
      "\n",
      "Processing input length: 288\n",
      "  X_train shape: (6353, 288, 1), y_train shape: (6353, 6)\n",
      "  X_val shape: (963, 288, 1), y_val shape: (963, 6)\n",
      "  X_test shape: (660, 288, 1), y_test shape: (660, 6)\n",
      "\n",
      "Processing input length: 312\n",
      "  X_train shape: (6281, 312, 1), y_train shape: (6281, 6)\n",
      "  X_val shape: (891, 312, 1), y_val shape: (891, 6)\n",
      "  X_test shape: (588, 312, 1), y_test shape: (588, 6)\n",
      "\n",
      "Processing input length: 336\n",
      "  X_train shape: (6209, 336, 1), y_train shape: (6209, 6)\n",
      "  X_val shape: (819, 336, 1), y_val shape: (819, 6)\n",
      "  X_test shape: (516, 336, 1), y_test shape: (516, 6)\n",
      "\n",
      "Processing input length: 360\n",
      "  X_train shape: (6137, 360, 1), y_train shape: (6137, 6)\n",
      "  X_val shape: (747, 360, 1), y_val shape: (747, 6)\n",
      "  X_test shape: (444, 360, 1), y_test shape: (444, 6)\n",
      "\n",
      "Processing input length: 384\n",
      "  X_train shape: (6065, 384, 1), y_train shape: (6065, 6)\n",
      "  X_val shape: (675, 384, 1), y_val shape: (675, 6)\n",
      "  X_test shape: (390, 384, 1), y_test shape: (390, 6)\n",
      "\n",
      "Processing input length: 408\n",
      "  X_train shape: (5993, 408, 1), y_train shape: (5993, 6)\n",
      "  X_val shape: (603, 408, 1), y_val shape: (603, 6)\n",
      "  X_test shape: (342, 408, 1), y_test shape: (342, 6)\n",
      "\n",
      "Processing input length: 432\n",
      "  X_train shape: (5921, 432, 1), y_train shape: (5921, 6)\n",
      "  X_val shape: (531, 432, 1), y_val shape: (531, 6)\n",
      "  X_test shape: (311, 432, 1), y_test shape: (311, 6)\n",
      "\n",
      "Processing input length: 456\n",
      "  X_train shape: (5849, 456, 1), y_train shape: (5849, 6)\n",
      "  X_val shape: (459, 456, 1), y_val shape: (459, 6)\n",
      "  X_test shape: (287, 456, 1), y_test shape: (287, 6)\n",
      "\n",
      "Processing input length: 480\n",
      "  X_train shape: (5777, 480, 1), y_train shape: (5777, 6)\n",
      "  X_val shape: (387, 480, 1), y_val shape: (387, 6)\n",
      "  X_test shape: (263, 480, 1), y_test shape: (263, 6)\n",
      "\n",
      "Processing input length: 504\n",
      "  X_train shape: (5705, 504, 1), y_train shape: (5705, 6)\n",
      "  X_val shape: (333, 504, 1), y_val shape: (333, 6)\n",
      "  X_test shape: (239, 504, 1), y_test shape: (239, 6)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "data_dict = defaultdict(dict)\n",
    "\n",
    "for length in input_lengths:\n",
    "    print(f\"Processing input length: {length}\")\n",
    "    \n",
    "    # Create sequences with forecast_horizon=6\n",
    "    X_train, y_train = create_sequences(train_set, length, forecast_horizon=6)\n",
    "    X_val, y_val = create_sequences(valid_set, length, forecast_horizon=6)\n",
    "    X_test, y_test = create_sequences(test_set, length, forecast_horizon=6)\n",
    "    \n",
    "    # Store in the dictionary\n",
    "    data_dict[length]['X_train'] = X_train\n",
    "    data_dict[length]['y_train'] = y_train\n",
    "    data_dict[length]['X_val'] = X_val\n",
    "    data_dict[length]['y_val'] = y_val\n",
    "    data_dict[length]['X_test'] = X_test\n",
    "    data_dict[length]['y_test'] = y_test\n",
    "    \n",
    "    # Print shapes and ensure no NaNs\n",
    "    print(f\"  X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "    print(f\"  X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
    "    print(f\"  X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Build LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(hyperparams, input_length):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=hyperparams['units'], activation='tanh', input_shape=(input_length, 1)))\n",
    "    model.add(Dropout(rate=hyperparams['dropout']))\n",
    "    model.add(Dense(6))  # Output layer for multi-step forecasting\n",
    "\n",
    "    # Compile the model with MSE as the loss function\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=hyperparams['learning_rate'])\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mse'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Define the hyperparameter grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter options\n",
    "units_list = [32, 64, 128, 256]\n",
    "dropout_rates = [0.0, 0.1, 0.2, 0.3, 0.4]\n",
    "learning_rates = [0.01, 0.001, 0.0005]\n",
    "batch_sizes = [32, 64, 128]\n",
    "\n",
    "# Create all possible combinations\n",
    "all_combinations = list(product(units_list, dropout_rates, learning_rates, batch_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(32, 0.0, 0.01, 32),\n",
       " (32, 0.0, 0.01, 64),\n",
       " (32, 0.0, 0.01, 128),\n",
       " (32, 0.0, 0.001, 32),\n",
       " (32, 0.0, 0.001, 64),\n",
       " (32, 0.0, 0.001, 128),\n",
       " (32, 0.0, 0.0005, 32),\n",
       " (32, 0.0, 0.0005, 64),\n",
       " (32, 0.0, 0.0005, 128),\n",
       " (32, 0.1, 0.01, 32),\n",
       " (32, 0.1, 0.01, 64),\n",
       " (32, 0.1, 0.01, 128),\n",
       " (32, 0.1, 0.001, 32),\n",
       " (32, 0.1, 0.001, 64),\n",
       " (32, 0.1, 0.001, 128),\n",
       " (32, 0.1, 0.0005, 32),\n",
       " (32, 0.1, 0.0005, 64),\n",
       " (32, 0.1, 0.0005, 128),\n",
       " (32, 0.2, 0.01, 32),\n",
       " (32, 0.2, 0.01, 64),\n",
       " (32, 0.2, 0.01, 128),\n",
       " (32, 0.2, 0.001, 32),\n",
       " (32, 0.2, 0.001, 64),\n",
       " (32, 0.2, 0.001, 128),\n",
       " (32, 0.2, 0.0005, 32),\n",
       " (32, 0.2, 0.0005, 64),\n",
       " (32, 0.2, 0.0005, 128),\n",
       " (32, 0.3, 0.01, 32),\n",
       " (32, 0.3, 0.01, 64),\n",
       " (32, 0.3, 0.01, 128),\n",
       " (32, 0.3, 0.001, 32),\n",
       " (32, 0.3, 0.001, 64),\n",
       " (32, 0.3, 0.001, 128),\n",
       " (32, 0.3, 0.0005, 32),\n",
       " (32, 0.3, 0.0005, 64),\n",
       " (32, 0.3, 0.0005, 128),\n",
       " (32, 0.4, 0.01, 32),\n",
       " (32, 0.4, 0.01, 64),\n",
       " (32, 0.4, 0.01, 128),\n",
       " (32, 0.4, 0.001, 32),\n",
       " (32, 0.4, 0.001, 64),\n",
       " (32, 0.4, 0.001, 128),\n",
       " (32, 0.4, 0.0005, 32),\n",
       " (32, 0.4, 0.0005, 64),\n",
       " (32, 0.4, 0.0005, 128),\n",
       " (64, 0.0, 0.01, 32),\n",
       " (64, 0.0, 0.01, 64),\n",
       " (64, 0.0, 0.01, 128),\n",
       " (64, 0.0, 0.001, 32),\n",
       " (64, 0.0, 0.001, 64),\n",
       " (64, 0.0, 0.001, 128),\n",
       " (64, 0.0, 0.0005, 32),\n",
       " (64, 0.0, 0.0005, 64),\n",
       " (64, 0.0, 0.0005, 128),\n",
       " (64, 0.1, 0.01, 32),\n",
       " (64, 0.1, 0.01, 64),\n",
       " (64, 0.1, 0.01, 128),\n",
       " (64, 0.1, 0.001, 32),\n",
       " (64, 0.1, 0.001, 64),\n",
       " (64, 0.1, 0.001, 128),\n",
       " (64, 0.1, 0.0005, 32),\n",
       " (64, 0.1, 0.0005, 64),\n",
       " (64, 0.1, 0.0005, 128),\n",
       " (64, 0.2, 0.01, 32),\n",
       " (64, 0.2, 0.01, 64),\n",
       " (64, 0.2, 0.01, 128),\n",
       " (64, 0.2, 0.001, 32),\n",
       " (64, 0.2, 0.001, 64),\n",
       " (64, 0.2, 0.001, 128),\n",
       " (64, 0.2, 0.0005, 32),\n",
       " (64, 0.2, 0.0005, 64),\n",
       " (64, 0.2, 0.0005, 128),\n",
       " (64, 0.3, 0.01, 32),\n",
       " (64, 0.3, 0.01, 64),\n",
       " (64, 0.3, 0.01, 128),\n",
       " (64, 0.3, 0.001, 32),\n",
       " (64, 0.3, 0.001, 64),\n",
       " (64, 0.3, 0.001, 128),\n",
       " (64, 0.3, 0.0005, 32),\n",
       " (64, 0.3, 0.0005, 64),\n",
       " (64, 0.3, 0.0005, 128),\n",
       " (64, 0.4, 0.01, 32),\n",
       " (64, 0.4, 0.01, 64),\n",
       " (64, 0.4, 0.01, 128),\n",
       " (64, 0.4, 0.001, 32),\n",
       " (64, 0.4, 0.001, 64),\n",
       " (64, 0.4, 0.001, 128),\n",
       " (64, 0.4, 0.0005, 32),\n",
       " (64, 0.4, 0.0005, 64),\n",
       " (64, 0.4, 0.0005, 128),\n",
       " (128, 0.0, 0.01, 32),\n",
       " (128, 0.0, 0.01, 64),\n",
       " (128, 0.0, 0.01, 128),\n",
       " (128, 0.0, 0.001, 32),\n",
       " (128, 0.0, 0.001, 64),\n",
       " (128, 0.0, 0.001, 128),\n",
       " (128, 0.0, 0.0005, 32),\n",
       " (128, 0.0, 0.0005, 64),\n",
       " (128, 0.0, 0.0005, 128),\n",
       " (128, 0.1, 0.01, 32),\n",
       " (128, 0.1, 0.01, 64),\n",
       " (128, 0.1, 0.01, 128),\n",
       " (128, 0.1, 0.001, 32),\n",
       " (128, 0.1, 0.001, 64),\n",
       " (128, 0.1, 0.001, 128),\n",
       " (128, 0.1, 0.0005, 32),\n",
       " (128, 0.1, 0.0005, 64),\n",
       " (128, 0.1, 0.0005, 128),\n",
       " (128, 0.2, 0.01, 32),\n",
       " (128, 0.2, 0.01, 64),\n",
       " (128, 0.2, 0.01, 128),\n",
       " (128, 0.2, 0.001, 32),\n",
       " (128, 0.2, 0.001, 64),\n",
       " (128, 0.2, 0.001, 128),\n",
       " (128, 0.2, 0.0005, 32),\n",
       " (128, 0.2, 0.0005, 64),\n",
       " (128, 0.2, 0.0005, 128),\n",
       " (128, 0.3, 0.01, 32),\n",
       " (128, 0.3, 0.01, 64),\n",
       " (128, 0.3, 0.01, 128),\n",
       " (128, 0.3, 0.001, 32),\n",
       " (128, 0.3, 0.001, 64),\n",
       " (128, 0.3, 0.001, 128),\n",
       " (128, 0.3, 0.0005, 32),\n",
       " (128, 0.3, 0.0005, 64),\n",
       " (128, 0.3, 0.0005, 128),\n",
       " (128, 0.4, 0.01, 32),\n",
       " (128, 0.4, 0.01, 64),\n",
       " (128, 0.4, 0.01, 128),\n",
       " (128, 0.4, 0.001, 32),\n",
       " (128, 0.4, 0.001, 64),\n",
       " (128, 0.4, 0.001, 128),\n",
       " (128, 0.4, 0.0005, 32),\n",
       " (128, 0.4, 0.0005, 64),\n",
       " (128, 0.4, 0.0005, 128),\n",
       " (256, 0.0, 0.01, 32),\n",
       " (256, 0.0, 0.01, 64),\n",
       " (256, 0.0, 0.01, 128),\n",
       " (256, 0.0, 0.001, 32),\n",
       " (256, 0.0, 0.001, 64),\n",
       " (256, 0.0, 0.001, 128),\n",
       " (256, 0.0, 0.0005, 32),\n",
       " (256, 0.0, 0.0005, 64),\n",
       " (256, 0.0, 0.0005, 128),\n",
       " (256, 0.1, 0.01, 32),\n",
       " (256, 0.1, 0.01, 64),\n",
       " (256, 0.1, 0.01, 128),\n",
       " (256, 0.1, 0.001, 32),\n",
       " (256, 0.1, 0.001, 64),\n",
       " (256, 0.1, 0.001, 128),\n",
       " (256, 0.1, 0.0005, 32),\n",
       " (256, 0.1, 0.0005, 64),\n",
       " (256, 0.1, 0.0005, 128),\n",
       " (256, 0.2, 0.01, 32),\n",
       " (256, 0.2, 0.01, 64),\n",
       " (256, 0.2, 0.01, 128),\n",
       " (256, 0.2, 0.001, 32),\n",
       " (256, 0.2, 0.001, 64),\n",
       " (256, 0.2, 0.001, 128),\n",
       " (256, 0.2, 0.0005, 32),\n",
       " (256, 0.2, 0.0005, 64),\n",
       " (256, 0.2, 0.0005, 128),\n",
       " (256, 0.3, 0.01, 32),\n",
       " (256, 0.3, 0.01, 64),\n",
       " (256, 0.3, 0.01, 128),\n",
       " (256, 0.3, 0.001, 32),\n",
       " (256, 0.3, 0.001, 64),\n",
       " (256, 0.3, 0.001, 128),\n",
       " (256, 0.3, 0.0005, 32),\n",
       " (256, 0.3, 0.0005, 64),\n",
       " (256, 0.3, 0.0005, 128),\n",
       " (256, 0.4, 0.01, 32),\n",
       " (256, 0.4, 0.01, 64),\n",
       " (256, 0.4, 0.01, 128),\n",
       " (256, 0.4, 0.001, 32),\n",
       " (256, 0.4, 0.001, 64),\n",
       " (256, 0.4, 0.001, 128),\n",
       " (256, 0.4, 0.0005, 32),\n",
       " (256, 0.4, 0.0005, 64),\n",
       " (256, 0.4, 0.0005, 128)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Defining manual grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting grid search for input length: 24\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 10:21:59.714687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22263 MB memory:  -> device: 0, name: NVIDIA A30, pci bus id: 276f:00:00.0, compute capability: 8.0\n",
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-10-23 10:22:02.343934: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 64.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 93: early stopping\n",
      "Restoring model weights from the end of the best epoch: 83.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 100: early stopping\n",
      "Restoring model weights from the end of the best epoch: 90.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 97.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 91: early stopping\n",
      "Restoring model weights from the end of the best epoch: 81.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 99.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 83: early stopping\n",
      "Restoring model weights from the end of the best epoch: 73.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 98.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 95.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 98.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 90: early stopping\n",
      "Restoring model weights from the end of the best epoch: 80.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 66.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 98.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 78: early stopping\n",
      "Restoring model weights from the end of the best epoch: 68.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 78: early stopping\n",
      "Restoring model weights from the end of the best epoch: 68.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 99.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 94.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 93.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 99.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 100.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 96.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 97.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 88: early stopping\n",
      "Restoring model weights from the end of the best epoch: 78.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 96.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 80: early stopping\n",
      "Restoring model weights from the end of the best epoch: 70.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 98.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 81: early stopping\n",
      "Restoring model weights from the end of the best epoch: 71.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 84: early stopping\n",
      "Restoring model weights from the end of the best epoch: 74.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 85: early stopping\n",
      "Restoring model weights from the end of the best epoch: 75.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 81: early stopping\n",
      "Restoring model weights from the end of the best epoch: 71.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 94.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 93.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 77: early stopping\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 95.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 91: early stopping\n",
      "Restoring model weights from the end of the best epoch: 81.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 71: early stopping\n",
      "Restoring model weights from the end of the best epoch: 61.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 89: early stopping\n",
      "Restoring model weights from the end of the best epoch: 79.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 77: early stopping\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 92.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 88: early stopping\n",
      "Restoring model weights from the end of the best epoch: 78.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 84: early stopping\n",
      "Restoring model weights from the end of the best epoch: 74.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 97.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 63.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 84: early stopping\n",
      "Restoring model weights from the end of the best epoch: 74.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 75: early stopping\n",
      "Restoring model weights from the end of the best epoch: 65.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 98: early stopping\n",
      "Restoring model weights from the end of the best epoch: 88.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 87: early stopping\n",
      "Restoring model weights from the end of the best epoch: 77.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 79: early stopping\n",
      "Restoring model weights from the end of the best epoch: 69.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 71: early stopping\n",
      "Restoring model weights from the end of the best epoch: 61.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 72: early stopping\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 82: early stopping\n",
      "Restoring model weights from the end of the best epoch: 72.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 92.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0046\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed grid search for input length: 24\n",
      "  Best Validation MSE: 0.0042\n",
      "  Best Hyperparameters: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "\n",
      "Starting grid search for input length: 48\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 71: early stopping\n",
      "Restoring model weights from the end of the best epoch: 61.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 64.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.0066\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0044\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed grid search for input length: 48\n",
      "  Best Validation MSE: 0.0043\n",
      "  Best Hyperparameters: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "\n",
      "Starting grid search for input length: 72\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 66.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 83: early stopping\n",
      "Restoring model weights from the end of the best epoch: 73.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 75: early stopping\n",
      "Restoring model weights from the end of the best epoch: 65.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 78: early stopping\n",
      "Restoring model weights from the end of the best epoch: 68.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 78: early stopping\n",
      "Restoring model weights from the end of the best epoch: 68.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 71: early stopping\n",
      "Restoring model weights from the end of the best epoch: 61.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 92: early stopping\n",
      "Restoring model weights from the end of the best epoch: 82.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 66.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 83: early stopping\n",
      "Restoring model weights from the end of the best epoch: 73.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0046\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed grid search for input length: 72\n",
      "  Best Validation MSE: 0.0042\n",
      "  Best Hyperparameters: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "\n",
      "Starting grid search for input length: 96\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 72: early stopping\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 63.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 81: early stopping\n",
      "Restoring model weights from the end of the best epoch: 71.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 79: early stopping\n",
      "Restoring model weights from the end of the best epoch: 69.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 79: early stopping\n",
      "Restoring model weights from the end of the best epoch: 69.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 63.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 77: early stopping\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0155\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0046\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Completed grid search for input length: 96\n",
      "  Best Validation MSE: 0.0041\n",
      "  Best Hyperparameters: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "\n",
      "Starting grid search for input length: 120\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 90: early stopping\n",
      "Restoring model weights from the end of the best epoch: 80.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 93: early stopping\n",
      "Restoring model weights from the end of the best epoch: 83.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 89: early stopping\n",
      "Restoring model weights from the end of the best epoch: 79.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 71: early stopping\n",
      "Restoring model weights from the end of the best epoch: 61.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 80: early stopping\n",
      "Restoring model weights from the end of the best epoch: 70.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 71: early stopping\n",
      "Restoring model weights from the end of the best epoch: 61.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 83: early stopping\n",
      "Restoring model weights from the end of the best epoch: 73.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 75: early stopping\n",
      "Restoring model weights from the end of the best epoch: 65.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 82: early stopping\n",
      "Restoring model weights from the end of the best epoch: 72.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0059\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 71: early stopping\n",
      "Restoring model weights from the end of the best epoch: 61.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 63.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0043\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Completed grid search for input length: 120\n",
      "  Best Validation MSE: 0.0041\n",
      "  Best Hyperparameters: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "\n",
      "Starting grid search for input length: 144\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 77: early stopping\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 77: early stopping\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 77: early stopping\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 63.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 63.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 86: early stopping\n",
      "Restoring model weights from the end of the best epoch: 76.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 75: early stopping\n",
      "Restoring model weights from the end of the best epoch: 65.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 84: early stopping\n",
      "Restoring model weights from the end of the best epoch: 74.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 75: early stopping\n",
      "Restoring model weights from the end of the best epoch: 65.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 72: early stopping\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0088\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0196\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0045\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Completed grid search for input length: 144\n",
      "  Best Validation MSE: 0.0040\n",
      "  Best Hyperparameters: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "\n",
      "Starting grid search for input length: 168\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 78: early stopping\n",
      "Restoring model weights from the end of the best epoch: 68.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 77: early stopping\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 77: early stopping\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 63.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 100: early stopping\n",
      "Restoring model weights from the end of the best epoch: 90.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 95: early stopping\n",
      "Restoring model weights from the end of the best epoch: 85.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 80: early stopping\n",
      "Restoring model weights from the end of the best epoch: 70.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 86: early stopping\n",
      "Restoring model weights from the end of the best epoch: 76.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 81: early stopping\n",
      "Restoring model weights from the end of the best epoch: 71.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 96: early stopping\n",
      "Restoring model weights from the end of the best epoch: 86.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0120\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0144\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0133\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 77: early stopping\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "Validation loss: 0.0097\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.0129\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 90: early stopping\n",
      "Restoring model weights from the end of the best epoch: 80.\n",
      "Validation loss: 0.0101\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0045\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "Completed grid search for input length: 168\n",
      "  Best Validation MSE: 0.0041\n",
      "  Best Hyperparameters: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "\n",
      "Starting grid search for input length: 192\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 64.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 66.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 64.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 77: early stopping\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 77: early stopping\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 92.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 97.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 81: early stopping\n",
      "Restoring model weights from the end of the best epoch: 71.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0155\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0044\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "Completed grid search for input length: 192\n",
      "  Best Validation MSE: 0.0040\n",
      "  Best Hyperparameters: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "\n",
      "Starting grid search for input length: 216\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 78: early stopping\n",
      "Restoring model weights from the end of the best epoch: 68.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 72: early stopping\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 63.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 92.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 81: early stopping\n",
      "Restoring model weights from the end of the best epoch: 71.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 66.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0083\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Validation loss: 0.0040\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Completed grid search for input length: 216\n",
      "  Best Validation MSE: 0.0036\n",
      "  Best Hyperparameters: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "\n",
      "Starting grid search for input length: 240\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 71: early stopping\n",
      "Restoring model weights from the end of the best epoch: 61.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 64.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 64.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0159\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 96: early stopping\n",
      "Restoring model weights from the end of the best epoch: 86.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0041\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Completed grid search for input length: 240\n",
      "  Best Validation MSE: 0.0037\n",
      "  Best Hyperparameters: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "\n",
      "Starting grid search for input length: 264\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 64.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 72: early stopping\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 90: early stopping\n",
      "Restoring model weights from the end of the best epoch: 80.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 87: early stopping\n",
      "Restoring model weights from the end of the best epoch: 77.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 63.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 72: early stopping\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 77: early stopping\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0136\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0106\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0130\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0043\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Completed grid search for input length: 264\n",
      "  Best Validation MSE: 0.0039\n",
      "  Best Hyperparameters: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "\n",
      "Starting grid search for input length: 288\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 78: early stopping\n",
      "Restoring model weights from the end of the best epoch: 68.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 91: early stopping\n",
      "Restoring model weights from the end of the best epoch: 81.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 64.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 93: early stopping\n",
      "Restoring model weights from the end of the best epoch: 83.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 84: early stopping\n",
      "Restoring model weights from the end of the best epoch: 74.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 72: early stopping\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 71: early stopping\n",
      "Restoring model weights from the end of the best epoch: 61.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.0113\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.0041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Completed grid search for input length: 288\n",
      "  Best Validation MSE: 0.0038\n",
      "  Best Hyperparameters: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "\n",
      "Starting grid search for input length: 312\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 77: early stopping\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 87: early stopping\n",
      "Restoring model weights from the end of the best epoch: 77.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 78: early stopping\n",
      "Restoring model weights from the end of the best epoch: 68.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0057\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0127\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0133\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0035\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0135\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0041\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Completed grid search for input length: 312\n",
      "  Best Validation MSE: 0.0035\n",
      "  Best Hyperparameters: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "\n",
      "Starting grid search for input length: 336\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0035\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 99.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 64.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0035\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0035\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0035\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0034\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 64.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0035\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 78: early stopping\n",
      "Restoring model weights from the end of the best epoch: 68.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.0035\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0145\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0100\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0148\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.0147\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0035\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0039\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Completed grid search for input length: 336\n",
      "  Best Validation MSE: 0.0034\n",
      "  Best Hyperparameters: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "\n",
      "Starting grid search for input length: 360\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 72: early stopping\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 99.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 77: early stopping\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 77: early stopping\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 91.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 91: early stopping\n",
      "Restoring model weights from the end of the best epoch: 81.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 66.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.0092\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0090\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0116\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Validation loss: 0.0039\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Completed grid search for input length: 360\n",
      "  Best Validation MSE: 0.0036\n",
      "  Best Hyperparameters: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "\n",
      "Starting grid search for input length: 384\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 84: early stopping\n",
      "Restoring model weights from the end of the best epoch: 74.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 83: early stopping\n",
      "Restoring model weights from the end of the best epoch: 73.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 79: early stopping\n",
      "Restoring model weights from the end of the best epoch: 69.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 81: early stopping\n",
      "Restoring model weights from the end of the best epoch: 71.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 90: early stopping\n",
      "Restoring model weights from the end of the best epoch: 80.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 81: early stopping\n",
      "Restoring model weights from the end of the best epoch: 71.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 72: early stopping\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 79: early stopping\n",
      "Restoring model weights from the end of the best epoch: 69.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 87: early stopping\n",
      "Restoring model weights from the end of the best epoch: 77.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0100\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0068\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0041\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "Completed grid search for input length: 384\n",
      "  Best Validation MSE: 0.0036\n",
      "  Best Hyperparameters: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "\n",
      "Starting grid search for input length: 408\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 96.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 64.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 83: early stopping\n",
      "Restoring model weights from the end of the best epoch: 73.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 77: early stopping\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 71: early stopping\n",
      "Restoring model weights from the end of the best epoch: 61.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 79: early stopping\n",
      "Restoring model weights from the end of the best epoch: 69.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 63.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 86: early stopping\n",
      "Restoring model weights from the end of the best epoch: 76.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0042\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Completed grid search for input length: 408\n",
      "  Best Validation MSE: 0.0037\n",
      "  Best Hyperparameters: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "\n",
      "Starting grid search for input length: 432\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 78: early stopping\n",
      "Restoring model weights from the end of the best epoch: 68.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 100: early stopping\n",
      "Restoring model weights from the end of the best epoch: 90.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0037\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0038\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0036\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.0081\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.0148\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0063\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0041\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Completed grid search for input length: 432\n",
      "  Best Validation MSE: 0.0036\n",
      "  Best Hyperparameters: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "\n",
      "Starting grid search for input length: 456\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 90: early stopping\n",
      "Restoring model weights from the end of the best epoch: 80.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 86: early stopping\n",
      "Restoring model weights from the end of the best epoch: 76.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 83: early stopping\n",
      "Restoring model weights from the end of the best epoch: 73.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0039\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 80: early stopping\n",
      "Restoring model weights from the end of the best epoch: 70.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0093\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0098\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0153\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0042\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0041\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0166\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.0153\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0040\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.0154\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.0044\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Completed grid search for input length: 456\n",
      "  Best Validation MSE: 0.0039\n",
      "  Best Hyperparameters: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "\n",
      "Starting grid search for input length: 480\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 63.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 80: early stopping\n",
      "Restoring model weights from the end of the best epoch: 70.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 82: early stopping\n",
      "Restoring model weights from the end of the best epoch: 72.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 82: early stopping\n",
      "Restoring model weights from the end of the best epoch: 72.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0043\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 79: early stopping\n",
      "Restoring model weights from the end of the best epoch: 69.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0044\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0084\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: 0.0142\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 63.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0045\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0117\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0046\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0048\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0049\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "Completed grid search for input length: 480\n",
      "  Best Validation MSE: 0.0043\n",
      "  Best Hyperparameters: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "\n",
      "Starting grid search for input length: 504\n",
      "  Evaluating combination 1/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 2/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 3/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 4/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.0056\n",
      "  Evaluating combination 5/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0055\n",
      "  Evaluating combination 6/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.0055\n",
      "  Evaluating combination 7/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 8/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0055\n",
      "  Evaluating combination 9/180: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0055\n",
      "  Evaluating combination 10/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 11/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 12/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 13/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 14/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0056\n",
      "  Evaluating combination 15/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 83: early stopping\n",
      "Restoring model weights from the end of the best epoch: 73.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 16/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0055\n",
      "  Evaluating combination 17/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.0055\n",
      "  Evaluating combination 18/180: {'units': 32, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0056\n",
      "  Evaluating combination 19/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 20/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 21/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 22/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 23/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 24/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.0055\n",
      "  Evaluating combination 25/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0055\n",
      "  Evaluating combination 26/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0056\n",
      "  Evaluating combination 27/180: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 72: early stopping\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "Validation loss: 0.0056\n",
      "  Evaluating combination 28/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 29/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 30/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 31/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0055\n",
      "  Evaluating combination 32/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0055\n",
      "  Evaluating combination 33/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 75: early stopping\n",
      "Restoring model weights from the end of the best epoch: 65.\n",
      "Validation loss: 0.0055\n",
      "  Evaluating combination 34/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0056\n",
      "  Evaluating combination 35/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.0055\n",
      "  Evaluating combination 36/180: {'units': 32, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "Validation loss: 0.0056\n",
      "  Evaluating combination 37/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 38/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 39/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 40/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 41/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0055\n",
      "  Evaluating combination 42/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 43/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0055\n",
      "  Evaluating combination 44/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Validation loss: 0.0055\n",
      "  Evaluating combination 45/180: {'units': 32, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0056\n",
      "  Evaluating combination 46/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 47/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 48/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 49/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 50/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0055\n",
      "  Evaluating combination 51/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0056\n",
      "  Evaluating combination 52/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.0058\n",
      "  Evaluating combination 53/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0057\n",
      "  Evaluating combination 54/180: {'units': 64, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0057\n",
      "  Evaluating combination 55/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 56/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 57/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 58/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 59/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 60/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0056\n",
      "  Evaluating combination 61/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 62/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 79: early stopping\n",
      "Restoring model weights from the end of the best epoch: 69.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 63/180: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.0056\n",
      "  Evaluating combination 64/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 65/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 66/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 67/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 68/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 69/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0056\n",
      "  Evaluating combination 70/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0055\n",
      "  Evaluating combination 71/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 72/180: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0056\n",
      "  Evaluating combination 73/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0047\n",
      "  Evaluating combination 74/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 75/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 76/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 77/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 78/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0055\n",
      "  Evaluating combination 79/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 80/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 81/180: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0057\n",
      "  Evaluating combination 82/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 83/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 84/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 85/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 86/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 87/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0055\n",
      "  Evaluating combination 88/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 89/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0055\n",
      "  Evaluating combination 90/180: {'units': 64, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.0056\n",
      "  Evaluating combination 91/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 92/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 93/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 94/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 95/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.0056\n",
      "  Evaluating combination 96/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0055\n",
      "  Evaluating combination 97/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 98/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 99/180: {'units': 128, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0057\n",
      "  Evaluating combination 100/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 101/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 102/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 103/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 104/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 105/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 106/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 107/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 108/180: {'units': 128, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0056\n",
      "  Evaluating combination 109/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 110/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 111/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 112/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 113/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 114/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 115/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 116/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 117/180: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0056\n",
      "  Evaluating combination 118/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 119/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 120/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 121/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 122/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 123/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 124/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 125/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 126/180: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0056\n",
      "  Evaluating combination 127/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 128/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 129/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 130/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 131/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 132/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 133/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 134/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 135/180: {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0055\n",
      "  Evaluating combination 136/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 137/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 138/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0106\n",
      "  Evaluating combination 139/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 140/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 141/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 142/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 143/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.0057\n",
      "  Evaluating combination 144/180: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0057\n",
      "  Evaluating combination 145/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 146/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0049\n",
      "  Evaluating combination 147/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 148/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 149/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 150/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 151/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 152/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 153/180: {'units': 256, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0055\n",
      "  Evaluating combination 154/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.0055\n",
      "  Evaluating combination 155/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.0168\n",
      "  Evaluating combination 156/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0163\n",
      "  Evaluating combination 157/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 158/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 159/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 160/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 161/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 162/180: {'units': 256, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 163/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 164/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 165/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 166/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 167/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 168/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 169/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 170/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.0052\n",
      "  Evaluating combination 171/180: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 172/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.0051\n",
      "  Evaluating combination 173/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 174/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 175/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.0050\n",
      "  Evaluating combination 176/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 177/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 178/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.0053\n",
      "  Evaluating combination 179/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.0054\n",
      "  Evaluating combination 180/180: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.0054\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Completed grid search for input length: 504\n",
      "  Best Validation MSE: 0.0047\n",
      "  Best Hyperparameters: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 32}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "for length in input_lengths:\n",
    "    print(f\"Starting grid search for input length: {length}\")\n",
    "    \n",
    "    X_train = data_dict[length]['X_train']\n",
    "    y_train = data_dict[length]['y_train']\n",
    "    X_val = data_dict[length]['X_val']\n",
    "    y_val = data_dict[length]['y_val']\n",
    "    \n",
    "    best_mse = float('inf')\n",
    "    best_params = {}\n",
    "    best_model = None\n",
    "    \n",
    "    for idx, combination in enumerate(all_combinations):\n",
    "        # Extract hyperparameters\n",
    "        hyperparams = {\n",
    "            'units': combination[0],\n",
    "            'dropout': combination[1],\n",
    "            'learning_rate': combination[2],\n",
    "            'batch_size': combination[3]\n",
    "        }\n",
    "        \n",
    "        print(f\"  Evaluating combination {idx + 1}/{len(all_combinations)}: {hyperparams}\")\n",
    "        \n",
    "        model = build_lstm_model(hyperparams, length)\n",
    "        \n",
    "        # Early Stopping Callback\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True,verbose=1)\n",
    "        \n",
    "        # Train the model\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=100,\n",
    "            batch_size=hyperparams['batch_size'],\n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=[early_stop],\n",
    "            verbose=0  # Set to 1 to see training progress\n",
    "        )\n",
    "        \n",
    "        # Retrieve the best validation MSE from the history\n",
    "        current_best_mse = min(history.history['val_loss'])\n",
    "        print(f\"Validation loss: {current_best_mse:.4f}\")\n",
    "        \n",
    "        # Check if this is the best model so far\n",
    "        if current_best_mse < best_mse:\n",
    "            best_mse = current_best_mse\n",
    "            best_params = hyperparams.copy()\n",
    "            best_model = model  # Optionally, save the model if needed\n",
    "    \n",
    "    # After evaluating all combinations, store the best results\n",
    "    results.append({\n",
    "        'Input_Length': length,\n",
    "        'Best_MSE': best_mse,\n",
    "        'Validation_MSE': mean_squared_error(y_val, best_model.predict(X_val)),\n",
    "        'Validation_MAE': mean_absolute_error(y_val, best_model.predict(X_val)),\n",
    "        'Validation_MAPE': mean_absolute_percentage_error(y_val, best_model.predict(X_val)) * 100,  # In percentage\n",
    "        'Validation_RMSE': np.sqrt(mean_squared_error(y_val, best_model.predict(X_val))),\n",
    "        'Best_Hyperparameters': best_params\n",
    "    })\n",
    "    \n",
    "    print(f\"Completed grid search for input length: {length}\")\n",
    "    print(f\"  Best Validation MSE: {best_mse:.4f}\")\n",
    "    print(f\"  Best Hyperparameters: {best_params}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 192\n",
    "  Best Validation MSE: 0.0040\n",
    "  Best Hyperparameters: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 32}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 216\n",
    "  Best Validation MSE: 0.0035\n",
    "  Best Hyperparameters: {'units': 32, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 240\n",
    "  Best Validation MSE: 0.0036\n",
    "  Best Hyperparameters: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 264\n",
    "  Best Validation MSE: 0.0038\n",
    "  Best Hyperparameters: {'units': 256, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 288\n",
    "  Best Validation MSE: 0.0036\n",
    "  Best Hyperparameters: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 128}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 312\n",
    "  Best Validation MSE: 0.0035\n",
    "  Best Hyperparameters: {'units': 128, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 128}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 336\n",
    "  Best Validation MSE: 0.0035\n",
    "  Best Hyperparameters: {'units': 64, 'dropout': 0.2, 'learning_rate': 0.01, 'batch_size': 64}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 360\n",
    "  Best Validation MSE: 0.0036\n",
    "  Best Hyperparameters: {'units': 256, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 384\n",
    "  Best Validation MSE: 0.0035\n",
    "  Best Hyperparameters: {'units': 32, 'dropout': 0.0, 'learning_rate': 0.01, 'batch_size': 32}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 408\n",
    "  Best Validation MSE: 0.0036\n",
    "  Best Hyperparameters: {'units': 256, 'dropout': 0.4, 'learning_rate': 0.01, 'batch_size': 64}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 432\n",
    "  Best Validation MSE: 0.0036\n",
    "  Best Hyperparameters: {'units': 64, 'dropout': 0.1, 'learning_rate': 0.01, 'batch_size': 64}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 456\n",
    "  Best Validation MSE: 0.0039\n",
    "  Best Hyperparameters: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 480\n",
    "  Best Validation MSE: 0.0043\n",
    "  Best Hyperparameters: {'units': 64, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 504\n",
    "  Best Validation MSE: 0.0048\n",
    "  Best Hyperparameters: {'units': 128, 'dropout': 0.3, 'learning_rate': 0.01, 'batch_size': 64}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Storing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Results DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input_Length</th>\n",
       "      <th>Best_MSE</th>\n",
       "      <th>Validation_MSE</th>\n",
       "      <th>Validation_MAE</th>\n",
       "      <th>Validation_MAPE</th>\n",
       "      <th>Validation_RMSE</th>\n",
       "      <th>units</th>\n",
       "      <th>dropout</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>0.004180</td>\n",
       "      <td>0.004180</td>\n",
       "      <td>0.046268</td>\n",
       "      <td>48.645039</td>\n",
       "      <td>0.064649</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>0.004267</td>\n",
       "      <td>0.004267</td>\n",
       "      <td>0.047123</td>\n",
       "      <td>50.158704</td>\n",
       "      <td>0.065326</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>0.004178</td>\n",
       "      <td>0.004178</td>\n",
       "      <td>0.046671</td>\n",
       "      <td>51.007772</td>\n",
       "      <td>0.064636</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.046948</td>\n",
       "      <td>53.932355</td>\n",
       "      <td>0.064420</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>0.004057</td>\n",
       "      <td>0.004057</td>\n",
       "      <td>0.044997</td>\n",
       "      <td>42.296438</td>\n",
       "      <td>0.063698</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>144</td>\n",
       "      <td>0.003970</td>\n",
       "      <td>0.003970</td>\n",
       "      <td>0.045152</td>\n",
       "      <td>42.139950</td>\n",
       "      <td>0.063006</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>168</td>\n",
       "      <td>0.004064</td>\n",
       "      <td>0.004064</td>\n",
       "      <td>0.046992</td>\n",
       "      <td>58.048964</td>\n",
       "      <td>0.063748</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>192</td>\n",
       "      <td>0.004010</td>\n",
       "      <td>0.004010</td>\n",
       "      <td>0.046197</td>\n",
       "      <td>46.153253</td>\n",
       "      <td>0.063325</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>216</td>\n",
       "      <td>0.003580</td>\n",
       "      <td>0.003580</td>\n",
       "      <td>0.043131</td>\n",
       "      <td>43.863506</td>\n",
       "      <td>0.059834</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>240</td>\n",
       "      <td>0.003665</td>\n",
       "      <td>0.003665</td>\n",
       "      <td>0.044303</td>\n",
       "      <td>41.677153</td>\n",
       "      <td>0.060540</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>264</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>0.045836</td>\n",
       "      <td>45.385732</td>\n",
       "      <td>0.062258</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>288</td>\n",
       "      <td>0.003760</td>\n",
       "      <td>0.003760</td>\n",
       "      <td>0.044875</td>\n",
       "      <td>51.343928</td>\n",
       "      <td>0.061317</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>312</td>\n",
       "      <td>0.003517</td>\n",
       "      <td>0.003517</td>\n",
       "      <td>0.043831</td>\n",
       "      <td>54.408386</td>\n",
       "      <td>0.059300</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>336</td>\n",
       "      <td>0.003450</td>\n",
       "      <td>0.003450</td>\n",
       "      <td>0.043052</td>\n",
       "      <td>49.255691</td>\n",
       "      <td>0.058732</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>360</td>\n",
       "      <td>0.003580</td>\n",
       "      <td>0.003580</td>\n",
       "      <td>0.042739</td>\n",
       "      <td>42.865112</td>\n",
       "      <td>0.059830</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>384</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.042853</td>\n",
       "      <td>43.891297</td>\n",
       "      <td>0.060003</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>408</td>\n",
       "      <td>0.003686</td>\n",
       "      <td>0.003686</td>\n",
       "      <td>0.043394</td>\n",
       "      <td>53.606368</td>\n",
       "      <td>0.060709</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>432</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>0.042055</td>\n",
       "      <td>44.192843</td>\n",
       "      <td>0.060264</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>456</td>\n",
       "      <td>0.003925</td>\n",
       "      <td>0.003925</td>\n",
       "      <td>0.043491</td>\n",
       "      <td>40.448529</td>\n",
       "      <td>0.062648</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>480</td>\n",
       "      <td>0.004287</td>\n",
       "      <td>0.004287</td>\n",
       "      <td>0.046455</td>\n",
       "      <td>50.406332</td>\n",
       "      <td>0.065478</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>504</td>\n",
       "      <td>0.004693</td>\n",
       "      <td>0.004693</td>\n",
       "      <td>0.047284</td>\n",
       "      <td>43.695004</td>\n",
       "      <td>0.068506</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Input_Length  Best_MSE  Validation_MSE  Validation_MAE  Validation_MAPE  \\\n",
       "0             24  0.004180        0.004180        0.046268        48.645039   \n",
       "1             48  0.004267        0.004267        0.047123        50.158704   \n",
       "2             72  0.004178        0.004178        0.046671        51.007772   \n",
       "3             96  0.004150        0.004150        0.046948        53.932355   \n",
       "4            120  0.004057        0.004057        0.044997        42.296438   \n",
       "5            144  0.003970        0.003970        0.045152        42.139950   \n",
       "6            168  0.004064        0.004064        0.046992        58.048964   \n",
       "7            192  0.004010        0.004010        0.046197        46.153253   \n",
       "8            216  0.003580        0.003580        0.043131        43.863506   \n",
       "9            240  0.003665        0.003665        0.044303        41.677153   \n",
       "10           264  0.003876        0.003876        0.045836        45.385732   \n",
       "11           288  0.003760        0.003760        0.044875        51.343928   \n",
       "12           312  0.003517        0.003517        0.043831        54.408386   \n",
       "13           336  0.003450        0.003450        0.043052        49.255691   \n",
       "14           360  0.003580        0.003580        0.042739        42.865112   \n",
       "15           384  0.003600        0.003600        0.042853        43.891297   \n",
       "16           408  0.003686        0.003686        0.043394        53.606368   \n",
       "17           432  0.003632        0.003632        0.042055        44.192843   \n",
       "18           456  0.003925        0.003925        0.043491        40.448529   \n",
       "19           480  0.004287        0.004287        0.046455        50.406332   \n",
       "20           504  0.004693        0.004693        0.047284        43.695004   \n",
       "\n",
       "    Validation_RMSE  units  dropout  learning_rate  batch_size  \n",
       "0          0.064649  128.0      0.1         0.0010        32.0  \n",
       "1          0.065326  128.0      0.1         0.0010        32.0  \n",
       "2          0.064636  128.0      0.2         0.0100       128.0  \n",
       "3          0.064420   32.0      0.2         0.0100        32.0  \n",
       "4          0.063698  128.0      0.1         0.0010        32.0  \n",
       "5          0.063006  256.0      0.0         0.0100        64.0  \n",
       "6          0.063748  128.0      0.1         0.0100       128.0  \n",
       "7          0.063325   64.0      0.0         0.0005        64.0  \n",
       "8          0.059834   32.0      0.2         0.0100        32.0  \n",
       "9          0.060540  128.0      0.3         0.0100        32.0  \n",
       "10         0.062258   64.0      0.2         0.0100        64.0  \n",
       "11         0.061317   32.0      0.2         0.0100        32.0  \n",
       "12         0.059300  256.0      0.3         0.0100        32.0  \n",
       "13         0.058732   64.0      0.3         0.0100        32.0  \n",
       "14         0.059830   64.0      0.0         0.0100       128.0  \n",
       "15         0.060003  128.0      0.2         0.0100        32.0  \n",
       "16         0.060709   64.0      0.1         0.0100        32.0  \n",
       "17         0.060264  256.0      0.0         0.0100        64.0  \n",
       "18         0.062648   32.0      0.3         0.0100        32.0  \n",
       "19         0.065478  128.0      0.4         0.0100        32.0  \n",
       "20         0.068506   64.0      0.3         0.0100        32.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the results list to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Expand the hyperparameters dictionary into separate columns for clarity\n",
    "hyperparams_df = results_df['Best_Hyperparameters'].apply(pd.Series)\n",
    "\n",
    "# Combine the main dataframe with hyperparameters\n",
    "final_results_df = pd.concat([results_df.drop('Best_Hyperparameters', axis=1), hyperparams_df], axis=1)\n",
    "\n",
    "# Display the final dataframe\n",
    "print(\"Final Results DataFrame:\")\n",
    "final_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| input_len | Best_MSE | units | dropout | learning_rate | batch_size |\n",
    "|-----------|---------:|------:|--------:|--------------:|-----------:|\n",
    "| 24        | 0.004180 | 128   | 0.1     | 0.0010        | 32         |\n",
    "| 48        | 0.004267 | 128   | 0.1     | 0.0010        | 32         |\n",
    "| 72        | 0.004178 | 128   | 0.2     | 0.0100        | 128        |\n",
    "| 96        | 0.004150 | 32    | 0.2     | 0.0100        | 32         |\n",
    "| 120       | 0.004057 | 128   | 0.1     | 0.0010        | 32         |\n",
    "| 144       | 0.003970 | 256   | 0.0     | 0.0100        | 64         |\n",
    "| 168       | 0.004064 | 128   | 0.1     | 0.0100        | 128        |\n",
    "| 192       | 0.004010 | 64    | 0.0     | 0.0005        | 64         |\n",
    "| 216       | 0.003580 | 32    | 0.2     | 0.0100        | 32         |\n",
    "| 240       | 0.003665 | 128   | 0.3     | 0.0100        | 32         |\n",
    "| 264       | 0.003876 | 64    | 0.2     | 0.0100        | 64         |\n",
    "| 288       | 0.003760 | 32    | 0.2     | 0.0100        | 32         |\n",
    "| 312       | 0.003517 | 256   | 0.3     | 0.0100        | 32         |\n",
    "| 336       | 0.003450 | 64    | 0.3     | 0.0100        | 32         |\n",
    "| 360       | 0.003580 | 64    | 0.0     | 0.0100        | 128        |\n",
    "| 384       | 0.003600 | 128   | 0.2     | 0.0100        | 32         |\n",
    "| 408       | 0.003686 | 64    | 0.1     | 0.0100        | 32         |\n",
    "| 432       | 0.003632 | 256   | 0.0     | 0.0100        | 64         |\n",
    "| 456       | 0.003925 | 32    | 0.3     | 0.0100        | 32         |\n",
    "| 480       | 0.004287 | 128   | 0.4     | 0.0100        | 32         |\n",
    "| 504       | 0.004693 | 64    | 0.3     | 0.0100        | 32         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Results\n",
    "\n",
    "| Input_Length | Best Validation MSE | units | dropout | learning_rate | batch_size |\n",
    "|--------------|---------------------|-------|---------|---------------|------------|\n",
    "| 24           | 0.004132            | 256   | 0.4     | 0.001         | 32         |\n",
    "| 48           | 0.004258            | 32    | 0.1     | 0.010         | 64         |\n",
    "| 72           | 0.004136            | 64    | 0.1     | 0.010         | 64         |\n",
    "| 96           | 0.004128            | 128   | 0.3     | 0.010         | 64         |\n",
    "| 120          | 0.003844            | 128   | 0.2     | 0.010         | 64         |\n",
    "| 144          | 0.003995            | 32    | 0.0     | 0.010         | 64         |\n",
    "| 168          | 0.004008            | 32    | 0.0     | 0.001         | 32         |\n",
    "| 192          | 0.0040              | 32    | 0.2     | 0.01          | 32         |\n",
    "| 216          | 0.0035              | 32    | 0.2     | 0.01          | 128        |\n",
    "| 240          | 0.0036              | 32    | 0.0     | 0.01          | 128        |\n",
    "| 264          | 0.0038              | 256   | 0.3     | 0.001         | 32         |\n",
    "| 288          | 0.0036              | 256   | 0.0     | 0.01          | 128        |\n",
    "| 312          | 0.0035              | 128   | 0.2     | 0.01          | 128        |\n",
    "| 336          | 0.0035              | 64    | 0.2     | 0.01          | 64         |\n",
    "| 360          | 0.0036              | 256   | 0.0     | 0.01          | 32         |\n",
    "| 384          | 0.0035              | 32    | 0.0     | 0.01          | 32         |\n",
    "| 408          | 0.0036              | 256   | 0.4     | 0.01          | 64         |\n",
    "| 432          | 0.0036              | 64    | 0.1     | 0.01          | 64         |\n",
    "| 456          | 0.0039              | 64    | 0.3     | 0.01          | 64         |\n",
    "| 480          | 0.0043              | 64    | 0.3     | 0.01          | 64         |\n",
    "| 504          | 0.0048              | 128   | 0.3     | 0.01          | 64         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Retrain the model after getting the best hyperparameters of each input length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparameters = {\n",
    "    24: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.1,\n",
    "        'learning_rate': 0.0010,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    48: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.1,\n",
    "        'learning_rate': 0.0010,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    72: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 128\n",
    "    },\n",
    "    96: {\n",
    "        'units': 32,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    120: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.1,\n",
    "        'learning_rate': 0.0010,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    144: {\n",
    "        'units': 256,\n",
    "        'dropout': 0.0,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 64\n",
    "    },\n",
    "    168: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.1,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 128\n",
    "    },\n",
    "    192: {\n",
    "        'units': 64,\n",
    "        'dropout': 0.0,\n",
    "        'learning_rate': 0.0005,\n",
    "        'batch_size': 64\n",
    "    },\n",
    "    216: {\n",
    "        'units': 32,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    240: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.3,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    264: {\n",
    "        'units': 64,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 64\n",
    "    },\n",
    "    288: {\n",
    "        'units': 32,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    312: {\n",
    "        'units': 256,\n",
    "        'dropout': 0.3,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    336: {\n",
    "        'units': 64,\n",
    "        'dropout': 0.3,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    360: {\n",
    "        'units': 64,\n",
    "        'dropout': 0.0,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 128\n",
    "    },\n",
    "    384: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    408: {\n",
    "        'units': 64,\n",
    "        'dropout': 0.1,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    432: {\n",
    "        'units': 256,\n",
    "        'dropout': 0.0,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 64\n",
    "    },\n",
    "    456: {\n",
    "        'units': 32,\n",
    "        'dropout': 0.3,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    480: {\n",
    "        'units': 128,\n",
    "        'dropout': 0.4,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    504: {\n",
    "        'units': 64,\n",
    "        'dropout': 0.3,\n",
    "        'learning_rate': 0.0100,\n",
    "        'batch_size': 32\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(hyperparams,data_dict,length, seed=None):  # add seed\n",
    "    if seed is not None:\n",
    "        set_seed(seed)\n",
    "    \n",
    "    #get the data of each length\n",
    "    X_train = data_dict[length]['X_train']\n",
    "    y_train = data_dict[length]['y_train']\n",
    "    X_val = data_dict[length]['X_val']\n",
    "    y_val = data_dict[length]['y_val']\n",
    "    \n",
    "    # Train the model\n",
    "    model = build_lstm_model(hyperparams, length)    \n",
    "    # Early Stopping Callback\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True,verbose=1)    \n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=100,\n",
    "        batch_size=hyperparams['batch_size'],\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[early_stop],\n",
    "        verbose=0  # Set to 1 to see training progress\n",
    "    )\n",
    "    \n",
    "    # Retrieve the best validation MSE from the history\n",
    "    best_mse = min(history.history['val_loss'])\n",
    "    print(f\"Validation loss: {best_mse:.5f}\")\n",
    "    \n",
    "    return model, best_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "def make_prediction(model, X_obs, y_obs):\n",
    "    y_pred = model.predict(X_obs,verbose=0)\n",
    "    n_samples = X_obs.shape[0]\n",
    "    output_len = y_obs.shape[1]\n",
    "\n",
    "    # Reshape for inverse scaling\n",
    "    y_pred_reshaped = y_pred.reshape(-1, 1)\n",
    "    y_obs_reshaped = y_obs.reshape(-1, 1)\n",
    "\n",
    "    # Inverse transform\n",
    "    y_pred_inverse = scaler.inverse_transform(y_pred_reshaped).reshape(n_samples, output_len)\n",
    "    y_obs_inverse = scaler.inverse_transform(y_obs_reshaped).reshape(n_samples, output_len)\n",
    "\n",
    "    return y_pred_inverse, y_obs_inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Metrics for Each Time Step\n",
    "def evaluation(y_pred_inverse, y_obs_inverse):\n",
    "    \n",
    "    output_len = y_pred_inverse.shape[1]\n",
    "    metrics_list = []  # To store metrics for each time step\n",
    "    \n",
    "    for i in range(output_len):\n",
    "        y_true = y_obs_inverse[:, i]\n",
    "        y_pred = y_pred_inverse[:, i]\n",
    "\n",
    "        # Mean Absolute Error (MAE)\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "        # Mean Squared Error (MSE)\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "        # Root Mean Squared Error (RMSE)\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        # Mean Absolute Percentage Error (MAPE)\n",
    "        # Avoid division by zero by adding a small epsilon to y_test_flat if necessary\n",
    "        epsilon = 1e-10\n",
    "        y_true_safe = np.where(y_true == 0, epsilon, y_true)\n",
    "        mape = np.mean(np.abs((y_true - y_pred) / y_true_safe)) * 100\n",
    "\n",
    "                # Append the metrics for the current time step to the list\n",
    "        metrics_list.append({\n",
    "            'Time Step': i + 1,\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse,\n",
    "            'MAPE (%)': mape\n",
    "        })\n",
    "\n",
    "    # Create a DataFrame from the list of metrics\n",
    "    metrics_df = pd.DataFrame(metrics_list)\n",
    "    metrics_df.set_index('Time Step', inplace=True)\n",
    "\n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "\n",
      "--- Run 1 ---\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.00430\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.00436\n",
      "\n",
      "--- Run 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00453\n",
      "\n",
      "--- Run 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00438\n",
      "\n",
      "--- Run 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.00429\n",
      "\n",
      "--- Run 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Validation loss: 0.00429\n",
      "\n",
      "--- Run 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00443\n",
      "\n",
      "--- Run 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Validation loss: 0.00440\n",
      "\n",
      "--- Run 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00433\n",
      "\n",
      "--- Run 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77: early stopping\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "Validation loss: 0.00419\n",
      "\n",
      "--- Aggregated Mean of All Metrics Across 10 Runs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.196726</td>\n",
       "      <td>35.206263</td>\n",
       "      <td>35.427416</td>\n",
       "      <td>21.274125</td>\n",
       "      <td>29.709942</td>\n",
       "      <td>30.171852</td>\n",
       "      <td>19.960012</td>\n",
       "      <td>25.768764</td>\n",
       "      <td>18.049392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.253840</td>\n",
       "      <td>40.181383</td>\n",
       "      <td>40.599087</td>\n",
       "      <td>24.815992</td>\n",
       "      <td>34.585551</td>\n",
       "      <td>34.907396</td>\n",
       "      <td>24.184106</td>\n",
       "      <td>31.712940</td>\n",
       "      <td>21.741709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.890504</td>\n",
       "      <td>42.484448</td>\n",
       "      <td>44.763898</td>\n",
       "      <td>26.562489</td>\n",
       "      <td>36.714279</td>\n",
       "      <td>38.980310</td>\n",
       "      <td>26.807227</td>\n",
       "      <td>34.625214</td>\n",
       "      <td>24.223394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.038804</td>\n",
       "      <td>43.997132</td>\n",
       "      <td>47.801962</td>\n",
       "      <td>27.782584</td>\n",
       "      <td>38.369888</td>\n",
       "      <td>41.957398</td>\n",
       "      <td>28.425959</td>\n",
       "      <td>36.339324</td>\n",
       "      <td>26.039394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.136699</td>\n",
       "      <td>45.448723</td>\n",
       "      <td>51.637742</td>\n",
       "      <td>28.862588</td>\n",
       "      <td>39.603779</td>\n",
       "      <td>45.987274</td>\n",
       "      <td>29.088489</td>\n",
       "      <td>37.051100</td>\n",
       "      <td>26.782715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30.917877</td>\n",
       "      <td>46.738272</td>\n",
       "      <td>55.806944</td>\n",
       "      <td>29.252044</td>\n",
       "      <td>40.358002</td>\n",
       "      <td>49.680750</td>\n",
       "      <td>28.475943</td>\n",
       "      <td>36.477571</td>\n",
       "      <td>26.661334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  MAPE (%)_val  \\\n",
       "24                                                                              \n",
       "1   23.196726   35.206263       35.427416  21.274125  29.709942     30.171852   \n",
       "2   26.253840   40.181383       40.599087  24.815992  34.585551     34.907396   \n",
       "3   27.890504   42.484448       44.763898  26.562489  36.714279     38.980310   \n",
       "4   29.038804   43.997132       47.801962  27.782584  38.369888     41.957398   \n",
       "5   30.136699   45.448723       51.637742  28.862588  39.603779     45.987274   \n",
       "6   30.917877   46.738272       55.806944  29.252044  40.358002     49.680750   \n",
       "\n",
       "     MAE_test  RMSE_test  MAPE (%)_test  \n",
       "24                                       \n",
       "1   19.960012  25.768764      18.049392  \n",
       "2   24.184106  31.712940      21.741709  \n",
       "3   26.807227  34.625214      24.223394  \n",
       "4   28.425959  36.339324      26.039394  \n",
       "5   29.088489  37.051100      26.782715  \n",
       "6   28.475943  36.477571      26.661334  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "\n",
      "--- Run 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00426\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00457\n",
      "\n",
      "--- Run 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00437\n",
      "\n",
      "--- Run 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00440\n",
      "\n",
      "--- Run 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00438\n",
      "\n",
      "--- Run 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00427\n",
      "\n",
      "--- Run 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00449\n",
      "\n",
      "--- Run 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00448\n",
      "\n",
      "--- Run 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00454\n",
      "\n",
      "--- Run 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00453\n",
      "\n",
      "--- Aggregated Mean of All Metrics Across 10 Runs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.776811</td>\n",
       "      <td>35.781761</td>\n",
       "      <td>37.963585</td>\n",
       "      <td>21.844494</td>\n",
       "      <td>30.252641</td>\n",
       "      <td>32.514131</td>\n",
       "      <td>19.590866</td>\n",
       "      <td>25.353476</td>\n",
       "      <td>17.615900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.780380</td>\n",
       "      <td>40.732673</td>\n",
       "      <td>41.803691</td>\n",
       "      <td>25.202016</td>\n",
       "      <td>35.192799</td>\n",
       "      <td>36.022697</td>\n",
       "      <td>22.916488</td>\n",
       "      <td>30.536198</td>\n",
       "      <td>20.038009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.372860</td>\n",
       "      <td>42.784282</td>\n",
       "      <td>47.133249</td>\n",
       "      <td>27.110958</td>\n",
       "      <td>37.494059</td>\n",
       "      <td>41.403547</td>\n",
       "      <td>25.605186</td>\n",
       "      <td>33.315361</td>\n",
       "      <td>22.593482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.067260</td>\n",
       "      <td>43.786807</td>\n",
       "      <td>49.543488</td>\n",
       "      <td>28.059721</td>\n",
       "      <td>38.650848</td>\n",
       "      <td>44.502011</td>\n",
       "      <td>27.096081</td>\n",
       "      <td>35.113778</td>\n",
       "      <td>23.497050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29.621170</td>\n",
       "      <td>45.004776</td>\n",
       "      <td>51.270727</td>\n",
       "      <td>28.737713</td>\n",
       "      <td>39.616922</td>\n",
       "      <td>46.731915</td>\n",
       "      <td>28.224943</td>\n",
       "      <td>36.461136</td>\n",
       "      <td>24.164940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30.395940</td>\n",
       "      <td>46.297219</td>\n",
       "      <td>53.376497</td>\n",
       "      <td>29.170106</td>\n",
       "      <td>40.271229</td>\n",
       "      <td>48.773600</td>\n",
       "      <td>28.376052</td>\n",
       "      <td>36.817732</td>\n",
       "      <td>24.342912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  MAPE (%)_val  \\\n",
       "48                                                                              \n",
       "1   23.776811   35.781761       37.963585  21.844494  30.252641     32.514131   \n",
       "2   26.780380   40.732673       41.803691  25.202016  35.192799     36.022697   \n",
       "3   28.372860   42.784282       47.133249  27.110958  37.494059     41.403547   \n",
       "4   29.067260   43.786807       49.543488  28.059721  38.650848     44.502011   \n",
       "5   29.621170   45.004776       51.270727  28.737713  39.616922     46.731915   \n",
       "6   30.395940   46.297219       53.376497  29.170106  40.271229     48.773600   \n",
       "\n",
       "     MAE_test  RMSE_test  MAPE (%)_test  \n",
       "48                                       \n",
       "1   19.590866  25.353476      17.615900  \n",
       "2   22.916488  30.536198      20.038009  \n",
       "3   25.605186  33.315361      22.593482  \n",
       "4   27.096081  35.113778      23.497050  \n",
       "5   28.224943  36.461136      24.164940  \n",
       "6   28.376052  36.817732      24.342912  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "\n",
      "--- Run 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00441\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00428\n",
      "\n",
      "--- Run 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00431\n",
      "\n",
      "--- Run 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00442\n",
      "\n",
      "--- Run 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00450\n",
      "\n",
      "--- Run 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00425\n",
      "\n",
      "--- Run 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00437\n",
      "\n",
      "--- Run 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00455\n",
      "\n",
      "--- Run 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00451\n",
      "\n",
      "--- Run 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00443\n",
      "\n",
      "--- Aggregated Mean of All Metrics Across 10 Runs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.140011</td>\n",
       "      <td>35.963937</td>\n",
       "      <td>40.493105</td>\n",
       "      <td>22.179408</td>\n",
       "      <td>30.213459</td>\n",
       "      <td>34.678162</td>\n",
       "      <td>19.260445</td>\n",
       "      <td>24.839494</td>\n",
       "      <td>17.288484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.217278</td>\n",
       "      <td>41.081662</td>\n",
       "      <td>47.100390</td>\n",
       "      <td>25.370360</td>\n",
       "      <td>34.827442</td>\n",
       "      <td>39.259674</td>\n",
       "      <td>22.253137</td>\n",
       "      <td>29.825911</td>\n",
       "      <td>19.621195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.669532</td>\n",
       "      <td>43.231536</td>\n",
       "      <td>50.484887</td>\n",
       "      <td>26.898220</td>\n",
       "      <td>36.867225</td>\n",
       "      <td>42.733478</td>\n",
       "      <td>24.222403</td>\n",
       "      <td>31.829741</td>\n",
       "      <td>21.005122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.743364</td>\n",
       "      <td>44.748064</td>\n",
       "      <td>52.739876</td>\n",
       "      <td>28.274604</td>\n",
       "      <td>38.626516</td>\n",
       "      <td>45.629941</td>\n",
       "      <td>25.917641</td>\n",
       "      <td>33.773762</td>\n",
       "      <td>22.281308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.293770</td>\n",
       "      <td>45.873952</td>\n",
       "      <td>54.351580</td>\n",
       "      <td>29.043045</td>\n",
       "      <td>39.658021</td>\n",
       "      <td>48.275651</td>\n",
       "      <td>27.141151</td>\n",
       "      <td>35.073339</td>\n",
       "      <td>23.067239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31.284652</td>\n",
       "      <td>47.111803</td>\n",
       "      <td>58.797547</td>\n",
       "      <td>29.763232</td>\n",
       "      <td>40.512194</td>\n",
       "      <td>52.107464</td>\n",
       "      <td>27.335641</td>\n",
       "      <td>35.534549</td>\n",
       "      <td>23.361001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  MAPE (%)_val  \\\n",
       "72                                                                              \n",
       "1   24.140011   35.963937       40.493105  22.179408  30.213459     34.678162   \n",
       "2   27.217278   41.081662       47.100390  25.370360  34.827442     39.259674   \n",
       "3   28.669532   43.231536       50.484887  26.898220  36.867225     42.733478   \n",
       "4   29.743364   44.748064       52.739876  28.274604  38.626516     45.629941   \n",
       "5   30.293770   45.873952       54.351580  29.043045  39.658021     48.275651   \n",
       "6   31.284652   47.111803       58.797547  29.763232  40.512194     52.107464   \n",
       "\n",
       "     MAE_test  RMSE_test  MAPE (%)_test  \n",
       "72                                       \n",
       "1   19.260445  24.839494      17.288484  \n",
       "2   22.253137  29.825911      19.621195  \n",
       "3   24.222403  31.829741      21.005122  \n",
       "4   25.917641  33.773762      22.281308  \n",
       "5   27.141151  35.073339      23.067239  \n",
       "6   27.335641  35.534549      23.361001  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "\n",
      "--- Run 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00423\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00460\n",
      "\n",
      "--- Run 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00429\n",
      "\n",
      "--- Run 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00437\n",
      "\n",
      "--- Run 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00434\n",
      "\n",
      "--- Run 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00438\n",
      "\n",
      "--- Run 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00430\n",
      "\n",
      "--- Run 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00422\n",
      "\n",
      "--- Run 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00451\n",
      "\n",
      "--- Run 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00441\n",
      "\n",
      "--- Aggregated Mean of All Metrics Across 10 Runs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.100732</td>\n",
       "      <td>36.372669</td>\n",
       "      <td>37.107401</td>\n",
       "      <td>21.868642</td>\n",
       "      <td>30.149635</td>\n",
       "      <td>31.196385</td>\n",
       "      <td>19.329569</td>\n",
       "      <td>25.039879</td>\n",
       "      <td>16.791435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.521108</td>\n",
       "      <td>41.700968</td>\n",
       "      <td>45.009941</td>\n",
       "      <td>25.288893</td>\n",
       "      <td>34.830660</td>\n",
       "      <td>38.008385</td>\n",
       "      <td>22.281507</td>\n",
       "      <td>29.672844</td>\n",
       "      <td>19.294867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.017534</td>\n",
       "      <td>43.891466</td>\n",
       "      <td>50.470661</td>\n",
       "      <td>26.961623</td>\n",
       "      <td>36.923854</td>\n",
       "      <td>43.959856</td>\n",
       "      <td>24.074073</td>\n",
       "      <td>31.552398</td>\n",
       "      <td>20.950211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.182735</td>\n",
       "      <td>45.289721</td>\n",
       "      <td>55.349926</td>\n",
       "      <td>28.438583</td>\n",
       "      <td>38.615711</td>\n",
       "      <td>49.075088</td>\n",
       "      <td>25.356398</td>\n",
       "      <td>32.957215</td>\n",
       "      <td>22.244948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.425283</td>\n",
       "      <td>46.243519</td>\n",
       "      <td>55.360513</td>\n",
       "      <td>28.798028</td>\n",
       "      <td>39.257837</td>\n",
       "      <td>49.884433</td>\n",
       "      <td>26.759733</td>\n",
       "      <td>34.617114</td>\n",
       "      <td>23.100334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31.420929</td>\n",
       "      <td>47.519572</td>\n",
       "      <td>58.461386</td>\n",
       "      <td>29.430287</td>\n",
       "      <td>40.125184</td>\n",
       "      <td>52.906538</td>\n",
       "      <td>26.689753</td>\n",
       "      <td>34.891515</td>\n",
       "      <td>23.135077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  MAPE (%)_val  \\\n",
       "96                                                                              \n",
       "1   24.100732   36.372669       37.107401  21.868642  30.149635     31.196385   \n",
       "2   27.521108   41.700968       45.009941  25.288893  34.830660     38.008385   \n",
       "3   29.017534   43.891466       50.470661  26.961623  36.923854     43.959856   \n",
       "4   30.182735   45.289721       55.349926  28.438583  38.615711     49.075088   \n",
       "5   30.425283   46.243519       55.360513  28.798028  39.257837     49.884433   \n",
       "6   31.420929   47.519572       58.461386  29.430287  40.125184     52.906538   \n",
       "\n",
       "     MAE_test  RMSE_test  MAPE (%)_test  \n",
       "96                                       \n",
       "1   19.329569  25.039879      16.791435  \n",
       "2   22.281507  29.672844      19.294867  \n",
       "3   24.074073  31.552398      20.950211  \n",
       "4   25.356398  32.957215      22.244948  \n",
       "5   26.759733  34.617114      23.100334  \n",
       "6   26.689753  34.891515      23.135077  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "\n",
      "--- Run 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00412\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00423\n",
      "\n",
      "--- Run 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00400\n",
      "\n",
      "--- Run 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00428\n",
      "\n",
      "--- Run 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00411\n",
      "\n",
      "--- Run 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00419\n",
      "\n",
      "--- Run 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00416\n",
      "\n",
      "--- Run 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00419\n",
      "\n",
      "--- Run 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00434\n",
      "\n",
      "--- Run 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00430\n",
      "\n",
      "--- Aggregated Mean of All Metrics Across 10 Runs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.981813</td>\n",
       "      <td>36.046899</td>\n",
       "      <td>36.773603</td>\n",
       "      <td>21.507522</td>\n",
       "      <td>29.086505</td>\n",
       "      <td>30.547784</td>\n",
       "      <td>19.239169</td>\n",
       "      <td>24.901053</td>\n",
       "      <td>16.745151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.054832</td>\n",
       "      <td>41.272915</td>\n",
       "      <td>42.167206</td>\n",
       "      <td>24.523499</td>\n",
       "      <td>33.588259</td>\n",
       "      <td>34.925322</td>\n",
       "      <td>22.685276</td>\n",
       "      <td>30.204873</td>\n",
       "      <td>19.468747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.518388</td>\n",
       "      <td>43.508543</td>\n",
       "      <td>46.084088</td>\n",
       "      <td>26.275125</td>\n",
       "      <td>36.117374</td>\n",
       "      <td>39.527270</td>\n",
       "      <td>25.008360</td>\n",
       "      <td>32.759194</td>\n",
       "      <td>21.233811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.351482</td>\n",
       "      <td>44.719805</td>\n",
       "      <td>49.589933</td>\n",
       "      <td>27.541997</td>\n",
       "      <td>37.834076</td>\n",
       "      <td>43.724179</td>\n",
       "      <td>26.104055</td>\n",
       "      <td>34.195974</td>\n",
       "      <td>22.070725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.304708</td>\n",
       "      <td>45.955743</td>\n",
       "      <td>53.586288</td>\n",
       "      <td>28.685380</td>\n",
       "      <td>38.967784</td>\n",
       "      <td>48.669126</td>\n",
       "      <td>26.802559</td>\n",
       "      <td>34.905544</td>\n",
       "      <td>22.551937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31.209531</td>\n",
       "      <td>47.067107</td>\n",
       "      <td>58.846580</td>\n",
       "      <td>29.255630</td>\n",
       "      <td>39.679552</td>\n",
       "      <td>53.590643</td>\n",
       "      <td>26.539709</td>\n",
       "      <td>34.864429</td>\n",
       "      <td>22.242916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  \\\n",
       "120                                                                \n",
       "1    23.981813   36.046899       36.773603  21.507522  29.086505   \n",
       "2    27.054832   41.272915       42.167206  24.523499  33.588259   \n",
       "3    28.518388   43.508543       46.084088  26.275125  36.117374   \n",
       "4    29.351482   44.719805       49.589933  27.541997  37.834076   \n",
       "5    30.304708   45.955743       53.586288  28.685380  38.967784   \n",
       "6    31.209531   47.067107       58.846580  29.255630  39.679552   \n",
       "\n",
       "     MAPE (%)_val   MAE_test  RMSE_test  MAPE (%)_test  \n",
       "120                                                     \n",
       "1       30.547784  19.239169  24.901053      16.745151  \n",
       "2       34.925322  22.685276  30.204873      19.468747  \n",
       "3       39.527270  25.008360  32.759194      21.233811  \n",
       "4       43.724179  26.104055  34.195974      22.070725  \n",
       "5       48.669126  26.802559  34.905544      22.551937  \n",
       "6       53.590643  26.539709  34.864429      22.242916  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "\n",
      "--- Run 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00432\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00426\n",
      "\n",
      "--- Run 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00446\n",
      "\n",
      "--- Run 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00426\n",
      "\n",
      "--- Run 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00415\n",
      "\n",
      "--- Run 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00422\n",
      "\n",
      "--- Run 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00427\n",
      "\n",
      "--- Run 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00451\n",
      "\n",
      "--- Run 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00423\n",
      "\n",
      "--- Run 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.00430\n",
      "\n",
      "--- Aggregated Mean of All Metrics Across 10 Runs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.625918</td>\n",
       "      <td>35.763129</td>\n",
       "      <td>36.163656</td>\n",
       "      <td>21.428161</td>\n",
       "      <td>29.006120</td>\n",
       "      <td>30.619394</td>\n",
       "      <td>19.742538</td>\n",
       "      <td>25.443419</td>\n",
       "      <td>16.827676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.658017</td>\n",
       "      <td>40.802869</td>\n",
       "      <td>41.639720</td>\n",
       "      <td>24.596922</td>\n",
       "      <td>33.782921</td>\n",
       "      <td>35.325943</td>\n",
       "      <td>23.021153</td>\n",
       "      <td>30.547944</td>\n",
       "      <td>19.348504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.059302</td>\n",
       "      <td>42.830781</td>\n",
       "      <td>46.300278</td>\n",
       "      <td>26.487891</td>\n",
       "      <td>36.443585</td>\n",
       "      <td>40.498418</td>\n",
       "      <td>25.083540</td>\n",
       "      <td>32.766233</td>\n",
       "      <td>20.971720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.207095</td>\n",
       "      <td>44.148669</td>\n",
       "      <td>50.655377</td>\n",
       "      <td>28.106427</td>\n",
       "      <td>38.335041</td>\n",
       "      <td>45.988504</td>\n",
       "      <td>26.484346</td>\n",
       "      <td>34.342831</td>\n",
       "      <td>22.100087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29.778985</td>\n",
       "      <td>45.214695</td>\n",
       "      <td>52.963759</td>\n",
       "      <td>29.027377</td>\n",
       "      <td>39.545883</td>\n",
       "      <td>48.515481</td>\n",
       "      <td>27.885017</td>\n",
       "      <td>35.850423</td>\n",
       "      <td>23.088465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31.060372</td>\n",
       "      <td>46.665866</td>\n",
       "      <td>59.151084</td>\n",
       "      <td>29.960592</td>\n",
       "      <td>40.640929</td>\n",
       "      <td>53.572349</td>\n",
       "      <td>28.276238</td>\n",
       "      <td>36.437127</td>\n",
       "      <td>23.307221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  \\\n",
       "144                                                                \n",
       "1    23.625918   35.763129       36.163656  21.428161  29.006120   \n",
       "2    26.658017   40.802869       41.639720  24.596922  33.782921   \n",
       "3    28.059302   42.830781       46.300278  26.487891  36.443585   \n",
       "4    29.207095   44.148669       50.655377  28.106427  38.335041   \n",
       "5    29.778985   45.214695       52.963759  29.027377  39.545883   \n",
       "6    31.060372   46.665866       59.151084  29.960592  40.640929   \n",
       "\n",
       "     MAPE (%)_val   MAE_test  RMSE_test  MAPE (%)_test  \n",
       "144                                                     \n",
       "1       30.619394  19.742538  25.443419      16.827676  \n",
       "2       35.325943  23.021153  30.547944      19.348504  \n",
       "3       40.498418  25.083540  32.766233      20.971720  \n",
       "4       45.988504  26.484346  34.342831      22.100087  \n",
       "5       48.515481  27.885017  35.850423      23.088465  \n",
       "6       53.572349  28.276238  36.437127      23.307221  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\n",
      "\n",
      "--- Run 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86: early stopping\n",
      "Restoring model weights from the end of the best epoch: 66.\n",
      "Validation loss: 0.00422\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.00445\n",
      "\n",
      "--- Run 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80: early stopping\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "Validation loss: 0.00417\n",
      "\n",
      "--- Run 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88: early stopping\n",
      "Restoring model weights from the end of the best epoch: 68.\n",
      "Validation loss: 0.00428\n",
      "\n",
      "--- Run 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Validation loss: 0.00431\n",
      "\n",
      "--- Run 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 86.\n",
      "Validation loss: 0.00417\n",
      "\n",
      "--- Run 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00444\n",
      "\n",
      "--- Run 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Validation loss: 0.00411\n",
      "\n",
      "--- Run 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00421\n",
      "\n",
      "--- Run 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86: early stopping\n",
      "Restoring model weights from the end of the best epoch: 66.\n",
      "Validation loss: 0.00420\n",
      "\n",
      "--- Aggregated Mean of All Metrics Across 10 Runs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.138737</td>\n",
       "      <td>35.439980</td>\n",
       "      <td>33.676544</td>\n",
       "      <td>21.310556</td>\n",
       "      <td>28.932446</td>\n",
       "      <td>29.250211</td>\n",
       "      <td>19.777370</td>\n",
       "      <td>25.720180</td>\n",
       "      <td>16.767063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.284943</td>\n",
       "      <td>40.508673</td>\n",
       "      <td>38.751018</td>\n",
       "      <td>24.745211</td>\n",
       "      <td>33.955579</td>\n",
       "      <td>34.673521</td>\n",
       "      <td>23.773558</td>\n",
       "      <td>31.312852</td>\n",
       "      <td>20.224771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.759045</td>\n",
       "      <td>42.400503</td>\n",
       "      <td>44.131429</td>\n",
       "      <td>26.743518</td>\n",
       "      <td>36.597417</td>\n",
       "      <td>41.062858</td>\n",
       "      <td>25.821543</td>\n",
       "      <td>33.443464</td>\n",
       "      <td>21.842732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.179606</td>\n",
       "      <td>43.220780</td>\n",
       "      <td>46.264912</td>\n",
       "      <td>27.767014</td>\n",
       "      <td>38.074183</td>\n",
       "      <td>44.527537</td>\n",
       "      <td>26.893025</td>\n",
       "      <td>34.689442</td>\n",
       "      <td>22.735474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28.717483</td>\n",
       "      <td>44.238870</td>\n",
       "      <td>47.853401</td>\n",
       "      <td>28.686609</td>\n",
       "      <td>39.258719</td>\n",
       "      <td>46.877028</td>\n",
       "      <td>27.727205</td>\n",
       "      <td>35.596922</td>\n",
       "      <td>23.330394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29.491162</td>\n",
       "      <td>45.225293</td>\n",
       "      <td>50.287426</td>\n",
       "      <td>29.321317</td>\n",
       "      <td>40.022835</td>\n",
       "      <td>49.917660</td>\n",
       "      <td>27.881389</td>\n",
       "      <td>36.022101</td>\n",
       "      <td>23.461952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  \\\n",
       "168                                                                \n",
       "1    23.138737   35.439980       33.676544  21.310556  28.932446   \n",
       "2    26.284943   40.508673       38.751018  24.745211  33.955579   \n",
       "3    27.759045   42.400503       44.131429  26.743518  36.597417   \n",
       "4    28.179606   43.220780       46.264912  27.767014  38.074183   \n",
       "5    28.717483   44.238870       47.853401  28.686609  39.258719   \n",
       "6    29.491162   45.225293       50.287426  29.321317  40.022835   \n",
       "\n",
       "     MAPE (%)_val   MAE_test  RMSE_test  MAPE (%)_test  \n",
       "168                                                     \n",
       "1       29.250211  19.777370  25.720180      16.767063  \n",
       "2       34.673521  23.773558  31.312852      20.224771  \n",
       "3       41.062858  25.821543  33.443464      21.842732  \n",
       "4       44.527537  26.893025  34.689442      22.735474  \n",
       "5       46.877028  27.727205  35.596922      23.330394  \n",
       "6       49.917660  27.881389  36.022101      23.461952  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n",
      "\n",
      "--- Run 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00434\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00427\n",
      "\n",
      "--- Run 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00449\n",
      "\n",
      "--- Run 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00431\n",
      "\n",
      "--- Run 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00477\n",
      "\n",
      "--- Run 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00430\n",
      "\n",
      "--- Run 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00427\n",
      "\n",
      "--- Run 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00454\n",
      "\n",
      "--- Run 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00426\n",
      "\n",
      "--- Run 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00421\n",
      "\n",
      "--- Aggregated Mean of All Metrics Across 10 Runs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.312066</td>\n",
       "      <td>36.327453</td>\n",
       "      <td>39.784838</td>\n",
       "      <td>22.323798</td>\n",
       "      <td>29.868688</td>\n",
       "      <td>34.011554</td>\n",
       "      <td>20.545188</td>\n",
       "      <td>26.267399</td>\n",
       "      <td>17.668767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.454630</td>\n",
       "      <td>41.925095</td>\n",
       "      <td>50.260644</td>\n",
       "      <td>26.369539</td>\n",
       "      <td>35.025561</td>\n",
       "      <td>43.198352</td>\n",
       "      <td>24.053564</td>\n",
       "      <td>31.567219</td>\n",
       "      <td>20.762468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.335614</td>\n",
       "      <td>43.666095</td>\n",
       "      <td>52.150702</td>\n",
       "      <td>27.387898</td>\n",
       "      <td>36.886081</td>\n",
       "      <td>45.759563</td>\n",
       "      <td>25.664359</td>\n",
       "      <td>33.574865</td>\n",
       "      <td>21.793129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.987585</td>\n",
       "      <td>44.688246</td>\n",
       "      <td>55.918345</td>\n",
       "      <td>28.426238</td>\n",
       "      <td>38.184808</td>\n",
       "      <td>50.138779</td>\n",
       "      <td>26.860141</td>\n",
       "      <td>35.057363</td>\n",
       "      <td>22.693666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.663225</td>\n",
       "      <td>45.853918</td>\n",
       "      <td>57.775741</td>\n",
       "      <td>29.488925</td>\n",
       "      <td>39.558979</td>\n",
       "      <td>53.136050</td>\n",
       "      <td>28.032745</td>\n",
       "      <td>36.362951</td>\n",
       "      <td>23.422883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31.449055</td>\n",
       "      <td>47.024032</td>\n",
       "      <td>59.541179</td>\n",
       "      <td>30.178607</td>\n",
       "      <td>40.479254</td>\n",
       "      <td>55.903265</td>\n",
       "      <td>28.423267</td>\n",
       "      <td>37.050050</td>\n",
       "      <td>23.437725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  \\\n",
       "192                                                                \n",
       "1    24.312066   36.327453       39.784838  22.323798  29.868688   \n",
       "2    28.454630   41.925095       50.260644  26.369539  35.025561   \n",
       "3    29.335614   43.666095       52.150702  27.387898  36.886081   \n",
       "4    29.987585   44.688246       55.918345  28.426238  38.184808   \n",
       "5    30.663225   45.853918       57.775741  29.488925  39.558979   \n",
       "6    31.449055   47.024032       59.541179  30.178607  40.479254   \n",
       "\n",
       "     MAPE (%)_val   MAE_test  RMSE_test  MAPE (%)_test  \n",
       "192                                                     \n",
       "1       34.011554  20.545188  26.267399      17.668767  \n",
       "2       43.198352  24.053564  31.567219      20.762468  \n",
       "3       45.759563  25.664359  33.574865      21.793129  \n",
       "4       50.138779  26.860141  35.057363      22.693666  \n",
       "5       53.136050  28.032745  36.362951      23.422883  \n",
       "6       55.903265  28.423267  37.050050      23.437725  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216\n",
      "\n",
      "--- Run 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00389\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00375\n",
      "\n",
      "--- Run 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00381\n",
      "\n",
      "--- Run 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00391\n",
      "\n",
      "--- Run 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00371\n",
      "\n",
      "--- Run 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00396\n",
      "\n",
      "--- Run 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.00372\n",
      "\n",
      "--- Run 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00369\n",
      "\n",
      "--- Run 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00377\n",
      "\n",
      "--- Run 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00388\n",
      "\n",
      "--- Aggregated Mean of All Metrics Across 10 Runs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.644735</td>\n",
       "      <td>36.037667</td>\n",
       "      <td>36.281593</td>\n",
       "      <td>20.978987</td>\n",
       "      <td>28.063148</td>\n",
       "      <td>30.569236</td>\n",
       "      <td>19.120242</td>\n",
       "      <td>24.608769</td>\n",
       "      <td>15.834484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.778178</td>\n",
       "      <td>41.138512</td>\n",
       "      <td>41.360461</td>\n",
       "      <td>23.856575</td>\n",
       "      <td>32.061108</td>\n",
       "      <td>35.304229</td>\n",
       "      <td>21.987550</td>\n",
       "      <td>29.370845</td>\n",
       "      <td>18.359501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.186023</td>\n",
       "      <td>43.293678</td>\n",
       "      <td>45.331604</td>\n",
       "      <td>25.367448</td>\n",
       "      <td>34.133231</td>\n",
       "      <td>39.966786</td>\n",
       "      <td>24.497577</td>\n",
       "      <td>31.988001</td>\n",
       "      <td>20.369583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.096147</td>\n",
       "      <td>44.389018</td>\n",
       "      <td>49.382846</td>\n",
       "      <td>26.789306</td>\n",
       "      <td>35.816351</td>\n",
       "      <td>44.981589</td>\n",
       "      <td>25.700648</td>\n",
       "      <td>33.482998</td>\n",
       "      <td>21.300258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29.668883</td>\n",
       "      <td>45.611043</td>\n",
       "      <td>49.820894</td>\n",
       "      <td>27.694249</td>\n",
       "      <td>37.042650</td>\n",
       "      <td>46.393194</td>\n",
       "      <td>27.305273</td>\n",
       "      <td>35.296464</td>\n",
       "      <td>22.520933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30.842688</td>\n",
       "      <td>47.056758</td>\n",
       "      <td>53.358381</td>\n",
       "      <td>28.540367</td>\n",
       "      <td>38.120842</td>\n",
       "      <td>50.253590</td>\n",
       "      <td>27.580548</td>\n",
       "      <td>35.794116</td>\n",
       "      <td>22.723453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  \\\n",
       "216                                                                \n",
       "1    23.644735   36.037667       36.281593  20.978987  28.063148   \n",
       "2    26.778178   41.138512       41.360461  23.856575  32.061108   \n",
       "3    28.186023   43.293678       45.331604  25.367448  34.133231   \n",
       "4    29.096147   44.389018       49.382846  26.789306  35.816351   \n",
       "5    29.668883   45.611043       49.820894  27.694249  37.042650   \n",
       "6    30.842688   47.056758       53.358381  28.540367  38.120842   \n",
       "\n",
       "     MAPE (%)_val   MAE_test  RMSE_test  MAPE (%)_test  \n",
       "216                                                     \n",
       "1       30.569236  19.120242  24.608769      15.834484  \n",
       "2       35.304229  21.987550  29.370845      18.359501  \n",
       "3       39.966786  24.497577  31.988001      20.369583  \n",
       "4       44.981589  25.700648  33.482998      21.300258  \n",
       "5       46.393194  27.305273  35.296464      22.520933  \n",
       "6       50.253590  27.580548  35.794116      22.723453  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n",
      "\n",
      "--- Run 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00390\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00408\n",
      "\n",
      "--- Run 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00413\n",
      "\n",
      "--- Run 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00400\n",
      "\n",
      "--- Run 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00389\n",
      "\n",
      "--- Run 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00388\n",
      "\n",
      "--- Run 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.00386\n",
      "\n",
      "--- Run 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00388\n",
      "\n",
      "--- Run 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00422\n",
      "\n",
      "--- Run 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00391\n",
      "\n",
      "--- Aggregated Mean of All Metrics Across 10 Runs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.898936</td>\n",
       "      <td>36.538404</td>\n",
       "      <td>34.043272</td>\n",
       "      <td>21.623739</td>\n",
       "      <td>29.063107</td>\n",
       "      <td>29.241094</td>\n",
       "      <td>19.414999</td>\n",
       "      <td>25.175027</td>\n",
       "      <td>16.187328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.374099</td>\n",
       "      <td>41.591782</td>\n",
       "      <td>42.522704</td>\n",
       "      <td>24.631883</td>\n",
       "      <td>32.948835</td>\n",
       "      <td>36.052879</td>\n",
       "      <td>22.386285</td>\n",
       "      <td>29.644583</td>\n",
       "      <td>18.901498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.776273</td>\n",
       "      <td>43.783573</td>\n",
       "      <td>46.289869</td>\n",
       "      <td>26.133467</td>\n",
       "      <td>35.079243</td>\n",
       "      <td>40.716984</td>\n",
       "      <td>24.521734</td>\n",
       "      <td>31.937874</td>\n",
       "      <td>20.458348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.682480</td>\n",
       "      <td>44.924049</td>\n",
       "      <td>50.246351</td>\n",
       "      <td>27.536933</td>\n",
       "      <td>36.627988</td>\n",
       "      <td>46.383755</td>\n",
       "      <td>25.418196</td>\n",
       "      <td>32.978321</td>\n",
       "      <td>21.154970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.118094</td>\n",
       "      <td>45.976552</td>\n",
       "      <td>50.991586</td>\n",
       "      <td>28.165674</td>\n",
       "      <td>37.623462</td>\n",
       "      <td>47.901120</td>\n",
       "      <td>27.215746</td>\n",
       "      <td>34.903941</td>\n",
       "      <td>22.523248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30.979227</td>\n",
       "      <td>47.313389</td>\n",
       "      <td>53.017479</td>\n",
       "      <td>28.583342</td>\n",
       "      <td>38.475890</td>\n",
       "      <td>49.819812</td>\n",
       "      <td>27.803767</td>\n",
       "      <td>35.651846</td>\n",
       "      <td>23.053963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  \\\n",
       "240                                                                \n",
       "1    23.898936   36.538404       34.043272  21.623739  29.063107   \n",
       "2    27.374099   41.591782       42.522704  24.631883  32.948835   \n",
       "3    28.776273   43.783573       46.289869  26.133467  35.079243   \n",
       "4    29.682480   44.924049       50.246351  27.536933  36.627988   \n",
       "5    30.118094   45.976552       50.991586  28.165674  37.623462   \n",
       "6    30.979227   47.313389       53.017479  28.583342  38.475890   \n",
       "\n",
       "     MAPE (%)_val   MAE_test  RMSE_test  MAPE (%)_test  \n",
       "240                                                     \n",
       "1       29.241094  19.414999  25.175027      16.187328  \n",
       "2       36.052879  22.386285  29.644583      18.901498  \n",
       "3       40.716984  24.521734  31.937874      20.458348  \n",
       "4       46.383755  25.418196  32.978321      21.154970  \n",
       "5       47.901120  27.215746  34.903941      22.523248  \n",
       "6       49.819812  27.803767  35.651846      23.053963  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264\n",
      "\n",
      "--- Run 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00388\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00403\n",
      "\n",
      "--- Run 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00395\n",
      "\n",
      "--- Run 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.00414\n",
      "\n",
      "--- Run 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00444\n",
      "\n",
      "--- Run 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00431\n",
      "\n",
      "--- Run 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00417\n",
      "\n",
      "--- Run 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00426\n",
      "\n",
      "--- Run 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00407\n",
      "\n",
      "--- Run 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00422\n",
      "\n",
      "--- Aggregated Mean of All Metrics Across 10 Runs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.134236</td>\n",
       "      <td>36.655709</td>\n",
       "      <td>37.023117</td>\n",
       "      <td>22.207940</td>\n",
       "      <td>29.685193</td>\n",
       "      <td>32.287631</td>\n",
       "      <td>18.899466</td>\n",
       "      <td>24.285570</td>\n",
       "      <td>15.033838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.702861</td>\n",
       "      <td>42.095465</td>\n",
       "      <td>44.671771</td>\n",
       "      <td>25.400074</td>\n",
       "      <td>33.960309</td>\n",
       "      <td>39.158839</td>\n",
       "      <td>21.869854</td>\n",
       "      <td>29.004273</td>\n",
       "      <td>17.306815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.157933</td>\n",
       "      <td>44.308757</td>\n",
       "      <td>47.303460</td>\n",
       "      <td>26.836075</td>\n",
       "      <td>36.114230</td>\n",
       "      <td>42.533248</td>\n",
       "      <td>24.178521</td>\n",
       "      <td>31.472254</td>\n",
       "      <td>19.114002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.896708</td>\n",
       "      <td>45.491215</td>\n",
       "      <td>49.274768</td>\n",
       "      <td>27.679089</td>\n",
       "      <td>37.401952</td>\n",
       "      <td>45.040990</td>\n",
       "      <td>25.445246</td>\n",
       "      <td>33.134077</td>\n",
       "      <td>19.995358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.548114</td>\n",
       "      <td>46.644463</td>\n",
       "      <td>51.075142</td>\n",
       "      <td>28.407075</td>\n",
       "      <td>38.315512</td>\n",
       "      <td>47.616489</td>\n",
       "      <td>26.189247</td>\n",
       "      <td>34.129496</td>\n",
       "      <td>20.545205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31.359215</td>\n",
       "      <td>47.901019</td>\n",
       "      <td>54.901447</td>\n",
       "      <td>28.764158</td>\n",
       "      <td>38.851147</td>\n",
       "      <td>51.649213</td>\n",
       "      <td>26.310223</td>\n",
       "      <td>34.498603</td>\n",
       "      <td>20.472290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  \\\n",
       "264                                                                \n",
       "1    24.134236   36.655709       37.023117  22.207940  29.685193   \n",
       "2    27.702861   42.095465       44.671771  25.400074  33.960309   \n",
       "3    29.157933   44.308757       47.303460  26.836075  36.114230   \n",
       "4    29.896708   45.491215       49.274768  27.679089  37.401952   \n",
       "5    30.548114   46.644463       51.075142  28.407075  38.315512   \n",
       "6    31.359215   47.901019       54.901447  28.764158  38.851147   \n",
       "\n",
       "     MAPE (%)_val   MAE_test  RMSE_test  MAPE (%)_test  \n",
       "264                                                     \n",
       "1       32.287631  18.899466  24.285570      15.033838  \n",
       "2       39.158839  21.869854  29.004273      17.306815  \n",
       "3       42.533248  24.178521  31.472254      19.114002  \n",
       "4       45.040990  25.445246  33.134077      19.995358  \n",
       "5       47.616489  26.189247  34.129496      20.545205  \n",
       "6       51.649213  26.310223  34.498603      20.472290  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288\n",
      "\n",
      "--- Run 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00411\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.00394\n",
      "\n",
      "--- Run 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00483\n",
      "\n",
      "--- Run 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00412\n",
      "\n",
      "--- Run 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00398\n",
      "\n",
      "--- Run 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.01024\n",
      "\n",
      "--- Run 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00421\n",
      "\n",
      "--- Run 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00403\n",
      "\n",
      "--- Run 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: early stopping\n",
      "Restoring model weights from the end of the best epoch: 69.\n",
      "Validation loss: 0.00443\n",
      "\n",
      "--- Run 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00395\n",
      "\n",
      "--- Aggregated Mean of All Metrics Across 10 Runs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.215196</td>\n",
       "      <td>37.132905</td>\n",
       "      <td>41.579855</td>\n",
       "      <td>22.639205</td>\n",
       "      <td>29.929535</td>\n",
       "      <td>35.172626</td>\n",
       "      <td>19.245575</td>\n",
       "      <td>24.583013</td>\n",
       "      <td>15.203472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.380056</td>\n",
       "      <td>43.230382</td>\n",
       "      <td>50.258131</td>\n",
       "      <td>26.540902</td>\n",
       "      <td>35.068277</td>\n",
       "      <td>42.656671</td>\n",
       "      <td>22.928721</td>\n",
       "      <td>30.070596</td>\n",
       "      <td>17.835942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.169667</td>\n",
       "      <td>46.327128</td>\n",
       "      <td>48.751888</td>\n",
       "      <td>28.626292</td>\n",
       "      <td>38.435415</td>\n",
       "      <td>42.906464</td>\n",
       "      <td>27.266998</td>\n",
       "      <td>34.877115</td>\n",
       "      <td>20.990146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.432236</td>\n",
       "      <td>47.344346</td>\n",
       "      <td>58.242587</td>\n",
       "      <td>29.776330</td>\n",
       "      <td>39.551567</td>\n",
       "      <td>51.210622</td>\n",
       "      <td>27.507680</td>\n",
       "      <td>34.951989</td>\n",
       "      <td>21.505016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33.461147</td>\n",
       "      <td>49.025803</td>\n",
       "      <td>61.300958</td>\n",
       "      <td>31.036886</td>\n",
       "      <td>41.161772</td>\n",
       "      <td>53.857284</td>\n",
       "      <td>28.785910</td>\n",
       "      <td>36.505733</td>\n",
       "      <td>22.471565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>35.096586</td>\n",
       "      <td>50.662654</td>\n",
       "      <td>71.160751</td>\n",
       "      <td>32.031754</td>\n",
       "      <td>42.316915</td>\n",
       "      <td>61.731142</td>\n",
       "      <td>28.782684</td>\n",
       "      <td>36.565183</td>\n",
       "      <td>22.617835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  \\\n",
       "288                                                                \n",
       "1    25.215196   37.132905       41.579855  22.639205  29.929535   \n",
       "2    29.380056   43.230382       50.258131  26.540902  35.068277   \n",
       "3    31.169667   46.327128       48.751888  28.626292  38.435415   \n",
       "4    32.432236   47.344346       58.242587  29.776330  39.551567   \n",
       "5    33.461147   49.025803       61.300958  31.036886  41.161772   \n",
       "6    35.096586   50.662654       71.160751  32.031754  42.316915   \n",
       "\n",
       "     MAPE (%)_val   MAE_test  RMSE_test  MAPE (%)_test  \n",
       "288                                                     \n",
       "1       35.172626  19.245575  24.583013      15.203472  \n",
       "2       42.656671  22.928721  30.070596      17.835942  \n",
       "3       42.906464  27.266998  34.877115      20.990146  \n",
       "4       51.210622  27.507680  34.951989      21.505016  \n",
       "5       53.857284  28.785910  36.505733      22.471565  \n",
       "6       61.731142  28.782684  36.565183      22.617835  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312\n",
      "\n",
      "--- Run 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00417\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00396\n",
      "\n",
      "--- Run 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00403\n",
      "\n",
      "--- Run 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00385\n",
      "\n",
      "--- Run 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00385\n",
      "\n",
      "--- Run 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00395\n",
      "\n",
      "--- Run 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00370\n",
      "\n",
      "--- Run 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Validation loss: 0.00379\n",
      "\n",
      "--- Run 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00405\n",
      "\n",
      "--- Run 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00373\n",
      "\n",
      "--- Aggregated Mean of All Metrics Across 10 Runs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.832341</td>\n",
       "      <td>36.226354</td>\n",
       "      <td>35.646514</td>\n",
       "      <td>21.125101</td>\n",
       "      <td>28.229526</td>\n",
       "      <td>31.201789</td>\n",
       "      <td>18.528515</td>\n",
       "      <td>24.041364</td>\n",
       "      <td>14.415626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.161176</td>\n",
       "      <td>41.352509</td>\n",
       "      <td>42.527347</td>\n",
       "      <td>24.320739</td>\n",
       "      <td>32.699802</td>\n",
       "      <td>36.932030</td>\n",
       "      <td>21.337536</td>\n",
       "      <td>28.697092</td>\n",
       "      <td>16.513149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.737333</td>\n",
       "      <td>43.603629</td>\n",
       "      <td>46.613324</td>\n",
       "      <td>26.016786</td>\n",
       "      <td>35.227518</td>\n",
       "      <td>41.623784</td>\n",
       "      <td>23.811865</td>\n",
       "      <td>31.040757</td>\n",
       "      <td>18.554877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.373425</td>\n",
       "      <td>44.761568</td>\n",
       "      <td>48.234328</td>\n",
       "      <td>26.820542</td>\n",
       "      <td>36.437187</td>\n",
       "      <td>44.158921</td>\n",
       "      <td>24.686857</td>\n",
       "      <td>32.013889</td>\n",
       "      <td>19.114910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.016366</td>\n",
       "      <td>45.808675</td>\n",
       "      <td>51.461378</td>\n",
       "      <td>27.525441</td>\n",
       "      <td>37.318260</td>\n",
       "      <td>47.631889</td>\n",
       "      <td>25.459397</td>\n",
       "      <td>32.873002</td>\n",
       "      <td>19.745555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30.892987</td>\n",
       "      <td>47.040803</td>\n",
       "      <td>55.388173</td>\n",
       "      <td>27.977959</td>\n",
       "      <td>38.004578</td>\n",
       "      <td>51.598576</td>\n",
       "      <td>25.708700</td>\n",
       "      <td>33.278359</td>\n",
       "      <td>20.112652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  \\\n",
       "312                                                                \n",
       "1    23.832341   36.226354       35.646514  21.125101  28.229526   \n",
       "2    27.161176   41.352509       42.527347  24.320739  32.699802   \n",
       "3    28.737333   43.603629       46.613324  26.016786  35.227518   \n",
       "4    29.373425   44.761568       48.234328  26.820542  36.437187   \n",
       "5    30.016366   45.808675       51.461378  27.525441  37.318260   \n",
       "6    30.892987   47.040803       55.388173  27.977959  38.004578   \n",
       "\n",
       "     MAPE (%)_val   MAE_test  RMSE_test  MAPE (%)_test  \n",
       "312                                                     \n",
       "1       31.201789  18.528515  24.041364      14.415626  \n",
       "2       36.932030  21.337536  28.697092      16.513149  \n",
       "3       41.623784  23.811865  31.040757      18.554877  \n",
       "4       44.158921  24.686857  32.013889      19.114910  \n",
       "5       47.631889  25.459397  32.873002      19.745555  \n",
       "6       51.598576  25.708700  33.278359      20.112652  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336\n",
      "\n",
      "--- Run 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00368\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00369\n",
      "\n",
      "--- Run 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00383\n",
      "\n",
      "--- Run 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Validation loss: 0.00369\n",
      "\n",
      "--- Run 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Validation loss: 0.00354\n",
      "\n",
      "--- Run 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83: early stopping\n",
      "Restoring model weights from the end of the best epoch: 63.\n",
      "Validation loss: 0.00398\n",
      "\n",
      "--- Run 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00353\n",
      "\n",
      "--- Run 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00382\n",
      "\n",
      "--- Run 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00371\n",
      "\n",
      "--- Run 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00385\n",
      "\n",
      "--- Aggregated Mean of All Metrics Across 10 Runs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.621773</td>\n",
       "      <td>35.698941</td>\n",
       "      <td>34.951762</td>\n",
       "      <td>20.667164</td>\n",
       "      <td>27.628806</td>\n",
       "      <td>29.889462</td>\n",
       "      <td>18.629063</td>\n",
       "      <td>24.143526</td>\n",
       "      <td>14.584684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.582165</td>\n",
       "      <td>40.001252</td>\n",
       "      <td>43.208189</td>\n",
       "      <td>23.377477</td>\n",
       "      <td>31.588592</td>\n",
       "      <td>36.707587</td>\n",
       "      <td>21.003797</td>\n",
       "      <td>27.981111</td>\n",
       "      <td>16.502794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.227887</td>\n",
       "      <td>42.119653</td>\n",
       "      <td>48.274254</td>\n",
       "      <td>25.108645</td>\n",
       "      <td>34.028053</td>\n",
       "      <td>41.918300</td>\n",
       "      <td>24.007650</td>\n",
       "      <td>30.941638</td>\n",
       "      <td>18.986934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.848440</td>\n",
       "      <td>43.005659</td>\n",
       "      <td>51.200989</td>\n",
       "      <td>26.113690</td>\n",
       "      <td>35.448788</td>\n",
       "      <td>45.660878</td>\n",
       "      <td>25.602675</td>\n",
       "      <td>32.535440</td>\n",
       "      <td>20.368816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29.662849</td>\n",
       "      <td>43.963450</td>\n",
       "      <td>54.305966</td>\n",
       "      <td>27.158018</td>\n",
       "      <td>36.813228</td>\n",
       "      <td>48.904216</td>\n",
       "      <td>26.105835</td>\n",
       "      <td>33.069553</td>\n",
       "      <td>20.799830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30.642358</td>\n",
       "      <td>45.285756</td>\n",
       "      <td>58.677131</td>\n",
       "      <td>27.591886</td>\n",
       "      <td>37.561998</td>\n",
       "      <td>53.171757</td>\n",
       "      <td>25.555779</td>\n",
       "      <td>33.045016</td>\n",
       "      <td>20.276121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  \\\n",
       "336                                                                \n",
       "1    23.621773   35.698941       34.951762  20.667164  27.628806   \n",
       "2    26.582165   40.001252       43.208189  23.377477  31.588592   \n",
       "3    28.227887   42.119653       48.274254  25.108645  34.028053   \n",
       "4    28.848440   43.005659       51.200989  26.113690  35.448788   \n",
       "5    29.662849   43.963450       54.305966  27.158018  36.813228   \n",
       "6    30.642358   45.285756       58.677131  27.591886  37.561998   \n",
       "\n",
       "     MAPE (%)_val   MAE_test  RMSE_test  MAPE (%)_test  \n",
       "336                                                     \n",
       "1       29.889462  18.629063  24.143526      14.584684  \n",
       "2       36.707587  21.003797  27.981111      16.502794  \n",
       "3       41.918300  24.007650  30.941638      18.986934  \n",
       "4       45.660878  25.602675  32.535440      20.368816  \n",
       "5       48.904216  26.105835  33.069553      20.799830  \n",
       "6       53.171757  25.555779  33.045016      20.276121  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360\n",
      "\n",
      "--- Run 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00437\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00392\n",
      "\n",
      "--- Run 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00425\n",
      "\n",
      "--- Run 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.00416\n",
      "\n",
      "--- Run 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00396\n",
      "\n",
      "--- Run 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00379\n",
      "\n",
      "--- Run 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.01393\n",
      "\n",
      "--- Run 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82: early stopping\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "Validation loss: 0.00825\n",
      "\n",
      "--- Run 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00383\n",
      "\n",
      "--- Run 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00372\n",
      "\n",
      "--- Aggregated Mean of All Metrics Across 10 Runs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.799884</td>\n",
       "      <td>39.127496</td>\n",
       "      <td>49.868384</td>\n",
       "      <td>23.729301</td>\n",
       "      <td>31.046113</td>\n",
       "      <td>42.544297</td>\n",
       "      <td>20.203050</td>\n",
       "      <td>25.660022</td>\n",
       "      <td>16.461189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.817799</td>\n",
       "      <td>45.149527</td>\n",
       "      <td>54.307504</td>\n",
       "      <td>27.496802</td>\n",
       "      <td>36.495626</td>\n",
       "      <td>45.702660</td>\n",
       "      <td>24.147242</td>\n",
       "      <td>31.485309</td>\n",
       "      <td>19.146240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.525728</td>\n",
       "      <td>48.459473</td>\n",
       "      <td>68.632214</td>\n",
       "      <td>30.191436</td>\n",
       "      <td>39.847207</td>\n",
       "      <td>58.529779</td>\n",
       "      <td>27.638095</td>\n",
       "      <td>34.941612</td>\n",
       "      <td>23.190197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.540459</td>\n",
       "      <td>51.457485</td>\n",
       "      <td>59.016382</td>\n",
       "      <td>31.929285</td>\n",
       "      <td>42.449284</td>\n",
       "      <td>51.616980</td>\n",
       "      <td>31.852512</td>\n",
       "      <td>40.035165</td>\n",
       "      <td>24.328375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36.079103</td>\n",
       "      <td>51.520561</td>\n",
       "      <td>69.619586</td>\n",
       "      <td>32.572504</td>\n",
       "      <td>42.846037</td>\n",
       "      <td>60.638641</td>\n",
       "      <td>30.597661</td>\n",
       "      <td>38.492960</td>\n",
       "      <td>23.757149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>37.325468</td>\n",
       "      <td>53.753831</td>\n",
       "      <td>69.363133</td>\n",
       "      <td>33.404821</td>\n",
       "      <td>44.280979</td>\n",
       "      <td>61.077412</td>\n",
       "      <td>31.785268</td>\n",
       "      <td>40.290111</td>\n",
       "      <td>23.997427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  \\\n",
       "360                                                                \n",
       "1    26.799884   39.127496       49.868384  23.729301  31.046113   \n",
       "2    30.817799   45.149527       54.307504  27.496802  36.495626   \n",
       "3    33.525728   48.459473       68.632214  30.191436  39.847207   \n",
       "4    35.540459   51.457485       59.016382  31.929285  42.449284   \n",
       "5    36.079103   51.520561       69.619586  32.572504  42.846037   \n",
       "6    37.325468   53.753831       69.363133  33.404821  44.280979   \n",
       "\n",
       "     MAPE (%)_val   MAE_test  RMSE_test  MAPE (%)_test  \n",
       "360                                                     \n",
       "1       42.544297  20.203050  25.660022      16.461189  \n",
       "2       45.702660  24.147242  31.485309      19.146240  \n",
       "3       58.529779  27.638095  34.941612      23.190197  \n",
       "4       51.616980  31.852512  40.035165      24.328375  \n",
       "5       60.638641  30.597661  38.492960      23.757149  \n",
       "6       61.077412  31.785268  40.290111      23.997427  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n",
      "\n",
      "--- Run 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00377\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00364\n",
      "\n",
      "--- Run 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00405\n",
      "\n",
      "--- Run 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00394\n",
      "\n",
      "--- Run 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00374\n",
      "\n",
      "--- Run 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.00364\n",
      "\n",
      "--- Run 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00377\n",
      "\n",
      "--- Run 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00366\n",
      "\n",
      "--- Run 9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00394\n",
      "\n",
      "--- Run 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00376\n",
      "\n",
      "--- Aggregated Mean of All Metrics Across 10 Runs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>MAPE (%)_train</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.799162</td>\n",
       "      <td>35.689579</td>\n",
       "      <td>34.490973</td>\n",
       "      <td>20.728607</td>\n",
       "      <td>27.942606</td>\n",
       "      <td>29.836789</td>\n",
       "      <td>17.766302</td>\n",
       "      <td>22.579090</td>\n",
       "      <td>14.550479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.461130</td>\n",
       "      <td>40.620138</td>\n",
       "      <td>37.660362</td>\n",
       "      <td>22.911461</td>\n",
       "      <td>31.982322</td>\n",
       "      <td>30.528578</td>\n",
       "      <td>21.250889</td>\n",
       "      <td>28.191314</td>\n",
       "      <td>17.440946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.496000</td>\n",
       "      <td>42.805635</td>\n",
       "      <td>45.706083</td>\n",
       "      <td>24.641970</td>\n",
       "      <td>34.312622</td>\n",
       "      <td>37.127073</td>\n",
       "      <td>24.260091</td>\n",
       "      <td>31.270137</td>\n",
       "      <td>20.092817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.777956</td>\n",
       "      <td>43.722002</td>\n",
       "      <td>45.379580</td>\n",
       "      <td>25.356683</td>\n",
       "      <td>35.707557</td>\n",
       "      <td>37.796732</td>\n",
       "      <td>26.171241</td>\n",
       "      <td>33.489085</td>\n",
       "      <td>21.615495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29.520495</td>\n",
       "      <td>44.875203</td>\n",
       "      <td>49.189920</td>\n",
       "      <td>26.091006</td>\n",
       "      <td>36.881440</td>\n",
       "      <td>40.334039</td>\n",
       "      <td>27.372634</td>\n",
       "      <td>34.786807</td>\n",
       "      <td>22.629633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30.541791</td>\n",
       "      <td>46.255961</td>\n",
       "      <td>53.662735</td>\n",
       "      <td>26.630364</td>\n",
       "      <td>37.925881</td>\n",
       "      <td>43.678908</td>\n",
       "      <td>28.680369</td>\n",
       "      <td>36.330548</td>\n",
       "      <td>23.516314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAE_train  RMSE_train  MAPE (%)_train    MAE_val   RMSE_val  \\\n",
       "384                                                                \n",
       "1    23.799162   35.689579       34.490973  20.728607  27.942606   \n",
       "2    26.461130   40.620138       37.660362  22.911461  31.982322   \n",
       "3    28.496000   42.805635       45.706083  24.641970  34.312622   \n",
       "4    28.777956   43.722002       45.379580  25.356683  35.707557   \n",
       "5    29.520495   44.875203       49.189920  26.091006  36.881440   \n",
       "6    30.541791   46.255961       53.662735  26.630364  37.925881   \n",
       "\n",
       "     MAPE (%)_val   MAE_test  RMSE_test  MAPE (%)_test  \n",
       "384                                                     \n",
       "1       29.836789  17.766302  22.579090      14.550479  \n",
       "2       30.528578  21.250889  28.191314      17.440946  \n",
       "3       37.127073  24.260091  31.270137      20.092817  \n",
       "4       37.796732  26.171241  33.489085      21.615495  \n",
       "5       40.334039  27.372634  34.786807      22.629633  \n",
       "6       43.678908  28.680369  36.330548      23.516314  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408\n",
      "\n",
      "--- Run 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation loss: nan\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m y_pred_test, y_obs_test \u001b[38;5;241m=\u001b[39m make_prediction(model, X_test, y_test)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#calculate the evaluation metrics of each output step\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m df_train \u001b[38;5;241m=\u001b[39m \u001b[43mevaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_obs_train\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39madd_suffix(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_train\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     36\u001b[0m df_val \u001b[38;5;241m=\u001b[39m evaluation(y_pred_val, y_obs_val)\u001b[38;5;241m.\u001b[39madd_suffix(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_val\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     37\u001b[0m df_test \u001b[38;5;241m=\u001b[39m evaluation(y_pred_test, y_obs_test)\u001b[38;5;241m.\u001b[39madd_suffix(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_test\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[51], line 12\u001b[0m, in \u001b[0;36mevaluation\u001b[0;34m(y_pred_inverse, y_obs_inverse)\u001b[0m\n\u001b[1;32m      9\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m y_pred_inverse[:, i]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Mean Absolute Error (MAE)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m mae \u001b[38;5;241m=\u001b[39m \u001b[43mmean_absolute_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Mean Squared Error (MSE)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m mse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_true, y_pred)\n",
      "File \u001b[0;32m~/Yue/code/jupyter_env/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Yue/code/jupyter_env/lib/python3.12/site-packages/sklearn/metrics/_regression.py:216\u001b[0m, in \u001b[0;36mmean_absolute_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    153\u001b[0m     {\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    162\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m ):\n\u001b[1;32m    164\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Mean absolute error regression loss.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <mean_absolute_error>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;124;03m    np.float64(0.85...)\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    220\u001b[0m     output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage(np\u001b[38;5;241m.\u001b[39mabs(y_pred \u001b[38;5;241m-\u001b[39m y_true), weights\u001b[38;5;241m=\u001b[39msample_weight, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Yue/code/jupyter_env/lib/python3.12/site-packages/sklearn/metrics/_regression.py:113\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype, xp)\u001b[0m\n\u001b[1;32m    111\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m    112\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m--> 113\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    116\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mreshape(y_true, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/Yue/code/jupyter_env/lib/python3.12/site-packages/sklearn/utils/validation.py:1064\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1061\u001b[0m     )\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m-> 1064\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m   1073\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[0;32m~/Yue/code/jupyter_env/lib/python3.12/site-packages/sklearn/utils/validation.py:123\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Yue/code/jupyter_env/lib/python3.12/site-packages/sklearn/utils/validation.py:172\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    171\u001b[0m     )\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "mean_metrics_list=[]\n",
    "for length in best_hyperparameters.keys():\n",
    "    print(length)\n",
    "    \n",
    "    # Number of runs\n",
    "    n_runs = 10\n",
    "    \n",
    "    # get the best hyperparameter of each length\n",
    "    hyperparams = best_hyperparameters[length]\n",
    "    # Initialize lists to store mean metrics and all metrics from each run\n",
    "    mean_metrics_rows = []\n",
    "    df_all_metrics_list = []\n",
    "\n",
    "    for run in range(1, n_runs + 1):\n",
    "        print(f\"\\n--- Run {run} ---\")\n",
    "\n",
    "        # Optionally set a unique seed for each run to ensure variability\n",
    "        seed = run  \n",
    "        # Train the model\n",
    "        model, mse = train_model(hyperparams, data_dict, length, seed=seed)\n",
    "        \n",
    "        X_train = data_dict[length]['X_train']\n",
    "        y_train = data_dict[length]['y_train']\n",
    "        X_val = data_dict[length]['X_val']\n",
    "        y_val = data_dict[length]['y_val']\n",
    "        X_test = data_dict[length]['X_test']\n",
    "        y_test = data_dict[length]['y_test']\n",
    "\n",
    "        #get the true flow and predicted flow\n",
    "        y_pred_train, y_obs_train = make_prediction(model, X_train, y_train)\n",
    "        y_pred_val, y_obs_val = make_prediction(model, X_val, y_val)\n",
    "        y_pred_test, y_obs_test = make_prediction(model, X_test, y_test)\n",
    "\n",
    "        #calculate the evaluation metrics of each output step\n",
    "        df_train = evaluation(y_pred_train, y_obs_train).add_suffix('_train')\n",
    "        df_val = evaluation(y_pred_val, y_obs_val).add_suffix('_val')\n",
    "        df_test = evaluation(y_pred_test, y_obs_test).add_suffix('_test')\n",
    "\n",
    "        df_all_metrics = pd.concat([df_train, df_val, df_test], axis=1)\n",
    "        df_all_metrics.index.name = length\n",
    "        \n",
    "        # Append df_all_metrics to the list\n",
    "        df_all_metrics_list.append(df_all_metrics)\n",
    "\n",
    "        # Calculate mean for all output step\n",
    "        mean_metrics = df_val.mean()\n",
    "        mean_metrics_row = pd.DataFrame(mean_metrics).T\n",
    "        mean_metrics_row['MSE_val(loss)'] = mse\n",
    "        mean_metrics_row['input_len'] = length\n",
    "        mean_metrics_row = mean_metrics_row[['input_len','MSE_val(loss)', 'MAE_val', 'RMSE_val', 'MAPE (%)_val']]\n",
    "        \n",
    "        # Append to the list\n",
    "        mean_metrics_rows.append(mean_metrics_row)\n",
    "        \n",
    "    # Concatenate all df_all_metrics into a single DataFrame with a new level for runs\n",
    "    concatenated_all_metrics = pd.concat(df_all_metrics_list, keys=range(1, n_runs + 1), names=['Run', 'Time Step'])\n",
    "\n",
    "    # Calculate the mean across runs for each metric and time step\n",
    "    # This will group by 'Time Step' and calculate the mean of each metric across all runs\n",
    "    aggregated_all_metrics_mean = concatenated_all_metrics.groupby('Time Step').mean()\n",
    "    aggregated_all_metrics_mean.index.name = length\n",
    "\n",
    "    print(\"\\n--- Aggregated Mean of All Metrics Across 10 Runs ---\")\n",
    "    display(aggregated_all_metrics_mean)\n",
    "\n",
    "    # After all runs, create a DataFrame of mean metrics\n",
    "    mean_metrics_df = pd.concat(mean_metrics_rows, ignore_index=True)\n",
    "    # Calculate the mean of each metric across the 10 runs\n",
    "    final_mean_metrics = mean_metrics_df.mean()\n",
    "\n",
    "    # Create a DataFrame for the final mean metrics\n",
    "    final_mean_metrics_df = pd.DataFrame(final_mean_metrics).T\n",
    "    \n",
    "    mean_metrics_list.append(final_mean_metrics_df)\n",
    "\n",
    "mean_metrics_df = pd.concat(mean_metrics_list).reset_index(drop=True)\n",
    "print(\"\\n--- Final Mean Metrics Across 10 Runs ---\")\n",
    "mean_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Run 1 ---\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00423\n",
      "0.004234453663229942\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m seed \u001b[38;5;241m=\u001b[39m run  \n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m model, mse \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhyperparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(mse)\n",
      "Cell \u001b[0;32mIn[49], line 16\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(hyperparams, data_dict, length, seed)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Early Stopping Callback\u001b[39;00m\n\u001b[1;32m     14\u001b[0m early_stop \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)    \n\u001b[0;32m---> 16\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Set to 1 to see training progress\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Retrieve the best validation MSE from the history\u001b[39;00m\n\u001b[1;32m     26\u001b[0m best_mse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    322\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m~/Yue/code/jupyter_env/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Yue/code/jupyter_env/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Yue/code/jupyter_env/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Yue/code/jupyter_env/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Yue/code/jupyter_env/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Yue/code/jupyter_env/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/Yue/code/jupyter_env/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/Yue/code/jupyter_env/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1567\u001b[0m   )\n",
      "File \u001b[0;32m~/Yue/code/jupyter_env/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "length = 96   \n",
    "# Number of runs\n",
    "n_runs = 10\n",
    "\n",
    "# get the best hyperparameter of each length\n",
    "hyperparams = best_hyperparameters[length]\n",
    "# Initialize lists to store mean metrics and all metrics from each run\n",
    "mean_metrics_rows = []\n",
    "df_all_metrics_list = []\n",
    "\n",
    "for run in range(1, n_runs + 1):\n",
    "    print(f\"\\n--- Run {run} ---\")\n",
    "\n",
    "    # Optionally set a unique seed for each run to ensure variability\n",
    "    seed = run  \n",
    "    # Train the model\n",
    "    model, mse = train_model(hyperparams, data_dict, length, seed=seed)\n",
    "\n",
    "    print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to predict next 6 steps simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will use\n",
    "* the last 12 steps\n",
    "\n",
    "* previous one week (24 steps)\n",
    "\n",
    "* previous one month  (168 steps)\n",
    "\n",
    "*  to forecast current (0 step) and 5 steps ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1141040 into shape (168,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create input-output sequences with the provided function\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_train, y_train, X_train_df, y_train_df \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_multi_step_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_n_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mday_lag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweek_lag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_future_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m X_valid, y_valid, X_valid_df, y_valid_df \u001b[38;5;241m=\u001b[39m create_multi_step_sequence(valid_set, last_n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m7\u001b[39m, day_lag\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, week_lag\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, n_future_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)\n\u001b[0;32m      4\u001b[0m X_test, y_test, X_test_df, y_test_df \u001b[38;5;241m=\u001b[39m create_multi_step_sequence(test_set, last_n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m7\u001b[39m, day_lag\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, week_lag\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, n_future_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)\n",
      "Cell \u001b[1;32mIn[10], line 40\u001b[0m, in \u001b[0;36mcreate_multi_step_sequence\u001b[1;34m(data, last_n_steps, day_lag, week_lag, n_future_steps)\u001b[0m\n\u001b[0;32m     37\u001b[0m         y\u001b[38;5;241m.\u001b[39mappend(output_seq)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Convert to numpy arrays and reshape X to match CNN expected input (samples, timesteps, features)\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_n_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Add the 2 additional features (last_day_value, last_week_value)\u001b[39;00m\n\u001b[0;32m     41\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(y)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, n_future_steps)  \u001b[38;5;66;03m# Multiple output steps\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Convert the entire input and output into a pandas DataFrame with appropriate column names for multi-step prediction\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Define column names for the input DataFrame\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 1141040 into shape (168,1)"
     ]
    }
   ],
   "source": [
    "# Create input-output sequences with the provided function\n",
    "X_train, y_train, X_train_df, y_train_df = create_multi_step_sequence(train_set, last_n_steps=12, day_lag=24, week_lag=168, n_future_steps=6)\n",
    "X_valid, y_valid, X_valid_df, y_valid_df = create_multi_step_sequence(valid_set, last_n_steps=12, day_lag=24, week_lag=168, n_future_steps=6)\n",
    "X_test, y_test, X_test_df, y_test_df = create_multi_step_sequence(test_set, last_n_steps=12, day_lag=24, week_lag=168, n_future_steps=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model_multi_step(input_shape, n_outputs, units, dropout_rate, learning_rate):\n",
    "    model = keras.Sequential()\n",
    "    model.add(LSTM(units=units, activation='tanh', input_shape=input_shape))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(n_outputs))\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        loss='mse',  # Mean Squared Error loss for regression\n",
    "        optimizer=optimizer,\n",
    "        metrics=['mae']  # Mean Absolute Error as a metric\n",
    "    )\n",
    "    return model\n",
    "\n",
    "input_shape = (x_train_scaled.shape[1], x_train_scaled.shape[2])\n",
    "n_outputs = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCIZFe1MAx-X"
   },
   "source": [
    "## 6. Set Up Hyperparameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter options\n",
    "units_list = [50, 100, 200]\n",
    "dropout_rates = [0, 0.3, 0.5]\n",
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "batch_sizes = [32, 64, 128]\n",
    "\n",
    "# Create all possible combinations\n",
    "hyperparameter_combinations = list(product(units_list, dropout_rates, learning_rates, batch_sizes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ixRU8sQA8NW"
   },
   "source": [
    "## 7. Train the Model with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination 1/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.01, batch_size=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\program\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation MAE: 0.0602\n",
      "\n",
      "Combination 2/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.01, batch_size=64\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation MAE: 0.0600\n",
      "\n",
      "Combination 3/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.01, batch_size=128\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation MAE: 0.0600\n",
      "\n",
      "Combination 4/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0618\n",
      "\n",
      "Combination 5/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation MAE: 0.0634\n",
      "\n",
      "Combination 6/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0644\n",
      "\n",
      "Combination 7/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.0001, batch_size=32\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation MAE: 0.0685\n",
      "\n",
      "Combination 8/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0685\n",
      "\n",
      "Combination 9/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0700\n",
      "\n",
      "Combination 10/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.01, batch_size=32\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation MAE: 0.0610\n",
      "\n",
      "Combination 11/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.01, batch_size=64\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation MAE: 0.0604\n",
      "\n",
      "Combination 12/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.01, batch_size=128\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation MAE: 0.0611\n",
      "\n",
      "Combination 13/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0619\n",
      "\n",
      "Combination 14/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0640\n",
      "\n",
      "Combination 15/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0652\n",
      "\n",
      "Combination 16/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0688\n",
      "\n",
      "Combination 17/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0711\n",
      "\n",
      "Combination 18/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0740\n",
      "\n",
      "Combination 19/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.01, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation MAE: 0.0610\n",
      "\n",
      "Combination 20/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.01, batch_size=64\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation MAE: 0.0614\n",
      "\n",
      "Combination 21/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.01, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0603\n",
      "\n",
      "Combination 22/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation MAE: 0.0630\n",
      "\n",
      "Combination 23/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.001, batch_size=64\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation MAE: 0.0658\n",
      "\n",
      "Combination 24/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0657\n",
      "\n",
      "Combination 25/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0686\n",
      "\n",
      "Combination 26/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0720\n",
      "\n",
      "Combination 27/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0745\n",
      "\n",
      "Combination 28/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.01, batch_size=32\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation MAE: 0.0608\n",
      "\n",
      "Combination 29/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.01, batch_size=64\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation MAE: 0.0608\n",
      "\n",
      "Combination 30/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.01, batch_size=128\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation MAE: 0.0606\n",
      "\n",
      "Combination 31/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation MAE: 0.0603\n",
      "\n",
      "Combination 32/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0616\n",
      "\n",
      "Combination 33/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation MAE: 0.0633\n",
      "\n",
      "Combination 34/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0669\n",
      "\n",
      "Combination 35/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0679\n",
      "\n",
      "Combination 36/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0682\n",
      "\n",
      "Combination 37/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.01, batch_size=32\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation MAE: 0.0606\n",
      "\n",
      "Combination 38/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.01, batch_size=64\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation MAE: 0.0607\n",
      "\n",
      "Combination 39/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.01, batch_size=128\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation MAE: 0.0595\n",
      "\n",
      "Combination 40/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation MAE: 0.0610\n",
      "\n",
      "Combination 41/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0618\n",
      "\n",
      "Combination 42/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0643\n",
      "\n",
      "Combination 43/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation MAE: 0.0675\n",
      "\n",
      "Combination 44/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation MAE: 0.0687\n",
      "\n",
      "Combination 45/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.0001, batch_size=128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0708\n",
      "\n",
      "Combination 46/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.01, batch_size=32\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation MAE: 0.0605\n",
      "\n",
      "Combination 47/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.01, batch_size=64\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation MAE: 0.0606\n",
      "\n",
      "Combination 48/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.01, batch_size=128\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation MAE: 0.0608\n",
      "\n",
      "Combination 49/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0616\n",
      "\n",
      "Combination 50/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0632\n",
      "\n",
      "Combination 51/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.001, batch_size=128\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation MAE: 0.0654\n",
      "\n",
      "Combination 52/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0672\n",
      "\n",
      "Combination 53/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0690\n",
      "\n",
      "Combination 54/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0712\n",
      "\n",
      "Combination 55/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.01, batch_size=32\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation MAE: 0.0600\n",
      "\n",
      "Combination 56/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.01, batch_size=64\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation MAE: 0.0604\n",
      "\n",
      "Combination 57/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.01, batch_size=128\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation MAE: 0.0605\n",
      "\n",
      "Combination 58/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.001, batch_size=32\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation MAE: 0.0605\n",
      "\n",
      "Combination 59/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0601\n",
      "\n",
      "Combination 60/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0618\n",
      "\n",
      "Combination 61/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0658\n",
      "\n",
      "Combination 62/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0672\n",
      "\n",
      "Combination 63/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.0001, batch_size=128\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation MAE: 0.0688\n",
      "\n",
      "Combination 64/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.01, batch_size=32\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation MAE: 0.0612\n",
      "\n",
      "Combination 65/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.01, batch_size=64\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation MAE: 0.0612\n",
      "\n",
      "Combination 66/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.01, batch_size=128\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation MAE: 0.0607\n",
      "\n",
      "Combination 67/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0603\n",
      "\n",
      "Combination 68/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0607\n",
      "\n",
      "Combination 69/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation MAE: 0.0631\n",
      "\n",
      "Combination 70/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0659\n",
      "\n",
      "Combination 71/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0682\n",
      "\n",
      "Combination 72/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0688\n",
      "\n",
      "Combination 73/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.01, batch_size=32\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation MAE: 0.0596\n",
      "\n",
      "Combination 74/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.01, batch_size=64\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation MAE: 0.0595\n",
      "\n",
      "Combination 75/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.01, batch_size=128\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation MAE: 0.0605\n",
      "\n",
      "Combination 76/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0607\n",
      "\n",
      "Combination 77/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0612\n",
      "\n",
      "Combination 78/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0635\n",
      "\n",
      "Combination 79/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0661\n",
      "\n",
      "Combination 80/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0679\n",
      "\n",
      "Combination 81/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0689\n",
      "\n",
      "Best Hyperparameters:\n",
      "units: 100\n",
      "dropout_rate: 0.3\n",
      "learning_rate: 0.01\n",
      "batch_size: 128\n",
      "Best Validation MAE: 0.0595\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables to store the best model and hyperparameters\n",
    "best_val_mae = np.inf\n",
    "best_hyperparams = None\n",
    "best_model = None\n",
    "\n",
    "for idx, (units, dropout_rate, learning_rate, batch_size) in enumerate(hyperparameter_combinations):\n",
    "    print(f\"\\nCombination {idx+1}/{len(hyperparameter_combinations)}\")\n",
    "    print(f\"Training with units={units}, dropout_rate={dropout_rate}, learning_rate={learning_rate}, batch_size={batch_size}\")\n",
    "\n",
    "    # Create the LSTM model with the current hyperparameters\n",
    "    model = create_lstm_model_multi_step(\n",
    "        input_shape=input_shape,\n",
    "        n_outputs=n_outputs,\n",
    "        units=units,\n",
    "        dropout_rate=dropout_rate,\n",
    "        learning_rate=learning_rate\n",
    "    )\n",
    "\n",
    "    # Initialize EarlyStopping\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_mae',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        x_train_scaled, y_train_scaled,\n",
    "        epochs=50,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_val_scaled, y_val_scaled),\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Get the best validation MAE from this training run\n",
    "    val_mae = min(history.history['val_mae'])\n",
    "    print(f\"Validation MAE: {val_mae:.4f}\")\n",
    "\n",
    "    # Update best model if current one is better\n",
    "    if val_mae < best_val_mae:\n",
    "        best_val_mae = val_mae\n",
    "        best_model = model\n",
    "        best_hyperparams = {\n",
    "            'units': units,\n",
    "            'dropout_rate': dropout_rate,\n",
    "            'learning_rate': learning_rate,\n",
    "            'batch_size': batch_size\n",
    "        }\n",
    "\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "for param, value in best_hyperparams.items():\n",
    "    print(f\"{param}: {value}\")\n",
    "print(f\"Best Validation MAE: {best_val_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "13:33"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Hyperparameters for full time:\n",
    "units: 200\n",
    "dropout_rate: 0.5\n",
    "learning_rate: 0.01\n",
    "batch_size: 32\n",
    "Best Validation MAE: 0.0503\n",
    "\n",
    "Best Hyperparameters for after covid:\n",
    "units: 100\n",
    "dropout_rate: 0.3\n",
    "learning_rate: 0.01\n",
    "batch_size: 128\n",
    "Best Validation MAE: 0.0595"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred_scaled = best_model.predict(x_test_scaled)\n",
    "\n",
    "# Reshape for inverse scaling\n",
    "y_pred_reshaped = y_pred_scaled.reshape(-1, 1)\n",
    "y_test_reshaped = y_test_scaled.reshape(-1, 1)\n",
    "\n",
    "# Inverse transform\n",
    "y_pred_inverse = y_scaler.inverse_transform(y_pred_reshaped).reshape(n_test_samples, n_outputs)\n",
    "y_test_inverse = y_scaler.inverse_transform(y_test_reshaped).reshape(n_test_samples, n_outputs)\n",
    "\n",
    "y_test_flat = y_test_inverse.flatten()\n",
    "y_pred_flat = y_pred_inverse.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9SREwnRqxMN1"
   },
   "source": [
    "## 9. Evaluating the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time Step 1 Evaluation Metrics:\n",
      "RMSE: 28.4454\n",
      "MAE: 20.8450\n",
      "MAPE: 19.44%\n",
      "\n",
      "Time Step 2 Evaluation Metrics:\n",
      "RMSE: 36.2563\n",
      "MAE: 26.7673\n",
      "MAPE: 25.02%\n",
      "\n",
      "Time Step 3 Evaluation Metrics:\n",
      "RMSE: 43.7203\n",
      "MAE: 33.1341\n",
      "MAPE: 29.97%\n",
      "\n",
      "Time Step 4 Evaluation Metrics:\n",
      "RMSE: 49.3573\n",
      "MAE: 38.0972\n",
      "MAPE: 35.19%\n",
      "\n",
      "Time Step 5 Evaluation Metrics:\n",
      "RMSE: 53.2812\n",
      "MAE: 41.5888\n",
      "MAPE: 39.42%\n",
      "\n",
      "Time Step 6 Evaluation Metrics:\n",
      "RMSE: 53.3926\n",
      "MAE: 42.0135\n",
      "MAPE: 44.19%\n"
     ]
    }
   ],
   "source": [
    "# Compute Metrics for Each Time Step\n",
    "\n",
    "for i in range(n_outputs):\n",
    "    y_true = y_test_inverse[:, i]\n",
    "    y_pred = y_pred_inverse[:, i]\n",
    "\n",
    "    # Mean Absolute Error (MAE)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "    # Mean Squared Error (MSE)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "    # Root Mean Squared Error (RMSE)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # Mean Absolute Percentage Error (MAPE)\n",
    "    # Avoid division by zero by adding a small epsilon to y_test_flat if necessary\n",
    "    epsilon = 1e-10\n",
    "    y_true_safe = np.where(y_true == 0, epsilon, y_true)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true_safe)) * 100\n",
    "\n",
    "    print(f\"\\nTime Step {i+1} Evaluation Metrics:\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"MAPE: {mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyYn2XL2GUxw"
   },
   "source": [
    "# Code to predict next 6 steps step-by-step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vavf9D4-lc6E"
   },
   "source": [
    "#### We will use\n",
    "* the last 12 steps\n",
    "\n",
    "* previous one week (24 steps)\n",
    "\n",
    "* previous one month  (168 steps)\n",
    "\n",
    "*  to forecast current (0 step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OfV8VwesmXS3"
   },
   "source": [
    "## 4. Create input and output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "PJaM65dTlc6E"
   },
   "outputs": [],
   "source": [
    "# Create input-output sequences with the provided function\n",
    "X_train, y_train, X_train_df, y_train_df = create_multi_step_sequence(train_set, last_n_steps=12, day_lag=24, week_lag=168, n_future_steps=1)\n",
    "X_valid, y_valid, X_valid_df, y_valid_df = create_multi_step_sequence(valid_set, last_n_steps=12, day_lag=24, week_lag=168, n_future_steps=1)\n",
    "X_test, y_test, X_test_df, y_test_df = create_multi_step_sequence(test_set, last_n_steps=12, day_lag=24, week_lag=168, n_future_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ipA2bPAcm2L1",
    "outputId": "687db2e3-3f26-4cc3-c15b-0d8066617ff8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19570, 14, 1), (6907, 14, 1), (5623, 14, 1))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0GNpslqvlx5_"
   },
   "source": [
    "## 5. Normalise the data after split (step-by-step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_Co01Aflx6B"
   },
   "source": [
    "Normalise X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Z7YuPxvRlx6C"
   },
   "outputs": [],
   "source": [
    "# Separate scalers for inputs and outputs\n",
    "x_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "y_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Reshape x_train to 2D for scaling\n",
    "n_samples, n_timesteps, n_features = X_train.shape\n",
    "x_train_reshaped = X_train.reshape(-1, n_features)  # Shape: (n_samples * n_timesteps, n_features)\n",
    "# Fit the scaler on the training data\n",
    "x_scaler.fit(x_train_reshaped)\n",
    "# Transform the training data\n",
    "x_train_scaled = x_scaler.transform(x_train_reshaped)\n",
    "# Reshape back to original shape\n",
    "x_train_scaled = x_train_scaled.reshape(n_samples, n_timesteps, n_features)\n",
    "\n",
    "# x_val\n",
    "n_val_samples = X_valid.shape[0]\n",
    "x_val_reshaped = X_valid.reshape(-1, n_features)\n",
    "x_val_scaled = x_scaler.transform(x_val_reshaped)\n",
    "x_val_scaled = x_val_scaled.reshape(n_val_samples, n_timesteps, n_features)\n",
    "\n",
    "# x_test\n",
    "n_test_samples = X_test.shape[0]\n",
    "x_test_reshaped = X_test.reshape(-1, n_features)\n",
    "x_test_scaled = x_scaler.transform(x_test_reshaped)\n",
    "x_test_scaled = x_test_scaled.reshape(n_test_samples, n_timesteps, n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rw7rcIWPlx6D"
   },
   "source": [
    "Normalise y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "azSWFgFmlx6D"
   },
   "outputs": [],
   "source": [
    "# Reshape y_train to 2D for scaling\n",
    "y_train_reshaped = y_train.reshape(-1, 1)  # Shape: (n_samples * n_outputs, 1)\n",
    "# Fit the scaler on the training data\n",
    "y_scaler.fit(y_train_reshaped)\n",
    "# Transform the training data\n",
    "y_train_scaled = y_scaler.transform(y_train_reshaped)\n",
    "# Reshape back to original shape\n",
    "y_train_scaled = y_train_scaled.reshape(n_samples, y_train.shape[1])\n",
    "\n",
    "# y_val\n",
    "y_val_reshaped = y_valid.reshape(-1, 1)\n",
    "y_val_scaled = y_scaler.transform(y_val_reshaped)\n",
    "y_val_scaled = y_val_scaled.reshape(n_val_samples, y_valid.shape[1])\n",
    "\n",
    "# y_test\n",
    "y_test_reshaped = y_test.reshape(-1, 1)\n",
    "y_test_scaled = y_scaler.transform(y_test_reshaped)\n",
    "y_test_scaled = y_test_scaled.reshape(n_test_samples, y_test.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJ7sNErrpc9O"
   },
   "source": [
    "## 6. Build LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "eE7DAUCIoVSt"
   },
   "outputs": [],
   "source": [
    "def create_lstm_model(input_shape, units, dropout_rate, learning_rate):\n",
    "    model = keras.Sequential()\n",
    "    model.add(LSTM(units=units, activation='tanh', input_shape=input_shape))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1)) # Output layer for one-step prediction\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        loss='mse',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "input_shape = (x_train_scaled.shape[1], x_train_scaled.shape[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYD8kk0NpzNp"
   },
   "source": [
    "## 7. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u4zCXOAo9tN"
   },
   "outputs": [],
   "source": [
    "# Hyperparameter options\n",
    "units_list = [50, 100, 200]\n",
    "dropout_rates = [0, 0.3, 0.5]\n",
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "batch_sizes = [32, 64, 128]\n",
    "\n",
    "# Create all possible combinations\n",
    "hyperparameter_combinations = list(product(units_list, dropout_rates, learning_rates, batch_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "5d-_-jwBp45_",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "e551e47c-fc12-4b0c-d237-39b9eb0d4f7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination 1/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.01, batch_size=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\program\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation MAE: 0.0452\n",
      "\n",
      "Combination 2/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.01, batch_size=64\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation MAE: 0.0452\n",
      "\n",
      "Combination 3/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.01, batch_size=128\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation MAE: 0.0466\n",
      "\n",
      "Combination 4/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0450\n",
      "\n",
      "Combination 5/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0463\n",
      "\n",
      "Combination 6/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0492\n",
      "\n",
      "Combination 7/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0496\n",
      "\n",
      "Combination 8/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0506\n",
      "\n",
      "Combination 9/81\n",
      "Training with units=50, dropout_rate=0, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0512\n",
      "\n",
      "Combination 10/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.01, batch_size=32\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation MAE: 0.0464\n",
      "\n",
      "Combination 11/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.01, batch_size=64\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation MAE: 0.0467\n",
      "\n",
      "Combination 12/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.01, batch_size=128\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation MAE: 0.0457\n",
      "\n",
      "Combination 13/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0466\n",
      "\n",
      "Combination 14/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.001, batch_size=64\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation MAE: 0.0498\n",
      "\n",
      "Combination 15/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0493\n",
      "\n",
      "Combination 16/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0508\n",
      "\n",
      "Combination 17/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0516\n",
      "\n",
      "Combination 18/81\n",
      "Training with units=50, dropout_rate=0.3, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0517\n",
      "\n",
      "Combination 19/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.01, batch_size=32\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation MAE: 0.0459\n",
      "\n",
      "Combination 20/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.01, batch_size=64\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation MAE: 0.0461\n",
      "\n",
      "Combination 21/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.01, batch_size=128\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation MAE: 0.0463\n",
      "\n",
      "Combination 22/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0471\n",
      "\n",
      "Combination 23/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0489\n",
      "\n",
      "Combination 24/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0501\n",
      "\n",
      "Combination 25/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0510\n",
      "\n",
      "Combination 26/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation MAE: 0.0514\n",
      "\n",
      "Combination 27/81\n",
      "Training with units=50, dropout_rate=0.5, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0522\n",
      "\n",
      "Combination 28/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.01, batch_size=32\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation MAE: 0.0463\n",
      "\n",
      "Combination 29/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.01, batch_size=64\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation MAE: 0.0461\n",
      "\n",
      "Combination 30/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.01, batch_size=128\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation MAE: 0.0453\n",
      "\n",
      "Combination 31/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation MAE: 0.0450\n",
      "\n",
      "Combination 32/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation MAE: 0.0458\n",
      "\n",
      "Combination 33/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.001, batch_size=128\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation MAE: 0.0496\n",
      "\n",
      "Combination 34/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0494\n",
      "\n",
      "Combination 35/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0502\n",
      "\n",
      "Combination 36/81\n",
      "Training with units=100, dropout_rate=0, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation MAE: 0.0512\n",
      "\n",
      "Combination 37/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.01, batch_size=32\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation MAE: 0.0463\n",
      "\n",
      "Combination 38/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.01, batch_size=64\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation MAE: 0.0459\n",
      "\n",
      "Combination 39/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.01, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0457\n",
      "\n",
      "Combination 40/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0456\n",
      "\n",
      "Combination 41/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0469\n",
      "\n",
      "Combination 42/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation MAE: 0.0494\n",
      "\n",
      "Combination 43/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.0001, batch_size=32\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation MAE: 0.0502\n",
      "\n",
      "Combination 44/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0509\n",
      "\n",
      "Combination 45/81\n",
      "Training with units=100, dropout_rate=0.3, learning_rate=0.0001, batch_size=128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation MAE: 0.0513\n",
      "\n",
      "Combination 46/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.01, batch_size=32\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation MAE: 0.0466\n",
      "\n",
      "Combination 47/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.01, batch_size=64\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation MAE: 0.0460\n",
      "\n",
      "Combination 48/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.01, batch_size=128\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation MAE: 0.0458\n",
      "\n",
      "Combination 49/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0463\n",
      "\n",
      "Combination 50/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.001, batch_size=64\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation MAE: 0.0496\n",
      "\n",
      "Combination 51/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation MAE: 0.0496\n",
      "\n",
      "Combination 52/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0505\n",
      "\n",
      "Combination 53/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0511\n",
      "\n",
      "Combination 54/81\n",
      "Training with units=100, dropout_rate=0.5, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0514\n",
      "\n",
      "Combination 55/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.01, batch_size=32\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation MAE: 0.0464\n",
      "\n",
      "Combination 56/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.01, batch_size=64\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation MAE: 0.0452\n",
      "\n",
      "Combination 57/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.01, batch_size=128\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation MAE: 0.0455\n",
      "\n",
      "Combination 58/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0452\n",
      "\n",
      "Combination 59/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation MAE: 0.0459\n",
      "\n",
      "Combination 60/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation MAE: 0.0470\n",
      "\n",
      "Combination 61/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0492\n",
      "\n",
      "Combination 62/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0497\n",
      "\n",
      "Combination 63/81\n",
      "Training with units=200, dropout_rate=0, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0503\n",
      "\n",
      "Combination 64/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.01, batch_size=32\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation MAE: 0.0460\n",
      "\n",
      "Combination 65/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.01, batch_size=64\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation MAE: 0.0461\n",
      "\n",
      "Combination 66/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.01, batch_size=128\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation MAE: 0.0486\n",
      "\n",
      "Combination 67/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation MAE: 0.0460\n",
      "\n",
      "Combination 68/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0460\n",
      "\n",
      "Combination 69/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0471\n",
      "\n",
      "Combination 70/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0495\n",
      "\n",
      "Combination 71/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0499\n",
      "\n",
      "Combination 72/81\n",
      "Training with units=200, dropout_rate=0.3, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0504\n",
      "\n",
      "Combination 73/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.01, batch_size=32\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation MAE: 0.0455\n",
      "\n",
      "Combination 74/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.01, batch_size=64\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation MAE: 0.0466\n",
      "\n",
      "Combination 75/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.01, batch_size=128\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation MAE: 0.0465\n",
      "\n",
      "Combination 76/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.001, batch_size=32\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation MAE: 0.0467\n",
      "\n",
      "Combination 77/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.001, batch_size=64\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation MAE: 0.0478\n",
      "\n",
      "Combination 78/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation MAE: 0.0477\n",
      "\n",
      "Combination 79/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.0001, batch_size=32\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0496\n",
      "\n",
      "Combination 80/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.0001, batch_size=64\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0502\n",
      "\n",
      "Combination 81/81\n",
      "Training with units=200, dropout_rate=0.5, learning_rate=0.0001, batch_size=128\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation MAE: 0.0508\n",
      "\n",
      "Best Hyperparameters:\n",
      "units: 100\n",
      "dropout_rate: 0\n",
      "learning_rate: 0.001\n",
      "batch_size: 32\n",
      "Best Validation MAE: 0.0450\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables to store the best model and hyperparameters\n",
    "best_val_mae = np.inf\n",
    "best_hyperparams = None\n",
    "best_model = None\n",
    "\n",
    "for idx, (units, dropout_rate, learning_rate, batch_size) in enumerate(hyperparameter_combinations):\n",
    "    print(f\"\\nCombination {idx+1}/{len(hyperparameter_combinations)}\")\n",
    "    print(f\"Training with units={units}, dropout_rate={dropout_rate}, learning_rate={learning_rate}, batch_size={batch_size}\")\n",
    "\n",
    "    # Create the LSTM model with the current hyperparameters\n",
    "    model = create_lstm_model(\n",
    "        input_shape=input_shape,\n",
    "        units=units,\n",
    "        dropout_rate=dropout_rate,\n",
    "        learning_rate=learning_rate\n",
    "    )\n",
    "\n",
    "    # Initialize EarlyStopping\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_mae',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        x_train_scaled, y_train_scaled,\n",
    "        epochs=50,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_val_scaled, y_val_scaled),\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Get the best validation MAE from this training run\n",
    "    val_mae = min(history.history['val_mae'])\n",
    "    print(f\"Validation MAE: {val_mae:.4f}\")\n",
    "\n",
    "    # Update best model if current one is better\n",
    "    if val_mae < best_val_mae:\n",
    "        best_val_mae = val_mae\n",
    "        best_model = model\n",
    "        best_hyperparams = {\n",
    "            'units': units,\n",
    "            'dropout_rate': dropout_rate,\n",
    "            'learning_rate': learning_rate,\n",
    "            'batch_size': batch_size\n",
    "        }\n",
    "\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "for param, value in best_hyperparams.items():\n",
    "    print(f\"{param}: {value}\")\n",
    "print(f\"Best Validation MAE: {best_val_mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Hyperparameters full time:\n",
    "units: 50\n",
    "dropout_rate: 0\n",
    "learning_rate: 0.01\n",
    "batch_size: 128\n",
    "Best Validation MAE: 0.0388\n",
    "\n",
    "Best Hyperparameters after covid:\n",
    "units: 100\n",
    "dropout_rate: 0\n",
    "learning_rate: 0.001\n",
    "batch_size: 32\n",
    "Best Validation MAE: 0.0450"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recreate the model¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_lstm_model(input_shape, units, dropout_rate, learning_rate):\n",
    "    model = keras.Sequential()\n",
    "    model.add(LSTM(units=units, activation='tanh', input_shape=input_shape))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1)) # Output layer for one-step prediction\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        loss='mse',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (x_train_scaled.shape[1], x_train_scaled.shape[2])\n",
    "units=50\n",
    "dropout_rate=0\n",
    "learning_rate=0.01\n",
    "batch_size=128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrain the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize EarlyStopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_mae',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0044 - mae: 0.0474 - val_loss: 0.0039 - val_mae: 0.0405\n",
      "Epoch 2/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0043 - mae: 0.0465 - val_loss: 0.0039 - val_mae: 0.0406\n",
      "Epoch 3/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0043 - mae: 0.0467 - val_loss: 0.0040 - val_mae: 0.0432\n",
      "Epoch 4/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0044 - mae: 0.0472 - val_loss: 0.0039 - val_mae: 0.0401\n",
      "Epoch 5/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0043 - mae: 0.0469 - val_loss: 0.0040 - val_mae: 0.0430\n",
      "Epoch 6/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0044 - mae: 0.0473 - val_loss: 0.0039 - val_mae: 0.0399\n",
      "Epoch 7/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0043 - mae: 0.0464 - val_loss: 0.0039 - val_mae: 0.0406\n",
      "Epoch 8/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0045 - mae: 0.0475 - val_loss: 0.0039 - val_mae: 0.0416\n",
      "Epoch 9/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0043 - mae: 0.0464 - val_loss: 0.0039 - val_mae: 0.0411\n",
      "Epoch 10/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - loss: 0.0044 - mae: 0.0468 - val_loss: 0.0039 - val_mae: 0.0406\n",
      "Epoch 11/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0043 - mae: 0.0463 - val_loss: 0.0039 - val_mae: 0.0404\n",
      "Epoch 12/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0042 - mae: 0.0459 - val_loss: 0.0041 - val_mae: 0.0421\n",
      "Epoch 13/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0043 - mae: 0.0464 - val_loss: 0.0039 - val_mae: 0.0400\n",
      "Epoch 14/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0041 - mae: 0.0459 - val_loss: 0.0039 - val_mae: 0.0394\n",
      "Epoch 15/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0043 - mae: 0.0466 - val_loss: 0.0039 - val_mae: 0.0411\n",
      "Epoch 16/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0042 - mae: 0.0460 - val_loss: 0.0039 - val_mae: 0.0401\n",
      "Epoch 17/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0042 - mae: 0.0459 - val_loss: 0.0039 - val_mae: 0.0399\n",
      "Epoch 18/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0042 - mae: 0.0462 - val_loss: 0.0040 - val_mae: 0.0411\n",
      "Epoch 19/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.0041 - mae: 0.0456 - val_loss: 0.0039 - val_mae: 0.0394\n",
      "Epoch 20/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0040 - mae: 0.0454 - val_loss: 0.0039 - val_mae: 0.0405\n",
      "Epoch 21/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0044 - mae: 0.0467 - val_loss: 0.0040 - val_mae: 0.0409\n",
      "Epoch 22/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.0042 - mae: 0.0461 - val_loss: 0.0041 - val_mae: 0.0421\n",
      "Epoch 23/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0042 - mae: 0.0464 - val_loss: 0.0040 - val_mae: 0.0409\n",
      "Epoch 24/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0042 - mae: 0.0462 - val_loss: 0.0040 - val_mae: 0.0396\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = best_model.fit(\n",
    "    x_train_scaled, y_train_scaled,\n",
    "    epochs=50,  # You can adjust this as needed\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(x_val_scaled, y_val_scaled),\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1  # Set to 1 to see detailed training output\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27LXIyi-w0th"
   },
   "source": [
    "## 8. Recursive Forecasting with LSTM (step-by-step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "O5eKQOi8dLQ-"
   },
   "outputs": [],
   "source": [
    "def recursive_forecast(model, x_test_scaled, start_index, n_steps, x_scaler, y_scaler):\n",
    "    \"\"\"\n",
    "    Perform recursive forecasting using the trained model.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained model\n",
    "    - x_test_scaled: The scaled test input data (shape: n_samples, n_timesteps, n_features)\n",
    "    - start_index: The starting index in the test data\n",
    "    - n_steps: Number of future steps to predict\n",
    "    - x_scaler: Scaler used for input features\n",
    "    - y_scaler: Scaler used for target variable\n",
    "\n",
    "    Returns:\n",
    "    - predictions: List of predicted values (in original scale)\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    scaled_predictions = []\n",
    "    current_input = x_test_scaled[start_index].copy()  # Shape: (n_timesteps, n_features)\n",
    "\n",
    "    for step in range(n_steps):\n",
    "        # Reshape to (1, n_timesteps, n_features) for prediction\n",
    "        input_seq = current_input.reshape((1, current_input.shape[0], current_input.shape[1]))\n",
    "\n",
    "        # Predict the next time step (scaled)\n",
    "        yhat_scaled = model.predict(input_seq, verbose=0)  # Shape: (1, 1)\n",
    "\n",
    "        # Inverse transform the prediction to original scale\n",
    "        yhat = y_scaler.inverse_transform(yhat_scaled)[0, 0]\n",
    "        \n",
    "        # Transform the prediction back to input feature scale for lag features\n",
    "        yhat_for_input = x_scaler.transform(yhat.reshape(-1, 1))[0, 0]\n",
    "\n",
    "        # Append predictions\n",
    "        predictions.append(yhat)\n",
    "        scaled_predictions.append(yhat_for_input)\n",
    "\n",
    "        # Move to the next time step in x_test_scaled\n",
    "        next_index = start_index + step + 1\n",
    "        if next_index < len(x_test_scaled):\n",
    "            # Use features from the next time step\n",
    "            next_input = x_test_scaled[next_index].copy()\n",
    "        else:\n",
    "            # Reached the end of x_test_scaled\n",
    "            break\n",
    "\n",
    "        # Update lag features with available scaled predictions\n",
    "        for lag in range(1, min(step + 1, 6) + 1):\n",
    "            feature_index = 12 - lag  # lag1 is at index 11\n",
    "            next_input[feature_index, 0] = scaled_predictions[-lag]\n",
    "\n",
    "        # Keep lag24 and lag168 as they are, or update if necessary\n",
    "\n",
    "        # Set current_input for next iteration\n",
    "        current_input = next_input\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBK2TyUSxCQ-"
   },
   "source": [
    "## 9. Make step-by-step prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "79gLJQDkdNBl"
   },
   "outputs": [],
   "source": [
    "# Number of steps to predict\n",
    "n_steps = 6\n",
    "\n",
    "# Initialize lists to store predictions and actual values\n",
    "all_predictions = []\n",
    "all_actuals = []\n",
    "\n",
    "# Ensure we have enough data for recursive predictions\n",
    "n_test_samples = x_test_scaled.shape[0]\n",
    "\n",
    "for i in range(n_test_samples - n_steps):\n",
    "    # Perform recursive forecasting\n",
    "    predictions = recursive_forecast(\n",
    "        model=best_model,\n",
    "        x_test_scaled=x_test_scaled,\n",
    "        start_index=i,\n",
    "        n_steps=n_steps,\n",
    "        x_scaler=x_scaler,\n",
    "        y_scaler=y_scaler\n",
    "    )\n",
    "\n",
    "    # Get the actual future values (in original scale)\n",
    "    actual_values = y_test[i+1:i + len(predictions) + 1].flatten()\n",
    "\n",
    "    # Store the predictions and actual values\n",
    "    all_predictions.append(predictions)\n",
    "    all_actuals.append(actual_values)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_actuals = np.array(all_actuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9SREwnRqxMN1"
   },
   "source": [
    "## 10. Evaluating the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xw9n5yNExAkJ",
    "outputId": "4f5b2721-8d8e-4871-eb56-dfd1b17ab14c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time Step 1 Evaluation Metrics:\n",
      "RMSE: 41.4159\n",
      "MAE: 29.8309\n",
      "MAPE: 32.89%\n",
      "\n",
      "Time Step 2 Evaluation Metrics:\n",
      "RMSE: 44.7596\n",
      "MAE: 31.9444\n",
      "MAPE: 36.16%\n",
      "\n",
      "Time Step 3 Evaluation Metrics:\n",
      "RMSE: 47.2820\n",
      "MAE: 33.4781\n",
      "MAPE: 39.15%\n",
      "\n",
      "Time Step 4 Evaluation Metrics:\n",
      "RMSE: 49.5900\n",
      "MAE: 34.8770\n",
      "MAPE: 41.75%\n",
      "\n",
      "Time Step 5 Evaluation Metrics:\n",
      "RMSE: 51.5312\n",
      "MAE: 35.9326\n",
      "MAPE: 43.32%\n",
      "\n",
      "Time Step 6 Evaluation Metrics:\n",
      "RMSE: 53.2142\n",
      "MAE: 36.6299\n",
      "MAPE: 44.43%\n"
     ]
    }
   ],
   "source": [
    "# Compute evaluation metrics\n",
    "epsilon = 1e-10  # To avoid division by zero in MAPE\n",
    "\n",
    "for i in range(n_steps):\n",
    "    y_true = all_actuals[:, i]\n",
    "    y_pred = all_predictions[:, i]\n",
    "\n",
    "    # Mean Absolute Error (MAE)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "    # Root Mean Squared Error (RMSE)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "    # Mean Absolute Percentage Error (MAPE)\n",
    "    y_true_safe = np.where(y_true == 0, epsilon, y_true)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true_safe)) * 100\n",
    "\n",
    "    print(f\"\\nTime Step {i+1} Evaluation Metrics:\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"MAPE: {mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k9VMIQUvBZ3q"
   },
   "outputs": [],
   "source": [
    "step-by-step full date"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
