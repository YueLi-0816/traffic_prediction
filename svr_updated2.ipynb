{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e584ad9-1bbb-4cff-81db-6c6610f18e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVR\n",
    "from itertools import product\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c748fcf6-3240-42d5-ba15-0a869b5b9a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_data = pd.read_csv('GD030A_S.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb3ffa4-ef8c-4e92-b599-348a58650238",
   "metadata": {},
   "source": [
    "## 1. Recover timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cace866-97bc-4517-a8a2-7aece8ba9553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the recover_timestamp function\n",
    "def recover_timestamp(data):\n",
    "    # Combine 'date' and 'time' to form a datetime column\n",
    "    data['datetime'] = pd.to_datetime(data['date'] + ' ' + data['time'].astype(str) + ':00', format='%Y-%m-%d %H:%M')\n",
    "\n",
    "    # Set 'datetime' as index\n",
    "    data = data.set_index('datetime')\n",
    "\n",
    "    # Create a complete range of timestamps with hourly frequency\n",
    "    full_time_range = pd.date_range(start=data.index.min(), end=data.index.max(), freq='H')\n",
    "\n",
    "    # Reindex the data to include all timestamps, filling missing rows with NaN\n",
    "    data_full = data.reindex(full_time_range)\n",
    "\n",
    "    return data_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2b088c7-7dcc-4b08-9177-9c76c49609ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>flow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-10-01 00:00:00</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01 01:00:00</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01 02:00:00</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01 03:00:00</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01 04:00:00</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-30 19:00:00</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>19.0</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-30 20:00:00</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>20.0</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-30 21:00:00</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>21.0</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-30 22:00:00</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>22.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-30 23:00:00</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>23.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35064 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           date  time   flow\n",
       "2019-10-01 00:00:00  2019-10-01   0.0   15.0\n",
       "2019-10-01 01:00:00  2019-10-01   1.0    9.0\n",
       "2019-10-01 02:00:00  2019-10-01   2.0    9.0\n",
       "2019-10-01 03:00:00  2019-10-01   3.0    7.0\n",
       "2019-10-01 04:00:00  2019-10-01   4.0    9.0\n",
       "...                         ...   ...    ...\n",
       "2023-09-30 19:00:00  2023-09-30  19.0  129.0\n",
       "2023-09-30 20:00:00  2023-09-30  20.0  119.0\n",
       "2023-09-30 21:00:00  2023-09-30  21.0  106.0\n",
       "2023-09-30 22:00:00  2023-09-30  22.0   88.0\n",
       "2023-09-30 23:00:00  2023-09-30  23.0   88.0\n",
       "\n",
       "[35064 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the recover_timestamp function to recover the full time series\n",
    "traffic_full = recover_timestamp(traffic_data)\n",
    "traffic_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf1e7fe-f9ef-4ea1-be19-409f1fa38091",
   "metadata": {},
   "source": [
    "## 2. Train, validate, test data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c934458-dee3-41f0-ab07-399a5a672804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of train_set : 0.6037\n",
      "Proportion of valid_set : 0.2094\n",
      "Proportion of test_set : 0.1869\n"
     ]
    }
   ],
   "source": [
    "train_set = traffic_full[:'2022-02-28 23:00:00']\n",
    "valid_set = traffic_full['2022-03-01 00:00:00':'2022-12-31 23:00:00']\n",
    "test_set = traffic_full['2023-01-01 00:00:00':]\n",
    "\n",
    "print('Proportion of train_set : {:.4f}'.format(len(train_set)/len(traffic_full)))\n",
    "print('Proportion of valid_set : {:.4f}'.format(len(valid_set)/len(traffic_full)))\n",
    "print('Proportion of test_set : {:.4f}'.format(len(test_set)/len(traffic_full)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e84283a-40b6-49f0-9249-8311c0816c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date    927\n",
      "time    927\n",
      "flow    927\n",
      "dtype: int64 21168\n",
      "date    91\n",
      "time    91\n",
      "flow    91\n",
      "dtype: int64 7344\n",
      "date    403\n",
      "time    403\n",
      "flow    403\n",
      "dtype: int64 6552\n"
     ]
    }
   ],
   "source": [
    "print(train_set.isnull().sum(), len(train_set))\n",
    "print(valid_set.isnull().sum(),len(valid_set))\n",
    "print(test_set.isnull().sum(),len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c378aad9-ff66-42ae-9939-8acc9e5112a3",
   "metadata": {},
   "source": [
    "## 3. Normalise the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40e3a7e1-9452-4548-9af1-721f37fef075",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2571992/1100395100.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_set.loc[:, 'flow_scaled'] = scaler.transform(train_set[['flow']])\n",
      "/tmp/ipykernel_2571992/1100395100.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  valid_set.loc[:, 'flow_scaled'] = scaler.transform(valid_set[['flow']])\n",
      "/tmp/ipykernel_2571992/1100395100.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_set.loc[:, 'flow_scaled'] = scaler.transform(test_set[['flow']])\n"
     ]
    }
   ],
   "source": [
    "# Initialize the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler on the training data's 'flow' feature\n",
    "scaler.fit(train_set[['flow']])\n",
    "\n",
    "# Transform the 'flow' feature in all datasets\n",
    "train_set.loc[:, 'flow_scaled'] = scaler.transform(train_set[['flow']])\n",
    "valid_set.loc[:, 'flow_scaled'] = scaler.transform(valid_set[['flow']])\n",
    "test_set.loc[:, 'flow_scaled'] = scaler.transform(test_set[['flow']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582bec02-7267-4d5f-91fe-d6e2ce2b8061",
   "metadata": {},
   "source": [
    "## 4. Split the data into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f3e43ed-2a69-4834-9811-efb982d05823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, input_length, forecast_horizon):\n",
    "    \"\"\"\n",
    "    Creates input-output sequences for time series data for SVR (MultiOutputRegressor).\n",
    "    \n",
    "    Parameters:\n",
    "    - data: pandas DataFrame containing the data. Must include the 'flow_scaled' column.\n",
    "    - input_length: int, number of past time steps to include in each input sequence.\n",
    "    - forecast_horizon: int, number of future steps to predict.\n",
    "    \n",
    "    Returns:\n",
    "    - X: numpy array of shape (num_valid_samples, input_length)\n",
    "    - y: numpy array of shape (num_valid_samples, forecast_horizon)\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    \n",
    "    # Iterate through the data to create sequences\n",
    "    for i in range(input_length, len(data) - forecast_horizon + 1):\n",
    "        # Extract the input sequence (flattened to a 1D array)\n",
    "        X_seq = data.iloc[i - input_length:i]['flow_scaled'].values\n",
    "        \n",
    "        # Extract the target sequence (future steps)\n",
    "        y_seq = data.iloc[i:i + forecast_horizon]['flow_scaled'].values\n",
    "        \n",
    "        # Check for NaN values in the input sequence and target sequence\n",
    "        if not np.isnan(X_seq).any() and not np.isnan(y_seq).any():\n",
    "            X.append(X_seq)\n",
    "            y.append(y_seq)\n",
    "        else:\n",
    "            # Optionally, log or count the skipped sequences\n",
    "            pass  # Simply skip sequences with NaNs\n",
    "        \n",
    "    # Convert to numpy arrays\n",
    "    X = np.array(X)  # Shape: (num_valid_samples, input_length)\n",
    "    y = np.array(y)  # Shape: (num_valid_samples, forecast_horizon)\n",
    "    \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d281f8e6-7266-43c3-80db-ef878d0c5895",
   "metadata": {},
   "source": [
    "## 5. Create X and y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f3c25b-bdd0-4814-abf7-912028ccc87d",
   "metadata": {},
   "source": [
    "#### We will use\n",
    "* the last 24*N steps\n",
    "\n",
    "*  to forecast current (0 step) and 5 steps ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "365afa04-ea00-42cb-8ce8-4bade3e5918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Input Sequence Lengths\n",
    "input_lengths = [24 * i for i in range(1, 22)]  # [24, 48, ..., 168]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47eebff6-c972-4d8e-86ff-e671f9a70bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing input length: 24\n",
      "  X_train shape: (19806, 24), y_train shape: (19806, 6)\n",
      "  X_val shape: (7108, 24), y_val shape: (7108, 6)\n",
      "  X_test shape: (5915, 24), y_test shape: (5915, 6)\n",
      "\n",
      "Processing input length: 48\n",
      "  X_train shape: (19446, 48), y_train shape: (19446, 6)\n",
      "  X_val shape: (6988, 48), y_val shape: (6988, 6)\n",
      "  X_test shape: (5728, 48), y_test shape: (5728, 6)\n",
      "\n",
      "Processing input length: 72\n",
      "  X_train shape: (19086, 72), y_train shape: (19086, 6)\n",
      "  X_val shape: (6868, 72), y_val shape: (6868, 6)\n",
      "  X_test shape: (5560, 72), y_test shape: (5560, 6)\n",
      "\n",
      "Processing input length: 96\n",
      "  X_train shape: (18726, 96), y_train shape: (18726, 6)\n",
      "  X_val shape: (6748, 96), y_val shape: (6748, 6)\n",
      "  X_test shape: (5392, 96), y_test shape: (5392, 6)\n",
      "\n",
      "Processing input length: 120\n",
      "  X_train shape: (18366, 120), y_train shape: (18366, 6)\n",
      "  X_val shape: (6628, 120), y_val shape: (6628, 6)\n",
      "  X_test shape: (5224, 120), y_test shape: (5224, 6)\n",
      "\n",
      "Processing input length: 144\n",
      "  X_train shape: (18006, 144), y_train shape: (18006, 6)\n",
      "  X_val shape: (6508, 144), y_val shape: (6508, 6)\n",
      "  X_test shape: (5056, 144), y_test shape: (5056, 6)\n",
      "\n",
      "Processing input length: 168\n",
      "  X_train shape: (17646, 168), y_train shape: (17646, 6)\n",
      "  X_val shape: (6388, 168), y_val shape: (6388, 6)\n",
      "  X_test shape: (4888, 168), y_test shape: (4888, 6)\n",
      "\n",
      "Processing input length: 192\n",
      "  X_train shape: (17286, 192), y_train shape: (17286, 6)\n",
      "  X_val shape: (6268, 192), y_val shape: (6268, 6)\n",
      "  X_test shape: (4720, 192), y_test shape: (4720, 6)\n",
      "\n",
      "Processing input length: 216\n",
      "  X_train shape: (16926, 216), y_train shape: (16926, 6)\n",
      "  X_val shape: (6148, 216), y_val shape: (6148, 6)\n",
      "  X_test shape: (4552, 216), y_test shape: (4552, 6)\n",
      "\n",
      "Processing input length: 240\n",
      "  X_train shape: (16566, 240), y_train shape: (16566, 6)\n",
      "  X_val shape: (6028, 240), y_val shape: (6028, 6)\n",
      "  X_test shape: (4384, 240), y_test shape: (4384, 6)\n",
      "\n",
      "Processing input length: 264\n",
      "  X_train shape: (16206, 264), y_train shape: (16206, 6)\n",
      "  X_val shape: (5908, 264), y_val shape: (5908, 6)\n",
      "  X_test shape: (4216, 264), y_test shape: (4216, 6)\n",
      "\n",
      "Processing input length: 288\n",
      "  X_train shape: (15846, 288), y_train shape: (15846, 6)\n",
      "  X_val shape: (5788, 288), y_val shape: (5788, 6)\n",
      "  X_test shape: (4048, 288), y_test shape: (4048, 6)\n",
      "\n",
      "Processing input length: 312\n",
      "  X_train shape: (15486, 312), y_train shape: (15486, 6)\n",
      "  X_val shape: (5687, 312), y_val shape: (5687, 6)\n",
      "  X_test shape: (3880, 312), y_test shape: (3880, 6)\n",
      "\n",
      "Processing input length: 336\n",
      "  X_train shape: (15126, 336), y_train shape: (15126, 6)\n",
      "  X_val shape: (5591, 336), y_val shape: (5591, 6)\n",
      "  X_test shape: (3712, 336), y_test shape: (3712, 6)\n",
      "\n",
      "Processing input length: 360\n",
      "  X_train shape: (14766, 360), y_train shape: (14766, 6)\n",
      "  X_val shape: (5495, 360), y_val shape: (5495, 6)\n",
      "  X_test shape: (3544, 360), y_test shape: (3544, 6)\n",
      "\n",
      "Processing input length: 384\n",
      "  X_train shape: (14419, 384), y_train shape: (14419, 6)\n",
      "  X_val shape: (5399, 384), y_val shape: (5399, 6)\n",
      "  X_test shape: (3394, 384), y_test shape: (3394, 6)\n",
      "\n",
      "Processing input length: 408\n",
      "  X_train shape: (14107, 408), y_train shape: (14107, 6)\n",
      "  X_val shape: (5303, 408), y_val shape: (5303, 6)\n",
      "  X_test shape: (3250, 408), y_test shape: (3250, 6)\n",
      "\n",
      "Processing input length: 432\n",
      "  X_train shape: (13824, 432), y_train shape: (13824, 6)\n",
      "  X_val shape: (5207, 432), y_val shape: (5207, 6)\n",
      "  X_test shape: (3123, 432), y_test shape: (3123, 6)\n",
      "\n",
      "Processing input length: 456\n",
      "  X_train shape: (13560, 456), y_train shape: (13560, 6)\n",
      "  X_val shape: (5111, 456), y_val shape: (5111, 6)\n",
      "  X_test shape: (3003, 456), y_test shape: (3003, 6)\n",
      "\n",
      "Processing input length: 480\n",
      "  X_train shape: (13296, 480), y_train shape: (13296, 6)\n",
      "  X_val shape: (5015, 480), y_val shape: (5015, 6)\n",
      "  X_test shape: (2883, 480), y_test shape: (2883, 6)\n",
      "\n",
      "Processing input length: 504\n",
      "  X_train shape: (13046, 504), y_train shape: (13046, 6)\n",
      "  X_val shape: (4919, 504), y_val shape: (4919, 6)\n",
      "  X_test shape: (2781, 504), y_test shape: (2781, 6)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "data_dict = defaultdict(dict)\n",
    "\n",
    "for length in input_lengths:\n",
    "    print(f\"Processing input length: {length}\")\n",
    "    \n",
    "    # Create sequences with forecast_horizon=6\n",
    "    X_train, y_train = create_sequences(train_set, length, forecast_horizon=6)\n",
    "    X_val, y_val = create_sequences(valid_set, length, forecast_horizon=6)\n",
    "    X_test, y_test = create_sequences(test_set, length, forecast_horizon=6)\n",
    "    \n",
    "    # Store in the dictionary\n",
    "    data_dict[length]['X_train'] = X_train\n",
    "    data_dict[length]['y_train'] = y_train\n",
    "    data_dict[length]['X_val'] = X_val\n",
    "    data_dict[length]['y_val'] = y_val\n",
    "    data_dict[length]['X_test'] = X_test\n",
    "    data_dict[length]['y_test'] = y_test\n",
    "    \n",
    "    # Print shapes and ensure no NaNs\n",
    "    print(f\"  X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "    print(f\"  X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
    "    print(f\"  X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0629542-7def-472c-98f5-0f64ffeba783",
   "metadata": {},
   "source": [
    "## 6. Build SVR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d7a4120-2b4c-4066-b0d3-f114740b7686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_svr_model(hyperparams):\n",
    "    if hyperparams['kernel'] == 'poly':  # Ensure degree is used for 'poly' kernel\n",
    "        model = MultiOutputRegressor(SVR(C=hyperparams['C'], epsilon=hyperparams['epsilon'], \n",
    "                                             kernel=hyperparams['kernel'], gamma=hyperparams['gamma'], \n",
    "                                             degree=hyperparams['degree']))\n",
    "    elif hyperparams['kernel'] == 'linear':  # No need for gamma or degree for 'linear'\n",
    "        model = MultiOutputRegressor(SVR(C=hyperparams['C'], epsilon=hyperparams['epsilon'], \n",
    "                                             kernel=hyperparams['kernel']))\n",
    "    else: # For RBF, sigmoid, etc., gamma is necessary\n",
    "        model = MultiOutputRegressor(SVR(C=hyperparams['C'], epsilon=hyperparams['epsilon'], \n",
    "                                             kernel=hyperparams['kernel'], gamma=hyperparams['gamma']))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961dfa63-3058-4aa4-86ec-61948e9a7ede",
   "metadata": {},
   "source": [
    "## 7. Define the hyperparameter grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8991c39f-3dd7-4e1b-ae36-e1c3f9f5b41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total combinations: 279\n",
      "[(1, 0.01, None, 'linear', None), (1, 0.1, None, 'linear', None), (1, 0.2, None, 'linear', None), (10, 0.01, None, 'linear', None), (10, 0.1, None, 'linear', None), (10, 0.2, None, 'linear', None), (100, 0.01, None, 'linear', None), (100, 0.1, None, 'linear', None), (100, 0.2, None, 'linear', None), (1, 0.01, 'scale', 'rbf', None)]\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Define hyperparameter grid with conditions on kernel types\n",
    "hyperparameter_grid = {               \n",
    "    'C': [1, 10, 100],              # Regularization parameter\n",
    "    'epsilon': [0.01, 0.1, 0.2],    # Epsilon parameter\n",
    "    'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1],  # Kernel coefficient for RBF, poly, and sigmoid\n",
    "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],  # Kernels to try\n",
    "    'degree': [2, 3, 4]             # Degree of the polynomial kernel (only for 'poly')\n",
    "}\n",
    "\n",
    "# Generate all combinations, respecting kernel-specific constraints\n",
    "all_combinations = []\n",
    "\n",
    "# Iterate over each kernel type and create the combinations accordingly\n",
    "for kernel in hyperparameter_grid['kernel']:\n",
    "    if kernel == 'linear':\n",
    "        # For linear kernel, do not include 'gamma' and 'degree'\n",
    "        for C, epsilon in product(hyperparameter_grid['C'], hyperparameter_grid['epsilon']):\n",
    "            all_combinations.append((C, epsilon, None, kernel, None))  # No gamma, no degree\n",
    "    elif kernel == 'poly':\n",
    "        # For poly kernel, include 'gamma' and 'degree'\n",
    "        for C, epsilon, gamma, degree in product(\n",
    "            hyperparameter_grid['C'], \n",
    "            hyperparameter_grid['epsilon'], \n",
    "            hyperparameter_grid['gamma'], \n",
    "            hyperparameter_grid['degree']\n",
    "        ):\n",
    "            all_combinations.append((C, epsilon, gamma, kernel, degree))  # Include gamma and degree\n",
    "    else:\n",
    "        # For other kernels (rbf, sigmoid), include 'gamma' but not 'degree'\n",
    "        for C, epsilon, gamma in product(\n",
    "            hyperparameter_grid['C'], \n",
    "            hyperparameter_grid['epsilon'], \n",
    "            hyperparameter_grid['gamma']\n",
    "        ):\n",
    "            all_combinations.append((C, epsilon, gamma, kernel, None))  # No degree\n",
    "\n",
    "# Display the resulting combinations\n",
    "print(f\"Total combinations: {len(all_combinations)}\")\n",
    "print(all_combinations[:10])  # Display the first 10 combinations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25479126-abb6-404d-acb9-8c749126146b",
   "metadata": {},
   "source": [
    "## 8. Defining manual grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3382bcac-659b-4b4b-87ee-960360054b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Set the logging level to INFO\n",
    "    format='%(asctime)s - %(message)s',  # Customize the log message format\n",
    "    handlers=[\n",
    "        logging.FileHandler('svr_updated2.log'),  # Log messages to 'output.log'\n",
    "        logging.StreamHandler()             # Also output to console/notebook\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "932f944c-ebd2-4127-b989-0c8ab46dfd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-15 12:52:43,138 - test\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80f29c7-b904-4901-b647-0fa05ce2fcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-15 13:00:42,126 - Starting grid search for input length: 24\n",
      "2025-01-15 13:00:42,127 -   Evaluating combination 1/279: {'C': 1, 'epsilon': 0.01, 'gamma': None, 'kernel': 'linear', 'degree': None}\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "# Loop over each input length\n",
    "for length in input_lengths:\n",
    "    logging.info(f\"Starting grid search for input length: {length}\")\n",
    "    \n",
    "    X_train = data_dict[length]['X_train']\n",
    "    y_train = data_dict[length]['y_train']\n",
    "    X_val = data_dict[length]['X_val']\n",
    "    y_val = data_dict[length]['y_val']\n",
    "    \n",
    "    best_mse = float('inf')\n",
    "    best_params = {}\n",
    "    best_model = None\n",
    "    \n",
    "    # Iterate through all combinations of hyperparameters\n",
    "    for idx, combination in enumerate(all_combinations):\n",
    "        hyperparams = {\n",
    "            'C': combination[0],\n",
    "            'epsilon': combination[1],\n",
    "            'gamma': combination[2],\n",
    "            'kernel': combination[3],\n",
    "            'degree': combination[4]\n",
    "        }\n",
    "        \n",
    "        logging.info(f\"  Evaluating combination {idx + 1}/{len(all_combinations)}: {hyperparams}\")\n",
    "\n",
    "        # build the svr model\n",
    "        model = build_svr_model(hyperparams)\n",
    "        # train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        # Validate the model on the validation set\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        # Calculate MSE on the validation set\n",
    "        current_best_mse = mean_squared_error(y_val, y_val_pred)\n",
    "        logging.info(f\"Validation MSE: {current_best_mse:.5f}\")\n",
    "        \n",
    "        # If this combination gives a better validation MSE, update the best model\n",
    "        if current_best_mse < best_mse:\n",
    "            best_mse = current_best_mse\n",
    "            best_params = hyperparams.copy()\n",
    "            best_model = model\n",
    "    \n",
    "    # Store the best results\n",
    "    results.append({\n",
    "        'Input_Length': length,\n",
    "        'Best_MSE': best_mse,\n",
    "        'Best_Hyperparameters': best_params\n",
    "    })\n",
    "    \n",
    "    logging.info(f\"Completed grid search for input length: {length}\")\n",
    "    logging.info(f\"  Best Validation MSE: {best_mse:.5f}\")\n",
    "    logging.info(f\"  Best Hyperparameters: {best_params}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c4c84d-0d18-48be-864a-9bd575a56581",
   "metadata": {},
   "source": [
    "## 9. Storing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b03331-46d9-436c-b5fb-b3231d756eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the results list to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Expand the hyperparameters dictionary into separate columns for clarity\n",
    "hyperparams_df = results_df['Best_Hyperparameters'].apply(pd.Series)\n",
    "\n",
    "# Combine the main dataframe with hyperparameters\n",
    "final_results_df = pd.concat([results_df.drop('Best_Hyperparameters', axis=1), hyperparams_df], axis=1)\n",
    "\n",
    "# Display the final dataframe\n",
    "print(\"Final Results DataFrame:\")\n",
    "final_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666f466e-a17d-4ee3-80dd-7318766e9375",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
