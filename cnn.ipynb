{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aipy1cdPrF5n"
   },
   "source": [
    "# Create the adjacency matrix based on the network distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VVQp0-W7bvc2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import igraph as ig\n",
    "import numpy as np\n",
    "from shapely.geometry import Point, LineString, MultiLineString\n",
    "from scipy.sparse import lil_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pXFMFA5lhEXE"
   },
   "outputs": [],
   "source": [
    "# Load the shapefile\n",
    "shapefile_path = '/content/drive/MyDrive/traffic predict/traffic_flow_data/20211110_glasgow_road_link.shp'\n",
    "\n",
    "# Load the shapefile and check for multi-part geometries\n",
    "road = gpd.read_file(shapefile_path)\n",
    "road = road[['TOID','startNode','endNode','SHAPE_Leng','geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2f_2vL28nw-_"
   },
   "outputs": [],
   "source": [
    "sensor_locations = pd.read_csv('/content/drive/MyDrive/traffic predict/traffic_flow_data/locations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vW4yrPB0rXR6",
    "outputId": "93648a2d-33c6-40e2-d5b8-f6d9168e63e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MULTILINESTRING Z ((251248.17809751772 669639.0000000012 6.399999999994179, 251247.0000000005 669639.0000000012 6.399999999994179, 251245.95858065385 669639.2603548367 6.399999999994179), (251238.56264667233 669639.112529336 6.399999999994179, 251238.00000000026 669639.0000000012 6.399999999994179, 251230.00000000055 669635.3069999991 6.5, 251179.45799999978 669611.9780000006 6.69999999999709, 251174.4590000003 669607.2569999994 6.69999999999709, 251170.01599999957 669602.3509999997 6.69999999999709), (251256.00000000073 669631.9999999998 6.399999999994179, 251254.49207804582 669634.0105626032 6.399999999994179))\n",
      "LINESTRING Z (266867.00000000035 664490.0000000007 60.10000000000582, 266914.00000000023 664422.9999999993 59.69999999999709, 266922 664409.9999999993 59.80000000000291)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32179"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(road.loc[794].geometry)\n",
    "print(road.loc[793].geometry)\n",
    "len(road)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "collapsed": true,
    "id": "bgAh3rcKstrT",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "d95fd89d-a0b5-4a19-846f-1a8a63654f44"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "all_edges"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-0d5c7144-da6c-4d6a-aae1-6fbb934453a5\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LINESTRING Z (265498 666414 91.5, 265498 66641...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LINESTRING Z (265498 666416 91.5, 265491.164 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LINESTRING Z (252430 668308 16.1, 252401 66825...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LINESTRING Z (252401 668254 15.5, 252398.6 668...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LINESTRING Z (252398.6 668250 15.4, 252389 668...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LINESTRING Z (252389 668234 14.5, 252369 66820...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LINESTRING Z (252369 668208 12.8, 252348 66817...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LINESTRING Z (252348 668177 10.9, 252306 66812...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LINESTRING Z (252066.564 660968.5 27.9, 252075...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LINESTRING Z (252075.98 660958.817 28.1, 25208...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d5c7144-da6c-4d6a-aae1-6fbb934453a5')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-0d5c7144-da6c-4d6a-aae1-6fbb934453a5 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-0d5c7144-da6c-4d6a-aae1-6fbb934453a5');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-66b53657-20a1-447d-83dc-b7e00c0f574a\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-66b53657-20a1-447d-83dc-b7e00c0f574a')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-66b53657-20a1-447d-83dc-b7e00c0f574a button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                            geometry\n",
       "0  LINESTRING Z (265498 666414 91.5, 265498 66641...\n",
       "1  LINESTRING Z (265498 666416 91.5, 265491.164 6...\n",
       "2  LINESTRING Z (252430 668308 16.1, 252401 66825...\n",
       "3  LINESTRING Z (252401 668254 15.5, 252398.6 668...\n",
       "4  LINESTRING Z (252398.6 668250 15.4, 252389 668...\n",
       "5  LINESTRING Z (252389 668234 14.5, 252369 66820...\n",
       "6  LINESTRING Z (252369 668208 12.8, 252348 66817...\n",
       "7  LINESTRING Z (252348 668177 10.9, 252306 66812...\n",
       "8  LINESTRING Z (252066.564 660968.5 27.9, 252075...\n",
       "9  LINESTRING Z (252075.98 660958.817 28.1, 25208..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reconstruct the road geodataframe to make sure each row as a single edge of the road network\n",
    "# split a LineString or MultiLineString into two-point LineStrings\n",
    "def split_to_edges(geometry):\n",
    "    \"\"\"Splits a LineString or MultiLineString geometry into individual two-point LineStrings.\"\"\"\n",
    "    edges = []\n",
    "\n",
    "    if isinstance(geometry, LineString):\n",
    "        # Split LineString into two-point segments\n",
    "        points = list(geometry.coords)\n",
    "        for i in range(len(points) - 1):\n",
    "            edges.append(LineString([points[i], points[i+1]]))\n",
    "\n",
    "    elif isinstance(geometry, MultiLineString):\n",
    "        # First break MultiLineString into individual LineStrings\n",
    "        for line in geometry.geoms:\n",
    "            # Then split each LineString into two-point segments\n",
    "            points = list(line.coords)\n",
    "            for i in range(len(points) - 1):\n",
    "                edges.append(LineString([points[i], points[i+1]]))\n",
    "\n",
    "    return edges\n",
    "\n",
    "# Create a new list to store the two-point LineStrings\n",
    "new_geometries = []\n",
    "\n",
    "# Iterate over each row in the GeoDataFrame and split the geometries\n",
    "for geom in road.geometry:\n",
    "    new_geometries.extend(split_to_edges(geom))\n",
    "\n",
    "# Create a new GeoDataFrame from the split geometries\n",
    "all_edges = gpd.GeoDataFrame(geometry=new_geometries, crs=road.crs)\n",
    "\n",
    "# Display the first few rows of the new GeoDataFrame\n",
    "all_edges.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O0VNE8hcuqDc",
    "outputId": "5b4d0b06-7e6f-4271-825e-baa3fe898309"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143751"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kRHGFvzip5nN"
   },
   "outputs": [],
   "source": [
    "# Step 1: Convert sensor locations to GeoDataFrame with Point geometries\n",
    "sensor_locations['geometry'] = sensor_locations.apply(lambda row: Point(row['longitude'], row['latitude']), axis=1)\n",
    "sensor_gdf = gpd.GeoDataFrame(sensor_locations, geometry='geometry', crs='EPSG:4326')  # Assuming WGS84 coordinate system\n",
    "\n",
    "# Convert road edges and sensor locations to the same projection if necessary (road_edges may use a different CRS)\n",
    "sensor_gdf = sensor_gdf.to_crs(road.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u27kjh_DntI6"
   },
   "outputs": [],
   "source": [
    "# Step 2: Calculate the perpendicular distance from each sensor to each edge in the road network\n",
    "# We'll loop through each sensor and find the nearest edge by minimizing the perpendicular distance\n",
    "\n",
    "nearest_edges = []  # This will store the nearest edge for each sensor\n",
    "\n",
    "# Loop through each sensor and find the nearest edge by perpendicular distance\n",
    "for sensor in sensor_gdf.geometry:\n",
    "    distances = all_edges.geometry.apply(lambda edge: sensor.distance(edge))  # Perpendicular distance to each edge\n",
    "    nearest_edge_idx = np.argmin(distances)  # Index of the nearest edge\n",
    "    nearest_edges.append(all_edges.iloc[nearest_edge_idx])  # Store the nearest edge\n",
    "\n",
    "# Create a GeoDataFrame with the nearest edges corresponding to each sensor\n",
    "sensor_to_edge_mapping = gpd.GeoDataFrame(nearest_edges, geometry='geometry')\n",
    "\n",
    "# Step 3: Filter the unique edges that have sensors mapped to them\n",
    "sensor_edges = sensor_to_edge_mapping.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZEuDkIxhx4xB",
    "outputId": "f449a379-997c-48bd-f94e-60f41c0e7b51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "444"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sensor_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wBas038Tyeqi"
   },
   "outputs": [],
   "source": [
    "# Step 4: Prepare for calculating road network distances between the mapped sensor edges\n",
    "# Create a list of all vertices (start and end points of the edges)\n",
    "vertices = {}  # To map points (start, end) to unique IDs\n",
    "vertex_id = 0\n",
    "\n",
    "edges = []  # To store the edges as (start_vertex, end_vertex, distance)\n",
    "for idx, row in all_edges.iterrows():\n",
    "    line = row.geometry\n",
    "    start_point = Point(line.coords[0])\n",
    "    end_point = Point(line.coords[-1])\n",
    "\n",
    "    if start_point not in vertices:\n",
    "        vertices[start_point] = vertex_id\n",
    "        vertex_id += 1\n",
    "    if end_point not in vertices:\n",
    "        vertices[end_point] = vertex_id\n",
    "        vertex_id += 1\n",
    "\n",
    "    # Add the edge (start vertex, end vertex, length of the road segment)\n",
    "    edge_length = start_point.distance(end_point)  # Assuming Euclidean distance for the edge length\n",
    "    edges.append((vertices[start_point], vertices[end_point], edge_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fUT7JLyJz1vb"
   },
   "outputs": [],
   "source": [
    "# Step 5: Create an igraph Graph object for the full road network\n",
    "g = ig.Graph()\n",
    "g.add_vertices(len(vertices))  # Add vertices to the graph (number of unique points in the network)\n",
    "g.add_edges([(e[0], e[1]) for e in edges])  # Add the edges (start_vertex, end_vertex) to the graph\n",
    "g.es['weight'] = [e[2] for e in edges]  # Set the edge weights as road segment lengths (distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K1G1Lh-G0V3B"
   },
   "outputs": [],
   "source": [
    "# Step 6: Function to calculate the shortest path between the start vertices of two sensor edges\n",
    "def get_dynamic_network_distance(edge1, edge2):\n",
    "    start_v1 = edge1['geometry'].coords[0]  # Start vertex of edge 1\n",
    "    start_v2 = edge2['geometry'].coords[0]  # Start vertex of edge 2\n",
    "\n",
    "    # Retrieve the corresponding vertex IDs from the vertices dictionary\n",
    "    vertex_id_1 = vertices[Point(start_v1)]\n",
    "    vertex_id_2 = vertices[Point(start_v2)]\n",
    "\n",
    "    # Use Dijkstra's algorithm to compute the shortest path between the two vertices dynamically\n",
    "    distance = g.distances(source=vertex_id_1, target=vertex_id_2, weights='weight')[0][0]\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "Drff4yj0z4ec",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "a70aca95-2313-45eb-a549-d15a07f306c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "343 394\n",
      "343 395\n",
      "343 396\n",
      "343 397\n",
      "343 398\n",
      "343 399\n",
      "343 400\n",
      "343 401\n",
      "343 402\n",
      "343 403\n",
      "343 404\n",
      "343 405\n",
      "343 406\n",
      "343 407\n",
      "343 408\n",
      "343 409\n",
      "343 410\n",
      "343 411\n",
      "343 412\n",
      "343 413\n",
      "343 414\n",
      "343 415\n",
      "343 416\n",
      "343 417\n",
      "343 418\n",
      "343 419\n",
      "343 420\n",
      "343 421\n",
      "343 422\n",
      "343 423\n",
      "343 424\n",
      "343 425\n",
      "343 426\n",
      "343 427\n",
      "343 428\n",
      "343 429\n",
      "343 430\n",
      "343 431\n",
      "343 432\n",
      "343 433\n",
      "343 434\n",
      "343 435\n",
      "343 436\n",
      "343 437\n",
      "343 438\n",
      "343 439\n",
      "343 440\n",
      "343 441\n",
      "343 442\n",
      "343 443\n",
      "344 345\n",
      "344 346\n",
      "344 347\n",
      "344 348\n",
      "344 349\n",
      "344 350\n",
      "344 351\n",
      "344 352\n",
      "344 353\n",
      "344 354\n",
      "344 355\n",
      "344 356\n",
      "344 357\n",
      "344 358\n",
      "344 359\n",
      "344 360\n",
      "344 361\n",
      "344 362\n",
      "344 363\n",
      "344 364\n",
      "344 365\n",
      "344 366\n",
      "344 367\n",
      "344 368\n",
      "344 369\n",
      "344 370\n",
      "344 371\n",
      "344 372\n",
      "344 373\n",
      "344 374\n",
      "344 375\n",
      "344 376\n",
      "344 377\n",
      "344 378\n",
      "344 379\n",
      "344 380\n",
      "344 381\n",
      "344 382\n",
      "344 383\n",
      "344 384\n",
      "344 385\n",
      "344 386\n",
      "344 387\n",
      "344 388\n",
      "344 389\n",
      "344 390\n",
      "344 391\n",
      "344 392\n",
      "344 393\n",
      "344 394\n",
      "344 395\n",
      "344 396\n",
      "344 397\n",
      "344 398\n",
      "344 399\n",
      "344 400\n",
      "344 401\n",
      "344 402\n",
      "344 403\n",
      "344 404\n",
      "344 405\n",
      "344 406\n",
      "344 407\n",
      "344 408\n",
      "344 409\n",
      "344 410\n",
      "344 411\n",
      "344 412\n",
      "344 413\n",
      "344 414\n",
      "344 415\n",
      "344 416\n",
      "344 417\n",
      "344 418\n",
      "344 419\n",
      "344 420\n",
      "344 421\n",
      "344 422\n",
      "344 423\n",
      "344 424\n",
      "344 425\n",
      "344 426\n",
      "344 427\n",
      "344 428\n",
      "344 429\n",
      "344 430\n",
      "344 431\n",
      "344 432\n",
      "344 433\n",
      "344 434\n",
      "344 435\n",
      "344 436\n",
      "344 437\n",
      "344 438\n",
      "344 439\n",
      "344 440\n",
      "344 441\n",
      "344 442\n",
      "344 443\n",
      "345 346\n",
      "345 347\n",
      "345 348\n",
      "345 349\n",
      "345 350\n",
      "345 351\n",
      "345 352\n",
      "345 353\n",
      "345 354\n",
      "345 355\n",
      "345 356\n",
      "345 357\n",
      "345 358\n",
      "345 359\n",
      "345 360\n",
      "345 361\n",
      "345 362\n",
      "345 363\n",
      "345 364\n",
      "345 365\n",
      "345 366\n",
      "345 367\n",
      "345 368\n",
      "345 369\n",
      "345 370\n",
      "345 371\n",
      "345 372\n",
      "345 373\n",
      "345 374\n",
      "345 375\n",
      "345 376\n",
      "345 377\n",
      "345 378\n",
      "345 379\n",
      "345 380\n",
      "345 381\n",
      "345 382\n",
      "345 383\n",
      "345 384\n",
      "345 385\n",
      "345 386\n",
      "345 387\n",
      "345 388\n",
      "345 389\n",
      "345 390\n",
      "345 391\n",
      "345 392\n",
      "345 393\n",
      "345 394\n",
      "345 395\n",
      "345 396\n",
      "345 397\n",
      "345 398\n",
      "345 399\n",
      "345 400\n",
      "345 401\n",
      "345 402\n",
      "345 403\n",
      "345 404\n",
      "345 405\n",
      "345 406\n",
      "345 407\n",
      "345 408\n",
      "345 409\n",
      "345 410\n",
      "345 411\n",
      "345 412\n",
      "345 413\n",
      "345 414\n",
      "345 415\n",
      "345 416\n",
      "345 417\n",
      "345 418\n",
      "345 419\n",
      "345 420\n",
      "345 421\n",
      "345 422\n",
      "345 423\n",
      "345 424\n",
      "345 425\n",
      "345 426\n",
      "345 427\n",
      "345 428\n",
      "345 429\n",
      "345 430\n",
      "345 431\n",
      "345 432\n",
      "345 433\n",
      "345 434\n",
      "345 435\n",
      "345 436\n",
      "345 437\n",
      "345 438\n",
      "345 439\n",
      "345 440\n",
      "345 441\n",
      "345 442\n",
      "345 443\n",
      "346 347\n",
      "346 348\n",
      "346 349\n",
      "346 350\n",
      "346 351\n",
      "346 352\n",
      "346 353\n",
      "346 354\n",
      "346 355\n",
      "346 356\n",
      "346 357\n",
      "346 358\n",
      "346 359\n",
      "346 360\n",
      "346 361\n",
      "346 362\n",
      "346 363\n",
      "346 364\n",
      "346 365\n",
      "346 366\n",
      "346 367\n",
      "346 368\n",
      "346 369\n",
      "346 370\n",
      "346 371\n",
      "346 372\n",
      "346 373\n",
      "346 374\n",
      "346 375\n",
      "346 376\n",
      "346 377\n",
      "346 378\n",
      "346 379\n",
      "346 380\n",
      "346 381\n",
      "346 382\n",
      "346 383\n",
      "346 384\n",
      "346 385\n",
      "346 386\n",
      "346 387\n",
      "346 388\n",
      "346 389\n",
      "346 390\n",
      "346 391\n",
      "346 392\n",
      "346 393\n",
      "346 394\n",
      "346 395\n",
      "346 396\n",
      "346 397\n",
      "346 398\n",
      "346 399\n",
      "346 400\n",
      "346 401\n",
      "346 402\n",
      "346 403\n",
      "346 404\n",
      "346 405\n",
      "346 406\n",
      "346 407\n",
      "346 408\n",
      "346 409\n",
      "346 410\n",
      "346 411\n",
      "346 412\n",
      "346 413\n",
      "346 414\n",
      "346 415\n",
      "346 416\n",
      "346 417\n",
      "346 418\n",
      "346 419\n",
      "346 420\n",
      "346 421\n",
      "346 422\n",
      "346 423\n",
      "346 424\n",
      "346 425\n",
      "346 426\n",
      "346 427\n",
      "346 428\n",
      "346 429\n",
      "346 430\n",
      "346 431\n",
      "346 432\n",
      "346 433\n",
      "346 434\n",
      "346 435\n",
      "346 436\n",
      "346 437\n",
      "346 438\n",
      "346 439\n",
      "346 440\n",
      "346 441\n",
      "346 442\n",
      "346 443\n",
      "347 348\n",
      "347 349\n",
      "347 350\n",
      "347 351\n",
      "347 352\n",
      "347 353\n",
      "347 354\n",
      "347 355\n",
      "347 356\n",
      "347 357\n",
      "347 358\n",
      "347 359\n",
      "347 360\n",
      "347 361\n",
      "347 362\n",
      "347 363\n",
      "347 364\n",
      "347 365\n",
      "347 366\n",
      "347 367\n",
      "347 368\n",
      "347 369\n",
      "347 370\n",
      "347 371\n",
      "347 372\n",
      "347 373\n",
      "347 374\n",
      "347 375\n",
      "347 376\n",
      "347 377\n",
      "347 378\n",
      "347 379\n",
      "347 380\n",
      "347 381\n",
      "347 382\n",
      "347 383\n",
      "347 384\n",
      "347 385\n",
      "347 386\n",
      "347 387\n",
      "347 388\n",
      "347 389\n",
      "347 390\n",
      "347 391\n",
      "347 392\n",
      "347 393\n",
      "347 394\n",
      "347 395\n",
      "347 396\n",
      "347 397\n",
      "347 398\n",
      "347 399\n",
      "347 400\n",
      "347 401\n",
      "347 402\n",
      "347 403\n",
      "347 404\n",
      "347 405\n",
      "347 406\n",
      "347 407\n",
      "347 408\n",
      "347 409\n",
      "347 410\n",
      "347 411\n",
      "347 412\n",
      "347 413\n",
      "347 414\n",
      "347 415\n",
      "347 416\n",
      "347 417\n",
      "347 418\n",
      "347 419\n",
      "347 420\n",
      "347 421\n",
      "347 422\n",
      "347 423\n",
      "347 424\n",
      "347 425\n",
      "347 426\n",
      "347 427\n",
      "347 428\n",
      "347 429\n",
      "347 430\n",
      "347 431\n",
      "347 432\n",
      "347 433\n",
      "347 434\n",
      "347 435\n",
      "347 436\n",
      "347 437\n",
      "347 438\n",
      "347 439\n",
      "347 440\n",
      "347 441\n",
      "347 442\n",
      "347 443\n",
      "348 349\n",
      "348 350\n",
      "348 351\n",
      "348 352\n",
      "348 353\n",
      "348 354\n",
      "348 355\n",
      "348 356\n",
      "348 357\n",
      "348 358\n",
      "348 359\n",
      "348 360\n",
      "348 361\n",
      "348 362\n",
      "348 363\n",
      "348 364\n",
      "348 365\n",
      "348 366\n",
      "348 367\n",
      "348 368\n",
      "348 369\n",
      "348 370\n",
      "348 371\n",
      "348 372\n",
      "348 373\n",
      "348 374\n",
      "348 375\n",
      "348 376\n",
      "348 377\n",
      "348 378\n",
      "348 379\n",
      "348 380\n",
      "348 381\n",
      "348 382\n",
      "348 383\n",
      "348 384\n",
      "348 385\n",
      "348 386\n",
      "348 387\n",
      "348 388\n",
      "348 389\n",
      "348 390\n",
      "348 391\n",
      "348 392\n",
      "348 393\n",
      "348 394\n",
      "348 395\n",
      "348 396\n",
      "348 397\n",
      "348 398\n",
      "348 399\n",
      "348 400\n",
      "348 401\n",
      "348 402\n",
      "348 403\n",
      "348 404\n",
      "348 405\n",
      "348 406\n",
      "348 407\n",
      "348 408\n",
      "348 409\n",
      "348 410\n",
      "348 411\n",
      "348 412\n",
      "348 413\n",
      "348 414\n",
      "348 415\n",
      "348 416\n",
      "348 417\n",
      "348 418\n",
      "348 419\n",
      "348 420\n",
      "348 421\n",
      "348 422\n",
      "348 423\n",
      "348 424\n",
      "348 425\n",
      "348 426\n",
      "348 427\n",
      "348 428\n",
      "348 429\n",
      "348 430\n",
      "348 431\n",
      "348 432\n",
      "348 433\n",
      "348 434\n",
      "348 435\n",
      "348 436\n",
      "348 437\n",
      "348 438\n",
      "348 439\n",
      "348 440\n",
      "348 441\n",
      "348 442\n",
      "348 443\n",
      "349 350\n",
      "349 351\n",
      "349 352\n",
      "349 353\n",
      "349 354\n",
      "349 355\n",
      "349 356\n",
      "349 357\n",
      "349 358\n",
      "349 359\n",
      "349 360\n",
      "349 361\n",
      "349 362\n",
      "349 363\n",
      "349 364\n",
      "349 365\n",
      "349 366\n",
      "349 367\n",
      "349 368\n",
      "349 369\n",
      "349 370\n",
      "349 371\n",
      "349 372\n",
      "349 373\n",
      "349 374\n",
      "349 375\n",
      "349 376\n",
      "349 377\n",
      "349 378\n",
      "349 379\n",
      "349 380\n",
      "349 381\n",
      "349 382\n",
      "349 383\n",
      "349 384\n",
      "349 385\n",
      "349 386\n",
      "349 387\n",
      "349 388\n",
      "349 389\n",
      "349 390\n",
      "349 391\n",
      "349 392\n",
      "349 393\n",
      "349 394\n",
      "349 395\n",
      "349 396\n",
      "349 397\n",
      "349 398\n",
      "349 399\n",
      "349 400\n",
      "349 401\n",
      "349 402\n",
      "349 403\n",
      "349 404\n",
      "349 405\n",
      "349 406\n",
      "349 407\n",
      "349 408\n",
      "349 409\n",
      "349 410\n",
      "349 411\n",
      "349 412\n",
      "349 413\n",
      "349 414\n",
      "349 415\n",
      "349 416\n",
      "349 417\n",
      "349 418\n",
      "349 419\n",
      "349 420\n",
      "349 421\n",
      "349 422\n",
      "349 423\n",
      "349 424\n",
      "349 425\n",
      "349 426\n",
      "349 427\n",
      "349 428\n",
      "349 429\n",
      "349 430\n",
      "349 431\n",
      "349 432\n",
      "349 433\n",
      "349 434\n",
      "349 435\n",
      "349 436\n",
      "349 437\n",
      "349 438\n",
      "349 439\n",
      "349 440\n",
      "349 441\n",
      "349 442\n",
      "349 443\n",
      "350 351\n",
      "350 352\n",
      "350 353\n",
      "350 354\n",
      "350 355\n",
      "350 356\n",
      "350 357\n",
      "350 358\n",
      "350 359\n",
      "350 360\n",
      "350 361\n",
      "350 362\n",
      "350 363\n",
      "350 364\n",
      "350 365\n",
      "350 366\n",
      "350 367\n",
      "350 368\n",
      "350 369\n",
      "350 370\n",
      "350 371\n",
      "350 372\n",
      "350 373\n",
      "350 374\n",
      "350 375\n",
      "350 376\n",
      "350 377\n",
      "350 378\n",
      "350 379\n",
      "350 380\n",
      "350 381\n",
      "350 382\n",
      "350 383\n",
      "350 384\n",
      "350 385\n",
      "350 386\n",
      "350 387\n",
      "350 388\n",
      "350 389\n",
      "350 390\n",
      "350 391\n",
      "350 392\n",
      "350 393\n",
      "350 394\n",
      "350 395\n",
      "350 396\n",
      "350 397\n",
      "350 398\n",
      "350 399\n",
      "350 400\n",
      "350 401\n",
      "350 402\n",
      "350 403\n",
      "350 404\n",
      "350 405\n",
      "350 406\n",
      "350 407\n",
      "350 408\n",
      "350 409\n",
      "350 410\n",
      "350 411\n",
      "350 412\n",
      "350 413\n",
      "350 414\n",
      "350 415\n",
      "350 416\n",
      "350 417\n",
      "350 418\n",
      "350 419\n",
      "350 420\n",
      "350 421\n",
      "350 422\n",
      "350 423\n",
      "350 424\n",
      "350 425\n",
      "350 426\n",
      "350 427\n",
      "350 428\n",
      "350 429\n",
      "350 430\n",
      "350 431\n",
      "350 432\n",
      "350 433\n",
      "350 434\n",
      "350 435\n",
      "350 436\n",
      "350 437\n",
      "350 438\n",
      "350 439\n",
      "350 440\n",
      "350 441\n",
      "350 442\n",
      "350 443\n",
      "351 352\n",
      "351 353\n",
      "351 354\n",
      "351 355\n",
      "351 356\n",
      "351 357\n",
      "351 358\n",
      "351 359\n",
      "351 360\n",
      "351 361\n",
      "351 362\n",
      "351 363\n",
      "351 364\n",
      "351 365\n",
      "351 366\n",
      "351 367\n",
      "351 368\n",
      "351 369\n",
      "351 370\n",
      "351 371\n",
      "351 372\n",
      "351 373\n",
      "351 374\n",
      "351 375\n",
      "351 376\n",
      "351 377\n",
      "351 378\n",
      "351 379\n",
      "351 380\n",
      "351 381\n",
      "351 382\n",
      "351 383\n",
      "351 384\n",
      "351 385\n",
      "351 386\n",
      "351 387\n",
      "351 388\n",
      "351 389\n",
      "351 390\n",
      "351 391\n",
      "351 392\n",
      "351 393\n",
      "351 394\n",
      "351 395\n",
      "351 396\n",
      "351 397\n",
      "351 398\n",
      "351 399\n",
      "351 400\n",
      "351 401\n",
      "351 402\n",
      "351 403\n",
      "351 404\n",
      "351 405\n",
      "351 406\n",
      "351 407\n",
      "351 408\n",
      "351 409\n",
      "351 410\n",
      "351 411\n",
      "351 412\n",
      "351 413\n",
      "351 414\n",
      "351 415\n",
      "351 416\n",
      "351 417\n",
      "351 418\n",
      "351 419\n",
      "351 420\n",
      "351 421\n",
      "351 422\n",
      "351 423\n",
      "351 424\n",
      "351 425\n",
      "351 426\n",
      "351 427\n",
      "351 428\n",
      "351 429\n",
      "351 430\n",
      "351 431\n",
      "351 432\n",
      "351 433\n",
      "351 434\n",
      "351 435\n",
      "351 436\n",
      "351 437\n",
      "351 438\n",
      "351 439\n",
      "351 440\n",
      "351 441\n",
      "351 442\n",
      "351 443\n",
      "352 353\n",
      "352 354\n",
      "352 355\n",
      "352 356\n",
      "352 357\n",
      "352 358\n",
      "352 359\n",
      "352 360\n",
      "352 361\n",
      "352 362\n",
      "352 363\n",
      "352 364\n",
      "352 365\n",
      "352 366\n",
      "352 367\n",
      "352 368\n",
      "352 369\n",
      "352 370\n",
      "352 371\n",
      "352 372\n",
      "352 373\n",
      "352 374\n",
      "352 375\n",
      "352 376\n",
      "352 377\n",
      "352 378\n",
      "352 379\n",
      "352 380\n",
      "352 381\n",
      "352 382\n",
      "352 383\n",
      "352 384\n",
      "352 385\n",
      "352 386\n",
      "352 387\n",
      "352 388\n",
      "352 389\n",
      "352 390\n",
      "352 391\n",
      "352 392\n",
      "352 393\n",
      "352 394\n",
      "352 395\n",
      "352 396\n",
      "352 397\n",
      "352 398\n",
      "352 399\n",
      "352 400\n",
      "352 401\n",
      "352 402\n",
      "352 403\n",
      "352 404\n",
      "352 405\n",
      "352 406\n",
      "352 407\n",
      "352 408\n",
      "352 409\n",
      "352 410\n",
      "352 411\n",
      "352 412\n",
      "352 413\n",
      "352 414\n",
      "352 415\n",
      "352 416\n",
      "352 417\n",
      "352 418\n",
      "352 419\n",
      "352 420\n",
      "352 421\n",
      "352 422\n",
      "352 423\n",
      "352 424\n",
      "352 425\n",
      "352 426\n",
      "352 427\n",
      "352 428\n",
      "352 429\n",
      "352 430\n",
      "352 431\n",
      "352 432\n",
      "352 433\n",
      "352 434\n",
      "352 435\n",
      "352 436\n",
      "352 437\n",
      "352 438\n",
      "352 439\n",
      "352 440\n",
      "352 441\n",
      "352 442\n",
      "352 443\n",
      "353 354\n",
      "353 355\n",
      "353 356\n",
      "353 357\n",
      "353 358\n",
      "353 359\n",
      "353 360\n",
      "353 361\n",
      "353 362\n",
      "353 363\n",
      "353 364\n",
      "353 365\n",
      "353 366\n",
      "353 367\n",
      "353 368\n",
      "353 369\n",
      "353 370\n",
      "353 371\n",
      "353 372\n",
      "353 373\n",
      "353 374\n",
      "353 375\n",
      "353 376\n",
      "353 377\n",
      "353 378\n",
      "353 379\n",
      "353 380\n",
      "353 381\n",
      "353 382\n",
      "353 383\n",
      "353 384\n",
      "353 385\n",
      "353 386\n",
      "353 387\n",
      "353 388\n",
      "353 389\n",
      "353 390\n",
      "353 391\n",
      "353 392\n",
      "353 393\n",
      "353 394\n",
      "353 395\n",
      "353 396\n",
      "353 397\n",
      "353 398\n",
      "353 399\n",
      "353 400\n",
      "353 401\n",
      "353 402\n",
      "353 403\n",
      "353 404\n",
      "353 405\n",
      "353 406\n",
      "353 407\n",
      "353 408\n",
      "353 409\n",
      "353 410\n",
      "353 411\n",
      "353 412\n",
      "353 413\n",
      "353 414\n",
      "353 415\n",
      "353 416\n",
      "353 417\n",
      "353 418\n",
      "353 419\n",
      "353 420\n",
      "353 421\n",
      "353 422\n",
      "353 423\n",
      "353 424\n",
      "353 425\n",
      "353 426\n",
      "353 427\n",
      "353 428\n",
      "353 429\n",
      "353 430\n",
      "353 431\n",
      "353 432\n",
      "353 433\n",
      "353 434\n",
      "353 435\n",
      "353 436\n",
      "353 437\n",
      "353 438\n",
      "353 439\n",
      "353 440\n",
      "353 441\n",
      "353 442\n",
      "353 443\n",
      "354 355\n",
      "354 356\n",
      "354 357\n",
      "354 358\n",
      "354 359\n",
      "354 360\n",
      "354 361\n",
      "354 362\n",
      "354 363\n",
      "354 364\n",
      "354 365\n",
      "354 366\n",
      "354 367\n",
      "354 368\n",
      "354 369\n",
      "354 370\n",
      "354 371\n",
      "354 372\n",
      "354 373\n",
      "354 374\n",
      "354 375\n",
      "354 376\n",
      "354 377\n",
      "354 378\n",
      "354 379\n",
      "354 380\n",
      "354 381\n",
      "354 382\n",
      "354 383\n",
      "354 384\n",
      "354 385\n",
      "354 386\n",
      "354 387\n",
      "354 388\n",
      "354 389\n",
      "354 390\n",
      "354 391\n",
      "354 392\n",
      "354 393\n",
      "354 394\n",
      "354 395\n",
      "354 396\n",
      "354 397\n",
      "354 398\n",
      "354 399\n",
      "354 400\n",
      "354 401\n",
      "354 402\n",
      "354 403\n",
      "354 404\n",
      "354 405\n",
      "354 406\n",
      "354 407\n",
      "354 408\n",
      "354 409\n",
      "354 410\n",
      "354 411\n",
      "354 412\n",
      "354 413\n",
      "354 414\n",
      "354 415\n",
      "354 416\n",
      "354 417\n",
      "354 418\n",
      "354 419\n",
      "354 420\n",
      "354 421\n",
      "354 422\n",
      "354 423\n",
      "354 424\n",
      "354 425\n",
      "354 426\n",
      "354 427\n",
      "354 428\n",
      "354 429\n",
      "354 430\n",
      "354 431\n",
      "354 432\n",
      "354 433\n",
      "354 434\n",
      "354 435\n",
      "354 436\n",
      "354 437\n",
      "354 438\n",
      "354 439\n",
      "354 440\n",
      "354 441\n",
      "354 442\n",
      "354 443\n",
      "355 356\n",
      "355 357\n",
      "355 358\n",
      "355 359\n",
      "355 360\n",
      "355 361\n",
      "355 362\n",
      "355 363\n",
      "355 364\n",
      "355 365\n",
      "355 366\n",
      "355 367\n",
      "355 368\n",
      "355 369\n",
      "355 370\n",
      "355 371\n",
      "355 372\n",
      "355 373\n",
      "355 374\n",
      "355 375\n",
      "355 376\n",
      "355 377\n",
      "355 378\n",
      "355 379\n",
      "355 380\n",
      "355 381\n",
      "355 382\n",
      "355 383\n",
      "355 384\n",
      "355 385\n",
      "355 386\n",
      "355 387\n",
      "355 388\n",
      "355 389\n",
      "355 390\n",
      "355 391\n",
      "355 392\n",
      "355 393\n",
      "355 394\n",
      "355 395\n",
      "355 396\n",
      "355 397\n",
      "355 398\n",
      "355 399\n",
      "355 400\n",
      "355 401\n",
      "355 402\n",
      "355 403\n",
      "355 404\n",
      "355 405\n",
      "355 406\n",
      "355 407\n",
      "355 408\n",
      "355 409\n",
      "355 410\n",
      "355 411\n",
      "355 412\n",
      "355 413\n",
      "355 414\n",
      "355 415\n",
      "355 416\n",
      "355 417\n",
      "355 418\n",
      "355 419\n",
      "355 420\n",
      "355 421\n",
      "355 422\n",
      "355 423\n",
      "355 424\n",
      "355 425\n",
      "355 426\n",
      "355 427\n",
      "355 428\n",
      "355 429\n",
      "355 430\n",
      "355 431\n",
      "355 432\n",
      "355 433\n",
      "355 434\n",
      "355 435\n",
      "355 436\n",
      "355 437\n",
      "355 438\n",
      "355 439\n",
      "355 440\n",
      "355 441\n",
      "355 442\n",
      "355 443\n",
      "356 357\n",
      "356 358\n",
      "356 359\n",
      "356 360\n",
      "356 361\n",
      "356 362\n",
      "356 363\n",
      "356 364\n",
      "356 365\n",
      "356 366\n",
      "356 367\n",
      "356 368\n",
      "356 369\n",
      "356 370\n",
      "356 371\n",
      "356 372\n",
      "356 373\n",
      "356 374\n",
      "356 375\n",
      "356 376\n",
      "356 377\n",
      "356 378\n",
      "356 379\n",
      "356 380\n",
      "356 381\n",
      "356 382\n",
      "356 383\n",
      "356 384\n",
      "356 385\n",
      "356 386\n",
      "356 387\n",
      "356 388\n",
      "356 389\n",
      "356 390\n",
      "356 391\n",
      "356 392\n",
      "356 393\n",
      "356 394\n",
      "356 395\n",
      "356 396\n",
      "356 397\n",
      "356 398\n",
      "356 399\n",
      "356 400\n",
      "356 401\n",
      "356 402\n",
      "356 403\n",
      "356 404\n",
      "356 405\n",
      "356 406\n",
      "356 407\n",
      "356 408\n",
      "356 409\n",
      "356 410\n",
      "356 411\n",
      "356 412\n",
      "356 413\n",
      "356 414\n",
      "356 415\n",
      "356 416\n",
      "356 417\n",
      "356 418\n",
      "356 419\n",
      "356 420\n",
      "356 421\n",
      "356 422\n",
      "356 423\n",
      "356 424\n",
      "356 425\n",
      "356 426\n",
      "356 427\n",
      "356 428\n",
      "356 429\n",
      "356 430\n",
      "356 431\n",
      "356 432\n",
      "356 433\n",
      "356 434\n",
      "356 435\n",
      "356 436\n",
      "356 437\n",
      "356 438\n",
      "356 439\n",
      "356 440\n",
      "356 441\n",
      "356 442\n",
      "356 443\n",
      "357 358\n",
      "357 359\n",
      "357 360\n",
      "357 361\n",
      "357 362\n",
      "357 363\n",
      "357 364\n",
      "357 365\n",
      "357 366\n",
      "357 367\n",
      "357 368\n",
      "357 369\n",
      "357 370\n",
      "357 371\n",
      "357 372\n",
      "357 373\n",
      "357 374\n",
      "357 375\n",
      "357 376\n",
      "357 377\n",
      "357 378\n",
      "357 379\n",
      "357 380\n",
      "357 381\n",
      "357 382\n",
      "357 383\n",
      "357 384\n",
      "357 385\n",
      "357 386\n",
      "357 387\n",
      "357 388\n",
      "357 389\n",
      "357 390\n",
      "357 391\n",
      "357 392\n",
      "357 393\n",
      "357 394\n",
      "357 395\n",
      "357 396\n",
      "357 397\n",
      "357 398\n",
      "357 399\n",
      "357 400\n",
      "357 401\n",
      "357 402\n",
      "357 403\n",
      "357 404\n",
      "357 405\n",
      "357 406\n",
      "357 407\n",
      "357 408\n",
      "357 409\n",
      "357 410\n",
      "357 411\n",
      "357 412\n",
      "357 413\n",
      "357 414\n",
      "357 415\n",
      "357 416\n",
      "357 417\n",
      "357 418\n",
      "357 419\n",
      "357 420\n",
      "357 421\n",
      "357 422\n",
      "357 423\n",
      "357 424\n",
      "357 425\n",
      "357 426\n",
      "357 427\n",
      "357 428\n",
      "357 429\n",
      "357 430\n",
      "357 431\n",
      "357 432\n",
      "357 433\n",
      "357 434\n",
      "357 435\n",
      "357 436\n",
      "357 437\n",
      "357 438\n",
      "357 439\n",
      "357 440\n",
      "357 441\n",
      "357 442\n",
      "357 443\n",
      "358 359\n",
      "358 360\n",
      "358 361\n",
      "358 362\n",
      "358 363\n",
      "358 364\n",
      "358 365\n",
      "358 366\n",
      "358 367\n",
      "358 368\n",
      "358 369\n",
      "358 370\n",
      "358 371\n",
      "358 372\n",
      "358 373\n",
      "358 374\n",
      "358 375\n",
      "358 376\n",
      "358 377\n",
      "358 378\n",
      "358 379\n",
      "358 380\n",
      "358 381\n",
      "358 382\n",
      "358 383\n",
      "358 384\n",
      "358 385\n",
      "358 386\n",
      "358 387\n",
      "358 388\n",
      "358 389\n",
      "358 390\n",
      "358 391\n",
      "358 392\n",
      "358 393\n",
      "358 394\n",
      "358 395\n",
      "358 396\n",
      "358 397\n",
      "358 398\n",
      "358 399\n",
      "358 400\n",
      "358 401\n",
      "358 402\n",
      "358 403\n",
      "358 404\n",
      "358 405\n",
      "358 406\n",
      "358 407\n",
      "358 408\n",
      "358 409\n",
      "358 410\n",
      "358 411\n",
      "358 412\n",
      "358 413\n",
      "358 414\n",
      "358 415\n",
      "358 416\n",
      "358 417\n",
      "358 418\n",
      "358 419\n",
      "358 420\n",
      "358 421\n",
      "358 422\n",
      "358 423\n",
      "358 424\n",
      "358 425\n",
      "358 426\n",
      "358 427\n",
      "358 428\n",
      "358 429\n",
      "358 430\n",
      "358 431\n",
      "358 432\n",
      "358 433\n",
      "358 434\n",
      "358 435\n",
      "358 436\n",
      "358 437\n",
      "358 438\n",
      "358 439\n",
      "358 440\n",
      "358 441\n",
      "358 442\n",
      "358 443\n",
      "359 360\n",
      "359 361\n",
      "359 362\n",
      "359 363\n",
      "359 364\n",
      "359 365\n",
      "359 366\n",
      "359 367\n",
      "359 368\n",
      "359 369\n",
      "359 370\n",
      "359 371\n",
      "359 372\n",
      "359 373\n",
      "359 374\n",
      "359 375\n",
      "359 376\n",
      "359 377\n",
      "359 378\n",
      "359 379\n",
      "359 380\n",
      "359 381\n",
      "359 382\n",
      "359 383\n",
      "359 384\n",
      "359 385\n",
      "359 386\n",
      "359 387\n",
      "359 388\n",
      "359 389\n",
      "359 390\n",
      "359 391\n",
      "359 392\n",
      "359 393\n",
      "359 394\n",
      "359 395\n",
      "359 396\n",
      "359 397\n",
      "359 398\n",
      "359 399\n",
      "359 400\n",
      "359 401\n",
      "359 402\n",
      "359 403\n",
      "359 404\n",
      "359 405\n",
      "359 406\n",
      "359 407\n",
      "359 408\n",
      "359 409\n",
      "359 410\n",
      "359 411\n",
      "359 412\n",
      "359 413\n",
      "359 414\n",
      "359 415\n",
      "359 416\n",
      "359 417\n",
      "359 418\n",
      "359 419\n",
      "359 420\n",
      "359 421\n",
      "359 422\n",
      "359 423\n",
      "359 424\n",
      "359 425\n",
      "359 426\n",
      "359 427\n",
      "359 428\n",
      "359 429\n",
      "359 430\n",
      "359 431\n",
      "359 432\n",
      "359 433\n",
      "359 434\n",
      "359 435\n",
      "359 436\n",
      "359 437\n",
      "359 438\n",
      "359 439\n",
      "359 440\n",
      "359 441\n",
      "359 442\n",
      "359 443\n",
      "360 361\n",
      "360 362\n",
      "360 363\n",
      "360 364\n",
      "360 365\n",
      "360 366\n",
      "360 367\n",
      "360 368\n",
      "360 369\n",
      "360 370\n",
      "360 371\n",
      "360 372\n",
      "360 373\n",
      "360 374\n",
      "360 375\n",
      "360 376\n",
      "360 377\n",
      "360 378\n",
      "360 379\n",
      "360 380\n",
      "360 381\n",
      "360 382\n",
      "360 383\n",
      "360 384\n",
      "360 385\n",
      "360 386\n",
      "360 387\n",
      "360 388\n",
      "360 389\n",
      "360 390\n",
      "360 391\n",
      "360 392\n",
      "360 393\n",
      "360 394\n",
      "360 395\n",
      "360 396\n",
      "360 397\n",
      "360 398\n",
      "360 399\n",
      "360 400\n",
      "360 401\n",
      "360 402\n",
      "360 403\n",
      "360 404\n",
      "360 405\n",
      "360 406\n",
      "360 407\n",
      "360 408\n",
      "360 409\n",
      "360 410\n",
      "360 411\n",
      "360 412\n",
      "360 413\n",
      "360 414\n",
      "360 415\n",
      "360 416\n",
      "360 417\n",
      "360 418\n",
      "360 419\n",
      "360 420\n",
      "360 421\n",
      "360 422\n",
      "360 423\n",
      "360 424\n",
      "360 425\n",
      "360 426\n",
      "360 427\n",
      "360 428\n",
      "360 429\n",
      "360 430\n",
      "360 431\n",
      "360 432\n",
      "360 433\n",
      "360 434\n",
      "360 435\n",
      "360 436\n",
      "360 437\n",
      "360 438\n",
      "360 439\n",
      "360 440\n",
      "360 441\n",
      "360 442\n",
      "360 443\n",
      "361 362\n",
      "361 363\n",
      "361 364\n",
      "361 365\n",
      "361 366\n",
      "361 367\n",
      "361 368\n",
      "361 369\n",
      "361 370\n",
      "361 371\n",
      "361 372\n",
      "361 373\n",
      "361 374\n",
      "361 375\n",
      "361 376\n",
      "361 377\n",
      "361 378\n",
      "361 379\n",
      "361 380\n",
      "361 381\n",
      "361 382\n",
      "361 383\n",
      "361 384\n",
      "361 385\n",
      "361 386\n",
      "361 387\n",
      "361 388\n",
      "361 389\n",
      "361 390\n",
      "361 391\n",
      "361 392\n",
      "361 393\n",
      "361 394\n",
      "361 395\n",
      "361 396\n",
      "361 397\n",
      "361 398\n",
      "361 399\n",
      "361 400\n",
      "361 401\n",
      "361 402\n",
      "361 403\n",
      "361 404\n",
      "361 405\n",
      "361 406\n",
      "361 407\n",
      "361 408\n",
      "361 409\n",
      "361 410\n",
      "361 411\n",
      "361 412\n",
      "361 413\n",
      "361 414\n",
      "361 415\n",
      "361 416\n",
      "361 417\n",
      "361 418\n",
      "361 419\n",
      "361 420\n",
      "361 421\n",
      "361 422\n",
      "361 423\n",
      "361 424\n",
      "361 425\n",
      "361 426\n",
      "361 427\n",
      "361 428\n",
      "361 429\n",
      "361 430\n",
      "361 431\n",
      "361 432\n",
      "361 433\n",
      "361 434\n",
      "361 435\n",
      "361 436\n",
      "361 437\n",
      "361 438\n",
      "361 439\n",
      "361 440\n",
      "361 441\n",
      "361 442\n",
      "361 443\n",
      "362 363\n",
      "362 364\n",
      "362 365\n",
      "362 366\n",
      "362 367\n",
      "362 368\n",
      "362 369\n",
      "362 370\n",
      "362 371\n",
      "362 372\n",
      "362 373\n",
      "362 374\n",
      "362 375\n",
      "362 376\n",
      "362 377\n",
      "362 378\n",
      "362 379\n",
      "362 380\n",
      "362 381\n",
      "362 382\n",
      "362 383\n",
      "362 384\n",
      "362 385\n",
      "362 386\n",
      "362 387\n",
      "362 388\n",
      "362 389\n",
      "362 390\n",
      "362 391\n",
      "362 392\n",
      "362 393\n",
      "362 394\n",
      "362 395\n",
      "362 396\n",
      "362 397\n",
      "362 398\n",
      "362 399\n",
      "362 400\n",
      "362 401\n",
      "362 402\n",
      "362 403\n",
      "362 404\n",
      "362 405\n",
      "362 406\n",
      "362 407\n",
      "362 408\n",
      "362 409\n",
      "362 410\n",
      "362 411\n",
      "362 412\n",
      "362 413\n",
      "362 414\n",
      "362 415\n",
      "362 416\n",
      "362 417\n",
      "362 418\n",
      "362 419\n",
      "362 420\n",
      "362 421\n",
      "362 422\n",
      "362 423\n",
      "362 424\n",
      "362 425\n",
      "362 426\n",
      "362 427\n",
      "362 428\n",
      "362 429\n",
      "362 430\n",
      "362 431\n",
      "362 432\n",
      "362 433\n",
      "362 434\n",
      "362 435\n",
      "362 436\n",
      "362 437\n",
      "362 438\n",
      "362 439\n",
      "362 440\n",
      "362 441\n",
      "362 442\n",
      "362 443\n",
      "363 364\n",
      "363 365\n",
      "363 366\n",
      "363 367\n",
      "363 368\n",
      "363 369\n",
      "363 370\n",
      "363 371\n",
      "363 372\n",
      "363 373\n",
      "363 374\n",
      "363 375\n",
      "363 376\n",
      "363 377\n",
      "363 378\n",
      "363 379\n",
      "363 380\n",
      "363 381\n",
      "363 382\n",
      "363 383\n",
      "363 384\n",
      "363 385\n",
      "363 386\n",
      "363 387\n",
      "363 388\n",
      "363 389\n",
      "363 390\n",
      "363 391\n",
      "363 392\n",
      "363 393\n",
      "363 394\n",
      "363 395\n",
      "363 396\n",
      "363 397\n",
      "363 398\n",
      "363 399\n",
      "363 400\n",
      "363 401\n",
      "363 402\n",
      "363 403\n",
      "363 404\n",
      "363 405\n",
      "363 406\n",
      "363 407\n",
      "363 408\n",
      "363 409\n",
      "363 410\n",
      "363 411\n",
      "363 412\n",
      "363 413\n",
      "363 414\n",
      "363 415\n",
      "363 416\n",
      "363 417\n",
      "363 418\n",
      "363 419\n",
      "363 420\n",
      "363 421\n",
      "363 422\n",
      "363 423\n",
      "363 424\n",
      "363 425\n",
      "363 426\n",
      "363 427\n",
      "363 428\n",
      "363 429\n",
      "363 430\n",
      "363 431\n",
      "363 432\n",
      "363 433\n",
      "363 434\n",
      "363 435\n",
      "363 436\n",
      "363 437\n",
      "363 438\n",
      "363 439\n",
      "363 440\n",
      "363 441\n",
      "363 442\n",
      "363 443\n",
      "364 365\n",
      "364 366\n",
      "364 367\n",
      "364 368\n",
      "364 369\n",
      "364 370\n",
      "364 371\n",
      "364 372\n",
      "364 373\n",
      "364 374\n",
      "364 375\n",
      "364 376\n",
      "364 377\n",
      "364 378\n",
      "364 379\n",
      "364 380\n",
      "364 381\n",
      "364 382\n",
      "364 383\n",
      "364 384\n",
      "364 385\n",
      "364 386\n",
      "364 387\n",
      "364 388\n",
      "364 389\n",
      "364 390\n",
      "364 391\n",
      "364 392\n",
      "364 393\n",
      "364 394\n",
      "364 395\n",
      "364 396\n",
      "364 397\n",
      "364 398\n",
      "364 399\n",
      "364 400\n",
      "364 401\n",
      "364 402\n",
      "364 403\n",
      "364 404\n",
      "364 405\n",
      "364 406\n",
      "364 407\n",
      "364 408\n",
      "364 409\n",
      "364 410\n",
      "364 411\n",
      "364 412\n",
      "364 413\n",
      "364 414\n",
      "364 415\n",
      "364 416\n",
      "364 417\n",
      "364 418\n",
      "364 419\n",
      "364 420\n",
      "364 421\n",
      "364 422\n",
      "364 423\n",
      "364 424\n",
      "364 425\n",
      "364 426\n",
      "364 427\n",
      "364 428\n",
      "364 429\n",
      "364 430\n",
      "364 431\n",
      "364 432\n",
      "364 433\n",
      "364 434\n",
      "364 435\n",
      "364 436\n",
      "364 437\n",
      "364 438\n",
      "364 439\n",
      "364 440\n",
      "364 441\n",
      "364 442\n",
      "364 443\n",
      "365 366\n",
      "365 367\n",
      "365 368\n",
      "365 369\n",
      "365 370\n",
      "365 371\n",
      "365 372\n",
      "365 373\n",
      "365 374\n",
      "365 375\n",
      "365 376\n",
      "365 377\n",
      "365 378\n",
      "365 379\n",
      "365 380\n",
      "365 381\n",
      "365 382\n",
      "365 383\n",
      "365 384\n",
      "365 385\n",
      "365 386\n",
      "365 387\n",
      "365 388\n",
      "365 389\n",
      "365 390\n",
      "365 391\n",
      "365 392\n",
      "365 393\n",
      "365 394\n",
      "365 395\n",
      "365 396\n",
      "365 397\n",
      "365 398\n",
      "365 399\n",
      "365 400\n",
      "365 401\n",
      "365 402\n",
      "365 403\n",
      "365 404\n",
      "365 405\n",
      "365 406\n",
      "365 407\n",
      "365 408\n",
      "365 409\n",
      "365 410\n",
      "365 411\n",
      "365 412\n",
      "365 413\n",
      "365 414\n",
      "365 415\n",
      "365 416\n",
      "365 417\n",
      "365 418\n",
      "365 419\n",
      "365 420\n",
      "365 421\n",
      "365 422\n",
      "365 423\n",
      "365 424\n",
      "365 425\n",
      "365 426\n",
      "365 427\n",
      "365 428\n",
      "365 429\n",
      "365 430\n",
      "365 431\n",
      "365 432\n",
      "365 433\n",
      "365 434\n",
      "365 435\n",
      "365 436\n",
      "365 437\n",
      "365 438\n",
      "365 439\n",
      "365 440\n",
      "365 441\n",
      "365 442\n",
      "365 443\n",
      "366 367\n",
      "366 368\n",
      "366 369\n",
      "366 370\n",
      "366 371\n",
      "366 372\n",
      "366 373\n",
      "366 374\n",
      "366 375\n",
      "366 376\n",
      "366 377\n",
      "366 378\n",
      "366 379\n",
      "366 380\n",
      "366 381\n",
      "366 382\n",
      "366 383\n",
      "366 384\n",
      "366 385\n",
      "366 386\n",
      "366 387\n",
      "366 388\n",
      "366 389\n",
      "366 390\n",
      "366 391\n",
      "366 392\n",
      "366 393\n",
      "366 394\n",
      "366 395\n",
      "366 396\n",
      "366 397\n",
      "366 398\n",
      "366 399\n",
      "366 400\n",
      "366 401\n",
      "366 402\n",
      "366 403\n",
      "366 404\n",
      "366 405\n",
      "366 406\n",
      "366 407\n",
      "366 408\n",
      "366 409\n",
      "366 410\n",
      "366 411\n",
      "366 412\n",
      "366 413\n",
      "366 414\n",
      "366 415\n",
      "366 416\n",
      "366 417\n",
      "366 418\n",
      "366 419\n",
      "366 420\n",
      "366 421\n",
      "366 422\n",
      "366 423\n",
      "366 424\n",
      "366 425\n",
      "366 426\n",
      "366 427\n",
      "366 428\n",
      "366 429\n",
      "366 430\n",
      "366 431\n",
      "366 432\n",
      "366 433\n",
      "366 434\n",
      "366 435\n",
      "366 436\n",
      "366 437\n",
      "366 438\n",
      "366 439\n",
      "366 440\n",
      "366 441\n",
      "366 442\n",
      "366 443\n",
      "367 368\n",
      "367 369\n",
      "367 370\n",
      "367 371\n",
      "367 372\n",
      "367 373\n",
      "367 374\n",
      "367 375\n",
      "367 376\n",
      "367 377\n",
      "367 378\n",
      "367 379\n",
      "367 380\n",
      "367 381\n",
      "367 382\n",
      "367 383\n",
      "367 384\n",
      "367 385\n",
      "367 386\n",
      "367 387\n",
      "367 388\n",
      "367 389\n",
      "367 390\n",
      "367 391\n",
      "367 392\n",
      "367 393\n",
      "367 394\n",
      "367 395\n",
      "367 396\n",
      "367 397\n",
      "367 398\n",
      "367 399\n",
      "367 400\n",
      "367 401\n",
      "367 402\n",
      "367 403\n",
      "367 404\n",
      "367 405\n",
      "367 406\n",
      "367 407\n",
      "367 408\n",
      "367 409\n",
      "367 410\n",
      "367 411\n",
      "367 412\n",
      "367 413\n",
      "367 414\n",
      "367 415\n",
      "367 416\n",
      "367 417\n",
      "367 418\n",
      "367 419\n",
      "367 420\n",
      "367 421\n",
      "367 422\n",
      "367 423\n",
      "367 424\n",
      "367 425\n",
      "367 426\n",
      "367 427\n",
      "367 428\n",
      "367 429\n",
      "367 430\n",
      "367 431\n",
      "367 432\n",
      "367 433\n",
      "367 434\n",
      "367 435\n",
      "367 436\n",
      "367 437\n",
      "367 438\n",
      "367 439\n",
      "367 440\n",
      "367 441\n",
      "367 442\n",
      "367 443\n",
      "368 369\n",
      "368 370\n",
      "368 371\n",
      "368 372\n",
      "368 373\n",
      "368 374\n",
      "368 375\n",
      "368 376\n",
      "368 377\n",
      "368 378\n",
      "368 379\n",
      "368 380\n",
      "368 381\n",
      "368 382\n",
      "368 383\n",
      "368 384\n",
      "368 385\n",
      "368 386\n",
      "368 387\n",
      "368 388\n",
      "368 389\n",
      "368 390\n",
      "368 391\n",
      "368 392\n",
      "368 393\n",
      "368 394\n",
      "368 395\n",
      "368 396\n",
      "368 397\n",
      "368 398\n",
      "368 399\n",
      "368 400\n",
      "368 401\n",
      "368 402\n",
      "368 403\n",
      "368 404\n",
      "368 405\n",
      "368 406\n",
      "368 407\n",
      "368 408\n",
      "368 409\n",
      "368 410\n",
      "368 411\n",
      "368 412\n",
      "368 413\n",
      "368 414\n",
      "368 415\n",
      "368 416\n",
      "368 417\n",
      "368 418\n",
      "368 419\n",
      "368 420\n",
      "368 421\n",
      "368 422\n",
      "368 423\n",
      "368 424\n",
      "368 425\n",
      "368 426\n",
      "368 427\n",
      "368 428\n",
      "368 429\n",
      "368 430\n",
      "368 431\n",
      "368 432\n",
      "368 433\n",
      "368 434\n",
      "368 435\n",
      "368 436\n",
      "368 437\n",
      "368 438\n",
      "368 439\n",
      "368 440\n",
      "368 441\n",
      "368 442\n",
      "368 443\n",
      "369 370\n",
      "369 371\n",
      "369 372\n",
      "369 373\n",
      "369 374\n",
      "369 375\n",
      "369 376\n",
      "369 377\n",
      "369 378\n",
      "369 379\n",
      "369 380\n",
      "369 381\n",
      "369 382\n",
      "369 383\n",
      "369 384\n",
      "369 385\n",
      "369 386\n",
      "369 387\n",
      "369 388\n",
      "369 389\n",
      "369 390\n",
      "369 391\n",
      "369 392\n",
      "369 393\n",
      "369 394\n",
      "369 395\n",
      "369 396\n",
      "369 397\n",
      "369 398\n",
      "369 399\n",
      "369 400\n",
      "369 401\n",
      "369 402\n",
      "369 403\n",
      "369 404\n",
      "369 405\n",
      "369 406\n",
      "369 407\n",
      "369 408\n",
      "369 409\n",
      "369 410\n",
      "369 411\n",
      "369 412\n",
      "369 413\n",
      "369 414\n",
      "369 415\n",
      "369 416\n",
      "369 417\n",
      "369 418\n",
      "369 419\n",
      "369 420\n",
      "369 421\n",
      "369 422\n",
      "369 423\n",
      "369 424\n",
      "369 425\n",
      "369 426\n",
      "369 427\n",
      "369 428\n",
      "369 429\n",
      "369 430\n",
      "369 431\n",
      "369 432\n",
      "369 433\n",
      "369 434\n",
      "369 435\n",
      "369 436\n",
      "369 437\n",
      "369 438\n",
      "369 439\n",
      "369 440\n",
      "369 441\n",
      "369 442\n",
      "369 443\n",
      "370 371\n",
      "370 372\n",
      "370 373\n",
      "370 374\n",
      "370 375\n",
      "370 376\n",
      "370 377\n",
      "370 378\n",
      "370 379\n",
      "370 380\n",
      "370 381\n",
      "370 382\n",
      "370 383\n",
      "370 384\n",
      "370 385\n",
      "370 386\n",
      "370 387\n",
      "370 388\n",
      "370 389\n",
      "370 390\n",
      "370 391\n",
      "370 392\n",
      "370 393\n",
      "370 394\n",
      "370 395\n",
      "370 396\n",
      "370 397\n",
      "370 398\n",
      "370 399\n",
      "370 400\n",
      "370 401\n",
      "370 402\n",
      "370 403\n",
      "370 404\n",
      "370 405\n",
      "370 406\n",
      "370 407\n",
      "370 408\n",
      "370 409\n",
      "370 410\n",
      "370 411\n",
      "370 412\n",
      "370 413\n",
      "370 414\n",
      "370 415\n",
      "370 416\n",
      "370 417\n",
      "370 418\n",
      "370 419\n",
      "370 420\n",
      "370 421\n",
      "370 422\n",
      "370 423\n",
      "370 424\n",
      "370 425\n",
      "370 426\n",
      "370 427\n",
      "370 428\n",
      "370 429\n",
      "370 430\n",
      "370 431\n",
      "370 432\n",
      "370 433\n",
      "370 434\n",
      "370 435\n",
      "370 436\n",
      "370 437\n",
      "370 438\n",
      "370 439\n",
      "370 440\n",
      "370 441\n",
      "370 442\n",
      "370 443\n",
      "371 372\n",
      "371 373\n",
      "371 374\n",
      "371 375\n",
      "371 376\n",
      "371 377\n",
      "371 378\n",
      "371 379\n",
      "371 380\n",
      "371 381\n",
      "371 382\n",
      "371 383\n",
      "371 384\n",
      "371 385\n",
      "371 386\n",
      "371 387\n",
      "371 388\n",
      "371 389\n",
      "371 390\n",
      "371 391\n",
      "371 392\n",
      "371 393\n",
      "371 394\n",
      "371 395\n",
      "371 396\n",
      "371 397\n",
      "371 398\n",
      "371 399\n",
      "371 400\n",
      "371 401\n",
      "371 402\n",
      "371 403\n",
      "371 404\n",
      "371 405\n",
      "371 406\n",
      "371 407\n",
      "371 408\n",
      "371 409\n",
      "371 410\n",
      "371 411\n",
      "371 412\n",
      "371 413\n",
      "371 414\n",
      "371 415\n",
      "371 416\n",
      "371 417\n",
      "371 418\n",
      "371 419\n",
      "371 420\n",
      "371 421\n",
      "371 422\n",
      "371 423\n",
      "371 424\n",
      "371 425\n",
      "371 426\n",
      "371 427\n",
      "371 428\n",
      "371 429\n",
      "371 430\n",
      "371 431\n",
      "371 432\n",
      "371 433\n",
      "371 434\n",
      "371 435\n",
      "371 436\n",
      "371 437\n",
      "371 438\n",
      "371 439\n",
      "371 440\n",
      "371 441\n",
      "371 442\n",
      "371 443\n",
      "372 373\n",
      "372 374\n",
      "372 375\n",
      "372 376\n",
      "372 377\n",
      "372 378\n",
      "372 379\n",
      "372 380\n",
      "372 381\n",
      "372 382\n",
      "372 383\n",
      "372 384\n",
      "372 385\n",
      "372 386\n",
      "372 387\n",
      "372 388\n",
      "372 389\n",
      "372 390\n",
      "372 391\n",
      "372 392\n",
      "372 393\n",
      "372 394\n",
      "372 395\n",
      "372 396\n",
      "372 397\n",
      "372 398\n",
      "372 399\n",
      "372 400\n",
      "372 401\n",
      "372 402\n",
      "372 403\n",
      "372 404\n",
      "372 405\n",
      "372 406\n",
      "372 407\n",
      "372 408\n",
      "372 409\n",
      "372 410\n",
      "372 411\n",
      "372 412\n",
      "372 413\n",
      "372 414\n",
      "372 415\n",
      "372 416\n",
      "372 417\n",
      "372 418\n",
      "372 419\n",
      "372 420\n",
      "372 421\n",
      "372 422\n",
      "372 423\n",
      "372 424\n",
      "372 425\n",
      "372 426\n",
      "372 427\n",
      "372 428\n",
      "372 429\n",
      "372 430\n",
      "372 431\n",
      "372 432\n",
      "372 433\n",
      "372 434\n",
      "372 435\n",
      "372 436\n",
      "372 437\n",
      "372 438\n",
      "372 439\n",
      "372 440\n",
      "372 441\n",
      "372 442\n",
      "372 443\n",
      "373 374\n",
      "373 375\n",
      "373 376\n",
      "373 377\n",
      "373 378\n",
      "373 379\n",
      "373 380\n",
      "373 381\n",
      "373 382\n",
      "373 383\n",
      "373 384\n",
      "373 385\n",
      "373 386\n",
      "373 387\n",
      "373 388\n",
      "373 389\n",
      "373 390\n",
      "373 391\n",
      "373 392\n",
      "373 393\n",
      "373 394\n",
      "373 395\n",
      "373 396\n",
      "373 397\n",
      "373 398\n",
      "373 399\n",
      "373 400\n",
      "373 401\n",
      "373 402\n",
      "373 403\n",
      "373 404\n",
      "373 405\n",
      "373 406\n",
      "373 407\n",
      "373 408\n",
      "373 409\n",
      "373 410\n",
      "373 411\n",
      "373 412\n",
      "373 413\n",
      "373 414\n",
      "373 415\n",
      "373 416\n",
      "373 417\n",
      "373 418\n",
      "373 419\n",
      "373 420\n",
      "373 421\n",
      "373 422\n",
      "373 423\n",
      "373 424\n",
      "373 425\n",
      "373 426\n",
      "373 427\n",
      "373 428\n",
      "373 429\n",
      "373 430\n",
      "373 431\n",
      "373 432\n",
      "373 433\n",
      "373 434\n",
      "373 435\n",
      "373 436\n",
      "373 437\n",
      "373 438\n",
      "373 439\n",
      "373 440\n",
      "373 441\n",
      "373 442\n",
      "373 443\n",
      "374 375\n",
      "374 376\n",
      "374 377\n",
      "374 378\n",
      "374 379\n",
      "374 380\n",
      "374 381\n",
      "374 382\n",
      "374 383\n",
      "374 384\n",
      "374 385\n",
      "374 386\n",
      "374 387\n",
      "374 388\n",
      "374 389\n",
      "374 390\n",
      "374 391\n",
      "374 392\n",
      "374 393\n",
      "374 394\n",
      "374 395\n",
      "374 396\n",
      "374 397\n",
      "374 398\n",
      "374 399\n",
      "374 400\n",
      "374 401\n",
      "374 402\n",
      "374 403\n",
      "374 404\n",
      "374 405\n",
      "374 406\n",
      "374 407\n",
      "374 408\n",
      "374 409\n",
      "374 410\n",
      "374 411\n",
      "374 412\n",
      "374 413\n",
      "374 414\n",
      "374 415\n",
      "374 416\n",
      "374 417\n",
      "374 418\n",
      "374 419\n",
      "374 420\n",
      "374 421\n",
      "374 422\n",
      "374 423\n",
      "374 424\n",
      "374 425\n",
      "374 426\n",
      "374 427\n",
      "374 428\n",
      "374 429\n",
      "374 430\n",
      "374 431\n",
      "374 432\n",
      "374 433\n",
      "374 434\n",
      "374 435\n",
      "374 436\n",
      "374 437\n",
      "374 438\n",
      "374 439\n",
      "374 440\n",
      "374 441\n",
      "374 442\n",
      "374 443\n",
      "375 376\n",
      "375 377\n",
      "375 378\n",
      "375 379\n",
      "375 380\n",
      "375 381\n",
      "375 382\n",
      "375 383\n",
      "375 384\n",
      "375 385\n",
      "375 386\n",
      "375 387\n",
      "375 388\n",
      "375 389\n",
      "375 390\n",
      "375 391\n",
      "375 392\n",
      "375 393\n",
      "375 394\n",
      "375 395\n",
      "375 396\n",
      "375 397\n",
      "375 398\n",
      "375 399\n",
      "375 400\n",
      "375 401\n",
      "375 402\n",
      "375 403\n",
      "375 404\n",
      "375 405\n",
      "375 406\n",
      "375 407\n",
      "375 408\n",
      "375 409\n",
      "375 410\n",
      "375 411\n",
      "375 412\n",
      "375 413\n",
      "375 414\n",
      "375 415\n",
      "375 416\n",
      "375 417\n",
      "375 418\n",
      "375 419\n",
      "375 420\n",
      "375 421\n",
      "375 422\n",
      "375 423\n",
      "375 424\n",
      "375 425\n",
      "375 426\n",
      "375 427\n",
      "375 428\n",
      "375 429\n",
      "375 430\n",
      "375 431\n",
      "375 432\n",
      "375 433\n",
      "375 434\n",
      "375 435\n",
      "375 436\n",
      "375 437\n",
      "375 438\n",
      "375 439\n",
      "375 440\n",
      "375 441\n",
      "375 442\n",
      "375 443\n",
      "376 377\n",
      "376 378\n",
      "376 379\n",
      "376 380\n",
      "376 381\n",
      "376 382\n",
      "376 383\n",
      "376 384\n",
      "376 385\n",
      "376 386\n",
      "376 387\n",
      "376 388\n",
      "376 389\n",
      "376 390\n",
      "376 391\n",
      "376 392\n",
      "376 393\n",
      "376 394\n",
      "376 395\n",
      "376 396\n",
      "376 397\n",
      "376 398\n",
      "376 399\n",
      "376 400\n",
      "376 401\n",
      "376 402\n",
      "376 403\n",
      "376 404\n",
      "376 405\n",
      "376 406\n",
      "376 407\n",
      "376 408\n",
      "376 409\n",
      "376 410\n",
      "376 411\n",
      "376 412\n",
      "376 413\n",
      "376 414\n",
      "376 415\n",
      "376 416\n",
      "376 417\n",
      "376 418\n",
      "376 419\n",
      "376 420\n",
      "376 421\n",
      "376 422\n",
      "376 423\n",
      "376 424\n",
      "376 425\n",
      "376 426\n",
      "376 427\n",
      "376 428\n",
      "376 429\n",
      "376 430\n",
      "376 431\n",
      "376 432\n",
      "376 433\n",
      "376 434\n",
      "376 435\n",
      "376 436\n",
      "376 437\n",
      "376 438\n",
      "376 439\n",
      "376 440\n",
      "376 441\n",
      "376 442\n",
      "376 443\n",
      "377 378\n",
      "377 379\n",
      "377 380\n",
      "377 381\n",
      "377 382\n",
      "377 383\n",
      "377 384\n",
      "377 385\n",
      "377 386\n",
      "377 387\n",
      "377 388\n",
      "377 389\n",
      "377 390\n",
      "377 391\n",
      "377 392\n",
      "377 393\n",
      "377 394\n",
      "377 395\n",
      "377 396\n",
      "377 397\n",
      "377 398\n",
      "377 399\n",
      "377 400\n",
      "377 401\n",
      "377 402\n",
      "377 403\n",
      "377 404\n",
      "377 405\n",
      "377 406\n",
      "377 407\n",
      "377 408\n",
      "377 409\n",
      "377 410\n",
      "377 411\n",
      "377 412\n",
      "377 413\n",
      "377 414\n",
      "377 415\n",
      "377 416\n",
      "377 417\n",
      "377 418\n",
      "377 419\n",
      "377 420\n",
      "377 421\n",
      "377 422\n",
      "377 423\n",
      "377 424\n",
      "377 425\n",
      "377 426\n",
      "377 427\n",
      "377 428\n",
      "377 429\n",
      "377 430\n",
      "377 431\n",
      "377 432\n",
      "377 433\n",
      "377 434\n",
      "377 435\n",
      "377 436\n",
      "377 437\n",
      "377 438\n",
      "377 439\n",
      "377 440\n",
      "377 441\n",
      "377 442\n",
      "377 443\n",
      "378 379\n",
      "378 380\n",
      "378 381\n",
      "378 382\n",
      "378 383\n",
      "378 384\n",
      "378 385\n",
      "378 386\n",
      "378 387\n",
      "378 388\n",
      "378 389\n",
      "378 390\n",
      "378 391\n",
      "378 392\n",
      "378 393\n",
      "378 394\n",
      "378 395\n",
      "378 396\n",
      "378 397\n",
      "378 398\n",
      "378 399\n",
      "378 400\n",
      "378 401\n",
      "378 402\n",
      "378 403\n",
      "378 404\n",
      "378 405\n",
      "378 406\n",
      "378 407\n",
      "378 408\n",
      "378 409\n",
      "378 410\n",
      "378 411\n",
      "378 412\n",
      "378 413\n",
      "378 414\n",
      "378 415\n",
      "378 416\n",
      "378 417\n",
      "378 418\n",
      "378 419\n",
      "378 420\n",
      "378 421\n",
      "378 422\n",
      "378 423\n",
      "378 424\n",
      "378 425\n",
      "378 426\n",
      "378 427\n",
      "378 428\n",
      "378 429\n",
      "378 430\n",
      "378 431\n",
      "378 432\n",
      "378 433\n",
      "378 434\n",
      "378 435\n",
      "378 436\n",
      "378 437\n",
      "378 438\n",
      "378 439\n",
      "378 440\n",
      "378 441\n",
      "378 442\n",
      "378 443\n",
      "379 380\n",
      "379 381\n",
      "379 382\n",
      "379 383\n",
      "379 384\n",
      "379 385\n",
      "379 386\n",
      "379 387\n",
      "379 388\n",
      "379 389\n",
      "379 390\n",
      "379 391\n",
      "379 392\n",
      "379 393\n",
      "379 394\n",
      "379 395\n",
      "379 396\n",
      "379 397\n",
      "379 398\n",
      "379 399\n",
      "379 400\n",
      "379 401\n",
      "379 402\n",
      "379 403\n",
      "379 404\n",
      "379 405\n",
      "379 406\n",
      "379 407\n",
      "379 408\n",
      "379 409\n",
      "379 410\n",
      "379 411\n",
      "379 412\n",
      "379 413\n",
      "379 414\n",
      "379 415\n",
      "379 416\n",
      "379 417\n",
      "379 418\n",
      "379 419\n",
      "379 420\n",
      "379 421\n",
      "379 422\n",
      "379 423\n",
      "379 424\n",
      "379 425\n",
      "379 426\n",
      "379 427\n",
      "379 428\n",
      "379 429\n",
      "379 430\n",
      "379 431\n",
      "379 432\n",
      "379 433\n",
      "379 434\n",
      "379 435\n",
      "379 436\n",
      "379 437\n",
      "379 438\n",
      "379 439\n",
      "379 440\n",
      "379 441\n",
      "379 442\n",
      "379 443\n",
      "380 381\n",
      "380 382\n",
      "380 383\n",
      "380 384\n",
      "380 385\n",
      "380 386\n",
      "380 387\n",
      "380 388\n",
      "380 389\n",
      "380 390\n",
      "380 391\n",
      "380 392\n",
      "380 393\n",
      "380 394\n",
      "380 395\n",
      "380 396\n",
      "380 397\n",
      "380 398\n",
      "380 399\n",
      "380 400\n",
      "380 401\n",
      "380 402\n",
      "380 403\n",
      "380 404\n",
      "380 405\n",
      "380 406\n",
      "380 407\n",
      "380 408\n",
      "380 409\n",
      "380 410\n",
      "380 411\n",
      "380 412\n",
      "380 413\n",
      "380 414\n",
      "380 415\n",
      "380 416\n",
      "380 417\n",
      "380 418\n",
      "380 419\n",
      "380 420\n",
      "380 421\n",
      "380 422\n",
      "380 423\n",
      "380 424\n",
      "380 425\n",
      "380 426\n",
      "380 427\n",
      "380 428\n",
      "380 429\n",
      "380 430\n",
      "380 431\n",
      "380 432\n",
      "380 433\n",
      "380 434\n",
      "380 435\n",
      "380 436\n",
      "380 437\n",
      "380 438\n",
      "380 439\n",
      "380 440\n",
      "380 441\n",
      "380 442\n",
      "380 443\n",
      "381 382\n",
      "381 383\n",
      "381 384\n",
      "381 385\n",
      "381 386\n",
      "381 387\n",
      "381 388\n",
      "381 389\n",
      "381 390\n",
      "381 391\n",
      "381 392\n",
      "381 393\n",
      "381 394\n",
      "381 395\n",
      "381 396\n",
      "381 397\n",
      "381 398\n",
      "381 399\n",
      "381 400\n",
      "381 401\n",
      "381 402\n",
      "381 403\n",
      "381 404\n",
      "381 405\n",
      "381 406\n",
      "381 407\n",
      "381 408\n",
      "381 409\n",
      "381 410\n",
      "381 411\n",
      "381 412\n",
      "381 413\n",
      "381 414\n",
      "381 415\n",
      "381 416\n",
      "381 417\n",
      "381 418\n",
      "381 419\n",
      "381 420\n",
      "381 421\n",
      "381 422\n",
      "381 423\n",
      "381 424\n",
      "381 425\n",
      "381 426\n",
      "381 427\n",
      "381 428\n",
      "381 429\n",
      "381 430\n",
      "381 431\n",
      "381 432\n",
      "381 433\n",
      "381 434\n",
      "381 435\n",
      "381 436\n",
      "381 437\n",
      "381 438\n",
      "381 439\n",
      "381 440\n",
      "381 441\n",
      "381 442\n",
      "381 443\n",
      "382 383\n",
      "382 384\n",
      "382 385\n",
      "382 386\n",
      "382 387\n",
      "382 388\n",
      "382 389\n",
      "382 390\n",
      "382 391\n",
      "382 392\n",
      "382 393\n",
      "382 394\n",
      "382 395\n",
      "382 396\n",
      "382 397\n",
      "382 398\n",
      "382 399\n",
      "382 400\n",
      "382 401\n",
      "382 402\n",
      "382 403\n",
      "382 404\n",
      "382 405\n",
      "382 406\n",
      "382 407\n",
      "382 408\n",
      "382 409\n",
      "382 410\n",
      "382 411\n",
      "382 412\n",
      "382 413\n",
      "382 414\n",
      "382 415\n",
      "382 416\n",
      "382 417\n",
      "382 418\n",
      "382 419\n",
      "382 420\n",
      "382 421\n",
      "382 422\n",
      "382 423\n",
      "382 424\n",
      "382 425\n",
      "382 426\n",
      "382 427\n",
      "382 428\n",
      "382 429\n",
      "382 430\n",
      "382 431\n",
      "382 432\n",
      "382 433\n",
      "382 434\n",
      "382 435\n",
      "382 436\n",
      "382 437\n",
      "382 438\n",
      "382 439\n",
      "382 440\n",
      "382 441\n",
      "382 442\n",
      "382 443\n",
      "383 384\n",
      "383 385\n",
      "383 386\n",
      "383 387\n",
      "383 388\n",
      "383 389\n",
      "383 390\n",
      "383 391\n",
      "383 392\n",
      "383 393\n",
      "383 394\n",
      "383 395\n",
      "383 396\n",
      "383 397\n",
      "383 398\n",
      "383 399\n",
      "383 400\n",
      "383 401\n",
      "383 402\n",
      "383 403\n",
      "383 404\n",
      "383 405\n",
      "383 406\n",
      "383 407\n",
      "383 408\n",
      "383 409\n",
      "383 410\n",
      "383 411\n",
      "383 412\n",
      "383 413\n",
      "383 414\n",
      "383 415\n",
      "383 416\n",
      "383 417\n",
      "383 418\n",
      "383 419\n",
      "383 420\n",
      "383 421\n",
      "383 422\n",
      "383 423\n",
      "383 424\n",
      "383 425\n",
      "383 426\n",
      "383 427\n",
      "383 428\n",
      "383 429\n",
      "383 430\n",
      "383 431\n",
      "383 432\n",
      "383 433\n",
      "383 434\n",
      "383 435\n",
      "383 436\n",
      "383 437\n",
      "383 438\n",
      "383 439\n",
      "383 440\n",
      "383 441\n",
      "383 442\n",
      "383 443\n",
      "384 385\n",
      "384 386\n",
      "384 387\n",
      "384 388\n",
      "384 389\n",
      "384 390\n",
      "384 391\n",
      "384 392\n",
      "384 393\n",
      "384 394\n",
      "384 395\n",
      "384 396\n",
      "384 397\n",
      "384 398\n",
      "384 399\n",
      "384 400\n",
      "384 401\n",
      "384 402\n",
      "384 403\n",
      "384 404\n",
      "384 405\n",
      "384 406\n",
      "384 407\n",
      "384 408\n",
      "384 409\n",
      "384 410\n",
      "384 411\n",
      "384 412\n",
      "384 413\n",
      "384 414\n",
      "384 415\n",
      "384 416\n",
      "384 417\n",
      "384 418\n",
      "384 419\n",
      "384 420\n",
      "384 421\n",
      "384 422\n",
      "384 423\n",
      "384 424\n",
      "384 425\n",
      "384 426\n",
      "384 427\n",
      "384 428\n",
      "384 429\n",
      "384 430\n",
      "384 431\n",
      "384 432\n",
      "384 433\n",
      "384 434\n",
      "384 435\n",
      "384 436\n",
      "384 437\n",
      "384 438\n",
      "384 439\n",
      "384 440\n",
      "384 441\n",
      "384 442\n",
      "384 443\n",
      "385 386\n",
      "385 387\n",
      "385 388\n",
      "385 389\n",
      "385 390\n",
      "385 391\n",
      "385 392\n",
      "385 393\n",
      "385 394\n",
      "385 395\n",
      "385 396\n",
      "385 397\n",
      "385 398\n",
      "385 399\n",
      "385 400\n",
      "385 401\n",
      "385 402\n",
      "385 403\n",
      "385 404\n",
      "385 405\n",
      "385 406\n",
      "385 407\n",
      "385 408\n",
      "385 409\n",
      "385 410\n",
      "385 411\n",
      "385 412\n",
      "385 413\n",
      "385 414\n",
      "385 415\n",
      "385 416\n",
      "385 417\n",
      "385 418\n",
      "385 419\n",
      "385 420\n",
      "385 421\n",
      "385 422\n",
      "385 423\n",
      "385 424\n",
      "385 425\n",
      "385 426\n",
      "385 427\n",
      "385 428\n",
      "385 429\n",
      "385 430\n",
      "385 431\n",
      "385 432\n",
      "385 433\n",
      "385 434\n",
      "385 435\n",
      "385 436\n",
      "385 437\n",
      "385 438\n",
      "385 439\n",
      "385 440\n",
      "385 441\n",
      "385 442\n",
      "385 443\n",
      "386 387\n",
      "386 388\n",
      "386 389\n",
      "386 390\n",
      "386 391\n",
      "386 392\n",
      "386 393\n",
      "386 394\n",
      "386 395\n",
      "386 396\n",
      "386 397\n",
      "386 398\n",
      "386 399\n",
      "386 400\n",
      "386 401\n",
      "386 402\n",
      "386 403\n",
      "386 404\n",
      "386 405\n",
      "386 406\n",
      "386 407\n",
      "386 408\n",
      "386 409\n",
      "386 410\n",
      "386 411\n",
      "386 412\n",
      "386 413\n",
      "386 414\n",
      "386 415\n",
      "386 416\n",
      "386 417\n",
      "386 418\n",
      "386 419\n",
      "386 420\n",
      "386 421\n",
      "386 422\n",
      "386 423\n",
      "386 424\n",
      "386 425\n",
      "386 426\n",
      "386 427\n",
      "386 428\n",
      "386 429\n",
      "386 430\n",
      "386 431\n",
      "386 432\n",
      "386 433\n",
      "386 434\n",
      "386 435\n",
      "386 436\n",
      "386 437\n",
      "386 438\n",
      "386 439\n",
      "386 440\n",
      "386 441\n",
      "386 442\n",
      "386 443\n",
      "387 388\n",
      "387 389\n",
      "387 390\n",
      "387 391\n",
      "387 392\n",
      "387 393\n",
      "387 394\n",
      "387 395\n",
      "387 396\n",
      "387 397\n",
      "387 398\n",
      "387 399\n",
      "387 400\n",
      "387 401\n",
      "387 402\n",
      "387 403\n",
      "387 404\n",
      "387 405\n",
      "387 406\n",
      "387 407\n",
      "387 408\n",
      "387 409\n",
      "387 410\n",
      "387 411\n",
      "387 412\n",
      "387 413\n",
      "387 414\n",
      "387 415\n",
      "387 416\n",
      "387 417\n",
      "387 418\n",
      "387 419\n",
      "387 420\n",
      "387 421\n",
      "387 422\n",
      "387 423\n",
      "387 424\n",
      "387 425\n",
      "387 426\n",
      "387 427\n",
      "387 428\n",
      "387 429\n",
      "387 430\n",
      "387 431\n",
      "387 432\n",
      "387 433\n",
      "387 434\n",
      "387 435\n",
      "387 436\n",
      "387 437\n",
      "387 438\n",
      "387 439\n",
      "387 440\n",
      "387 441\n",
      "387 442\n",
      "387 443\n",
      "388 389\n",
      "388 390\n",
      "388 391\n",
      "388 392\n",
      "388 393\n",
      "388 394\n",
      "388 395\n",
      "388 396\n",
      "388 397\n",
      "388 398\n",
      "388 399\n",
      "388 400\n",
      "388 401\n",
      "388 402\n",
      "388 403\n",
      "388 404\n",
      "388 405\n",
      "388 406\n",
      "388 407\n",
      "388 408\n",
      "388 409\n",
      "388 410\n",
      "388 411\n",
      "388 412\n",
      "388 413\n",
      "388 414\n",
      "388 415\n",
      "388 416\n",
      "388 417\n",
      "388 418\n",
      "388 419\n",
      "388 420\n",
      "388 421\n",
      "388 422\n",
      "388 423\n",
      "388 424\n",
      "388 425\n",
      "388 426\n",
      "388 427\n",
      "388 428\n",
      "388 429\n",
      "388 430\n",
      "388 431\n",
      "388 432\n",
      "388 433\n",
      "388 434\n",
      "388 435\n",
      "388 436\n",
      "388 437\n",
      "388 438\n",
      "388 439\n",
      "388 440\n",
      "388 441\n",
      "388 442\n",
      "388 443\n",
      "389 390\n",
      "389 391\n",
      "389 392\n",
      "389 393\n",
      "389 394\n",
      "389 395\n",
      "389 396\n",
      "389 397\n",
      "389 398\n",
      "389 399\n",
      "389 400\n",
      "389 401\n",
      "389 402\n",
      "389 403\n",
      "389 404\n",
      "389 405\n",
      "389 406\n",
      "389 407\n",
      "389 408\n",
      "389 409\n",
      "389 410\n",
      "389 411\n",
      "389 412\n",
      "389 413\n",
      "389 414\n",
      "389 415\n",
      "389 416\n",
      "389 417\n",
      "389 418\n",
      "389 419\n",
      "389 420\n",
      "389 421\n",
      "389 422\n",
      "389 423\n",
      "389 424\n",
      "389 425\n",
      "389 426\n",
      "389 427\n",
      "389 428\n",
      "389 429\n",
      "389 430\n",
      "389 431\n",
      "389 432\n",
      "389 433\n",
      "389 434\n",
      "389 435\n",
      "389 436\n",
      "389 437\n",
      "389 438\n",
      "389 439\n",
      "389 440\n",
      "389 441\n",
      "389 442\n",
      "389 443\n",
      "390 391\n",
      "390 392\n",
      "390 393\n",
      "390 394\n",
      "390 395\n",
      "390 396\n",
      "390 397\n",
      "390 398\n",
      "390 399\n",
      "390 400\n",
      "390 401\n",
      "390 402\n",
      "390 403\n",
      "390 404\n",
      "390 405\n",
      "390 406\n",
      "390 407\n",
      "390 408\n",
      "390 409\n",
      "390 410\n",
      "390 411\n",
      "390 412\n",
      "390 413\n",
      "390 414\n",
      "390 415\n",
      "390 416\n",
      "390 417\n",
      "390 418\n",
      "390 419\n",
      "390 420\n",
      "390 421\n",
      "390 422\n",
      "390 423\n",
      "390 424\n",
      "390 425\n",
      "390 426\n",
      "390 427\n",
      "390 428\n",
      "390 429\n",
      "390 430\n",
      "390 431\n",
      "390 432\n",
      "390 433\n",
      "390 434\n",
      "390 435\n",
      "390 436\n",
      "390 437\n",
      "390 438\n",
      "390 439\n",
      "390 440\n",
      "390 441\n",
      "390 442\n",
      "390 443\n",
      "391 392\n",
      "391 393\n",
      "391 394\n",
      "391 395\n",
      "391 396\n",
      "391 397\n",
      "391 398\n",
      "391 399\n",
      "391 400\n",
      "391 401\n",
      "391 402\n",
      "391 403\n",
      "391 404\n",
      "391 405\n",
      "391 406\n",
      "391 407\n",
      "391 408\n",
      "391 409\n",
      "391 410\n",
      "391 411\n",
      "391 412\n",
      "391 413\n",
      "391 414\n",
      "391 415\n",
      "391 416\n",
      "391 417\n",
      "391 418\n",
      "391 419\n",
      "391 420\n",
      "391 421\n",
      "391 422\n",
      "391 423\n",
      "391 424\n",
      "391 425\n",
      "391 426\n",
      "391 427\n",
      "391 428\n",
      "391 429\n",
      "391 430\n",
      "391 431\n",
      "391 432\n",
      "391 433\n",
      "391 434\n",
      "391 435\n",
      "391 436\n",
      "391 437\n",
      "391 438\n",
      "391 439\n",
      "391 440\n",
      "391 441\n",
      "391 442\n",
      "391 443\n",
      "392 393\n",
      "392 394\n",
      "392 395\n",
      "392 396\n",
      "392 397\n",
      "392 398\n",
      "392 399\n",
      "392 400\n",
      "392 401\n",
      "392 402\n",
      "392 403\n",
      "392 404\n",
      "392 405\n",
      "392 406\n",
      "392 407\n",
      "392 408\n",
      "392 409\n",
      "392 410\n",
      "392 411\n",
      "392 412\n",
      "392 413\n",
      "392 414\n",
      "392 415\n",
      "392 416\n",
      "392 417\n",
      "392 418\n",
      "392 419\n",
      "392 420\n",
      "392 421\n",
      "392 422\n",
      "392 423\n",
      "392 424\n",
      "392 425\n",
      "392 426\n",
      "392 427\n",
      "392 428\n",
      "392 429\n",
      "392 430\n",
      "392 431\n",
      "392 432\n",
      "392 433\n",
      "392 434\n",
      "392 435\n",
      "392 436\n",
      "392 437\n",
      "392 438\n",
      "392 439\n",
      "392 440\n",
      "392 441\n",
      "392 442\n",
      "392 443\n",
      "393 394\n",
      "393 395\n",
      "393 396\n",
      "393 397\n",
      "393 398\n",
      "393 399\n",
      "393 400\n",
      "393 401\n",
      "393 402\n",
      "393 403\n",
      "393 404\n",
      "393 405\n",
      "393 406\n",
      "393 407\n",
      "393 408\n",
      "393 409\n",
      "393 410\n",
      "393 411\n",
      "393 412\n",
      "393 413\n",
      "393 414\n",
      "393 415\n",
      "393 416\n",
      "393 417\n",
      "393 418\n",
      "393 419\n",
      "393 420\n",
      "393 421\n",
      "393 422\n",
      "393 423\n",
      "393 424\n",
      "393 425\n",
      "393 426\n",
      "393 427\n",
      "393 428\n",
      "393 429\n",
      "393 430\n",
      "393 431\n",
      "393 432\n",
      "393 433\n",
      "393 434\n",
      "393 435\n",
      "393 436\n",
      "393 437\n",
      "393 438\n",
      "393 439\n",
      "393 440\n",
      "393 441\n",
      "393 442\n",
      "393 443\n",
      "394 395\n",
      "394 396\n",
      "394 397\n",
      "394 398\n",
      "394 399\n",
      "394 400\n",
      "394 401\n",
      "394 402\n",
      "394 403\n",
      "394 404\n",
      "394 405\n",
      "394 406\n",
      "394 407\n",
      "394 408\n",
      "394 409\n",
      "394 410\n",
      "394 411\n",
      "394 412\n",
      "394 413\n",
      "394 414\n",
      "394 415\n",
      "394 416\n",
      "394 417\n",
      "394 418\n",
      "394 419\n",
      "394 420\n",
      "394 421\n",
      "394 422\n",
      "394 423\n",
      "394 424\n",
      "394 425\n",
      "394 426\n",
      "394 427\n",
      "394 428\n",
      "394 429\n",
      "394 430\n",
      "394 431\n",
      "394 432\n",
      "394 433\n",
      "394 434\n",
      "394 435\n",
      "394 436\n",
      "394 437\n",
      "394 438\n",
      "394 439\n",
      "394 440\n",
      "394 441\n",
      "394 442\n",
      "394 443\n",
      "395 396\n",
      "395 397\n",
      "395 398\n",
      "395 399\n",
      "395 400\n",
      "395 401\n",
      "395 402\n",
      "395 403\n",
      "395 404\n",
      "395 405\n",
      "395 406\n",
      "395 407\n",
      "395 408\n",
      "395 409\n",
      "395 410\n",
      "395 411\n",
      "395 412\n",
      "395 413\n",
      "395 414\n",
      "395 415\n",
      "395 416\n",
      "395 417\n",
      "395 418\n",
      "395 419\n",
      "395 420\n",
      "395 421\n",
      "395 422\n",
      "395 423\n",
      "395 424\n",
      "395 425\n",
      "395 426\n",
      "395 427\n",
      "395 428\n",
      "395 429\n",
      "395 430\n",
      "395 431\n",
      "395 432\n",
      "395 433\n",
      "395 434\n",
      "395 435\n",
      "395 436\n",
      "395 437\n",
      "395 438\n",
      "395 439\n",
      "395 440\n",
      "395 441\n",
      "395 442\n",
      "395 443\n",
      "396 397\n",
      "396 398\n",
      "396 399\n",
      "396 400\n",
      "396 401\n",
      "396 402\n",
      "396 403\n",
      "396 404\n",
      "396 405\n",
      "396 406\n",
      "396 407\n",
      "396 408\n",
      "396 409\n",
      "396 410\n",
      "396 411\n",
      "396 412\n",
      "396 413\n",
      "396 414\n",
      "396 415\n",
      "396 416\n",
      "396 417\n",
      "396 418\n",
      "396 419\n",
      "396 420\n",
      "396 421\n",
      "396 422\n",
      "396 423\n",
      "396 424\n",
      "396 425\n",
      "396 426\n",
      "396 427\n",
      "396 428\n",
      "396 429\n",
      "396 430\n",
      "396 431\n",
      "396 432\n",
      "396 433\n",
      "396 434\n",
      "396 435\n",
      "396 436\n",
      "396 437\n",
      "396 438\n",
      "396 439\n",
      "396 440\n",
      "396 441\n",
      "396 442\n",
      "396 443\n",
      "397 398\n",
      "397 399\n",
      "397 400\n",
      "397 401\n",
      "397 402\n",
      "397 403\n",
      "397 404\n",
      "397 405\n",
      "397 406\n",
      "397 407\n",
      "397 408\n",
      "397 409\n",
      "397 410\n",
      "397 411\n",
      "397 412\n",
      "397 413\n",
      "397 414\n",
      "397 415\n",
      "397 416\n",
      "397 417\n",
      "397 418\n",
      "397 419\n",
      "397 420\n",
      "397 421\n",
      "397 422\n",
      "397 423\n",
      "397 424\n",
      "397 425\n",
      "397 426\n",
      "397 427\n",
      "397 428\n",
      "397 429\n",
      "397 430\n",
      "397 431\n",
      "397 432\n",
      "397 433\n",
      "397 434\n",
      "397 435\n",
      "397 436\n",
      "397 437\n",
      "397 438\n",
      "397 439\n",
      "397 440\n",
      "397 441\n",
      "397 442\n",
      "397 443\n",
      "398 399\n",
      "398 400\n",
      "398 401\n",
      "398 402\n",
      "398 403\n",
      "398 404\n",
      "398 405\n",
      "398 406\n",
      "398 407\n",
      "398 408\n",
      "398 409\n",
      "398 410\n",
      "398 411\n",
      "398 412\n",
      "398 413\n",
      "398 414\n",
      "398 415\n",
      "398 416\n",
      "398 417\n",
      "398 418\n",
      "398 419\n",
      "398 420\n",
      "398 421\n",
      "398 422\n",
      "398 423\n",
      "398 424\n",
      "398 425\n",
      "398 426\n",
      "398 427\n",
      "398 428\n",
      "398 429\n",
      "398 430\n",
      "398 431\n",
      "398 432\n",
      "398 433\n",
      "398 434\n",
      "398 435\n",
      "398 436\n",
      "398 437\n",
      "398 438\n",
      "398 439\n",
      "398 440\n",
      "398 441\n",
      "398 442\n",
      "398 443\n",
      "399 400\n",
      "399 401\n",
      "399 402\n",
      "399 403\n",
      "399 404\n",
      "399 405\n",
      "399 406\n",
      "399 407\n",
      "399 408\n",
      "399 409\n",
      "399 410\n",
      "399 411\n",
      "399 412\n",
      "399 413\n",
      "399 414\n",
      "399 415\n",
      "399 416\n",
      "399 417\n",
      "399 418\n",
      "399 419\n",
      "399 420\n",
      "399 421\n",
      "399 422\n",
      "399 423\n",
      "399 424\n",
      "399 425\n",
      "399 426\n",
      "399 427\n",
      "399 428\n",
      "399 429\n",
      "399 430\n",
      "399 431\n",
      "399 432\n",
      "399 433\n",
      "399 434\n",
      "399 435\n",
      "399 436\n",
      "399 437\n",
      "399 438\n",
      "399 439\n",
      "399 440\n",
      "399 441\n",
      "399 442\n",
      "399 443\n",
      "400 401\n",
      "400 402\n",
      "400 403\n",
      "400 404\n",
      "400 405\n",
      "400 406\n",
      "400 407\n",
      "400 408\n",
      "400 409\n",
      "400 410\n",
      "400 411\n",
      "400 412\n",
      "400 413\n",
      "400 414\n",
      "400 415\n",
      "400 416\n",
      "400 417\n",
      "400 418\n",
      "400 419\n",
      "400 420\n",
      "400 421\n",
      "400 422\n",
      "400 423\n",
      "400 424\n",
      "400 425\n",
      "400 426\n",
      "400 427\n",
      "400 428\n",
      "400 429\n",
      "400 430\n",
      "400 431\n",
      "400 432\n",
      "400 433\n",
      "400 434\n",
      "400 435\n",
      "400 436\n",
      "400 437\n",
      "400 438\n",
      "400 439\n",
      "400 440\n",
      "400 441\n",
      "400 442\n",
      "400 443\n",
      "401 402\n",
      "401 403\n",
      "401 404\n",
      "401 405\n",
      "401 406\n",
      "401 407\n",
      "401 408\n",
      "401 409\n",
      "401 410\n",
      "401 411\n",
      "401 412\n",
      "401 413\n",
      "401 414\n",
      "401 415\n",
      "401 416\n",
      "401 417\n",
      "401 418\n",
      "401 419\n",
      "401 420\n",
      "401 421\n",
      "401 422\n",
      "401 423\n",
      "401 424\n",
      "401 425\n",
      "401 426\n",
      "401 427\n",
      "401 428\n",
      "401 429\n",
      "401 430\n",
      "401 431\n",
      "401 432\n",
      "401 433\n",
      "401 434\n",
      "401 435\n",
      "401 436\n",
      "401 437\n",
      "401 438\n",
      "401 439\n",
      "401 440\n",
      "401 441\n",
      "401 442\n",
      "401 443\n",
      "402 403\n",
      "402 404\n",
      "402 405\n",
      "402 406\n",
      "402 407\n",
      "402 408\n",
      "402 409\n",
      "402 410\n",
      "402 411\n",
      "402 412\n",
      "402 413\n",
      "402 414\n",
      "402 415\n",
      "402 416\n",
      "402 417\n",
      "402 418\n",
      "402 419\n",
      "402 420\n",
      "402 421\n",
      "402 422\n",
      "402 423\n",
      "402 424\n",
      "402 425\n",
      "402 426\n",
      "402 427\n",
      "402 428\n",
      "402 429\n",
      "402 430\n",
      "402 431\n",
      "402 432\n",
      "402 433\n",
      "402 434\n",
      "402 435\n",
      "402 436\n",
      "402 437\n",
      "402 438\n",
      "402 439\n",
      "402 440\n",
      "402 441\n",
      "402 442\n",
      "402 443\n",
      "403 404\n",
      "403 405\n",
      "403 406\n",
      "403 407\n",
      "403 408\n",
      "403 409\n",
      "403 410\n",
      "403 411\n",
      "403 412\n",
      "403 413\n",
      "403 414\n",
      "403 415\n",
      "403 416\n",
      "403 417\n",
      "403 418\n",
      "403 419\n",
      "403 420\n",
      "403 421\n",
      "403 422\n",
      "403 423\n",
      "403 424\n",
      "403 425\n",
      "403 426\n",
      "403 427\n",
      "403 428\n",
      "403 429\n",
      "403 430\n",
      "403 431\n",
      "403 432\n",
      "403 433\n",
      "403 434\n",
      "403 435\n",
      "403 436\n",
      "403 437\n",
      "403 438\n",
      "403 439\n",
      "403 440\n",
      "403 441\n",
      "403 442\n",
      "403 443\n",
      "404 405\n",
      "404 406\n",
      "404 407\n",
      "404 408\n",
      "404 409\n",
      "404 410\n",
      "404 411\n",
      "404 412\n",
      "404 413\n",
      "404 414\n",
      "404 415\n",
      "404 416\n",
      "404 417\n",
      "404 418\n",
      "404 419\n",
      "404 420\n",
      "404 421\n",
      "404 422\n",
      "404 423\n",
      "404 424\n",
      "404 425\n",
      "404 426\n",
      "404 427\n",
      "404 428\n",
      "404 429\n",
      "404 430\n",
      "404 431\n",
      "404 432\n",
      "404 433\n",
      "404 434\n",
      "404 435\n",
      "404 436\n",
      "404 437\n",
      "404 438\n",
      "404 439\n",
      "404 440\n",
      "404 441\n",
      "404 442\n",
      "404 443\n",
      "405 406\n",
      "405 407\n",
      "405 408\n",
      "405 409\n",
      "405 410\n",
      "405 411\n",
      "405 412\n",
      "405 413\n",
      "405 414\n",
      "405 415\n",
      "405 416\n",
      "405 417\n",
      "405 418\n",
      "405 419\n",
      "405 420\n",
      "405 421\n",
      "405 422\n",
      "405 423\n",
      "405 424\n",
      "405 425\n",
      "405 426\n",
      "405 427\n",
      "405 428\n",
      "405 429\n",
      "405 430\n",
      "405 431\n",
      "405 432\n",
      "405 433\n",
      "405 434\n",
      "405 435\n",
      "405 436\n",
      "405 437\n",
      "405 438\n",
      "405 439\n",
      "405 440\n",
      "405 441\n",
      "405 442\n",
      "405 443\n",
      "406 407\n",
      "406 408\n",
      "406 409\n",
      "406 410\n",
      "406 411\n",
      "406 412\n",
      "406 413\n",
      "406 414\n",
      "406 415\n",
      "406 416\n",
      "406 417\n",
      "406 418\n",
      "406 419\n",
      "406 420\n",
      "406 421\n",
      "406 422\n",
      "406 423\n",
      "406 424\n",
      "406 425\n",
      "406 426\n",
      "406 427\n",
      "406 428\n",
      "406 429\n",
      "406 430\n",
      "406 431\n",
      "406 432\n",
      "406 433\n",
      "406 434\n",
      "406 435\n",
      "406 436\n",
      "406 437\n",
      "406 438\n",
      "406 439\n",
      "406 440\n",
      "406 441\n",
      "406 442\n",
      "406 443\n",
      "407 408\n",
      "407 409\n",
      "407 410\n",
      "407 411\n",
      "407 412\n",
      "407 413\n",
      "407 414\n",
      "407 415\n",
      "407 416\n",
      "407 417\n",
      "407 418\n",
      "407 419\n",
      "407 420\n",
      "407 421\n",
      "407 422\n",
      "407 423\n",
      "407 424\n",
      "407 425\n",
      "407 426\n",
      "407 427\n",
      "407 428\n",
      "407 429\n",
      "407 430\n",
      "407 431\n",
      "407 432\n",
      "407 433\n",
      "407 434\n",
      "407 435\n",
      "407 436\n",
      "407 437\n",
      "407 438\n",
      "407 439\n",
      "407 440\n",
      "407 441\n",
      "407 442\n",
      "407 443\n",
      "408 409\n",
      "408 410\n",
      "408 411\n",
      "408 412\n",
      "408 413\n",
      "408 414\n",
      "408 415\n",
      "408 416\n",
      "408 417\n",
      "408 418\n",
      "408 419\n",
      "408 420\n",
      "408 421\n",
      "408 422\n",
      "408 423\n",
      "408 424\n",
      "408 425\n",
      "408 426\n",
      "408 427\n",
      "408 428\n",
      "408 429\n",
      "408 430\n",
      "408 431\n",
      "408 432\n",
      "408 433\n",
      "408 434\n",
      "408 435\n",
      "408 436\n",
      "408 437\n",
      "408 438\n",
      "408 439\n",
      "408 440\n",
      "408 441\n",
      "408 442\n",
      "408 443\n",
      "409 410\n",
      "409 411\n",
      "409 412\n",
      "409 413\n",
      "409 414\n",
      "409 415\n",
      "409 416\n",
      "409 417\n",
      "409 418\n",
      "409 419\n",
      "409 420\n",
      "409 421\n",
      "409 422\n",
      "409 423\n",
      "409 424\n",
      "409 425\n",
      "409 426\n",
      "409 427\n",
      "409 428\n",
      "409 429\n",
      "409 430\n",
      "409 431\n",
      "409 432\n",
      "409 433\n",
      "409 434\n",
      "409 435\n",
      "409 436\n",
      "409 437\n",
      "409 438\n",
      "409 439\n",
      "409 440\n",
      "409 441\n",
      "409 442\n",
      "409 443\n",
      "410 411\n",
      "410 412\n",
      "410 413\n",
      "410 414\n",
      "410 415\n",
      "410 416\n",
      "410 417\n",
      "410 418\n",
      "410 419\n",
      "410 420\n",
      "410 421\n",
      "410 422\n",
      "410 423\n",
      "410 424\n",
      "410 425\n",
      "410 426\n",
      "410 427\n",
      "410 428\n",
      "410 429\n",
      "410 430\n",
      "410 431\n",
      "410 432\n",
      "410 433\n",
      "410 434\n",
      "410 435\n",
      "410 436\n",
      "410 437\n",
      "410 438\n",
      "410 439\n",
      "410 440\n",
      "410 441\n",
      "410 442\n",
      "410 443\n",
      "411 412\n",
      "411 413\n",
      "411 414\n",
      "411 415\n",
      "411 416\n",
      "411 417\n",
      "411 418\n",
      "411 419\n",
      "411 420\n",
      "411 421\n",
      "411 422\n",
      "411 423\n",
      "411 424\n",
      "411 425\n",
      "411 426\n",
      "411 427\n",
      "411 428\n",
      "411 429\n",
      "411 430\n",
      "411 431\n",
      "411 432\n",
      "411 433\n",
      "411 434\n",
      "411 435\n",
      "411 436\n",
      "411 437\n",
      "411 438\n",
      "411 439\n",
      "411 440\n",
      "411 441\n",
      "411 442\n",
      "411 443\n",
      "412 413\n",
      "412 414\n",
      "412 415\n",
      "412 416\n",
      "412 417\n",
      "412 418\n",
      "412 419\n",
      "412 420\n",
      "412 421\n",
      "412 422\n",
      "412 423\n",
      "412 424\n",
      "412 425\n",
      "412 426\n",
      "412 427\n",
      "412 428\n",
      "412 429\n",
      "412 430\n",
      "412 431\n",
      "412 432\n",
      "412 433\n",
      "412 434\n",
      "412 435\n",
      "412 436\n",
      "412 437\n",
      "412 438\n",
      "412 439\n",
      "412 440\n",
      "412 441\n",
      "412 442\n",
      "412 443\n",
      "413 414\n",
      "413 415\n",
      "413 416\n",
      "413 417\n",
      "413 418\n",
      "413 419\n",
      "413 420\n",
      "413 421\n",
      "413 422\n",
      "413 423\n",
      "413 424\n",
      "413 425\n",
      "413 426\n",
      "413 427\n",
      "413 428\n",
      "413 429\n",
      "413 430\n",
      "413 431\n",
      "413 432\n",
      "413 433\n",
      "413 434\n",
      "413 435\n",
      "413 436\n",
      "413 437\n",
      "413 438\n",
      "413 439\n",
      "413 440\n",
      "413 441\n",
      "413 442\n",
      "413 443\n",
      "414 415\n",
      "414 416\n",
      "414 417\n",
      "414 418\n",
      "414 419\n",
      "414 420\n",
      "414 421\n",
      "414 422\n",
      "414 423\n",
      "414 424\n",
      "414 425\n",
      "414 426\n",
      "414 427\n",
      "414 428\n",
      "414 429\n",
      "414 430\n",
      "414 431\n",
      "414 432\n",
      "414 433\n",
      "414 434\n",
      "414 435\n",
      "414 436\n",
      "414 437\n",
      "414 438\n",
      "414 439\n",
      "414 440\n",
      "414 441\n",
      "414 442\n",
      "414 443\n",
      "415 416\n",
      "415 417\n",
      "415 418\n",
      "415 419\n",
      "415 420\n",
      "415 421\n",
      "415 422\n",
      "415 423\n",
      "415 424\n",
      "415 425\n",
      "415 426\n",
      "415 427\n",
      "415 428\n",
      "415 429\n",
      "415 430\n",
      "415 431\n",
      "415 432\n",
      "415 433\n",
      "415 434\n",
      "415 435\n",
      "415 436\n",
      "415 437\n",
      "415 438\n",
      "415 439\n",
      "415 440\n",
      "415 441\n",
      "415 442\n",
      "415 443\n",
      "416 417\n",
      "416 418\n",
      "416 419\n",
      "416 420\n",
      "416 421\n",
      "416 422\n",
      "416 423\n",
      "416 424\n",
      "416 425\n",
      "416 426\n",
      "416 427\n",
      "416 428\n",
      "416 429\n",
      "416 430\n",
      "416 431\n",
      "416 432\n",
      "416 433\n",
      "416 434\n",
      "416 435\n",
      "416 436\n",
      "416 437\n",
      "416 438\n",
      "416 439\n",
      "416 440\n",
      "416 441\n",
      "416 442\n",
      "416 443\n",
      "417 418\n",
      "417 419\n",
      "417 420\n",
      "417 421\n",
      "417 422\n",
      "417 423\n",
      "417 424\n",
      "417 425\n",
      "417 426\n",
      "417 427\n",
      "417 428\n",
      "417 429\n",
      "417 430\n",
      "417 431\n",
      "417 432\n",
      "417 433\n",
      "417 434\n",
      "417 435\n",
      "417 436\n",
      "417 437\n",
      "417 438\n",
      "417 439\n",
      "417 440\n",
      "417 441\n",
      "417 442\n",
      "417 443\n",
      "418 419\n",
      "418 420\n",
      "418 421\n",
      "418 422\n",
      "418 423\n",
      "418 424\n",
      "418 425\n",
      "418 426\n",
      "418 427\n",
      "418 428\n",
      "418 429\n",
      "418 430\n",
      "418 431\n",
      "418 432\n",
      "418 433\n",
      "418 434\n",
      "418 435\n",
      "418 436\n",
      "418 437\n",
      "418 438\n",
      "418 439\n",
      "418 440\n",
      "418 441\n",
      "418 442\n",
      "418 443\n",
      "419 420\n",
      "419 421\n",
      "419 422\n",
      "419 423\n",
      "419 424\n",
      "419 425\n",
      "419 426\n",
      "419 427\n",
      "419 428\n",
      "419 429\n",
      "419 430\n",
      "419 431\n",
      "419 432\n",
      "419 433\n",
      "419 434\n",
      "419 435\n",
      "419 436\n",
      "419 437\n",
      "419 438\n",
      "419 439\n",
      "419 440\n",
      "419 441\n",
      "419 442\n",
      "419 443\n",
      "420 421\n",
      "420 422\n",
      "420 423\n",
      "420 424\n",
      "420 425\n",
      "420 426\n",
      "420 427\n",
      "420 428\n",
      "420 429\n",
      "420 430\n",
      "420 431\n",
      "420 432\n",
      "420 433\n",
      "420 434\n",
      "420 435\n",
      "420 436\n",
      "420 437\n",
      "420 438\n",
      "420 439\n",
      "420 440\n",
      "420 441\n",
      "420 442\n",
      "420 443\n",
      "421 422\n",
      "421 423\n",
      "421 424\n",
      "421 425\n",
      "421 426\n",
      "421 427\n",
      "421 428\n",
      "421 429\n",
      "421 430\n",
      "421 431\n",
      "421 432\n",
      "421 433\n",
      "421 434\n",
      "421 435\n",
      "421 436\n",
      "421 437\n",
      "421 438\n",
      "421 439\n",
      "421 440\n",
      "421 441\n",
      "421 442\n",
      "421 443\n",
      "422 423\n",
      "422 424\n",
      "422 425\n",
      "422 426\n",
      "422 427\n",
      "422 428\n",
      "422 429\n",
      "422 430\n",
      "422 431\n",
      "422 432\n",
      "422 433\n",
      "422 434\n",
      "422 435\n",
      "422 436\n",
      "422 437\n",
      "422 438\n",
      "422 439\n",
      "422 440\n",
      "422 441\n",
      "422 442\n",
      "422 443\n",
      "423 424\n",
      "423 425\n",
      "423 426\n",
      "423 427\n",
      "423 428\n",
      "423 429\n",
      "423 430\n",
      "423 431\n",
      "423 432\n",
      "423 433\n",
      "423 434\n",
      "423 435\n",
      "423 436\n",
      "423 437\n",
      "423 438\n",
      "423 439\n",
      "423 440\n",
      "423 441\n",
      "423 442\n",
      "423 443\n",
      "424 425\n",
      "424 426\n",
      "424 427\n",
      "424 428\n",
      "424 429\n",
      "424 430\n",
      "424 431\n",
      "424 432\n",
      "424 433\n",
      "424 434\n",
      "424 435\n",
      "424 436\n",
      "424 437\n",
      "424 438\n",
      "424 439\n",
      "424 440\n",
      "424 441\n",
      "424 442\n",
      "424 443\n",
      "425 426\n",
      "425 427\n",
      "425 428\n",
      "425 429\n",
      "425 430\n",
      "425 431\n",
      "425 432\n",
      "425 433\n",
      "425 434\n",
      "425 435\n",
      "425 436\n",
      "425 437\n",
      "425 438\n",
      "425 439\n",
      "425 440\n",
      "425 441\n",
      "425 442\n",
      "425 443\n",
      "426 427\n",
      "426 428\n",
      "426 429\n",
      "426 430\n",
      "426 431\n",
      "426 432\n",
      "426 433\n",
      "426 434\n",
      "426 435\n",
      "426 436\n",
      "426 437\n",
      "426 438\n",
      "426 439\n",
      "426 440\n",
      "426 441\n",
      "426 442\n",
      "426 443\n",
      "427 428\n",
      "427 429\n",
      "427 430\n",
      "427 431\n",
      "427 432\n",
      "427 433\n",
      "427 434\n",
      "427 435\n",
      "427 436\n",
      "427 437\n",
      "427 438\n",
      "427 439\n",
      "427 440\n",
      "427 441\n",
      "427 442\n",
      "427 443\n",
      "428 429\n",
      "428 430\n",
      "428 431\n",
      "428 432\n",
      "428 433\n",
      "428 434\n",
      "428 435\n",
      "428 436\n",
      "428 437\n",
      "428 438\n",
      "428 439\n",
      "428 440\n",
      "428 441\n",
      "428 442\n",
      "428 443\n",
      "429 430\n",
      "429 431\n",
      "429 432\n",
      "429 433\n",
      "429 434\n",
      "429 435\n",
      "429 436\n",
      "429 437\n",
      "429 438\n",
      "429 439\n",
      "429 440\n",
      "429 441\n",
      "429 442\n",
      "429 443\n",
      "430 431\n",
      "430 432\n",
      "430 433\n",
      "430 434\n",
      "430 435\n",
      "430 436\n",
      "430 437\n",
      "430 438\n",
      "430 439\n",
      "430 440\n",
      "430 441\n",
      "430 442\n",
      "430 443\n",
      "431 432\n",
      "431 433\n",
      "431 434\n",
      "431 435\n",
      "431 436\n",
      "431 437\n",
      "431 438\n",
      "431 439\n",
      "431 440\n",
      "431 441\n",
      "431 442\n",
      "431 443\n",
      "432 433\n",
      "432 434\n",
      "432 435\n",
      "432 436\n",
      "432 437\n",
      "432 438\n",
      "432 439\n",
      "432 440\n",
      "432 441\n",
      "432 442\n",
      "432 443\n",
      "433 434\n",
      "433 435\n",
      "433 436\n",
      "433 437\n",
      "433 438\n",
      "433 439\n",
      "433 440\n",
      "433 441\n",
      "433 442\n",
      "433 443\n",
      "434 435\n",
      "434 436\n",
      "434 437\n",
      "434 438\n",
      "434 439\n",
      "434 440\n",
      "434 441\n",
      "434 442\n",
      "434 443\n",
      "435 436\n",
      "435 437\n",
      "435 438\n",
      "435 439\n",
      "435 440\n",
      "435 441\n",
      "435 442\n",
      "435 443\n",
      "436 437\n",
      "436 438\n",
      "436 439\n",
      "436 440\n",
      "436 441\n",
      "436 442\n",
      "436 443\n",
      "437 438\n",
      "437 439\n",
      "437 440\n",
      "437 441\n",
      "437 442\n",
      "437 443\n",
      "438 439\n",
      "438 440\n",
      "438 441\n",
      "438 442\n",
      "438 443\n",
      "439 440\n",
      "439 441\n",
      "439 442\n",
      "439 443\n",
      "440 441\n",
      "440 442\n",
      "440 443\n",
      "441 442\n",
      "441 443\n",
      "442 443\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Compute the road network distances between each pair of sensor edges dynamically\n",
    "num_sensors = len(sensor_edges)\n",
    "sensor_adjacency_matrix = lil_matrix((num_sensors, num_sensors), dtype=np.float32)\n",
    "\n",
    "for i in range(num_sensors):\n",
    "    for j in range(i + 1, num_sensors):  # Only compute for upper triangle to avoid redundant calculations\n",
    "        print(i,j)\n",
    "        edge1 = sensor_edges.iloc[i]\n",
    "        edge2 = sensor_edges.iloc[j]\n",
    "\n",
    "        # Get the shortest road network distance between the start vertices of the sensor edges\n",
    "        distance = get_dynamic_network_distance(edge1, edge2)\n",
    "\n",
    "        # Fill the adjacency matrix symmetrically\n",
    "        sensor_adjacency_matrix[i, j] = distance\n",
    "        sensor_adjacency_matrix[j, i] = distance  # Symmetry since the graph is undirected\n",
    "\n",
    "# Now sensor_adjacency_matrix contains the road network distances between all sensor edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CF7d8sJ2-QRQ"
   },
   "outputs": [],
   "source": [
    "dense_matrix = sensor_adjacency_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "56rig_zWFTUu"
   },
   "outputs": [],
   "source": [
    "# Save the dense matrix as a CSV file\n",
    "np.savetxt('/content/drive/MyDrive/traffic predict/dense_matrix.csv', dense_matrix, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGmaKVf1-wj8"
   },
   "source": [
    "# **Data pre-proess**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "M9McoK9sACZD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-12 15:54:51.544976: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-12 15:54:52.342109: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-12 15:54:52.606166: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-12 15:54:52.687196: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-12 15:54:53.265497: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-12 15:54:55.419444: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from itertools import product\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ymY_fsKjZBrX"
   },
   "source": [
    "Sensors:\n",
    "\n",
    "GD030A_S, GD025A_B, GD0451_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_KVeMbWF-7XB"
   },
   "outputs": [],
   "source": [
    "traffic_data = pd.read_csv('GD030A_S.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KZRSO8dF_Sik"
   },
   "source": [
    "## 1. Recover timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4TWZuMkMiYtJ"
   },
   "outputs": [],
   "source": [
    "# Define the recover_timestamp function\n",
    "def recover_timestamp(data):\n",
    "    # Combine 'date' and 'time' to form a datetime column\n",
    "    data['datetime'] = pd.to_datetime(data['date'] + ' ' + data['time'].astype(str) + ':00', format='%Y-%m-%d %H:%M')\n",
    "\n",
    "    # Set 'datetime' as index\n",
    "    data = data.set_index('datetime')\n",
    "\n",
    "    # Create a complete range of timestamps with hourly frequency\n",
    "    full_time_range = pd.date_range(start=data.index.min(), end=data.index.max(), freq='H')\n",
    "\n",
    "    # Reindex the data to include all timestamps, filling missing rows with NaN\n",
    "    data_full = data.reindex(full_time_range)\n",
    "\n",
    "    return data_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "rwy81CAA_Y4r",
    "outputId": "4877a7be-1b8c-4442-be65-d40d117d8dbf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_636502/36863830.py:10: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  full_time_range = pd.date_range(start=data.index.min(), end=data.index.max(), freq='H')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>flow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-10-01 00:00:00</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01 01:00:00</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01 02:00:00</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01 03:00:00</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01 04:00:00</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-30 19:00:00</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>19.0</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-30 20:00:00</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>20.0</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-30 21:00:00</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>21.0</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-30 22:00:00</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>22.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-30 23:00:00</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>23.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35064 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           date  time   flow\n",
       "2019-10-01 00:00:00  2019-10-01   0.0   15.0\n",
       "2019-10-01 01:00:00  2019-10-01   1.0    9.0\n",
       "2019-10-01 02:00:00  2019-10-01   2.0    9.0\n",
       "2019-10-01 03:00:00  2019-10-01   3.0    7.0\n",
       "2019-10-01 04:00:00  2019-10-01   4.0    9.0\n",
       "...                         ...   ...    ...\n",
       "2023-09-30 19:00:00  2023-09-30  19.0  129.0\n",
       "2023-09-30 20:00:00  2023-09-30  20.0  119.0\n",
       "2023-09-30 21:00:00  2023-09-30  21.0  106.0\n",
       "2023-09-30 22:00:00  2023-09-30  22.0   88.0\n",
       "2023-09-30 23:00:00  2023-09-30  23.0   88.0\n",
       "\n",
       "[35064 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the recover_timestamp function to recover the full time series\n",
    "traffic_full = recover_timestamp(traffic_data)\n",
    "traffic_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "OQ0AnM3RzJYo",
    "outputId": "c7ab4e27-15b2-4e24-bc37-f13d654b715f"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_objects\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgo\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Create interactive plot using Plotly\u001b[39;00m\n\u001b[1;32m      3\u001b[0m fig \u001b[38;5;241m=\u001b[39m go\u001b[38;5;241m.\u001b[39mFigure()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "# Create interactive plot using Plotly\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add observed data to the plot\n",
    "fig.add_trace(go.Scatter(x=traffic_full['flow'].index, y=traffic_full['flow'], mode='lines', name='Observed Data'))\n",
    "\n",
    "# Update layout for better visualization\n",
    "fig.update_layout(\n",
    "    title='Observed Data ',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Traffic Flow',\n",
    "    legend_title='Legend'\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8z-mdqKewzjt"
   },
   "source": [
    "## 2. Train, validate, test data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h60qTUKvwzCb",
    "outputId": "0cd7af08-7c2b-4d3d-d2a0-d060ac0dab96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of train_set : 0.6227\n",
      "Proportion of valid_set : 0.1876\n",
      "Proportion of test_set : 0.1897\n"
     ]
    }
   ],
   "source": [
    "# train_set = traffic_full[:'2022-02-28 23:00:00']\n",
    "# valid_set = traffic_full['2022-03-01 00:00:00':'2022-12-31 23:00:00']\n",
    "# test_set = traffic_full['2023-01-01 00:00:00':]\n",
    "train_set = traffic_full['2022-06-03 00:00:00':'2023-03-31 23:00:00']\n",
    "valid_set = traffic_full['2023-04-01 00:00:00':'2023-06-30 23:00:00']\n",
    "test_set = traffic_full['2023-07-01 00:00:00':]\n",
    "print('Proportion of train_set : {:.4f}'.format(len(train_set)/len(traffic_full['2022-06-03 00:00:00':])))\n",
    "print('Proportion of valid_set : {:.4f}'.format(len(valid_set)/len(traffic_full['2022-06-03 00:00:00':])))\n",
    "print('Proportion of test_set : {:.4f}'.format(len(test_set)/len(traffic_full['2022-06-03 00:00:00':])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date    16\n",
      "time    16\n",
      "flow    16\n",
      "dtype: int64 7248\n",
      "date    61\n",
      "time    61\n",
      "flow    61\n",
      "dtype: int64 2184\n",
      "date    342\n",
      "time    342\n",
      "flow    342\n",
      "dtype: int64 2208\n"
     ]
    }
   ],
   "source": [
    "print(train_set.isnull().sum(), len(train_set))\n",
    "print(valid_set.isnull().sum(),len(valid_set))\n",
    "print(test_set.isnull().sum(),len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bd0hRLpW9gJs"
   },
   "source": [
    "## 3. Normalise the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_636502/1100395100.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_set.loc[:, 'flow_scaled'] = scaler.transform(train_set[['flow']])\n",
      "/tmp/ipykernel_636502/1100395100.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  valid_set.loc[:, 'flow_scaled'] = scaler.transform(valid_set[['flow']])\n",
      "/tmp/ipykernel_636502/1100395100.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_set.loc[:, 'flow_scaled'] = scaler.transform(test_set[['flow']])\n"
     ]
    }
   ],
   "source": [
    "# Initialize the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler on the training data's 'flow' feature\n",
    "scaler.fit(train_set[['flow']])\n",
    "\n",
    "# Transform the 'flow' feature in all datasets\n",
    "train_set.loc[:, 'flow_scaled'] = scaler.transform(train_set[['flow']])\n",
    "valid_set.loc[:, 'flow_scaled'] = scaler.transform(valid_set[['flow']])\n",
    "test_set.loc[:, 'flow_scaled'] = scaler.transform(test_set[['flow']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xak17ms1uZ-6"
   },
   "source": [
    "## 4. Split the data into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, input_length, forecast_horizon):\n",
    "    \"\"\"\n",
    "    Creates input-output sequences for time series data, excluding any sequences containing NaN values.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: pandas DataFrame containing the data. Must include the 'flow_scaled' column.\n",
    "    - input_length: int, number of past time steps to include in each input sequence.\n",
    "    - forecast_horizon: int, number of future steps to predict.\n",
    "    \n",
    "    Returns:\n",
    "    - X: numpy array of shape (num_valid_samples, input_length, num_features)\n",
    "    - y: numpy array of shape (num_valid_samples, forecast_horizon)\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    num_features = data.shape[1]\n",
    "    total_length = input_length + forecast_horizon\n",
    "    \n",
    "    for i in range(input_length, len(data) - forecast_horizon + 1):\n",
    "        # Extract the input sequence\n",
    "        X_seq = data.iloc[i - input_length:i]['flow_scaled'].values\n",
    "        # Extract the target sequence\n",
    "        y_seq = data.iloc[i:i + forecast_horizon]['flow_scaled'].values\n",
    "        \n",
    "        # Check for NaN values in the input sequence and target sequence\n",
    "        if not np.isnan(X_seq).any() and not np.isnan(y_seq).any():\n",
    "            X.append(X_seq)\n",
    "            y.append(y_seq)\n",
    "        else:\n",
    "            # Optionally, log or count the skipped sequences\n",
    "            pass  # Simply skip sequences with NaNs\n",
    "        \n",
    "    # Convert to numpy arrays and reshape X to match LSTM expected input (samples, timesteps, features)\n",
    "    X = np.array(X).reshape(-1, input_length, 1)\n",
    "    y = np.array(y).reshape(-1, forecast_horizon)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create X and y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will use\n",
    "* the last 24*N steps\n",
    "\n",
    "*  to forecast current (0 step) and 5 steps ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Input Sequence Lengths\n",
    "input_lengths = [24 * i for i in range(1, 22)]  # [24, 48, ..., 168]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing input length: 408\n",
      "  X_train shape: (5993, 408, 1), y_train shape: (5993, 6)\n",
      "  X_val shape: (603, 408, 1), y_val shape: (603, 6)\n",
      "  X_test shape: (342, 408, 1), y_test shape: (342, 6)\n",
      "\n",
      "Processing input length: 432\n",
      "  X_train shape: (5921, 432, 1), y_train shape: (5921, 6)\n",
      "  X_val shape: (531, 432, 1), y_val shape: (531, 6)\n",
      "  X_test shape: (311, 432, 1), y_test shape: (311, 6)\n",
      "\n",
      "Processing input length: 456\n",
      "  X_train shape: (5849, 456, 1), y_train shape: (5849, 6)\n",
      "  X_val shape: (459, 456, 1), y_val shape: (459, 6)\n",
      "  X_test shape: (287, 456, 1), y_test shape: (287, 6)\n",
      "\n",
      "Processing input length: 480\n",
      "  X_train shape: (5777, 480, 1), y_train shape: (5777, 6)\n",
      "  X_val shape: (387, 480, 1), y_val shape: (387, 6)\n",
      "  X_test shape: (263, 480, 1), y_test shape: (263, 6)\n",
      "\n",
      "Processing input length: 504\n",
      "  X_train shape: (5705, 504, 1), y_train shape: (5705, 6)\n",
      "  X_val shape: (333, 504, 1), y_val shape: (333, 6)\n",
      "  X_test shape: (239, 504, 1), y_test shape: (239, 6)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "data_dict = defaultdict(dict)\n",
    "\n",
    "for length in input_lengths:\n",
    "    print(f\"Processing input length: {length}\")\n",
    "    \n",
    "    # Create sequences with forecast_horizon=6\n",
    "    X_train, y_train = create_sequences(train_set, length, forecast_horizon=6)\n",
    "    X_val, y_val = create_sequences(valid_set, length, forecast_horizon=6)\n",
    "    X_test, y_test = create_sequences(test_set, length, forecast_horizon=6)\n",
    "    \n",
    "    # Store in the dictionary\n",
    "    data_dict[length]['X_train'] = X_train\n",
    "    data_dict[length]['y_train'] = y_train\n",
    "    data_dict[length]['X_val'] = X_val\n",
    "    data_dict[length]['y_val'] = y_val\n",
    "    data_dict[length]['X_test'] = X_test\n",
    "    data_dict[length]['y_test'] = y_test\n",
    "    \n",
    "    # Print shapes and ensure no NaNs\n",
    "    print(f\"  X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "    print(f\"  X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
    "    print(f\"  X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Buid the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_model(hyperparams, input_length):\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    # First Conv layer requires input shape\n",
    "    model.add(layers.Conv1D(filters=hyperparams['filters'], \n",
    "                            kernel_size=hyperparams['kernel_size'],\n",
    "                            activation='relu',\n",
    "                            input_shape=(input_length, 1)))\n",
    "    model.add(layers.Conv1D(filters=hyperparams['filters'], \n",
    "                            kernel_size=hyperparams['kernel_size'],\n",
    "                            activation='relu'))\n",
    "    model.add(layers.MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dropout(rate=hyperparams['dropout']))\n",
    "    model.add(layers.Dense(6))  # Output layer for multi-step forecasting\n",
    "    \n",
    "    # Compile the model with MSE as the loss function\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=hyperparams['learning_rate'])\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mse'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Define the hyperparameter grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_grid = {               \n",
    "    'filters': [32, 64, 128],                  # Number of filters in each Conv layer\n",
    "    'kernel_size': [2, 3, 5],                     # Size of the convolutional kernels\n",
    "    'dropout': [0.0, 0.1, 0.2, 0.3],                # Dropout rates to prevent overfitting\n",
    "    'learning_rate': [0.001, 0.0005, 0.0001],          # Learning rates for the optimizer\n",
    "    'batch_size': [32, 64, 128]                # Batch sizes for training\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_combinations = list(product(\n",
    "    hyperparameter_grid['filters'],\n",
    "    hyperparameter_grid['kernel_size'],\n",
    "    hyperparameter_grid['dropout'],\n",
    "    hyperparameter_grid['learning_rate'],\n",
    "    hyperparameter_grid['batch_size']\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_combinations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting grid search for input length: 408\n",
      "  Evaluating combination 1/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-10-12 15:56:48.447342: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00447\n",
      "  Evaluating combination 2/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 3/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 4/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 5/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 6/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 7/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 8/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00411\n",
      "  Evaluating combination 9/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00419\n",
      "  Evaluating combination 10/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 11/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 12/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00397\n",
      "  Evaluating combination 13/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00457\n",
      "  Evaluating combination 14/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00440\n",
      "  Evaluating combination 15/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 16/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 17/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 18/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00414\n",
      "  Evaluating combination 19/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00414\n",
      "  Evaluating combination 20/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00414\n",
      "  Evaluating combination 21/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 22/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 23/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 24/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 25/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00412\n",
      "  Evaluating combination 26/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.00422\n",
      "  Evaluating combination 27/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.00421\n",
      "  Evaluating combination 28/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 29/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 30/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 31/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 32/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 33/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00408\n",
      "  Evaluating combination 34/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00410\n",
      "  Evaluating combination 35/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 36/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 37/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00454\n",
      "  Evaluating combination 38/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 39/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00443\n",
      "  Evaluating combination 40/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 41/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00460\n",
      "  Evaluating combination 42/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00413\n",
      "  Evaluating combination 43/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 44/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 45/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 46/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00468\n",
      "  Evaluating combination 47/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00467\n",
      "  Evaluating combination 48/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00415\n",
      "  Evaluating combination 49/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00440\n",
      "  Evaluating combination 50/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 51/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 52/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 53/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 54/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00413\n",
      "  Evaluating combination 55/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 56/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00443\n",
      "  Evaluating combination 57/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00422\n",
      "  Evaluating combination 58/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 59/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 60/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 61/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 62/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 63/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 64/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 65/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00441\n",
      "  Evaluating combination 66/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 67/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 68/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00443\n",
      "  Evaluating combination 69/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 70/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 71/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 72/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 73/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00471\n",
      "  Evaluating combination 74/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00456\n",
      "  Evaluating combination 75/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00450\n",
      "  Evaluating combination 76/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 77/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 78/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00455\n",
      "  Evaluating combination 79/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 80/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 81/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.00455\n",
      "  Evaluating combination 82/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00452\n",
      "  Evaluating combination 83/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00453\n",
      "  Evaluating combination 84/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00459\n",
      "  Evaluating combination 85/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00449\n",
      "  Evaluating combination 86/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00457\n",
      "  Evaluating combination 87/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00454\n",
      "  Evaluating combination 88/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 89/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 90/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.00452\n",
      "  Evaluating combination 91/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00472\n",
      "  Evaluating combination 92/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 93/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00459\n",
      "  Evaluating combination 94/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 95/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00459\n",
      "  Evaluating combination 96/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 97/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 98/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 99/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 100/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 101/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00449\n",
      "  Evaluating combination 102/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 103/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 104/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 105/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00448\n",
      "  Evaluating combination 106/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00458\n",
      "  Evaluating combination 107/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 108/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00447\n",
      "  Evaluating combination 109/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00452\n",
      "  Evaluating combination 110/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 111/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00412\n",
      "  Evaluating combination 112/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00440\n",
      "  Evaluating combination 113/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00421\n",
      "  Evaluating combination 114/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 115/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00402\n",
      "  Evaluating combination 116/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00411\n",
      "  Evaluating combination 117/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00407\n",
      "  Evaluating combination 118/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00456\n",
      "  Evaluating combination 119/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 120/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 121/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 122/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 123/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00411\n",
      "  Evaluating combination 124/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00412\n",
      "  Evaluating combination 125/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00406\n",
      "  Evaluating combination 126/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 127/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 128/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 129/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 130/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 131/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 132/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00421\n",
      "  Evaluating combination 133/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 134/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 135/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 136/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 137/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 138/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 139/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00419\n",
      "  Evaluating combination 140/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00422\n",
      "  Evaluating combination 141/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 142/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00407\n",
      "  Evaluating combination 143/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 144/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00412\n",
      "  Evaluating combination 145/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 146/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00456\n",
      "  Evaluating combination 147/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 148/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 149/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 150/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00419\n",
      "  Evaluating combination 151/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 152/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 153/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 154/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00472\n",
      "  Evaluating combination 155/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 156/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 157/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00443\n",
      "  Evaluating combination 158/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00406\n",
      "  Evaluating combination 159/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 160/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00435\n",
      "  Evaluating combination 161/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00415\n",
      "  Evaluating combination 162/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 163/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00442\n",
      "  Evaluating combination 164/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00450\n",
      "  Evaluating combination 165/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00441\n",
      "  Evaluating combination 166/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 167/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 168/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 169/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 170/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 171/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 172/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00442\n",
      "  Evaluating combination 173/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 174/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 175/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00440\n",
      "  Evaluating combination 176/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 177/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 178/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 179/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00422\n",
      "  Evaluating combination 180/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 181/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 182/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 183/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00469\n",
      "  Evaluating combination 184/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00473\n",
      "  Evaluating combination 185/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00459\n",
      "  Evaluating combination 186/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 187/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00451\n",
      "  Evaluating combination 188/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 189/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 190/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00478\n",
      "  Evaluating combination 191/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 192/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00465\n",
      "  Evaluating combination 193/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 194/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 195/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00454\n",
      "  Evaluating combination 196/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 197/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 198/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00450\n",
      "  Evaluating combination 199/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00458\n",
      "  Evaluating combination 200/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00464\n",
      "  Evaluating combination 201/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 202/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00472\n",
      "  Evaluating combination 203/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00457\n",
      "  Evaluating combination 204/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00442\n",
      "  Evaluating combination 205/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 206/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 207/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 208/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00450\n",
      "  Evaluating combination 209/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 210/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00451\n",
      "  Evaluating combination 211/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00454\n",
      "  Evaluating combination 212/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00440\n",
      "  Evaluating combination 213/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 214/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 215/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 216/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 217/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 218/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 219/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 220/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00422\n",
      "  Evaluating combination 221/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 222/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00415\n",
      "  Evaluating combination 223/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00421\n",
      "  Evaluating combination 224/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00408\n",
      "  Evaluating combination 225/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00410\n",
      "  Evaluating combination 226/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00440\n",
      "  Evaluating combination 227/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 228/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 229/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00422\n",
      "  Evaluating combination 230/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 231/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00412\n",
      "  Evaluating combination 232/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00419\n",
      "  Evaluating combination 233/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00412\n",
      "  Evaluating combination 234/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00412\n",
      "  Evaluating combination 235/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00441\n",
      "  Evaluating combination 236/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 237/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00402\n",
      "  Evaluating combination 238/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 239/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 240/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00419\n",
      "  Evaluating combination 241/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 242/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00411\n",
      "  Evaluating combination 243/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00409\n",
      "  Evaluating combination 244/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00453\n",
      "  Evaluating combination 245/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 246/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00413\n",
      "  Evaluating combination 247/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 248/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 249/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 250/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00413\n",
      "  Evaluating combination 251/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 252/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00411\n",
      "  Evaluating combination 253/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00464\n",
      "  Evaluating combination 254/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 255/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 256/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 257/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 258/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00412\n",
      "  Evaluating combination 259/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 260/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 261/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 262/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00451\n",
      "  Evaluating combination 263/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00440\n",
      "  Evaluating combination 264/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 265/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00421\n",
      "  Evaluating combination 266/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 267/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 268/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00421\n",
      "  Evaluating combination 269/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 270/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 271/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00451\n",
      "  Evaluating combination 272/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 273/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 274/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 275/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 276/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 277/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 278/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 279/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00414\n",
      "  Evaluating combination 280/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00451\n",
      "  Evaluating combination 281/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 282/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 283/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 284/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 285/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 286/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 287/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00419\n",
      "  Evaluating combination 288/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00409\n",
      "  Evaluating combination 289/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00476\n",
      "  Evaluating combination 290/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00449\n",
      "  Evaluating combination 291/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00465\n",
      "  Evaluating combination 292/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 293/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00450\n",
      "  Evaluating combination 294/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00441\n",
      "  Evaluating combination 295/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00450\n",
      "  Evaluating combination 296/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 297/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 298/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00456\n",
      "  Evaluating combination 299/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00469\n",
      "  Evaluating combination 300/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00455\n",
      "  Evaluating combination 301/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00451\n",
      "  Evaluating combination 302/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00450\n",
      "  Evaluating combination 303/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00452\n",
      "  Evaluating combination 304/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 305/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 306/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 307/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00468\n",
      "  Evaluating combination 308/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 309/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00443\n",
      "  Evaluating combination 310/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00451\n",
      "  Evaluating combination 311/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00443\n",
      "  Evaluating combination 312/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00447\n",
      "  Evaluating combination 313/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 314/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00440\n",
      "  Evaluating combination 315/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.00422\n",
      "  Evaluating combination 316/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00451\n",
      "  Evaluating combination 317/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 318/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 319/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 320/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 321/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 322/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 323/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 324/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00431\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Completed grid search for input length: 408\n",
      "  Best Validation MSE: 0.0040\n",
      "  Best Hyperparameters: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "\n",
      "Starting grid search for input length: 432\n",
      "  Evaluating combination 1/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00456\n",
      "  Evaluating combination 2/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00421\n",
      "  Evaluating combination 3/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00441\n",
      "  Evaluating combination 4/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 5/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00435\n",
      "  Evaluating combination 6/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 7/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00413\n",
      "  Evaluating combination 8/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 9/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 10/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00450\n",
      "  Evaluating combination 11/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 12/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00441\n",
      "  Evaluating combination 13/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 14/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 15/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 16/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 17/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00410\n",
      "  Evaluating combination 18/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.00411\n",
      "  Evaluating combination 19/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 20/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 21/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00422\n",
      "  Evaluating combination 22/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00458\n",
      "  Evaluating combination 23/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 24/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 25/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00421\n",
      "  Evaluating combination 26/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00410\n",
      "  Evaluating combination 27/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 28/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 29/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00447\n",
      "  Evaluating combination 30/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 31/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 32/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 33/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 34/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 35/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 36/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00440\n",
      "  Evaluating combination 37/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00459\n",
      "  Evaluating combination 38/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00451\n",
      "  Evaluating combination 39/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 40/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00461\n",
      "  Evaluating combination 41/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 42/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 43/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00392\n",
      "  Evaluating combination 44/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 45/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 46/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00473\n",
      "  Evaluating combination 47/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00443\n",
      "  Evaluating combination 48/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 49/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 50/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00450\n",
      "  Evaluating combination 51/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00440\n",
      "  Evaluating combination 52/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00435\n",
      "  Evaluating combination 53/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 54/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 55/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00478\n",
      "  Evaluating combination 56/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00457\n",
      "  Evaluating combination 57/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00451\n",
      "  Evaluating combination 58/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00453\n",
      "  Evaluating combination 59/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 60/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00440\n",
      "  Evaluating combination 61/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 62/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 63/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 64/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00467\n",
      "  Evaluating combination 65/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00459\n",
      "  Evaluating combination 66/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00464\n",
      "  Evaluating combination 67/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00450\n",
      "  Evaluating combination 68/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00442\n",
      "  Evaluating combination 69/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 70/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 71/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00441\n",
      "  Evaluating combination 72/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 73/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00481\n",
      "  Evaluating combination 74/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00476\n",
      "  Evaluating combination 75/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00465\n",
      "  Evaluating combination 76/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00473\n",
      "  Evaluating combination 77/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00467\n",
      "  Evaluating combination 78/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00460\n",
      "  Evaluating combination 79/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00455\n",
      "  Evaluating combination 80/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00465\n",
      "  Evaluating combination 81/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00440\n",
      "  Evaluating combination 82/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00480\n",
      "  Evaluating combination 83/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00471\n",
      "  Evaluating combination 84/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00481\n",
      "  Evaluating combination 85/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00465\n",
      "  Evaluating combination 86/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00455\n",
      "  Evaluating combination 87/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00471\n",
      "  Evaluating combination 88/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 89/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 90/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.00455\n",
      "  Evaluating combination 91/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00467\n",
      "  Evaluating combination 92/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00469\n",
      "  Evaluating combination 93/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00483\n",
      "  Evaluating combination 94/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00453\n",
      "  Evaluating combination 95/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00472\n",
      "  Evaluating combination 96/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00490\n",
      "  Evaluating combination 97/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00452\n",
      "  Evaluating combination 98/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00448\n",
      "  Evaluating combination 99/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00451\n",
      "  Evaluating combination 100/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00456\n",
      "  Evaluating combination 101/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00475\n",
      "  Evaluating combination 102/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00473\n",
      "  Evaluating combination 103/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00453\n",
      "  Evaluating combination 104/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00461\n",
      "  Evaluating combination 105/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00466\n",
      "  Evaluating combination 106/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 107/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 108/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.00455\n",
      "  Evaluating combination 109/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00451\n",
      "  Evaluating combination 110/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00450\n",
      "  Evaluating combination 111/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 112/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 113/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00449\n",
      "  Evaluating combination 114/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00415\n",
      "  Evaluating combination 115/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 116/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00412\n",
      "  Evaluating combination 117/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00416\n",
      "  Evaluating combination 118/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00466\n",
      "  Evaluating combination 119/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00441\n",
      "  Evaluating combination 120/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 121/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 122/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 123/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00441\n",
      "  Evaluating combination 124/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00414\n",
      "  Evaluating combination 125/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00421\n",
      "  Evaluating combination 126/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00414\n",
      "  Evaluating combination 127/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00458\n",
      "  Evaluating combination 128/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00455\n",
      "  Evaluating combination 129/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 130/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 131/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 132/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 133/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 134/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 135/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00419\n",
      "  Evaluating combination 136/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00458\n",
      "  Evaluating combination 137/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00453\n",
      "  Evaluating combination 138/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 139/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00450\n",
      "  Evaluating combination 140/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 141/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 142/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 143/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 144/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 145/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00478\n",
      "  Evaluating combination 146/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 147/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 148/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 149/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 150/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 151/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 152/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00443\n",
      "  Evaluating combination 153/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 154/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00498\n",
      "  Evaluating combination 155/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00448\n",
      "  Evaluating combination 156/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00471\n",
      "  Evaluating combination 157/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00468\n",
      "  Evaluating combination 158/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 159/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00435\n",
      "  Evaluating combination 160/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 161/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 162/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 163/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00464\n",
      "  Evaluating combination 164/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00443\n",
      "  Evaluating combination 165/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 166/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 167/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 168/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00458\n",
      "  Evaluating combination 169/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 170/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00427\n",
      "  Evaluating combination 171/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00432\n",
      "  Evaluating combination 172/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00502\n",
      "  Evaluating combination 173/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00453\n",
      "  Evaluating combination 174/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 175/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 176/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 177/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00449\n",
      "  Evaluating combination 178/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 179/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00419\n",
      "  Evaluating combination 180/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 181/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00478\n",
      "  Evaluating combination 182/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00491\n",
      "  Evaluating combination 183/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00480\n",
      "  Evaluating combination 184/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00479\n",
      "  Evaluating combination 185/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00479\n",
      "  Evaluating combination 186/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00489\n",
      "  Evaluating combination 187/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 188/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00448\n",
      "  Evaluating combination 189/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00456\n",
      "  Evaluating combination 190/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00470\n",
      "  Evaluating combination 191/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00450\n",
      "  Evaluating combination 192/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00460\n",
      "  Evaluating combination 193/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 194/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00477\n",
      "  Evaluating combination 195/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00465\n",
      "  Evaluating combination 196/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00441\n",
      "  Evaluating combination 197/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 198/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 199/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00462\n",
      "  Evaluating combination 200/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00468\n",
      "  Evaluating combination 201/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00460\n",
      "  Evaluating combination 202/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00477\n",
      "  Evaluating combination 203/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00449\n",
      "  Evaluating combination 204/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00447\n",
      "  Evaluating combination 205/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00447\n",
      "  Evaluating combination 206/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00443\n",
      "  Evaluating combination 207/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 208/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00456\n",
      "  Evaluating combination 209/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00466\n",
      "  Evaluating combination 210/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00450\n",
      "  Evaluating combination 211/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00456\n",
      "  Evaluating combination 212/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00456\n",
      "  Evaluating combination 213/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00460\n",
      "  Evaluating combination 214/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00442\n",
      "  Evaluating combination 215/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 216/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 217/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00451\n",
      "  Evaluating combination 218/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00448\n",
      "  Evaluating combination 219/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00450\n",
      "  Evaluating combination 220/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00471\n",
      "  Evaluating combination 221/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 222/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00440\n",
      "  Evaluating combination 223/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 224/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 225/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00408\n",
      "  Evaluating combination 226/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00492\n",
      "  Evaluating combination 227/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00443\n",
      "  Evaluating combination 228/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00458\n",
      "  Evaluating combination 229/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00457\n",
      "  Evaluating combination 230/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00419\n",
      "  Evaluating combination 231/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 232/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 233/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00414\n",
      "  Evaluating combination 234/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00419\n",
      "  Evaluating combination 235/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 236/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00460\n",
      "  Evaluating combination 237/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00434\n",
      "  Evaluating combination 238/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00455\n",
      "  Evaluating combination 239/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 240/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 241/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00422\n",
      "  Evaluating combination 242/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00419\n",
      "  Evaluating combination 243/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 244/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00447\n",
      "  Evaluating combination 245/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 246/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00440\n",
      "  Evaluating combination 247/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00464\n",
      "  Evaluating combination 248/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 249/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00451\n",
      "  Evaluating combination 250/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00415\n",
      "  Evaluating combination 251/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00423\n",
      "  Evaluating combination 252/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 253/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00476\n",
      "  Evaluating combination 254/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00446\n",
      "  Evaluating combination 255/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 256/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00440\n",
      "  Evaluating combination 257/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 258/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 259/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 260/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00422\n",
      "  Evaluating combination 261/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00425\n",
      "  Evaluating combination 262/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00485\n",
      "  Evaluating combination 263/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00462\n",
      "  Evaluating combination 264/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00448\n",
      "  Evaluating combination 265/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00448\n",
      "  Evaluating combination 266/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00454\n",
      "  Evaluating combination 267/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 268/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00429\n",
      "  Evaluating combination 269/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00428\n",
      "  Evaluating combination 270/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00420\n",
      "  Evaluating combination 271/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00471\n",
      "  Evaluating combination 272/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00449\n",
      "  Evaluating combination 273/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00441\n",
      "  Evaluating combination 274/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00455\n",
      "  Evaluating combination 275/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 276/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00449\n",
      "  Evaluating combination 277/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00422\n",
      "  Evaluating combination 278/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00422\n",
      "  Evaluating combination 279/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00417\n",
      "  Evaluating combination 280/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00467\n",
      "  Evaluating combination 281/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00451\n",
      "  Evaluating combination 282/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00441\n",
      "  Evaluating combination 283/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00462\n",
      "  Evaluating combination 284/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 285/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 286/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00424\n",
      "  Evaluating combination 287/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00426\n",
      "  Evaluating combination 288/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00418\n",
      "  Evaluating combination 289/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00474\n",
      "  Evaluating combination 290/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00462\n",
      "  Evaluating combination 291/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00474\n",
      "  Evaluating combination 292/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00474\n",
      "  Evaluating combination 293/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00463\n",
      "  Evaluating combination 294/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00467\n",
      "  Evaluating combination 295/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00437\n",
      "  Evaluating combination 296/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00451\n",
      "  Evaluating combination 297/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00431\n",
      "  Evaluating combination 298/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00459\n",
      "  Evaluating combination 299/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00470\n",
      "  Evaluating combination 300/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00478\n",
      "  Evaluating combination 301/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00461\n",
      "  Evaluating combination 302/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00440\n",
      "  Evaluating combination 303/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 304/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00459\n",
      "  Evaluating combination 305/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00452\n",
      "  Evaluating combination 306/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00436\n",
      "  Evaluating combination 307/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00474\n",
      "  Evaluating combination 308/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00455\n",
      "  Evaluating combination 309/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00480\n",
      "  Evaluating combination 310/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00467\n",
      "  Evaluating combination 311/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00461\n",
      "  Evaluating combination 312/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00460\n",
      "  Evaluating combination 313/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00439\n",
      "  Evaluating combination 314/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00445\n",
      "  Evaluating combination 315/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00433\n",
      "  Evaluating combination 316/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00464\n",
      "  Evaluating combination 317/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00447\n",
      "  Evaluating combination 318/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00476\n",
      "  Evaluating combination 319/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00466\n",
      "  Evaluating combination 320/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00448\n",
      "  Evaluating combination 321/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00456\n",
      "  Evaluating combination 322/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00438\n",
      "  Evaluating combination 323/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00444\n",
      "  Evaluating combination 324/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00433\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Completed grid search for input length: 432\n",
      "  Best Validation MSE: 0.0039\n",
      "  Best Hyperparameters: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "\n",
      "Starting grid search for input length: 456\n",
      "  Evaluating combination 1/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00486\n",
      "  Evaluating combination 2/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00480\n",
      "  Evaluating combination 3/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00464\n",
      "  Evaluating combination 4/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00477\n",
      "  Evaluating combination 5/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00473\n",
      "  Evaluating combination 6/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00496\n",
      "  Evaluating combination 7/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00476\n",
      "  Evaluating combination 8/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00475\n",
      "  Evaluating combination 9/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.00479\n",
      "  Evaluating combination 10/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00528\n",
      "  Evaluating combination 11/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00495\n",
      "  Evaluating combination 12/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00472\n",
      "  Evaluating combination 13/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00483\n",
      "  Evaluating combination 14/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00496\n",
      "  Evaluating combination 15/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00465\n",
      "  Evaluating combination 16/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00469\n",
      "  Evaluating combination 17/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00497\n",
      "  Evaluating combination 18/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00502\n",
      "  Evaluating combination 19/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00500\n",
      "  Evaluating combination 20/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00500\n",
      "  Evaluating combination 21/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00490\n",
      "  Evaluating combination 22/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00478\n",
      "  Evaluating combination 23/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00492\n",
      "  Evaluating combination 24/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00462\n",
      "  Evaluating combination 25/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00460\n",
      "  Evaluating combination 26/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00484\n",
      "  Evaluating combination 27/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.00485\n",
      "  Evaluating combination 28/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00516\n",
      "  Evaluating combination 29/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00494\n",
      "  Evaluating combination 30/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00473\n",
      "  Evaluating combination 31/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00473\n",
      "  Evaluating combination 32/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00468\n",
      "  Evaluating combination 33/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00460\n",
      "  Evaluating combination 34/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00467\n",
      "  Evaluating combination 35/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00481\n",
      "  Evaluating combination 36/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00498\n",
      "  Evaluating combination 37/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00488\n",
      "  Evaluating combination 38/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00493\n",
      "  Evaluating combination 39/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00490\n",
      "  Evaluating combination 40/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00512\n",
      "  Evaluating combination 41/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00484\n",
      "  Evaluating combination 42/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00492\n",
      "  Evaluating combination 43/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00474\n",
      "  Evaluating combination 44/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00430\n",
      "  Evaluating combination 45/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00450\n",
      "  Evaluating combination 46/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00505\n",
      "  Evaluating combination 47/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00505\n",
      "  Evaluating combination 48/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00513\n",
      "  Evaluating combination 49/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00507\n",
      "  Evaluating combination 50/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00486\n",
      "  Evaluating combination 51/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00496\n",
      "  Evaluating combination 52/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00466\n",
      "  Evaluating combination 53/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00493\n",
      "  Evaluating combination 54/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00483\n",
      "  Evaluating combination 55/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00508\n",
      "  Evaluating combination 56/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00500\n",
      "  Evaluating combination 57/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00483\n",
      "  Evaluating combination 58/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00480\n",
      "  Evaluating combination 59/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00496\n",
      "  Evaluating combination 60/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00480\n",
      "  Evaluating combination 61/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00463\n",
      "  Evaluating combination 62/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00473\n",
      "  Evaluating combination 63/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00471\n",
      "  Evaluating combination 64/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00501\n",
      "  Evaluating combination 65/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00501\n",
      "  Evaluating combination 66/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00513\n",
      "  Evaluating combination 67/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00499\n",
      "  Evaluating combination 68/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00494\n",
      "  Evaluating combination 69/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00474\n",
      "  Evaluating combination 70/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00472\n",
      "  Evaluating combination 71/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00510\n",
      "  Evaluating combination 72/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.00463\n",
      "  Evaluating combination 73/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00546\n",
      "  Evaluating combination 74/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00531\n",
      "  Evaluating combination 75/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00568\n",
      "  Evaluating combination 76/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00515\n",
      "  Evaluating combination 77/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00529\n",
      "  Evaluating combination 78/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00544\n",
      "  Evaluating combination 79/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00486\n",
      "  Evaluating combination 80/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00511\n",
      "  Evaluating combination 81/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00466\n",
      "  Evaluating combination 82/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00540\n",
      "  Evaluating combination 83/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00543\n",
      "  Evaluating combination 84/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00523\n",
      "  Evaluating combination 85/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00516\n",
      "  Evaluating combination 86/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00503\n",
      "  Evaluating combination 87/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00519\n",
      "  Evaluating combination 88/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00464\n",
      "  Evaluating combination 89/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00510\n",
      "  Evaluating combination 90/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.00500\n",
      "  Evaluating combination 91/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00530\n",
      "  Evaluating combination 92/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00515\n",
      "  Evaluating combination 93/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00525\n",
      "  Evaluating combination 94/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00532\n",
      "  Evaluating combination 95/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00520\n",
      "  Evaluating combination 96/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00473\n",
      "  Evaluating combination 97/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00507\n",
      "  Evaluating combination 98/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.00477\n",
      "  Evaluating combination 99/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00495\n",
      "  Evaluating combination 100/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00520\n",
      "  Evaluating combination 101/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00495\n",
      "  Evaluating combination 102/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00507\n",
      "  Evaluating combination 103/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00532\n",
      "  Evaluating combination 104/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00519\n",
      "  Evaluating combination 105/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00507\n",
      "  Evaluating combination 106/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00474\n",
      "  Evaluating combination 107/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.00500\n",
      "  Evaluating combination 108/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00482\n",
      "  Evaluating combination 109/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00495\n",
      "  Evaluating combination 110/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00506\n",
      "  Evaluating combination 111/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00497\n",
      "  Evaluating combination 112/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00509\n",
      "  Evaluating combination 113/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00484\n",
      "  Evaluating combination 114/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00459\n",
      "  Evaluating combination 115/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00465\n",
      "  Evaluating combination 116/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00471\n",
      "  Evaluating combination 117/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00480\n",
      "  Evaluating combination 118/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00520\n",
      "  Evaluating combination 119/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00500\n",
      "  Evaluating combination 120/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00493\n",
      "  Evaluating combination 121/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00479\n",
      "  Evaluating combination 122/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00488\n",
      "  Evaluating combination 123/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00478\n",
      "  Evaluating combination 124/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00466\n",
      "  Evaluating combination 125/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00475\n",
      "  Evaluating combination 126/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00479\n",
      "  Evaluating combination 127/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00516\n",
      "  Evaluating combination 128/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00503\n",
      "  Evaluating combination 129/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00489\n",
      "  Evaluating combination 130/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00495\n",
      "  Evaluating combination 131/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00490\n",
      "  Evaluating combination 132/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00472\n",
      "  Evaluating combination 133/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00448\n",
      "  Evaluating combination 134/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00468\n",
      "  Evaluating combination 135/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00476\n",
      "  Evaluating combination 136/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00481\n",
      "  Evaluating combination 137/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00488\n",
      "  Evaluating combination 138/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00496\n",
      "  Evaluating combination 139/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00487\n",
      "  Evaluating combination 140/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00491\n",
      "  Evaluating combination 141/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00482\n",
      "  Evaluating combination 142/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00467\n",
      "  Evaluating combination 143/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00472\n",
      "  Evaluating combination 144/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00468\n",
      "  Evaluating combination 145/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00497\n",
      "  Evaluating combination 146/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00513\n",
      "  Evaluating combination 147/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00506\n",
      "  Evaluating combination 148/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00504\n",
      "  Evaluating combination 149/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00504\n",
      "  Evaluating combination 150/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00478\n",
      "  Evaluating combination 151/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00491\n",
      "  Evaluating combination 152/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00475\n",
      "  Evaluating combination 153/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00479\n",
      "  Evaluating combination 154/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00519\n",
      "  Evaluating combination 155/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00517\n",
      "  Evaluating combination 156/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00516\n",
      "  Evaluating combination 157/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00495\n",
      "  Evaluating combination 158/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00480\n",
      "  Evaluating combination 159/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00481\n",
      "  Evaluating combination 160/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00484\n",
      "  Evaluating combination 161/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00474\n",
      "  Evaluating combination 162/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00486\n",
      "  Evaluating combination 163/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00501\n",
      "  Evaluating combination 164/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00475\n",
      "  Evaluating combination 165/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00510\n",
      "  Evaluating combination 166/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00509\n",
      "  Evaluating combination 167/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00482\n",
      "  Evaluating combination 168/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00475\n",
      "  Evaluating combination 169/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00475\n",
      "  Evaluating combination 170/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00473\n",
      "  Evaluating combination 171/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00478\n",
      "  Evaluating combination 172/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00524\n",
      "  Evaluating combination 173/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00506\n",
      "  Evaluating combination 174/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00502\n",
      "  Evaluating combination 175/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00514\n",
      "  Evaluating combination 176/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00469\n",
      "  Evaluating combination 177/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00482\n",
      "  Evaluating combination 178/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00478\n",
      "  Evaluating combination 179/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.00468\n",
      "  Evaluating combination 180/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00464\n",
      "  Evaluating combination 181/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00528\n",
      "  Evaluating combination 182/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00533\n",
      "  Evaluating combination 183/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00506\n",
      "  Evaluating combination 184/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00533\n",
      "  Evaluating combination 185/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00524\n",
      "  Evaluating combination 186/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00500\n",
      "  Evaluating combination 187/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00504\n",
      "  Evaluating combination 188/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00499\n",
      "  Evaluating combination 189/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00519\n",
      "  Evaluating combination 190/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00509\n",
      "  Evaluating combination 191/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00527\n",
      "  Evaluating combination 192/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00471\n",
      "  Evaluating combination 193/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00516\n",
      "  Evaluating combination 194/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00528\n",
      "  Evaluating combination 195/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00517\n",
      "  Evaluating combination 196/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00502\n",
      "  Evaluating combination 197/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00493\n",
      "  Evaluating combination 198/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00486\n",
      "  Evaluating combination 199/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00508\n",
      "  Evaluating combination 200/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00506\n",
      "  Evaluating combination 201/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00530\n",
      "  Evaluating combination 202/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00496\n",
      "  Evaluating combination 203/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00500\n",
      "  Evaluating combination 204/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00472\n",
      "  Evaluating combination 205/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00481\n",
      "  Evaluating combination 206/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00489\n",
      "  Evaluating combination 207/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00487\n",
      "  Evaluating combination 208/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00491\n",
      "  Evaluating combination 209/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00515\n",
      "  Evaluating combination 210/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00515\n",
      "  Evaluating combination 211/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00504\n",
      "  Evaluating combination 212/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00499\n",
      "  Evaluating combination 213/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00490\n",
      "  Evaluating combination 214/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00481\n",
      "  Evaluating combination 215/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00497\n",
      "  Evaluating combination 216/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00479\n",
      "  Evaluating combination 217/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00521\n",
      "  Evaluating combination 218/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00507\n",
      "  Evaluating combination 219/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00490\n",
      "  Evaluating combination 220/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00480\n",
      "  Evaluating combination 221/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00478\n",
      "  Evaluating combination 222/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00487\n",
      "  Evaluating combination 223/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00460\n",
      "  Evaluating combination 224/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00459\n",
      "  Evaluating combination 225/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00476\n",
      "  Evaluating combination 226/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00480\n",
      "  Evaluating combination 227/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00493\n",
      "  Evaluating combination 228/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00495\n",
      "  Evaluating combination 229/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00504\n",
      "  Evaluating combination 230/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00481\n",
      "  Evaluating combination 231/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00467\n",
      "  Evaluating combination 232/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00489\n",
      "  Evaluating combination 233/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00457\n",
      "  Evaluating combination 234/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00468\n",
      "  Evaluating combination 235/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00487\n",
      "  Evaluating combination 236/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00499\n",
      "  Evaluating combination 237/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00475\n",
      "  Evaluating combination 238/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00521\n",
      "  Evaluating combination 239/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00500\n",
      "  Evaluating combination 240/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00485\n",
      "  Evaluating combination 241/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00481\n",
      "  Evaluating combination 242/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00472\n",
      "  Evaluating combination 243/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00475\n",
      "  Evaluating combination 244/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00538\n",
      "  Evaluating combination 245/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00500\n",
      "  Evaluating combination 246/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00506\n",
      "  Evaluating combination 247/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00494\n",
      "  Evaluating combination 248/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00483\n",
      "  Evaluating combination 249/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00490\n",
      "  Evaluating combination 250/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00477\n",
      "  Evaluating combination 251/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00465\n",
      "  Evaluating combination 252/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00464\n",
      "  Evaluating combination 253/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00495\n",
      "  Evaluating combination 254/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00543\n",
      "  Evaluating combination 255/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00520\n",
      "  Evaluating combination 256/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00507\n",
      "  Evaluating combination 257/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00496\n",
      "  Evaluating combination 258/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00496\n",
      "  Evaluating combination 259/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00490\n",
      "  Evaluating combination 260/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00473\n",
      "  Evaluating combination 261/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00474\n",
      "  Evaluating combination 262/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00527\n",
      "  Evaluating combination 263/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00486\n",
      "  Evaluating combination 264/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00487\n",
      "  Evaluating combination 265/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00505\n",
      "  Evaluating combination 266/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00488\n",
      "  Evaluating combination 267/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00485\n",
      "  Evaluating combination 268/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00482\n",
      "  Evaluating combination 269/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00486\n",
      "  Evaluating combination 270/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00490\n",
      "  Evaluating combination 271/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00535\n",
      "  Evaluating combination 272/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00518\n",
      "  Evaluating combination 273/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00499\n",
      "  Evaluating combination 274/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00509\n",
      "  Evaluating combination 275/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00505\n",
      "  Evaluating combination 276/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00496\n",
      "  Evaluating combination 277/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00484\n",
      "  Evaluating combination 278/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00471\n",
      "  Evaluating combination 279/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00470\n",
      "  Evaluating combination 280/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00526\n",
      "  Evaluating combination 281/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00523\n",
      "  Evaluating combination 282/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00504\n",
      "  Evaluating combination 283/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00508\n",
      "  Evaluating combination 284/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00493\n",
      "  Evaluating combination 285/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00483\n",
      "  Evaluating combination 286/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00471\n",
      "  Evaluating combination 287/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00474\n",
      "  Evaluating combination 288/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00480\n",
      "  Evaluating combination 289/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00489\n",
      "  Evaluating combination 290/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00530\n",
      "  Evaluating combination 291/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00491\n",
      "  Evaluating combination 292/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00514\n",
      "  Evaluating combination 293/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00515\n",
      "  Evaluating combination 294/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00504\n",
      "  Evaluating combination 295/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00500\n",
      "  Evaluating combination 296/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00493\n",
      "  Evaluating combination 297/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00512\n",
      "  Evaluating combination 298/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00515\n",
      "  Evaluating combination 299/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00491\n",
      "  Evaluating combination 300/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00502\n",
      "  Evaluating combination 301/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00524\n",
      "  Evaluating combination 302/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00512\n",
      "  Evaluating combination 303/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00507\n",
      "  Evaluating combination 304/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00498\n",
      "  Evaluating combination 305/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00485\n",
      "  Evaluating combination 306/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00514\n",
      "  Evaluating combination 307/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00535\n",
      "  Evaluating combination 308/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00516\n",
      "  Evaluating combination 309/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00492\n",
      "  Evaluating combination 310/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00509\n",
      "  Evaluating combination 311/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00492\n",
      "  Evaluating combination 312/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00496\n",
      "  Evaluating combination 313/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00516\n",
      "  Evaluating combination 314/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00506\n",
      "  Evaluating combination 315/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00487\n",
      "  Evaluating combination 316/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00508\n",
      "  Evaluating combination 317/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00546\n",
      "  Evaluating combination 318/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00525\n",
      "  Evaluating combination 319/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00493\n",
      "  Evaluating combination 320/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00496\n",
      "  Evaluating combination 321/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00513\n",
      "  Evaluating combination 322/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00471\n",
      "  Evaluating combination 323/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00489\n",
      "  Evaluating combination 324/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00477\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Completed grid search for input length: 456\n",
      "  Best Validation MSE: 0.0043\n",
      "  Best Hyperparameters: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "\n",
      "Starting grid search for input length: 480\n",
      "  Evaluating combination 1/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00572\n",
      "  Evaluating combination 2/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00536\n",
      "  Evaluating combination 3/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00571\n",
      "  Evaluating combination 4/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00557\n",
      "  Evaluating combination 5/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00531\n",
      "  Evaluating combination 6/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00509\n",
      "  Evaluating combination 7/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00513\n",
      "  Evaluating combination 8/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00494\n",
      "  Evaluating combination 9/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00507\n",
      "  Evaluating combination 10/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00590\n",
      "  Evaluating combination 11/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00534\n",
      "  Evaluating combination 12/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00545\n",
      "  Evaluating combination 13/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00559\n",
      "  Evaluating combination 14/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00520\n",
      "  Evaluating combination 15/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00525\n",
      "  Evaluating combination 16/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00516\n",
      "  Evaluating combination 17/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00537\n",
      "  Evaluating combination 18/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.00514\n",
      "  Evaluating combination 19/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00564\n",
      "  Evaluating combination 20/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00528\n",
      "  Evaluating combination 21/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00512\n",
      "  Evaluating combination 22/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00533\n",
      "  Evaluating combination 23/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00533\n",
      "  Evaluating combination 24/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00510\n",
      "  Evaluating combination 25/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00539\n",
      "  Evaluating combination 26/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00500\n",
      "  Evaluating combination 27/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00528\n",
      "  Evaluating combination 28/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00539\n",
      "  Evaluating combination 29/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00555\n",
      "  Evaluating combination 30/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00531\n",
      "  Evaluating combination 31/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00551\n",
      "  Evaluating combination 32/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00535\n",
      "  Evaluating combination 33/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00527\n",
      "  Evaluating combination 34/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00508\n",
      "  Evaluating combination 35/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation loss: 0.00506\n",
      "  Evaluating combination 36/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00518\n",
      "  Evaluating combination 37/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00531\n",
      "  Evaluating combination 38/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00564\n",
      "  Evaluating combination 39/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00533\n",
      "  Evaluating combination 40/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00541\n",
      "  Evaluating combination 41/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00531\n",
      "  Evaluating combination 42/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00525\n",
      "  Evaluating combination 43/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00497\n",
      "  Evaluating combination 44/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00528\n",
      "  Evaluating combination 45/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00497\n",
      "  Evaluating combination 46/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00583\n",
      "  Evaluating combination 47/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00526\n",
      "  Evaluating combination 48/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00558\n",
      "  Evaluating combination 49/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00512\n",
      "  Evaluating combination 50/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00530\n",
      "  Evaluating combination 51/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00542\n",
      "  Evaluating combination 52/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00494\n",
      "  Evaluating combination 53/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00498\n",
      "  Evaluating combination 54/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00520\n",
      "  Evaluating combination 55/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00569\n",
      "  Evaluating combination 56/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00586\n",
      "  Evaluating combination 57/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00540\n",
      "  Evaluating combination 58/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00528\n",
      "  Evaluating combination 59/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00520\n",
      "  Evaluating combination 60/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00542\n",
      "  Evaluating combination 61/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00521\n",
      "  Evaluating combination 62/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00521\n",
      "  Evaluating combination 63/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00527\n",
      "  Evaluating combination 64/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00560\n",
      "  Evaluating combination 65/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00551\n",
      "  Evaluating combination 66/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00555\n",
      "  Evaluating combination 67/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00529\n",
      "  Evaluating combination 68/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00501\n",
      "  Evaluating combination 69/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00533\n",
      "  Evaluating combination 70/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00514\n",
      "  Evaluating combination 71/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00520\n",
      "  Evaluating combination 72/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00543\n",
      "  Evaluating combination 73/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00585\n",
      "  Evaluating combination 74/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00581\n",
      "  Evaluating combination 75/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00566\n",
      "  Evaluating combination 76/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00584\n",
      "  Evaluating combination 77/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00612\n",
      "  Evaluating combination 78/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00595\n",
      "  Evaluating combination 79/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00556\n",
      "  Evaluating combination 80/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00539\n",
      "  Evaluating combination 81/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.00546\n",
      "  Evaluating combination 82/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00600\n",
      "  Evaluating combination 83/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00568\n",
      "  Evaluating combination 84/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00560\n",
      "  Evaluating combination 85/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00561\n",
      "  Evaluating combination 86/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00558\n",
      "  Evaluating combination 87/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00566\n",
      "  Evaluating combination 88/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00531\n",
      "  Evaluating combination 89/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation loss: 0.00532\n",
      "  Evaluating combination 90/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00503\n",
      "  Evaluating combination 91/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00580\n",
      "  Evaluating combination 92/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00569\n",
      "  Evaluating combination 93/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00551\n",
      "  Evaluating combination 94/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00608\n",
      "  Evaluating combination 95/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00522\n",
      "  Evaluating combination 96/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00567\n",
      "  Evaluating combination 97/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00544\n",
      "  Evaluating combination 98/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00536\n",
      "  Evaluating combination 99/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00520\n",
      "  Evaluating combination 100/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00547\n",
      "  Evaluating combination 101/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00591\n",
      "  Evaluating combination 102/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00577\n",
      "  Evaluating combination 103/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00573\n",
      "  Evaluating combination 104/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00558\n",
      "  Evaluating combination 105/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00562\n",
      "  Evaluating combination 106/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00540\n",
      "  Evaluating combination 107/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00530\n",
      "  Evaluating combination 108/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00537\n",
      "  Evaluating combination 109/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00539\n",
      "  Evaluating combination 110/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00593\n",
      "  Evaluating combination 111/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00525\n",
      "  Evaluating combination 112/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00529\n",
      "  Evaluating combination 113/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00546\n",
      "  Evaluating combination 114/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00522\n",
      "  Evaluating combination 115/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00495\n",
      "  Evaluating combination 116/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00501\n",
      "  Evaluating combination 117/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00515\n",
      "  Evaluating combination 118/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00588\n",
      "  Evaluating combination 119/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00558\n",
      "  Evaluating combination 120/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00557\n",
      "  Evaluating combination 121/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00534\n",
      "  Evaluating combination 122/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00529\n",
      "  Evaluating combination 123/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00528\n",
      "  Evaluating combination 124/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00499\n",
      "  Evaluating combination 125/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00500\n",
      "  Evaluating combination 126/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00497\n",
      "  Evaluating combination 127/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00577\n",
      "  Evaluating combination 128/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00529\n",
      "  Evaluating combination 129/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00536\n",
      "  Evaluating combination 130/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00540\n",
      "  Evaluating combination 131/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00550\n",
      "  Evaluating combination 132/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00516\n",
      "  Evaluating combination 133/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00485\n",
      "  Evaluating combination 134/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00498\n",
      "  Evaluating combination 135/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00496\n",
      "  Evaluating combination 136/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00564\n",
      "  Evaluating combination 137/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00548\n",
      "  Evaluating combination 138/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00524\n",
      "  Evaluating combination 139/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00501\n",
      "  Evaluating combination 140/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00530\n",
      "  Evaluating combination 141/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00526\n",
      "  Evaluating combination 142/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00506\n",
      "  Evaluating combination 143/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00505\n",
      "  Evaluating combination 144/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00515\n",
      "  Evaluating combination 145/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00574\n",
      "  Evaluating combination 146/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00554\n",
      "  Evaluating combination 147/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00545\n",
      "  Evaluating combination 148/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00533\n",
      "  Evaluating combination 149/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00565\n",
      "  Evaluating combination 150/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00539\n",
      "  Evaluating combination 151/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00534\n",
      "  Evaluating combination 152/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00531\n",
      "  Evaluating combination 153/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00518\n",
      "  Evaluating combination 154/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00612\n",
      "  Evaluating combination 155/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00560\n",
      "  Evaluating combination 156/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00619\n",
      "  Evaluating combination 157/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00556\n",
      "  Evaluating combination 158/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00551\n",
      "  Evaluating combination 159/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00524\n",
      "  Evaluating combination 160/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00521\n",
      "  Evaluating combination 161/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00541\n",
      "  Evaluating combination 162/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00516\n",
      "  Evaluating combination 163/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00520\n",
      "  Evaluating combination 164/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00544\n",
      "  Evaluating combination 165/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00534\n",
      "  Evaluating combination 166/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00545\n",
      "  Evaluating combination 167/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00545\n",
      "  Evaluating combination 168/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00538\n",
      "  Evaluating combination 169/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00519\n",
      "  Evaluating combination 170/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00545\n",
      "  Evaluating combination 171/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00498\n",
      "  Evaluating combination 172/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00566\n",
      "  Evaluating combination 173/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00588\n",
      "  Evaluating combination 174/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00575\n",
      "  Evaluating combination 175/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00554\n",
      "  Evaluating combination 176/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00529\n",
      "  Evaluating combination 177/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00534\n",
      "  Evaluating combination 178/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00512\n",
      "  Evaluating combination 179/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00511\n",
      "  Evaluating combination 180/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00515\n",
      "  Evaluating combination 181/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00567\n",
      "  Evaluating combination 182/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00578\n",
      "  Evaluating combination 183/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00551\n",
      "  Evaluating combination 184/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00548\n",
      "  Evaluating combination 185/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00572\n",
      "  Evaluating combination 186/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00582\n",
      "  Evaluating combination 187/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00539\n",
      "  Evaluating combination 188/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00528\n",
      "  Evaluating combination 189/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00564\n",
      "  Evaluating combination 190/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00607\n",
      "  Evaluating combination 191/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00551\n",
      "  Evaluating combination 192/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00586\n",
      "  Evaluating combination 193/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00607\n",
      "  Evaluating combination 194/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00592\n",
      "  Evaluating combination 195/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00596\n",
      "  Evaluating combination 196/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00544\n",
      "  Evaluating combination 197/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00534\n",
      "  Evaluating combination 198/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00544\n",
      "  Evaluating combination 199/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00586\n",
      "  Evaluating combination 200/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00534\n",
      "  Evaluating combination 201/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00581\n",
      "  Evaluating combination 202/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00582\n",
      "  Evaluating combination 203/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00579\n",
      "  Evaluating combination 204/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00569\n",
      "  Evaluating combination 205/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00529\n",
      "  Evaluating combination 206/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00540\n",
      "  Evaluating combination 207/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation loss: 0.00517\n",
      "  Evaluating combination 208/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00567\n",
      "  Evaluating combination 209/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00571\n",
      "  Evaluating combination 210/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00557\n",
      "  Evaluating combination 211/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00592\n",
      "  Evaluating combination 212/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00557\n",
      "  Evaluating combination 213/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00545\n",
      "  Evaluating combination 214/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00533\n",
      "  Evaluating combination 215/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00532\n",
      "  Evaluating combination 216/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00560\n",
      "  Evaluating combination 217/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00540\n",
      "  Evaluating combination 218/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00569\n",
      "  Evaluating combination 219/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00524\n",
      "  Evaluating combination 220/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00540\n",
      "  Evaluating combination 221/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00570\n",
      "  Evaluating combination 222/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00525\n",
      "  Evaluating combination 223/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00495\n",
      "  Evaluating combination 224/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00487\n",
      "  Evaluating combination 225/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00508\n",
      "  Evaluating combination 226/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00577\n",
      "  Evaluating combination 227/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00528\n",
      "  Evaluating combination 228/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00516\n",
      "  Evaluating combination 229/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00525\n",
      "  Evaluating combination 230/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00518\n",
      "  Evaluating combination 231/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00526\n",
      "  Evaluating combination 232/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00500\n",
      "  Evaluating combination 233/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00500\n",
      "  Evaluating combination 234/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00506\n",
      "  Evaluating combination 235/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00573\n",
      "  Evaluating combination 236/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00538\n",
      "  Evaluating combination 237/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00568\n",
      "  Evaluating combination 238/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00527\n",
      "  Evaluating combination 239/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00545\n",
      "  Evaluating combination 240/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00531\n",
      "  Evaluating combination 241/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00518\n",
      "  Evaluating combination 242/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00501\n",
      "  Evaluating combination 243/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00509\n",
      "  Evaluating combination 244/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00566\n",
      "  Evaluating combination 245/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00556\n",
      "  Evaluating combination 246/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00530\n",
      "  Evaluating combination 247/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00570\n",
      "  Evaluating combination 248/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00521\n",
      "  Evaluating combination 249/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00538\n",
      "  Evaluating combination 250/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00500\n",
      "  Evaluating combination 251/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00501\n",
      "  Evaluating combination 252/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00492\n",
      "  Evaluating combination 253/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00575\n",
      "  Evaluating combination 254/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00587\n",
      "  Evaluating combination 255/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00559\n",
      "  Evaluating combination 256/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00596\n",
      "  Evaluating combination 257/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00548\n",
      "  Evaluating combination 258/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00510\n",
      "  Evaluating combination 259/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00530\n",
      "  Evaluating combination 260/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00523\n",
      "  Evaluating combination 261/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00509\n",
      "  Evaluating combination 262/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00602\n",
      "  Evaluating combination 263/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00590\n",
      "  Evaluating combination 264/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00556\n",
      "  Evaluating combination 265/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00557\n",
      "  Evaluating combination 266/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00541\n",
      "  Evaluating combination 267/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00524\n",
      "  Evaluating combination 268/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00520\n",
      "  Evaluating combination 269/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00517\n",
      "  Evaluating combination 270/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00512\n",
      "  Evaluating combination 271/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00613\n",
      "  Evaluating combination 272/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00547\n",
      "  Evaluating combination 273/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00537\n",
      "  Evaluating combination 274/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00564\n",
      "  Evaluating combination 275/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00544\n",
      "  Evaluating combination 276/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00536\n",
      "  Evaluating combination 277/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00521\n",
      "  Evaluating combination 278/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00515\n",
      "  Evaluating combination 279/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00519\n",
      "  Evaluating combination 280/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00586\n",
      "  Evaluating combination 281/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00559\n",
      "  Evaluating combination 282/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00516\n",
      "  Evaluating combination 283/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00559\n",
      "  Evaluating combination 284/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00558\n",
      "  Evaluating combination 285/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00513\n",
      "  Evaluating combination 286/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00519\n",
      "  Evaluating combination 287/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00514\n",
      "  Evaluating combination 288/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation loss: 0.00508\n",
      "  Evaluating combination 289/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00598\n",
      "  Evaluating combination 290/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00567\n",
      "  Evaluating combination 291/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00573\n",
      "  Evaluating combination 292/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00547\n",
      "  Evaluating combination 293/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00585\n",
      "  Evaluating combination 294/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00572\n",
      "  Evaluating combination 295/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00532\n",
      "  Evaluating combination 296/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00530\n",
      "  Evaluating combination 297/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00551\n",
      "  Evaluating combination 298/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00558\n",
      "  Evaluating combination 299/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00589\n",
      "  Evaluating combination 300/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00571\n",
      "  Evaluating combination 301/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00582\n",
      "  Evaluating combination 302/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00582\n",
      "  Evaluating combination 303/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00554\n",
      "  Evaluating combination 304/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00523\n",
      "  Evaluating combination 305/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00540\n",
      "  Evaluating combination 306/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00538\n",
      "  Evaluating combination 307/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00568\n",
      "  Evaluating combination 308/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00581\n",
      "  Evaluating combination 309/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00590\n",
      "  Evaluating combination 310/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00571\n",
      "  Evaluating combination 311/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00569\n",
      "  Evaluating combination 312/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00556\n",
      "  Evaluating combination 313/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00541\n",
      "  Evaluating combination 314/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00549\n",
      "  Evaluating combination 315/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00544\n",
      "  Evaluating combination 316/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00566\n",
      "  Evaluating combination 317/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00594\n",
      "  Evaluating combination 318/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00555\n",
      "  Evaluating combination 319/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00584\n",
      "  Evaluating combination 320/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00546\n",
      "  Evaluating combination 321/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00561\n",
      "  Evaluating combination 322/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00537\n",
      "  Evaluating combination 323/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00556\n",
      "  Evaluating combination 324/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00542\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "Completed grid search for input length: 480\n",
      "  Best Validation MSE: 0.0048\n",
      "  Best Hyperparameters: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "\n",
      "Starting grid search for input length: 504\n",
      "  Evaluating combination 1/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/jupyter_env/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00645\n",
      "  Evaluating combination 2/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00573\n",
      "  Evaluating combination 3/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00549\n",
      "  Evaluating combination 4/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00567\n",
      "  Evaluating combination 5/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00585\n",
      "  Evaluating combination 6/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00558\n",
      "  Evaluating combination 7/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00556\n",
      "  Evaluating combination 8/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00538\n",
      "  Evaluating combination 9/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00577\n",
      "  Evaluating combination 10/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00576\n",
      "  Evaluating combination 11/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00561\n",
      "  Evaluating combination 12/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00578\n",
      "  Evaluating combination 13/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00569\n",
      "  Evaluating combination 14/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00567\n",
      "  Evaluating combination 15/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00586\n",
      "  Evaluating combination 16/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00531\n",
      "  Evaluating combination 17/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00505\n",
      "  Evaluating combination 18/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation loss: 0.00572\n",
      "  Evaluating combination 19/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00617\n",
      "  Evaluating combination 20/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00580\n",
      "  Evaluating combination 21/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00576\n",
      "  Evaluating combination 22/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00599\n",
      "  Evaluating combination 23/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00566\n",
      "  Evaluating combination 24/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00571\n",
      "  Evaluating combination 25/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00558\n",
      "  Evaluating combination 26/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00558\n",
      "  Evaluating combination 27/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation loss: 0.00550\n",
      "  Evaluating combination 28/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00585\n",
      "  Evaluating combination 29/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00574\n",
      "  Evaluating combination 30/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00548\n",
      "  Evaluating combination 31/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00546\n",
      "  Evaluating combination 32/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00613\n",
      "  Evaluating combination 33/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00587\n",
      "  Evaluating combination 34/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00537\n",
      "  Evaluating combination 35/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00569\n",
      "  Evaluating combination 36/324: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation loss: 0.00560\n",
      "  Evaluating combination 37/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00605\n",
      "  Evaluating combination 38/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00623\n",
      "  Evaluating combination 39/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00623\n",
      "  Evaluating combination 40/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00611\n",
      "  Evaluating combination 41/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00618\n",
      "  Evaluating combination 42/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00580\n",
      "  Evaluating combination 43/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00556\n",
      "  Evaluating combination 44/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00613\n",
      "  Evaluating combination 45/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00530\n",
      "  Evaluating combination 46/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00601\n",
      "  Evaluating combination 47/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00606\n",
      "  Evaluating combination 48/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00587\n",
      "  Evaluating combination 49/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00652\n",
      "  Evaluating combination 50/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00620\n",
      "  Evaluating combination 51/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00612\n",
      "  Evaluating combination 52/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00580\n",
      "  Evaluating combination 53/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation loss: 0.00545\n",
      "  Evaluating combination 54/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00599\n",
      "  Evaluating combination 55/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00608\n",
      "  Evaluating combination 56/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00633\n",
      "  Evaluating combination 57/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00693\n",
      "  Evaluating combination 58/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00680\n",
      "  Evaluating combination 59/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00580\n",
      "  Evaluating combination 60/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00590\n",
      "  Evaluating combination 61/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00571\n",
      "  Evaluating combination 62/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00568\n",
      "  Evaluating combination 63/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00578\n",
      "  Evaluating combination 64/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00657\n",
      "  Evaluating combination 65/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00669\n",
      "  Evaluating combination 66/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00626\n",
      "  Evaluating combination 67/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00599\n",
      "  Evaluating combination 68/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00596\n",
      "  Evaluating combination 69/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00554\n",
      "  Evaluating combination 70/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00558\n",
      "  Evaluating combination 71/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00563\n",
      "  Evaluating combination 72/324: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00557\n",
      "  Evaluating combination 73/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00668\n",
      "  Evaluating combination 74/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00676\n",
      "  Evaluating combination 75/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00646\n",
      "  Evaluating combination 76/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00648\n",
      "  Evaluating combination 77/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00617\n",
      "  Evaluating combination 78/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00662\n",
      "  Evaluating combination 79/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00615\n",
      "  Evaluating combination 80/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation loss: 0.00619\n",
      "  Evaluating combination 81/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00608\n",
      "  Evaluating combination 82/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00659\n",
      "  Evaluating combination 83/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00671\n",
      "  Evaluating combination 84/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00645\n",
      "  Evaluating combination 85/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00647\n",
      "  Evaluating combination 86/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00628\n",
      "  Evaluating combination 87/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00656\n",
      "  Evaluating combination 88/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00582\n",
      "  Evaluating combination 89/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00623\n",
      "  Evaluating combination 90/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation loss: 0.00626\n",
      "  Evaluating combination 91/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00643\n",
      "  Evaluating combination 92/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00654\n",
      "  Evaluating combination 93/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00663\n",
      "  Evaluating combination 94/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00619\n",
      "  Evaluating combination 95/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00628\n",
      "  Evaluating combination 96/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00649\n",
      "  Evaluating combination 97/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00595\n",
      "  Evaluating combination 98/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation loss: 0.00618\n",
      "  Evaluating combination 99/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation loss: 0.00603\n",
      "  Evaluating combination 100/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00658\n",
      "  Evaluating combination 101/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00675\n",
      "  Evaluating combination 102/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00645\n",
      "  Evaluating combination 103/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00597\n",
      "  Evaluating combination 104/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00598\n",
      "  Evaluating combination 105/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00620\n",
      "  Evaluating combination 106/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00576\n",
      "  Evaluating combination 107/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation loss: 0.00563\n",
      "  Evaluating combination 108/324: {'filters': 32, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation loss: 0.00634\n",
      "  Evaluating combination 109/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00590\n",
      "  Evaluating combination 110/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00612\n",
      "  Evaluating combination 111/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00583\n",
      "  Evaluating combination 112/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00614\n",
      "  Evaluating combination 113/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00635\n",
      "  Evaluating combination 114/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00570\n",
      "  Evaluating combination 115/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00555\n",
      "  Evaluating combination 116/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00546\n",
      "  Evaluating combination 117/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00566\n",
      "  Evaluating combination 118/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00559\n",
      "  Evaluating combination 119/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00599\n",
      "  Evaluating combination 120/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00576\n",
      "  Evaluating combination 121/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00583\n",
      "  Evaluating combination 122/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00586\n",
      "  Evaluating combination 123/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00573\n",
      "  Evaluating combination 124/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00547\n",
      "  Evaluating combination 125/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00538\n",
      "  Evaluating combination 126/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation loss: 0.00550\n",
      "  Evaluating combination 127/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00586\n",
      "  Evaluating combination 128/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00626\n",
      "  Evaluating combination 129/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00575\n",
      "  Evaluating combination 130/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00589\n",
      "  Evaluating combination 131/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00574\n",
      "  Evaluating combination 132/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00573\n",
      "  Evaluating combination 133/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00545\n",
      "  Evaluating combination 134/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00533\n",
      "  Evaluating combination 135/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00554\n",
      "  Evaluating combination 136/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00610\n",
      "  Evaluating combination 137/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00606\n",
      "  Evaluating combination 138/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00579\n",
      "  Evaluating combination 139/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00603\n",
      "  Evaluating combination 140/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00579\n",
      "  Evaluating combination 141/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00573\n",
      "  Evaluating combination 142/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00547\n",
      "  Evaluating combination 143/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00550\n",
      "  Evaluating combination 144/324: {'filters': 64, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation loss: 0.00548\n",
      "  Evaluating combination 145/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00622\n",
      "  Evaluating combination 146/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00631\n",
      "  Evaluating combination 147/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00618\n",
      "  Evaluating combination 148/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00599\n",
      "  Evaluating combination 149/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00621\n",
      "  Evaluating combination 150/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00611\n",
      "  Evaluating combination 151/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00569\n",
      "  Evaluating combination 152/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00563\n",
      "  Evaluating combination 153/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00571\n",
      "  Evaluating combination 154/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00674\n",
      "  Evaluating combination 155/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00634\n",
      "  Evaluating combination 156/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00595\n",
      "  Evaluating combination 157/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00617\n",
      "  Evaluating combination 158/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00608\n",
      "  Evaluating combination 159/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00573\n",
      "  Evaluating combination 160/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00578\n",
      "  Evaluating combination 161/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00551\n",
      "  Evaluating combination 162/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation loss: 0.00546\n",
      "  Evaluating combination 163/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00616\n",
      "  Evaluating combination 164/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00618\n",
      "  Evaluating combination 165/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00623\n",
      "  Evaluating combination 166/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00597\n",
      "  Evaluating combination 167/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00598\n",
      "  Evaluating combination 168/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00609\n",
      "  Evaluating combination 169/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00580\n",
      "  Evaluating combination 170/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00557\n",
      "  Evaluating combination 171/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation loss: 0.00573\n",
      "  Evaluating combination 172/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00586\n",
      "  Evaluating combination 173/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00627\n",
      "  Evaluating combination 174/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00605\n",
      "  Evaluating combination 175/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00573\n",
      "  Evaluating combination 176/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00585\n",
      "  Evaluating combination 177/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00588\n",
      "  Evaluating combination 178/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00570\n",
      "  Evaluating combination 179/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00575\n",
      "  Evaluating combination 180/324: {'filters': 64, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation loss: 0.00581\n",
      "  Evaluating combination 181/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00648\n",
      "  Evaluating combination 182/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00676\n",
      "  Evaluating combination 183/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00660\n",
      "  Evaluating combination 184/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00640\n",
      "  Evaluating combination 185/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00654\n",
      "  Evaluating combination 186/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00645\n",
      "  Evaluating combination 187/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00607\n",
      "  Evaluating combination 188/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00626\n",
      "  Evaluating combination 189/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00582\n",
      "  Evaluating combination 190/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00719\n",
      "  Evaluating combination 191/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00630\n",
      "  Evaluating combination 192/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00649\n",
      "  Evaluating combination 193/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00699\n",
      "  Evaluating combination 194/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00638\n",
      "  Evaluating combination 195/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00651\n",
      "  Evaluating combination 196/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00620\n",
      "  Evaluating combination 197/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00606\n",
      "  Evaluating combination 198/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation loss: 0.00587\n",
      "  Evaluating combination 199/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00628\n",
      "  Evaluating combination 200/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00643\n",
      "  Evaluating combination 201/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00634\n",
      "  Evaluating combination 202/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00632\n",
      "  Evaluating combination 203/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00637\n",
      "  Evaluating combination 204/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00655\n",
      "  Evaluating combination 205/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00593\n",
      "  Evaluating combination 206/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00588\n",
      "  Evaluating combination 207/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00594\n",
      "  Evaluating combination 208/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00668\n",
      "  Evaluating combination 209/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00650\n",
      "  Evaluating combination 210/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00624\n",
      "  Evaluating combination 211/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00651\n",
      "  Evaluating combination 212/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00650\n",
      "  Evaluating combination 213/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00635\n",
      "  Evaluating combination 214/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation loss: 0.00609\n",
      "  Evaluating combination 215/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00591\n",
      "  Evaluating combination 216/324: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation loss: 0.00597\n",
      "  Evaluating combination 217/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00613\n",
      "  Evaluating combination 218/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00592\n",
      "  Evaluating combination 219/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00585\n",
      "  Evaluating combination 220/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00647\n",
      "  Evaluating combination 221/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00568\n",
      "  Evaluating combination 222/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00575\n",
      "  Evaluating combination 223/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00552\n",
      "  Evaluating combination 224/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00553\n",
      "  Evaluating combination 225/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation loss: 0.00547\n",
      "  Evaluating combination 226/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00612\n",
      "  Evaluating combination 227/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00627\n",
      "  Evaluating combination 228/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00612\n",
      "  Evaluating combination 229/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00582\n",
      "  Evaluating combination 230/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00582\n",
      "  Evaluating combination 231/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00556\n",
      "  Evaluating combination 232/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation loss: 0.00540\n",
      "  Evaluating combination 233/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00562\n",
      "  Evaluating combination 234/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00541\n",
      "  Evaluating combination 235/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00604\n",
      "  Evaluating combination 236/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00625\n",
      "  Evaluating combination 237/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00616\n",
      "  Evaluating combination 238/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00590\n",
      "  Evaluating combination 239/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00641\n",
      "  Evaluating combination 240/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00561\n",
      "  Evaluating combination 241/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00558\n",
      "  Evaluating combination 242/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00517\n",
      "  Evaluating combination 243/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation loss: 0.00533\n",
      "  Evaluating combination 244/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00581\n",
      "  Evaluating combination 245/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00610\n",
      "  Evaluating combination 246/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00607\n",
      "  Evaluating combination 247/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00615\n",
      "  Evaluating combination 248/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00596\n",
      "  Evaluating combination 249/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00597\n",
      "  Evaluating combination 250/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00516\n",
      "  Evaluating combination 251/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00553\n",
      "  Evaluating combination 252/324: {'filters': 128, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation loss: 0.00539\n",
      "  Evaluating combination 253/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00608\n",
      "  Evaluating combination 254/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00651\n",
      "  Evaluating combination 255/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00647\n",
      "  Evaluating combination 256/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00594\n",
      "  Evaluating combination 257/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00609\n",
      "  Evaluating combination 258/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00603\n",
      "  Evaluating combination 259/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00586\n",
      "  Evaluating combination 260/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00566\n",
      "  Evaluating combination 261/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation loss: 0.00560\n",
      "  Evaluating combination 262/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00642\n",
      "  Evaluating combination 263/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00621\n",
      "  Evaluating combination 264/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00586\n",
      "  Evaluating combination 265/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00627\n",
      "  Evaluating combination 266/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00621\n",
      "  Evaluating combination 267/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00567\n",
      "  Evaluating combination 268/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00549\n",
      "  Evaluating combination 269/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00575\n",
      "  Evaluating combination 270/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00568\n",
      "  Evaluating combination 271/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00611\n",
      "  Evaluating combination 272/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00642\n",
      "  Evaluating combination 273/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00590\n",
      "  Evaluating combination 274/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00622\n",
      "  Evaluating combination 275/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00611\n",
      "  Evaluating combination 276/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00584\n",
      "  Evaluating combination 277/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation loss: 0.00575\n",
      "  Evaluating combination 278/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00548\n",
      "  Evaluating combination 279/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation loss: 0.00576\n",
      "  Evaluating combination 280/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00636\n",
      "  Evaluating combination 281/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00620\n",
      "  Evaluating combination 282/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00612\n",
      "  Evaluating combination 283/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00620\n",
      "  Evaluating combination 284/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00610\n",
      "  Evaluating combination 285/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00623\n",
      "  Evaluating combination 286/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00567\n",
      "  Evaluating combination 287/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00554\n",
      "  Evaluating combination 288/324: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00572\n",
      "  Evaluating combination 289/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00657\n",
      "  Evaluating combination 290/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00706\n",
      "  Evaluating combination 291/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00631\n",
      "  Evaluating combination 292/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00681\n",
      "  Evaluating combination 293/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation loss: 0.00685\n",
      "  Evaluating combination 294/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00664\n",
      "  Evaluating combination 295/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00605\n",
      "  Evaluating combination 296/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation loss: 0.00596\n",
      "  Evaluating combination 297/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00601\n",
      "  Evaluating combination 298/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00650\n",
      "  Evaluating combination 299/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00667\n",
      "  Evaluating combination 300/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00644\n",
      "  Evaluating combination 301/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00661\n",
      "  Evaluating combination 302/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00648\n",
      "  Evaluating combination 303/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00648\n",
      "  Evaluating combination 304/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation loss: 0.00616\n",
      "  Evaluating combination 305/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation loss: 0.00638\n",
      "  Evaluating combination 306/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation loss: 0.00629\n",
      "  Evaluating combination 307/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation loss: 0.00672\n",
      "  Evaluating combination 308/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00634\n",
      "  Evaluating combination 309/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00631\n",
      "  Evaluating combination 310/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00630\n",
      "  Evaluating combination 311/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation loss: 0.00626\n",
      "  Evaluating combination 312/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00646\n",
      "  Evaluating combination 313/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00616\n",
      "  Evaluating combination 314/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00603\n",
      "  Evaluating combination 315/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00627\n",
      "  Evaluating combination 316/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 32}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00627\n",
      "  Evaluating combination 317/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation loss: 0.00658\n",
      "  Evaluating combination 318/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00601\n",
      "  Evaluating combination 319/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation loss: 0.00668\n",
      "  Evaluating combination 320/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation loss: 0.00652\n",
      "  Evaluating combination 321/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation loss: 0.00628\n",
      "  Evaluating combination 322/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation loss: 0.00613\n",
      "  Evaluating combination 323/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation loss: 0.00599\n",
      "  Evaluating combination 324/324: {'filters': 128, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation loss: 0.00608\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Completed grid search for input length: 504\n",
      "  Best Validation MSE: 0.0051\n",
      "  Best Hyperparameters: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for length in input_lengths:\n",
    "    print(f\"Starting grid search for input length: {length}\")\n",
    "    \n",
    "    X_train = data_dict[length]['X_train']\n",
    "    y_train = data_dict[length]['y_train']\n",
    "    X_val = data_dict[length]['X_val']\n",
    "    y_val = data_dict[length]['y_val']\n",
    "    \n",
    "    best_mse = float('inf')\n",
    "    best_params = {}\n",
    "    best_model = None\n",
    "    \n",
    "    for idx, combination in enumerate(all_combinations):\n",
    "        # Extract hyperparameters\n",
    "        hyperparams = {\n",
    "            'filters': combination[0],\n",
    "            'kernel_size': combination[1],\n",
    "            'dropout': combination[2],\n",
    "            'learning_rate': combination[3],\n",
    "            'batch_size': combination[4]\n",
    "        }\n",
    "        \n",
    "        print(f\"  Evaluating combination {idx + 1}/{len(all_combinations)}: {hyperparams}\")\n",
    "        \n",
    "        # Build the CNN model\n",
    "        model = build_cnn_model(hyperparams, length)\n",
    "        \n",
    "        # Early Stopping Callback\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True,verbose=1)\n",
    "        \n",
    "        # Train the model\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=50,\n",
    "            batch_size=hyperparams['batch_size'],\n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=[early_stop],\n",
    "            verbose=0  # Set to 1 to see training progress\n",
    "        )\n",
    "        \n",
    "        # Retrieve the best validation MSE from the history\n",
    "        current_best_mse = min(history.history['val_loss'])\n",
    "        print(f\"Validation loss: {current_best_mse:.5f}\")\n",
    "        \n",
    "        # Check if this is the best model so far\n",
    "        if current_best_mse < best_mse:\n",
    "            best_mse = current_best_mse\n",
    "            best_params = hyperparams.copy()\n",
    "            best_model = model  # Optionally, save the model if needed\n",
    "    \n",
    "    # After evaluating all combinations, store the best results\n",
    "    results.append({\n",
    "        'Input_Length': length,\n",
    "        'Best_MSE': best_mse,\n",
    "        'Validation_MSE': mean_squared_error(y_val, best_model.predict(X_val)),\n",
    "        'Validation_MAE': mean_absolute_error(y_val, best_model.predict(X_val)),\n",
    "        'Validation_MAPE': mean_absolute_percentage_error(y_val, best_model.predict(X_val)) * 100,  # In percentage\n",
    "        'Validation_RMSE': np.sqrt(mean_squared_error(y_val, best_model.predict(X_val))),\n",
    "        'Best_Hyperparameters': best_params\n",
    "    })\n",
    "    \n",
    "    print(f\"Completed grid search for input length: {length}\")\n",
    "    print(f\"  Best Validation MSE: {best_mse:.4f}\")\n",
    "    print(f\"  Best Hyperparameters: {best_params}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 24\n",
    "  Best Validation MSE: 0.0042\n",
    "  Best Hyperparameters: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 48\n",
    "  Best Validation MSE: 0.0042\n",
    "  Best Hyperparameters: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 72\n",
    "  Best Validation MSE: 0.0041\n",
    "  Best Hyperparameters: {'filters': 64, 'kernel_size': 5, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 96\n",
    "  Best Validation MSE: 0.0042\n",
    "  Best Hyperparameters: {'filters': 64, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0005, 'batch_size': 128}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 120\n",
    "  Best Validation MSE: 0.0040\n",
    "  Best Hyperparameters: {'filters': 64, 'kernel_size': 3, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 144\n",
    "  Best Validation MSE: 0.0040\n",
    "  Best Hyperparameters: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 168\n",
    "  Best Validation MSE: 0.0038\n",
    "  Best Hyperparameters: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 64}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 192\n",
    "  Best Validation MSE: 0.0037\n",
    "  Best Hyperparameters: {'filters': 128, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 216\n",
    "  Best Validation MSE: 0.0034\n",
    "  Best Hyperparameters: {'filters': 64, 'kernel_size': 3, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 240\n",
    "  Best Validation MSE: 0.0035\n",
    "  Best Hyperparameters: {'filters': 32, 'kernel_size': 5, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}\n",
    "  \n",
    "Completed grid search for input length: 264\n",
    "  Best Validation MSE: 0.0036\n",
    "  Best Hyperparameters: {'filters': 128, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 32}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 288\n",
    "  Best Validation MSE: 0.0035\n",
    "  Best Hyperparameters: {'filters': 32, 'kernel_size': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 32}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 312\n",
    "  Best Validation MSE: 0.0035\n",
    "  Best Hyperparameters: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 336\n",
    "  Best Validation MSE: 0.0034\n",
    "  Best Hyperparameters: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 360\n",
    "  Best Validation MSE: 0.0035\n",
    "  Best Hyperparameters: {'filters': 32, 'kernel_size': 2, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 64}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 384\n",
    "  Best Validation MSE: 0.0038\n",
    "  Best Hyperparameters: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 128}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 408\n",
    "  Best Validation MSE: 0.0040\n",
    "  Best Hyperparameters: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 128}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 432\n",
    "  Best Validation MSE: 0.0039\n",
    "  Best Hyperparameters: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 32}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 456\n",
    "  Best Validation MSE: 0.0043\n",
    "  Best Hyperparameters: {'filters': 32, 'kernel_size': 3, 'dropout': 0.0, 'learning_rate': 0.0001, 'batch_size': 64}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 480\n",
    "  Best Validation MSE: 0.0048\n",
    "  Best Hyperparameters: {'filters': 64, 'kernel_size': 2, 'dropout': 0.2, 'learning_rate': 0.0001, 'batch_size': 32}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed grid search for input length: 504\n",
    "  Best Validation MSE: 0.0051\n",
    "  Best Hyperparameters: {'filters': 32, 'kernel_size': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 64}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Retrain the model after getting the best hyperparameters of each input length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the best hyperparameters for each input length\n",
    "\n",
    "best_hyperparameters = {\n",
    "    24: {\n",
    "        'filters': 128,\n",
    "        'kernel_size': 3,\n",
    "        'dropout': 0.3,\n",
    "        'learning_rate': 0.0005,\n",
    "        'batch_size': 64\n",
    "    },\n",
    "    48: {\n",
    "        'filters': 64,\n",
    "        'kernel_size': 3,\n",
    "        'dropout': 0.0,\n",
    "        'learning_rate': 0.0005,\n",
    "        'batch_size': 128\n",
    "    },\n",
    "    72: {\n",
    "        'filters': 64,\n",
    "        'kernel_size': 5,\n",
    "        'dropout': 0.3,\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': 64\n",
    "    },\n",
    "    96: {\n",
    "        'filters': 64,\n",
    "        'kernel_size': 3,\n",
    "        'dropout': 0.0,\n",
    "        'learning_rate': 0.0005,\n",
    "        'batch_size': 128\n",
    "    },\n",
    "    120: {\n",
    "        'filters': 64,\n",
    "        'kernel_size': 3,\n",
    "        'dropout': 0.1,\n",
    "        'learning_rate': 0.0005,\n",
    "        'batch_size': 128\n",
    "    },\n",
    "    144: {\n",
    "        'filters': 32,\n",
    "        'kernel_size': 2,\n",
    "        'dropout': 0.3,\n",
    "        'learning_rate': 0.0005,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    168: {\n",
    "        'filters': 32,\n",
    "        'kernel_size': 2,\n",
    "        'dropout': 0.1,\n",
    "        'learning_rate': 0.0005,\n",
    "        'batch_size': 64\n",
    "    },\n",
    "    192: {\n",
    "        'filters': 128,\n",
    "        'kernel_size': 3,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.0001,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    216: {\n",
    "        'filters': 64,\n",
    "        'kernel_size': 3,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.0001,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    240: {\n",
    "        'filters': 32,\n",
    "        'kernel_size': 5,\n",
    "        'dropout': 0.0,\n",
    "        'learning_rate': 0.0001,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    264: {\n",
    "        'filters': 128,\n",
    "        'kernel_size': 3,\n",
    "        'dropout': 0.3,\n",
    "        'learning_rate': 0.0005,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    288: {\n",
    "        'filters': 32,\n",
    "        'kernel_size': 3,\n",
    "        'dropout': 0.3,\n",
    "        'learning_rate': 0.0001,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    312: {\n",
    "        'filters': 32,\n",
    "        'kernel_size': 2,\n",
    "        'dropout': 0.1,\n",
    "        'learning_rate': 0.0005,\n",
    "        'batch_size': 128\n",
    "    },\n",
    "    336: {\n",
    "        'filters': 64,\n",
    "        'kernel_size': 2,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.0001,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    360: {\n",
    "        'filters': 32,\n",
    "        'kernel_size': 2,\n",
    "        'dropout': 0.3,\n",
    "        'learning_rate': 0.0001,\n",
    "        'batch_size': 64\n",
    "    },\n",
    "    384: {\n",
    "        'filters': 32,\n",
    "        'kernel_size': 2,\n",
    "        'dropout': 0.1,\n",
    "        'learning_rate': 0.0001,\n",
    "        'batch_size': 128\n",
    "    },\n",
    "    408: {\n",
    "        'filters': 32,\n",
    "        'kernel_size': 2,\n",
    "        'dropout': 0.1,\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': 128\n",
    "    },\n",
    "    432: {\n",
    "        'filters': 32,\n",
    "        'kernel_size': 3,\n",
    "        'dropout': 0.0,\n",
    "        'learning_rate': 0.0001,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    456: {\n",
    "        'filters': 32,\n",
    "        'kernel_size': 3,\n",
    "        'dropout': 0.0,\n",
    "        'learning_rate': 0.0001,\n",
    "        'batch_size': 64\n",
    "    },\n",
    "    480: {\n",
    "        'filters': 64,\n",
    "        'kernel_size': 2,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.0001,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    504: {\n",
    "        'filters': 32,\n",
    "        'kernel_size': 2,\n",
    "        'dropout': 0.1,\n",
    "        'learning_rate': 0.0001,\n",
    "        'batch_size': 64\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(hyperparams,data_dict,length, seed=None):  # add seed\n",
    "    if seed is not None:\n",
    "        set_seed(seed)\n",
    "    \n",
    "    #get the data of each length\n",
    "    X_train = data_dict[length]['X_train']\n",
    "    y_train = data_dict[length]['y_train']\n",
    "    X_val = data_dict[length]['X_val']\n",
    "    y_val = data_dict[length]['y_val']\n",
    "    \n",
    "    # Train the model\n",
    "    model = build_cnn_model(hyperparams, length)    \n",
    "    # Early Stopping Callback\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True,verbose=1)    \n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=100,\n",
    "        batch_size=hyperparams['batch_size'],\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[early_stop],\n",
    "        verbose=0  # Set to 1 to see training progress\n",
    "    )\n",
    "    \n",
    "    # Retrieve the best validation MSE from the history\n",
    "    best_mse = min(history.history['val_loss'])\n",
    "    print(f\"Validation loss: {best_mse:.5f}\")\n",
    "    \n",
    "    return model, best_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "def make_prediction(model, X_obs, y_obs):\n",
    "    y_pred = model.predict(X_obs,verbose=0)\n",
    "    n_samples = X_obs.shape[0]\n",
    "    output_len = y_obs.shape[1]\n",
    "\n",
    "    # Reshape for inverse scaling\n",
    "    y_pred_reshaped = y_pred.reshape(-1, 1)\n",
    "    y_obs_reshaped = y_obs.reshape(-1, 1)\n",
    "\n",
    "    # Inverse transform\n",
    "    y_pred_inverse = scaler.inverse_transform(y_pred_reshaped).reshape(n_samples, output_len)\n",
    "    y_obs_inverse = scaler.inverse_transform(y_obs_reshaped).reshape(n_samples, output_len)\n",
    "\n",
    "    return y_pred_inverse, y_obs_inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Metrics for Each Time Step\n",
    "def evaluation(y_pred_inverse, y_obs_inverse):\n",
    "    \n",
    "    output_len = y_pred_inverse.shape[1]\n",
    "    metrics_list = []  # To store metrics for each time step\n",
    "    \n",
    "    for i in range(output_len):\n",
    "        y_true = y_obs_inverse[:, i]\n",
    "        y_pred = y_pred_inverse[:, i]\n",
    "\n",
    "        # Mean Absolute Error (MAE)\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "        # Mean Squared Error (MSE)\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "        # Root Mean Squared Error (RMSE)\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        # Mean Absolute Percentage Error (MAPE)\n",
    "        # Avoid division by zero by adding a small epsilon to y_test_flat if necessary\n",
    "        epsilon = 1e-10\n",
    "        y_true_safe = np.where(y_true == 0, epsilon, y_true)\n",
    "        mape = np.mean(np.abs((y_true - y_pred) / y_true_safe)) * 100\n",
    "\n",
    "                # Append the metrics for the current time step to the list\n",
    "        metrics_list.append({\n",
    "            'Time Step': i + 1,\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse,\n",
    "            'MAPE (%)': mape\n",
    "        })\n",
    "\n",
    "    # Create a DataFrame from the list of metrics\n",
    "    metrics_df = pd.DataFrame(metrics_list)\n",
    "    metrics_df.set_index('Time Step', inplace=True)\n",
    "\n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_hyperparameters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m n_runs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m      5\u001b[0m length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m24\u001b[39m\n\u001b[1;32m----> 6\u001b[0m hyperparams \u001b[38;5;241m=\u001b[39m \u001b[43mbest_hyperparameters\u001b[49m[length]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Initialize lists to store mean metrics and all metrics from each run\u001b[39;00m\n\u001b[0;32m      9\u001b[0m mean_metrics_rows \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_hyperparameters' is not defined"
     ]
    }
   ],
   "source": [
    "# test 1\n",
    "# Number of runs\n",
    "n_runs = 10\n",
    "\n",
    "length = 24\n",
    "hyperparams = best_hyperparameters[length]\n",
    "\n",
    "# Initialize lists to store mean metrics and all metrics from each run\n",
    "mean_metrics_rows = []\n",
    "df_all_metrics_list = []\n",
    "\n",
    "for run in range(1, n_runs + 1):\n",
    "    print(f\"\\n--- Run {run} ---\")\n",
    "    \n",
    "    # Optionally set a unique seed for each run to ensure variability\n",
    "    #seed = run  \n",
    "    # Train the model\n",
    "    model, mse = train_model(hyperparams, data_dict, length, seed=None)\n",
    "\n",
    "    X_train = data_dict[length]['X_train']\n",
    "    y_train = data_dict[length]['y_train']\n",
    "    X_val = data_dict[length]['X_val']\n",
    "    y_val = data_dict[length]['y_val']\n",
    "    X_test = data_dict[length]['X_test']\n",
    "    y_test = data_dict[length]['y_test']\n",
    "\n",
    "    y_pred_train, y_obs_train = make_prediction(model, X_train, y_train)\n",
    "    y_pred_val, y_obs_val = make_prediction(model, X_val, y_val)\n",
    "    y_pred_test, y_obs_test = make_prediction(model, X_test, y_test)\n",
    "\n",
    "    df_train = evaluation(y_pred_train, y_obs_train).add_suffix('_train')\n",
    "    df_val = evaluation(y_pred_val, y_obs_val).add_suffix('_val')\n",
    "    df_test = evaluation(y_pred_test, y_obs_test).add_suffix('_test')\n",
    "\n",
    "    df_all_metrics = pd.concat([df_train, df_val, df_test], axis=1)\n",
    "    df_all_metrics.index.name = length\n",
    "    \n",
    "    # Append df_all_metrics to the list\n",
    "    df_all_metrics_list.append(df_all_metrics)\n",
    "\n",
    "    # Calculate mean for each metric\n",
    "    mean_metrics = df_val.mean()\n",
    "    mean_metrics_row = pd.DataFrame(mean_metrics).T\n",
    "    mean_metrics_row['MSE_val(loss)'] = mse\n",
    "    mean_metrics_row['input_len'] = length\n",
    "    mean_metrics_row = mean_metrics_row[['input_len','MSE_val(loss)', 'MAE_val', 'RMSE_val', 'MAPE (%)_val']]\n",
    "    \n",
    "    # Append to the list\n",
    "    mean_metrics_rows.append(mean_metrics_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 2\n",
    "# Concatenate all df_all_metrics into a single DataFrame with a new level for runs\n",
    "concatenated_all_metrics = pd.concat(df_all_metrics_list, keys=range(1, n_runs + 1), names=['Run', 'Time Step'])\n",
    "\n",
    "# Calculate the mean across runs for each metric and time step\n",
    "# This will group by 'Time Step' and calculate the mean of each metric across all runs\n",
    "aggregated_all_metrics_mean = concatenated_all_metrics.groupby('Time Step').mean()\n",
    "aggregated_all_metrics_mean.index.name = length\n",
    "\n",
    "print(\"\\n--- Aggregated Mean of All Metrics Across 10 Runs ---\")\n",
    "display(aggregated_all_metrics_mean)\n",
    "\n",
    "# After all runs, create a DataFrame of mean metrics\n",
    "mean_metrics_df = pd.concat(mean_metrics_rows, ignore_index=True)\n",
    "# Calculate the mean of each metric across the 10 runs\n",
    "final_mean_metrics = mean_metrics_df.mean()\n",
    "\n",
    "# Create a DataFrame for the final mean metrics\n",
    "final_mean_metrics_df = pd.DataFrame(final_mean_metrics).T\n",
    "\n",
    "print(\"\\n--- Final Mean Metrics Across 10 Runs ---\")\n",
    "final_mean_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "\n",
      "--- Run 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\program\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation loss: 0.00432\n",
      "\n",
      "--- Run 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\program\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation loss: 0.00423\n",
      "\n",
      "--- Run 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\program\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation loss: 0.00427\n",
      "\n",
      "--- Run 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\program\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation loss: 0.00424\n",
      "\n",
      "--- Run 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\program\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation loss: 0.00424\n",
      "\n",
      "--- Run 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\program\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation loss: 0.00426\n",
      "\n",
      "--- Run 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\program\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_metrics_list=[]\n",
    "for length in best_hyperparameters.keys():\n",
    "    print(length)\n",
    "    \n",
    "    # Number of runs\n",
    "    n_runs = 10\n",
    "    \n",
    "    # get the best hyperparameter of each length\n",
    "    hyperparams = best_hyperparameters[length]\n",
    "    # Initialize lists to store mean metrics and all metrics from each run\n",
    "    mean_metrics_rows = []\n",
    "    df_all_metrics_list = []\n",
    "\n",
    "    for run in range(1, n_runs + 1):\n",
    "        print(f\"\\n--- Run {run} ---\")\n",
    "\n",
    "        # Optionally set a unique seed for each run to ensure variability\n",
    "        seed = run  \n",
    "        # Train the model\n",
    "        model, mse = train_model(hyperparams, data_dict, length, seed=seed)\n",
    "        \n",
    "        X_train = data_dict[length]['X_train']\n",
    "        y_train = data_dict[length]['y_train']\n",
    "        X_val = data_dict[length]['X_val']\n",
    "        y_val = data_dict[length]['y_val']\n",
    "        X_test = data_dict[length]['X_test']\n",
    "        y_test = data_dict[length]['y_test']\n",
    "\n",
    "        #get the true flow and predicted flow\n",
    "        y_pred_train, y_obs_train = make_prediction(model, X_train, y_train)\n",
    "        y_pred_val, y_obs_val = make_prediction(model, X_val, y_val)\n",
    "        y_pred_test, y_obs_test = make_prediction(model, X_test, y_test)\n",
    "\n",
    "        #calculate the evaluation metrics of each output step\n",
    "        df_train = evaluation(y_pred_train, y_obs_train).add_suffix('_train')\n",
    "        df_val = evaluation(y_pred_val, y_obs_val).add_suffix('_val')\n",
    "        df_test = evaluation(y_pred_test, y_obs_test).add_suffix('_test')\n",
    "\n",
    "        df_all_metrics = pd.concat([df_train, df_val, df_test], axis=1)\n",
    "        df_all_metrics.index.name = length\n",
    "        \n",
    "        # Append df_all_metrics to the list\n",
    "        df_all_metrics_list.append(df_all_metrics)\n",
    "\n",
    "        # Calculate mean for all output step\n",
    "        mean_metrics = df_val.mean()\n",
    "        mean_metrics_row = pd.DataFrame(mean_metrics).T\n",
    "        mean_metrics_row['MSE_val(loss)'] = mse\n",
    "        mean_metrics_row['input_len'] = length\n",
    "        mean_metrics_row = mean_metrics_row[['input_len','MSE_val(loss)', 'MAE_val', 'RMSE_val', 'MAPE (%)_val']]\n",
    "        \n",
    "        # Append to the list\n",
    "        mean_metrics_rows.append(mean_metrics_row)\n",
    "        \n",
    "    # Concatenate all df_all_metrics into a single DataFrame with a new level for runs\n",
    "    concatenated_all_metrics = pd.concat(df_all_metrics_list, keys=range(1, n_runs + 1), names=['Run', 'Time Step'])\n",
    "\n",
    "    # Calculate the mean across runs for each metric and time step\n",
    "    # This will group by 'Time Step' and calculate the mean of each metric across all runs\n",
    "    aggregated_all_metrics_mean = concatenated_all_metrics.groupby('Time Step').mean()\n",
    "    aggregated_all_metrics_mean.index.name = length\n",
    "\n",
    "    print(\"\\n--- Aggregated Mean of All Metrics Across 10 Runs ---\")\n",
    "    display(aggregated_all_metrics_mean)\n",
    "\n",
    "    # After all runs, create a DataFrame of mean metrics\n",
    "    mean_metrics_df = pd.concat(mean_metrics_rows, ignore_index=True)\n",
    "    # Calculate the mean of each metric across the 10 runs\n",
    "    final_mean_metrics = mean_metrics_df.mean()\n",
    "\n",
    "    # Create a DataFrame for the final mean metrics\n",
    "    final_mean_metrics_df = pd.DataFrame(final_mean_metrics).T\n",
    "    \n",
    "    mean_metrics_list.append(final_mean_metrics_df)\n",
    "\n",
    "mean_metrics_df = pd.concat(mean_metrics_list).reset_index(drop=True)\n",
    "print(\"\\n--- Final Mean Metrics Across 10 Runs ---\")\n",
    "mean_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_len</th>\n",
       "      <th>MSE_val(loss)</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>MAPE (%)_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0.004265</td>\n",
       "      <td>26.205162</td>\n",
       "      <td>36.255125</td>\n",
       "      <td>43.886447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.0</td>\n",
       "      <td>0.004287</td>\n",
       "      <td>26.229182</td>\n",
       "      <td>36.345324</td>\n",
       "      <td>42.311301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72.0</td>\n",
       "      <td>0.004252</td>\n",
       "      <td>26.128547</td>\n",
       "      <td>36.225445</td>\n",
       "      <td>42.704548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96.0</td>\n",
       "      <td>0.004268</td>\n",
       "      <td>26.183151</td>\n",
       "      <td>36.258214</td>\n",
       "      <td>43.057429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.004109</td>\n",
       "      <td>25.769214</td>\n",
       "      <td>35.570711</td>\n",
       "      <td>43.494388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>144.0</td>\n",
       "      <td>0.004119</td>\n",
       "      <td>25.819611</td>\n",
       "      <td>35.626515</td>\n",
       "      <td>43.322926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>168.0</td>\n",
       "      <td>0.003862</td>\n",
       "      <td>24.786606</td>\n",
       "      <td>34.492432</td>\n",
       "      <td>41.654022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>192.0</td>\n",
       "      <td>0.003810</td>\n",
       "      <td>24.557236</td>\n",
       "      <td>34.295043</td>\n",
       "      <td>38.974767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>216.0</td>\n",
       "      <td>0.003502</td>\n",
       "      <td>24.161857</td>\n",
       "      <td>32.885453</td>\n",
       "      <td>40.072552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>240.0</td>\n",
       "      <td>0.003759</td>\n",
       "      <td>25.139706</td>\n",
       "      <td>34.073613</td>\n",
       "      <td>41.733799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>264.0</td>\n",
       "      <td>0.003804</td>\n",
       "      <td>24.989412</td>\n",
       "      <td>34.294569</td>\n",
       "      <td>39.397702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>288.0</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>24.201852</td>\n",
       "      <td>33.223878</td>\n",
       "      <td>39.514339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>312.0</td>\n",
       "      <td>0.003637</td>\n",
       "      <td>24.139480</td>\n",
       "      <td>33.516042</td>\n",
       "      <td>38.600159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>336.0</td>\n",
       "      <td>0.003511</td>\n",
       "      <td>24.079966</td>\n",
       "      <td>32.912177</td>\n",
       "      <td>41.371121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    input_len  MSE_val(loss)    MAE_val   RMSE_val  MAPE (%)_val\n",
       "0        24.0       0.004265  26.205162  36.255125     43.886447\n",
       "1        48.0       0.004287  26.229182  36.345324     42.311301\n",
       "2        72.0       0.004252  26.128547  36.225445     42.704548\n",
       "3        96.0       0.004268  26.183151  36.258214     43.057429\n",
       "4       120.0       0.004109  25.769214  35.570711     43.494388\n",
       "5       144.0       0.004119  25.819611  35.626515     43.322926\n",
       "6       168.0       0.003862  24.786606  34.492432     41.654022\n",
       "7       192.0       0.003810  24.557236  34.295043     38.974767\n",
       "8       216.0       0.003502  24.161857  32.885453     40.072552\n",
       "9       240.0       0.003759  25.139706  34.073613     41.733799\n",
       "10      264.0       0.003804  24.989412  34.294569     39.397702\n",
       "11      288.0       0.003571  24.201852  33.223878     39.514339\n",
       "12      312.0       0.003637  24.139480  33.516042     38.600159\n",
       "13      336.0       0.003511  24.079966  32.912177     41.371121"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Store the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Results DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input_Length</th>\n",
       "      <th>Best_MSE</th>\n",
       "      <th>Validation_MSE</th>\n",
       "      <th>Validation_MAE</th>\n",
       "      <th>Validation_MAPE</th>\n",
       "      <th>Validation_RMSE</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192</td>\n",
       "      <td>0.003742</td>\n",
       "      <td>0.003742</td>\n",
       "      <td>0.044218</td>\n",
       "      <td>48.484668</td>\n",
       "      <td>0.061174</td>\n",
       "      <td>128.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>216</td>\n",
       "      <td>0.003442</td>\n",
       "      <td>0.003442</td>\n",
       "      <td>0.043077</td>\n",
       "      <td>48.433814</td>\n",
       "      <td>0.058665</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>240</td>\n",
       "      <td>0.003536</td>\n",
       "      <td>0.003536</td>\n",
       "      <td>0.043359</td>\n",
       "      <td>45.041577</td>\n",
       "      <td>0.059463</td>\n",
       "      <td>32.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>264</td>\n",
       "      <td>0.003598</td>\n",
       "      <td>0.003598</td>\n",
       "      <td>0.043513</td>\n",
       "      <td>45.719254</td>\n",
       "      <td>0.059979</td>\n",
       "      <td>128.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>288</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>0.042542</td>\n",
       "      <td>45.630643</td>\n",
       "      <td>0.059243</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>312</td>\n",
       "      <td>0.003469</td>\n",
       "      <td>0.003469</td>\n",
       "      <td>0.043472</td>\n",
       "      <td>47.613100</td>\n",
       "      <td>0.058897</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>336</td>\n",
       "      <td>0.003374</td>\n",
       "      <td>0.003374</td>\n",
       "      <td>0.042398</td>\n",
       "      <td>51.722801</td>\n",
       "      <td>0.058084</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Input_Length  Best_MSE  Validation_MSE  Validation_MAE  Validation_MAPE  \\\n",
       "0           192  0.003742        0.003742        0.044218        48.484668   \n",
       "1           216  0.003442        0.003442        0.043077        48.433814   \n",
       "2           240  0.003536        0.003536        0.043359        45.041577   \n",
       "3           264  0.003598        0.003598        0.043513        45.719254   \n",
       "4           288  0.003510        0.003510        0.042542        45.630643   \n",
       "5           312  0.003469        0.003469        0.043472        47.613100   \n",
       "6           336  0.003374        0.003374        0.042398        51.722801   \n",
       "\n",
       "   Validation_RMSE  filters  kernel_size  dropout  learning_rate  batch_size  \n",
       "0         0.061174    128.0          3.0      0.2         0.0001        32.0  \n",
       "1         0.058665     64.0          3.0      0.2         0.0001        32.0  \n",
       "2         0.059463     32.0          5.0      0.0         0.0001        32.0  \n",
       "3         0.059979    128.0          3.0      0.3         0.0005        32.0  \n",
       "4         0.059243     32.0          3.0      0.3         0.0001        32.0  \n",
       "5         0.058897     32.0          2.0      0.1         0.0005       128.0  \n",
       "6         0.058084     64.0          2.0      0.2         0.0001        32.0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the results list to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Expand the hyperparameters dictionary into separate columns for clarity\n",
    "hyperparams_df = results_df['Best_Hyperparameters'].apply(pd.Series)\n",
    "\n",
    "# Combine the main dataframe with hyperparameters\n",
    "final_results_df = pd.concat([results_df.drop('Best_Hyperparameters', axis=1), hyperparams_df], axis=1)\n",
    "\n",
    "# Display the final dataframe\n",
    "print(\"Final Results DataFrame:\")\n",
    "final_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQSTAJPWHrUJ"
   },
   "source": [
    "## 5. Define the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "hwueLP9vAA3h"
   },
   "outputs": [],
   "source": [
    "def create_cnn_model(input_shape, n_outputs, dropout_rate=0.5, learning_rate=0.001, filters=64, kernel_size=3):\n",
    "    model = keras.Sequential([\n",
    "        layers.Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', input_shape=input_shape),\n",
    "        layers.Conv1D(filters=filters, kernel_size=kernel_size, activation='relu'),\n",
    "        layers.MaxPooling1D(pool_size=2),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(50, activation='relu'),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(n_outputs)\n",
    "    ])\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        loss='mse',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "input_shape = (x_train_scaled.shape[1], x_train_scaled.shape[2])\n",
    "n_outputs = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCIZFe1MAx-X"
   },
   "source": [
    "## 6. Set Up Hyperparameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u6BEmc0rA1dJ",
    "outputId": "20c85d15-7883-4fbb-cb22-74cc3a9f02a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total combinations: 243\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Define hyperparameter options\n",
    "dropout_rates = [0.3, 0.5, 0.7]\n",
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "batch_sizes = [32, 64, 128]\n",
    "filters_list = [32, 64, 128]\n",
    "kernel_sizes = [2, 3, 5]\n",
    "\n",
    "# Create a list of all hyperparameter combinations\n",
    "hyperparameter_combinations = list(product(dropout_rates, learning_rates, batch_sizes, filters_list, kernel_sizes))\n",
    "\n",
    "print(f\"Total combinations: {len(hyperparameter_combinations)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ixRU8sQA8NW"
   },
   "source": [
    "## 7. Train the Model with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aYYTmgvvA2Dz",
    "outputId": "57c086f5-a79c-4fb4-81ad-4a34626dc18e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination 1/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=32, filters=32, kernel_size=2\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation MAE: 0.0675\n",
      "\n",
      "Combination 2/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=32, filters=32, kernel_size=3\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation MAE: 0.0637\n",
      "\n",
      "Combination 3/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=32, filters=32, kernel_size=5\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation MAE: 0.0661\n",
      "\n",
      "Combination 4/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=32, filters=64, kernel_size=2\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation MAE: 0.0647\n",
      "\n",
      "Combination 5/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=32, filters=64, kernel_size=3\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation MAE: 0.0631\n",
      "\n",
      "Combination 6/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=32, filters=64, kernel_size=5\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation MAE: 0.0666\n",
      "\n",
      "Combination 7/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=32, filters=128, kernel_size=2\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation MAE: 0.0665\n",
      "\n",
      "Combination 8/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=32, filters=128, kernel_size=3\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation MAE: 0.0663\n",
      "\n",
      "Combination 9/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=32, filters=128, kernel_size=5\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation MAE: 0.0640\n",
      "\n",
      "Combination 10/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=64, filters=32, kernel_size=2\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation MAE: 0.0637\n",
      "\n",
      "Combination 11/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=64, filters=32, kernel_size=3\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation MAE: 0.0660\n",
      "\n",
      "Combination 12/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=64, filters=32, kernel_size=5\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation MAE: 0.0644\n",
      "\n",
      "Combination 13/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=64, filters=64, kernel_size=2\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation MAE: 0.0660\n",
      "\n",
      "Combination 14/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=64, filters=64, kernel_size=3\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation MAE: 0.0645\n",
      "\n",
      "Combination 15/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=64, filters=64, kernel_size=5\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation MAE: 0.0637\n",
      "\n",
      "Combination 16/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=64, filters=128, kernel_size=2\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation MAE: 0.0645\n",
      "\n",
      "Combination 17/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=64, filters=128, kernel_size=3\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation MAE: 0.0666\n",
      "\n",
      "Combination 18/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=64, filters=128, kernel_size=5\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation MAE: 0.0649\n",
      "\n",
      "Combination 19/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=128, filters=32, kernel_size=2\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation MAE: 0.0635\n",
      "\n",
      "Combination 20/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=128, filters=32, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation MAE: 0.0637\n",
      "\n",
      "Combination 21/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=128, filters=32, kernel_size=5\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation MAE: 0.0624\n",
      "\n",
      "Combination 22/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=128, filters=64, kernel_size=2\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation MAE: 0.0636\n",
      "\n",
      "Combination 23/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=128, filters=64, kernel_size=3\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation MAE: 0.0636\n",
      "\n",
      "Combination 24/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=128, filters=64, kernel_size=5\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation MAE: 0.0621\n",
      "\n",
      "Combination 25/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=128, filters=128, kernel_size=2\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation MAE: 0.0628\n",
      "\n",
      "Combination 26/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=128, filters=128, kernel_size=3\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation MAE: 0.0629\n",
      "\n",
      "Combination 27/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=128, filters=128, kernel_size=5\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation MAE: 0.0639\n",
      "\n",
      "Combination 28/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=32, filters=32, kernel_size=2\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation MAE: 0.0615\n",
      "\n",
      "Combination 29/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=32, filters=32, kernel_size=3\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation MAE: 0.0606\n",
      "\n",
      "Combination 30/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=32, filters=32, kernel_size=5\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation MAE: 0.0604\n",
      "\n",
      "Combination 31/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=32, filters=64, kernel_size=2\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation MAE: 0.0602\n",
      "\n",
      "Combination 32/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=32, filters=64, kernel_size=3\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation MAE: 0.0595\n",
      "\n",
      "Combination 33/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=32, filters=64, kernel_size=5\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation MAE: 0.0600\n",
      "\n",
      "Combination 34/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=32, filters=128, kernel_size=2\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation MAE: 0.0603\n",
      "\n",
      "Combination 35/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=32, filters=128, kernel_size=3\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation MAE: 0.0600\n",
      "\n",
      "Combination 36/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=32, filters=128, kernel_size=5\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation MAE: 0.0600\n",
      "\n",
      "Combination 37/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=64, filters=32, kernel_size=2\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation MAE: 0.0617\n",
      "\n",
      "Combination 38/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=64, filters=32, kernel_size=3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation MAE: 0.0605\n",
      "\n",
      "Combination 39/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=64, filters=32, kernel_size=5\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation MAE: 0.0613\n",
      "\n",
      "Combination 40/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=64, filters=64, kernel_size=2\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation MAE: 0.0618\n",
      "\n",
      "Combination 41/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=64, filters=64, kernel_size=3\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation MAE: 0.0599\n",
      "\n",
      "Combination 42/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=64, filters=64, kernel_size=5\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation MAE: 0.0603\n",
      "\n",
      "Combination 43/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=64, filters=128, kernel_size=2\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation MAE: 0.0602\n",
      "\n",
      "Combination 44/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=64, filters=128, kernel_size=3\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation MAE: 0.0592\n",
      "\n",
      "Combination 45/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=64, filters=128, kernel_size=5\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation MAE: 0.0598\n",
      "\n",
      "Combination 46/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=128, filters=32, kernel_size=2\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation MAE: 0.0616\n",
      "\n",
      "Combination 47/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=128, filters=32, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0599\n",
      "\n",
      "Combination 48/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=128, filters=32, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation MAE: 0.0604\n",
      "\n",
      "Combination 49/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=128, filters=64, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0601\n",
      "\n",
      "Combination 50/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=128, filters=64, kernel_size=3\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation MAE: 0.0605\n",
      "\n",
      "Combination 51/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=128, filters=64, kernel_size=5\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation MAE: 0.0596\n",
      "\n",
      "Combination 52/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=128, filters=128, kernel_size=2\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation MAE: 0.0612\n",
      "\n",
      "Combination 53/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=128, filters=128, kernel_size=3\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation MAE: 0.0596\n",
      "\n",
      "Combination 54/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=128, filters=128, kernel_size=5\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation MAE: 0.0601\n",
      "\n",
      "Combination 55/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=32, filters=32, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0626\n",
      "\n",
      "Combination 56/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=32, filters=32, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0620\n",
      "\n",
      "Combination 57/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=32, filters=32, kernel_size=5\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation MAE: 0.0619\n",
      "\n",
      "Combination 58/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=32, filters=64, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0614\n",
      "\n",
      "Combination 59/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=32, filters=64, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0602\n",
      "\n",
      "Combination 60/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=32, filters=64, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0604\n",
      "\n",
      "Combination 61/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=32, filters=128, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0606\n",
      "\n",
      "Combination 62/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=32, filters=128, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation MAE: 0.0595\n",
      "\n",
      "Combination 63/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=32, filters=128, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation MAE: 0.0592\n",
      "\n",
      "Combination 64/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=64, filters=32, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0644\n",
      "\n",
      "Combination 65/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=64, filters=32, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0627\n",
      "\n",
      "Combination 66/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=64, filters=32, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0632\n",
      "\n",
      "Combination 67/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=64, filters=64, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation MAE: 0.0630\n",
      "\n",
      "Combination 68/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=64, filters=64, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0617\n",
      "\n",
      "Combination 69/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=64, filters=64, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0612\n",
      "\n",
      "Combination 70/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=64, filters=128, kernel_size=2\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation MAE: 0.0624\n",
      "\n",
      "Combination 71/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=64, filters=128, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0602\n",
      "\n",
      "Combination 72/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=64, filters=128, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation MAE: 0.0605\n",
      "\n",
      "Combination 73/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=128, filters=32, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0680\n",
      "\n",
      "Combination 74/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=128, filters=32, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0653\n",
      "\n",
      "Combination 75/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=128, filters=32, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0662\n",
      "\n",
      "Combination 76/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=128, filters=64, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0645\n",
      "\n",
      "Combination 77/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=128, filters=64, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0629\n",
      "\n",
      "Combination 78/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=128, filters=64, kernel_size=5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0626\n",
      "\n",
      "Combination 79/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=128, filters=128, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0637\n",
      "\n",
      "Combination 80/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=128, filters=128, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation MAE: 0.0619\n",
      "\n",
      "Combination 81/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=128, filters=128, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0612\n",
      "\n",
      "Combination 82/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=32, filters=32, kernel_size=2\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation MAE: 0.0721\n",
      "\n",
      "Combination 83/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=32, filters=32, kernel_size=3\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation MAE: 0.0721\n",
      "\n",
      "Combination 84/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=32, filters=32, kernel_size=5\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation MAE: 0.0763\n",
      "\n",
      "Combination 85/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=32, filters=64, kernel_size=2\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation MAE: 0.0715\n",
      "\n",
      "Combination 86/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=32, filters=64, kernel_size=3\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation MAE: 0.0734\n",
      "\n",
      "Combination 87/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=32, filters=64, kernel_size=5\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation MAE: 0.0676\n",
      "\n",
      "Combination 88/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=32, filters=128, kernel_size=2\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation MAE: 0.0731\n",
      "\n",
      "Combination 89/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=32, filters=128, kernel_size=3\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation MAE: 0.0737\n",
      "\n",
      "Combination 90/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=32, filters=128, kernel_size=5\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation MAE: 0.0702\n",
      "\n",
      "Combination 91/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=64, filters=32, kernel_size=2\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation MAE: 0.0702\n",
      "\n",
      "Combination 92/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=64, filters=32, kernel_size=3\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation MAE: 0.0664\n",
      "\n",
      "Combination 93/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=64, filters=32, kernel_size=5\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation MAE: 0.0678\n",
      "\n",
      "Combination 94/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=64, filters=64, kernel_size=2\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation MAE: 0.0719\n",
      "\n",
      "Combination 95/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=64, filters=64, kernel_size=3\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation MAE: 0.0673\n",
      "\n",
      "Combination 96/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=64, filters=64, kernel_size=5\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation MAE: 0.0663\n",
      "\n",
      "Combination 97/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=64, filters=128, kernel_size=2\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation MAE: 0.0711\n",
      "\n",
      "Combination 98/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=64, filters=128, kernel_size=3\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation MAE: 0.0710\n",
      "\n",
      "Combination 99/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=64, filters=128, kernel_size=5\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation MAE: 0.0688\n",
      "\n",
      "Combination 100/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=128, filters=32, kernel_size=2\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation MAE: 0.0693\n",
      "\n",
      "Combination 101/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=128, filters=32, kernel_size=3\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation MAE: 0.0680\n",
      "\n",
      "Combination 102/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=128, filters=32, kernel_size=5\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation MAE: 0.0705\n",
      "\n",
      "Combination 103/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=128, filters=64, kernel_size=2\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation MAE: 0.0675\n",
      "\n",
      "Combination 104/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=128, filters=64, kernel_size=3\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation MAE: 0.0674\n",
      "\n",
      "Combination 105/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=128, filters=64, kernel_size=5\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation MAE: 0.0659\n",
      "\n",
      "Combination 106/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=128, filters=128, kernel_size=2\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation MAE: 0.0679\n",
      "\n",
      "Combination 107/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=128, filters=128, kernel_size=3\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation MAE: 0.0657\n",
      "\n",
      "Combination 108/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=128, filters=128, kernel_size=5\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation MAE: 0.0681\n",
      "\n",
      "Combination 109/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=32, filters=32, kernel_size=2\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation MAE: 0.0652\n",
      "\n",
      "Combination 110/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=32, filters=32, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0626\n",
      "\n",
      "Combination 111/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=32, filters=32, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation MAE: 0.0625\n",
      "\n",
      "Combination 112/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=32, filters=64, kernel_size=2\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation MAE: 0.0628\n",
      "\n",
      "Combination 113/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=32, filters=64, kernel_size=3\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation MAE: 0.0628\n",
      "\n",
      "Combination 114/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=32, filters=64, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation MAE: 0.0619\n",
      "\n",
      "Combination 115/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=32, filters=128, kernel_size=2\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation MAE: 0.0621\n",
      "\n",
      "Combination 116/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=32, filters=128, kernel_size=3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation MAE: 0.0612\n",
      "\n",
      "Combination 117/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=32, filters=128, kernel_size=5\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation MAE: 0.0622\n",
      "\n",
      "Combination 118/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=64, filters=32, kernel_size=2\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation MAE: 0.0655\n",
      "\n",
      "Combination 119/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=64, filters=32, kernel_size=3\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation MAE: 0.0631\n",
      "\n",
      "Combination 120/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=64, filters=32, kernel_size=5\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation MAE: 0.0650\n",
      "\n",
      "Combination 121/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=64, filters=64, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation MAE: 0.0627\n",
      "\n",
      "Combination 122/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=64, filters=64, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation MAE: 0.0620\n",
      "\n",
      "Combination 123/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=64, filters=64, kernel_size=5\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation MAE: 0.0623\n",
      "\n",
      "Combination 124/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=64, filters=128, kernel_size=2\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation MAE: 0.0620\n",
      "\n",
      "Combination 125/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=64, filters=128, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation MAE: 0.0615\n",
      "\n",
      "Combination 126/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=64, filters=128, kernel_size=5\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation MAE: 0.0617\n",
      "\n",
      "Combination 127/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=128, filters=32, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0645\n",
      "\n",
      "Combination 128/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=128, filters=32, kernel_size=3\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation MAE: 0.0662\n",
      "\n",
      "Combination 129/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=128, filters=32, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation MAE: 0.0635\n",
      "\n",
      "Combination 130/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=128, filters=64, kernel_size=2\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation MAE: 0.0638\n",
      "\n",
      "Combination 131/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=128, filters=64, kernel_size=3\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation MAE: 0.0629\n",
      "\n",
      "Combination 132/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=128, filters=64, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0620\n",
      "\n",
      "Combination 133/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=128, filters=128, kernel_size=2\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation MAE: 0.0630\n",
      "\n",
      "Combination 134/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=128, filters=128, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0612\n",
      "\n",
      "Combination 135/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=128, filters=128, kernel_size=5\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation MAE: 0.0624\n",
      "\n",
      "Combination 136/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=32, filters=32, kernel_size=2\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation MAE: 0.0678\n",
      "\n",
      "Combination 137/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=32, filters=32, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation MAE: 0.0640\n",
      "\n",
      "Combination 138/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=32, filters=32, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation MAE: 0.0642\n",
      "\n",
      "Combination 139/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=32, filters=64, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0655\n",
      "\n",
      "Combination 140/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=32, filters=64, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0626\n",
      "\n",
      "Combination 141/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=32, filters=64, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation MAE: 0.0631\n",
      "\n",
      "Combination 142/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=32, filters=128, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation MAE: 0.0622\n",
      "\n",
      "Combination 143/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=32, filters=128, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation MAE: 0.0616\n",
      "\n",
      "Combination 144/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=32, filters=128, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0610\n",
      "\n",
      "Combination 145/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=64, filters=32, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0678\n",
      "\n",
      "Combination 146/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=64, filters=32, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0678\n",
      "\n",
      "Combination 147/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=64, filters=32, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0681\n",
      "\n",
      "Combination 148/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=64, filters=64, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0653\n",
      "\n",
      "Combination 149/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=64, filters=64, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation MAE: 0.0648\n",
      "\n",
      "Combination 150/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=64, filters=64, kernel_size=5\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation MAE: 0.0641\n",
      "\n",
      "Combination 151/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=64, filters=128, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0634\n",
      "\n",
      "Combination 152/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=64, filters=128, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0626\n",
      "\n",
      "Combination 153/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=64, filters=128, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0620\n",
      "\n",
      "Combination 154/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=128, filters=32, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0713\n",
      "\n",
      "Combination 155/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=128, filters=32, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 50.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE: 0.0688\n",
      "\n",
      "Combination 156/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=128, filters=32, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation MAE: 0.0715\n",
      "\n",
      "Combination 157/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=128, filters=64, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0685\n",
      "\n",
      "Combination 158/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=128, filters=64, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0656\n",
      "\n",
      "Combination 159/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=128, filters=64, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0659\n",
      "\n",
      "Combination 160/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=128, filters=128, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0666\n",
      "\n",
      "Combination 161/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=128, filters=128, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0639\n",
      "\n",
      "Combination 162/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=128, filters=128, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0623\n",
      "\n",
      "Combination 163/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.01, batch_size=32, filters=32, kernel_size=2\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation MAE: 0.1023\n",
      "\n",
      "Combination 164/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.01, batch_size=32, filters=32, kernel_size=3\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation MAE: 0.1022\n",
      "\n",
      "Combination 165/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.01, batch_size=32, filters=32, kernel_size=5\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation MAE: 0.1001\n",
      "\n",
      "Combination 166/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.01, batch_size=32, filters=64, kernel_size=2\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation MAE: 0.0923\n",
      "\n",
      "Combination 167/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.01, batch_size=32, filters=64, kernel_size=3\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation MAE: 0.0909\n",
      "\n",
      "Combination 168/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.01, batch_size=32, filters=64, kernel_size=5\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation MAE: 0.1045\n",
      "\n",
      "Combination 169/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.01, batch_size=32, filters=128, kernel_size=2\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation MAE: 0.0923\n",
      "\n",
      "Combination 170/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.01, batch_size=32, filters=128, kernel_size=3\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation MAE: 0.0934\n",
      "\n",
      "Combination 171/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.01, batch_size=32, filters=128, kernel_size=5\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation MAE: 0.0991\n",
      "\n",
      "Combination 172/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.01, batch_size=64, filters=32, kernel_size=2\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation MAE: 0.0852\n",
      "\n",
      "Combination 173/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.01, batch_size=64, filters=32, kernel_size=3\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation MAE: 0.0804\n",
      "\n",
      "Combination 174/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.01, batch_size=64, filters=32, kernel_size=5\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation MAE: 0.0911\n",
      "\n",
      "Combination 175/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.01, batch_size=64, filters=64, kernel_size=2\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation MAE: 0.0833\n",
      "\n",
      "Combination 176/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.01, batch_size=64, filters=64, kernel_size=3\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation MAE: 0.0822\n",
      "\n",
      "Combination 177/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.01, batch_size=64, filters=64, kernel_size=5\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation MAE: 0.0927\n",
      "\n",
      "Combination 178/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.01, batch_size=64, filters=128, kernel_size=2\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation MAE: 0.0808\n",
      "\n",
      "Combination 179/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.01, batch_size=64, filters=128, kernel_size=3\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation MAE: 0.0803\n",
      "\n",
      "Combination 180/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.01, batch_size=64, filters=128, kernel_size=5\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation MAE: 0.0808\n",
      "\n",
      "Combination 181/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.01, batch_size=128, filters=32, kernel_size=2\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation MAE: 0.0786\n",
      "\n",
      "Combination 182/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.01, batch_size=128, filters=32, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0754\n",
      "\n",
      "Combination 183/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.01, batch_size=128, filters=32, kernel_size=5\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation MAE: 0.0954\n",
      "\n",
      "Combination 184/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.01, batch_size=128, filters=64, kernel_size=2\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation MAE: 0.0804\n",
      "\n",
      "Combination 185/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.01, batch_size=128, filters=64, kernel_size=3\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation MAE: 0.0762\n",
      "\n",
      "Combination 186/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.01, batch_size=128, filters=64, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0763\n",
      "\n",
      "Combination 187/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.01, batch_size=128, filters=128, kernel_size=2\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation MAE: 0.0800\n",
      "\n",
      "Combination 188/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.01, batch_size=128, filters=128, kernel_size=3\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation MAE: 0.0776\n",
      "\n",
      "Combination 189/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.01, batch_size=128, filters=128, kernel_size=5\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation MAE: 0.0843\n",
      "\n",
      "Combination 190/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.001, batch_size=32, filters=32, kernel_size=2\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation MAE: 0.0735\n",
      "\n",
      "Combination 191/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.001, batch_size=32, filters=32, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0694\n",
      "\n",
      "Combination 192/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.001, batch_size=32, filters=32, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation MAE: 0.0681\n",
      "\n",
      "Combination 193/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.001, batch_size=32, filters=64, kernel_size=2\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE: 0.0721\n",
      "\n",
      "Combination 194/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.001, batch_size=32, filters=64, kernel_size=3\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation MAE: 0.0682\n",
      "\n",
      "Combination 195/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.001, batch_size=32, filters=64, kernel_size=5\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation MAE: 0.0682\n",
      "\n",
      "Combination 196/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.001, batch_size=32, filters=128, kernel_size=2\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation MAE: 0.0682\n",
      "\n",
      "Combination 197/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.001, batch_size=32, filters=128, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation MAE: 0.0663\n",
      "\n",
      "Combination 198/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.001, batch_size=32, filters=128, kernel_size=5\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation MAE: 0.0658\n",
      "\n",
      "Combination 199/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.001, batch_size=64, filters=32, kernel_size=2\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation MAE: 0.0716\n",
      "\n",
      "Combination 200/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.001, batch_size=64, filters=32, kernel_size=3\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation MAE: 0.0723\n",
      "\n",
      "Combination 201/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.001, batch_size=64, filters=32, kernel_size=5\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation MAE: 0.0715\n",
      "\n",
      "Combination 202/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.001, batch_size=64, filters=64, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0694\n",
      "\n",
      "Combination 203/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.001, batch_size=64, filters=64, kernel_size=3\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation MAE: 0.0685\n",
      "\n",
      "Combination 204/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.001, batch_size=64, filters=64, kernel_size=5\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation MAE: 0.0707\n",
      "\n",
      "Combination 205/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.001, batch_size=64, filters=128, kernel_size=2\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation MAE: 0.0681\n",
      "\n",
      "Combination 206/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.001, batch_size=64, filters=128, kernel_size=3\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation MAE: 0.0674\n",
      "\n",
      "Combination 207/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.001, batch_size=64, filters=128, kernel_size=5\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation MAE: 0.0659\n",
      "\n",
      "Combination 208/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.001, batch_size=128, filters=32, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0722\n",
      "\n",
      "Combination 209/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.001, batch_size=128, filters=32, kernel_size=3\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation MAE: 0.0702\n",
      "\n",
      "Combination 210/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.001, batch_size=128, filters=32, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation MAE: 0.0753\n",
      "\n",
      "Combination 211/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.001, batch_size=128, filters=64, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0702\n",
      "\n",
      "Combination 212/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.001, batch_size=128, filters=64, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0677\n",
      "\n",
      "Combination 213/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.001, batch_size=128, filters=64, kernel_size=5\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation MAE: 0.0682\n",
      "\n",
      "Combination 214/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.001, batch_size=128, filters=128, kernel_size=2\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation MAE: 0.0700\n",
      "\n",
      "Combination 215/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.001, batch_size=128, filters=128, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation MAE: 0.0662\n",
      "\n",
      "Combination 216/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.001, batch_size=128, filters=128, kernel_size=5\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation MAE: 0.0655\n",
      "\n",
      "Combination 217/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.0001, batch_size=32, filters=32, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation MAE: 0.0748\n",
      "\n",
      "Combination 218/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.0001, batch_size=32, filters=32, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation MAE: 0.0744\n",
      "\n",
      "Combination 219/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.0001, batch_size=32, filters=32, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0742\n",
      "\n",
      "Combination 220/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.0001, batch_size=32, filters=64, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0724\n",
      "\n",
      "Combination 221/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.0001, batch_size=32, filters=64, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation MAE: 0.0704\n",
      "\n",
      "Combination 222/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.0001, batch_size=32, filters=64, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation MAE: 0.0708\n",
      "\n",
      "Combination 223/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.0001, batch_size=32, filters=128, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0694\n",
      "\n",
      "Combination 224/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.0001, batch_size=32, filters=128, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation MAE: 0.0667\n",
      "\n",
      "Combination 225/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.0001, batch_size=32, filters=128, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation MAE: 0.0656\n",
      "\n",
      "Combination 226/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.0001, batch_size=64, filters=32, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0790\n",
      "\n",
      "Combination 227/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.0001, batch_size=64, filters=32, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0790\n",
      "\n",
      "Combination 228/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.0001, batch_size=64, filters=32, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation MAE: 0.0818\n",
      "\n",
      "Combination 229/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.0001, batch_size=64, filters=64, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0765\n",
      "\n",
      "Combination 230/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.0001, batch_size=64, filters=64, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0716\n",
      "\n",
      "Combination 231/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.0001, batch_size=64, filters=64, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0726\n",
      "\n",
      "Combination 232/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.0001, batch_size=64, filters=128, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0703\n",
      "\n",
      "Combination 233/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.0001, batch_size=64, filters=128, kernel_size=3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0676\n",
      "\n",
      "Combination 234/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.0001, batch_size=64, filters=128, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation MAE: 0.0682\n",
      "\n",
      "Combination 235/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.0001, batch_size=128, filters=32, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0858\n",
      "\n",
      "Combination 236/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.0001, batch_size=128, filters=32, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0840\n",
      "\n",
      "Combination 237/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.0001, batch_size=128, filters=32, kernel_size=5\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation MAE: 0.0873\n",
      "\n",
      "Combination 238/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.0001, batch_size=128, filters=64, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0780\n",
      "\n",
      "Combination 239/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.0001, batch_size=128, filters=64, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0754\n",
      "\n",
      "Combination 240/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.0001, batch_size=128, filters=64, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0776\n",
      "\n",
      "Combination 241/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.0001, batch_size=128, filters=128, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0739\n",
      "\n",
      "Combination 242/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.0001, batch_size=128, filters=128, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0704\n",
      "\n",
      "Combination 243/243\n",
      "Training with dropout_rate=0.7, learning_rate=0.0001, batch_size=128, filters=128, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0713\n",
      "\n",
      "Best Hyperparameters:\n",
      "dropout_rate: 0.3\n",
      "learning_rate: 0.0001\n",
      "batch_size: 32\n",
      "filters: 128\n",
      "kernel_size: 5\n",
      "Best Validation MAE: 0.0592\n"
     ]
    }
   ],
   "source": [
    "best_val_mae = np.inf\n",
    "best_hyperparams = None\n",
    "best_model = None\n",
    "\n",
    "for idx, (dropout_rate, learning_rate, batch_size, filters, kernel_size) in enumerate(hyperparameter_combinations):\n",
    "    print(f\"\\nCombination {idx+1}/{len(hyperparameter_combinations)}\")\n",
    "    print(f\"Training with dropout_rate={dropout_rate}, learning_rate={learning_rate}, batch_size={batch_size}, filters={filters}, kernel_size={kernel_size}\")\n",
    "\n",
    "    model = create_cnn_model(\n",
    "        input_shape, n_outputs,\n",
    "        dropout_rate=dropout_rate,\n",
    "        learning_rate=learning_rate,\n",
    "        filters=filters,\n",
    "        kernel_size=kernel_size\n",
    "    )\n",
    "\n",
    "    # Initialize EarlyStopping inside the loop\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_mae',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        x_train_scaled, y_train_scaled,\n",
    "        epochs=50,  # Set higher epochs due to Early Stopping\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_val_scaled, y_val_scaled),\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0  # Change to 1 for detailed output\n",
    "    )\n",
    "\n",
    "    val_mae = min(history.history['val_mae'])\n",
    "    print(f\"Validation MAE: {val_mae:.4f}\")\n",
    "\n",
    "    if val_mae < best_val_mae:\n",
    "        best_val_mae = val_mae\n",
    "        best_model = model\n",
    "        best_hyperparams = {\n",
    "            'dropout_rate': dropout_rate,\n",
    "            'learning_rate': learning_rate,\n",
    "            'batch_size': batch_size,\n",
    "            'filters': filters,\n",
    "            'kernel_size': kernel_size\n",
    "        }\n",
    "\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "for param, value in best_hyperparams.items():\n",
    "    print(f\"{param}: {value}\")\n",
    "print(f\"Best Validation MAE: {best_val_mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Hyperparameters for full time:\n",
    "dropout_rate: 0.3\n",
    "learning_rate: 0.001\n",
    "batch_size: 64\n",
    "filters: 128\n",
    "kernel_size: 5\n",
    "\n",
    "Best Hyperparameters for after covid:\n",
    "dropout_rate: 0.3\n",
    "learning_rate: 0.0001\n",
    "batch_size: 32\n",
    "filters: 128\n",
    "kernel_size: 5\n",
    "Best Validation MAE: 0.0592"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "erMGays0Redw"
   },
   "source": [
    "## 8. Make Predictions and Get Evaluation Metrics\n",
    "I forget the store the results of best_model, but still have the results of best_hyperparameter\n",
    "\n",
    "So I have to recreate the model using these hyperparameters and retrain it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppIzpGSCZGCY"
   },
   "source": [
    "#### 8.1 Recreate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2e7yOQ99RXif"
   },
   "outputs": [],
   "source": [
    "def create_best_cnn_model(input_shape, n_outputs):\n",
    "    model = keras.Sequential([\n",
    "        # First convolutional layer\n",
    "        layers.Conv1D(filters=128, kernel_size=5, activation='relu', input_shape=input_shape),\n",
    "        # Second convolutional layer\n",
    "        layers.Conv1D(filters=128, kernel_size=5, activation='relu'),\n",
    "        # Pooling layer\n",
    "        layers.MaxPooling1D(pool_size=2),\n",
    "        # Regularization\n",
    "        layers.Dropout(0.3),\n",
    "        # Flattening the output\n",
    "        layers.Flatten(),\n",
    "        # Fully connected layers\n",
    "        layers.Dense(50, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        # Output layer\n",
    "        layers.Dense(n_outputs)\n",
    "    ])\n",
    "    # Compile the model\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(\n",
    "        loss='mse',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ush-69jZEa2",
    "outputId": "3829be76-1aa2-46b6-d737-491a19231cb2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Recreate the model\n",
    "input_shape = (x_train_scaled.shape[1], x_train_scaled.shape[2])\n",
    "n_outputs = y_train.shape[1]\n",
    "best_model = create_best_cnn_model(input_shape, n_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZDlERj6Zb3s"
   },
   "source": [
    "#### 8.2 Retrain the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "da0WpEFIZYft"
   },
   "outputs": [],
   "source": [
    "# Initialize EarlyStopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_mae',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "j7yTmBHpZwtP",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "cbfa60cb-5667-4ca3-d9e0-5e57be8dd432"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 0.0264 - mae: 0.1218 - val_loss: 0.0072 - val_mae: 0.0583\n",
      "Epoch 2/50\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0117 - mae: 0.0809 - val_loss: 0.0071 - val_mae: 0.0575\n",
      "Epoch 3/50\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0102 - mae: 0.0753 - val_loss: 0.0070 - val_mae: 0.0555\n",
      "Epoch 4/50\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0096 - mae: 0.0728 - val_loss: 0.0070 - val_mae: 0.0537\n",
      "Epoch 5/50\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0094 - mae: 0.0723 - val_loss: 0.0072 - val_mae: 0.0589\n",
      "Epoch 6/50\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0092 - mae: 0.0713 - val_loss: 0.0068 - val_mae: 0.0551\n",
      "Epoch 7/50\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0090 - mae: 0.0701 - val_loss: 0.0069 - val_mae: 0.0573\n",
      "Epoch 8/50\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0087 - mae: 0.0692 - val_loss: 0.0071 - val_mae: 0.0587\n",
      "Epoch 9/50\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0087 - mae: 0.0691 - val_loss: 0.0066 - val_mae: 0.0532\n",
      "Epoch 10/50\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0086 - mae: 0.0685 - val_loss: 0.0068 - val_mae: 0.0541\n",
      "Epoch 11/50\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0085 - mae: 0.0680 - val_loss: 0.0069 - val_mae: 0.0573\n",
      "Epoch 12/50\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0085 - mae: 0.0681 - val_loss: 0.0067 - val_mae: 0.0540\n",
      "Epoch 13/50\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0083 - mae: 0.0673 - val_loss: 0.0067 - val_mae: 0.0524\n",
      "Epoch 14/50\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0084 - mae: 0.0678 - val_loss: 0.0067 - val_mae: 0.0531\n",
      "Epoch 15/50\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0083 - mae: 0.0674 - val_loss: 0.0069 - val_mae: 0.0570\n",
      "Epoch 16/50\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0083 - mae: 0.0672 - val_loss: 0.0067 - val_mae: 0.0545\n",
      "Epoch 17/50\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0082 - mae: 0.0670 - val_loss: 0.0067 - val_mae: 0.0537\n",
      "Epoch 18/50\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0081 - mae: 0.0664 - val_loss: 0.0066 - val_mae: 0.0523\n",
      "Epoch 19/50\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0081 - mae: 0.0666 - val_loss: 0.0067 - val_mae: 0.0525\n",
      "Epoch 20/50\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0082 - mae: 0.0667 - val_loss: 0.0071 - val_mae: 0.0569\n",
      "Epoch 21/50\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0080 - mae: 0.0660 - val_loss: 0.0066 - val_mae: 0.0515\n",
      "Epoch 22/50\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0080 - mae: 0.0660 - val_loss: 0.0071 - val_mae: 0.0594\n",
      "Epoch 23/50\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0080 - mae: 0.0665 - val_loss: 0.0066 - val_mae: 0.0523\n",
      "Epoch 24/50\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0079 - mae: 0.0655 - val_loss: 0.0068 - val_mae: 0.0557\n",
      "Epoch 25/50\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0080 - mae: 0.0661 - val_loss: 0.0068 - val_mae: 0.0534\n",
      "Epoch 26/50\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0078 - mae: 0.0655 - val_loss: 0.0068 - val_mae: 0.0560\n",
      "Epoch 27/50\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0078 - mae: 0.0653 - val_loss: 0.0069 - val_mae: 0.0553\n",
      "Epoch 28/50\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0078 - mae: 0.0652 - val_loss: 0.0070 - val_mae: 0.0573\n",
      "Epoch 29/50\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0076 - mae: 0.0646 - val_loss: 0.0069 - val_mae: 0.0545\n",
      "Epoch 30/50\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0078 - mae: 0.0650 - val_loss: 0.0067 - val_mae: 0.0538\n",
      "Epoch 31/50\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0078 - mae: 0.0651 - val_loss: 0.0068 - val_mae: 0.0545\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = best_model.fit(\n",
    "    x_train_scaled, y_train_scaled,\n",
    "    epochs=50,  # You can adjust this as needed\n",
    "    batch_size=64,\n",
    "    validation_data=(x_val_scaled, y_val_scaled),\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1  # Set to 1 to see detailed training output\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04gJKtE3aFr5"
   },
   "source": [
    "#### 8.3 Make Predictions and Get Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dm0GDom6aC_F",
    "outputId": "f0be3ba9-c5ee-4344-b1a0-c8bf0368b69b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred_scaled = best_model.predict(x_test_scaled)\n",
    "\n",
    "# Reshape for inverse scaling\n",
    "y_pred_reshaped = y_pred_scaled.reshape(-1, 1)\n",
    "y_test_reshaped = y_test_scaled.reshape(-1, 1)\n",
    "\n",
    "# Inverse transform\n",
    "y_pred_inverse = y_scaler.inverse_transform(y_pred_reshaped).reshape(n_test_samples, n_outputs)\n",
    "y_test_inverse = y_scaler.inverse_transform(y_test_reshaped).reshape(n_test_samples, n_outputs)\n",
    "\n",
    "y_test_flat = y_test_inverse.flatten()\n",
    "y_pred_flat = y_pred_inverse.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZySuhSHnaQJs",
    "outputId": "cf1b8196-ce73-421a-b2ac-fbd9a61c24f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time Step 1 Evaluation Metrics:\n",
      "RMSE: 28.3201\n",
      "MAE: 21.0287\n",
      "MAPE: 20.43%\n",
      "\n",
      "Time Step 2 Evaluation Metrics:\n",
      "RMSE: 36.8282\n",
      "MAE: 27.7824\n",
      "MAPE: 26.41%\n",
      "\n",
      "Time Step 3 Evaluation Metrics:\n",
      "RMSE: 44.9135\n",
      "MAE: 34.3549\n",
      "MAPE: 31.76%\n",
      "\n",
      "Time Step 4 Evaluation Metrics:\n",
      "RMSE: 51.2590\n",
      "MAE: 39.5928\n",
      "MAPE: 36.60%\n",
      "\n",
      "Time Step 5 Evaluation Metrics:\n",
      "RMSE: 57.0935\n",
      "MAE: 44.7165\n",
      "MAPE: 41.28%\n",
      "\n",
      "Time Step 6 Evaluation Metrics:\n",
      "RMSE: 59.9910\n",
      "MAE: 47.6431\n",
      "MAPE: 44.87%\n"
     ]
    }
   ],
   "source": [
    "# Compute Metrics for Each Time Step\n",
    "\n",
    "for i in range(n_outputs):\n",
    "    y_true = y_test_inverse[:, i]\n",
    "    y_pred = y_pred_inverse[:, i]\n",
    "\n",
    "    # Mean Absolute Error (MAE)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "    # Mean Squared Error (MSE)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "    # Root Mean Squared Error (RMSE)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # Mean Absolute Percentage Error (MAPE)\n",
    "    # Avoid division by zero by adding a small epsilon to y_test_flat if necessary\n",
    "    epsilon = 1e-10\n",
    "    y_true_safe = np.where(y_true == 0, epsilon, y_true)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true_safe)) * 100\n",
    "\n",
    "    print(f\"\\nTime Step {i+1} Evaluation Metrics:\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"MAPE: {mape:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyYn2XL2GUxw"
   },
   "source": [
    "# Code to predict next 6 steps step-by-step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vavf9D4-lc6E"
   },
   "source": [
    "#### We will use\n",
    "* the last 12 steps\n",
    "\n",
    "* previous one week (24 steps)\n",
    "\n",
    "* previous one month  (168 steps)\n",
    "\n",
    "*  to forecast current (0 step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OfV8VwesmXS3"
   },
   "source": [
    "## 1. Create input and output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "PJaM65dTlc6E"
   },
   "outputs": [],
   "source": [
    "# Create input-output sequences with the provided function\n",
    "X_train, y_train, X_train_df, y_train_df = create_multi_step_sequence(train_set, last_n_steps=12, day_lag=24, week_lag=168, n_future_steps=1)\n",
    "X_valid, y_valid, X_valid_df, y_valid_df = create_multi_step_sequence(valid_set, last_n_steps=12, day_lag=24, week_lag=168, n_future_steps=1)\n",
    "X_test, y_test, X_test_df, y_test_df = create_multi_step_sequence(test_set, last_n_steps=12, day_lag=24, week_lag=168, n_future_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "ipA2bPAcm2L1",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "8fc8cd28-878b-4936-8a7f-304a718b97a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19570, 14, 1),\n",
       " array([[[173.],\n",
       "         [168.],\n",
       "         [155.],\n",
       "         ...,\n",
       "         [ 27.],\n",
       "         [ 21.],\n",
       "         [ 15.]],\n",
       " \n",
       "        [[168.],\n",
       "         [155.],\n",
       "         [186.],\n",
       "         ...,\n",
       "         [  9.],\n",
       "         [  8.],\n",
       "         [  9.]],\n",
       " \n",
       "        [[155.],\n",
       "         [186.],\n",
       "         [333.],\n",
       "         ...,\n",
       "         [ 10.],\n",
       "         [ 10.],\n",
       "         [  9.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[141.],\n",
       "         [142.],\n",
       "         [107.],\n",
       "         ...,\n",
       "         [160.],\n",
       "         [129.],\n",
       "         [131.]],\n",
       " \n",
       "        [[142.],\n",
       "         [107.],\n",
       "         [128.],\n",
       "         ...,\n",
       "         [ 94.],\n",
       "         [ 87.],\n",
       "         [ 77.]],\n",
       " \n",
       "        [[107.],\n",
       "         [128.],\n",
       "         [150.],\n",
       "         ...,\n",
       "         [ 80.],\n",
       "         [ 63.],\n",
       "         [ 35.]]]),\n",
       " (19570, 1),\n",
       " array([[ 9.],\n",
       "        [10.],\n",
       "        [ 8.],\n",
       "        ...,\n",
       "        [94.],\n",
       "        [80.],\n",
       "        [63.]]))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_train, y_train.shape, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0GNpslqvlx5_"
   },
   "source": [
    "## 2. Normalise the data after split (step-by-step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_Co01Aflx6B"
   },
   "source": [
    "Normalise X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "id": "Z7YuPxvRlx6C"
   },
   "outputs": [],
   "source": [
    "# Separate scalers for inputs and outputs\n",
    "x_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "y_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Reshape x_train to 2D for scaling\n",
    "n_samples, n_timesteps, n_features = X_train.shape\n",
    "x_train_reshaped = X_train.reshape(-1, n_features)  # Shape: (n_samples * n_timesteps, n_features)\n",
    "# Fit the scaler on the training data\n",
    "x_scaler.fit(x_train_reshaped)\n",
    "# Transform the training data\n",
    "x_train_scaled = x_scaler.transform(x_train_reshaped)\n",
    "# Reshape back to original shape\n",
    "x_train_scaled = x_train_scaled.reshape(n_samples, n_timesteps, n_features)\n",
    "\n",
    "# x_val\n",
    "n_val_samples = X_valid.shape[0]\n",
    "x_val_reshaped = X_valid.reshape(-1, n_features)\n",
    "x_val_scaled = x_scaler.transform(x_val_reshaped)\n",
    "x_val_scaled = x_val_scaled.reshape(n_val_samples, n_timesteps, n_features)\n",
    "\n",
    "# x_test\n",
    "n_test_samples = X_test.shape[0]\n",
    "x_test_reshaped = X_test.reshape(-1, n_features)\n",
    "x_test_scaled = x_scaler.transform(x_test_reshaped)\n",
    "x_test_scaled = x_test_scaled.reshape(n_test_samples, n_timesteps, n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rw7rcIWPlx6D"
   },
   "source": [
    "Normalise y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "azSWFgFmlx6D"
   },
   "outputs": [],
   "source": [
    "# Reshape y_train to 2D for scaling\n",
    "y_train_reshaped = y_train.reshape(-1, 1)  # Shape: (n_samples * n_outputs, 1)\n",
    "# Fit the scaler on the training data\n",
    "y_scaler.fit(y_train_reshaped)\n",
    "# Transform the training data\n",
    "y_train_scaled = y_scaler.transform(y_train_reshaped)\n",
    "# Reshape back to original shape\n",
    "y_train_scaled = y_train_scaled.reshape(n_samples, y_train.shape[1])\n",
    "\n",
    "# y_val\n",
    "y_val_reshaped = y_valid.reshape(-1, 1)\n",
    "y_val_scaled = y_scaler.transform(y_val_reshaped)\n",
    "y_val_scaled = y_val_scaled.reshape(n_val_samples, y_valid.shape[1])\n",
    "\n",
    "# y_test\n",
    "y_test_reshaped = y_test.reshape(-1, 1)\n",
    "y_test_scaled = y_scaler.transform(y_test_reshaped)\n",
    "y_test_scaled = y_test_scaled.reshape(n_test_samples, y_test.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZ0-bDswmeQj"
   },
   "source": [
    "## 3. Build the CNN model (step-by-step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "kxm7aAuplxhH"
   },
   "outputs": [],
   "source": [
    "def create_cnn_model_recursive(input_shape,\n",
    "                               dropout_rate=0.5,\n",
    "                               learning_rate=0.001,\n",
    "                               filters=64,\n",
    "                               kernel_size=3):\n",
    "    model = keras.Sequential([\n",
    "        layers.Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', input_shape=input_shape),\n",
    "        layers.Conv1D(filters=filters, kernel_size=kernel_size, activation='relu'),\n",
    "        layers.MaxPooling1D(pool_size=2),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(50, activation='relu'),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(1)  # Output layer for one-step prediction\n",
    "    ])\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNCpVPIsoiwy"
   },
   "source": [
    "## 4. Define Separate Hyperparameter Grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "v0jfjebqpu9r"
   },
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "rJITS9S6ogV7"
   },
   "outputs": [],
   "source": [
    "dropout_rates = [0, 0.3, 0.5]\n",
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "batch_sizes = [32, 64, 128]\n",
    "filters_list = [32, 64, 128]\n",
    "kernel_sizes = [2, 3, 5]\n",
    "\n",
    "# Create a list of all hyperparameter combinations\n",
    "hyperparameter_combinations = list(product(dropout_rates,\n",
    "                                           learning_rates, batch_sizes,\n",
    "                                           filters_list,\n",
    "                                           kernel_sizes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tuning hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CWDXJpuepTIS",
    "outputId": "9f42c434-cd3d-4ed6-83e2-c1eff4878ec2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination 1/243\n",
      "Training with dropout_rate=0, learning_rate=0.01, batch_size=32, filters=32, kernel_size=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\program\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation MAE: 0.0463\n",
      "\n",
      "Combination 2/243\n",
      "Training with dropout_rate=0, learning_rate=0.01, batch_size=32, filters=32, kernel_size=3\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation MAE: 0.0468\n",
      "\n",
      "Combination 3/243\n",
      "Training with dropout_rate=0, learning_rate=0.01, batch_size=32, filters=32, kernel_size=5\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation MAE: 0.0468\n",
      "\n",
      "Combination 4/243\n",
      "Training with dropout_rate=0, learning_rate=0.01, batch_size=32, filters=64, kernel_size=2\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation MAE: 0.0471\n",
      "\n",
      "Combination 5/243\n",
      "Training with dropout_rate=0, learning_rate=0.01, batch_size=32, filters=64, kernel_size=3\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation MAE: 0.0476\n",
      "\n",
      "Combination 6/243\n",
      "Training with dropout_rate=0, learning_rate=0.01, batch_size=32, filters=64, kernel_size=5\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation MAE: 0.0467\n",
      "\n",
      "Combination 7/243\n",
      "Training with dropout_rate=0, learning_rate=0.01, batch_size=32, filters=128, kernel_size=2\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation MAE: 0.0476\n",
      "\n",
      "Combination 8/243\n",
      "Training with dropout_rate=0, learning_rate=0.01, batch_size=32, filters=128, kernel_size=3\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation MAE: 0.0471\n",
      "\n",
      "Combination 9/243\n",
      "Training with dropout_rate=0, learning_rate=0.01, batch_size=32, filters=128, kernel_size=5\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation MAE: 0.0471\n",
      "\n",
      "Combination 10/243\n",
      "Training with dropout_rate=0, learning_rate=0.01, batch_size=64, filters=32, kernel_size=2\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation MAE: 0.0459\n",
      "\n",
      "Combination 11/243\n",
      "Training with dropout_rate=0, learning_rate=0.01, batch_size=64, filters=32, kernel_size=3\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation MAE: 0.0463\n",
      "\n",
      "Combination 12/243\n",
      "Training with dropout_rate=0, learning_rate=0.01, batch_size=64, filters=32, kernel_size=5\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation MAE: 0.0462\n",
      "\n",
      "Combination 13/243\n",
      "Training with dropout_rate=0, learning_rate=0.01, batch_size=64, filters=64, kernel_size=2\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation MAE: 0.0463\n",
      "\n",
      "Combination 14/243\n",
      "Training with dropout_rate=0, learning_rate=0.01, batch_size=64, filters=64, kernel_size=3\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation MAE: 0.0460\n",
      "\n",
      "Combination 15/243\n",
      "Training with dropout_rate=0, learning_rate=0.01, batch_size=64, filters=64, kernel_size=5\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation MAE: 0.0463\n",
      "\n",
      "Combination 16/243\n",
      "Training with dropout_rate=0, learning_rate=0.01, batch_size=64, filters=128, kernel_size=2\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation MAE: 0.0464\n",
      "\n",
      "Combination 17/243\n",
      "Training with dropout_rate=0, learning_rate=0.01, batch_size=64, filters=128, kernel_size=3\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation MAE: 0.0473\n",
      "\n",
      "Combination 18/243\n",
      "Training with dropout_rate=0, learning_rate=0.01, batch_size=64, filters=128, kernel_size=5\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation MAE: 0.0468\n",
      "\n",
      "Combination 19/243\n",
      "Training with dropout_rate=0, learning_rate=0.01, batch_size=128, filters=32, kernel_size=2\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation MAE: 0.0462\n",
      "\n",
      "Combination 20/243\n",
      "Training with dropout_rate=0, learning_rate=0.01, batch_size=128, filters=32, kernel_size=3\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation MAE: 0.0465\n",
      "\n",
      "Combination 21/243\n",
      "Training with dropout_rate=0, learning_rate=0.01, batch_size=128, filters=32, kernel_size=5\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation MAE: 0.0459\n",
      "\n",
      "Combination 22/243\n",
      "Training with dropout_rate=0, learning_rate=0.01, batch_size=128, filters=64, kernel_size=2\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation MAE: 0.0460\n",
      "\n",
      "Combination 23/243\n",
      "Training with dropout_rate=0, learning_rate=0.01, batch_size=128, filters=64, kernel_size=3\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation MAE: 0.0461\n",
      "\n",
      "Combination 24/243\n",
      "Training with dropout_rate=0, learning_rate=0.01, batch_size=128, filters=64, kernel_size=5\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation MAE: 0.0460\n",
      "\n",
      "Combination 25/243\n",
      "Training with dropout_rate=0, learning_rate=0.01, batch_size=128, filters=128, kernel_size=2\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation MAE: 0.0470\n",
      "\n",
      "Combination 26/243\n",
      "Training with dropout_rate=0, learning_rate=0.01, batch_size=128, filters=128, kernel_size=3\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation MAE: 0.0473\n",
      "\n",
      "Combination 27/243\n",
      "Training with dropout_rate=0, learning_rate=0.01, batch_size=128, filters=128, kernel_size=5\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation MAE: 0.0485\n",
      "\n",
      "Combination 28/243\n",
      "Training with dropout_rate=0, learning_rate=0.001, batch_size=32, filters=32, kernel_size=2\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation MAE: 0.0461\n",
      "\n",
      "Combination 29/243\n",
      "Training with dropout_rate=0, learning_rate=0.001, batch_size=32, filters=32, kernel_size=3\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation MAE: 0.0456\n",
      "\n",
      "Combination 30/243\n",
      "Training with dropout_rate=0, learning_rate=0.001, batch_size=32, filters=32, kernel_size=5\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation MAE: 0.0459\n",
      "\n",
      "Combination 31/243\n",
      "Training with dropout_rate=0, learning_rate=0.001, batch_size=32, filters=64, kernel_size=2\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation MAE: 0.0452\n",
      "\n",
      "Combination 32/243\n",
      "Training with dropout_rate=0, learning_rate=0.001, batch_size=32, filters=64, kernel_size=3\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation MAE: 0.0469\n",
      "\n",
      "Combination 33/243\n",
      "Training with dropout_rate=0, learning_rate=0.001, batch_size=32, filters=64, kernel_size=5\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation MAE: 0.0453\n",
      "\n",
      "Combination 34/243\n",
      "Training with dropout_rate=0, learning_rate=0.001, batch_size=32, filters=128, kernel_size=2\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation MAE: 0.0451\n",
      "\n",
      "Combination 35/243\n",
      "Training with dropout_rate=0, learning_rate=0.001, batch_size=32, filters=128, kernel_size=3\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation MAE: 0.0452\n",
      "\n",
      "Combination 36/243\n",
      "Training with dropout_rate=0, learning_rate=0.001, batch_size=32, filters=128, kernel_size=5\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation MAE: 0.0449\n",
      "\n",
      "Combination 37/243\n",
      "Training with dropout_rate=0, learning_rate=0.001, batch_size=64, filters=32, kernel_size=2\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation MAE: 0.0451\n",
      "\n",
      "Combination 38/243\n",
      "Training with dropout_rate=0, learning_rate=0.001, batch_size=64, filters=32, kernel_size=3\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE: 0.0452\n",
      "\n",
      "Combination 39/243\n",
      "Training with dropout_rate=0, learning_rate=0.001, batch_size=64, filters=32, kernel_size=5\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation MAE: 0.0453\n",
      "\n",
      "Combination 40/243\n",
      "Training with dropout_rate=0, learning_rate=0.001, batch_size=64, filters=64, kernel_size=2\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation MAE: 0.0454\n",
      "\n",
      "Combination 41/243\n",
      "Training with dropout_rate=0, learning_rate=0.001, batch_size=64, filters=64, kernel_size=3\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation MAE: 0.0449\n",
      "\n",
      "Combination 42/243\n",
      "Training with dropout_rate=0, learning_rate=0.001, batch_size=64, filters=64, kernel_size=5\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation MAE: 0.0460\n",
      "\n",
      "Combination 43/243\n",
      "Training with dropout_rate=0, learning_rate=0.001, batch_size=64, filters=128, kernel_size=2\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation MAE: 0.0449\n",
      "\n",
      "Combination 44/243\n",
      "Training with dropout_rate=0, learning_rate=0.001, batch_size=64, filters=128, kernel_size=3\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation MAE: 0.0450\n",
      "\n",
      "Combination 45/243\n",
      "Training with dropout_rate=0, learning_rate=0.001, batch_size=64, filters=128, kernel_size=5\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation MAE: 0.0452\n",
      "\n",
      "Combination 46/243\n",
      "Training with dropout_rate=0, learning_rate=0.001, batch_size=128, filters=32, kernel_size=2\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation MAE: 0.0447\n",
      "\n",
      "Combination 47/243\n",
      "Training with dropout_rate=0, learning_rate=0.001, batch_size=128, filters=32, kernel_size=3\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Validation MAE: 0.0450\n",
      "\n",
      "Combination 48/243\n",
      "Training with dropout_rate=0, learning_rate=0.001, batch_size=128, filters=32, kernel_size=5\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation MAE: 0.0453\n",
      "\n",
      "Combination 49/243\n",
      "Training with dropout_rate=0, learning_rate=0.001, batch_size=128, filters=64, kernel_size=2\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation MAE: 0.0448\n",
      "\n",
      "Combination 50/243\n",
      "Training with dropout_rate=0, learning_rate=0.001, batch_size=128, filters=64, kernel_size=3\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation MAE: 0.0446\n",
      "\n",
      "Combination 51/243\n",
      "Training with dropout_rate=0, learning_rate=0.001, batch_size=128, filters=64, kernel_size=5\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation MAE: 0.0449\n",
      "\n",
      "Combination 52/243\n",
      "Training with dropout_rate=0, learning_rate=0.001, batch_size=128, filters=128, kernel_size=2\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation MAE: 0.0452\n",
      "\n",
      "Combination 53/243\n",
      "Training with dropout_rate=0, learning_rate=0.001, batch_size=128, filters=128, kernel_size=3\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation MAE: 0.0451\n",
      "\n",
      "Combination 54/243\n",
      "Training with dropout_rate=0, learning_rate=0.001, batch_size=128, filters=128, kernel_size=5\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation MAE: 0.0453\n",
      "\n",
      "Combination 55/243\n",
      "Training with dropout_rate=0, learning_rate=0.0001, batch_size=32, filters=32, kernel_size=2\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation MAE: 0.0455\n",
      "\n",
      "Combination 56/243\n",
      "Training with dropout_rate=0, learning_rate=0.0001, batch_size=32, filters=32, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0451\n",
      "\n",
      "Combination 57/243\n",
      "Training with dropout_rate=0, learning_rate=0.0001, batch_size=32, filters=32, kernel_size=5\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation MAE: 0.0452\n",
      "\n",
      "Combination 58/243\n",
      "Training with dropout_rate=0, learning_rate=0.0001, batch_size=32, filters=64, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0448\n",
      "\n",
      "Combination 59/243\n",
      "Training with dropout_rate=0, learning_rate=0.0001, batch_size=32, filters=64, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation MAE: 0.0448\n",
      "\n",
      "Combination 60/243\n",
      "Training with dropout_rate=0, learning_rate=0.0001, batch_size=32, filters=64, kernel_size=5\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation MAE: 0.0449\n",
      "\n",
      "Combination 61/243\n",
      "Training with dropout_rate=0, learning_rate=0.0001, batch_size=32, filters=128, kernel_size=2\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation MAE: 0.0448\n",
      "\n",
      "Combination 62/243\n",
      "Training with dropout_rate=0, learning_rate=0.0001, batch_size=32, filters=128, kernel_size=3\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation MAE: 0.0452\n",
      "\n",
      "Combination 63/243\n",
      "Training with dropout_rate=0, learning_rate=0.0001, batch_size=32, filters=128, kernel_size=5\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation MAE: 0.0448\n",
      "\n",
      "Combination 64/243\n",
      "Training with dropout_rate=0, learning_rate=0.0001, batch_size=64, filters=32, kernel_size=2\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation MAE: 0.0451\n",
      "\n",
      "Combination 65/243\n",
      "Training with dropout_rate=0, learning_rate=0.0001, batch_size=64, filters=32, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation MAE: 0.0449\n",
      "\n",
      "Combination 66/243\n",
      "Training with dropout_rate=0, learning_rate=0.0001, batch_size=64, filters=32, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0452\n",
      "\n",
      "Combination 67/243\n",
      "Training with dropout_rate=0, learning_rate=0.0001, batch_size=64, filters=64, kernel_size=2\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation MAE: 0.0451\n",
      "\n",
      "Combination 68/243\n",
      "Training with dropout_rate=0, learning_rate=0.0001, batch_size=64, filters=64, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0447\n",
      "\n",
      "Combination 69/243\n",
      "Training with dropout_rate=0, learning_rate=0.0001, batch_size=64, filters=64, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation MAE: 0.0449\n",
      "\n",
      "Combination 70/243\n",
      "Training with dropout_rate=0, learning_rate=0.0001, batch_size=64, filters=128, kernel_size=2\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation MAE: 0.0448\n",
      "\n",
      "Combination 71/243\n",
      "Training with dropout_rate=0, learning_rate=0.0001, batch_size=64, filters=128, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0446\n",
      "\n",
      "Combination 72/243\n",
      "Training with dropout_rate=0, learning_rate=0.0001, batch_size=64, filters=128, kernel_size=5\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation MAE: 0.0447\n",
      "\n",
      "Combination 73/243\n",
      "Training with dropout_rate=0, learning_rate=0.0001, batch_size=128, filters=32, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0458\n",
      "\n",
      "Combination 74/243\n",
      "Training with dropout_rate=0, learning_rate=0.0001, batch_size=128, filters=32, kernel_size=3\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation MAE: 0.0455\n",
      "\n",
      "Combination 75/243\n",
      "Training with dropout_rate=0, learning_rate=0.0001, batch_size=128, filters=32, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0458\n",
      "\n",
      "Combination 76/243\n",
      "Training with dropout_rate=0, learning_rate=0.0001, batch_size=128, filters=64, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0452\n",
      "\n",
      "Combination 77/243\n",
      "Training with dropout_rate=0, learning_rate=0.0001, batch_size=128, filters=64, kernel_size=3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation MAE: 0.0450\n",
      "\n",
      "Combination 78/243\n",
      "Training with dropout_rate=0, learning_rate=0.0001, batch_size=128, filters=64, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation MAE: 0.0450\n",
      "\n",
      "Combination 79/243\n",
      "Training with dropout_rate=0, learning_rate=0.0001, batch_size=128, filters=128, kernel_size=2\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation MAE: 0.0452\n",
      "\n",
      "Combination 80/243\n",
      "Training with dropout_rate=0, learning_rate=0.0001, batch_size=128, filters=128, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation MAE: 0.0449\n",
      "\n",
      "Combination 81/243\n",
      "Training with dropout_rate=0, learning_rate=0.0001, batch_size=128, filters=128, kernel_size=5\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation MAE: 0.0449\n",
      "\n",
      "Combination 82/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=32, filters=32, kernel_size=2\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation MAE: 0.0520\n",
      "\n",
      "Combination 83/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=32, filters=32, kernel_size=3\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation MAE: 0.0490\n",
      "\n",
      "Combination 84/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=32, filters=32, kernel_size=5\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation MAE: 0.0500\n",
      "\n",
      "Combination 85/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=32, filters=64, kernel_size=2\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation MAE: 0.0515\n",
      "\n",
      "Combination 86/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=32, filters=64, kernel_size=3\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation MAE: 0.0502\n",
      "\n",
      "Combination 87/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=32, filters=64, kernel_size=5\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation MAE: 0.0518\n",
      "\n",
      "Combination 88/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=32, filters=128, kernel_size=2\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation MAE: 0.0516\n",
      "\n",
      "Combination 89/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=32, filters=128, kernel_size=3\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation MAE: 0.0523\n",
      "\n",
      "Combination 90/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=32, filters=128, kernel_size=5\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation MAE: 0.0493\n",
      "\n",
      "Combination 91/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=64, filters=32, kernel_size=2\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation MAE: 0.0490\n",
      "\n",
      "Combination 92/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=64, filters=32, kernel_size=3\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation MAE: 0.0497\n",
      "\n",
      "Combination 93/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=64, filters=32, kernel_size=5\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation MAE: 0.0488\n",
      "\n",
      "Combination 94/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=64, filters=64, kernel_size=2\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation MAE: 0.0495\n",
      "\n",
      "Combination 95/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=64, filters=64, kernel_size=3\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation MAE: 0.0501\n",
      "\n",
      "Combination 96/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=64, filters=64, kernel_size=5\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation MAE: 0.0478\n",
      "\n",
      "Combination 97/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=64, filters=128, kernel_size=2\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation MAE: 0.0517\n",
      "\n",
      "Combination 98/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=64, filters=128, kernel_size=3\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation MAE: 0.0481\n",
      "\n",
      "Combination 99/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=64, filters=128, kernel_size=5\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation MAE: 0.0487\n",
      "\n",
      "Combination 100/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=128, filters=32, kernel_size=2\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation MAE: 0.0499\n",
      "\n",
      "Combination 101/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=128, filters=32, kernel_size=3\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation MAE: 0.0486\n",
      "\n",
      "Combination 102/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=128, filters=32, kernel_size=5\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation MAE: 0.0488\n",
      "\n",
      "Combination 103/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=128, filters=64, kernel_size=2\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Validation MAE: 0.0473\n",
      "\n",
      "Combination 104/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=128, filters=64, kernel_size=3\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation MAE: 0.0475\n",
      "\n",
      "Combination 105/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=128, filters=64, kernel_size=5\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation MAE: 0.0511\n",
      "\n",
      "Combination 106/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=128, filters=128, kernel_size=2\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation MAE: 0.0528\n",
      "\n",
      "Combination 107/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=128, filters=128, kernel_size=3\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Validation MAE: 0.0488\n",
      "\n",
      "Combination 108/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.01, batch_size=128, filters=128, kernel_size=5\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation MAE: 0.0496\n",
      "\n",
      "Combination 109/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=32, filters=32, kernel_size=2\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation MAE: 0.0462\n",
      "\n",
      "Combination 110/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=32, filters=32, kernel_size=3\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation MAE: 0.0465\n",
      "\n",
      "Combination 111/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=32, filters=32, kernel_size=5\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation MAE: 0.0477\n",
      "\n",
      "Combination 112/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=32, filters=64, kernel_size=2\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation MAE: 0.0464\n",
      "\n",
      "Combination 113/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=32, filters=64, kernel_size=3\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation MAE: 0.0460\n",
      "\n",
      "Combination 114/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=32, filters=64, kernel_size=5\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE: 0.0460\n",
      "\n",
      "Combination 115/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=32, filters=128, kernel_size=2\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation MAE: 0.0469\n",
      "\n",
      "Combination 116/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=32, filters=128, kernel_size=3\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation MAE: 0.0460\n",
      "\n",
      "Combination 117/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=32, filters=128, kernel_size=5\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation MAE: 0.0457\n",
      "\n",
      "Combination 118/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=64, filters=32, kernel_size=2\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation MAE: 0.0458\n",
      "\n",
      "Combination 119/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=64, filters=32, kernel_size=3\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation MAE: 0.0466\n",
      "\n",
      "Combination 120/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=64, filters=32, kernel_size=5\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation MAE: 0.0474\n",
      "\n",
      "Combination 121/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=64, filters=64, kernel_size=2\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation MAE: 0.0460\n",
      "\n",
      "Combination 122/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=64, filters=64, kernel_size=3\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation MAE: 0.0464\n",
      "\n",
      "Combination 123/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=64, filters=64, kernel_size=5\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation MAE: 0.0457\n",
      "\n",
      "Combination 124/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=64, filters=128, kernel_size=2\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation MAE: 0.0456\n",
      "\n",
      "Combination 125/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=64, filters=128, kernel_size=3\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation MAE: 0.0458\n",
      "\n",
      "Combination 126/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=64, filters=128, kernel_size=5\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation MAE: 0.0461\n",
      "\n",
      "Combination 127/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=128, filters=32, kernel_size=2\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation MAE: 0.0464\n",
      "\n",
      "Combination 128/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=128, filters=32, kernel_size=3\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation MAE: 0.0472\n",
      "\n",
      "Combination 129/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=128, filters=32, kernel_size=5\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Validation MAE: 0.0475\n",
      "\n",
      "Combination 130/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=128, filters=64, kernel_size=2\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation MAE: 0.0460\n",
      "\n",
      "Combination 131/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=128, filters=64, kernel_size=3\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation MAE: 0.0456\n",
      "\n",
      "Combination 132/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=128, filters=64, kernel_size=5\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Validation MAE: 0.0460\n",
      "\n",
      "Combination 133/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=128, filters=128, kernel_size=2\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation MAE: 0.0464\n",
      "\n",
      "Combination 134/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=128, filters=128, kernel_size=3\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation MAE: 0.0459\n",
      "\n",
      "Combination 135/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.001, batch_size=128, filters=128, kernel_size=5\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Validation MAE: 0.0456\n",
      "\n",
      "Combination 136/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=32, filters=32, kernel_size=2\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Validation MAE: 0.0469\n",
      "\n",
      "Combination 137/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=32, filters=32, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0460\n",
      "\n",
      "Combination 138/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=32, filters=32, kernel_size=5\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation MAE: 0.0471\n",
      "\n",
      "Combination 139/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=32, filters=64, kernel_size=2\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation MAE: 0.0464\n",
      "\n",
      "Combination 140/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=32, filters=64, kernel_size=3\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation MAE: 0.0458\n",
      "\n",
      "Combination 141/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=32, filters=64, kernel_size=5\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation MAE: 0.0453\n",
      "\n",
      "Combination 142/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=32, filters=128, kernel_size=2\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation MAE: 0.0453\n",
      "\n",
      "Combination 143/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=32, filters=128, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation MAE: 0.0451\n",
      "\n",
      "Combination 144/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=32, filters=128, kernel_size=5\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation MAE: 0.0461\n",
      "\n",
      "Combination 145/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=64, filters=32, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0470\n",
      "\n",
      "Combination 146/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=64, filters=32, kernel_size=3\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation MAE: 0.0464\n",
      "\n",
      "Combination 147/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=64, filters=32, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0471\n",
      "\n",
      "Combination 148/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=64, filters=64, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation MAE: 0.0460\n",
      "\n",
      "Combination 149/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=64, filters=64, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation MAE: 0.0458\n",
      "\n",
      "Combination 150/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=64, filters=64, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0456\n",
      "\n",
      "Combination 151/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=64, filters=128, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation MAE: 0.0458\n",
      "\n",
      "Combination 152/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=64, filters=128, kernel_size=3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation MAE: 0.0457\n",
      "\n",
      "Combination 153/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=64, filters=128, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0450\n",
      "\n",
      "Combination 154/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=128, filters=32, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0482\n",
      "\n",
      "Combination 155/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=128, filters=32, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0473\n",
      "\n",
      "Combination 156/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=128, filters=32, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation MAE: 0.0473\n",
      "\n",
      "Combination 157/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=128, filters=64, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0468\n",
      "\n",
      "Combination 158/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=128, filters=64, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0462\n",
      "\n",
      "Combination 159/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=128, filters=64, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Validation MAE: 0.0463\n",
      "\n",
      "Combination 160/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=128, filters=128, kernel_size=2\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation MAE: 0.0460\n",
      "\n",
      "Combination 161/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=128, filters=128, kernel_size=3\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation MAE: 0.0461\n",
      "\n",
      "Combination 162/243\n",
      "Training with dropout_rate=0.3, learning_rate=0.0001, batch_size=128, filters=128, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation MAE: 0.0456\n",
      "\n",
      "Combination 163/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=32, filters=32, kernel_size=2\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation MAE: 0.0560\n",
      "\n",
      "Combination 164/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=32, filters=32, kernel_size=3\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation MAE: 0.0542\n",
      "\n",
      "Combination 165/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=32, filters=32, kernel_size=5\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation MAE: 0.0522\n",
      "\n",
      "Combination 166/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=32, filters=64, kernel_size=2\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation MAE: 0.0546\n",
      "\n",
      "Combination 167/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=32, filters=64, kernel_size=3\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Validation MAE: 0.0552\n",
      "\n",
      "Combination 168/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=32, filters=64, kernel_size=5\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation MAE: 0.0549\n",
      "\n",
      "Combination 169/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=32, filters=128, kernel_size=2\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation MAE: 0.0578\n",
      "\n",
      "Combination 170/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=32, filters=128, kernel_size=3\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation MAE: 0.0523\n",
      "\n",
      "Combination 171/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=32, filters=128, kernel_size=5\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation MAE: 0.0535\n",
      "\n",
      "Combination 172/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=64, filters=32, kernel_size=2\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation MAE: 0.0535\n",
      "\n",
      "Combination 173/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=64, filters=32, kernel_size=3\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation MAE: 0.0529\n",
      "\n",
      "Combination 174/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=64, filters=32, kernel_size=5\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Validation MAE: 0.0572\n",
      "\n",
      "Combination 175/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=64, filters=64, kernel_size=2\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Validation MAE: 0.0554\n",
      "\n",
      "Combination 176/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=64, filters=64, kernel_size=3\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation MAE: 0.0552\n",
      "\n",
      "Combination 177/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=64, filters=64, kernel_size=5\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation MAE: 0.0525\n",
      "\n",
      "Combination 178/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=64, filters=128, kernel_size=2\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation MAE: 0.0529\n",
      "\n",
      "Combination 179/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=64, filters=128, kernel_size=3\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation MAE: 0.0521\n",
      "\n",
      "Combination 180/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=64, filters=128, kernel_size=5\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation MAE: 0.0554\n",
      "\n",
      "Combination 181/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=128, filters=32, kernel_size=2\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation MAE: 0.0548\n",
      "\n",
      "Combination 182/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=128, filters=32, kernel_size=3\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Validation MAE: 0.0496\n",
      "\n",
      "Combination 183/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=128, filters=32, kernel_size=5\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Validation MAE: 0.0503\n",
      "\n",
      "Combination 184/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=128, filters=64, kernel_size=2\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Validation MAE: 0.0535\n",
      "\n",
      "Combination 185/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=128, filters=64, kernel_size=3\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation MAE: 0.0544\n",
      "\n",
      "Combination 186/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=128, filters=64, kernel_size=5\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Validation MAE: 0.0579\n",
      "\n",
      "Combination 187/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=128, filters=128, kernel_size=2\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation MAE: 0.0557\n",
      "\n",
      "Combination 188/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=128, filters=128, kernel_size=3\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Validation MAE: 0.0631\n",
      "\n",
      "Combination 189/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.01, batch_size=128, filters=128, kernel_size=5\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Validation MAE: 0.0549\n",
      "\n",
      "Combination 190/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=32, filters=32, kernel_size=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Validation MAE: 0.0483\n",
      "\n",
      "Combination 191/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=32, filters=32, kernel_size=3\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation MAE: 0.0484\n",
      "\n",
      "Combination 192/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=32, filters=32, kernel_size=5\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation MAE: 0.0483\n",
      "\n",
      "Combination 193/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=32, filters=64, kernel_size=2\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Validation MAE: 0.0471\n",
      "\n",
      "Combination 194/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=32, filters=64, kernel_size=3\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation MAE: 0.0468\n",
      "\n",
      "Combination 195/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=32, filters=64, kernel_size=5\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Validation MAE: 0.0475\n",
      "\n",
      "Combination 196/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=32, filters=128, kernel_size=2\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation MAE: 0.0460\n",
      "\n",
      "Combination 197/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=32, filters=128, kernel_size=3\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation MAE: 0.0465\n",
      "\n",
      "Combination 198/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=32, filters=128, kernel_size=5\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation MAE: 0.0461\n",
      "\n",
      "Combination 199/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=64, filters=32, kernel_size=2\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation MAE: 0.0486\n",
      "\n",
      "Combination 200/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=64, filters=32, kernel_size=3\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Validation MAE: 0.0472\n",
      "\n",
      "Combination 201/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=64, filters=32, kernel_size=5\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Validation MAE: 0.0515\n",
      "\n",
      "Combination 202/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=64, filters=64, kernel_size=2\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Validation MAE: 0.0473\n",
      "\n",
      "Combination 203/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=64, filters=64, kernel_size=3\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation MAE: 0.0467\n",
      "\n",
      "Combination 204/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=64, filters=64, kernel_size=5\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Validation MAE: 0.0474\n",
      "\n",
      "Combination 205/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=64, filters=128, kernel_size=2\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Validation MAE: 0.0464\n",
      "\n",
      "Combination 206/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=64, filters=128, kernel_size=3\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation MAE: 0.0465\n",
      "\n",
      "Combination 207/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=64, filters=128, kernel_size=5\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Validation MAE: 0.0463\n",
      "\n",
      "Combination 208/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=128, filters=32, kernel_size=2\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Validation MAE: 0.0483\n",
      "\n",
      "Combination 209/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=128, filters=32, kernel_size=3\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation MAE: 0.0480\n",
      "\n",
      "Combination 210/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=128, filters=32, kernel_size=5\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Validation MAE: 0.0504\n",
      "\n",
      "Combination 211/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=128, filters=64, kernel_size=2\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation MAE: 0.0477\n",
      "\n",
      "Combination 212/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=128, filters=64, kernel_size=3\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Validation MAE: 0.0472\n",
      "\n",
      "Combination 213/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=128, filters=64, kernel_size=5\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Validation MAE: 0.0466\n",
      "\n",
      "Combination 214/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=128, filters=128, kernel_size=2\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Validation MAE: 0.0478\n",
      "\n",
      "Combination 215/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=128, filters=128, kernel_size=3\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Validation MAE: 0.0469\n",
      "\n",
      "Combination 216/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.001, batch_size=128, filters=128, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Validation MAE: 0.0463\n",
      "\n",
      "Combination 217/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=32, filters=32, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Validation MAE: 0.0484\n",
      "\n",
      "Combination 218/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=32, filters=32, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Validation MAE: 0.0479\n",
      "\n",
      "Combination 219/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=32, filters=32, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation MAE: 0.0491\n",
      "\n",
      "Combination 220/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=32, filters=64, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation MAE: 0.0472\n",
      "\n",
      "Combination 221/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=32, filters=64, kernel_size=3\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Validation MAE: 0.0472\n",
      "\n",
      "Combination 222/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=32, filters=64, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation MAE: 0.0468\n",
      "\n",
      "Combination 223/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=32, filters=128, kernel_size=2\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Validation MAE: 0.0475\n",
      "\n",
      "Combination 224/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=32, filters=128, kernel_size=3\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Validation MAE: 0.0465\n",
      "\n",
      "Combination 225/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=32, filters=128, kernel_size=5\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation MAE: 0.0459\n",
      "\n",
      "Combination 226/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=64, filters=32, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0497\n",
      "\n",
      "Combination 227/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=64, filters=32, kernel_size=3\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Validation MAE: 0.0482\n",
      "\n",
      "Combination 228/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=64, filters=32, kernel_size=5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation MAE: 0.0493\n",
      "\n",
      "Combination 229/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=64, filters=64, kernel_size=2\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation MAE: 0.0478\n",
      "\n",
      "Combination 230/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=64, filters=64, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Validation MAE: 0.0470\n",
      "\n",
      "Combination 231/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=64, filters=64, kernel_size=5\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Validation MAE: 0.0474\n",
      "\n",
      "Combination 232/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=64, filters=128, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0468\n",
      "\n",
      "Combination 233/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=64, filters=128, kernel_size=3\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Validation MAE: 0.0467\n",
      "\n",
      "Combination 234/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=64, filters=128, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation MAE: 0.0465\n",
      "\n",
      "Combination 235/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=128, filters=32, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0498\n",
      "\n",
      "Combination 236/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=128, filters=32, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Validation MAE: 0.0496\n",
      "\n",
      "Combination 237/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=128, filters=32, kernel_size=5\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Validation MAE: 0.0502\n",
      "\n",
      "Combination 238/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=128, filters=64, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Validation MAE: 0.0487\n",
      "\n",
      "Combination 239/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=128, filters=64, kernel_size=3\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Validation MAE: 0.0480\n",
      "\n",
      "Combination 240/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=128, filters=64, kernel_size=5\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Validation MAE: 0.0480\n",
      "\n",
      "Combination 241/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=128, filters=128, kernel_size=2\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Validation MAE: 0.0472\n",
      "\n",
      "Combination 242/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=128, filters=128, kernel_size=3\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Validation MAE: 0.0470\n",
      "\n",
      "Combination 243/243\n",
      "Training with dropout_rate=0.5, learning_rate=0.0001, batch_size=128, filters=128, kernel_size=5\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Validation MAE: 0.0469\n",
      "\n",
      "Best Hyperparameters:\n",
      "dropout_rate: 0\n",
      "learning_rate: 0.0001\n",
      "batch_size: 64\n",
      "filters: 128\n",
      "kernel_size: 3\n",
      "Best Validation MAE: 0.0446\n"
     ]
    }
   ],
   "source": [
    "best_val_mae = np.inf\n",
    "best_hyperparams = None\n",
    "best_model = None\n",
    "\n",
    "for idx, (dropout_rate, learning_rate, batch_size,\n",
    "          filters, kernel_size) in enumerate(hyperparameter_combinations):\n",
    "    print(f\"\\nCombination {idx+1}/{len(hyperparameter_combinations)}\")\n",
    "    print(f\"Training with dropout_rate={dropout_rate}, \"\n",
    "          f\"learning_rate={learning_rate}, batch_size={batch_size}, \"\n",
    "          f\"filters={filters}, \"\n",
    "          f\"kernel_size={kernel_size}\")\n",
    "\n",
    "    model = create_cnn_model_recursive(\n",
    "        input_shape=(n_timesteps, 1),\n",
    "        dropout_rate=dropout_rate,\n",
    "        learning_rate=learning_rate,\n",
    "        filters=filters,\n",
    "        kernel_size=kernel_size\n",
    "    )\n",
    "\n",
    "    # Initialize EarlyStopping inside the loop\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_mae',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        x_train_scaled, y_train_scaled,\n",
    "        epochs=50,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_val_scaled, y_val_scaled),\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0  # Set to 1 to see detailed training output\n",
    "    )\n",
    "\n",
    "    # Get the best validation MAE from this training run\n",
    "    val_mae = min(history.history['val_mae'])\n",
    "    print(f\"Validation MAE: {val_mae:.4f}\")\n",
    "\n",
    "    # Update best model if current one is better\n",
    "    if val_mae < best_val_mae:\n",
    "        best_val_mae = val_mae\n",
    "        best_model = model\n",
    "        best_hyperparams = {\n",
    "            'dropout_rate': dropout_rate,\n",
    "            'learning_rate': learning_rate,\n",
    "            'batch_size': batch_size,\n",
    "            'filters': filters,\n",
    "            'kernel_size': kernel_size\n",
    "        }\n",
    "\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "for param, value in best_hyperparams.items():\n",
    "    print(f\"{param}: {value}\")\n",
    "print(f\"Best Validation MAE: {best_val_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dt4QEaoOzlW5"
   },
   "source": [
    "Best hyperparameter for full time:\n",
    "'dropout_rate': 0,\n",
    " 'learning_rate': 0.001,\n",
    " 'batch_size': 32,\n",
    " 'filters': 128,\n",
    " 'kernel_size': 3\n",
    " \n",
    "Best hyperparameter for after covid:\n",
    "dropout_rate: 0\n",
    "learning_rate: 0.0001\n",
    "batch_size: 64\n",
    "filters: 128\n",
    "kernel_size: 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppIzpGSCZGCY"
   },
   "source": [
    "#### 5.1 Recreate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "2e7yOQ99RXif"
   },
   "outputs": [],
   "source": [
    "def create_best_cnn_model(input_shape, n_outputs):\n",
    "    model = keras.Sequential([\n",
    "        # First convolutional layer\n",
    "        layers.Conv1D(filters=128, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "        # Second convolutional layer\n",
    "        layers.Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
    "        # Pooling layer\n",
    "        layers.MaxPooling1D(pool_size=2),\n",
    "        # Regularization\n",
    "        layers.Dropout(0),\n",
    "        # Flattening the output\n",
    "        layers.Flatten(),\n",
    "        # Fully connected layers\n",
    "        layers.Dense(50, activation='relu'),\n",
    "        layers.Dropout(0),\n",
    "        # Output layer\n",
    "        layers.Dense(n_outputs)\n",
    "    ])\n",
    "    # Compile the model\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    model.compile(\n",
    "        loss='mse',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ush-69jZEa2",
    "outputId": "3829be76-1aa2-46b6-d737-491a19231cb2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\program\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Recreate the model\n",
    "input_shape = (x_train_scaled.shape[1], x_train_scaled.shape[2])\n",
    "n_outputs = y_train.shape[1]\n",
    "best_model = create_best_cnn_model(input_shape, n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14, 1), 1, (2141, 14, 1))"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape,n_outputs,x_test_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZDlERj6Zb3s"
   },
   "source": [
    "#### 5.2 Retrain the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "da0WpEFIZYft"
   },
   "outputs": [],
   "source": [
    "# Initialize EarlyStopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_mae',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j7yTmBHpZwtP",
    "outputId": "cbfa60cb-5667-4ca3-d9e0-5e57be8dd432",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0245 - mae: 0.1161 - val_loss: 0.0057 - val_mae: 0.0513\n",
      "Epoch 2/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0048 - mae: 0.0457 - val_loss: 0.0055 - val_mae: 0.0491\n",
      "Epoch 3/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0044 - mae: 0.0441 - val_loss: 0.0050 - val_mae: 0.0475\n",
      "Epoch 4/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0042 - mae: 0.0424 - val_loss: 0.0049 - val_mae: 0.0467\n",
      "Epoch 5/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0038 - mae: 0.0412 - val_loss: 0.0047 - val_mae: 0.0467\n",
      "Epoch 6/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0042 - mae: 0.0423 - val_loss: 0.0059 - val_mae: 0.0512\n",
      "Epoch 7/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0042 - mae: 0.0426 - val_loss: 0.0048 - val_mae: 0.0459\n",
      "Epoch 8/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0040 - mae: 0.0415 - val_loss: 0.0047 - val_mae: 0.0462\n",
      "Epoch 9/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0040 - mae: 0.0418 - val_loss: 0.0049 - val_mae: 0.0462\n",
      "Epoch 10/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0042 - mae: 0.0420 - val_loss: 0.0045 - val_mae: 0.0465\n",
      "Epoch 11/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0039 - mae: 0.0412 - val_loss: 0.0047 - val_mae: 0.0459\n",
      "Epoch 12/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0036 - mae: 0.0399 - val_loss: 0.0047 - val_mae: 0.0495\n",
      "Epoch 13/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0040 - mae: 0.0425 - val_loss: 0.0045 - val_mae: 0.0455\n",
      "Epoch 14/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0041 - mae: 0.0421 - val_loss: 0.0045 - val_mae: 0.0454\n",
      "Epoch 15/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0038 - mae: 0.0404 - val_loss: 0.0045 - val_mae: 0.0455\n",
      "Epoch 16/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0040 - mae: 0.0412 - val_loss: 0.0044 - val_mae: 0.0460\n",
      "Epoch 17/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0405 - val_loss: 0.0045 - val_mae: 0.0451\n",
      "Epoch 18/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - mae: 0.0398 - val_loss: 0.0045 - val_mae: 0.0455\n",
      "Epoch 19/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0038 - mae: 0.0401 - val_loss: 0.0045 - val_mae: 0.0463\n",
      "Epoch 20/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - mae: 0.0400 - val_loss: 0.0044 - val_mae: 0.0465\n",
      "Epoch 21/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0040 - mae: 0.0409 - val_loss: 0.0045 - val_mae: 0.0450\n",
      "Epoch 22/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0038 - mae: 0.0401 - val_loss: 0.0044 - val_mae: 0.0449\n",
      "Epoch 23/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - mae: 0.0398 - val_loss: 0.0045 - val_mae: 0.0452\n",
      "Epoch 24/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0043 - mae: 0.0407 - val_loss: 0.0044 - val_mae: 0.0459\n",
      "Epoch 25/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0039 - mae: 0.0400 - val_loss: 0.0045 - val_mae: 0.0451\n",
      "Epoch 26/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0039 - mae: 0.0404 - val_loss: 0.0045 - val_mae: 0.0457\n",
      "Epoch 27/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0038 - mae: 0.0402 - val_loss: 0.0045 - val_mae: 0.0481\n",
      "Epoch 28/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0039 - mae: 0.0416 - val_loss: 0.0045 - val_mae: 0.0448\n",
      "Epoch 29/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0392 - val_loss: 0.0044 - val_mae: 0.0478\n",
      "Epoch 30/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0397 - val_loss: 0.0043 - val_mae: 0.0450\n",
      "Epoch 31/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0040 - mae: 0.0407 - val_loss: 0.0043 - val_mae: 0.0449\n",
      "Epoch 32/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0038 - mae: 0.0401 - val_loss: 0.0045 - val_mae: 0.0455\n",
      "Epoch 33/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0404 - val_loss: 0.0045 - val_mae: 0.0450\n",
      "Epoch 34/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0395 - val_loss: 0.0044 - val_mae: 0.0455\n",
      "Epoch 35/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0394 - val_loss: 0.0048 - val_mae: 0.0460\n",
      "Epoch 36/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0402 - val_loss: 0.0044 - val_mae: 0.0448\n",
      "Epoch 37/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0395 - val_loss: 0.0044 - val_mae: 0.0463\n",
      "Epoch 38/50\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0039 - mae: 0.0413 - val_loss: 0.0047 - val_mae: 0.0456\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = best_model.fit(\n",
    "    x_train_scaled, y_train_scaled,\n",
    "    epochs=50,  # You can adjust this as needed\n",
    "    batch_size=64,\n",
    "    validation_data=(x_val_scaled, y_val_scaled),\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1  # Set to 1 to see detailed training output\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Make prediction (step-by-step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "id": "O5eKQOi8dLQ-"
   },
   "outputs": [],
   "source": [
    "def recursive_forecast(model, x_test_scaled, start_index, n_steps, x_scaler, y_scaler):\n",
    "    \"\"\"\n",
    "    Perform recursive forecasting using the trained model.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained model\n",
    "    - x_test_scaled: The scaled test input data (shape: n_samples, n_timesteps, n_features)\n",
    "    - start_index: The starting index in the test data\n",
    "    - n_steps: Number of future steps to predict\n",
    "    - x_scaler: Scaler used for input features\n",
    "    - y_scaler: Scaler used for target variable\n",
    "\n",
    "    Returns:\n",
    "    - predictions: List of predicted values (in original scale)\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    scaled_predictions = []\n",
    "    current_input = x_test_scaled[start_index].copy()  # Shape: (n_timesteps, n_features)\n",
    "\n",
    "    for step in range(n_steps):\n",
    "        # Reshape to (1, n_timesteps, n_features) for prediction\n",
    "        input_seq = current_input.reshape((1, current_input.shape[0], current_input.shape[1]))\n",
    "\n",
    "        # Predict the next time step (scaled)\n",
    "        yhat_scaled = model.predict(input_seq, verbose=0)  # Shape: (1, 1)\n",
    "\n",
    "        # Inverse transform the prediction to original scale\n",
    "        yhat = y_scaler.inverse_transform(yhat_scaled)[0, 0]\n",
    "        \n",
    "        # Transform the prediction back to input feature scale for lag features\n",
    "        yhat_for_input = x_scaler.transform(yhat.reshape(-1, 1))[0, 0]\n",
    "\n",
    "        # Append predictions\n",
    "        predictions.append(yhat)\n",
    "        scaled_predictions.append(yhat_for_input)\n",
    "\n",
    "        # Move to the next time step in x_test_scaled\n",
    "        next_index = start_index + step + 1\n",
    "        if next_index < len(x_test_scaled):\n",
    "            # Use features from the next time step\n",
    "            next_input = x_test_scaled[next_index].copy()\n",
    "        else:\n",
    "            # Reached the end of x_test_scaled\n",
    "            break\n",
    "\n",
    "        # Update lag features with available scaled predictions\n",
    "        for lag in range(1, min(step + 1, 6) + 1):\n",
    "            feature_index = 12 - lag  # lag1 is at index 11\n",
    "            next_input[feature_index, 0] = scaled_predictions[-lag]\n",
    "\n",
    "        # Keep lag24 and lag168 as they are, or update if necessary\n",
    "\n",
    "        # Set current_input for next iteration\n",
    "        current_input = next_input\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "id": "79gLJQDkdNBl"
   },
   "outputs": [],
   "source": [
    "# Number of steps to predict\n",
    "n_steps = 6\n",
    "\n",
    "# Initialize lists to store predictions and actual values\n",
    "all_predictions = []\n",
    "all_actuals = []\n",
    "\n",
    "# Ensure we have enough data for recursive predictions\n",
    "n_test_samples = x_test_scaled.shape[0]\n",
    "\n",
    "for i in range(n_test_samples - n_steps):\n",
    "    # Perform recursive forecasting\n",
    "    predictions = recursive_forecast(\n",
    "        model=best_model,\n",
    "        x_test_scaled=x_test_scaled,\n",
    "        start_index=i,\n",
    "        n_steps=n_steps,\n",
    "        x_scaler=x_scaler,\n",
    "        y_scaler=y_scaler\n",
    "    )\n",
    "\n",
    "    # Get the actual future values (in original scale)\n",
    "    actual_values = y_test[i+1:i + len(predictions) + 1].flatten()\n",
    "\n",
    "    # Store the predictions and actual values\n",
    "    all_predictions.append(predictions)\n",
    "    all_actuals.append(actual_values)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_actuals = np.array(all_actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ZsETMYQd3dV",
    "outputId": "18143da8-f0a3-4959-f135-8835e1f15a8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time Step 1 Evaluation Metrics:\n",
      "MAE: 26.1654\n",
      "RMSE: 34.5064\n",
      "MAPE: 24.57%\n",
      "\n",
      "Time Step 2 Evaluation Metrics:\n",
      "MAE: 29.2920\n",
      "RMSE: 38.6517\n",
      "MAPE: 27.01%\n",
      "\n",
      "Time Step 3 Evaluation Metrics:\n",
      "MAE: 31.9744\n",
      "RMSE: 42.0223\n",
      "MAPE: 29.37%\n",
      "\n",
      "Time Step 4 Evaluation Metrics:\n",
      "MAE: 33.7413\n",
      "RMSE: 44.1884\n",
      "MAPE: 30.70%\n",
      "\n",
      "Time Step 5 Evaluation Metrics:\n",
      "MAE: 35.4154\n",
      "RMSE: 46.1681\n",
      "MAPE: 31.94%\n",
      "\n",
      "Time Step 6 Evaluation Metrics:\n",
      "MAE: 36.4250\n",
      "RMSE: 47.3673\n",
      "MAPE: 32.52%\n"
     ]
    }
   ],
   "source": [
    "epsilon = 1e-10  # For MAPE calculation to avoid division by zero\n",
    "\n",
    "# Loop over each time step\n",
    "for i in range(n_steps):\n",
    "    y_true = all_actuals[:, i]\n",
    "    y_pred = all_predictions[:, i]\n",
    "\n",
    "    # Mean Absolute Error (MAE)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "    # Root Mean Squared Error (RMSE)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "    # Mean Absolute Percentage Error (MAPE)\n",
    "    y_true_safe = np.where(y_true == 0, epsilon, y_true)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true_safe)) * 100\n",
    "\n",
    "    print(f\"\\nTime Step {i+1} Evaluation Metrics:\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAPE: {mape:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0VK0LXrSeTVo"
   },
   "outputs": [],
   "source": [
    "step-by-step after covid"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
