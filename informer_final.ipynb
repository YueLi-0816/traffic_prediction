{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67f7f33-1987-4932-9803-883ede914b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/zhouhaoyi/Informer2020.git\n",
    "#!git clone https://github.com/zhouhaoyi/ETDataset.git\n",
    "# modify the code based on my dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e4301a-419a-40b0-98e8-eea762441e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !{sys.executable} -m pip install matplotlib\n",
    "# !{sys.executable} -m pip install pandas\n",
    "# !{sys.executable} -m pip install scikit_learn\n",
    "# !{sys.executable} -m pip install torch\n",
    "# !{sys.executable} -m pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb6cc0a2-7f97-4bc2-b439-c7b775a9cd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from argparse import Namespace\n",
    "import re\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    root_mean_squared_error,\n",
    "    mean_absolute_percentage_error\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60a07922-9f8e-44bb-825a-b576a86a90e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not 'Informer2020' in sys.path:\n",
    "    sys.path += ['Informer2020']\n",
    "\n",
    "from data.data_loader import Dataset_Custom\n",
    "from utils.metrics import metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd148590-d5a3-4a2b-afa4-77b77d84a671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cu128\n",
      "12.8\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6373961a-d2b9-4fbb-96a5-9ad2c3fbdc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 1\n",
      "GPU 0: NVIDIA A30\n"
     ]
    }
   ],
   "source": [
    "num_gpus = torch.cuda.device_count()\n",
    "print(\"Number of GPUs available:\", num_gpus)\n",
    "\n",
    "for i in range(num_gpus):\n",
    "    gpu_name = torch.cuda.get_device_name(i)\n",
    "    print(f\"GPU {i}: {gpu_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd1c08a-8be5-4e5c-a69c-b838fc3803d5",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d5eb9c8-e5e9-43e4-b287-564297d0b25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = pd.read_csv('../GD030A_S.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e02c837f-f057-48fc-ad77-aa5d7c99d36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the recover_timestamp function\n",
    "def recover_timestamp(data):\n",
    "    # Combine 'date' and 'time' to form a datetime column\n",
    "    data['datetime'] = pd.to_datetime(data['date'] + ' ' + data['time'].astype(str) + ':00', format='%Y-%m-%d %H:%M')\n",
    "\n",
    "    # Set 'datetime' as index\n",
    "    data = data.set_index('datetime')\n",
    "\n",
    "    # Create a complete range of timestamps with hourly frequency\n",
    "    full_time_range = pd.date_range(start=data.index.min(), end=data.index.max(), freq='H')\n",
    "\n",
    "    # Reindex the data to include all timestamps, filling missing rows with NaN\n",
    "    data_full = data.reindex(full_time_range)\n",
    "\n",
    "    return data_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fb2e9e-0912-4c8a-8ccd-bca7f1fc91d9",
   "metadata": {},
   "source": [
    "Custom data (xxx.csv) has to include at least 2 features: date(format: YYYY-MM-DD hh:mm:ss) and target feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fa5669-e577-40ea-9c59-6e998abacda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_full = recover_timestamp(my_data)\n",
    "traffic_full.drop(['date', 'time'], axis=1, inplace=True)\n",
    "traffic_full = traffic_full.reset_index(names='date')\n",
    "traffic_full['date'] = traffic_full['date'].astype(str)\n",
    "traffic_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e64353-3a50-4922-b0ae-81f1f592c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#traffic_full.to_csv('traffic_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d99f3419-cdc6-43b7-8dfd-ba258dc9d745",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# after covid data\n",
    "traffic_full = pd.read_csv('../traffic_full.csv')\n",
    "traffic_full\n",
    "traffic_after_covid = traffic_full.loc[traffic_full[traffic_full['date'] == '2022-06-03 00:00:00'].index[0]:]\n",
    "traffic_after_covid = traffic_after_covid.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2ebd29df-5d60-447f-8794-473986ee8a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#traffic_after_covid.to_csv('../traffic_after_covid.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04616932-2190-4b35-bceb-1bf11fa3e582",
   "metadata": {},
   "source": [
    "## Run training directly using bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6890335e-1970-46ea-a2f0-9f3a9fb4938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure the shell commands below using the current Python environment\n",
    "os.environ[\"PATH\"] = f\"{sys.prefix}/bin:\" + os.environ[\"PATH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adf9133b-3e63-4228-8340-98bc089bf852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/transformer/Informer2020\n"
     ]
    }
   ],
   "source": [
    "cd Informer2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05ce82bd-438d-4fec-b166-87b2984ae0f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test\n",
    "# !python -u main_informer.py --model informer --data traffic_after_covid --root_path ../ --features S --seq_len 24 --label_len 24 --pred_len 6 --e_layers 2 --d_layers 1 --attn prob --des 'Exp' --itr 1 #--inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "297f6900-cd2b-4569-8ef9-4b2e4dd2b144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24, 48, 72, 96, 120, 144, 168, 192, 216, 240, 264, 288, 312, 336, 360, 384, 408, 432, 456, 480, 504]\n"
     ]
    }
   ],
   "source": [
    "seq_lens = [24 * i for i in range(1, 22)]\n",
    "print(seq_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c204d504-9a4c-489b-9c24-c4cfe2d2e711",
   "metadata": {},
   "source": [
    "## rerun the code with updated label_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97623185-1858-4ecd-99d3-bb9f6ff19c6c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running seq_len=24\n",
      "Args in experiment:\n",
      "Namespace(model='informer', data='traffic_full', root_path='../', data_path='traffic_full.csv', features='S', target='flow', freq='h', checkpoints='./checkpoints/', seq_len=24, label_len=24, pred_len=6, enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=2, d_layers=1, s_layers=[3, 2, 1], d_ff=2048, factor=5, padding=0, distil=True, dropout=0.05, attn='prob', embed='timeF', activation='gelu', output_attention=False, do_predict=False, mix=True, cols=None, num_workers=0, itr=10, train_epochs=6, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, inverse=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', detail_freq='h')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24515\n",
      "[DEBUG] Original dataset length: 24515\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 23049\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3471\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.5087171\n",
      "\tspeed: 0.0341s/iter; left time: 143.8689s\n",
      "\titers: 200, epoch: 1 | loss: 0.2924829\n",
      "\tspeed: 0.0241s/iter; left time: 99.2028s\n",
      "\titers: 300, epoch: 1 | loss: 0.2128198\n",
      "\tspeed: 0.0236s/iter; left time: 95.0376s\n",
      "\titers: 400, epoch: 1 | loss: 0.2423227\n",
      "\tspeed: 0.0243s/iter; left time: 95.1359s\n",
      "\titers: 500, epoch: 1 | loss: 0.1456409\n",
      "\tspeed: 0.0222s/iter; left time: 84.6965s\n",
      "\titers: 600, epoch: 1 | loss: 0.2169240\n",
      "\tspeed: 0.0263s/iter; left time: 97.6984s\n",
      "\titers: 700, epoch: 1 | loss: 0.1754534\n",
      "\tspeed: 0.0220s/iter; left time: 79.6601s\n",
      "Epoch: 1 cost time: 17.29293417930603\n",
      "Epoch: 1, Steps: 720 | Train Loss: 0.2715616 Vali Loss: 0.3496845 Test Loss: 0.2752833\n",
      "Validation loss decreased (inf --> 0.349685).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2565038\n",
      "\tspeed: 0.0572s/iter; left time: 200.3111s\n",
      "\titers: 200, epoch: 2 | loss: 0.1470400\n",
      "\tspeed: 0.0240s/iter; left time: 81.5308s\n",
      "\titers: 300, epoch: 2 | loss: 0.1972954\n",
      "\tspeed: 0.0222s/iter; left time: 73.2054s\n",
      "\titers: 400, epoch: 2 | loss: 0.2398903\n",
      "\tspeed: 0.0263s/iter; left time: 84.1974s\n",
      "\titers: 500, epoch: 2 | loss: 0.1779394\n",
      "\tspeed: 0.0235s/iter; left time: 72.8122s\n",
      "\titers: 600, epoch: 2 | loss: 0.1817638\n",
      "\tspeed: 0.0235s/iter; left time: 70.6369s\n",
      "\titers: 700, epoch: 2 | loss: 0.1919735\n",
      "\tspeed: 0.0226s/iter; left time: 65.6352s\n",
      "Epoch: 2 cost time: 16.97560739517212\n",
      "Epoch: 2, Steps: 720 | Train Loss: 0.2118871 Vali Loss: 0.3276516 Test Loss: 0.2484862\n",
      "Validation loss decreased (0.349685 --> 0.327652).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1172348\n",
      "\tspeed: 0.0553s/iter; left time: 153.8786s\n",
      "\titers: 200, epoch: 3 | loss: 0.2515314\n",
      "\tspeed: 0.0220s/iter; left time: 58.9480s\n",
      "\titers: 300, epoch: 3 | loss: 0.2703438\n",
      "\tspeed: 0.0231s/iter; left time: 59.6129s\n",
      "\titers: 400, epoch: 3 | loss: 0.2363581\n",
      "\tspeed: 0.0228s/iter; left time: 56.5113s\n",
      "\titers: 500, epoch: 3 | loss: 0.2137282\n",
      "\tspeed: 0.0239s/iter; left time: 56.8561s\n",
      "\titers: 600, epoch: 3 | loss: 0.4114272\n",
      "\tspeed: 0.0245s/iter; left time: 55.8818s\n",
      "\titers: 700, epoch: 3 | loss: 0.1659668\n",
      "\tspeed: 0.0247s/iter; left time: 53.7709s\n",
      "Epoch: 3 cost time: 16.90793490409851\n",
      "Epoch: 3, Steps: 720 | Train Loss: 0.1870971 Vali Loss: 0.3257646 Test Loss: 0.2409789\n",
      "Validation loss decreased (0.327652 --> 0.325765).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0879828\n",
      "\tspeed: 0.0581s/iter; left time: 119.7336s\n",
      "\titers: 200, epoch: 4 | loss: 0.1431465\n",
      "\tspeed: 0.0228s/iter; left time: 44.7471s\n",
      "\titers: 300, epoch: 4 | loss: 0.1361479\n",
      "\tspeed: 0.0238s/iter; left time: 44.3729s\n",
      "\titers: 400, epoch: 4 | loss: 0.1462383\n",
      "\tspeed: 0.0223s/iter; left time: 39.3123s\n",
      "\titers: 500, epoch: 4 | loss: 0.1556001\n",
      "\tspeed: 0.0229s/iter; left time: 37.9951s\n",
      "\titers: 600, epoch: 4 | loss: 0.1562320\n",
      "\tspeed: 0.0245s/iter; left time: 38.2767s\n",
      "\titers: 700, epoch: 4 | loss: 0.1500027\n",
      "\tspeed: 0.0222s/iter; left time: 32.4283s\n",
      "Epoch: 4 cost time: 16.663687467575073\n",
      "Epoch: 4, Steps: 720 | Train Loss: 0.1722991 Vali Loss: 0.3180571 Test Loss: 0.2378705\n",
      "Validation loss decreased (0.325765 --> 0.318057).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1926964\n",
      "\tspeed: 0.0555s/iter; left time: 74.3926s\n",
      "\titers: 200, epoch: 5 | loss: 0.1673174\n",
      "\tspeed: 0.0225s/iter; left time: 27.9566s\n",
      "\titers: 300, epoch: 5 | loss: 0.1978714\n",
      "\tspeed: 0.0223s/iter; left time: 25.4341s\n",
      "\titers: 400, epoch: 5 | loss: 0.1349317\n",
      "\tspeed: 0.0220s/iter; left time: 22.8741s\n",
      "\titers: 500, epoch: 5 | loss: 0.1320693\n",
      "\tspeed: 0.0247s/iter; left time: 23.2258s\n",
      "\titers: 600, epoch: 5 | loss: 0.1040730\n",
      "\tspeed: 0.0229s/iter; left time: 19.2183s\n",
      "\titers: 700, epoch: 5 | loss: 0.1999601\n",
      "\tspeed: 0.0229s/iter; left time: 17.0013s\n",
      "Epoch: 5 cost time: 16.506165981292725\n",
      "Epoch: 5, Steps: 720 | Train Loss: 0.1636747 Vali Loss: 0.3183323 Test Loss: 0.2414027\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1471926\n",
      "\tspeed: 0.0539s/iter; left time: 33.4794s\n",
      "\titers: 200, epoch: 6 | loss: 0.1814853\n",
      "\tspeed: 0.0235s/iter; left time: 12.2299s\n",
      "\titers: 300, epoch: 6 | loss: 0.1218549\n",
      "\tspeed: 0.0265s/iter; left time: 11.1516s\n",
      "\titers: 400, epoch: 6 | loss: 0.1131911\n",
      "\tspeed: 0.0235s/iter; left time: 7.5513s\n",
      "\titers: 500, epoch: 6 | loss: 0.1738588\n",
      "\tspeed: 0.0231s/iter; left time: 5.1067s\n",
      "\titers: 600, epoch: 6 | loss: 0.1474309\n",
      "\tspeed: 0.0236s/iter; left time: 2.8557s\n",
      "\titers: 700, epoch: 6 | loss: 0.1403441\n",
      "\tspeed: 0.0243s/iter; left time: 0.5113s\n",
      "Epoch: 6 cost time: 17.193161725997925\n",
      "Epoch: 6, Steps: 720 | Train Loss: 0.1585589 Vali Loss: 0.3199352 Test Loss: 0.2386226\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "Test cost time: 1.8817s\n",
      "test shape: (198, 32, 6, 1) (198, 32, 6, 1)\n",
      "test shape: (6336, 6, 1) (6336, 6, 1)\n",
      "mse:0.2376120239496231, mae:0.3280346095561981\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1627.11376953125\n",
      "MAE:  27.14528465270996\n",
      "RMSE: 40.33749771118164\n",
      "MAPE: 0.3675115406513214\n",
      "MSPE: 0.6534509062767029\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24515\n",
      "[DEBUG] Original dataset length: 24515\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 23049\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3471\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.2865759\n",
      "\tspeed: 0.0236s/iter; left time: 99.7769s\n",
      "\titers: 200, epoch: 1 | loss: 0.3600346\n",
      "\tspeed: 0.0238s/iter; left time: 97.9845s\n",
      "\titers: 300, epoch: 1 | loss: 0.2039701\n",
      "\tspeed: 0.0237s/iter; left time: 95.1521s\n",
      "\titers: 400, epoch: 1 | loss: 0.3763814\n",
      "\tspeed: 0.0236s/iter; left time: 92.3728s\n",
      "\titers: 500, epoch: 1 | loss: 0.2703598\n",
      "\tspeed: 0.0236s/iter; left time: 90.0435s\n",
      "\titers: 600, epoch: 1 | loss: 0.3783150\n",
      "\tspeed: 0.0255s/iter; left time: 94.8344s\n",
      "\titers: 700, epoch: 1 | loss: 0.2756423\n",
      "\tspeed: 0.0236s/iter; left time: 85.2891s\n",
      "Epoch: 1 cost time: 17.170438766479492\n",
      "Epoch: 1, Steps: 720 | Train Loss: 0.2675003 Vali Loss: 0.3315566 Test Loss: 0.2526740\n",
      "Validation loss decreased (inf --> 0.331557).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1252775\n",
      "\tspeed: 0.0562s/iter; left time: 196.8064s\n",
      "\titers: 200, epoch: 2 | loss: 0.1523359\n",
      "\tspeed: 0.0234s/iter; left time: 79.6576s\n",
      "\titers: 300, epoch: 2 | loss: 0.1905691\n",
      "\tspeed: 0.0231s/iter; left time: 76.3832s\n",
      "\titers: 400, epoch: 2 | loss: 0.2672682\n",
      "\tspeed: 0.0261s/iter; left time: 83.6065s\n",
      "\titers: 500, epoch: 2 | loss: 0.2054070\n",
      "\tspeed: 0.0242s/iter; left time: 75.0744s\n",
      "\titers: 600, epoch: 2 | loss: 0.1443106\n",
      "\tspeed: 0.0244s/iter; left time: 73.3293s\n",
      "\titers: 700, epoch: 2 | loss: 0.1974154\n",
      "\tspeed: 0.0237s/iter; left time: 68.8963s\n",
      "Epoch: 2 cost time: 17.27440071105957\n",
      "Epoch: 2, Steps: 720 | Train Loss: 0.2120125 Vali Loss: 0.3197114 Test Loss: 0.2475138\n",
      "Validation loss decreased (0.331557 --> 0.319711).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1647746\n",
      "\tspeed: 0.0564s/iter; left time: 156.7232s\n",
      "\titers: 200, epoch: 3 | loss: 0.1546676\n",
      "\tspeed: 0.0243s/iter; left time: 65.2342s\n",
      "\titers: 300, epoch: 3 | loss: 0.3313934\n",
      "\tspeed: 0.0248s/iter; left time: 63.9427s\n",
      "\titers: 400, epoch: 3 | loss: 0.3056658\n",
      "\tspeed: 0.0234s/iter; left time: 58.0973s\n",
      "\titers: 500, epoch: 3 | loss: 0.1591436\n",
      "\tspeed: 0.0239s/iter; left time: 56.9790s\n",
      "\titers: 600, epoch: 3 | loss: 0.1645430\n",
      "\tspeed: 0.0232s/iter; left time: 52.9655s\n",
      "\titers: 700, epoch: 3 | loss: 0.1868242\n",
      "\tspeed: 0.0252s/iter; left time: 54.9011s\n",
      "Epoch: 3 cost time: 17.362776279449463\n",
      "Epoch: 3, Steps: 720 | Train Loss: 0.1876903 Vali Loss: 0.3170635 Test Loss: 0.2469709\n",
      "Validation loss decreased (0.319711 --> 0.317063).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1220028\n",
      "\tspeed: 0.0611s/iter; left time: 125.8416s\n",
      "\titers: 200, epoch: 4 | loss: 0.1805813\n",
      "\tspeed: 0.0244s/iter; left time: 47.9187s\n",
      "\titers: 300, epoch: 4 | loss: 0.2149364\n",
      "\tspeed: 0.0240s/iter; left time: 44.5997s\n",
      "\titers: 400, epoch: 4 | loss: 0.1268175\n",
      "\tspeed: 0.0239s/iter; left time: 42.0292s\n",
      "\titers: 500, epoch: 4 | loss: 0.1782756\n",
      "\tspeed: 0.0233s/iter; left time: 38.6561s\n",
      "\titers: 600, epoch: 4 | loss: 0.1206533\n",
      "\tspeed: 0.0234s/iter; left time: 36.4537s\n",
      "\titers: 700, epoch: 4 | loss: 0.1106179\n",
      "\tspeed: 0.0259s/iter; left time: 37.8287s\n",
      "Epoch: 4 cost time: 17.669017791748047\n",
      "Epoch: 4, Steps: 720 | Train Loss: 0.1737786 Vali Loss: 0.3060316 Test Loss: 0.2337235\n",
      "Validation loss decreased (0.317063 --> 0.306032).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1621804\n",
      "\tspeed: 0.0567s/iter; left time: 76.0390s\n",
      "\titers: 200, epoch: 5 | loss: 0.1920145\n",
      "\tspeed: 0.0230s/iter; left time: 28.5471s\n",
      "\titers: 300, epoch: 5 | loss: 0.1459103\n",
      "\tspeed: 0.0242s/iter; left time: 27.5705s\n",
      "\titers: 400, epoch: 5 | loss: 0.1800229\n",
      "\tspeed: 0.0230s/iter; left time: 23.8948s\n",
      "\titers: 500, epoch: 5 | loss: 0.1570787\n",
      "\tspeed: 0.0257s/iter; left time: 24.2246s\n",
      "\titers: 600, epoch: 5 | loss: 0.1529829\n",
      "\tspeed: 0.0243s/iter; left time: 20.4375s\n",
      "\titers: 700, epoch: 5 | loss: 0.1487933\n",
      "\tspeed: 0.0222s/iter; left time: 16.4661s\n",
      "Epoch: 5 cost time: 17.125006437301636\n",
      "Epoch: 5, Steps: 720 | Train Loss: 0.1657011 Vali Loss: 0.3056881 Test Loss: 0.2338295\n",
      "Validation loss decreased (0.306032 --> 0.305688).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1198038\n",
      "\tspeed: 0.0563s/iter; left time: 34.9792s\n",
      "\titers: 200, epoch: 6 | loss: 0.1056487\n",
      "\tspeed: 0.0257s/iter; left time: 13.3963s\n",
      "\titers: 300, epoch: 6 | loss: 0.3691839\n",
      "\tspeed: 0.0254s/iter; left time: 10.7092s\n",
      "\titers: 400, epoch: 6 | loss: 0.0901388\n",
      "\tspeed: 0.0236s/iter; left time: 7.5597s\n",
      "\titers: 500, epoch: 6 | loss: 0.1602312\n",
      "\tspeed: 0.0228s/iter; left time: 5.0383s\n",
      "\titers: 600, epoch: 6 | loss: 0.1277051\n",
      "\tspeed: 0.0240s/iter; left time: 2.9031s\n",
      "\titers: 700, epoch: 6 | loss: 0.1304263\n",
      "\tspeed: 0.0225s/iter; left time: 0.4720s\n",
      "Epoch: 6 cost time: 17.267051935195923\n",
      "Epoch: 6, Steps: 720 | Train Loss: 0.1614326 Vali Loss: 0.3104371 Test Loss: 0.2371754\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "Test cost time: 1.8827s\n",
      "test shape: (198, 32, 6, 1) (198, 32, 6, 1)\n",
      "test shape: (6336, 6, 1) (6336, 6, 1)\n",
      "mse:0.23437808454036713, mae:0.32244306802749634\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1604.968505859375\n",
      "MAE:  26.682580947875977\n",
      "RMSE: 40.06205749511719\n",
      "MAPE: 0.3333260416984558\n",
      "MSPE: 0.5486890077590942\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24515\n",
      "[DEBUG] Original dataset length: 24515\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 23049\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3471\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.2744650\n",
      "\tspeed: 0.0257s/iter; left time: 108.6816s\n",
      "\titers: 200, epoch: 1 | loss: 0.2896386\n",
      "\tspeed: 0.0222s/iter; left time: 91.6704s\n",
      "\titers: 300, epoch: 1 | loss: 0.1667687\n",
      "\tspeed: 0.0242s/iter; left time: 97.4852s\n",
      "\titers: 400, epoch: 1 | loss: 0.2906582\n",
      "\tspeed: 0.0232s/iter; left time: 90.8604s\n",
      "\titers: 500, epoch: 1 | loss: 0.2721714\n",
      "\tspeed: 0.0235s/iter; left time: 89.8949s\n",
      "\titers: 600, epoch: 1 | loss: 0.3078634\n",
      "\tspeed: 0.0244s/iter; left time: 90.6703s\n",
      "\titers: 700, epoch: 1 | loss: 0.1628935\n",
      "\tspeed: 0.0234s/iter; left time: 84.8593s\n",
      "Epoch: 1 cost time: 17.19787073135376\n",
      "Epoch: 1, Steps: 720 | Train Loss: 0.2719501 Vali Loss: 0.3297973 Test Loss: 0.2573735\n",
      "Validation loss decreased (inf --> 0.329797).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3001851\n",
      "\tspeed: 0.0548s/iter; left time: 191.9943s\n",
      "\titers: 200, epoch: 2 | loss: 0.2518544\n",
      "\tspeed: 0.0238s/iter; left time: 80.8378s\n",
      "\titers: 300, epoch: 2 | loss: 0.1061586\n",
      "\tspeed: 0.0245s/iter; left time: 80.9013s\n",
      "\titers: 400, epoch: 2 | loss: 0.1308330\n",
      "\tspeed: 0.0264s/iter; left time: 84.5648s\n",
      "\titers: 500, epoch: 2 | loss: 0.1324591\n",
      "\tspeed: 0.0236s/iter; left time: 73.1132s\n",
      "\titers: 600, epoch: 2 | loss: 0.1751156\n",
      "\tspeed: 0.0234s/iter; left time: 70.1532s\n",
      "\titers: 700, epoch: 2 | loss: 0.1699983\n",
      "\tspeed: 0.0233s/iter; left time: 67.6783s\n",
      "Epoch: 2 cost time: 17.326830863952637\n",
      "Epoch: 2, Steps: 720 | Train Loss: 0.2163521 Vali Loss: 0.3210734 Test Loss: 0.2566946\n",
      "Validation loss decreased (0.329797 --> 0.321073).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1544362\n",
      "\tspeed: 0.0565s/iter; left time: 157.0100s\n",
      "\titers: 200, epoch: 3 | loss: 0.1541156\n",
      "\tspeed: 0.0259s/iter; left time: 69.3319s\n",
      "\titers: 300, epoch: 3 | loss: 0.2368840\n",
      "\tspeed: 0.0235s/iter; left time: 60.7802s\n",
      "\titers: 400, epoch: 3 | loss: 0.2679690\n",
      "\tspeed: 0.0236s/iter; left time: 58.5740s\n",
      "\titers: 500, epoch: 3 | loss: 0.2408451\n",
      "\tspeed: 0.0224s/iter; left time: 53.3475s\n",
      "\titers: 600, epoch: 3 | loss: 0.2103211\n",
      "\tspeed: 0.0238s/iter; left time: 54.2424s\n",
      "\titers: 700, epoch: 3 | loss: 0.1659282\n",
      "\tspeed: 0.0238s/iter; left time: 51.9129s\n",
      "Epoch: 3 cost time: 17.151901721954346\n",
      "Epoch: 3, Steps: 720 | Train Loss: 0.1884750 Vali Loss: 0.3357567 Test Loss: 0.2538561\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2896501\n",
      "\tspeed: 0.0584s/iter; left time: 120.3813s\n",
      "\titers: 200, epoch: 4 | loss: 0.1649207\n",
      "\tspeed: 0.0226s/iter; left time: 44.2827s\n",
      "\titers: 300, epoch: 4 | loss: 0.2061916\n",
      "\tspeed: 0.0237s/iter; left time: 44.0484s\n",
      "\titers: 400, epoch: 4 | loss: 0.1754446\n",
      "\tspeed: 0.0221s/iter; left time: 38.9405s\n",
      "\titers: 500, epoch: 4 | loss: 0.1536574\n",
      "\tspeed: 0.0230s/iter; left time: 38.1721s\n",
      "\titers: 600, epoch: 4 | loss: 0.1597869\n",
      "\tspeed: 0.0237s/iter; left time: 37.0185s\n",
      "\titers: 700, epoch: 4 | loss: 0.1866713\n",
      "\tspeed: 0.0237s/iter; left time: 34.5633s\n",
      "Epoch: 4 cost time: 16.87447237968445\n",
      "Epoch: 4, Steps: 720 | Train Loss: 0.1751381 Vali Loss: 0.3102418 Test Loss: 0.2352545\n",
      "Validation loss decreased (0.321073 --> 0.310242).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2251854\n",
      "\tspeed: 0.0541s/iter; left time: 72.5179s\n",
      "\titers: 200, epoch: 5 | loss: 0.1805743\n",
      "\tspeed: 0.0225s/iter; left time: 27.9402s\n",
      "\titers: 300, epoch: 5 | loss: 0.1773625\n",
      "\tspeed: 0.0221s/iter; left time: 25.2044s\n",
      "\titers: 400, epoch: 5 | loss: 0.1136182\n",
      "\tspeed: 0.0238s/iter; left time: 24.7791s\n",
      "\titers: 500, epoch: 5 | loss: 0.1537762\n",
      "\tspeed: 0.0280s/iter; left time: 26.3667s\n",
      "\titers: 600, epoch: 5 | loss: 0.1588420\n",
      "\tspeed: 0.0231s/iter; left time: 19.4282s\n",
      "\titers: 700, epoch: 5 | loss: 0.2164289\n",
      "\tspeed: 0.0236s/iter; left time: 17.4630s\n",
      "Epoch: 5 cost time: 17.08813762664795\n",
      "Epoch: 5, Steps: 720 | Train Loss: 0.1664495 Vali Loss: 0.3087876 Test Loss: 0.2400967\n",
      "Validation loss decreased (0.310242 --> 0.308788).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1690407\n",
      "\tspeed: 0.0564s/iter; left time: 35.0524s\n",
      "\titers: 200, epoch: 6 | loss: 0.1302037\n",
      "\tspeed: 0.0246s/iter; left time: 12.8142s\n",
      "\titers: 300, epoch: 6 | loss: 0.1850041\n",
      "\tspeed: 0.0244s/iter; left time: 10.2554s\n",
      "\titers: 400, epoch: 6 | loss: 0.1728292\n",
      "\tspeed: 0.0228s/iter; left time: 7.3201s\n",
      "\titers: 500, epoch: 6 | loss: 0.1521309\n",
      "\tspeed: 0.0225s/iter; left time: 4.9637s\n",
      "\titers: 600, epoch: 6 | loss: 0.1067053\n",
      "\tspeed: 0.0235s/iter; left time: 2.8461s\n",
      "\titers: 700, epoch: 6 | loss: 0.1677564\n",
      "\tspeed: 0.0238s/iter; left time: 0.5004s\n",
      "Epoch: 6 cost time: 17.090779304504395\n",
      "Epoch: 6, Steps: 720 | Train Loss: 0.1624983 Vali Loss: 0.3019986 Test Loss: 0.2360453\n",
      "Validation loss decreased (0.308788 --> 0.301999).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "Test cost time: 1.8895s\n",
      "test shape: (198, 32, 6, 1) (198, 32, 6, 1)\n",
      "test shape: (6336, 6, 1) (6336, 6, 1)\n",
      "mse:0.2356889843940735, mae:0.3247763514518738\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1613.945068359375\n",
      "MAE:  26.875661849975586\n",
      "RMSE: 40.17393493652344\n",
      "MAPE: 0.3408617675304413\n",
      "MSPE: 0.5721623301506042\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24515\n",
      "[DEBUG] Original dataset length: 24515\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 23049\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3471\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.2650527\n",
      "\tspeed: 0.0239s/iter; left time: 100.8915s\n",
      "\titers: 200, epoch: 1 | loss: 0.2219979\n",
      "\tspeed: 0.0229s/iter; left time: 94.5158s\n",
      "\titers: 300, epoch: 1 | loss: 0.2025732\n",
      "\tspeed: 0.0231s/iter; left time: 92.9999s\n",
      "\titers: 400, epoch: 1 | loss: 0.2251877\n",
      "\tspeed: 0.0237s/iter; left time: 93.0771s\n",
      "\titers: 500, epoch: 1 | loss: 0.2039747\n",
      "\tspeed: 0.0226s/iter; left time: 86.3022s\n",
      "\titers: 600, epoch: 1 | loss: 0.3058737\n",
      "\tspeed: 0.0263s/iter; left time: 98.0357s\n",
      "\titers: 700, epoch: 1 | loss: 0.3038377\n",
      "\tspeed: 0.0233s/iter; left time: 84.4925s\n",
      "Epoch: 1 cost time: 17.09080934524536\n",
      "Epoch: 1, Steps: 720 | Train Loss: 0.2718620 Vali Loss: 0.3364227 Test Loss: 0.2603308\n",
      "Validation loss decreased (inf --> 0.336423).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3192947\n",
      "\tspeed: 0.0578s/iter; left time: 202.5318s\n",
      "\titers: 200, epoch: 2 | loss: 0.3446273\n",
      "\tspeed: 0.0239s/iter; left time: 81.3909s\n",
      "\titers: 300, epoch: 2 | loss: 0.2148699\n",
      "\tspeed: 0.0236s/iter; left time: 77.8234s\n",
      "\titers: 400, epoch: 2 | loss: 0.1366628\n",
      "\tspeed: 0.0257s/iter; left time: 82.2395s\n",
      "\titers: 500, epoch: 2 | loss: 0.1799138\n",
      "\tspeed: 0.0229s/iter; left time: 70.9257s\n",
      "\titers: 600, epoch: 2 | loss: 0.1781433\n",
      "\tspeed: 0.0233s/iter; left time: 70.0401s\n",
      "\titers: 700, epoch: 2 | loss: 0.2341565\n",
      "\tspeed: 0.0255s/iter; left time: 73.9521s\n",
      "Epoch: 2 cost time: 17.30075454711914\n",
      "Epoch: 2, Steps: 720 | Train Loss: 0.2106485 Vali Loss: 0.3270538 Test Loss: 0.2547030\n",
      "Validation loss decreased (0.336423 --> 0.327054).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1174722\n",
      "\tspeed: 0.0598s/iter; left time: 166.1896s\n",
      "\titers: 200, epoch: 3 | loss: 0.1492120\n",
      "\tspeed: 0.0251s/iter; left time: 67.2539s\n",
      "\titers: 300, epoch: 3 | loss: 0.1613349\n",
      "\tspeed: 0.0220s/iter; left time: 56.8117s\n",
      "\titers: 400, epoch: 3 | loss: 0.1661272\n",
      "\tspeed: 0.0229s/iter; left time: 56.9226s\n",
      "\titers: 500, epoch: 3 | loss: 0.1898852\n",
      "\tspeed: 0.0231s/iter; left time: 54.9675s\n",
      "\titers: 600, epoch: 3 | loss: 0.1583087\n",
      "\tspeed: 0.0246s/iter; left time: 56.0503s\n",
      "\titers: 700, epoch: 3 | loss: 0.1923200\n",
      "\tspeed: 0.0244s/iter; left time: 53.2403s\n",
      "Epoch: 3 cost time: 17.232905864715576\n",
      "Epoch: 3, Steps: 720 | Train Loss: 0.1881493 Vali Loss: 0.3286547 Test Loss: 0.2491727\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1887914\n",
      "\tspeed: 0.0526s/iter; left time: 108.5047s\n",
      "\titers: 200, epoch: 4 | loss: 0.1533822\n",
      "\tspeed: 0.0213s/iter; left time: 41.8435s\n",
      "\titers: 300, epoch: 4 | loss: 0.2594321\n",
      "\tspeed: 0.0235s/iter; left time: 43.6740s\n",
      "\titers: 400, epoch: 4 | loss: 0.1869736\n",
      "\tspeed: 0.0240s/iter; left time: 42.3321s\n",
      "\titers: 500, epoch: 4 | loss: 0.1373258\n",
      "\tspeed: 0.0244s/iter; left time: 40.4907s\n",
      "\titers: 600, epoch: 4 | loss: 0.1089822\n",
      "\tspeed: 0.0252s/iter; left time: 39.4098s\n",
      "\titers: 700, epoch: 4 | loss: 0.1608785\n",
      "\tspeed: 0.0238s/iter; left time: 34.7855s\n",
      "Epoch: 4 cost time: 16.706403493881226\n",
      "Epoch: 4, Steps: 720 | Train Loss: 0.1730316 Vali Loss: 0.3165959 Test Loss: 0.2357844\n",
      "Validation loss decreased (0.327054 --> 0.316596).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1621994\n",
      "\tspeed: 0.0555s/iter; left time: 74.4800s\n",
      "\titers: 200, epoch: 5 | loss: 0.1842579\n",
      "\tspeed: 0.0226s/iter; left time: 28.0036s\n",
      "\titers: 300, epoch: 5 | loss: 0.1382771\n",
      "\tspeed: 0.0242s/iter; left time: 27.6334s\n",
      "\titers: 400, epoch: 5 | loss: 0.1971953\n",
      "\tspeed: 0.0259s/iter; left time: 26.9555s\n",
      "\titers: 500, epoch: 5 | loss: 0.1952503\n",
      "\tspeed: 0.0228s/iter; left time: 21.4133s\n",
      "\titers: 600, epoch: 5 | loss: 0.2498008\n",
      "\tspeed: 0.0235s/iter; left time: 19.7881s\n",
      "\titers: 700, epoch: 5 | loss: 0.1059090\n",
      "\tspeed: 0.0229s/iter; left time: 16.9371s\n",
      "Epoch: 5 cost time: 17.073793411254883\n",
      "Epoch: 5, Steps: 720 | Train Loss: 0.1649060 Vali Loss: 0.3213950 Test Loss: 0.2349425\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2616539\n",
      "\tspeed: 0.0557s/iter; left time: 34.6114s\n",
      "\titers: 200, epoch: 6 | loss: 0.1339238\n",
      "\tspeed: 0.0258s/iter; left time: 13.4249s\n",
      "\titers: 300, epoch: 6 | loss: 0.1539618\n",
      "\tspeed: 0.0246s/iter; left time: 10.3710s\n",
      "\titers: 400, epoch: 6 | loss: 0.1656114\n",
      "\tspeed: 0.0238s/iter; left time: 7.6308s\n",
      "\titers: 500, epoch: 6 | loss: 0.1363162\n",
      "\tspeed: 0.0231s/iter; left time: 5.1014s\n",
      "\titers: 600, epoch: 6 | loss: 0.1754659\n",
      "\tspeed: 0.0254s/iter; left time: 3.0771s\n",
      "\titers: 700, epoch: 6 | loss: 0.0997948\n",
      "\tspeed: 0.0240s/iter; left time: 0.5032s\n",
      "Epoch: 6 cost time: 17.539247035980225\n",
      "Epoch: 6, Steps: 720 | Train Loss: 0.1606391 Vali Loss: 0.3143761 Test Loss: 0.2341927\n",
      "Validation loss decreased (0.316596 --> 0.314376).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "Test cost time: 1.7630s\n",
      "test shape: (198, 32, 6, 1) (198, 32, 6, 1)\n",
      "test shape: (6336, 6, 1) (6336, 6, 1)\n",
      "mse:0.2336292415857315, mae:0.3213922381401062\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1599.840576171875\n",
      "MAE:  26.595619201660156\n",
      "RMSE: 39.998008728027344\n",
      "MAPE: 0.32498419284820557\n",
      "MSPE: 0.4747970402240753\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24515\n",
      "[DEBUG] Original dataset length: 24515\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 23049\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3471\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.5527468\n",
      "\tspeed: 0.0273s/iter; left time: 115.3552s\n",
      "\titers: 200, epoch: 1 | loss: 0.3311287\n",
      "\tspeed: 0.0245s/iter; left time: 100.8024s\n",
      "\titers: 300, epoch: 1 | loss: 0.2049724\n",
      "\tspeed: 0.0248s/iter; left time: 99.6629s\n",
      "\titers: 400, epoch: 1 | loss: 0.3211198\n",
      "\tspeed: 0.0234s/iter; left time: 91.7675s\n",
      "\titers: 500, epoch: 1 | loss: 0.1992905\n",
      "\tspeed: 0.0263s/iter; left time: 100.4708s\n",
      "\titers: 600, epoch: 1 | loss: 0.2566380\n",
      "\tspeed: 0.0230s/iter; left time: 85.6767s\n",
      "\titers: 700, epoch: 1 | loss: 0.2303926\n",
      "\tspeed: 0.0226s/iter; left time: 81.6786s\n",
      "Epoch: 1 cost time: 17.638620853424072\n",
      "Epoch: 1, Steps: 720 | Train Loss: 0.2682772 Vali Loss: 0.3367246 Test Loss: 0.2646706\n",
      "Validation loss decreased (inf --> 0.336725).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1566275\n",
      "\tspeed: 0.0545s/iter; left time: 190.6684s\n",
      "\titers: 200, epoch: 2 | loss: 0.1531208\n",
      "\tspeed: 0.0231s/iter; left time: 78.7137s\n",
      "\titers: 300, epoch: 2 | loss: 0.2799466\n",
      "\tspeed: 0.0255s/iter; left time: 84.1659s\n",
      "\titers: 400, epoch: 2 | loss: 0.1289977\n",
      "\tspeed: 0.0229s/iter; left time: 73.2419s\n",
      "\titers: 500, epoch: 2 | loss: 0.1932125\n",
      "\tspeed: 0.0231s/iter; left time: 71.7581s\n",
      "\titers: 600, epoch: 2 | loss: 0.2274318\n",
      "\tspeed: 0.0243s/iter; left time: 72.9586s\n",
      "\titers: 700, epoch: 2 | loss: 0.1344557\n",
      "\tspeed: 0.0241s/iter; left time: 69.8268s\n",
      "Epoch: 2 cost time: 17.0900559425354\n",
      "Epoch: 2, Steps: 720 | Train Loss: 0.2138353 Vali Loss: 0.3882794 Test Loss: 0.3128722\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1562793\n",
      "\tspeed: 0.0572s/iter; left time: 159.0634s\n",
      "\titers: 200, epoch: 3 | loss: 0.1347074\n",
      "\tspeed: 0.0240s/iter; left time: 64.4192s\n",
      "\titers: 300, epoch: 3 | loss: 0.2022909\n",
      "\tspeed: 0.0232s/iter; left time: 59.9630s\n",
      "\titers: 400, epoch: 3 | loss: 0.1361892\n",
      "\tspeed: 0.0228s/iter; left time: 56.4432s\n",
      "\titers: 500, epoch: 3 | loss: 0.1614300\n",
      "\tspeed: 0.0244s/iter; left time: 58.2054s\n",
      "\titers: 600, epoch: 3 | loss: 0.2304744\n",
      "\tspeed: 0.0233s/iter; left time: 53.1492s\n",
      "\titers: 700, epoch: 3 | loss: 0.1427994\n",
      "\tspeed: 0.0242s/iter; left time: 52.8613s\n",
      "Epoch: 3 cost time: 17.334230184555054\n",
      "Epoch: 3, Steps: 720 | Train Loss: 0.1861552 Vali Loss: 0.3251782 Test Loss: 0.2577867\n",
      "Validation loss decreased (0.336725 --> 0.325178).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2071881\n",
      "\tspeed: 0.0561s/iter; left time: 115.6852s\n",
      "\titers: 200, epoch: 4 | loss: 0.2575551\n",
      "\tspeed: 0.0238s/iter; left time: 46.6454s\n",
      "\titers: 300, epoch: 4 | loss: 0.1590323\n",
      "\tspeed: 0.0234s/iter; left time: 43.4992s\n",
      "\titers: 400, epoch: 4 | loss: 0.2344529\n",
      "\tspeed: 0.0241s/iter; left time: 42.3898s\n",
      "\titers: 500, epoch: 4 | loss: 0.1380359\n",
      "\tspeed: 0.0248s/iter; left time: 41.2331s\n",
      "\titers: 600, epoch: 4 | loss: 0.1637898\n",
      "\tspeed: 0.0251s/iter; left time: 39.1088s\n",
      "\titers: 700, epoch: 4 | loss: 0.1887952\n",
      "\tspeed: 0.0234s/iter; left time: 34.2184s\n",
      "Epoch: 4 cost time: 17.278543949127197\n",
      "Epoch: 4, Steps: 720 | Train Loss: 0.1725929 Vali Loss: 0.3219385 Test Loss: 0.2412459\n",
      "Validation loss decreased (0.325178 --> 0.321939).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2666981\n",
      "\tspeed: 0.0553s/iter; left time: 74.1070s\n",
      "\titers: 200, epoch: 5 | loss: 0.2087873\n",
      "\tspeed: 0.0233s/iter; left time: 28.9714s\n",
      "\titers: 300, epoch: 5 | loss: 0.1229014\n",
      "\tspeed: 0.0242s/iter; left time: 27.6303s\n",
      "\titers: 400, epoch: 5 | loss: 0.2954988\n",
      "\tspeed: 0.0260s/iter; left time: 27.0799s\n",
      "\titers: 500, epoch: 5 | loss: 0.1447592\n",
      "\tspeed: 0.0240s/iter; left time: 22.5647s\n",
      "\titers: 600, epoch: 5 | loss: 0.1152863\n",
      "\tspeed: 0.0237s/iter; left time: 19.8998s\n",
      "\titers: 700, epoch: 5 | loss: 0.1453368\n",
      "\tspeed: 0.0284s/iter; left time: 21.0112s\n",
      "Epoch: 5 cost time: 17.706292152404785\n",
      "Epoch: 5, Steps: 720 | Train Loss: 0.1634190 Vali Loss: 0.3107994 Test Loss: 0.2360738\n",
      "Validation loss decreased (0.321939 --> 0.310799).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2448484\n",
      "\tspeed: 0.0588s/iter; left time: 36.4903s\n",
      "\titers: 200, epoch: 6 | loss: 0.2627458\n",
      "\tspeed: 0.0238s/iter; left time: 12.3848s\n",
      "\titers: 300, epoch: 6 | loss: 0.1049539\n",
      "\tspeed: 0.0248s/iter; left time: 10.4351s\n",
      "\titers: 400, epoch: 6 | loss: 0.1866700\n",
      "\tspeed: 0.0239s/iter; left time: 7.6563s\n",
      "\titers: 500, epoch: 6 | loss: 0.1325213\n",
      "\tspeed: 0.0238s/iter; left time: 5.2701s\n",
      "\titers: 600, epoch: 6 | loss: 0.1152547\n",
      "\tspeed: 0.0238s/iter; left time: 2.8784s\n",
      "\titers: 300, epoch: 6 | loss: 0.1056100\n",
      "\tspeed: 0.0241s/iter; left time: 10.1512s\n",
      "\titers: 400, epoch: 6 | loss: 0.1469253\n",
      "\tspeed: 0.0226s/iter; left time: 7.2405s\n",
      "\titers: 500, epoch: 6 | loss: 0.1085294\n",
      "\tspeed: 0.0245s/iter; left time: 5.4175s\n",
      "\titers: 600, epoch: 6 | loss: 0.1695757\n",
      "\tspeed: 0.0226s/iter; left time: 2.7358s\n",
      "\titers: 700, epoch: 6 | loss: 0.0930622\n",
      "\tspeed: 0.0235s/iter; left time: 0.4925s\n",
      "Epoch: 6 cost time: 17.251235723495483\n",
      "Epoch: 6, Steps: 720 | Train Loss: 0.1611039 Vali Loss: 0.3092542 Test Loss: 0.2373717\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "Test cost time: 1.7897s\n",
      "test shape: (198, 32, 6, 1) (198, 32, 6, 1)\n",
      "test shape: (6336, 6, 1) (6336, 6, 1)\n",
      "mse:0.2303667962551117, mae:0.32790979743003845\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1577.5\n",
      "MAE:  27.13495635986328\n",
      "RMSE: 39.71775436401367\n",
      "MAPE: 0.3835509717464447\n",
      "MSPE: 0.7522261738777161\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24515\n",
      "[DEBUG] Original dataset length: 24515\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 23049\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3471\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.2623928\n",
      "\tspeed: 0.0241s/iter; left time: 101.8891s\n",
      "\titers: 200, epoch: 1 | loss: 0.2864740\n",
      "\tspeed: 0.0227s/iter; left time: 93.5551s\n",
      "\titers: 300, epoch: 1 | loss: 0.2192387\n",
      "\tspeed: 0.0221s/iter; left time: 88.9559s\n",
      "\titers: 400, epoch: 1 | loss: 0.1847513\n",
      "\tspeed: 0.0227s/iter; left time: 88.9984s\n",
      "\titers: 500, epoch: 1 | loss: 0.2801117\n",
      "\tspeed: 0.0251s/iter; left time: 95.7606s\n",
      "\titers: 600, epoch: 1 | loss: 0.2317281\n",
      "\tspeed: 0.0233s/iter; left time: 86.5145s\n",
      "\titers: 700, epoch: 1 | loss: 0.1556594\n",
      "\tspeed: 0.0220s/iter; left time: 79.5060s\n",
      "Epoch: 1 cost time: 16.603269815444946\n",
      "Epoch: 1, Steps: 720 | Train Loss: 0.2711262 Vali Loss: 0.3246966 Test Loss: 0.2513530\n",
      "Validation loss decreased (inf --> 0.324697).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1855732\n",
      "\tspeed: 0.0535s/iter; left time: 187.2394s\n",
      "\titers: 200, epoch: 2 | loss: 0.3065771\n",
      "\tspeed: 0.0225s/iter; left time: 76.3924s\n",
      "\titers: 300, epoch: 2 | loss: 0.1691128\n",
      "\tspeed: 0.0254s/iter; left time: 83.9270s\n",
      "\titers: 400, epoch: 2 | loss: 0.1108337\n",
      "\tspeed: 0.0248s/iter; left time: 79.2890s\n",
      "\titers: 500, epoch: 2 | loss: 0.2266400\n",
      "\tspeed: 0.0247s/iter; left time: 76.4562s\n",
      "\titers: 600, epoch: 2 | loss: 0.2419759\n",
      "\tspeed: 0.0236s/iter; left time: 70.7452s\n",
      "\titers: 700, epoch: 2 | loss: 0.1529615\n",
      "\tspeed: 0.0231s/iter; left time: 66.8967s\n",
      "Epoch: 2 cost time: 17.08172059059143\n",
      "Epoch: 2, Steps: 720 | Train Loss: 0.2130737 Vali Loss: 0.3353275 Test Loss: 0.2646066\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1763416\n",
      "\tspeed: 0.0583s/iter; left time: 162.0179s\n",
      "\titers: 200, epoch: 3 | loss: 0.1129971\n",
      "\tspeed: 0.0260s/iter; left time: 69.8190s\n",
      "\titers: 300, epoch: 3 | loss: 0.1638777\n",
      "\tspeed: 0.0243s/iter; left time: 62.8087s\n",
      "\titers: 400, epoch: 3 | loss: 0.2111806\n",
      "\tspeed: 0.0250s/iter; left time: 62.0663s\n",
      "\titers: 500, epoch: 3 | loss: 0.1769844\n",
      "\tspeed: 0.0259s/iter; left time: 61.5706s\n",
      "\titers: 600, epoch: 3 | loss: 0.2558082\n",
      "\tspeed: 0.0250s/iter; left time: 57.0643s\n",
      "\titers: 700, epoch: 3 | loss: 0.1396273\n",
      "\tspeed: 0.0286s/iter; left time: 62.4221s\n",
      "Epoch: 3 cost time: 18.6716570854187\n",
      "Epoch: 3, Steps: 720 | Train Loss: 0.1892953 Vali Loss: 0.3130230 Test Loss: 0.2433610\n",
      "Validation loss decreased (0.324697 --> 0.313023).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1437805\n",
      "\tspeed: 0.0614s/iter; left time: 126.4934s\n",
      "\titers: 200, epoch: 4 | loss: 0.1527761\n",
      "\tspeed: 0.0251s/iter; left time: 49.3085s\n",
      "\titers: 300, epoch: 4 | loss: 0.3058494\n",
      "\tspeed: 0.0262s/iter; left time: 48.7487s\n",
      "\titers: 400, epoch: 4 | loss: 0.1736861\n",
      "\tspeed: 0.0267s/iter; left time: 46.9396s\n",
      "\titers: 500, epoch: 4 | loss: 0.1563891\n",
      "\tspeed: 0.0281s/iter; left time: 46.7170s\n",
      "\titers: 600, epoch: 4 | loss: 0.1766855\n",
      "\tspeed: 0.0252s/iter; left time: 39.3473s\n",
      "\titers: 700, epoch: 4 | loss: 0.1883417\n",
      "\tspeed: 0.0232s/iter; left time: 33.8954s\n",
      "Epoch: 4 cost time: 18.528445959091187\n",
      "Epoch: 4, Steps: 720 | Train Loss: 0.1740954 Vali Loss: 0.3204594 Test Loss: 0.2483284\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1350636\n",
      "\tspeed: 0.0539s/iter; left time: 72.2764s\n",
      "\titers: 200, epoch: 5 | loss: 0.1391133\n",
      "\tspeed: 0.0251s/iter; left time: 31.1405s\n",
      "\titers: 300, epoch: 5 | loss: 0.1425400\n",
      "\tspeed: 0.0234s/iter; left time: 26.6940s\n",
      "\titers: 400, epoch: 5 | loss: 0.2509716\n",
      "\tspeed: 0.0229s/iter; left time: 23.8695s\n",
      "\titers: 500, epoch: 5 | loss: 0.2204332\n",
      "\tspeed: 0.0248s/iter; left time: 23.3225s\n",
      "\titers: 600, epoch: 5 | loss: 0.1883734\n",
      "\tspeed: 0.0236s/iter; left time: 19.8496s\n",
      "\titers: 700, epoch: 5 | loss: 0.1775103\n",
      "\tspeed: 0.0239s/iter; left time: 17.6845s\n",
      "Epoch: 5 cost time: 17.218992948532104\n",
      "Epoch: 5, Steps: 720 | Train Loss: 0.1655226 Vali Loss: 0.3101983 Test Loss: 0.2417996\n",
      "Validation loss decreased (0.313023 --> 0.310198).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1783492\n",
      "\tspeed: 0.0561s/iter; left time: 34.8252s\n",
      "\titers: 200, epoch: 6 | loss: 0.1266442\n",
      "\tspeed: 0.0235s/iter; left time: 12.2436s\n",
      "\titers: 300, epoch: 6 | loss: 0.1495442\n",
      "\tspeed: 0.0228s/iter; left time: 9.6018s\n",
      "\titers: 400, epoch: 6 | loss: 0.3149518\n",
      "\tspeed: 0.0235s/iter; left time: 7.5396s\n",
      "\titers: 500, epoch: 6 | loss: 0.1058590\n",
      "\tspeed: 0.0236s/iter; left time: 5.2141s\n",
      "\titers: 600, epoch: 6 | loss: 0.1137586\n",
      "\tspeed: 0.0234s/iter; left time: 2.8299s\n",
      "\titers: 700, epoch: 6 | loss: 0.1570315\n",
      "\tspeed: 0.0260s/iter; left time: 0.5465s\n",
      "Epoch: 6 cost time: 17.030725240707397\n",
      "Epoch: 6, Steps: 720 | Train Loss: 0.1605665 Vali Loss: 0.3124329 Test Loss: 0.2401771\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "Test cost time: 1.6797s\n",
      "test shape: (198, 32, 6, 1) (198, 32, 6, 1)\n",
      "test shape: (6336, 6, 1) (6336, 6, 1)\n",
      "mse:0.24249285459518433, mae:0.3238699436187744\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1660.536865234375\n",
      "MAE:  26.8006534576416\n",
      "RMSE: 40.74968719482422\n",
      "MAPE: 0.313726007938385\n",
      "MSPE: 0.43038856983184814\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24515\n",
      "[DEBUG] Original dataset length: 24515\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 23049\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3471\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.3414311\n",
      "\tspeed: 0.0219s/iter; left time: 92.4278s\n",
      "\titers: 200, epoch: 1 | loss: 0.1899702\n",
      "\tspeed: 0.0227s/iter; left time: 93.7322s\n",
      "\titers: 300, epoch: 1 | loss: 0.2339462\n",
      "\tspeed: 0.0226s/iter; left time: 90.7795s\n",
      "\titers: 400, epoch: 1 | loss: 0.2228068\n",
      "\tspeed: 0.0253s/iter; left time: 99.3953s\n",
      "\titers: 500, epoch: 1 | loss: 0.1567868\n",
      "\tspeed: 0.0244s/iter; left time: 93.1369s\n",
      "\titers: 600, epoch: 1 | loss: 0.2777991\n",
      "\tspeed: 0.0235s/iter; left time: 87.4861s\n",
      "\titers: 700, epoch: 1 | loss: 0.1768854\n",
      "\tspeed: 0.0217s/iter; left time: 78.5222s\n",
      "Epoch: 1 cost time: 16.676010847091675\n",
      "Epoch: 1, Steps: 720 | Train Loss: 0.2715081 Vali Loss: 0.3351253 Test Loss: 0.2570457\n",
      "Validation loss decreased (inf --> 0.335125).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2987531\n",
      "\tspeed: 0.0549s/iter; left time: 192.0420s\n",
      "\titers: 200, epoch: 2 | loss: 0.4505640\n",
      "\tspeed: 0.0242s/iter; left time: 82.4242s\n",
      "\titers: 300, epoch: 2 | loss: 0.1858991\n",
      "\tspeed: 0.0251s/iter; left time: 82.9982s\n",
      "\titers: 400, epoch: 2 | loss: 0.2055973\n",
      "\tspeed: 0.0250s/iter; left time: 80.0075s\n",
      "\titers: 500, epoch: 2 | loss: 0.2106659\n",
      "\tspeed: 0.0268s/iter; left time: 83.1349s\n",
      "\titers: 600, epoch: 2 | loss: 0.1065798\n",
      "\tspeed: 0.0259s/iter; left time: 77.7714s\n",
      "\titers: 700, epoch: 2 | loss: 0.3444892\n",
      "\tspeed: 0.0223s/iter; left time: 64.5613s\n",
      "Epoch: 2 cost time: 17.693127870559692\n",
      "Epoch: 2, Steps: 720 | Train Loss: 0.2146620 Vali Loss: 0.3338602 Test Loss: 0.2582022\n",
      "Validation loss decreased (0.335125 --> 0.333860).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0934819\n",
      "\tspeed: 0.0564s/iter; left time: 156.8257s\n",
      "\titers: 200, epoch: 3 | loss: 0.2109388\n",
      "\tspeed: 0.0234s/iter; left time: 62.7316s\n",
      "\titers: 300, epoch: 3 | loss: 0.1623186\n",
      "\tspeed: 0.0232s/iter; left time: 59.8882s\n",
      "\titers: 400, epoch: 3 | loss: 0.2894626\n",
      "\tspeed: 0.0233s/iter; left time: 57.6873s\n",
      "\titers: 500, epoch: 3 | loss: 0.1152503\n",
      "\tspeed: 0.0220s/iter; left time: 52.4149s\n",
      "\titers: 600, epoch: 3 | loss: 0.1225025\n",
      "\tspeed: 0.0222s/iter; left time: 50.5520s\n",
      "\titers: 700, epoch: 3 | loss: 0.1353572\n",
      "\tspeed: 0.0255s/iter; left time: 55.6173s\n",
      "Epoch: 3 cost time: 16.710644245147705\n",
      "Epoch: 3, Steps: 720 | Train Loss: 0.1905959 Vali Loss: 0.3129626 Test Loss: 0.2473625\n",
      "Validation loss decreased (0.333860 --> 0.312963).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1344570\n",
      "\tspeed: 0.0571s/iter; left time: 117.7200s\n",
      "\titers: 200, epoch: 4 | loss: 0.1686296\n",
      "\tspeed: 0.0239s/iter; left time: 46.9037s\n",
      "\titers: 300, epoch: 4 | loss: 0.1198684\n",
      "\tspeed: 0.0221s/iter; left time: 41.1459s\n",
      "\titers: 400, epoch: 4 | loss: 0.2628645\n",
      "\tspeed: 0.0250s/iter; left time: 44.0978s\n",
      "\titers: 500, epoch: 4 | loss: 0.1682374\n",
      "\tspeed: 0.0252s/iter; left time: 41.8111s\n",
      "\titers: 600, epoch: 4 | loss: 0.1190256\n",
      "\tspeed: 0.0237s/iter; left time: 37.0205s\n",
      "\titers: 700, epoch: 4 | loss: 0.1724586\n",
      "\tspeed: 0.0232s/iter; left time: 33.9242s\n",
      "Epoch: 4 cost time: 17.22277545928955\n",
      "Epoch: 4, Steps: 720 | Train Loss: 0.1757924 Vali Loss: 0.3037810 Test Loss: 0.2367902\n",
      "Validation loss decreased (0.312963 --> 0.303781).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1478476\n",
      "\tspeed: 0.0581s/iter; left time: 77.9771s\n",
      "\titers: 200, epoch: 5 | loss: 0.1326227\n",
      "\tspeed: 0.0232s/iter; left time: 28.8008s\n",
      "\titers: 300, epoch: 5 | loss: 0.1508033\n",
      "\tspeed: 0.0271s/iter; left time: 30.9347s\n",
      "\titers: 400, epoch: 5 | loss: 0.2109952\n",
      "\tspeed: 0.0239s/iter; left time: 24.9128s\n",
      "\titers: 500, epoch: 5 | loss: 0.1942344\n",
      "\tspeed: 0.0235s/iter; left time: 22.1147s\n",
      "\titers: 600, epoch: 5 | loss: 0.1613557\n",
      "\tspeed: 0.0237s/iter; left time: 19.9718s\n",
      "\titers: 700, epoch: 5 | loss: 0.1786553\n",
      "\tspeed: 0.0228s/iter; left time: 16.9001s\n",
      "Epoch: 5 cost time: 17.284706354141235\n",
      "Epoch: 5, Steps: 720 | Train Loss: 0.1667632 Vali Loss: 0.3163776 Test Loss: 0.2397199\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2221625\n",
      "\tspeed: 0.0572s/iter; left time: 35.5184s\n",
      "\titers: 200, epoch: 6 | loss: 0.1382099\n",
      "\tspeed: 0.0235s/iter; left time: 12.2262s\n",
      "\titers: 300, epoch: 6 | loss: 0.3008234\n",
      "\tspeed: 0.0229s/iter; left time: 9.6496s\n",
      "\titers: 400, epoch: 6 | loss: 0.0952990\n",
      "\tspeed: 0.0241s/iter; left time: 7.7519s\n",
      "\titers: 500, epoch: 6 | loss: 0.2238376\n",
      "\tspeed: 0.0230s/iter; left time: 5.0819s\n",
      "\titers: 600, epoch: 6 | loss: 0.1833549\n",
      "\tspeed: 0.0232s/iter; left time: 2.8060s\n",
      "\titers: 700, epoch: 6 | loss: 0.1252413\n",
      "\tspeed: 0.0263s/iter; left time: 0.5516s\n",
      "Epoch: 6 cost time: 17.37981367111206\n",
      "Epoch: 6, Steps: 720 | Train Loss: 0.1619495 Vali Loss: 0.3131686 Test Loss: 0.2429099\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "Test cost time: 1.7413s\n",
      "test shape: (198, 32, 6, 1) (198, 32, 6, 1)\n",
      "test shape: (6336, 6, 1) (6336, 6, 1)\n",
      "mse:0.23721960186958313, mae:0.3236594796180725\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1624.426513671875\n",
      "MAE:  26.783235549926758\n",
      "RMSE: 40.304176330566406\n",
      "MAPE: 0.3481487035751343\n",
      "MSPE: 0.585425078868866\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24515\n",
      "[DEBUG] Original dataset length: 24515\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 23049\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3471\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.2095406\n",
      "\tspeed: 0.0237s/iter; left time: 99.9963s\n",
      "\titers: 200, epoch: 1 | loss: 0.3680976\n",
      "\tspeed: 0.0232s/iter; left time: 95.5156s\n",
      "\titers: 300, epoch: 1 | loss: 0.2528623\n",
      "\tspeed: 0.0228s/iter; left time: 91.8696s\n",
      "\titers: 400, epoch: 1 | loss: 0.1550481\n",
      "\tspeed: 0.0259s/iter; left time: 101.6257s\n",
      "\titers: 500, epoch: 1 | loss: 0.2939257\n",
      "\tspeed: 0.0226s/iter; left time: 86.4118s\n",
      "\titers: 600, epoch: 1 | loss: 0.3265004\n",
      "\tspeed: 0.0226s/iter; left time: 84.0225s\n",
      "\titers: 700, epoch: 1 | loss: 0.1744516\n",
      "\tspeed: 0.0175s/iter; left time: 63.4609s\n",
      "Epoch: 1 cost time: 16.163893222808838\n",
      "Epoch: 1, Steps: 720 | Train Loss: 0.2724532 Vali Loss: 0.3339336 Test Loss: 0.2619038\n",
      "Validation loss decreased (inf --> 0.333934).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2605522\n",
      "\tspeed: 0.0525s/iter; left time: 183.6673s\n",
      "\titers: 200, epoch: 2 | loss: 0.1692313\n",
      "\tspeed: 0.0250s/iter; left time: 84.9114s\n",
      "\titers: 300, epoch: 2 | loss: 0.1547834\n",
      "\tspeed: 0.0262s/iter; left time: 86.4543s\n",
      "\titers: 400, epoch: 2 | loss: 0.3553451\n",
      "\tspeed: 0.0238s/iter; left time: 76.1255s\n",
      "\titers: 500, epoch: 2 | loss: 0.1434582\n",
      "\tspeed: 0.0235s/iter; left time: 72.9234s\n",
      "\titers: 600, epoch: 2 | loss: 0.2930814\n",
      "\tspeed: 0.0235s/iter; left time: 70.6482s\n",
      "\titers: 700, epoch: 2 | loss: 0.2578700\n",
      "\tspeed: 0.0231s/iter; left time: 66.8967s\n",
      "Epoch: 2 cost time: 17.243138551712036\n",
      "Epoch: 2, Steps: 720 | Train Loss: 0.2163328 Vali Loss: 0.3121336 Test Loss: 0.2501607\n",
      "Validation loss decreased (0.333934 --> 0.312134).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1632709\n",
      "\tspeed: 0.0592s/iter; left time: 164.5605s\n",
      "\titers: 200, epoch: 3 | loss: 0.1394314\n",
      "\tspeed: 0.0234s/iter; left time: 62.6164s\n",
      "\titers: 300, epoch: 3 | loss: 0.1221570\n",
      "\tspeed: 0.0230s/iter; left time: 59.3103s\n",
      "\titers: 400, epoch: 3 | loss: 0.1482583\n",
      "\tspeed: 0.0241s/iter; left time: 59.8954s\n",
      "\titers: 500, epoch: 3 | loss: 0.1701573\n",
      "\tspeed: 0.0236s/iter; left time: 56.2994s\n",
      "\titers: 600, epoch: 3 | loss: 0.1325508\n",
      "\tspeed: 0.0240s/iter; left time: 54.8388s\n",
      "\titers: 700, epoch: 3 | loss: 0.2224279\n",
      "\tspeed: 0.0255s/iter; left time: 55.6730s\n",
      "Epoch: 3 cost time: 17.32090926170349\n",
      "Epoch: 3, Steps: 720 | Train Loss: 0.1874845 Vali Loss: 0.3126444 Test Loss: 0.2540839\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1805493\n",
      "\tspeed: 0.0535s/iter; left time: 110.1825s\n",
      "\titers: 200, epoch: 4 | loss: 0.1811765\n",
      "\tspeed: 0.0228s/iter; left time: 44.7183s\n",
      "\titers: 300, epoch: 4 | loss: 0.0797887\n",
      "\tspeed: 0.0234s/iter; left time: 43.5931s\n",
      "\titers: 400, epoch: 4 | loss: 0.1427653\n",
      "\tspeed: 0.0227s/iter; left time: 40.0412s\n",
      "\titers: 500, epoch: 4 | loss: 0.0813835\n",
      "\tspeed: 0.0266s/iter; left time: 44.2643s\n",
      "\titers: 600, epoch: 4 | loss: 0.1861085\n",
      "\tspeed: 0.0231s/iter; left time: 36.1131s\n",
      "\titers: 700, epoch: 4 | loss: 0.2181343\n",
      "\tspeed: 0.0239s/iter; left time: 34.8905s\n",
      "Epoch: 4 cost time: 17.11237072944641\n",
      "Epoch: 4, Steps: 720 | Train Loss: 0.1742397 Vali Loss: 0.3057671 Test Loss: 0.2386443\n",
      "Validation loss decreased (0.312134 --> 0.305767).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1590848\n",
      "\tspeed: 0.0554s/iter; left time: 74.2978s\n",
      "\titers: 200, epoch: 5 | loss: 0.2364831\n",
      "\tspeed: 0.0235s/iter; left time: 29.1286s\n",
      "\titers: 300, epoch: 5 | loss: 0.1418073\n",
      "\tspeed: 0.0253s/iter; left time: 28.8514s\n",
      "\titers: 400, epoch: 5 | loss: 0.1251081\n",
      "\tspeed: 0.0252s/iter; left time: 26.2196s\n",
      "\titers: 500, epoch: 5 | loss: 0.1622922\n",
      "\tspeed: 0.0232s/iter; left time: 21.8418s\n",
      "\titers: 600, epoch: 5 | loss: 0.1210797\n",
      "\tspeed: 0.0239s/iter; left time: 20.0659s\n",
      "\titers: 700, epoch: 5 | loss: 0.1207851\n",
      "\tspeed: 0.0237s/iter; left time: 17.5329s\n",
      "Epoch: 5 cost time: 17.30023193359375\n",
      "Epoch: 5, Steps: 720 | Train Loss: 0.1659484 Vali Loss: 0.3023714 Test Loss: 0.2387340\n",
      "Validation loss decreased (0.305767 --> 0.302371).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1459343\n",
      "\tspeed: 0.0588s/iter; left time: 36.5101s\n",
      "\titers: 200, epoch: 6 | loss: 0.1696891\n",
      "\tspeed: 0.0228s/iter; left time: 11.8653s\n",
      "\titers: 300, epoch: 6 | loss: 0.1633240\n",
      "\tspeed: 0.0222s/iter; left time: 9.3257s\n",
      "\titers: 400, epoch: 6 | loss: 0.1348028\n",
      "\tspeed: 0.0241s/iter; left time: 7.7492s\n",
      "\titers: 500, epoch: 6 | loss: 0.1136203\n",
      "\tspeed: 0.0226s/iter; left time: 4.9845s\n",
      "\titers: 600, epoch: 6 | loss: 0.0934504\n",
      "\tspeed: 0.0230s/iter; left time: 2.7815s\n",
      "\titers: 700, epoch: 6 | loss: 0.1588615\n",
      "\tspeed: 0.0249s/iter; left time: 0.5232s\n",
      "Epoch: 6 cost time: 17.092089653015137\n",
      "Epoch: 6, Steps: 720 | Train Loss: 0.1607868 Vali Loss: 0.3073252 Test Loss: 0.2407584\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "Test cost time: 1.6340s\n",
      "test shape: (198, 32, 6, 1) (198, 32, 6, 1)\n",
      "test shape: (6336, 6, 1) (6336, 6, 1)\n",
      "mse:0.23889628052711487, mae:0.32353052496910095\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1635.9080810546875\n",
      "MAE:  26.77256965637207\n",
      "RMSE: 40.44636154174805\n",
      "MAPE: 0.316813200712204\n",
      "MSPE: 0.45653998851776123\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24515\n",
      "[DEBUG] Original dataset length: 24515\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 23049\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3471\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.2363328\n",
      "\tspeed: 0.0241s/iter; left time: 101.5339s\n",
      "\titers: 200, epoch: 1 | loss: 0.3365135\n",
      "\tspeed: 0.0250s/iter; left time: 102.8387s\n",
      "\titers: 300, epoch: 1 | loss: 0.2770802\n",
      "\tspeed: 0.0234s/iter; left time: 93.9482s\n",
      "\titers: 400, epoch: 1 | loss: 0.2811079\n",
      "\tspeed: 0.0254s/iter; left time: 99.7621s\n",
      "\titers: 500, epoch: 1 | loss: 0.1877128\n",
      "\tspeed: 0.0246s/iter; left time: 93.9853s\n",
      "\titers: 600, epoch: 1 | loss: 0.2600272\n",
      "\tspeed: 0.0239s/iter; left time: 88.9503s\n",
      "\titers: 700, epoch: 1 | loss: 0.1489640\n",
      "\tspeed: 0.0223s/iter; left time: 80.5823s\n",
      "Epoch: 1 cost time: 17.300275087356567\n",
      "Epoch: 1, Steps: 720 | Train Loss: 0.2685788 Vali Loss: 0.3278439 Test Loss: 0.2556056\n",
      "Validation loss decreased (inf --> 0.327844).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1440834\n",
      "\tspeed: 0.0563s/iter; left time: 196.9384s\n",
      "\titers: 200, epoch: 2 | loss: 0.1496831\n",
      "\tspeed: 0.0260s/iter; left time: 88.5556s\n",
      "\titers: 300, epoch: 2 | loss: 0.2025033\n",
      "\tspeed: 0.0234s/iter; left time: 77.2715s\n",
      "\titers: 400, epoch: 2 | loss: 0.1285628\n",
      "\tspeed: 0.0233s/iter; left time: 74.4252s\n",
      "\titers: 500, epoch: 2 | loss: 0.2302941\n",
      "\tspeed: 0.0237s/iter; left time: 73.5845s\n",
      "\titers: 600, epoch: 2 | loss: 0.2207744\n",
      "\tspeed: 0.0226s/iter; left time: 67.8980s\n",
      "\titers: 700, epoch: 2 | loss: 0.1772367\n",
      "\tspeed: 0.0233s/iter; left time: 67.6746s\n",
      "Epoch: 2 cost time: 17.05386185646057\n",
      "Epoch: 2, Steps: 720 | Train Loss: 0.2155362 Vali Loss: 0.3380999 Test Loss: 0.2630863\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1724974\n",
      "\tspeed: 0.0550s/iter; left time: 153.0133s\n",
      "\titers: 200, epoch: 3 | loss: 0.1823882\n",
      "\tspeed: 0.0236s/iter; left time: 63.2095s\n",
      "\titers: 300, epoch: 3 | loss: 0.1806660\n",
      "\tspeed: 0.0241s/iter; left time: 62.0858s\n",
      "\titers: 400, epoch: 3 | loss: 0.2218558\n",
      "\tspeed: 0.0227s/iter; left time: 56.3988s\n",
      "\titers: 500, epoch: 3 | loss: 0.1658197\n",
      "\tspeed: 0.0241s/iter; left time: 57.2805s\n",
      "\titers: 600, epoch: 3 | loss: 0.1470765\n",
      "\tspeed: 0.0237s/iter; left time: 54.1414s\n",
      "\titers: 700, epoch: 3 | loss: 0.1589901\n",
      "\tspeed: 0.0257s/iter; left time: 55.9875s\n",
      "Epoch: 3 cost time: 17.252692937850952\n",
      "Epoch: 3, Steps: 720 | Train Loss: 0.1904237 Vali Loss: 0.3296501 Test Loss: 0.2754223\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1778895\n",
      "\tspeed: 0.0546s/iter; left time: 112.5700s\n",
      "\titers: 200, epoch: 4 | loss: 0.1789588\n",
      "\tspeed: 0.0225s/iter; left time: 44.2178s\n",
      "\titers: 300, epoch: 4 | loss: 0.1910141\n",
      "\tspeed: 0.0220s/iter; left time: 40.9653s\n",
      "\titers: 400, epoch: 4 | loss: 0.1264728\n",
      "\tspeed: 0.0226s/iter; left time: 39.8824s\n",
      "\titers: 500, epoch: 4 | loss: 0.1202404\n",
      "\tspeed: 0.0264s/iter; left time: 43.8401s\n",
      "\titers: 600, epoch: 4 | loss: 0.1668287\n",
      "\tspeed: 0.0235s/iter; left time: 36.6444s\n",
      "\titers: 700, epoch: 4 | loss: 0.1828644\n",
      "\tspeed: 0.0231s/iter; left time: 33.7379s\n",
      "Epoch: 4 cost time: 16.894968271255493\n",
      "Epoch: 4, Steps: 720 | Train Loss: 0.1762035 Vali Loss: 0.3027068 Test Loss: 0.2406115\n",
      "Validation loss decreased (0.327844 --> 0.302707).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1850672\n",
      "\tspeed: 0.0568s/iter; left time: 76.2134s\n",
      "\titers: 200, epoch: 5 | loss: 0.1287893\n",
      "\tspeed: 0.0230s/iter; left time: 28.5745s\n",
      "\titers: 300, epoch: 5 | loss: 0.1777712\n",
      "\tspeed: 0.0282s/iter; left time: 32.1203s\n",
      "\titers: 400, epoch: 5 | loss: 0.2494338\n",
      "\tspeed: 0.0240s/iter; left time: 24.9357s\n",
      "\titers: 500, epoch: 5 | loss: 0.1151850\n",
      "\tspeed: 0.0230s/iter; left time: 21.6263s\n",
      "\titers: 600, epoch: 5 | loss: 0.2260147\n",
      "\tspeed: 0.0243s/iter; left time: 20.3999s\n",
      "\titers: 700, epoch: 5 | loss: 0.1898606\n",
      "\tspeed: 0.0242s/iter; left time: 17.9381s\n",
      "Epoch: 5 cost time: 17.51840877532959\n",
      "Epoch: 5, Steps: 720 | Train Loss: 0.1672058 Vali Loss: 0.3083397 Test Loss: 0.2436474\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1243304\n",
      "\tspeed: 0.0574s/iter; left time: 35.6224s\n",
      "\titers: 200, epoch: 6 | loss: 0.2118607\n",
      "\tspeed: 0.0233s/iter; left time: 12.1384s\n",
      "\titers: 300, epoch: 6 | loss: 0.1241337\n",
      "\tspeed: 0.0245s/iter; left time: 10.3020s\n",
      "\titers: 400, epoch: 6 | loss: 0.1316978\n",
      "\tspeed: 0.0245s/iter; left time: 7.8635s\n",
      "\titers: 500, epoch: 6 | loss: 0.1916963\n",
      "\tspeed: 0.0231s/iter; left time: 5.1116s\n",
      "\titers: 600, epoch: 6 | loss: 0.1652163\n",
      "\tspeed: 0.0234s/iter; left time: 2.8347s\n",
      "\titers: 700, epoch: 6 | loss: 0.1501549\n",
      "\tspeed: 0.0263s/iter; left time: 0.5523s\n",
      "Epoch: 6 cost time: 17.649580478668213\n",
      "Epoch: 6, Steps: 720 | Train Loss: 0.1616795 Vali Loss: 0.3042971 Test Loss: 0.2395506\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "Test cost time: 1.6244s\n",
      "test shape: (198, 32, 6, 1) (198, 32, 6, 1)\n",
      "test shape: (6336, 6, 1) (6336, 6, 1)\n",
      "mse:0.23971359431743622, mae:0.322177529335022\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1641.504638671875\n",
      "MAE:  26.66060447692871\n",
      "RMSE: 40.51548767089844\n",
      "MAPE: 0.31655874848365784\n",
      "MSPE: 0.4469534754753113\n",
      ">>>>>>>Running time saved<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Running seq_len=48\n",
      "Args in experiment:\n",
      "Namespace(model='informer', data='traffic_full', root_path='../', data_path='traffic_full.csv', features='S', target='flow', freq='h', checkpoints='./checkpoints/', seq_len=48, label_len=24, pred_len=6, enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=2, d_layers=1, s_layers=[3, 2, 1], d_ff=2048, factor=5, padding=0, distil=True, dropout=0.05, attn='prob', embed='timeF', activation='gelu', output_attention=False, do_predict=False, mix=True, cols=None, num_workers=0, itr=10, train_epochs=6, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, inverse=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', detail_freq='h')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24491\n",
      "[DEBUG] Original dataset length: 24491\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22641\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3447\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "\titers: 100, epoch: 1 | loss: 0.4210311\n",
      "\tspeed: 0.0383s/iter; left time: 158.4818s\n",
      "\titers: 200, epoch: 1 | loss: 0.3457952\n",
      "\tspeed: 0.0270s/iter; left time: 109.2311s\n",
      "\titers: 300, epoch: 1 | loss: 0.1513244\n",
      "\tspeed: 0.0251s/iter; left time: 98.9940s\n",
      "\titers: 400, epoch: 1 | loss: 0.2177240\n",
      "\tspeed: 0.0246s/iter; left time: 94.3818s\n",
      "\titers: 500, epoch: 1 | loss: 0.4256431\n",
      "\tspeed: 0.0233s/iter; left time: 87.2379s\n",
      "\titers: 600, epoch: 1 | loss: 0.2885630\n",
      "\tspeed: 0.0236s/iter; left time: 86.1039s\n",
      "\titers: 700, epoch: 1 | loss: 0.1595648\n",
      "\tspeed: 0.0232s/iter; left time: 82.2992s\n",
      "Epoch: 1 cost time: 17.807585954666138\n",
      "Epoch: 1, Steps: 707 | Train Loss: 0.2804786 Vali Loss: 0.3333379 Test Loss: 0.2599899\n",
      "Validation loss decreased (inf --> 0.333338).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3905847\n",
      "\tspeed: 0.0556s/iter; left time: 190.9797s\n",
      "\titers: 200, epoch: 2 | loss: 0.1405668\n",
      "\tspeed: 0.0240s/iter; left time: 79.9787s\n",
      "\titers: 300, epoch: 2 | loss: 0.1045581\n",
      "\tspeed: 0.0250s/iter; left time: 81.0538s\n",
      "\titers: 400, epoch: 2 | loss: 0.3019554\n",
      "\tspeed: 0.0237s/iter; left time: 74.3569s\n",
      "\titers: 500, epoch: 2 | loss: 0.2593046\n",
      "\tspeed: 0.0235s/iter; left time: 71.2186s\n",
      "\titers: 600, epoch: 2 | loss: 0.2665177\n",
      "\tspeed: 0.0252s/iter; left time: 73.9049s\n",
      "\titers: 700, epoch: 2 | loss: 0.2768565\n",
      "\tspeed: 0.0264s/iter; left time: 74.8195s\n",
      "Epoch: 2 cost time: 17.495580673217773\n",
      "Epoch: 2, Steps: 707 | Train Loss: 0.2114408 Vali Loss: 0.3176592 Test Loss: 0.2518454\n",
      "Validation loss decreased (0.333338 --> 0.317659).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2002572\n",
      "\tspeed: 0.0525s/iter; left time: 143.2258s\n",
      "\titers: 200, epoch: 3 | loss: 0.2935592\n",
      "\tspeed: 0.0239s/iter; left time: 62.8512s\n",
      "\titers: 300, epoch: 3 | loss: 0.2452094\n",
      "\tspeed: 0.0247s/iter; left time: 62.4923s\n",
      "\titers: 400, epoch: 3 | loss: 0.1751938\n",
      "\tspeed: 0.0247s/iter; left time: 60.0598s\n",
      "\titers: 500, epoch: 3 | loss: 0.2048770\n",
      "\tspeed: 0.0287s/iter; left time: 66.8183s\n",
      "\titers: 600, epoch: 3 | loss: 0.1291269\n",
      "\tspeed: 0.0239s/iter; left time: 53.2691s\n",
      "\titers: 700, epoch: 3 | loss: 0.1791790\n",
      "\tspeed: 0.0232s/iter; left time: 49.4615s\n",
      "Epoch: 3 cost time: 17.511465311050415\n",
      "Epoch: 3, Steps: 707 | Train Loss: 0.1859855 Vali Loss: 0.3070369 Test Loss: 0.2368643\n",
      "Validation loss decreased (0.317659 --> 0.307037).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1564780\n",
      "\tspeed: 0.0532s/iter; left time: 107.6137s\n",
      "\titers: 200, epoch: 4 | loss: 0.1667581\n",
      "\tspeed: 0.0250s/iter; left time: 48.0428s\n",
      "\titers: 300, epoch: 4 | loss: 0.1477265\n",
      "\tspeed: 0.0258s/iter; left time: 47.0434s\n",
      "\titers: 400, epoch: 4 | loss: 0.1481032\n",
      "\tspeed: 0.0239s/iter; left time: 41.1474s\n",
      "\titers: 500, epoch: 4 | loss: 0.1348788\n",
      "\tspeed: 0.0250s/iter; left time: 40.4989s\n",
      "\titers: 600, epoch: 4 | loss: 0.1294691\n",
      "\tspeed: 0.0244s/iter; left time: 37.0727s\n",
      "\titers: 700, epoch: 4 | loss: 0.1531549\n",
      "\tspeed: 0.0248s/iter; left time: 35.2060s\n",
      "Epoch: 4 cost time: 17.43866753578186\n",
      "Epoch: 4, Steps: 707 | Train Loss: 0.1710407 Vali Loss: 0.3080489 Test Loss: 0.2389767\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0991146\n",
      "\tspeed: 0.0540s/iter; left time: 70.9450s\n",
      "\titers: 200, epoch: 5 | loss: 0.1438493\n",
      "\tspeed: 0.0248s/iter; left time: 30.1200s\n",
      "\titers: 300, epoch: 5 | loss: 0.0933202\n",
      "\tspeed: 0.0247s/iter; left time: 27.5472s\n",
      "\titers: 400, epoch: 5 | loss: 0.0841533\n",
      "\tspeed: 0.0238s/iter; left time: 24.1759s\n",
      "\titers: 500, epoch: 5 | loss: 0.1186457\n",
      "\tspeed: 0.0245s/iter; left time: 22.4377s\n",
      "\titers: 600, epoch: 5 | loss: 0.2508901\n",
      "\tspeed: 0.0252s/iter; left time: 20.5340s\n",
      "\titers: 700, epoch: 5 | loss: 0.1364281\n",
      "\tspeed: 0.0266s/iter; left time: 19.0191s\n",
      "Epoch: 5 cost time: 17.737491130828857\n",
      "Epoch: 5, Steps: 707 | Train Loss: 0.1620446 Vali Loss: 0.3012838 Test Loss: 0.2373968\n",
      "Validation loss decreased (0.307037 --> 0.301284).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1858535\n",
      "\tspeed: 0.0536s/iter; left time: 32.5811s\n",
      "\titers: 200, epoch: 6 | loss: 0.1200128\n",
      "\tspeed: 0.0243s/iter; left time: 12.3531s\n",
      "\titers: 300, epoch: 6 | loss: 0.2558707\n",
      "\tspeed: 0.0250s/iter; left time: 10.1886s\n",
      "\titers: 400, epoch: 6 | loss: 0.0860212\n",
      "\tspeed: 0.0254s/iter; left time: 7.8140s\n",
      "\titers: 500, epoch: 6 | loss: 0.1418271\n",
      "\tspeed: 0.0250s/iter; left time: 5.2016s\n",
      "\titers: 600, epoch: 6 | loss: 0.1010118\n",
      "\tspeed: 0.0240s/iter; left time: 2.5956s\n",
      "\titers: 700, epoch: 6 | loss: 0.1927746\n",
      "\tspeed: 0.0239s/iter; left time: 0.1916s\n",
      "Epoch: 6 cost time: 17.434693574905396\n",
      "Epoch: 6, Steps: 707 | Train Loss: 0.1567271 Vali Loss: 0.3222309 Test Loss: 0.2441462\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "Test cost time: 1.7408s\n",
      "test shape: (192, 32, 6, 1) (192, 32, 6, 1)\n",
      "test shape: (6144, 6, 1) (6144, 6, 1)\n",
      "mse:0.23733316361904144, mae:0.3256560266017914\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1625.2042236328125\n",
      "MAE:  26.94845199584961\n",
      "RMSE: 40.313819885253906\n",
      "MAPE: 0.3423309326171875\n",
      "MSPE: 0.5607410669326782\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24491\n",
      "[DEBUG] Original dataset length: 24491\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22641\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3447\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "\titers: 100, epoch: 1 | loss: 0.4390069\n",
      "\tspeed: 0.0261s/iter; left time: 108.1554s\n",
      "\titers: 200, epoch: 1 | loss: 0.2514298\n",
      "\tspeed: 0.0251s/iter; left time: 101.4952s\n",
      "\titers: 300, epoch: 1 | loss: 0.2287695\n",
      "\tspeed: 0.0238s/iter; left time: 94.0039s\n",
      "\titers: 400, epoch: 1 | loss: 0.2228647\n",
      "\tspeed: 0.0251s/iter; left time: 96.3374s\n",
      "\titers: 500, epoch: 1 | loss: 0.3023682\n",
      "\tspeed: 0.0242s/iter; left time: 90.7072s\n",
      "\titers: 600, epoch: 1 | loss: 0.1733539\n",
      "\tspeed: 0.0248s/iter; left time: 90.3469s\n",
      "\titers: 700, epoch: 1 | loss: 0.1486857\n",
      "\tspeed: 0.0267s/iter; left time: 94.5472s\n",
      "Epoch: 1 cost time: 17.807084560394287\n",
      "Epoch: 1, Steps: 707 | Train Loss: 0.2753465 Vali Loss: 0.3358818 Test Loss: 0.2625759\n",
      "Validation loss decreased (inf --> 0.335882).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2089699\n",
      "\tspeed: 0.0547s/iter; left time: 188.1047s\n",
      "\titers: 200, epoch: 2 | loss: 0.2221625\n",
      "\tspeed: 0.0241s/iter; left time: 80.5167s\n",
      "\titers: 300, epoch: 2 | loss: 0.2049545\n",
      "\tspeed: 0.0243s/iter; left time: 78.5491s\n",
      "\titers: 400, epoch: 2 | loss: 0.2321509\n",
      "\tspeed: 0.0245s/iter; left time: 76.7277s\n",
      "\titers: 500, epoch: 2 | loss: 0.1381558\n",
      "\tspeed: 0.0270s/iter; left time: 82.0353s\n",
      "\titers: 600, epoch: 2 | loss: 0.1520614\n",
      "\tspeed: 0.0238s/iter; left time: 69.9116s\n",
      "\titers: 700, epoch: 2 | loss: 0.2239976\n",
      "\tspeed: 0.0237s/iter; left time: 67.3424s\n",
      "Epoch: 2 cost time: 17.442261219024658\n",
      "Epoch: 2, Steps: 707 | Train Loss: 0.2111526 Vali Loss: 0.3217575 Test Loss: 0.2536869\n",
      "Validation loss decreased (0.335882 --> 0.321758).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1364773\n",
      "\tspeed: 0.0540s/iter; left time: 147.3980s\n",
      "\titers: 200, epoch: 3 | loss: 0.2409610\n",
      "\tspeed: 0.0247s/iter; left time: 65.0290s\n",
      "\titers: 300, epoch: 3 | loss: 0.1257214\n",
      "\tspeed: 0.0274s/iter; left time: 69.2603s\n",
      "\titers: 400, epoch: 3 | loss: 0.1675286\n",
      "\tspeed: 0.0266s/iter; left time: 64.5114s\n",
      "\titers: 500, epoch: 3 | loss: 0.1347077\n",
      "\tspeed: 0.0258s/iter; left time: 60.2023s\n",
      "\titers: 600, epoch: 3 | loss: 0.1661098\n",
      "\tspeed: 0.0247s/iter; left time: 55.0093s\n",
      "\titers: 700, epoch: 3 | loss: 0.1089203\n",
      "\tspeed: 0.0239s/iter; left time: 50.9358s\n",
      "Epoch: 3 cost time: 17.85577893257141\n",
      "Epoch: 3, Steps: 707 | Train Loss: 0.1843082 Vali Loss: 0.3294305 Test Loss: 0.2671072\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1299461\n",
      "\tspeed: 0.0550s/iter; left time: 111.2203s\n",
      "\titers: 200, epoch: 4 | loss: 0.1347720\n",
      "\tspeed: 0.0245s/iter; left time: 47.0022s\n",
      "\titers: 300, epoch: 4 | loss: 0.1330140\n",
      "\tspeed: 0.0242s/iter; left time: 44.1729s\n",
      "\titers: 400, epoch: 4 | loss: 0.1948192\n",
      "\tspeed: 0.0249s/iter; left time: 42.9100s\n",
      "\titers: 500, epoch: 4 | loss: 0.1727332\n",
      "\tspeed: 0.0244s/iter; left time: 39.6106s\n",
      "\titers: 600, epoch: 4 | loss: 0.1938460\n",
      "\tspeed: 0.0252s/iter; left time: 38.3807s\n",
      "\titers: 700, epoch: 4 | loss: 0.1064410\n",
      "\tspeed: 0.0271s/iter; left time: 38.5130s\n",
      "Epoch: 4 cost time: 17.874019861221313\n",
      "Epoch: 4, Steps: 707 | Train Loss: 0.1717788 Vali Loss: 0.3170339 Test Loss: 0.2434676\n",
      "Validation loss decreased (0.321758 --> 0.317034).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1455170\n",
      "\tspeed: 0.0549s/iter; left time: 72.2490s\n",
      "\titers: 200, epoch: 5 | loss: 0.1549000\n",
      "\tspeed: 0.0236s/iter; left time: 28.6521s\n",
      "\titers: 300, epoch: 5 | loss: 0.1402128\n",
      "\tspeed: 0.0243s/iter; left time: 27.1430s\n",
      "\titers: 400, epoch: 5 | loss: 0.1134744\n",
      "\tspeed: 0.0248s/iter; left time: 25.2017s\n",
      "\titers: 500, epoch: 5 | loss: 0.1262564\n",
      "\tspeed: 0.0270s/iter; left time: 24.7486s\n",
      "\titers: 600, epoch: 5 | loss: 0.1395959\n",
      "\tspeed: 0.0246s/iter; left time: 20.0882s\n",
      "\titers: 700, epoch: 5 | loss: 0.1280554\n",
      "\tspeed: 0.0244s/iter; left time: 17.4223s\n",
      "Epoch: 5 cost time: 17.606274127960205\n",
      "Epoch: 5, Steps: 707 | Train Loss: 0.1615815 Vali Loss: 0.3096191 Test Loss: 0.2373020\n",
      "Validation loss decreased (0.317034 --> 0.309619).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1940884\n",
      "\tspeed: 0.0551s/iter; left time: 33.5286s\n",
      "\titers: 200, epoch: 6 | loss: 0.1898064\n",
      "\tspeed: 0.0246s/iter; left time: 12.5180s\n",
      "\titers: 300, epoch: 6 | loss: 0.3149776\n",
      "\tspeed: 0.0258s/iter; left time: 10.5446s\n",
      "\titers: 400, epoch: 6 | loss: 0.2096702\n",
      "\tspeed: 0.0238s/iter; left time: 7.3331s\n",
      "\titers: 500, epoch: 6 | loss: 0.1424762\n",
      "\tspeed: 0.0247s/iter; left time: 5.1304s\n",
      "\titers: 600, epoch: 6 | loss: 0.1819395\n",
      "\tspeed: 0.0234s/iter; left time: 2.5292s\n",
      "\titers: 700, epoch: 6 | loss: 0.1783880\n",
      "\tspeed: 0.0250s/iter; left time: 0.1999s\n",
      "Epoch: 6 cost time: 17.34546399116516\n",
      "Epoch: 6, Steps: 707 | Train Loss: 0.1563585 Vali Loss: 0.3135792 Test Loss: 0.2407655\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "Test cost time: 1.9008s\n",
      "test shape: (192, 32, 6, 1) (192, 32, 6, 1)\n",
      "test shape: (6144, 6, 1) (6144, 6, 1)\n",
      "mse:0.23867511749267578, mae:0.32231882214546204\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1634.3936767578125\n",
      "MAE:  26.67229652404785\n",
      "RMSE: 40.427635192871094\n",
      "MAPE: 0.32730603218078613\n",
      "MSPE: 0.48404496908187866\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24491\n",
      "[DEBUG] Original dataset length: 24491\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22641\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3447\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "\titers: 100, epoch: 1 | loss: 0.1704289\n",
      "\tspeed: 0.0266s/iter; left time: 110.3374s\n",
      "\titers: 200, epoch: 1 | loss: 0.2835771\n",
      "\tspeed: 0.0249s/iter; left time: 100.5798s\n",
      "\titers: 300, epoch: 1 | loss: 0.2850280\n",
      "\tspeed: 0.0237s/iter; left time: 93.5739s\n",
      "\titers: 400, epoch: 1 | loss: 0.2920347\n",
      "\tspeed: 0.0245s/iter; left time: 94.2281s\n",
      "\titers: 500, epoch: 1 | loss: 0.1958680\n",
      "\tspeed: 0.0243s/iter; left time: 90.8143s\n",
      "\titers: 600, epoch: 1 | loss: 0.2792860\n",
      "\tspeed: 0.0263s/iter; left time: 95.9120s\n",
      "\titers: 700, epoch: 1 | loss: 0.1850270\n",
      "\tspeed: 0.0236s/iter; left time: 83.5442s\n",
      "Epoch: 1 cost time: 17.562478065490723\n",
      "Epoch: 1, Steps: 707 | Train Loss: 0.2785999 Vali Loss: 0.3357542 Test Loss: 0.2677054\n",
      "Validation loss decreased (inf --> 0.335754).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2084626\n",
      "\tspeed: 0.0536s/iter; left time: 184.2814s\n",
      "\titers: 200, epoch: 2 | loss: 0.3886803\n",
      "\tspeed: 0.0251s/iter; left time: 83.7394s\n",
      "\titers: 300, epoch: 2 | loss: 0.1933730\n",
      "\tspeed: 0.0265s/iter; left time: 85.8617s\n",
      "\titers: 400, epoch: 2 | loss: 0.1982645\n",
      "\tspeed: 0.0266s/iter; left time: 83.4135s\n",
      "\titers: 500, epoch: 2 | loss: 0.1970346\n",
      "\tspeed: 0.0240s/iter; left time: 72.9749s\n",
      "\titers: 600, epoch: 2 | loss: 0.2151261\n",
      "\tspeed: 0.0249s/iter; left time: 72.9969s\n",
      "\titers: 700, epoch: 2 | loss: 0.2453477\n",
      "\tspeed: 0.0244s/iter; left time: 69.2992s\n",
      "Epoch: 2 cost time: 17.765398502349854\n",
      "Epoch: 2, Steps: 707 | Train Loss: 0.2146884 Vali Loss: 0.3046222 Test Loss: 0.2396729\n",
      "Validation loss decreased (0.335754 --> 0.304622).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1312850\n",
      "\tspeed: 0.0565s/iter; left time: 154.3200s\n",
      "\titers: 200, epoch: 3 | loss: 0.1794149\n",
      "\tspeed: 0.0252s/iter; left time: 66.2990s\n",
      "\titers: 300, epoch: 3 | loss: 0.1696878\n",
      "\tspeed: 0.0247s/iter; left time: 62.3799s\n",
      "\titers: 400, epoch: 3 | loss: 0.2421931\n",
      "\tspeed: 0.0235s/iter; left time: 57.0257s\n",
      "\titers: 500, epoch: 3 | loss: 0.2663363\n",
      "\tspeed: 0.0234s/iter; left time: 54.5860s\n",
      "\titers: 600, epoch: 3 | loss: 0.1547637\n",
      "\tspeed: 0.0256s/iter; left time: 57.1633s\n",
      "\titers: 700, epoch: 3 | loss: 0.2589108\n",
      "\tspeed: 0.0241s/iter; left time: 51.3881s\n",
      "Epoch: 3 cost time: 17.495702981948853\n",
      "Epoch: 3, Steps: 707 | Train Loss: 0.1842913 Vali Loss: 0.3125278 Test Loss: 0.2504686\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1227972\n",
      "\tspeed: 0.0574s/iter; left time: 116.0030s\n",
      "\titers: 200, epoch: 4 | loss: 0.2047904\n",
      "\tspeed: 0.0251s/iter; left time: 48.1879s\n",
      "\titers: 300, epoch: 4 | loss: 0.1599318\n",
      "\tspeed: 0.0246s/iter; left time: 44.8585s\n",
      "\titers: 400, epoch: 4 | loss: 0.1832275\n",
      "\tspeed: 0.0247s/iter; left time: 42.5947s\n",
      "\titers: 500, epoch: 4 | loss: 0.2185615\n",
      "\tspeed: 0.0262s/iter; left time: 42.5699s\n",
      "\titers: 600, epoch: 4 | loss: 0.1075266\n",
      "\tspeed: 0.0270s/iter; left time: 41.1325s\n",
      "\titers: 700, epoch: 4 | loss: 0.1197308\n",
      "\tspeed: 0.0255s/iter; left time: 36.2436s\n",
      "Epoch: 4 cost time: 18.12224268913269\n",
      "Epoch: 4, Steps: 707 | Train Loss: 0.1696726 Vali Loss: 0.3089542 Test Loss: 0.2398634\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1262471\n",
      "\tspeed: 0.0529s/iter; left time: 69.5015s\n",
      "\titers: 200, epoch: 5 | loss: 0.1710974\n",
      "\tspeed: 0.0244s/iter; left time: 29.6961s\n",
      "\titers: 300, epoch: 5 | loss: 0.1221268\n",
      "\tspeed: 0.0256s/iter; left time: 28.5178s\n",
      "\titers: 400, epoch: 5 | loss: 0.1425094\n",
      "\tspeed: 0.0240s/iter; left time: 24.3903s\n",
      "\titers: 500, epoch: 5 | loss: 0.1597150\n",
      "\tspeed: 0.0235s/iter; left time: 21.4926s\n",
      "\titers: 600, epoch: 5 | loss: 0.1187080\n",
      "\tspeed: 0.0241s/iter; left time: 19.6008s\n",
      "\titers: 700, epoch: 5 | loss: 0.1614824\n",
      "\tspeed: 0.0244s/iter; left time: 17.4462s\n",
      "Epoch: 5 cost time: 17.260797262191772\n",
      "Epoch: 5, Steps: 707 | Train Loss: 0.1606578 Vali Loss: 0.3172571 Test Loss: 0.2420775\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "Test cost time: 1.7372s\n",
      "test shape: (192, 32, 6, 1) (192, 32, 6, 1)\n",
      "test shape: (6144, 6, 1) (6144, 6, 1)\n",
      "mse:0.23908965289592743, mae:0.3309538662433624\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1637.232177734375\n",
      "MAE:  27.386857986450195\n",
      "RMSE: 40.46272659301758\n",
      "MAPE: 0.3898947536945343\n",
      "MSPE: 0.8209624886512756\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24491\n",
      "[DEBUG] Original dataset length: 24491\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22641\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3447\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "\titers: 100, epoch: 1 | loss: 0.2430533\n",
      "\tspeed: 0.0260s/iter; left time: 107.8957s\n",
      "\titers: 200, epoch: 1 | loss: 0.1424895\n",
      "\tspeed: 0.0243s/iter; left time: 98.0450s\n",
      "\titers: 300, epoch: 1 | loss: 0.2473363\n",
      "\tspeed: 0.0246s/iter; left time: 97.1037s\n",
      "\titers: 400, epoch: 1 | loss: 0.2519385\n",
      "\tspeed: 0.0242s/iter; left time: 92.9891s\n",
      "\titers: 500, epoch: 1 | loss: 0.2512153\n",
      "\tspeed: 0.0243s/iter; left time: 90.7827s\n",
      "\titers: 600, epoch: 1 | loss: 0.1901112\n",
      "\tspeed: 0.0256s/iter; left time: 93.2156s\n",
      "\titers: 700, epoch: 1 | loss: 0.1946077\n",
      "\tspeed: 0.0271s/iter; left time: 95.9216s\n",
      "Epoch: 1 cost time: 17.785075664520264\n",
      "Epoch: 1, Steps: 707 | Train Loss: 0.2758938 Vali Loss: 0.3558323 Test Loss: 0.2794919\n",
      "Validation loss decreased (inf --> 0.355832).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2309200\n",
      "\tspeed: 0.0540s/iter; left time: 185.5004s\n",
      "\titers: 200, epoch: 2 | loss: 0.1952427\n",
      "\tspeed: 0.0247s/iter; left time: 82.4404s\n",
      "\titers: 300, epoch: 2 | loss: 0.2590996\n",
      "\tspeed: 0.0275s/iter; left time: 88.8469s\n",
      "\titers: 400, epoch: 2 | loss: 0.2715459\n",
      "\tspeed: 0.0257s/iter; left time: 80.4603s\n",
      "\titers: 500, epoch: 2 | loss: 0.2971887\n",
      "\tspeed: 0.0260s/iter; left time: 78.7946s\n",
      "\titers: 600, epoch: 2 | loss: 0.2728703\n",
      "\tspeed: 0.0258s/iter; left time: 75.8717s\n",
      "\titers: 700, epoch: 2 | loss: 0.2956288\n",
      "\tspeed: 0.0243s/iter; left time: 68.9709s\n",
      "Epoch: 2 cost time: 18.021286249160767\n",
      "Epoch: 2, Steps: 707 | Train Loss: 0.2139078 Vali Loss: 0.3153602 Test Loss: 0.2464489\n",
      "Validation loss decreased (0.355832 --> 0.315360).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1681241\n",
      "\tspeed: 0.0532s/iter; left time: 145.2683s\n",
      "\titers: 200, epoch: 3 | loss: 0.1768613\n",
      "\tspeed: 0.0253s/iter; left time: 66.4574s\n",
      "\titers: 300, epoch: 3 | loss: 0.1515778\n",
      "\tspeed: 0.0241s/iter; left time: 60.8544s\n",
      "\titers: 400, epoch: 3 | loss: 0.1265035\n",
      "\tspeed: 0.0239s/iter; left time: 58.0695s\n",
      "\titers: 500, epoch: 3 | loss: 0.1581320\n",
      "\tspeed: 0.0241s/iter; left time: 56.2217s\n",
      "\titers: 600, epoch: 3 | loss: 0.1567674\n",
      "\tspeed: 0.0242s/iter; left time: 54.0407s\n",
      "\titers: 700, epoch: 3 | loss: 0.3244480\n",
      "\tspeed: 0.0241s/iter; left time: 51.3176s\n",
      "Epoch: 3 cost time: 17.184513568878174\n",
      "Epoch: 3, Steps: 707 | Train Loss: 0.1864818 Vali Loss: 0.3070256 Test Loss: 0.2450765\n",
      "Validation loss decreased (0.315360 --> 0.307026).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2119829\n",
      "\tspeed: 0.0555s/iter; left time: 112.1403s\n",
      "\titers: 200, epoch: 4 | loss: 0.1771836\n",
      "\tspeed: 0.0238s/iter; left time: 45.6923s\n",
      "\titers: 300, epoch: 4 | loss: 0.2999492\n",
      "\tspeed: 0.0241s/iter; left time: 43.8770s\n",
      "\titers: 400, epoch: 4 | loss: 0.3825095\n",
      "\tspeed: 0.0244s/iter; left time: 42.0087s\n",
      "\titers: 500, epoch: 4 | loss: 0.1672008\n",
      "\tspeed: 0.0240s/iter; left time: 38.9851s\n",
      "\titers: 600, epoch: 4 | loss: 0.1223279\n",
      "\tspeed: 0.0275s/iter; left time: 41.9001s\n",
      "\titers: 700, epoch: 4 | loss: 0.1807597\n",
      "\tspeed: 0.0254s/iter; left time: 36.0739s\n",
      "Epoch: 4 cost time: 17.5449275970459\n",
      "Epoch: 4, Steps: 707 | Train Loss: 0.1721883 Vali Loss: 0.3172728 Test Loss: 0.2490414\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1500980\n",
      "\tspeed: 0.0524s/iter; left time: 68.9156s\n",
      "\titers: 200, epoch: 5 | loss: 0.1349578\n",
      "\tspeed: 0.0253s/iter; left time: 30.7526s\n",
      "\titers: 300, epoch: 5 | loss: 0.1126065\n",
      "\tspeed: 0.0251s/iter; left time: 28.0206s\n",
      "\titers: 400, epoch: 5 | loss: 0.1088059\n",
      "\tspeed: 0.0276s/iter; left time: 28.0204s\n",
      "\titers: 500, epoch: 5 | loss: 0.1740093\n",
      "\tspeed: 0.0247s/iter; left time: 22.6394s\n",
      "\titers: 600, epoch: 5 | loss: 0.1469314\n",
      "\tspeed: 0.0236s/iter; left time: 19.2114s\n",
      "\titers: 700, epoch: 5 | loss: 0.3842281\n",
      "\tspeed: 0.0240s/iter; left time: 17.1677s\n",
      "Epoch: 5 cost time: 17.738157510757446\n",
      "Epoch: 5, Steps: 707 | Train Loss: 0.1623764 Vali Loss: 0.3075360 Test Loss: 0.2486005\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1886922\n",
      "\tspeed: 0.0530s/iter; left time: 32.2079s\n",
      "\titers: 200, epoch: 6 | loss: 0.2606882\n",
      "\tspeed: 0.0271s/iter; left time: 13.7700s\n",
      "\titers: 300, epoch: 6 | loss: 0.1584214\n",
      "\tspeed: 0.0247s/iter; left time: 10.0838s\n",
      "\titers: 400, epoch: 6 | loss: 0.1660562\n",
      "\tspeed: 0.0253s/iter; left time: 7.7895s\n",
      "\titers: 500, epoch: 6 | loss: 0.1014401\n",
      "\tspeed: 0.0267s/iter; left time: 5.5581s\n",
      "\titers: 600, epoch: 6 | loss: 0.1193060\n",
      "\tspeed: 0.0256s/iter; left time: 2.7686s\n",
      "\titers: 700, epoch: 6 | loss: 0.1573971\n",
      "\tspeed: 0.0245s/iter; left time: 0.1963s\n",
      "Epoch: 6 cost time: 18.011592149734497\n",
      "Epoch: 6, Steps: 707 | Train Loss: 0.1571155 Vali Loss: 0.3113485 Test Loss: 0.2481628\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "Test cost time: 1.6594s\n",
      "test shape: (192, 32, 6, 1) (192, 32, 6, 1)\n",
      "test shape: (6144, 6, 1) (6144, 6, 1)\n",
      "mse:0.2454405426979065, mae:0.33689382672309875\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1680.7216796875\n",
      "MAE:  27.87839698791504\n",
      "RMSE: 40.996604919433594\n",
      "MAPE: 0.39872029423713684\n",
      "MSPE: 0.8084724545478821\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24491\n",
      "[DEBUG] Original dataset length: 24491\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22641\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3447\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "\titers: 100, epoch: 1 | loss: 0.1970214\n",
      "\tspeed: 0.0248s/iter; left time: 102.5401s\n",
      "\titers: 200, epoch: 1 | loss: 0.4251861\n",
      "\tspeed: 0.0243s/iter; left time: 98.4007s\n",
      "\titers: 300, epoch: 1 | loss: 0.1874111\n",
      "\tspeed: 0.0250s/iter; left time: 98.7128s\n",
      "\titers: 400, epoch: 1 | loss: 0.1989802\n",
      "\tspeed: 0.0237s/iter; left time: 90.9912s\n",
      "\titers: 500, epoch: 1 | loss: 0.3984332\n",
      "\tspeed: 0.0274s/iter; left time: 102.5194s\n",
      "\titers: 600, epoch: 1 | loss: 0.2959691\n",
      "\tspeed: 0.0248s/iter; left time: 90.4085s\n",
      "\titers: 700, epoch: 1 | loss: 0.2260772\n",
      "\tspeed: 0.0249s/iter; left time: 88.2073s\n",
      "Epoch: 1 cost time: 17.693063497543335\n",
      "Epoch: 1, Steps: 707 | Train Loss: 0.2742888 Vali Loss: 0.3475755 Test Loss: 0.2840088\n",
      "Validation loss decreased (inf --> 0.347575).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1092309\n",
      "\tspeed: 0.0559s/iter; left time: 191.9771s\n",
      "\titers: 200, epoch: 2 | loss: 0.1888814\n",
      "\tspeed: 0.0261s/iter; left time: 87.1144s\n",
      "\titers: 300, epoch: 2 | loss: 0.1963721\n",
      "\tspeed: 0.0259s/iter; left time: 83.6764s\n",
      "\titers: 400, epoch: 2 | loss: 0.2408742\n",
      "\tspeed: 0.0240s/iter; left time: 75.1243s\n",
      "\titers: 500, epoch: 2 | loss: 0.1968239\n",
      "\tspeed: 0.0245s/iter; left time: 74.4447s\n",
      "\titers: 600, epoch: 2 | loss: 0.1582304\n",
      "\tspeed: 0.0246s/iter; left time: 72.2853s\n",
      "\titers: 700, epoch: 2 | loss: 0.2588986\n",
      "\tspeed: 0.0244s/iter; left time: 69.0997s\n",
      "Epoch: 2 cost time: 17.77568507194519\n",
      "Epoch: 2, Steps: 707 | Train Loss: 0.2121581 Vali Loss: 0.3269618 Test Loss: 0.2509369\n",
      "Validation loss decreased (0.347575 --> 0.326962).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1274087\n",
      "\tspeed: 0.0568s/iter; left time: 154.8916s\n",
      "\titers: 200, epoch: 3 | loss: 0.2098148\n",
      "\tspeed: 0.0237s/iter; left time: 62.3291s\n",
      "\titers: 300, epoch: 3 | loss: 0.1968028\n",
      "\tspeed: 0.0246s/iter; left time: 62.2476s\n",
      "\titers: 400, epoch: 3 | loss: 0.1446634\n",
      "\tspeed: 0.0234s/iter; left time: 56.8582s\n",
      "\titers: 500, epoch: 3 | loss: 0.2836033\n",
      "\tspeed: 0.0251s/iter; left time: 58.4894s\n",
      "\titers: 600, epoch: 3 | loss: 0.1563994\n",
      "\tspeed: 0.0257s/iter; left time: 57.3008s\n",
      "\titers: 700, epoch: 3 | loss: 0.1906391\n",
      "\tspeed: 0.0254s/iter; left time: 54.0501s\n",
      "Epoch: 3 cost time: 17.598198652267456\n",
      "Epoch: 3, Steps: 707 | Train Loss: 0.1850122 Vali Loss: 0.3126726 Test Loss: 0.2398090\n",
      "Validation loss decreased (0.326962 --> 0.312673).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1490543\n",
      "\tspeed: 0.0518s/iter; left time: 104.6908s\n",
      "\titers: 200, epoch: 4 | loss: 0.1509530\n",
      "\tspeed: 0.0246s/iter; left time: 47.3097s\n",
      "\titers: 300, epoch: 4 | loss: 0.1538040\n",
      "\tspeed: 0.0243s/iter; left time: 44.2209s\n",
      "\titers: 400, epoch: 4 | loss: 0.1713613\n",
      "\tspeed: 0.0257s/iter; left time: 44.2619s\n",
      "\titers: 500, epoch: 4 | loss: 0.1697745\n",
      "\tspeed: 0.0247s/iter; left time: 40.1355s\n",
      "\titers: 600, epoch: 4 | loss: 0.1506352\n",
      "\tspeed: 0.0246s/iter; left time: 37.3740s\n",
      "\titers: 700, epoch: 4 | loss: 0.1572773\n",
      "\tspeed: 0.0236s/iter; left time: 33.5079s\n",
      "Epoch: 4 cost time: 17.25846791267395\n",
      "Epoch: 4, Steps: 707 | Train Loss: 0.1704296 Vali Loss: 0.3124579 Test Loss: 0.2461192\n",
      "Validation loss decreased (0.312673 --> 0.312458).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2018645\n",
      "\tspeed: 0.0561s/iter; left time: 73.7496s\n",
      "\titers: 200, epoch: 5 | loss: 0.1390464\n",
      "\tspeed: 0.0267s/iter; left time: 32.4759s\n",
      "\titers: 300, epoch: 5 | loss: 0.1701632\n",
      "\tspeed: 0.0253s/iter; left time: 28.2065s\n",
      "\titers: 400, epoch: 5 | loss: 0.1334925\n",
      "\tspeed: 0.0252s/iter; left time: 25.5940s\n",
      "\titers: 500, epoch: 5 | loss: 0.1128838\n",
      "\tspeed: 0.0243s/iter; left time: 22.2295s\n",
      "\titers: 600, epoch: 5 | loss: 0.1860691\n",
      "\tspeed: 0.0244s/iter; left time: 19.9048s\n",
      "\titers: 700, epoch: 5 | loss: 0.1570954\n",
      "\tspeed: 0.0246s/iter; left time: 17.5722s\n",
      "Epoch: 5 cost time: 17.84394860267639\n",
      "Epoch: 5, Steps: 707 | Train Loss: 0.1614289 Vali Loss: 0.3191210 Test Loss: 0.2433257\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2862533\n",
      "\tspeed: 0.0573s/iter; left time: 34.8211s\n",
      "\titers: 200, epoch: 6 | loss: 0.1610891\n",
      "\tspeed: 0.0250s/iter; left time: 12.7114s\n",
      "\titers: 300, epoch: 6 | loss: 0.1552901\n",
      "\tspeed: 0.0249s/iter; left time: 10.1724s\n",
      "\titers: 400, epoch: 6 | loss: 0.1426588\n",
      "\tspeed: 0.0246s/iter; left time: 7.5795s\n",
      "\titers: 500, epoch: 6 | loss: 0.1016404\n",
      "\tspeed: 0.0249s/iter; left time: 5.1889s\n",
      "\titers: 600, epoch: 6 | loss: 0.1821592\n",
      "\tspeed: 0.0263s/iter; left time: 2.8364s\n",
      "\titers: 700, epoch: 6 | loss: 0.1188483\n",
      "\tspeed: 0.0245s/iter; left time: 0.1960s\n",
      "Epoch: 6 cost time: 17.817920923233032\n",
      "Epoch: 6, Steps: 707 | Train Loss: 0.1564801 Vali Loss: 0.3141914 Test Loss: 0.2393989\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "Test cost time: 1.7597s\n",
      "test shape: (192, 32, 6, 1) (192, 32, 6, 1)\n",
      "test shape: (6144, 6, 1) (6144, 6, 1)\n",
      "mse:0.24619068205356598, mae:0.32886335253715515\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1685.8585205078125\n",
      "MAE:  27.213865280151367\n",
      "RMSE: 41.059207916259766\n",
      "MAPE: 0.33019569516181946\n",
      "MSPE: 0.5152744650840759\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24491\n",
      "[DEBUG] Original dataset length: 24491\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22641\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3447\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "\titers: 100, epoch: 1 | loss: 0.2624912\n",
      "\tspeed: 0.0247s/iter; left time: 102.1436s\n",
      "\titers: 200, epoch: 1 | loss: 0.2369553\n",
      "\tspeed: 0.0237s/iter; left time: 95.7844s\n",
      "\titers: 300, epoch: 1 | loss: 0.2169856\n",
      "\tspeed: 0.0269s/iter; left time: 106.0649s\n",
      "\titers: 400, epoch: 1 | loss: 0.3148388\n",
      "\tspeed: 0.0247s/iter; left time: 94.9850s\n",
      "\titers: 500, epoch: 1 | loss: 0.3694952\n",
      "\tspeed: 0.0245s/iter; left time: 91.7928s\n",
      "\titers: 600, epoch: 1 | loss: 0.2361464\n",
      "\tspeed: 0.0243s/iter; left time: 88.4088s\n",
      "\titers: 700, epoch: 1 | loss: 0.2035276\n",
      "\tspeed: 0.0239s/iter; left time: 84.7495s\n",
      "Epoch: 1 cost time: 17.432974576950073\n",
      "Epoch: 1, Steps: 707 | Train Loss: 0.2721716 Vali Loss: 0.3411190 Test Loss: 0.2728106\n",
      "Validation loss decreased (inf --> 0.341119).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2627454\n",
      "\tspeed: 0.0554s/iter; left time: 190.4766s\n",
      "\titers: 200, epoch: 2 | loss: 0.2151890\n",
      "\tspeed: 0.0247s/iter; left time: 82.5313s\n",
      "\titers: 300, epoch: 2 | loss: 0.1368666\n",
      "\tspeed: 0.0238s/iter; left time: 76.9915s\n",
      "\titers: 400, epoch: 2 | loss: 0.1597940\n",
      "\tspeed: 0.0240s/iter; left time: 75.1395s\n",
      "\titers: 500, epoch: 2 | loss: 0.1648803\n",
      "\tspeed: 0.0240s/iter; left time: 72.7135s\n",
      "\titers: 600, epoch: 2 | loss: 0.1642832\n",
      "\tspeed: 0.0242s/iter; left time: 71.1399s\n",
      "\titers: 700, epoch: 2 | loss: 0.2267364\n",
      "\tspeed: 0.0258s/iter; left time: 73.2197s\n",
      "Epoch: 2 cost time: 17.420536994934082\n",
      "Epoch: 2, Steps: 707 | Train Loss: 0.2112080 Vali Loss: 0.3273308 Test Loss: 0.2597895\n",
      "Validation loss decreased (0.341119 --> 0.327331).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1678623\n",
      "\tspeed: 0.0525s/iter; left time: 143.2082s\n",
      "\titers: 200, epoch: 3 | loss: 0.1520821\n",
      "\tspeed: 0.0240s/iter; left time: 63.2254s\n",
      "\titers: 300, epoch: 3 | loss: 0.1390667\n",
      "\tspeed: 0.0239s/iter; left time: 60.3851s\n",
      "\titers: 400, epoch: 3 | loss: 0.1898718\n",
      "\tspeed: 0.0236s/iter; left time: 57.3212s\n",
      "\titers: 500, epoch: 3 | loss: 0.1458736\n",
      "\tspeed: 0.0273s/iter; left time: 63.5776s\n",
      "\titers: 600, epoch: 3 | loss: 0.1588878\n",
      "\tspeed: 0.0243s/iter; left time: 54.1518s\n",
      "\titers: 700, epoch: 3 | loss: 0.1248506\n",
      "\tspeed: 0.0239s/iter; left time: 50.9163s\n",
      "Epoch: 3 cost time: 17.257029056549072\n",
      "Epoch: 3, Steps: 707 | Train Loss: 0.1826997 Vali Loss: 0.3161964 Test Loss: 0.2429049\n",
      "Validation loss decreased (0.327331 --> 0.316196).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1300473\n",
      "\tspeed: 0.0538s/iter; left time: 108.7439s\n",
      "\titers: 200, epoch: 4 | loss: 0.1548194\n",
      "\tspeed: 0.0247s/iter; left time: 47.4614s\n",
      "\titers: 300, epoch: 4 | loss: 0.1670357\n",
      "\tspeed: 0.0281s/iter; left time: 51.1900s\n",
      "\titers: 400, epoch: 4 | loss: 0.2520872\n",
      "\tspeed: 0.0245s/iter; left time: 42.2644s\n",
      "\titers: 500, epoch: 4 | loss: 0.1647621\n",
      "\tspeed: 0.0241s/iter; left time: 39.1399s\n",
      "\titers: 600, epoch: 4 | loss: 0.1650347\n",
      "\tspeed: 0.0239s/iter; left time: 36.3445s\n",
      "\titers: 700, epoch: 4 | loss: 0.3114057\n",
      "\tspeed: 0.0250s/iter; left time: 35.6043s\n",
      "Epoch: 4 cost time: 17.64459538459778\n",
      "Epoch: 4, Steps: 707 | Train Loss: 0.1690125 Vali Loss: 0.3120865 Test Loss: 0.2389791\n",
      "Validation loss decreased (0.316196 --> 0.312086).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1810688\n",
      "\tspeed: 0.0559s/iter; left time: 73.4740s\n",
      "\titers: 200, epoch: 5 | loss: 0.1316139\n",
      "\tspeed: 0.0238s/iter; left time: 28.9762s\n",
      "\titers: 300, epoch: 5 | loss: 0.1087866\n",
      "\tspeed: 0.0237s/iter; left time: 26.4241s\n",
      "\titers: 400, epoch: 5 | loss: 0.1764771\n",
      "\tspeed: 0.0231s/iter; left time: 23.4650s\n",
      "\titers: 500, epoch: 5 | loss: 0.1000698\n",
      "\tspeed: 0.0239s/iter; left time: 21.9102s\n",
      "\titers: 600, epoch: 5 | loss: 0.1314719\n",
      "\tspeed: 0.0235s/iter; left time: 19.1204s\n",
      "\titers: 700, epoch: 5 | loss: 0.1175073\n",
      "\tspeed: 0.0285s/iter; left time: 20.3848s\n",
      "Epoch: 5 cost time: 17.420719623565674\n",
      "Epoch: 5, Steps: 707 | Train Loss: 0.1604316 Vali Loss: 0.3101284 Test Loss: 0.2367099\n",
      "Validation loss decreased (0.312086 --> 0.310128).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1360691\n",
      "\tspeed: 0.0548s/iter; left time: 33.3245s\n",
      "\titers: 200, epoch: 6 | loss: 0.1458851\n",
      "\tspeed: 0.0245s/iter; left time: 12.4490s\n",
      "\titers: 300, epoch: 6 | loss: 0.1260959\n",
      "\tspeed: 0.0241s/iter; left time: 9.8445s\n",
      "\titers: 400, epoch: 6 | loss: 0.1483242\n",
      "\tspeed: 0.0249s/iter; left time: 7.6841s\n",
      "\titers: 500, epoch: 6 | loss: 0.1880873\n",
      "\tspeed: 0.0255s/iter; left time: 5.3076s\n",
      "\titers: 600, epoch: 6 | loss: 0.1582057\n",
      "\tspeed: 0.0241s/iter; left time: 2.6006s\n",
      "\titers: 700, epoch: 6 | loss: 0.1079631\n",
      "\tspeed: 0.0241s/iter; left time: 0.1928s\n",
      "Epoch: 6 cost time: 17.429052352905273\n",
      "Epoch: 6, Steps: 707 | Train Loss: 0.1559147 Vali Loss: 0.3082407 Test Loss: 0.2395293\n",
      "Validation loss decreased (0.310128 --> 0.308241).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "Test cost time: 1.7133s\n",
      "test shape: (192, 32, 6, 1) (192, 32, 6, 1)\n",
      "test shape: (6144, 6, 1) (6144, 6, 1)\n",
      "mse:0.23957432806491852, mae:0.3197039067745209\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1640.55126953125\n",
      "MAE:  26.45590591430664\n",
      "RMSE: 40.503719329833984\n",
      "MAPE: 0.31858599185943604\n",
      "MSPE: 0.47728538513183594\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24491\n",
      "[DEBUG] Original dataset length: 24491\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22641\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3447\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "\titers: 100, epoch: 1 | loss: 0.4347847\n",
      "\tspeed: 0.0255s/iter; left time: 105.7032s\n",
      "\titers: 200, epoch: 1 | loss: 0.2799309\n",
      "\tspeed: 0.0263s/iter; left time: 106.3076s\n",
      "\titers: 300, epoch: 1 | loss: 0.1381925\n",
      "\tspeed: 0.0241s/iter; left time: 94.8367s\n",
      "\titers: 400, epoch: 1 | loss: 0.2589496\n",
      "\tspeed: 0.0239s/iter; left time: 91.8054s\n",
      "\titers: 500, epoch: 1 | loss: 0.1651228\n",
      "\tspeed: 0.0257s/iter; left time: 96.0346s\n",
      "\titers: 600, epoch: 1 | loss: 0.1733509\n",
      "\tspeed: 0.0245s/iter; left time: 89.2646s\n",
      "\titers: 700, epoch: 1 | loss: 0.2441595\n",
      "\tspeed: 0.0245s/iter; left time: 86.8490s\n",
      "Epoch: 1 cost time: 17.64698362350464\n",
      "Epoch: 1, Steps: 707 | Train Loss: 0.2739784 Vali Loss: 0.3525349 Test Loss: 0.2802344\n",
      "Validation loss decreased (inf --> 0.352535).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1569619\n",
      "\tspeed: 0.0571s/iter; left time: 196.2650s\n",
      "\titers: 200, epoch: 2 | loss: 0.2432044\n",
      "\tspeed: 0.0240s/iter; left time: 80.0048s\n",
      "\titers: 300, epoch: 2 | loss: 0.1202563\n",
      "\tspeed: 0.0241s/iter; left time: 77.9889s\n",
      "\titers: 400, epoch: 2 | loss: 0.1763499\n",
      "\tspeed: 0.0240s/iter; left time: 75.4032s\n",
      "\titers: 500, epoch: 2 | loss: 0.1657115\n",
      "\tspeed: 0.0243s/iter; left time: 73.6679s\n",
      "\titers: 600, epoch: 2 | loss: 0.2131277\n",
      "\tspeed: 0.0255s/iter; left time: 74.8286s\n",
      "\titers: 700, epoch: 2 | loss: 0.1473228\n",
      "\tspeed: 0.0254s/iter; left time: 72.0566s\n",
      "Epoch: 2 cost time: 17.419663906097412\n",
      "Epoch: 2, Steps: 707 | Train Loss: 0.2136463 Vali Loss: 0.3185003 Test Loss: 0.2460039\n",
      "Validation loss decreased (0.352535 --> 0.318500).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2504796\n",
      "\tspeed: 0.0530s/iter; left time: 144.6367s\n",
      "\titers: 200, epoch: 3 | loss: 0.1585726\n",
      "\tspeed: 0.0236s/iter; left time: 61.9374s\n",
      "\titers: 300, epoch: 3 | loss: 0.1674569\n",
      "\tspeed: 0.0253s/iter; left time: 64.0779s\n",
      "\titers: 400, epoch: 3 | loss: 0.1519075\n",
      "\tspeed: 0.0261s/iter; left time: 63.4324s\n",
      "\titers: 500, epoch: 3 | loss: 0.1065861\n",
      "\tspeed: 0.0250s/iter; left time: 58.1165s\n",
      "\titers: 600, epoch: 3 | loss: 0.1400174\n",
      "\tspeed: 0.0250s/iter; left time: 55.7403s\n",
      "\titers: 700, epoch: 3 | loss: 0.2040760\n",
      "\tspeed: 0.0245s/iter; left time: 52.1000s\n",
      "Epoch: 3 cost time: 17.56024694442749\n",
      "Epoch: 3, Steps: 707 | Train Loss: 0.1838965 Vali Loss: 0.3228337 Test Loss: 0.2455083\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3292779\n",
      "\tspeed: 0.0531s/iter; left time: 107.3606s\n",
      "\titers: 200, epoch: 4 | loss: 0.1572879\n",
      "\tspeed: 0.0273s/iter; left time: 52.4479s\n",
      "\titers: 300, epoch: 4 | loss: 0.1893162\n",
      "\tspeed: 0.0269s/iter; left time: 48.9792s\n",
      "\titers: 400, epoch: 4 | loss: 0.1697016\n",
      "\tspeed: 0.0322s/iter; left time: 55.5004s\n",
      "\titers: 500, epoch: 4 | loss: 0.1870130\n",
      "\tspeed: 0.0272s/iter; left time: 44.1895s\n",
      "\titers: 600, epoch: 4 | loss: 0.1696181\n",
      "\tspeed: 0.0259s/iter; left time: 39.4652s\n",
      "\titers: 700, epoch: 4 | loss: 0.2477964\n",
      "\tspeed: 0.0270s/iter; left time: 38.4534s\n",
      "Epoch: 4 cost time: 19.42985439300537\n",
      "Epoch: 4, Steps: 707 | Train Loss: 0.1699004 Vali Loss: 0.3286503 Test Loss: 0.2577085\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2063034\n",
      "\tspeed: 0.0525s/iter; left time: 69.0373s\n",
      "\titers: 200, epoch: 5 | loss: 0.1278777\n",
      "\tspeed: 0.0230s/iter; left time: 27.9401s\n",
      "\titers: 300, epoch: 5 | loss: 0.1492589\n",
      "\tspeed: 0.0234s/iter; left time: 26.0460s\n",
      "\titers: 400, epoch: 5 | loss: 0.1562801\n",
      "\tspeed: 0.0236s/iter; left time: 23.9998s\n",
      "\titers: 500, epoch: 5 | loss: 0.1800235\n",
      "\tspeed: 0.0265s/iter; left time: 24.2418s\n",
      "\titers: 600, epoch: 5 | loss: 0.2775350\n",
      "\tspeed: 0.0246s/iter; left time: 20.0873s\n",
      "\titers: 700, epoch: 5 | loss: 0.2317110\n",
      "\tspeed: 0.0244s/iter; left time: 17.4782s\n",
      "Epoch: 5 cost time: 17.156316995620728\n",
      "Epoch: 5, Steps: 707 | Train Loss: 0.1625201 Vali Loss: 0.3087347 Test Loss: 0.2455607\n",
      "Validation loss decreased (0.318500 --> 0.308735).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1463667\n",
      "\tspeed: 0.0544s/iter; left time: 33.1012s\n",
      "\titers: 200, epoch: 6 | loss: 0.1767887\n",
      "\tspeed: 0.0248s/iter; left time: 12.5852s\n",
      "\titers: 300, epoch: 6 | loss: 0.3152606\n",
      "\tspeed: 0.0255s/iter; left time: 10.3891s\n",
      "\titers: 400, epoch: 6 | loss: 0.2291121\n",
      "\tspeed: 0.0245s/iter; left time: 7.5596s\n",
      "\titers: 500, epoch: 6 | loss: 0.0999497\n",
      "\tspeed: 0.0237s/iter; left time: 4.9205s\n",
      "\titers: 600, epoch: 6 | loss: 0.3937173\n",
      "\tspeed: 0.0241s/iter; left time: 2.5978s\n",
      "\titers: 700, epoch: 6 | loss: 0.0919181\n",
      "\tspeed: 0.0230s/iter; left time: 0.1841s\n",
      "Epoch: 6 cost time: 17.248618602752686\n",
      "Epoch: 6, Steps: 707 | Train Loss: 0.1562946 Vali Loss: 0.3124709 Test Loss: 0.2443756\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "Test cost time: 1.8130s\n",
      "test shape: (192, 32, 6, 1) (192, 32, 6, 1)\n",
      "test shape: (6144, 6, 1) (6144, 6, 1)\n",
      "mse:0.24426259100437164, mae:0.3260432779788971\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1672.6552734375\n",
      "MAE:  26.980499267578125\n",
      "RMSE: 40.898109436035156\n",
      "MAPE: 0.34664440155029297\n",
      "MSPE: 0.5899494886398315\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24491\n",
      "[DEBUG] Original dataset length: 24491\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22641\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3447\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "\titers: 100, epoch: 1 | loss: 0.4444768\n",
      "\tspeed: 0.0242s/iter; left time: 100.3790s\n",
      "\titers: 200, epoch: 1 | loss: 0.1867145\n",
      "\tspeed: 0.0225s/iter; left time: 91.0537s\n",
      "\titers: 300, epoch: 1 | loss: 0.1943837\n",
      "\tspeed: 0.0242s/iter; left time: 95.5145s\n",
      "\titers: 400, epoch: 1 | loss: 0.2124525\n",
      "\tspeed: 0.0246s/iter; left time: 94.4245s\n",
      "\titers: 500, epoch: 1 | loss: 0.1608633\n",
      "\tspeed: 0.0239s/iter; left time: 89.3569s\n",
      "\titers: 600, epoch: 1 | loss: 0.1335092\n",
      "\tspeed: 0.0272s/iter; left time: 98.9934s\n",
      "\titers: 700, epoch: 1 | loss: 0.2394415\n",
      "\tspeed: 0.0245s/iter; left time: 86.8625s\n",
      "Epoch: 1 cost time: 17.29081630706787\n",
      "Epoch: 1, Steps: 707 | Train Loss: 0.2734672 Vali Loss: 0.3392263 Test Loss: 0.2619780\n",
      "Validation loss decreased (inf --> 0.339226).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2403276\n",
      "\tspeed: 0.0524s/iter; left time: 180.0361s\n",
      "\titers: 200, epoch: 2 | loss: 0.1553921\n",
      "\tspeed: 0.0232s/iter; left time: 77.3340s\n",
      "\titers: 300, epoch: 2 | loss: 0.2274613\n",
      "\tspeed: 0.0232s/iter; left time: 74.9185s\n",
      "\titers: 400, epoch: 2 | loss: 0.2178148\n",
      "\tspeed: 0.0256s/iter; left time: 80.3302s\n",
      "\titers: 500, epoch: 2 | loss: 0.2029242\n",
      "\tspeed: 0.0240s/iter; left time: 72.8762s\n",
      "\titers: 600, epoch: 2 | loss: 0.1173687\n",
      "\tspeed: 0.0251s/iter; left time: 73.6310s\n",
      "\titers: 700, epoch: 2 | loss: 0.3229123\n",
      "\tspeed: 0.0234s/iter; left time: 66.2569s\n",
      "Epoch: 2 cost time: 17.010798454284668\n",
      "Epoch: 2, Steps: 707 | Train Loss: 0.2123449 Vali Loss: 0.3260555 Test Loss: 0.2543950\n",
      "Validation loss decreased (0.339226 --> 0.326055).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1304518\n",
      "\tspeed: 0.0530s/iter; left time: 144.6212s\n",
      "\titers: 200, epoch: 3 | loss: 0.1404077\n",
      "\tspeed: 0.0266s/iter; left time: 69.8259s\n",
      "\titers: 300, epoch: 3 | loss: 0.1044299\n",
      "\tspeed: 0.0233s/iter; left time: 58.8345s\n",
      "\titers: 400, epoch: 3 | loss: 0.2172906\n",
      "\tspeed: 0.0237s/iter; left time: 57.6385s\n",
      "\titers: 500, epoch: 3 | loss: 0.1820336\n",
      "\tspeed: 0.0234s/iter; left time: 54.5105s\n",
      "\titers: 600, epoch: 3 | loss: 0.1431874\n",
      "\tspeed: 0.0234s/iter; left time: 52.2220s\n",
      "\titers: 700, epoch: 3 | loss: 0.2323357\n",
      "\tspeed: 0.0232s/iter; left time: 49.3209s\n",
      "Epoch: 3 cost time: 16.880901098251343\n",
      "Epoch: 3, Steps: 707 | Train Loss: 0.1836145 Vali Loss: 0.3317371 Test Loss: 0.2705674\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1609260\n",
      "\tspeed: 0.0547s/iter; left time: 110.6088s\n",
      "\titers: 200, epoch: 4 | loss: 0.1281888\n",
      "\tspeed: 0.0232s/iter; left time: 44.6697s\n",
      "\titers: 300, epoch: 4 | loss: 0.2045579\n",
      "\tspeed: 0.0233s/iter; left time: 42.3739s\n",
      "\titers: 400, epoch: 4 | loss: 0.1887595\n",
      "\tspeed: 0.0240s/iter; left time: 41.2490s\n",
      "\titers: 500, epoch: 4 | loss: 0.1701044\n",
      "\tspeed: 0.0241s/iter; left time: 39.1399s\n",
      "\titers: 600, epoch: 4 | loss: 0.1101347\n",
      "\tspeed: 0.0253s/iter; left time: 38.4570s\n",
      "\titers: 700, epoch: 4 | loss: 0.2121885\n",
      "\tspeed: 0.0246s/iter; left time: 35.0052s\n",
      "Epoch: 4 cost time: 17.065297603607178\n",
      "Epoch: 4, Steps: 707 | Train Loss: 0.1701137 Vali Loss: 0.3065315 Test Loss: 0.2452988\n",
      "Validation loss decreased (0.326055 --> 0.306532).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1337014\n",
      "\tspeed: 0.0515s/iter; left time: 67.7698s\n",
      "\titers: 200, epoch: 5 | loss: 0.1256626\n",
      "\tspeed: 0.0238s/iter; left time: 28.9429s\n",
      "\titers: 300, epoch: 5 | loss: 0.2063122\n",
      "\tspeed: 0.0227s/iter; left time: 25.3411s\n",
      "\titers: 400, epoch: 5 | loss: 0.1513298\n",
      "\tspeed: 0.0247s/iter; left time: 25.1048s\n",
      "\titers: 500, epoch: 5 | loss: 0.2019028\n",
      "\tspeed: 0.0247s/iter; left time: 22.5860s\n",
      "\titers: 600, epoch: 5 | loss: 0.0781524\n",
      "\tspeed: 0.0234s/iter; left time: 19.0626s\n",
      "\titers: 700, epoch: 5 | loss: 0.1288430\n",
      "\tspeed: 0.0231s/iter; left time: 16.5461s\n",
      "Epoch: 5 cost time: 16.85559582710266\n",
      "Epoch: 5, Steps: 707 | Train Loss: 0.1610021 Vali Loss: 0.3073981 Test Loss: 0.2417869\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2682326\n",
      "\tspeed: 0.0521s/iter; left time: 31.6622s\n",
      "\titers: 200, epoch: 6 | loss: 0.1734485\n",
      "\tspeed: 0.0256s/iter; left time: 12.9908s\n",
      "\titers: 300, epoch: 6 | loss: 0.1911126\n",
      "\tspeed: 0.0261s/iter; left time: 10.6465s\n",
      "\titers: 400, epoch: 6 | loss: 0.1840685\n",
      "\tspeed: 0.0239s/iter; left time: 7.3568s\n",
      "\titers: 500, epoch: 6 | loss: 0.1722349\n",
      "\tspeed: 0.0233s/iter; left time: 4.8416s\n",
      "\titers: 600, epoch: 6 | loss: 0.2045480\n",
      "\tspeed: 0.0237s/iter; left time: 2.5581s\n",
      "\titers: 700, epoch: 6 | loss: 0.2645633\n",
      "\tspeed: 0.0237s/iter; left time: 0.1900s\n",
      "Epoch: 6 cost time: 17.212225198745728\n",
      "Epoch: 6, Steps: 707 | Train Loss: 0.1559452 Vali Loss: 0.3009671 Test Loss: 0.2388863\n",
      "Validation loss decreased (0.306532 --> 0.300967).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "Test cost time: 1.7911s\n",
      "test shape: (192, 32, 6, 1) (192, 32, 6, 1)\n",
      "test shape: (6144, 6, 1) (6144, 6, 1)\n",
      "mse:0.23904983699321747, mae:0.33136463165283203\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1636.9595947265625\n",
      "MAE:  27.42085075378418\n",
      "RMSE: 40.45935821533203\n",
      "MAPE: 0.3696584701538086\n",
      "MSPE: 0.6598142981529236\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24491\n",
      "[DEBUG] Original dataset length: 24491\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22641\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3447\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "\titers: 100, epoch: 1 | loss: 0.2069304\n",
      "\tspeed: 0.0256s/iter; left time: 105.9648s\n",
      "\titers: 200, epoch: 1 | loss: 0.2207269\n",
      "\tspeed: 0.0259s/iter; left time: 104.5737s\n",
      "\titers: 300, epoch: 1 | loss: 0.1673749\n",
      "\tspeed: 0.0249s/iter; left time: 98.0354s\n",
      "\titers: 400, epoch: 1 | loss: 0.2241232\n",
      "\tspeed: 0.0244s/iter; left time: 93.7241s\n",
      "\titers: 500, epoch: 1 | loss: 0.1215394\n",
      "\tspeed: 0.0247s/iter; left time: 92.4298s\n",
      "\titers: 600, epoch: 1 | loss: 0.1740339\n",
      "\tspeed: 0.0257s/iter; left time: 93.5772s\n",
      "\titers: 700, epoch: 1 | loss: 0.2077230\n",
      "\tspeed: 0.0246s/iter; left time: 87.1827s\n",
      "Epoch: 1 cost time: 17.73860454559326\n",
      "Epoch: 1, Steps: 707 | Train Loss: 0.2760056 Vali Loss: 0.3381428 Test Loss: 0.2689813\n",
      "Validation loss decreased (inf --> 0.338143).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1603798\n",
      "\tspeed: 0.0507s/iter; left time: 174.3492s\n",
      "\titers: 200, epoch: 2 | loss: 0.1843710\n",
      "\tspeed: 0.0243s/iter; left time: 81.0943s\n",
      "\titers: 300, epoch: 2 | loss: 0.1770642\n",
      "\tspeed: 0.0229s/iter; left time: 74.2358s\n",
      "\titers: 400, epoch: 2 | loss: 0.1333831\n",
      "\tspeed: 0.0261s/iter; left time: 81.8177s\n",
      "\titers: 500, epoch: 2 | loss: 0.1778959\n",
      "\tspeed: 0.0230s/iter; left time: 69.8148s\n",
      "\titers: 600, epoch: 2 | loss: 0.0964809\n",
      "\tspeed: 0.0237s/iter; left time: 69.5971s\n",
      "\titers: 700, epoch: 2 | loss: 0.1615749\n",
      "\tspeed: 0.0236s/iter; left time: 67.0044s\n",
      "Epoch: 2 cost time: 16.84212851524353\n",
      "Epoch: 2, Steps: 707 | Train Loss: 0.2109457 Vali Loss: 0.3495789 Test Loss: 0.2724959\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1770540\n",
      "\tspeed: 0.0527s/iter; left time: 143.7675s\n",
      "\titers: 200, epoch: 3 | loss: 0.1440943\n",
      "\tspeed: 0.0253s/iter; left time: 66.5773s\n",
      "\titers: 300, epoch: 3 | loss: 0.1807164\n",
      "\tspeed: 0.0231s/iter; left time: 58.3442s\n",
      "\titers: 400, epoch: 3 | loss: 0.2671335\n",
      "\tspeed: 0.0235s/iter; left time: 57.1461s\n",
      "\titers: 500, epoch: 3 | loss: 0.1022030\n",
      "\tspeed: 0.0225s/iter; left time: 52.3981s\n",
      "\titers: 600, epoch: 3 | loss: 0.1648515\n",
      "\tspeed: 0.0231s/iter; left time: 51.3889s\n",
      "\titers: 700, epoch: 3 | loss: 0.1632743\n",
      "\tspeed: 0.0237s/iter; left time: 50.5155s\n",
      "Epoch: 3 cost time: 16.778504133224487\n",
      "Epoch: 3, Steps: 707 | Train Loss: 0.1847990 Vali Loss: 0.3105043 Test Loss: 0.2462937\n",
      "Validation loss decreased (0.338143 --> 0.310504).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0977050\n",
      "\tspeed: 0.0534s/iter; left time: 108.0356s\n",
      "\titers: 200, epoch: 4 | loss: 0.1873662\n",
      "\tspeed: 0.0235s/iter; left time: 45.1862s\n",
      "\titers: 300, epoch: 4 | loss: 0.1542448\n",
      "\tspeed: 0.0233s/iter; left time: 42.3914s\n",
      "\titers: 400, epoch: 4 | loss: 0.1173169\n",
      "\tspeed: 0.0226s/iter; left time: 38.9054s\n",
      "\titers: 500, epoch: 4 | loss: 0.1171046\n",
      "\tspeed: 0.0236s/iter; left time: 38.2048s\n",
      "\titers: 600, epoch: 4 | loss: 0.2594963\n",
      "\tspeed: 0.0253s/iter; left time: 38.4861s\n",
      "\titers: 700, epoch: 4 | loss: 0.1381603\n",
      "\tspeed: 0.0245s/iter; left time: 34.8425s\n",
      "Epoch: 4 cost time: 16.851014614105225\n",
      "Epoch: 4, Steps: 707 | Train Loss: 0.1701056 Vali Loss: 0.3061250 Test Loss: 0.2382746\n",
      "Validation loss decreased (0.310504 --> 0.306125).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1370104\n",
      "\tspeed: 0.0524s/iter; left time: 68.9699s\n",
      "\titers: 200, epoch: 5 | loss: 0.1258017\n",
      "\tspeed: 0.0235s/iter; left time: 28.5887s\n",
      "\titers: 300, epoch: 5 | loss: 0.1354257\n",
      "\tspeed: 0.0234s/iter; left time: 26.0853s\n",
      "\titers: 400, epoch: 5 | loss: 0.2373091\n",
      "\tspeed: 0.0246s/iter; left time: 25.0187s\n",
      "\titers: 500, epoch: 5 | loss: 0.2226449\n",
      "\tspeed: 0.0244s/iter; left time: 22.3581s\n",
      "\titers: 600, epoch: 5 | loss: 0.1507330\n",
      "\tspeed: 0.0244s/iter; left time: 19.9000s\n",
      "\titers: 700, epoch: 5 | loss: 0.1192460\n",
      "\tspeed: 0.0236s/iter; left time: 16.8656s\n",
      "Epoch: 5 cost time: 16.966277360916138\n",
      "Epoch: 5, Steps: 707 | Train Loss: 0.1602845 Vali Loss: 0.3132819 Test Loss: 0.2416231\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1146820\n",
      "\tspeed: 0.0514s/iter; left time: 31.2534s\n",
      "\titers: 200, epoch: 6 | loss: 0.1561900\n",
      "\tspeed: 0.0260s/iter; left time: 13.2223s\n",
      "\titers: 300, epoch: 6 | loss: 0.1411964\n",
      "\tspeed: 0.0253s/iter; left time: 10.3384s\n",
      "\titers: 400, epoch: 6 | loss: 0.1901719\n",
      "\tspeed: 0.0241s/iter; left time: 7.4149s\n",
      "\titers: 500, epoch: 6 | loss: 0.0970124\n",
      "\tspeed: 0.0238s/iter; left time: 4.9576s\n",
      "\titers: 600, epoch: 6 | loss: 0.1240107\n",
      "\tspeed: 0.0245s/iter; left time: 2.6412s\n",
      "\titers: 700, epoch: 6 | loss: 0.1784009\n",
      "\tspeed: 0.0230s/iter; left time: 0.1842s\n",
      "Epoch: 6 cost time: 17.218780040740967\n",
      "Epoch: 6, Steps: 707 | Train Loss: 0.1550268 Vali Loss: 0.3082604 Test Loss: 0.2409915\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "Test cost time: 1.5155s\n",
      "test shape: (192, 32, 6, 1) (192, 32, 6, 1)\n",
      "test shape: (6144, 6, 1) (6144, 6, 1)\n",
      "mse:0.2383483201265335, mae:0.32866477966308594\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1632.15576171875\n",
      "MAE:  27.197431564331055\n",
      "RMSE: 40.39994812011719\n",
      "MAPE: 0.3533102869987488\n",
      "MSPE: 0.601075291633606\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24491\n",
      "[DEBUG] Original dataset length: 24491\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22641\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3447\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "\titers: 100, epoch: 1 | loss: 0.3443511\n",
      "\tspeed: 0.0218s/iter; left time: 90.4828s\n",
      "\titers: 200, epoch: 1 | loss: 0.3228079\n",
      "\tspeed: 0.0227s/iter; left time: 91.6936s\n",
      "\titers: 300, epoch: 1 | loss: 0.2898109\n",
      "\tspeed: 0.0238s/iter; left time: 93.8525s\n",
      "\titers: 400, epoch: 1 | loss: 0.2541541\n",
      "\tspeed: 0.0237s/iter; left time: 91.1528s\n",
      "\titers: 500, epoch: 1 | loss: 0.1554191\n",
      "\tspeed: 0.0221s/iter; left time: 82.8579s\n",
      "\titers: 600, epoch: 1 | loss: 0.1276112\n",
      "\tspeed: 0.0256s/iter; left time: 93.2910s\n",
      "\titers: 700, epoch: 1 | loss: 0.1918742\n",
      "\tspeed: 0.0239s/iter; left time: 84.5402s\n",
      "Epoch: 1 cost time: 16.56454825401306\n",
      "Epoch: 1, Steps: 707 | Train Loss: 0.2702211 Vali Loss: 0.3436641 Test Loss: 0.2692783\n",
      "Validation loss decreased (inf --> 0.343664).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3337280\n",
      "\tspeed: 0.0501s/iter; left time: 172.2597s\n",
      "\titers: 200, epoch: 2 | loss: 0.1512230\n",
      "\tspeed: 0.0231s/iter; left time: 77.0985s\n",
      "\titers: 300, epoch: 2 | loss: 0.1764552\n",
      "\tspeed: 0.0224s/iter; left time: 72.3926s\n",
      "\titers: 400, epoch: 2 | loss: 0.1551416\n",
      "\tspeed: 0.0259s/iter; left time: 81.0791s\n",
      "\titers: 500, epoch: 2 | loss: 0.1714434\n",
      "\tspeed: 0.0243s/iter; left time: 73.8643s\n",
      "\titers: 600, epoch: 2 | loss: 0.2570945\n",
      "\tspeed: 0.0234s/iter; left time: 68.6536s\n",
      "\titers: 700, epoch: 2 | loss: 0.1650399\n",
      "\tspeed: 0.0235s/iter; left time: 66.7167s\n",
      "Epoch: 2 cost time: 16.725465536117554\n",
      "Epoch: 2, Steps: 707 | Train Loss: 0.2118833 Vali Loss: 0.3238188 Test Loss: 0.2478859\n",
      "Validation loss decreased (0.343664 --> 0.323819).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1234771\n",
      "\tspeed: 0.0511s/iter; left time: 139.4234s\n",
      "\titers: 200, epoch: 3 | loss: 0.1362148\n",
      "\tspeed: 0.0238s/iter; left time: 62.5958s\n",
      "\titers: 300, epoch: 3 | loss: 0.1341481\n",
      "\tspeed: 0.0253s/iter; left time: 63.9616s\n",
      "\titers: 400, epoch: 3 | loss: 0.1355446\n",
      "\tspeed: 0.0230s/iter; left time: 55.9349s\n",
      "\titers: 500, epoch: 3 | loss: 0.1282422\n",
      "\tspeed: 0.0234s/iter; left time: 54.5296s\n",
      "\titers: 600, epoch: 3 | loss: 0.1581760\n",
      "\tspeed: 0.0227s/iter; left time: 50.5047s\n",
      "\titers: 700, epoch: 3 | loss: 0.2171392\n",
      "\tspeed: 0.0232s/iter; left time: 49.3969s\n",
      "Epoch: 3 cost time: 16.712137699127197\n",
      "Epoch: 3, Steps: 707 | Train Loss: 0.1853145 Vali Loss: 0.3132448 Test Loss: 0.2397132\n",
      "Validation loss decreased (0.323819 --> 0.313245).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1348236\n",
      "\tspeed: 0.0539s/iter; left time: 109.0465s\n",
      "\titers: 200, epoch: 4 | loss: 0.2336283\n",
      "\tspeed: 0.0236s/iter; left time: 45.3641s\n",
      "\titers: 300, epoch: 4 | loss: 0.2336453\n",
      "\tspeed: 0.0237s/iter; left time: 43.1377s\n",
      "\titers: 400, epoch: 4 | loss: 0.2518083\n",
      "\tspeed: 0.0253s/iter; left time: 43.5671s\n",
      "\titers: 500, epoch: 4 | loss: 0.2181557\n",
      "\tspeed: 0.0244s/iter; left time: 39.5160s\n",
      "\titers: 600, epoch: 4 | loss: 0.2393189\n",
      "\tspeed: 0.0236s/iter; left time: 35.9545s\n",
      "\titers: 700, epoch: 4 | loss: 0.1496485\n",
      "\tspeed: 0.0265s/iter; left time: 37.6639s\n",
      "Epoch: 4 cost time: 17.400020122528076\n",
      "Epoch: 4, Steps: 707 | Train Loss: 0.1706601 Vali Loss: 0.3098186 Test Loss: 0.2318932\n",
      "Validation loss decreased (0.313245 --> 0.309819).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1557507\n",
      "\tspeed: 0.0525s/iter; left time: 69.0382s\n",
      "\titers: 200, epoch: 5 | loss: 0.1737061\n",
      "\tspeed: 0.0237s/iter; left time: 28.8223s\n",
      "\titers: 300, epoch: 5 | loss: 0.1028371\n",
      "\tspeed: 0.0235s/iter; left time: 26.2452s\n",
      "\titers: 400, epoch: 5 | loss: 0.1671810\n",
      "\tspeed: 0.0258s/iter; left time: 26.1908s\n",
      "\titers: 500, epoch: 5 | loss: 0.1786633\n",
      "\tspeed: 0.0272s/iter; left time: 24.9169s\n",
      "\titers: 600, epoch: 5 | loss: 0.1797329\n",
      "\tspeed: 0.0262s/iter; left time: 21.3128s\n",
      "\titers: 700, epoch: 5 | loss: 0.1907196\n",
      "\tspeed: 0.0251s/iter; left time: 17.9716s\n",
      "Epoch: 5 cost time: 17.654631853103638\n",
      "Epoch: 5, Steps: 707 | Train Loss: 0.1615465 Vali Loss: 0.3163817 Test Loss: 0.2401454\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1628708\n",
      "\tspeed: 0.0533s/iter; left time: 32.4055s\n",
      "\titers: 200, epoch: 6 | loss: 0.2006470\n",
      "\tspeed: 0.0264s/iter; left time: 13.4283s\n",
      "\titers: 300, epoch: 6 | loss: 0.1438445\n",
      "\tspeed: 0.0261s/iter; left time: 10.6555s\n",
      "\titers: 400, epoch: 6 | loss: 0.1193108\n",
      "\tspeed: 0.0264s/iter; left time: 8.1326s\n",
      "\titers: 500, epoch: 6 | loss: 0.1528928\n",
      "\tspeed: 0.0254s/iter; left time: 5.2930s\n",
      "\titers: 600, epoch: 6 | loss: 0.1361716\n",
      "\tspeed: 0.0266s/iter; left time: 2.8748s\n",
      "\titers: 700, epoch: 6 | loss: 0.0988534\n",
      "\tspeed: 0.0259s/iter; left time: 0.2072s\n",
      "Epoch: 6 cost time: 18.431868076324463\n",
      "Epoch: 6, Steps: 707 | Train Loss: 0.1564602 Vali Loss: 0.3133753 Test Loss: 0.2398692\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "Test cost time: 1.7423s\n",
      "test shape: (192, 32, 6, 1) (192, 32, 6, 1)\n",
      "test shape: (6144, 6, 1) (6144, 6, 1)\n",
      "mse:0.2314179241657257, mae:0.32282671332359314\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1584.69775390625\n",
      "MAE:  26.714326858520508\n",
      "RMSE: 39.80826187133789\n",
      "MAPE: 0.35564878582954407\n",
      "MSPE: 0.6074320077896118\n",
      ">>>>>>>Running time saved<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Running seq_len=72\n",
      "Args in experiment:\n",
      "Namespace(model='informer', data='traffic_full', root_path='../', data_path='traffic_full.csv', features='S', target='flow', freq='h', checkpoints='./checkpoints/', seq_len=72, label_len=24, pred_len=6, enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=2, d_layers=1, s_layers=[3, 2, 1], d_ff=2048, factor=5, padding=0, distil=True, dropout=0.05, attn='prob', embed='timeF', activation='gelu', output_attention=False, do_predict=False, mix=True, cols=None, num_workers=0, itr=10, train_epochs=6, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, inverse=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', detail_freq='h')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24467\n",
      "[DEBUG] Original dataset length: 24467\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22233\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3423\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "\titers: 100, epoch: 1 | loss: 0.3409803\n",
      "\tspeed: 0.0419s/iter; left time: 170.1732s\n",
      "\titers: 200, epoch: 1 | loss: 0.3249234\n",
      "\tspeed: 0.0271s/iter; left time: 107.4833s\n",
      "\titers: 300, epoch: 1 | loss: 0.3158022\n",
      "\tspeed: 0.0279s/iter; left time: 107.8389s\n",
      "\titers: 400, epoch: 1 | loss: 0.2243023\n",
      "\tspeed: 0.0275s/iter; left time: 103.3922s\n",
      "\titers: 500, epoch: 1 | loss: 0.1964700\n",
      "\tspeed: 0.0283s/iter; left time: 103.5904s\n",
      "\titers: 600, epoch: 1 | loss: 0.1899345\n",
      "\tspeed: 0.0273s/iter; left time: 97.4365s\n",
      "Epoch: 1 cost time: 19.748058080673218\n",
      "Epoch: 1, Steps: 694 | Train Loss: 0.2750601 Vali Loss: 0.3228438 Test Loss: 0.2607255\n",
      "Validation loss decreased (inf --> 0.322844).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1707512\n",
      "\tspeed: 0.0870s/iter; left time: 293.2824s\n",
      "\titers: 200, epoch: 2 | loss: 0.2462886\n",
      "\tspeed: 0.0275s/iter; left time: 90.0039s\n",
      "\titers: 300, epoch: 2 | loss: 0.1854431\n",
      "\tspeed: 0.0274s/iter; left time: 86.9603s\n",
      "\titers: 400, epoch: 2 | loss: 0.1778743\n",
      "\tspeed: 0.0273s/iter; left time: 83.8823s\n",
      "\titers: 500, epoch: 2 | loss: 0.2379427\n",
      "\tspeed: 0.0277s/iter; left time: 82.3826s\n",
      "\titers: 600, epoch: 2 | loss: 0.1998719\n",
      "\tspeed: 0.0292s/iter; left time: 83.7152s\n",
      "Epoch: 2 cost time: 19.411123752593994\n",
      "Epoch: 2, Steps: 694 | Train Loss: 0.2093997 Vali Loss: 0.3249131 Test Loss: 0.2761189\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2533138\n",
      "\tspeed: 0.0828s/iter; left time: 221.6611s\n",
      "\titers: 200, epoch: 3 | loss: 0.1102644\n",
      "\tspeed: 0.0279s/iter; left time: 71.9019s\n",
      "\titers: 300, epoch: 3 | loss: 0.1108884\n",
      "\tspeed: 0.0293s/iter; left time: 72.5775s\n",
      "\titers: 400, epoch: 3 | loss: 0.1204173\n",
      "\tspeed: 0.0277s/iter; left time: 65.7980s\n",
      "\titers: 500, epoch: 3 | loss: 0.1953272\n",
      "\tspeed: 0.0256s/iter; left time: 58.3637s\n",
      "\titers: 600, epoch: 3 | loss: 0.1584853\n",
      "\tspeed: 0.0255s/iter; left time: 55.5185s\n",
      "Epoch: 3 cost time: 18.682666778564453\n",
      "Epoch: 3, Steps: 694 | Train Loss: 0.1826182 Vali Loss: 0.3059770 Test Loss: 0.2380106\n",
      "Validation loss decreased (0.322844 --> 0.305977).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1428984\n",
      "\tspeed: 0.0810s/iter; left time: 160.6471s\n",
      "\titers: 200, epoch: 4 | loss: 0.1095511\n",
      "\tspeed: 0.0264s/iter; left time: 49.7250s\n",
      "\titers: 300, epoch: 4 | loss: 0.1426825\n",
      "\tspeed: 0.0258s/iter; left time: 45.9454s\n",
      "\titers: 400, epoch: 4 | loss: 0.1223251\n",
      "\tspeed: 0.0254s/iter; left time: 42.7371s\n",
      "\titers: 500, epoch: 4 | loss: 0.1480007\n",
      "\tspeed: 0.0252s/iter; left time: 39.9684s\n",
      "\titers: 600, epoch: 4 | loss: 0.1286352\n",
      "\tspeed: 0.0272s/iter; left time: 40.2785s\n",
      "Epoch: 4 cost time: 18.2106716632843\n",
      "Epoch: 4, Steps: 694 | Train Loss: 0.1672368 Vali Loss: 0.3068192 Test Loss: 0.2370473\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1538067\n",
      "\tspeed: 0.0811s/iter; left time: 104.5716s\n",
      "\titers: 200, epoch: 5 | loss: 0.2235938\n",
      "\tspeed: 0.0257s/iter; left time: 30.5507s\n",
      "\titers: 300, epoch: 5 | loss: 0.2415203\n",
      "\tspeed: 0.0253s/iter; left time: 27.5554s\n",
      "\titers: 400, epoch: 5 | loss: 0.1012496\n",
      "\tspeed: 0.0284s/iter; left time: 28.0733s\n",
      "\titers: 500, epoch: 5 | loss: 0.1793437\n",
      "\tspeed: 0.0274s/iter; left time: 24.3861s\n",
      "\titers: 600, epoch: 5 | loss: 0.2219589\n",
      "\tspeed: 0.0267s/iter; left time: 21.0467s\n",
      "Epoch: 5 cost time: 18.526186227798462\n",
      "Epoch: 5, Steps: 694 | Train Loss: 0.1574704 Vali Loss: 0.3136614 Test Loss: 0.2434279\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1953224\n",
      "\tspeed: 0.0810s/iter; left time: 48.1692s\n",
      "\titers: 200, epoch: 6 | loss: 0.1743095\n",
      "\tspeed: 0.0276s/iter; left time: 13.6560s\n",
      "\titers: 300, epoch: 6 | loss: 0.1481417\n",
      "\tspeed: 0.0261s/iter; left time: 10.3109s\n",
      "\titers: 400, epoch: 6 | loss: 0.2112621\n",
      "\tspeed: 0.0272s/iter; left time: 8.0346s\n",
      "\titers: 500, epoch: 6 | loss: 0.0925858\n",
      "\tspeed: 0.0260s/iter; left time: 5.0689s\n",
      "\titers: 600, epoch: 6 | loss: 0.1559274\n",
      "\tspeed: 0.0262s/iter; left time: 2.4862s\n",
      "Epoch: 6 cost time: 18.769315719604492\n",
      "Epoch: 6, Steps: 694 | Train Loss: 0.1530985 Vali Loss: 0.3108674 Test Loss: 0.2368336\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "Test cost time: 1.7034s\n",
      "test shape: (187, 32, 6, 1) (187, 32, 6, 1)\n",
      "test shape: (5984, 6, 1) (5984, 6, 1)\n",
      "mse:0.23736533522605896, mae:0.33197182416915894\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1625.424560546875\n",
      "MAE:  27.47109603881836\n",
      "RMSE: 40.31655502319336\n",
      "MAPE: 0.3683173358440399\n",
      "MSPE: 0.6663653254508972\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24467\n",
      "[DEBUG] Original dataset length: 24467\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22233\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3423\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "\titers: 100, epoch: 1 | loss: 0.2554073\n",
      "\tspeed: 0.0259s/iter; left time: 105.1534s\n",
      "\titers: 200, epoch: 1 | loss: 0.2202873\n",
      "\tspeed: 0.0251s/iter; left time: 99.5296s\n",
      "\titers: 300, epoch: 1 | loss: 0.2358459\n",
      "\tspeed: 0.0248s/iter; left time: 95.9019s\n",
      "\titers: 400, epoch: 1 | loss: 0.5838127\n",
      "\tspeed: 0.0279s/iter; left time: 104.8645s\n",
      "\titers: 500, epoch: 1 | loss: 0.2087775\n",
      "\tspeed: 0.0262s/iter; left time: 95.8889s\n",
      "\titers: 600, epoch: 1 | loss: 0.1991445\n",
      "\tspeed: 0.0260s/iter; left time: 92.5773s\n",
      "Epoch: 1 cost time: 18.016213178634644\n",
      "Epoch: 1, Steps: 694 | Train Loss: 0.2838688 Vali Loss: 0.3665615 Test Loss: 0.2970460\n",
      "Validation loss decreased (inf --> 0.366561).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1751004\n",
      "\tspeed: 0.0779s/iter; left time: 262.4764s\n",
      "\titers: 200, epoch: 2 | loss: 0.1429845\n",
      "\tspeed: 0.0272s/iter; left time: 88.8617s\n",
      "\titers: 300, epoch: 2 | loss: 0.1636482\n",
      "\tspeed: 0.0257s/iter; left time: 81.3791s\n",
      "\titers: 400, epoch: 2 | loss: 0.1642084\n",
      "\tspeed: 0.0248s/iter; left time: 76.2046s\n",
      "\titers: 500, epoch: 2 | loss: 0.2900245\n",
      "\tspeed: 0.0263s/iter; left time: 78.1700s\n",
      "\titers: 600, epoch: 2 | loss: 0.1741308\n",
      "\tspeed: 0.0252s/iter; left time: 72.3686s\n",
      "Epoch: 2 cost time: 18.160690546035767\n",
      "Epoch: 2, Steps: 694 | Train Loss: 0.2112950 Vali Loss: 0.3247822 Test Loss: 0.2585439\n",
      "Validation loss decreased (0.366561 --> 0.324782).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3061223\n",
      "\tspeed: 0.0846s/iter; left time: 226.5510s\n",
      "\titers: 200, epoch: 3 | loss: 0.1641892\n",
      "\tspeed: 0.0288s/iter; left time: 74.1987s\n",
      "\titers: 300, epoch: 3 | loss: 0.1212871\n",
      "\tspeed: 0.0301s/iter; left time: 74.4933s\n",
      "\titers: 400, epoch: 3 | loss: 0.1567393\n",
      "\tspeed: 0.0288s/iter; left time: 68.5572s\n",
      "\titers: 500, epoch: 3 | loss: 0.2686582\n",
      "\tspeed: 0.0294s/iter; left time: 66.8648s\n",
      "\titers: 600, epoch: 3 | loss: 0.1277671\n",
      "\tspeed: 0.0291s/iter; left time: 63.4230s\n",
      "Epoch: 3 cost time: 19.98784589767456\n",
      "Epoch: 3, Steps: 694 | Train Loss: 0.1831953 Vali Loss: 0.3286192 Test Loss: 0.2463432\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1405466\n",
      "\tspeed: 0.0857s/iter; left time: 169.9159s\n",
      "\titers: 200, epoch: 4 | loss: 0.2673686\n",
      "\tspeed: 0.0292s/iter; left time: 54.9264s\n",
      "\titers: 300, epoch: 4 | loss: 0.1614974\n",
      "\tspeed: 0.0285s/iter; left time: 50.8447s\n",
      "\titers: 400, epoch: 4 | loss: 0.1259707\n",
      "\tspeed: 0.0296s/iter; left time: 49.8825s\n",
      "\titers: 500, epoch: 4 | loss: 0.3040917\n",
      "\tspeed: 0.0284s/iter; left time: 45.0010s\n",
      "\titers: 600, epoch: 4 | loss: 0.1425252\n",
      "\tspeed: 0.0287s/iter; left time: 42.6074s\n",
      "Epoch: 4 cost time: 20.323758840560913\n",
      "Epoch: 4, Steps: 694 | Train Loss: 0.1687365 Vali Loss: 0.3234550 Test Loss: 0.2470015\n",
      "Validation loss decreased (0.324782 --> 0.323455).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2250851\n",
      "\tspeed: 0.0880s/iter; left time: 113.4535s\n",
      "\titers: 200, epoch: 5 | loss: 0.2518476\n",
      "\tspeed: 0.0287s/iter; left time: 34.1789s\n",
      "\titers: 300, epoch: 5 | loss: 0.1178036\n",
      "\tspeed: 0.0281s/iter; left time: 30.5805s\n",
      "\titers: 400, epoch: 5 | loss: 0.1146093\n",
      "\tspeed: 0.0302s/iter; left time: 29.8830s\n",
      "\titers: 500, epoch: 5 | loss: 0.1415918\n",
      "\tspeed: 0.0288s/iter; left time: 25.5692s\n",
      "\titers: 600, epoch: 5 | loss: 0.2009168\n",
      "\tspeed: 0.0272s/iter; left time: 21.4348s\n",
      "Epoch: 5 cost time: 19.720893621444702\n",
      "Epoch: 5, Steps: 694 | Train Loss: 0.1607693 Vali Loss: 0.3145719 Test Loss: 0.2356632\n",
      "Validation loss decreased (0.323455 --> 0.314572).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2928079\n",
      "\tspeed: 0.0863s/iter; left time: 51.3447s\n",
      "\titers: 200, epoch: 6 | loss: 0.1930345\n",
      "\tspeed: 0.0284s/iter; left time: 14.0390s\n",
      "\titers: 300, epoch: 6 | loss: 0.1461954\n",
      "\tspeed: 0.0276s/iter; left time: 10.9211s\n",
      "\titers: 400, epoch: 6 | loss: 0.1396809\n",
      "\tspeed: 0.0282s/iter; left time: 8.3227s\n",
      "\titers: 500, epoch: 6 | loss: 0.1170337\n",
      "\tspeed: 0.0272s/iter; left time: 5.2955s\n",
      "\titers: 600, epoch: 6 | loss: 0.1873637\n",
      "\tspeed: 0.0284s/iter; left time: 2.7027s\n",
      "Epoch: 6 cost time: 19.623568058013916\n",
      "Epoch: 6, Steps: 694 | Train Loss: 0.1554905 Vali Loss: 0.3099656 Test Loss: 0.2400856\n",
      "Validation loss decreased (0.314572 --> 0.309966).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "Test cost time: 2.0154s\n",
      "test shape: (187, 32, 6, 1) (187, 32, 6, 1)\n",
      "test shape: (5984, 6, 1) (5984, 6, 1)\n",
      "mse:0.23947328329086304, mae:0.3311498761177063\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1639.859130859375\n",
      "MAE:  27.403078079223633\n",
      "RMSE: 40.495174407958984\n",
      "MAPE: 0.3791086673736572\n",
      "MSPE: 0.7401858568191528\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24467\n",
      "[DEBUG] Original dataset length: 24467\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22233\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3423\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "\titers: 100, epoch: 1 | loss: 0.2739085\n",
      "\tspeed: 0.0273s/iter; left time: 110.9584s\n",
      "\titers: 200, epoch: 1 | loss: 0.2268024\n",
      "\tspeed: 0.0281s/iter; left time: 111.2449s\n",
      "\titers: 300, epoch: 1 | loss: 0.2424552\n",
      "\tspeed: 0.0303s/iter; left time: 117.2250s\n",
      "\titers: 400, epoch: 1 | loss: 0.2597516\n",
      "\tspeed: 0.0278s/iter; left time: 104.6058s\n",
      "\titers: 500, epoch: 1 | loss: 0.1403150\n",
      "\tspeed: 0.0280s/iter; left time: 102.7568s\n",
      "\titers: 600, epoch: 1 | loss: 0.2060911\n",
      "\tspeed: 0.0282s/iter; left time: 100.6236s\n",
      "Epoch: 1 cost time: 19.63163137435913\n",
      "Epoch: 1, Steps: 694 | Train Loss: 0.2768373 Vali Loss: 0.3288804 Test Loss: 0.2575395\n",
      "Validation loss decreased (inf --> 0.328880).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2306541\n",
      "\tspeed: 0.0884s/iter; left time: 297.8774s\n",
      "\titers: 200, epoch: 2 | loss: 0.1454096\n",
      "\tspeed: 0.0286s/iter; left time: 93.6291s\n",
      "\titers: 300, epoch: 2 | loss: 0.1731234\n",
      "\tspeed: 0.0281s/iter; left time: 89.0816s\n",
      "\titers: 400, epoch: 2 | loss: 0.2206531\n",
      "\tspeed: 0.0279s/iter; left time: 85.6019s\n",
      "\titers: 500, epoch: 2 | loss: 0.2684555\n",
      "\tspeed: 0.0264s/iter; left time: 78.3981s\n",
      "\titers: 600, epoch: 2 | loss: 0.1268166\n",
      "\tspeed: 0.0298s/iter; left time: 85.4490s\n",
      "Epoch: 2 cost time: 19.592257976531982\n",
      "Epoch: 2, Steps: 694 | Train Loss: 0.2084381 Vali Loss: 0.3193984 Test Loss: 0.2598117\n",
      "Validation loss decreased (0.328880 --> 0.319398).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2393579\n",
      "\tspeed: 0.0846s/iter; left time: 226.5405s\n",
      "\titers: 200, epoch: 3 | loss: 0.1869743\n",
      "\tspeed: 0.0295s/iter; left time: 76.1458s\n",
      "\titers: 300, epoch: 3 | loss: 0.1416301\n",
      "\tspeed: 0.0290s/iter; left time: 71.8369s\n",
      "\titers: 400, epoch: 3 | loss: 0.2244770\n",
      "\tspeed: 0.0265s/iter; left time: 62.8909s\n",
      "\titers: 500, epoch: 3 | loss: 0.1632283\n",
      "\tspeed: 0.0258s/iter; left time: 58.7510s\n",
      "\titers: 600, epoch: 3 | loss: 0.1625172\n",
      "\tspeed: 0.0246s/iter; left time: 53.6216s\n",
      "Epoch: 3 cost time: 18.576581478118896\n",
      "Epoch: 3, Steps: 694 | Train Loss: 0.1811600 Vali Loss: 0.3258228 Test Loss: 0.2494970\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1378765\n",
      "\tspeed: 0.0773s/iter; left time: 153.2415s\n",
      "\titers: 200, epoch: 4 | loss: 0.1688460\n",
      "\tspeed: 0.0250s/iter; left time: 47.1456s\n",
      "\titers: 300, epoch: 4 | loss: 0.1946570\n",
      "\tspeed: 0.0247s/iter; left time: 44.0345s\n",
      "\titers: 400, epoch: 4 | loss: 0.1831186\n",
      "\tspeed: 0.0249s/iter; left time: 41.9562s\n",
      "\titers: 500, epoch: 4 | loss: 0.1160598\n",
      "\tspeed: 0.0246s/iter; left time: 38.8852s\n",
      "\titers: 600, epoch: 4 | loss: 0.1670714\n",
      "\tspeed: 0.0249s/iter; left time: 36.9523s\n",
      "Epoch: 4 cost time: 17.734740495681763\n",
      "Epoch: 4, Steps: 694 | Train Loss: 0.1670601 Vali Loss: 0.3034357 Test Loss: 0.2382189\n",
      "Validation loss decreased (0.319398 --> 0.303436).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1277345\n",
      "\tspeed: 0.0795s/iter; left time: 102.4213s\n",
      "\titers: 200, epoch: 5 | loss: 0.1664719\n",
      "\tspeed: 0.0259s/iter; left time: 30.7762s\n",
      "\titers: 300, epoch: 5 | loss: 0.0815004\n",
      "\tspeed: 0.0251s/iter; left time: 27.3194s\n",
      "\titers: 400, epoch: 5 | loss: 0.2226363\n",
      "\tspeed: 0.0270s/iter; left time: 26.6602s\n",
      "\titers: 500, epoch: 5 | loss: 0.2092995\n",
      "\tspeed: 0.0263s/iter; left time: 23.3563s\n",
      "\titers: 600, epoch: 5 | loss: 0.1025684\n",
      "\tspeed: 0.0279s/iter; left time: 22.0079s\n",
      "Epoch: 5 cost time: 18.31456756591797\n",
      "Epoch: 5, Steps: 694 | Train Loss: 0.1583078 Vali Loss: 0.3199582 Test Loss: 0.2430761\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1216970\n",
      "\tspeed: 0.0782s/iter; left time: 46.5537s\n",
      "\titers: 200, epoch: 6 | loss: 0.1207305\n",
      "\tspeed: 0.0279s/iter; left time: 13.8175s\n",
      "\titers: 300, epoch: 6 | loss: 0.2060488\n",
      "\tspeed: 0.0267s/iter; left time: 10.5390s\n",
      "\titers: 400, epoch: 6 | loss: 0.2013859\n",
      "\tspeed: 0.0271s/iter; left time: 8.0032s\n",
      "\titers: 500, epoch: 6 | loss: 0.0923580\n",
      "\tspeed: 0.0267s/iter; left time: 5.1997s\n",
      "\titers: 600, epoch: 6 | loss: 0.2225401\n",
      "\tspeed: 0.0278s/iter; left time: 2.6417s\n",
      "Epoch: 6 cost time: 18.669161558151245\n",
      "Epoch: 6, Steps: 694 | Train Loss: 0.1529242 Vali Loss: 0.3358340 Test Loss: 0.2455351\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "Test cost time: 1.7384s\n",
      "test shape: (187, 32, 6, 1) (187, 32, 6, 1)\n",
      "test shape: (5984, 6, 1) (5984, 6, 1)\n",
      "mse:0.2383033037185669, mae:0.32584506273269653\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1631.8475341796875\n",
      "MAE:  26.964096069335938\n",
      "RMSE: 40.39613342285156\n",
      "MAPE: 0.3437339961528778\n",
      "MSPE: 0.5634836554527283\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24467\n",
      "[DEBUG] Original dataset length: 24467\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22233\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3423\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "\titers: 100, epoch: 1 | loss: 0.2398250\n",
      "\tspeed: 0.0269s/iter; left time: 109.4991s\n",
      "\titers: 200, epoch: 1 | loss: 0.3750010\n",
      "\tspeed: 0.0261s/iter; left time: 103.4208s\n",
      "\titers: 300, epoch: 1 | loss: 0.3206716\n",
      "\tspeed: 0.0262s/iter; left time: 101.1402s\n",
      "\titers: 400, epoch: 1 | loss: 0.1452438\n",
      "\tspeed: 0.0273s/iter; left time: 102.7869s\n",
      "\titers: 500, epoch: 1 | loss: 0.3335423\n",
      "\tspeed: 0.0255s/iter; left time: 93.4649s\n",
      "\titers: 600, epoch: 1 | loss: 0.1938671\n",
      "\tspeed: 0.0250s/iter; left time: 89.2536s\n",
      "Epoch: 1 cost time: 18.194655179977417\n",
      "Epoch: 1, Steps: 694 | Train Loss: 0.2790796 Vali Loss: 0.3366759 Test Loss: 0.2627607\n",
      "Validation loss decreased (inf --> 0.336676).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1338491\n",
      "\tspeed: 0.0802s/iter; left time: 270.3508s\n",
      "\titers: 200, epoch: 2 | loss: 0.2062624\n",
      "\tspeed: 0.0277s/iter; left time: 90.5497s\n",
      "\titers: 300, epoch: 2 | loss: 0.1540320\n",
      "\tspeed: 0.0272s/iter; left time: 86.1765s\n",
      "\titers: 400, epoch: 2 | loss: 0.2014459\n",
      "\tspeed: 0.0275s/iter; left time: 84.5062s\n",
      "\titers: 500, epoch: 2 | loss: 0.1456095\n",
      "\tspeed: 0.0275s/iter; left time: 81.7812s\n",
      "\titers: 600, epoch: 2 | loss: 0.1376741\n",
      "\tspeed: 0.0273s/iter; left time: 78.4247s\n",
      "Epoch: 2 cost time: 19.029186248779297\n",
      "Epoch: 2, Steps: 694 | Train Loss: 0.2088604 Vali Loss: 0.3284555 Test Loss: 0.2662525\n",
      "Validation loss decreased (0.336676 --> 0.328456).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3118194\n",
      "\tspeed: 0.0860s/iter; left time: 230.1034s\n",
      "\titers: 200, epoch: 3 | loss: 0.1852860\n",
      "\tspeed: 0.0273s/iter; left time: 70.3303s\n",
      "\titers: 300, epoch: 3 | loss: 0.1195199\n",
      "\tspeed: 0.0268s/iter; left time: 66.2796s\n",
      "\titers: 400, epoch: 3 | loss: 0.1548421\n",
      "\tspeed: 0.0270s/iter; left time: 64.1000s\n",
      "\titers: 500, epoch: 3 | loss: 0.2896580\n",
      "\tspeed: 0.0279s/iter; left time: 63.5942s\n",
      "\titers: 600, epoch: 3 | loss: 0.2804622\n",
      "\tspeed: 0.0276s/iter; left time: 60.1367s\n",
      "Epoch: 3 cost time: 18.908578395843506\n",
      "Epoch: 3, Steps: 694 | Train Loss: 0.1822909 Vali Loss: 0.3187012 Test Loss: 0.2401760\n",
      "Validation loss decreased (0.328456 --> 0.318701).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2386431\n",
      "\tspeed: 0.0784s/iter; left time: 155.4469s\n",
      "\titers: 200, epoch: 4 | loss: 0.2948148\n",
      "\tspeed: 0.0251s/iter; left time: 47.2633s\n",
      "\titers: 300, epoch: 4 | loss: 0.1503429\n",
      "\tspeed: 0.0257s/iter; left time: 45.9078s\n",
      "\titers: 400, epoch: 4 | loss: 0.1134693\n",
      "\tspeed: 0.0251s/iter; left time: 42.2750s\n",
      "\titers: 500, epoch: 4 | loss: 0.1269138\n",
      "\tspeed: 0.0258s/iter; left time: 40.7973s\n",
      "\titers: 600, epoch: 4 | loss: 0.1642206\n",
      "\tspeed: 0.0261s/iter; left time: 38.6716s\n",
      "Epoch: 4 cost time: 17.66938042640686\n",
      "Epoch: 4, Steps: 694 | Train Loss: 0.1665739 Vali Loss: 0.3218368 Test Loss: 0.2417678\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1477699\n",
      "\tspeed: 0.0790s/iter; left time: 101.8309s\n",
      "\titers: 200, epoch: 5 | loss: 0.1609240\n",
      "\tspeed: 0.0253s/iter; left time: 30.0908s\n",
      "\titers: 300, epoch: 5 | loss: 0.1582191\n",
      "\tspeed: 0.0249s/iter; left time: 27.1313s\n",
      "\titers: 400, epoch: 5 | loss: 0.1337576\n",
      "\tspeed: 0.0254s/iter; left time: 25.1568s\n",
      "\titers: 500, epoch: 5 | loss: 0.1432281\n",
      "\tspeed: 0.0255s/iter; left time: 22.6398s\n",
      "\titers: 600, epoch: 5 | loss: 0.1425126\n",
      "\tspeed: 0.0270s/iter; left time: 21.3418s\n",
      "Epoch: 5 cost time: 17.86085796356201\n",
      "Epoch: 5, Steps: 694 | Train Loss: 0.1577262 Vali Loss: 0.3234591 Test Loss: 0.2395599\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1432002\n",
      "\tspeed: 0.0761s/iter; left time: 45.2678s\n",
      "\titers: 200, epoch: 6 | loss: 0.1726767\n",
      "\tspeed: 0.0252s/iter; left time: 12.4937s\n",
      "\titers: 300, epoch: 6 | loss: 0.3174859\n",
      "\tspeed: 0.0250s/iter; left time: 9.8905s\n",
      "\titers: 400, epoch: 6 | loss: 0.0875717\n",
      "\tspeed: 0.0267s/iter; left time: 7.8870s\n",
      "\titers: 500, epoch: 6 | loss: 0.1538558\n",
      "\tspeed: 0.0256s/iter; left time: 4.9889s\n",
      "\titers: 600, epoch: 6 | loss: 0.1255595\n",
      "\tspeed: 0.0257s/iter; left time: 2.4380s\n",
      "Epoch: 6 cost time: 17.65100121498108\n",
      "Epoch: 6, Steps: 694 | Train Loss: 0.1523285 Vali Loss: 0.3204748 Test Loss: 0.2385073\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "Test cost time: 1.7218s\n",
      "test shape: (187, 32, 6, 1) (187, 32, 6, 1)\n",
      "test shape: (5984, 6, 1) (5984, 6, 1)\n",
      "mse:0.2399367094039917, mae:0.33067265152931213\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1643.0325927734375\n",
      "MAE:  27.363588333129883\n",
      "RMSE: 40.534339904785156\n",
      "MAPE: 0.40778595209121704\n",
      "MSPE: 0.8901311755180359\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24467\n",
      "[DEBUG] Original dataset length: 24467\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22233\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3423\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "\titers: 100, epoch: 1 | loss: 0.2805995\n",
      "\tspeed: 0.0275s/iter; left time: 111.7323s\n",
      "\titers: 200, epoch: 1 | loss: 0.4294890\n",
      "\tspeed: 0.0251s/iter; left time: 99.4275s\n",
      "\titers: 300, epoch: 1 | loss: 0.2490106\n",
      "\tspeed: 0.0252s/iter; left time: 97.3940s\n",
      "\titers: 400, epoch: 1 | loss: 0.1243879\n",
      "\tspeed: 0.0271s/iter; left time: 101.9165s\n",
      "\titers: 500, epoch: 1 | loss: 0.3166933\n",
      "\tspeed: 0.0272s/iter; left time: 99.7979s\n",
      "\titers: 600, epoch: 1 | loss: 0.3576617\n",
      "\tspeed: 0.0250s/iter; left time: 89.3010s\n",
      "Epoch: 1 cost time: 18.3642840385437\n",
      "Epoch: 1, Steps: 694 | Train Loss: 0.2782673 Vali Loss: 0.3300421 Test Loss: 0.2684274\n",
      "Validation loss decreased (inf --> 0.330042).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1386864\n",
      "\tspeed: 0.0802s/iter; left time: 270.2497s\n",
      "\titers: 200, epoch: 2 | loss: 0.4441116\n",
      "\tspeed: 0.0255s/iter; left time: 83.3167s\n",
      "\titers: 300, epoch: 2 | loss: 0.1347870\n",
      "\tspeed: 0.0250s/iter; left time: 79.1426s\n",
      "\titers: 400, epoch: 2 | loss: 0.1548928\n",
      "\tspeed: 0.0262s/iter; left time: 80.3834s\n",
      "\titers: 500, epoch: 2 | loss: 0.3336773\n",
      "\tspeed: 0.0270s/iter; left time: 80.3219s\n",
      "\titers: 600, epoch: 2 | loss: 0.1483292\n",
      "\tspeed: 0.0266s/iter; left time: 76.4897s\n",
      "Epoch: 2 cost time: 17.958589553833008\n",
      "Epoch: 2, Steps: 694 | Train Loss: 0.2079321 Vali Loss: 0.3286662 Test Loss: 0.2642932\n",
      "Validation loss decreased (0.330042 --> 0.328666).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2411736\n",
      "\tspeed: 0.0781s/iter; left time: 209.1082s\n",
      "\titers: 200, epoch: 3 | loss: 0.1469842\n",
      "\tspeed: 0.0277s/iter; left time: 71.4585s\n",
      "\titers: 300, epoch: 3 | loss: 0.2469993\n",
      "\tspeed: 0.0249s/iter; left time: 61.6963s\n",
      "\titers: 400, epoch: 3 | loss: 0.1850833\n",
      "\tspeed: 0.0251s/iter; left time: 59.7641s\n",
      "\titers: 500, epoch: 3 | loss: 0.2876591\n",
      "\tspeed: 0.0249s/iter; left time: 56.7004s\n",
      "\titers: 600, epoch: 3 | loss: 0.1276360\n",
      "\tspeed: 0.0252s/iter; left time: 54.7600s\n",
      "Epoch: 3 cost time: 17.63895082473755\n",
      "Epoch: 3, Steps: 694 | Train Loss: 0.1800883 Vali Loss: 0.3197890 Test Loss: 0.2419029\n",
      "Validation loss decreased (0.328666 --> 0.319789).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2010656\n",
      "\tspeed: 0.0797s/iter; left time: 158.0921s\n",
      "\titers: 200, epoch: 4 | loss: 0.1362626\n",
      "\tspeed: 0.0248s/iter; left time: 46.7886s\n",
      "\titers: 300, epoch: 4 | loss: 0.1647512\n",
      "\tspeed: 0.0257s/iter; left time: 45.7669s\n",
      "\titers: 400, epoch: 4 | loss: 0.1655477\n",
      "\tspeed: 0.0255s/iter; left time: 42.9735s\n",
      "\titers: 500, epoch: 4 | loss: 0.1909936\n",
      "\tspeed: 0.0242s/iter; left time: 38.3638s\n",
      "\titers: 600, epoch: 4 | loss: 0.2216070\n",
      "\tspeed: 0.0284s/iter; left time: 42.1036s\n",
      "Epoch: 4 cost time: 17.738229751586914\n",
      "Epoch: 4, Steps: 694 | Train Loss: 0.1667426 Vali Loss: 0.3309865 Test Loss: 0.2453883\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1276904\n",
      "\tspeed: 0.0763s/iter; left time: 98.4141s\n",
      "\titers: 200, epoch: 5 | loss: 0.1270677\n",
      "\tspeed: 0.0259s/iter; left time: 30.7996s\n",
      "\titers: 300, epoch: 5 | loss: 0.0941413\n",
      "\tspeed: 0.0257s/iter; left time: 27.9344s\n",
      "\titers: 400, epoch: 5 | loss: 0.1441821\n",
      "\tspeed: 0.0275s/iter; left time: 27.1796s\n",
      "\titers: 500, epoch: 5 | loss: 0.2025261\n",
      "\tspeed: 0.0248s/iter; left time: 22.0571s\n",
      "\titers: 600, epoch: 5 | loss: 0.1271688\n",
      "\tspeed: 0.0246s/iter; left time: 19.3868s\n",
      "Epoch: 5 cost time: 17.665274620056152\n",
      "Epoch: 5, Steps: 694 | Train Loss: 0.1575203 Vali Loss: 0.3081074 Test Loss: 0.2340420\n",
      "Validation loss decreased (0.319789 --> 0.308107).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1480437\n",
      "\tspeed: 0.0783s/iter; left time: 46.5944s\n",
      "\titers: 200, epoch: 6 | loss: 0.1025378\n",
      "\tspeed: 0.0257s/iter; left time: 12.7075s\n",
      "\titers: 300, epoch: 6 | loss: 0.1078293\n",
      "\tspeed: 0.0255s/iter; left time: 10.0536s\n",
      "\titers: 400, epoch: 6 | loss: 0.0851918\n",
      "\tspeed: 0.0248s/iter; left time: 7.3298s\n",
      "\titers: 500, epoch: 6 | loss: 0.0897382\n",
      "\tspeed: 0.0251s/iter; left time: 4.9039s\n",
      "\titers: 600, epoch: 6 | loss: 0.1337751\n",
      "\tspeed: 0.0248s/iter; left time: 2.3565s\n",
      "Epoch: 6 cost time: 17.834206342697144\n",
      "Epoch: 6, Steps: 694 | Train Loss: 0.1535926 Vali Loss: 0.3162490 Test Loss: 0.2377120\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "Test cost time: 2.0050s\n",
      "test shape: (187, 32, 6, 1) (187, 32, 6, 1)\n",
      "test shape: (5984, 6, 1) (5984, 6, 1)\n",
      "mse:0.23353160917758942, mae:0.3243888020515442\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1599.1722412109375\n",
      "MAE:  26.84358787536621\n",
      "RMSE: 39.98965072631836\n",
      "MAPE: 0.3651878535747528\n",
      "MSPE: 0.6687847375869751\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24467\n",
      "[DEBUG] Original dataset length: 24467\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22233\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3423\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "\titers: 100, epoch: 1 | loss: 0.4039428\n",
      "\tspeed: 0.0261s/iter; left time: 106.0763s\n",
      "\titers: 200, epoch: 1 | loss: 0.2784571\n",
      "\tspeed: 0.0253s/iter; left time: 100.1432s\n",
      "\titers: 300, epoch: 1 | loss: 0.5253747\n",
      "\tspeed: 0.0246s/iter; left time: 95.1055s\n",
      "\titers: 400, epoch: 1 | loss: 0.2525510\n",
      "\tspeed: 0.0277s/iter; left time: 104.1290s\n",
      "\titers: 500, epoch: 1 | loss: 0.1487749\n",
      "\tspeed: 0.0238s/iter; left time: 87.3545s\n",
      "\titers: 600, epoch: 1 | loss: 0.1662580\n",
      "\tspeed: 0.0260s/iter; left time: 92.5867s\n",
      "Epoch: 1 cost time: 17.72886347770691\n",
      "Epoch: 1, Steps: 694 | Train Loss: 0.2805522 Vali Loss: 0.3566460 Test Loss: 0.2844678\n",
      "Validation loss decreased (inf --> 0.356646).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1525078\n",
      "\tspeed: 0.0773s/iter; left time: 260.5867s\n",
      "\titers: 200, epoch: 2 | loss: 0.2582366\n",
      "\tspeed: 0.0276s/iter; left time: 90.2092s\n",
      "\titers: 300, epoch: 2 | loss: 0.1612046\n",
      "\tspeed: 0.0246s/iter; left time: 77.9337s\n",
      "\titers: 400, epoch: 2 | loss: 0.2719455\n",
      "\tspeed: 0.0251s/iter; left time: 77.0899s\n",
      "\titers: 500, epoch: 2 | loss: 0.2029378\n",
      "\tspeed: 0.0243s/iter; left time: 72.2550s\n",
      "\titers: 600, epoch: 2 | loss: 0.1531312\n",
      "\tspeed: 0.0256s/iter; left time: 73.4107s\n",
      "Epoch: 2 cost time: 17.5896577835083\n",
      "Epoch: 2, Steps: 694 | Train Loss: 0.2109424 Vali Loss: 0.3318719 Test Loss: 0.2763963\n",
      "Validation loss decreased (0.356646 --> 0.331872).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2234626\n",
      "\tspeed: 0.0802s/iter; left time: 214.7872s\n",
      "\titers: 200, epoch: 3 | loss: 0.1726478\n",
      "\tspeed: 0.0257s/iter; left time: 66.1543s\n",
      "\titers: 300, epoch: 3 | loss: 0.2923040\n",
      "\tspeed: 0.0249s/iter; left time: 61.5766s\n",
      "\titers: 400, epoch: 3 | loss: 0.2046906\n",
      "\tspeed: 0.0246s/iter; left time: 58.4860s\n",
      "\titers: 500, epoch: 3 | loss: 0.1344467\n",
      "\tspeed: 0.0245s/iter; left time: 55.7617s\n",
      "\titers: 600, epoch: 3 | loss: 0.1798038\n",
      "\tspeed: 0.0274s/iter; left time: 59.6498s\n",
      "Epoch: 3 cost time: 17.744879007339478\n",
      "Epoch: 3, Steps: 694 | Train Loss: 0.1829494 Vali Loss: 0.3307178 Test Loss: 0.2538470\n",
      "Validation loss decreased (0.331872 --> 0.330718).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1745115\n",
      "\tspeed: 0.0778s/iter; left time: 154.2143s\n",
      "\titers: 200, epoch: 4 | loss: 0.1453253\n",
      "\tspeed: 0.0252s/iter; left time: 47.4762s\n",
      "\titers: 300, epoch: 4 | loss: 0.1029684\n",
      "\tspeed: 0.0258s/iter; left time: 45.9812s\n",
      "\titers: 400, epoch: 4 | loss: 0.1685903\n",
      "\tspeed: 0.0254s/iter; left time: 42.8291s\n",
      "\titers: 500, epoch: 4 | loss: 0.1788940\n",
      "\tspeed: 0.0255s/iter; left time: 40.3456s\n",
      "\titers: 600, epoch: 4 | loss: 0.1607517\n",
      "\tspeed: 0.0265s/iter; left time: 39.3515s\n",
      "Epoch: 4 cost time: 17.690192222595215\n",
      "Epoch: 4, Steps: 694 | Train Loss: 0.1655909 Vali Loss: 0.3132521 Test Loss: 0.2513395\n",
      "Validation loss decreased (0.330718 --> 0.313252).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1221849\n",
      "\tspeed: 0.0810s/iter; left time: 104.3892s\n",
      "\titers: 200, epoch: 5 | loss: 0.1333274\n",
      "\tspeed: 0.0249s/iter; left time: 29.6607s\n",
      "\titers: 300, epoch: 5 | loss: 0.1628592\n",
      "\tspeed: 0.0259s/iter; left time: 28.1839s\n",
      "\titers: 400, epoch: 5 | loss: 0.1389243\n",
      "\tspeed: 0.0244s/iter; left time: 24.1126s\n",
      "\titers: 500, epoch: 5 | loss: 0.1563036\n",
      "\tspeed: 0.0250s/iter; left time: 22.2687s\n",
      "\titers: 600, epoch: 5 | loss: 0.1103525\n",
      "\tspeed: 0.0246s/iter; left time: 19.4107s\n",
      "Epoch: 5 cost time: 17.835129499435425\n",
      "Epoch: 5, Steps: 694 | Train Loss: 0.1570376 Vali Loss: 0.3166039 Test Loss: 0.2532886\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1888971\n",
      "\tspeed: 0.0780s/iter; left time: 46.4186s\n",
      "\titers: 200, epoch: 6 | loss: 0.1433958\n",
      "\tspeed: 0.0243s/iter; left time: 12.0087s\n",
      "\titers: 300, epoch: 6 | loss: 0.1081636\n",
      "\tspeed: 0.0250s/iter; left time: 9.8647s\n",
      "\titers: 400, epoch: 6 | loss: 0.1674747\n",
      "\tspeed: 0.0235s/iter; left time: 6.9450s\n",
      "\titers: 500, epoch: 6 | loss: 0.1313142\n",
      "\tspeed: 0.0261s/iter; left time: 5.0954s\n",
      "\titers: 600, epoch: 6 | loss: 0.1951635\n",
      "\tspeed: 0.0247s/iter; left time: 2.3419s\n",
      "Epoch: 6 cost time: 17.24839949607849\n",
      "Epoch: 6, Steps: 694 | Train Loss: 0.1514911 Vali Loss: 0.3133951 Test Loss: 0.2441896\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "Test cost time: 1.7891s\n",
      "test shape: (187, 32, 6, 1) (187, 32, 6, 1)\n",
      "test shape: (5984, 6, 1) (5984, 6, 1)\n",
      "mse:0.25086772441864014, mae:0.3563700318336487\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1717.8857421875\n",
      "MAE:  29.49007797241211\n",
      "RMSE: 41.447383880615234\n",
      "MAPE: 0.424684077501297\n",
      "MSPE: 0.8837221264839172\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24467\n",
      "[DEBUG] Original dataset length: 24467\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22233\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3423\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "\titers: 100, epoch: 1 | loss: 0.3430603\n",
      "\tspeed: 0.0258s/iter; left time: 104.9223s\n",
      "\titers: 200, epoch: 1 | loss: 0.2786937\n",
      "\tspeed: 0.0277s/iter; left time: 109.7649s\n",
      "\titers: 300, epoch: 1 | loss: 0.3571873\n",
      "\tspeed: 0.0256s/iter; left time: 98.9042s\n",
      "\titers: 400, epoch: 1 | loss: 0.2765152\n",
      "\tspeed: 0.0256s/iter; left time: 96.2553s\n",
      "\titers: 500, epoch: 1 | loss: 0.1967268\n",
      "\tspeed: 0.0264s/iter; left time: 96.6679s\n",
      "\titers: 600, epoch: 1 | loss: 0.2906364\n",
      "\tspeed: 0.0275s/iter; left time: 98.0908s\n",
      "Epoch: 1 cost time: 18.235947608947754\n",
      "Epoch: 1, Steps: 694 | Train Loss: 0.2796847 Vali Loss: 0.3214990 Test Loss: 0.2571988\n",
      "Validation loss decreased (inf --> 0.321499).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1462784\n",
      "\tspeed: 0.0785s/iter; left time: 264.6677s\n",
      "\titers: 200, epoch: 2 | loss: 0.2050264\n",
      "\tspeed: 0.0249s/iter; left time: 81.3494s\n",
      "\titers: 300, epoch: 2 | loss: 0.3074270\n",
      "\tspeed: 0.0245s/iter; left time: 77.5654s\n",
      "\titers: 400, epoch: 2 | loss: 0.1745635\n",
      "\tspeed: 0.0255s/iter; left time: 78.4095s\n",
      "\titers: 500, epoch: 2 | loss: 0.2850451\n",
      "\tspeed: 0.0264s/iter; left time: 78.3969s\n",
      "\titers: 600, epoch: 2 | loss: 0.2449945\n",
      "\tspeed: 0.0263s/iter; left time: 75.6113s\n",
      "Epoch: 2 cost time: 17.550727128982544\n",
      "Epoch: 2, Steps: 694 | Train Loss: 0.2107213 Vali Loss: 0.3115512 Test Loss: 0.2541990\n",
      "Validation loss decreased (0.321499 --> 0.311551).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1786151\n",
      "\tspeed: 0.0788s/iter; left time: 210.8951s\n",
      "\titers: 200, epoch: 3 | loss: 0.1594016\n",
      "\tspeed: 0.0270s/iter; left time: 69.4894s\n",
      "\titers: 300, epoch: 3 | loss: 0.1585838\n",
      "\tspeed: 0.0283s/iter; left time: 70.0566s\n",
      "\titers: 400, epoch: 3 | loss: 0.1406007\n",
      "\tspeed: 0.0249s/iter; left time: 59.1820s\n",
      "\titers: 500, epoch: 3 | loss: 0.1066036\n",
      "\tspeed: 0.0242s/iter; left time: 55.0028s\n",
      "\titers: 600, epoch: 3 | loss: 0.3447418\n",
      "\tspeed: 0.0247s/iter; left time: 53.8206s\n",
      "Epoch: 3 cost time: 17.91805148124695\n",
      "Epoch: 3, Steps: 694 | Train Loss: 0.1822421 Vali Loss: 0.3092482 Test Loss: 0.2440545\n",
      "Validation loss decreased (0.311551 --> 0.309248).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1849459\n",
      "\tspeed: 0.0797s/iter; left time: 158.1170s\n",
      "\titers: 200, epoch: 4 | loss: 0.1542125\n",
      "\tspeed: 0.0239s/iter; left time: 45.0122s\n",
      "\titers: 300, epoch: 4 | loss: 0.1585336\n",
      "\tspeed: 0.0248s/iter; left time: 44.2266s\n",
      "\titers: 400, epoch: 4 | loss: 0.1399030\n",
      "\tspeed: 0.0242s/iter; left time: 40.7567s\n",
      "\titers: 500, epoch: 4 | loss: 0.1654800\n",
      "\tspeed: 0.0240s/iter; left time: 38.0234s\n",
      "\titers: 600, epoch: 4 | loss: 0.1322191\n",
      "\tspeed: 0.0254s/iter; left time: 37.7305s\n",
      "Epoch: 4 cost time: 17.63982319831848\n",
      "Epoch: 4, Steps: 694 | Train Loss: 0.1682125 Vali Loss: 0.2996341 Test Loss: 0.2372149\n",
      "Validation loss decreased (0.309248 --> 0.299634).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1566457\n",
      "\tspeed: 0.0797s/iter; left time: 102.7262s\n",
      "\titers: 200, epoch: 5 | loss: 0.1067985\n",
      "\tspeed: 0.0245s/iter; left time: 29.1318s\n",
      "\titers: 300, epoch: 5 | loss: 0.1019668\n",
      "\tspeed: 0.0255s/iter; left time: 27.7750s\n",
      "\titers: 400, epoch: 5 | loss: 0.1526161\n",
      "\tspeed: 0.0239s/iter; left time: 23.6772s\n",
      "\titers: 500, epoch: 5 | loss: 0.1158882\n",
      "\tspeed: 0.0263s/iter; left time: 23.4200s\n",
      "\titers: 600, epoch: 5 | loss: 0.1516984\n",
      "\tspeed: 0.0246s/iter; left time: 19.4327s\n",
      "Epoch: 5 cost time: 17.508138179779053\n",
      "Epoch: 5, Steps: 694 | Train Loss: 0.1592099 Vali Loss: 0.3102481 Test Loss: 0.2398724\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1385091\n",
      "\tspeed: 0.0769s/iter; left time: 45.7462s\n",
      "\titers: 200, epoch: 6 | loss: 0.1556720\n",
      "\tspeed: 0.0271s/iter; left time: 13.3956s\n",
      "\titers: 300, epoch: 6 | loss: 0.1272038\n",
      "\tspeed: 0.0266s/iter; left time: 10.5018s\n",
      "\titers: 400, epoch: 6 | loss: 0.1107124\n",
      "\tspeed: 0.0245s/iter; left time: 7.2296s\n",
      "\titers: 500, epoch: 6 | loss: 0.1103693\n",
      "\tspeed: 0.0256s/iter; left time: 4.9932s\n",
      "\titers: 600, epoch: 6 | loss: 0.1576822\n",
      "\tspeed: 0.0252s/iter; left time: 2.3904s\n",
      "Epoch: 6 cost time: 17.729400396347046\n",
      "Epoch: 6, Steps: 694 | Train Loss: 0.1533890 Vali Loss: 0.3063022 Test Loss: 0.2375571\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "Test cost time: 1.7955s\n",
      "test shape: (187, 32, 6, 1) (187, 32, 6, 1)\n",
      "test shape: (5984, 6, 1) (5984, 6, 1)\n",
      "mse:0.23631250858306885, mae:0.3261943757534027\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1618.2149658203125\n",
      "MAE:  26.993003845214844\n",
      "RMSE: 40.22704315185547\n",
      "MAPE: 0.3336186408996582\n",
      "MSPE: 0.49564218521118164\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24467\n",
      "[DEBUG] Original dataset length: 24467\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22233\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3423\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "\titers: 100, epoch: 1 | loss: 0.3797213\n",
      "\tspeed: 0.0254s/iter; left time: 103.3534s\n",
      "\titers: 200, epoch: 1 | loss: 0.2658587\n",
      "\tspeed: 0.0240s/iter; left time: 95.1690s\n",
      "\titers: 300, epoch: 1 | loss: 0.2774786\n",
      "\tspeed: 0.0253s/iter; left time: 97.7378s\n",
      "\titers: 400, epoch: 1 | loss: 0.2616599\n",
      "\tspeed: 0.0241s/iter; left time: 90.8215s\n",
      "\titers: 500, epoch: 1 | loss: 0.1479681\n",
      "\tspeed: 0.0269s/iter; left time: 98.5676s\n",
      "\titers: 600, epoch: 1 | loss: 0.2252750\n",
      "\tspeed: 0.0258s/iter; left time: 91.9946s\n",
      "Epoch: 1 cost time: 17.603575229644775\n",
      "Epoch: 1, Steps: 694 | Train Loss: 0.2701321 Vali Loss: 0.3307036 Test Loss: 0.2640558\n",
      "Validation loss decreased (inf --> 0.330704).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1827703\n",
      "\tspeed: 0.0780s/iter; left time: 262.9795s\n",
      "\titers: 200, epoch: 2 | loss: 0.1555070\n",
      "\tspeed: 0.0235s/iter; left time: 76.8177s\n",
      "\titers: 300, epoch: 2 | loss: 0.2358910\n",
      "\tspeed: 0.0266s/iter; left time: 84.2985s\n",
      "\titers: 400, epoch: 2 | loss: 0.1895819\n",
      "\tspeed: 0.0259s/iter; left time: 79.5376s\n",
      "\titers: 500, epoch: 2 | loss: 0.3034494\n",
      "\tspeed: 0.0251s/iter; left time: 74.4971s\n",
      "\titers: 600, epoch: 2 | loss: 0.2377888\n",
      "\tspeed: 0.0247s/iter; left time: 71.0326s\n",
      "Epoch: 2 cost time: 17.52108335494995\n",
      "Epoch: 2, Steps: 694 | Train Loss: 0.2082006 Vali Loss: 0.3650741 Test Loss: 0.2866856\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1330291\n",
      "\tspeed: 0.0787s/iter; left time: 210.7586s\n",
      "\titers: 200, epoch: 3 | loss: 0.1535851\n",
      "\tspeed: 0.0251s/iter; left time: 64.6841s\n",
      "\titers: 300, epoch: 3 | loss: 0.1597961\n",
      "\tspeed: 0.0246s/iter; left time: 60.8911s\n",
      "\titers: 400, epoch: 3 | loss: 0.1834296\n",
      "\tspeed: 0.0251s/iter; left time: 59.7623s\n",
      "\titers: 500, epoch: 3 | loss: 0.1039628\n",
      "\tspeed: 0.0252s/iter; left time: 57.3726s\n",
      "\titers: 600, epoch: 3 | loss: 0.3041816\n",
      "\tspeed: 0.0244s/iter; left time: 53.1780s\n",
      "Epoch: 3 cost time: 17.673607349395752\n",
      "Epoch: 3, Steps: 694 | Train Loss: 0.1811571 Vali Loss: 0.3062214 Test Loss: 0.2410927\n",
      "Validation loss decreased (0.330704 --> 0.306221).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1470412\n",
      "\tspeed: 0.0782s/iter; left time: 155.1098s\n",
      "\titers: 200, epoch: 4 | loss: 0.0982060\n",
      "\tspeed: 0.0245s/iter; left time: 46.1356s\n",
      "\titers: 300, epoch: 4 | loss: 0.1559468\n",
      "\tspeed: 0.0250s/iter; left time: 44.6374s\n",
      "\titers: 400, epoch: 4 | loss: 0.1886702\n",
      "\tspeed: 0.0242s/iter; left time: 40.6676s\n",
      "\titers: 500, epoch: 4 | loss: 0.1240326\n",
      "\tspeed: 0.0269s/iter; left time: 42.6446s\n",
      "\titers: 600, epoch: 4 | loss: 0.1241009\n",
      "\tspeed: 0.0259s/iter; left time: 38.4714s\n",
      "Epoch: 4 cost time: 17.594051361083984\n",
      "Epoch: 4, Steps: 694 | Train Loss: 0.1659106 Vali Loss: 0.3102137 Test Loss: 0.2393160\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1419973\n",
      "\tspeed: 0.0774s/iter; left time: 99.7194s\n",
      "\titers: 200, epoch: 5 | loss: 0.2202415\n",
      "\tspeed: 0.0248s/iter; left time: 29.4599s\n",
      "\titers: 300, epoch: 5 | loss: 0.1255039\n",
      "\tspeed: 0.0265s/iter; left time: 28.8223s\n",
      "\titers: 400, epoch: 5 | loss: 0.1939327\n",
      "\tspeed: 0.0249s/iter; left time: 24.6057s\n",
      "\titers: 500, epoch: 5 | loss: 0.1403320\n",
      "\tspeed: 0.0245s/iter; left time: 21.7571s\n",
      "\titers: 600, epoch: 5 | loss: 0.2212058\n",
      "\tspeed: 0.0247s/iter; left time: 19.5040s\n",
      "Epoch: 5 cost time: 17.382118701934814\n",
      "Epoch: 5, Steps: 694 | Train Loss: 0.1569570 Vali Loss: 0.3106359 Test Loss: 0.2450630\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0970709\n",
      "\tspeed: 0.0765s/iter; left time: 45.5134s\n",
      "\titers: 200, epoch: 6 | loss: 0.1573481\n",
      "\tspeed: 0.0251s/iter; left time: 12.4203s\n",
      "\titers: 300, epoch: 6 | loss: 0.1065111\n",
      "\tspeed: 0.0248s/iter; left time: 9.7978s\n",
      "\titers: 400, epoch: 6 | loss: 0.1247957\n",
      "\tspeed: 0.0263s/iter; left time: 7.7557s\n",
      "\titers: 500, epoch: 6 | loss: 0.1928040\n",
      "\tspeed: 0.0247s/iter; left time: 4.8119s\n",
      "\titers: 600, epoch: 6 | loss: 0.2334690\n",
      "\tspeed: 0.0252s/iter; left time: 2.3894s\n",
      "Epoch: 6 cost time: 17.698272466659546\n",
      "Epoch: 6, Steps: 694 | Train Loss: 0.1518171 Vali Loss: 0.3097943 Test Loss: 0.2445479\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "Test cost time: 1.7307s\n",
      "test shape: (187, 32, 6, 1) (187, 32, 6, 1)\n",
      "test shape: (5984, 6, 1) (5984, 6, 1)\n",
      "mse:0.24168165028095245, mae:0.34000831842422485\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1654.9814453125\n",
      "MAE:  28.136123657226562\n",
      "RMSE: 40.681461334228516\n",
      "MAPE: 0.4224822223186493\n",
      "MSPE: 0.9310972690582275\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24467\n",
      "[DEBUG] Original dataset length: 24467\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22233\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3423\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "\titers: 100, epoch: 1 | loss: 0.2827383\n",
      "\tspeed: 0.0250s/iter; left time: 101.7105s\n",
      "\titers: 200, epoch: 1 | loss: 0.3517233\n",
      "\tspeed: 0.0238s/iter; left time: 94.4457s\n",
      "\titers: 300, epoch: 1 | loss: 0.4336426\n",
      "\tspeed: 0.0253s/iter; left time: 97.7774s\n",
      "\titers: 400, epoch: 1 | loss: 0.1709739\n",
      "\tspeed: 0.0274s/iter; left time: 103.0733s\n",
      "\titers: 500, epoch: 1 | loss: 0.2204542\n",
      "\tspeed: 0.0257s/iter; left time: 94.1625s\n",
      "\titers: 600, epoch: 1 | loss: 0.1877696\n",
      "\tspeed: 0.0270s/iter; left time: 96.0944s\n",
      "Epoch: 1 cost time: 17.802618741989136\n",
      "Epoch: 1, Steps: 694 | Train Loss: 0.2819516 Vali Loss: 0.3740912 Test Loss: 0.3092308\n",
      "Validation loss decreased (inf --> 0.374091).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2559817\n",
      "\tspeed: 0.0788s/iter; left time: 265.6787s\n",
      "\titers: 200, epoch: 2 | loss: 0.2341548\n",
      "\tspeed: 0.0257s/iter; left time: 83.9941s\n",
      "\titers: 300, epoch: 2 | loss: 0.2535928\n",
      "\tspeed: 0.0257s/iter; left time: 81.4820s\n",
      "\titers: 400, epoch: 2 | loss: 0.3300191\n",
      "\tspeed: 0.0264s/iter; left time: 81.0659s\n",
      "\titers: 500, epoch: 2 | loss: 0.1838703\n",
      "\tspeed: 0.0268s/iter; left time: 79.6587s\n",
      "\titers: 600, epoch: 2 | loss: 0.1710252\n",
      "\tspeed: 0.0271s/iter; left time: 77.7796s\n",
      "Epoch: 2 cost time: 18.259507179260254\n",
      "Epoch: 2, Steps: 694 | Train Loss: 0.2100893 Vali Loss: 0.3219248 Test Loss: 0.2545097\n",
      "Validation loss decreased (0.374091 --> 0.321925).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1799448\n",
      "\tspeed: 0.0814s/iter; left time: 217.7980s\n",
      "\titers: 200, epoch: 3 | loss: 0.3036849\n",
      "\tspeed: 0.0278s/iter; left time: 71.5190s\n",
      "\titers: 300, epoch: 3 | loss: 0.2459312\n",
      "\tspeed: 0.0263s/iter; left time: 65.1392s\n",
      "\titers: 400, epoch: 3 | loss: 0.1464523\n",
      "\tspeed: 0.0273s/iter; left time: 64.8374s\n",
      "\titers: 500, epoch: 3 | loss: 0.1344627\n",
      "\tspeed: 0.0274s/iter; left time: 62.4429s\n",
      "\titers: 600, epoch: 3 | loss: 0.1662224\n",
      "\tspeed: 0.0260s/iter; left time: 56.5715s\n",
      "Epoch: 3 cost time: 18.64191699028015\n",
      "Epoch: 3, Steps: 694 | Train Loss: 0.1804822 Vali Loss: 0.3290612 Test Loss: 0.2620697\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2229205\n",
      "\tspeed: 0.0768s/iter; left time: 152.3699s\n",
      "\titers: 200, epoch: 4 | loss: 0.1698362\n",
      "\tspeed: 0.0251s/iter; left time: 47.3403s\n",
      "\titers: 300, epoch: 4 | loss: 0.1427078\n",
      "\tspeed: 0.0242s/iter; left time: 43.1364s\n",
      "\titers: 400, epoch: 4 | loss: 0.2358326\n",
      "\tspeed: 0.0254s/iter; left time: 42.7760s\n",
      "\titers: 500, epoch: 4 | loss: 0.1264798\n",
      "\tspeed: 0.0247s/iter; left time: 39.1408s\n",
      "\titers: 600, epoch: 4 | loss: 0.2011376\n",
      "\tspeed: 0.0259s/iter; left time: 38.3818s\n",
      "Epoch: 4 cost time: 17.39179491996765\n",
      "Epoch: 4, Steps: 694 | Train Loss: 0.1653732 Vali Loss: 0.3256924 Test Loss: 0.2605685\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1208988\n",
      "\tspeed: 0.0784s/iter; left time: 100.9947s\n",
      "\titers: 200, epoch: 5 | loss: 0.1106549\n",
      "\tspeed: 0.0246s/iter; left time: 29.3011s\n",
      "\titers: 300, epoch: 5 | loss: 0.2252755\n",
      "\tspeed: 0.0242s/iter; left time: 26.4003s\n",
      "\titers: 400, epoch: 5 | loss: 0.1708536\n",
      "\tspeed: 0.0249s/iter; left time: 24.6041s\n",
      "\titers: 500, epoch: 5 | loss: 0.1338071\n",
      "\tspeed: 0.0241s/iter; left time: 21.4468s\n",
      "\titers: 600, epoch: 5 | loss: 0.0914249\n",
      "\tspeed: 0.0251s/iter; left time: 19.8081s\n",
      "Epoch: 5 cost time: 17.083539247512817\n",
      "Epoch: 5, Steps: 694 | Train Loss: 0.1568119 Vali Loss: 0.3106067 Test Loss: 0.2450749\n",
      "Validation loss decreased (0.321925 --> 0.310607).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3333494\n",
      "\tspeed: 0.0767s/iter; left time: 45.6358s\n",
      "\titers: 200, epoch: 6 | loss: 0.1965306\n",
      "\tspeed: 0.0268s/iter; left time: 13.2725s\n",
      "\titers: 300, epoch: 6 | loss: 0.1555898\n",
      "\tspeed: 0.0249s/iter; left time: 9.8459s\n",
      "\titers: 400, epoch: 6 | loss: 0.1360691\n",
      "\tspeed: 0.0269s/iter; left time: 7.9285s\n",
      "\titers: 500, epoch: 6 | loss: 0.1151728\n",
      "\tspeed: 0.0246s/iter; left time: 4.7916s\n",
      "\titers: 600, epoch: 6 | loss: 0.1145430\n",
      "\tspeed: 0.0250s/iter; left time: 2.3725s\n",
      "Epoch: 6 cost time: 17.684844493865967\n",
      "Epoch: 6, Steps: 694 | Train Loss: 0.1523245 Vali Loss: 0.3070359 Test Loss: 0.2465052\n",
      "Validation loss decreased (0.310607 --> 0.307036).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "Test cost time: 1.7157s\n",
      "test shape: (187, 32, 6, 1) (187, 32, 6, 1)\n",
      "test shape: (5984, 6, 1) (5984, 6, 1)\n",
      "mse:0.24552392959594727, mae:0.3262248635292053\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1681.292724609375\n",
      "MAE:  26.995525360107422\n",
      "RMSE: 41.003570556640625\n",
      "MAPE: 0.3214244544506073\n",
      "MSPE: 0.4447535574436188\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24467\n",
      "[DEBUG] Original dataset length: 24467\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22233\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3423\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "\titers: 100, epoch: 1 | loss: 0.2119062\n",
      "\tspeed: 0.0285s/iter; left time: 115.9234s\n",
      "\titers: 200, epoch: 1 | loss: 0.1774032\n",
      "\tspeed: 0.0250s/iter; left time: 99.2653s\n",
      "\titers: 300, epoch: 1 | loss: 0.1809429\n",
      "\tspeed: 0.0243s/iter; left time: 94.0961s\n",
      "\titers: 400, epoch: 1 | loss: 0.2875485\n",
      "\tspeed: 0.0241s/iter; left time: 90.7050s\n",
      "\titers: 500, epoch: 1 | loss: 0.2138849\n",
      "\tspeed: 0.0242s/iter; left time: 88.6536s\n",
      "\titers: 600, epoch: 1 | loss: 0.1619875\n",
      "\tspeed: 0.0251s/iter; left time: 89.4988s\n",
      "Epoch: 1 cost time: 17.509568452835083\n",
      "Epoch: 1, Steps: 694 | Train Loss: 0.2715796 Vali Loss: 0.3164892 Test Loss: 0.2604108\n",
      "Validation loss decreased (inf --> 0.316489).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1720259\n",
      "\tspeed: 0.0760s/iter; left time: 256.3537s\n",
      "\titers: 200, epoch: 2 | loss: 0.1845128\n",
      "\tspeed: 0.0240s/iter; left time: 78.4058s\n",
      "\titers: 300, epoch: 2 | loss: 0.1788667\n",
      "\tspeed: 0.0252s/iter; left time: 79.8012s\n",
      "\titers: 400, epoch: 2 | loss: 0.1648845\n",
      "\tspeed: 0.0242s/iter; left time: 74.3116s\n",
      "\titers: 500, epoch: 2 | loss: 0.2234200\n",
      "\tspeed: 0.0267s/iter; left time: 79.3823s\n",
      "\titers: 600, epoch: 2 | loss: 0.2498256\n",
      "\tspeed: 0.0256s/iter; left time: 73.3815s\n",
      "Epoch: 2 cost time: 17.313865900039673\n",
      "Epoch: 2, Steps: 694 | Train Loss: 0.2065717 Vali Loss: 0.3243748 Test Loss: 0.2625147\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2054175\n",
      "\tspeed: 0.0779s/iter; left time: 208.5018s\n",
      "\titers: 200, epoch: 3 | loss: 0.1868033\n",
      "\tspeed: 0.0262s/iter; left time: 67.5972s\n",
      "\titers: 300, epoch: 3 | loss: 0.1451205\n",
      "\tspeed: 0.0259s/iter; left time: 64.2671s\n",
      "\titers: 400, epoch: 3 | loss: 0.2474605\n",
      "\tspeed: 0.0239s/iter; left time: 56.7394s\n",
      "\titers: 500, epoch: 3 | loss: 0.1491046\n",
      "\tspeed: 0.0241s/iter; left time: 54.9177s\n",
      "\titers: 600, epoch: 3 | loss: 0.1880092\n",
      "\tspeed: 0.0243s/iter; left time: 52.8902s\n",
      "Epoch: 3 cost time: 17.353620052337646\n",
      "Epoch: 3, Steps: 694 | Train Loss: 0.1798715 Vali Loss: 0.3043353 Test Loss: 0.2447154\n",
      "Validation loss decreased (0.316489 --> 0.304335).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1423759\n",
      "\tspeed: 0.0785s/iter; left time: 155.7194s\n",
      "\titers: 200, epoch: 4 | loss: 0.1602405\n",
      "\tspeed: 0.0247s/iter; left time: 46.6025s\n",
      "\titers: 300, epoch: 4 | loss: 0.1673132\n",
      "\tspeed: 0.0249s/iter; left time: 44.3482s\n",
      "\titers: 400, epoch: 4 | loss: 0.2239697\n",
      "\tspeed: 0.0254s/iter; left time: 42.7612s\n",
      "\titers: 500, epoch: 4 | loss: 0.1514246\n",
      "\tspeed: 0.0243s/iter; left time: 38.4109s\n",
      "\titers: 600, epoch: 4 | loss: 0.1440474\n",
      "\tspeed: 0.0261s/iter; left time: 38.7536s\n",
      "Epoch: 4 cost time: 17.78390121459961\n",
      "Epoch: 4, Steps: 694 | Train Loss: 0.1656133 Vali Loss: 0.2957860 Test Loss: 0.2439236\n",
      "Validation loss decreased (0.304335 --> 0.295786).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1901167\n",
      "\tspeed: 0.0801s/iter; left time: 103.2698s\n",
      "\titers: 200, epoch: 5 | loss: 0.1065632\n",
      "\tspeed: 0.0241s/iter; left time: 28.6085s\n",
      "\titers: 300, epoch: 5 | loss: 0.1012249\n",
      "\tspeed: 0.0246s/iter; left time: 26.8112s\n",
      "\titers: 400, epoch: 5 | loss: 0.1135660\n",
      "\tspeed: 0.0255s/iter; left time: 25.2435s\n",
      "\titers: 500, epoch: 5 | loss: 0.1072739\n",
      "\tspeed: 0.0263s/iter; left time: 23.4148s\n",
      "\titers: 600, epoch: 5 | loss: 0.1858619\n",
      "\tspeed: 0.0243s/iter; left time: 19.2112s\n",
      "Epoch: 5 cost time: 17.463953256607056\n",
      "Epoch: 5, Steps: 694 | Train Loss: 0.1569550 Vali Loss: 0.3125770 Test Loss: 0.2501730\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1072491\n",
      "\tspeed: 0.0770s/iter; left time: 45.8327s\n",
      "\titers: 200, epoch: 6 | loss: 0.1196335\n",
      "\tspeed: 0.0270s/iter; left time: 13.3731s\n",
      "\titers: 300, epoch: 6 | loss: 0.1228994\n",
      "\tspeed: 0.0257s/iter; left time: 10.1677s\n",
      "\titers: 400, epoch: 6 | loss: 0.1587921\n",
      "\tspeed: 0.0247s/iter; left time: 7.2940s\n",
      "\titers: 500, epoch: 6 | loss: 0.1584047\n",
      "\tspeed: 0.0257s/iter; left time: 5.0049s\n",
      "\titers: 600, epoch: 6 | loss: 0.1401382\n",
      "\tspeed: 0.0240s/iter; left time: 2.2816s\n",
      "Epoch: 6 cost time: 17.60878896713257\n",
      "Epoch: 6, Steps: 694 | Train Loss: 0.1519130 Vali Loss: 0.2952696 Test Loss: 0.2404821\n",
      "Validation loss decreased (0.295786 --> 0.295270).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "Test cost time: 1.7329s\n",
      "test shape: (187, 32, 6, 1) (187, 32, 6, 1)\n",
      "test shape: (5984, 6, 1) (5984, 6, 1)\n",
      "mse:0.24053698778152466, mae:0.328543484210968\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1647.1435546875\n",
      "MAE:  27.187397003173828\n",
      "RMSE: 40.585018157958984\n",
      "MAPE: 0.3479536473751068\n",
      "MSPE: 0.5949198007583618\n",
      ">>>>>>>Running time saved<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Running seq_len=96\n",
      "Args in experiment:\n",
      "Namespace(model='informer', data='traffic_full', root_path='../', data_path='traffic_full.csv', features='S', target='flow', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=24, pred_len=6, enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=2, d_layers=1, s_layers=[3, 2, 1], d_ff=2048, factor=5, padding=0, distil=True, dropout=0.05, attn='prob', embed='timeF', activation='gelu', output_attention=False, do_predict=False, mix=True, cols=None, num_workers=0, itr=10, train_epochs=6, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, inverse=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', detail_freq='h')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24443\n",
      "[DEBUG] Original dataset length: 24443\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21825\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3399\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "\titers: 100, epoch: 1 | loss: 0.2606433\n",
      "\tspeed: 0.0414s/iter; left time: 165.3887s\n",
      "\titers: 200, epoch: 1 | loss: 0.2226450\n",
      "\tspeed: 0.0275s/iter; left time: 107.0616s\n",
      "\titers: 300, epoch: 1 | loss: 0.2953896\n",
      "\tspeed: 0.0299s/iter; left time: 113.3767s\n",
      "\titers: 400, epoch: 1 | loss: 0.1607261\n",
      "\tspeed: 0.0280s/iter; left time: 103.4055s\n",
      "\titers: 500, epoch: 1 | loss: 0.2511277\n",
      "\tspeed: 0.0273s/iter; left time: 98.0036s\n",
      "\titers: 600, epoch: 1 | loss: 0.2617537\n",
      "\tspeed: 0.0284s/iter; left time: 99.1990s\n",
      "Epoch: 1 cost time: 19.632600784301758\n",
      "Epoch: 1, Steps: 682 | Train Loss: 0.2787509 Vali Loss: 0.3212744 Test Loss: 0.2682815\n",
      "Validation loss decreased (inf --> 0.321274).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2218069\n",
      "\tspeed: 0.0822s/iter; left time: 272.1905s\n",
      "\titers: 200, epoch: 2 | loss: 0.2460992\n",
      "\tspeed: 0.0275s/iter; left time: 88.4030s\n",
      "\titers: 300, epoch: 2 | loss: 0.1526352\n",
      "\tspeed: 0.0276s/iter; left time: 85.7390s\n",
      "\titers: 400, epoch: 2 | loss: 0.1645587\n",
      "\tspeed: 0.0285s/iter; left time: 85.8953s\n",
      "\titers: 500, epoch: 2 | loss: 0.1623849\n",
      "\tspeed: 0.0272s/iter; left time: 79.1368s\n",
      "\titers: 600, epoch: 2 | loss: 0.1824595\n",
      "\tspeed: 0.0295s/iter; left time: 82.8313s\n",
      "Epoch: 2 cost time: 19.03902816772461\n",
      "Epoch: 2, Steps: 682 | Train Loss: 0.2106340 Vali Loss: 0.3376380 Test Loss: 0.2839659\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1137042\n",
      "\tspeed: 0.0808s/iter; left time: 212.4746s\n",
      "\titers: 200, epoch: 3 | loss: 0.2215439\n",
      "\tspeed: 0.0283s/iter; left time: 71.5737s\n",
      "\titers: 300, epoch: 3 | loss: 0.1838679\n",
      "\tspeed: 0.0293s/iter; left time: 71.1557s\n",
      "\titers: 400, epoch: 3 | loss: 0.1761702\n",
      "\tspeed: 0.0281s/iter; left time: 65.3393s\n",
      "\titers: 500, epoch: 3 | loss: 0.1404851\n",
      "\tspeed: 0.0275s/iter; left time: 61.2320s\n",
      "\titers: 600, epoch: 3 | loss: 0.2454724\n",
      "\tspeed: 0.0277s/iter; left time: 58.9877s\n",
      "Epoch: 3 cost time: 19.09357976913452\n",
      "Epoch: 3, Steps: 682 | Train Loss: 0.1795995 Vali Loss: 0.3076297 Test Loss: 0.2493220\n",
      "Validation loss decreased (0.321274 --> 0.307630).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1465688\n",
      "\tspeed: 0.0809s/iter; left time: 157.5168s\n",
      "\titers: 200, epoch: 4 | loss: 0.1719520\n",
      "\tspeed: 0.0275s/iter; left time: 50.7957s\n",
      "\titers: 300, epoch: 4 | loss: 0.1352011\n",
      "\tspeed: 0.0271s/iter; left time: 47.4098s\n",
      "\titers: 400, epoch: 4 | loss: 0.1210611\n",
      "\tspeed: 0.0278s/iter; left time: 45.7567s\n",
      "\titers: 500, epoch: 4 | loss: 0.1455963\n",
      "\tspeed: 0.0286s/iter; left time: 44.2058s\n",
      "\titers: 600, epoch: 4 | loss: 0.1083719\n",
      "\tspeed: 0.0288s/iter; left time: 41.7039s\n",
      "Epoch: 4 cost time: 19.06682014465332\n",
      "Epoch: 4, Steps: 682 | Train Loss: 0.1650796 Vali Loss: 0.3081255 Test Loss: 0.2477869\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1332861\n",
      "\tspeed: 0.0803s/iter; left time: 101.5477s\n",
      "\titers: 200, epoch: 5 | loss: 0.2968110\n",
      "\tspeed: 0.0274s/iter; left time: 31.8754s\n",
      "\titers: 300, epoch: 5 | loss: 0.1907922\n",
      "\tspeed: 0.0287s/iter; left time: 30.6147s\n",
      "\titers: 400, epoch: 5 | loss: 0.1441205\n",
      "\tspeed: 0.0288s/iter; left time: 27.7818s\n",
      "\titers: 500, epoch: 5 | loss: 0.1242176\n",
      "\tspeed: 0.0277s/iter; left time: 23.9345s\n",
      "\titers: 600, epoch: 5 | loss: 0.3008566\n",
      "\tspeed: 0.0266s/iter; left time: 20.3326s\n",
      "Epoch: 5 cost time: 18.988184928894043\n",
      "Epoch: 5, Steps: 682 | Train Loss: 0.1572779 Vali Loss: 0.3097733 Test Loss: 0.2452164\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1416904\n",
      "\tspeed: 0.0787s/iter; left time: 45.8818s\n",
      "\titers: 200, epoch: 6 | loss: 0.1988188\n",
      "\tspeed: 0.0268s/iter; left time: 12.9389s\n",
      "\titers: 300, epoch: 6 | loss: 0.1289576\n",
      "\tspeed: 0.0280s/iter; left time: 10.7397s\n",
      "\titers: 400, epoch: 6 | loss: 0.2322101\n",
      "\tspeed: 0.0264s/iter; left time: 7.4734s\n",
      "\titers: 500, epoch: 6 | loss: 0.0988267\n",
      "\tspeed: 0.0270s/iter; left time: 4.9403s\n",
      "\titers: 600, epoch: 6 | loss: 0.1260689\n",
      "\tspeed: 0.0273s/iter; left time: 2.2623s\n",
      "Epoch: 6 cost time: 18.586328983306885\n",
      "Epoch: 6, Steps: 682 | Train Loss: 0.1514850 Vali Loss: 0.3069593 Test Loss: 0.2444064\n",
      "Validation loss decreased (0.307630 --> 0.306959).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "Test cost time: 1.8368s\n",
      "test shape: (182, 32, 6, 1) (182, 32, 6, 1)\n",
      "test shape: (5824, 6, 1) (5824, 6, 1)\n",
      "mse:0.2452978938817978, mae:0.3370445668697357\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1679.744873046875\n",
      "MAE:  27.890871047973633\n",
      "RMSE: 40.98469161987305\n",
      "MAPE: 0.3945625424385071\n",
      "MSPE: 0.8041302561759949\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24443\n",
      "[DEBUG] Original dataset length: 24443\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21825\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3399\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "\titers: 100, epoch: 1 | loss: 0.2940768\n",
      "\tspeed: 0.0257s/iter; left time: 102.4516s\n",
      "\titers: 200, epoch: 1 | loss: 0.3284296\n",
      "\tspeed: 0.0266s/iter; left time: 103.3708s\n",
      "\titers: 300, epoch: 1 | loss: 0.5083297\n",
      "\tspeed: 0.0276s/iter; left time: 104.7453s\n",
      "\titers: 400, epoch: 1 | loss: 0.1898585\n",
      "\tspeed: 0.0267s/iter; left time: 98.6148s\n",
      "\titers: 500, epoch: 1 | loss: 0.1682469\n",
      "\tspeed: 0.0249s/iter; left time: 89.5333s\n",
      "\titers: 600, epoch: 1 | loss: 0.1467154\n",
      "\tspeed: 0.0268s/iter; left time: 93.7603s\n",
      "Epoch: 1 cost time: 18.010262966156006\n",
      "Epoch: 1, Steps: 682 | Train Loss: 0.2857738 Vali Loss: 0.3609137 Test Loss: 0.3039478\n",
      "Validation loss decreased (inf --> 0.360914).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2223784\n",
      "\tspeed: 0.0800s/iter; left time: 264.7392s\n",
      "\titers: 200, epoch: 2 | loss: 0.3151253\n",
      "\tspeed: 0.0269s/iter; left time: 86.3957s\n",
      "\titers: 300, epoch: 2 | loss: 0.1210879\n",
      "\tspeed: 0.0268s/iter; left time: 83.3667s\n",
      "\titers: 400, epoch: 2 | loss: 0.1714990\n",
      "\tspeed: 0.0263s/iter; left time: 79.1732s\n",
      "\titers: 500, epoch: 2 | loss: 0.1932441\n",
      "\tspeed: 0.0259s/iter; left time: 75.3372s\n",
      "\titers: 600, epoch: 2 | loss: 0.2078588\n",
      "\tspeed: 0.0281s/iter; left time: 78.9516s\n",
      "Epoch: 2 cost time: 18.466484785079956\n",
      "Epoch: 2, Steps: 682 | Train Loss: 0.2089195 Vali Loss: 0.3131611 Test Loss: 0.2527855\n",
      "Validation loss decreased (0.360914 --> 0.313161).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1654541\n",
      "\tspeed: 0.0786s/iter; left time: 206.6171s\n",
      "\titers: 200, epoch: 3 | loss: 0.0893412\n",
      "\tspeed: 0.0270s/iter; left time: 68.2615s\n",
      "\titers: 300, epoch: 3 | loss: 0.1162733\n",
      "\tspeed: 0.0279s/iter; left time: 67.7551s\n",
      "\titers: 400, epoch: 3 | loss: 0.1921985\n",
      "\tspeed: 0.0290s/iter; left time: 67.4881s\n",
      "\titers: 500, epoch: 3 | loss: 0.1814862\n",
      "\tspeed: 0.0264s/iter; left time: 58.8584s\n",
      "\titers: 600, epoch: 3 | loss: 0.1275392\n",
      "\tspeed: 0.0267s/iter; left time: 56.8359s\n",
      "Epoch: 3 cost time: 18.505163431167603\n",
      "Epoch: 3, Steps: 682 | Train Loss: 0.1821936 Vali Loss: 0.3138882 Test Loss: 0.2507607\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1736947\n",
      "\tspeed: 0.0792s/iter; left time: 154.1064s\n",
      "\titers: 200, epoch: 4 | loss: 0.1360120\n",
      "\tspeed: 0.0289s/iter; left time: 53.3379s\n",
      "\titers: 300, epoch: 4 | loss: 0.1910107\n",
      "\tspeed: 0.0265s/iter; left time: 46.2876s\n",
      "\titers: 400, epoch: 4 | loss: 0.1642022\n",
      "\tspeed: 0.0264s/iter; left time: 43.5525s\n",
      "\titers: 500, epoch: 4 | loss: 0.1855784\n",
      "\tspeed: 0.0260s/iter; left time: 40.2177s\n",
      "\titers: 600, epoch: 4 | loss: 0.1623384\n",
      "\tspeed: 0.0265s/iter; left time: 38.2758s\n",
      "Epoch: 4 cost time: 18.4733304977417\n",
      "Epoch: 4, Steps: 682 | Train Loss: 0.1658855 Vali Loss: 0.3121462 Test Loss: 0.2434208\n",
      "Validation loss decreased (0.313161 --> 0.312146).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1242552\n",
      "\tspeed: 0.0806s/iter; left time: 101.9761s\n",
      "\titers: 200, epoch: 5 | loss: 0.1874044\n",
      "\tspeed: 0.0264s/iter; left time: 30.8087s\n",
      "\titers: 300, epoch: 5 | loss: 0.1062739\n",
      "\tspeed: 0.0266s/iter; left time: 28.2808s\n",
      "\titers: 400, epoch: 5 | loss: 0.1269882\n",
      "\tspeed: 0.0264s/iter; left time: 25.4604s\n",
      "\titers: 500, epoch: 5 | loss: 0.1628805\n",
      "\tspeed: 0.0286s/iter; left time: 24.7203s\n",
      "\titers: 600, epoch: 5 | loss: 0.1510099\n",
      "\tspeed: 0.0266s/iter; left time: 20.3348s\n",
      "Epoch: 5 cost time: 18.371346950531006\n",
      "Epoch: 5, Steps: 682 | Train Loss: 0.1569139 Vali Loss: 0.3144073 Test Loss: 0.2473753\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1386060\n",
      "\tspeed: 0.0779s/iter; left time: 45.3938s\n",
      "\titers: 200, epoch: 6 | loss: 0.2467897\n",
      "\tspeed: 0.0274s/iter; left time: 13.2347s\n",
      "\titers: 300, epoch: 6 | loss: 0.1108377\n",
      "\tspeed: 0.0280s/iter; left time: 10.7156s\n",
      "\titers: 400, epoch: 6 | loss: 0.1117009\n",
      "\tspeed: 0.0260s/iter; left time: 7.3636s\n",
      "\titers: 500, epoch: 6 | loss: 0.1212313\n",
      "\tspeed: 0.0266s/iter; left time: 4.8743s\n",
      "\titers: 600, epoch: 6 | loss: 0.1741684\n",
      "\tspeed: 0.0270s/iter; left time: 2.2396s\n",
      "Epoch: 6 cost time: 18.455265998840332\n",
      "Epoch: 6, Steps: 682 | Train Loss: 0.1520439 Vali Loss: 0.3249802 Test Loss: 0.2523081\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "Test cost time: 1.8658s\n",
      "test shape: (182, 32, 6, 1) (182, 32, 6, 1)\n",
      "test shape: (5824, 6, 1) (5824, 6, 1)\n",
      "mse:0.24344871938228607, mae:0.3267466723918915\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1667.08203125\n",
      "MAE:  27.038705825805664\n",
      "RMSE: 40.82991409301758\n",
      "MAPE: 0.3438272476196289\n",
      "MSPE: 0.5520040988922119\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24443\n",
      "[DEBUG] Original dataset length: 24443\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21825\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3399\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "\titers: 100, epoch: 1 | loss: 0.3914268\n",
      "\tspeed: 0.0251s/iter; left time: 100.2737s\n",
      "\titers: 200, epoch: 1 | loss: 0.3169215\n",
      "\tspeed: 0.0282s/iter; left time: 109.6387s\n",
      "\titers: 300, epoch: 1 | loss: 0.1993535\n",
      "\tspeed: 0.0272s/iter; left time: 103.3323s\n",
      "\titers: 400, epoch: 1 | loss: 0.2100082\n",
      "\tspeed: 0.0278s/iter; left time: 102.8325s\n",
      "\titers: 500, epoch: 1 | loss: 0.1210216\n",
      "\tspeed: 0.0279s/iter; left time: 100.3737s\n",
      "\titers: 600, epoch: 1 | loss: 0.1677409\n",
      "\tspeed: 0.0266s/iter; left time: 93.0625s\n",
      "Epoch: 1 cost time: 18.50019335746765\n",
      "Epoch: 1, Steps: 682 | Train Loss: 0.2717152 Vali Loss: 0.3567911 Test Loss: 0.2830093\n",
      "Validation loss decreased (inf --> 0.356791).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3299569\n",
      "\tspeed: 0.0782s/iter; left time: 258.9585s\n",
      "\titers: 200, epoch: 2 | loss: 0.2402012\n",
      "\tspeed: 0.0280s/iter; left time: 89.8181s\n",
      "\titers: 300, epoch: 2 | loss: 0.1678945\n",
      "\tspeed: 0.0273s/iter; left time: 84.8499s\n",
      "\titers: 400, epoch: 2 | loss: 0.2878558\n",
      "\tspeed: 0.0260s/iter; left time: 78.4105s\n",
      "\titers: 500, epoch: 2 | loss: 0.2569010\n",
      "\tspeed: 0.0260s/iter; left time: 75.5888s\n",
      "\titers: 600, epoch: 2 | loss: 0.2058196\n",
      "\tspeed: 0.0264s/iter; left time: 74.2727s\n",
      "Epoch: 2 cost time: 18.161364316940308\n",
      "Epoch: 2, Steps: 682 | Train Loss: 0.2093011 Vali Loss: 0.3234760 Test Loss: 0.2588948\n",
      "Validation loss decreased (0.356791 --> 0.323476).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1470298\n",
      "\tspeed: 0.0797s/iter; left time: 209.5220s\n",
      "\titers: 200, epoch: 3 | loss: 0.1539797\n",
      "\tspeed: 0.0264s/iter; left time: 66.8510s\n",
      "\titers: 300, epoch: 3 | loss: 0.1360152\n",
      "\tspeed: 0.0262s/iter; left time: 63.5847s\n",
      "\titers: 400, epoch: 3 | loss: 0.2463717\n",
      "\tspeed: 0.0267s/iter; left time: 62.2772s\n",
      "\titers: 500, epoch: 3 | loss: 0.1551952\n",
      "\tspeed: 0.0270s/iter; left time: 60.2808s\n",
      "\titers: 600, epoch: 3 | loss: 0.1432827\n",
      "\tspeed: 0.0288s/iter; left time: 61.3914s\n",
      "Epoch: 3 cost time: 18.38491988182068\n",
      "Epoch: 3, Steps: 682 | Train Loss: 0.1783461 Vali Loss: 0.3262539 Test Loss: 0.2552591\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2348202\n",
      "\tspeed: 0.0784s/iter; left time: 152.6552s\n",
      "\titers: 200, epoch: 4 | loss: 0.2473141\n",
      "\tspeed: 0.0261s/iter; left time: 48.1407s\n",
      "\titers: 300, epoch: 4 | loss: 0.1219146\n",
      "\tspeed: 0.0290s/iter; left time: 50.6390s\n",
      "\titers: 400, epoch: 4 | loss: 0.1861583\n",
      "\tspeed: 0.0281s/iter; left time: 46.3072s\n",
      "\titers: 500, epoch: 4 | loss: 0.1194806\n",
      "\tspeed: 0.0269s/iter; left time: 41.6455s\n",
      "\titers: 600, epoch: 4 | loss: 0.2481789\n",
      "\tspeed: 0.0271s/iter; left time: 39.2317s\n",
      "Epoch: 4 cost time: 18.6368145942688\n",
      "Epoch: 4, Steps: 682 | Train Loss: 0.1630023 Vali Loss: 0.3154365 Test Loss: 0.2514522\n",
      "Validation loss decreased (0.323476 --> 0.315436).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1430224\n",
      "\tspeed: 0.0813s/iter; left time: 102.8574s\n",
      "\titers: 200, epoch: 5 | loss: 0.1843556\n",
      "\tspeed: 0.0275s/iter; left time: 32.0123s\n",
      "\titers: 300, epoch: 5 | loss: 0.1501911\n",
      "\tspeed: 0.0258s/iter; left time: 27.5160s\n",
      "\titers: 400, epoch: 5 | loss: 0.2035828\n",
      "\tspeed: 0.0275s/iter; left time: 26.5335s\n",
      "\titers: 500, epoch: 5 | loss: 0.1367852\n",
      "\tspeed: 0.0268s/iter; left time: 23.1937s\n",
      "\titers: 600, epoch: 5 | loss: 0.1492642\n",
      "\tspeed: 0.0277s/iter; left time: 21.2096s\n",
      "Epoch: 5 cost time: 18.70152997970581\n",
      "Epoch: 5, Steps: 682 | Train Loss: 0.1540852 Vali Loss: 0.3231741 Test Loss: 0.2548727\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1349524\n",
      "\tspeed: 0.0812s/iter; left time: 47.3579s\n",
      "\titers: 200, epoch: 6 | loss: 0.1449327\n",
      "\tspeed: 0.0274s/iter; left time: 13.2468s\n",
      "\titers: 300, epoch: 6 | loss: 0.1317154\n",
      "\tspeed: 0.0283s/iter; left time: 10.8274s\n",
      "\titers: 400, epoch: 6 | loss: 0.1102458\n",
      "\tspeed: 0.0292s/iter; left time: 8.2598s\n",
      "\titers: 500, epoch: 6 | loss: 0.1080158\n",
      "\tspeed: 0.0287s/iter; left time: 5.2483s\n",
      "\titers: 600, epoch: 6 | loss: 0.1031846\n",
      "\tspeed: 0.0278s/iter; left time: 2.3077s\n",
      "Epoch: 6 cost time: 19.171125888824463\n",
      "Epoch: 6, Steps: 682 | Train Loss: 0.1487281 Vali Loss: 0.3124165 Test Loss: 0.2462950\n",
      "Validation loss decreased (0.315436 --> 0.312416).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "Test cost time: 1.9958s\n",
      "test shape: (182, 32, 6, 1) (182, 32, 6, 1)\n",
      "test shape: (5824, 6, 1) (5824, 6, 1)\n",
      "mse:0.2440548539161682, mae:0.3249792158603668\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1671.2327880859375\n",
      "MAE:  26.89244842529297\n",
      "RMSE: 40.880714416503906\n",
      "MAPE: 0.33580875396728516\n",
      "MSPE: 0.5370451211929321\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24443\n",
      "[DEBUG] Original dataset length: 24443\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21825\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3399\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "\titers: 100, epoch: 1 | loss: 0.4324952\n",
      "\tspeed: 0.0286s/iter; left time: 114.1048s\n",
      "\titers: 200, epoch: 1 | loss: 0.3408072\n",
      "\tspeed: 0.0284s/iter; left time: 110.6863s\n",
      "\titers: 300, epoch: 1 | loss: 0.3254747\n",
      "\tspeed: 0.0288s/iter; left time: 109.1560s\n",
      "\titers: 400, epoch: 1 | loss: 0.2945028\n",
      "\tspeed: 0.0276s/iter; left time: 102.0407s\n",
      "\titers: 500, epoch: 1 | loss: 0.2341836\n",
      "\tspeed: 0.0270s/iter; left time: 96.9329s\n",
      "\titers: 600, epoch: 1 | loss: 0.2238352\n",
      "\tspeed: 0.0280s/iter; left time: 97.6514s\n",
      "Epoch: 1 cost time: 19.054199695587158\n",
      "Epoch: 1, Steps: 682 | Train Loss: 0.2802956 Vali Loss: 0.3205932 Test Loss: 0.2552159\n",
      "Validation loss decreased (inf --> 0.320593).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2017215\n",
      "\tspeed: 0.0805s/iter; left time: 266.4874s\n",
      "\titers: 200, epoch: 2 | loss: 0.2939855\n",
      "\tspeed: 0.0272s/iter; left time: 87.2818s\n",
      "\titers: 300, epoch: 2 | loss: 0.1400082\n",
      "\tspeed: 0.0289s/iter; left time: 90.0449s\n",
      "\titers: 400, epoch: 2 | loss: 0.1599213\n",
      "\tspeed: 0.0283s/iter; left time: 85.1908s\n",
      "\titers: 500, epoch: 2 | loss: 0.2712924\n",
      "\tspeed: 0.0261s/iter; left time: 75.9413s\n",
      "\titers: 600, epoch: 2 | loss: 0.1740143\n",
      "\tspeed: 0.0265s/iter; left time: 74.5024s\n",
      "Epoch: 2 cost time: 18.64768385887146\n",
      "Epoch: 2, Steps: 682 | Train Loss: 0.2121295 Vali Loss: 0.3136516 Test Loss: 0.2512748\n",
      "Validation loss decreased (0.320593 --> 0.313652).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1921326\n",
      "\tspeed: 0.0814s/iter; left time: 213.9256s\n",
      "\titers: 200, epoch: 3 | loss: 0.1833236\n",
      "\tspeed: 0.0263s/iter; left time: 66.4202s\n",
      "\titers: 300, epoch: 3 | loss: 0.1580416\n",
      "\tspeed: 0.0270s/iter; left time: 65.5483s\n",
      "\titers: 400, epoch: 3 | loss: 0.2103072\n",
      "\tspeed: 0.0287s/iter; left time: 66.9548s\n",
      "\titers: 500, epoch: 3 | loss: 0.1469759\n",
      "\tspeed: 0.0278s/iter; left time: 61.9361s\n",
      "\titers: 600, epoch: 3 | loss: 0.2304848\n",
      "\tspeed: 0.0284s/iter; left time: 60.3942s\n",
      "Epoch: 3 cost time: 18.885687351226807\n",
      "Epoch: 3, Steps: 682 | Train Loss: 0.1819781 Vali Loss: 0.3126324 Test Loss: 0.2525743\n",
      "Validation loss decreased (0.313652 --> 0.312632).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1842825\n",
      "\tspeed: 0.0789s/iter; left time: 153.5456s\n",
      "\titers: 200, epoch: 4 | loss: 0.1957416\n",
      "\tspeed: 0.0266s/iter; left time: 49.1838s\n",
      "\titers: 300, epoch: 4 | loss: 0.1098425\n",
      "\tspeed: 0.0272s/iter; left time: 47.4671s\n",
      "\titers: 400, epoch: 4 | loss: 0.1839446\n",
      "\tspeed: 0.0278s/iter; left time: 45.8092s\n",
      "\titers: 500, epoch: 4 | loss: 0.1164912\n",
      "\tspeed: 0.0271s/iter; left time: 41.9548s\n",
      "\titers: 600, epoch: 4 | loss: 0.1387854\n",
      "\tspeed: 0.0259s/iter; left time: 37.5260s\n",
      "Epoch: 4 cost time: 18.393566608428955\n",
      "Epoch: 4, Steps: 682 | Train Loss: 0.1646754 Vali Loss: 0.3084505 Test Loss: 0.2425210\n",
      "Validation loss decreased (0.312632 --> 0.308451).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1302898\n",
      "\tspeed: 0.0814s/iter; left time: 102.9821s\n",
      "\titers: 200, epoch: 5 | loss: 0.1216965\n",
      "\tspeed: 0.0267s/iter; left time: 31.1094s\n",
      "\titers: 300, epoch: 5 | loss: 0.2433997\n",
      "\tspeed: 0.0266s/iter; left time: 28.3041s\n",
      "\titers: 400, epoch: 5 | loss: 0.1547792\n",
      "\tspeed: 0.0265s/iter; left time: 25.5409s\n",
      "\titers: 500, epoch: 5 | loss: 0.2531561\n",
      "\tspeed: 0.0270s/iter; left time: 23.3809s\n",
      "\titers: 600, epoch: 5 | loss: 0.1486559\n",
      "\tspeed: 0.0258s/iter; left time: 19.7277s\n",
      "Epoch: 5 cost time: 18.607064962387085\n",
      "Epoch: 5, Steps: 682 | Train Loss: 0.1555343 Vali Loss: 0.3143842 Test Loss: 0.2463649\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1122835\n",
      "\tspeed: 0.0807s/iter; left time: 47.0277s\n",
      "\titers: 200, epoch: 6 | loss: 0.2777311\n",
      "\tspeed: 0.0265s/iter; left time: 12.8110s\n",
      "\titers: 300, epoch: 6 | loss: 0.1019590\n",
      "\tspeed: 0.0261s/iter; left time: 10.0139s\n",
      "\titers: 400, epoch: 6 | loss: 0.2058817\n",
      "\tspeed: 0.0274s/iter; left time: 7.7637s\n",
      "\titers: 500, epoch: 6 | loss: 0.1917352\n",
      "\tspeed: 0.0285s/iter; left time: 5.2231s\n",
      "\titers: 600, epoch: 6 | loss: 0.1314170\n",
      "\tspeed: 0.0265s/iter; left time: 2.2025s\n",
      "Epoch: 6 cost time: 18.402477741241455\n",
      "Epoch: 6, Steps: 682 | Train Loss: 0.1492492 Vali Loss: 0.3199969 Test Loss: 0.2496009\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "Test cost time: 1.8945s\n",
      "test shape: (182, 32, 6, 1) (182, 32, 6, 1)\n",
      "test shape: (5824, 6, 1) (5824, 6, 1)\n",
      "mse:0.24496403336524963, mae:0.3311961591243744\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1677.4586181640625\n",
      "MAE:  27.406906127929688\n",
      "RMSE: 40.956790924072266\n",
      "MAPE: 0.34799647331237793\n",
      "MSPE: 0.5666613578796387\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24443\n",
      "[DEBUG] Original dataset length: 24443\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21825\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3399\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "\titers: 100, epoch: 1 | loss: 0.3628126\n",
      "\tspeed: 0.0274s/iter; left time: 109.3850s\n",
      "\titers: 200, epoch: 1 | loss: 0.3142911\n",
      "\tspeed: 0.0273s/iter; left time: 106.2559s\n",
      "\titers: 300, epoch: 1 | loss: 0.2002925\n",
      "\tspeed: 0.0264s/iter; left time: 100.1871s\n",
      "\titers: 400, epoch: 1 | loss: 0.1739843\n",
      "\tspeed: 0.0259s/iter; left time: 95.5818s\n",
      "\titers: 500, epoch: 1 | loss: 0.4382226\n",
      "\tspeed: 0.0263s/iter; left time: 94.4727s\n",
      "\titers: 600, epoch: 1 | loss: 0.2589644\n",
      "\tspeed: 0.0267s/iter; left time: 93.1241s\n",
      "Epoch: 1 cost time: 18.396898984909058\n",
      "Epoch: 1, Steps: 682 | Train Loss: 0.2822062 Vali Loss: 0.3398049 Test Loss: 0.2729686\n",
      "Validation loss decreased (inf --> 0.339805).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1535294\n",
      "\tspeed: 0.0809s/iter; left time: 267.9655s\n",
      "\titers: 200, epoch: 2 | loss: 0.2238385\n",
      "\tspeed: 0.0271s/iter; left time: 86.9837s\n",
      "\titers: 300, epoch: 2 | loss: 0.1326815\n",
      "\tspeed: 0.0263s/iter; left time: 81.8605s\n",
      "\titers: 400, epoch: 2 | loss: 0.2571022\n",
      "\tspeed: 0.0273s/iter; left time: 82.3026s\n",
      "\titers: 500, epoch: 2 | loss: 0.2825384\n",
      "\tspeed: 0.0276s/iter; left time: 80.2159s\n",
      "\titers: 600, epoch: 2 | loss: 0.2129160\n",
      "\tspeed: 0.0261s/iter; left time: 73.3059s\n",
      "Epoch: 2 cost time: 18.293596744537354\n",
      "Epoch: 2, Steps: 682 | Train Loss: 0.2076172 Vali Loss: 0.3244736 Test Loss: 0.2622795\n",
      "Validation loss decreased (0.339805 --> 0.324474).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1113952\n",
      "\tspeed: 0.0787s/iter; left time: 206.8203s\n",
      "\titers: 200, epoch: 3 | loss: 0.1742168\n",
      "\tspeed: 0.0285s/iter; left time: 72.1262s\n",
      "\titers: 300, epoch: 3 | loss: 0.2389468\n",
      "\tspeed: 0.0270s/iter; left time: 65.6587s\n",
      "\titers: 400, epoch: 3 | loss: 0.1581928\n",
      "\tspeed: 0.0265s/iter; left time: 61.8010s\n",
      "\titers: 500, epoch: 3 | loss: 0.2971312\n",
      "\tspeed: 0.0263s/iter; left time: 58.6925s\n",
      "\titers: 600, epoch: 3 | loss: 0.3088046\n",
      "\tspeed: 0.0267s/iter; left time: 56.7817s\n",
      "Epoch: 3 cost time: 18.301929235458374\n",
      "Epoch: 3, Steps: 682 | Train Loss: 0.1806525 Vali Loss: 0.3168712 Test Loss: 0.2521790\n",
      "Validation loss decreased (0.324474 --> 0.316871).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2108514\n",
      "\tspeed: 0.0771s/iter; left time: 150.0257s\n",
      "\titers: 200, epoch: 4 | loss: 0.1158560\n",
      "\tspeed: 0.0265s/iter; left time: 49.0311s\n",
      "\titers: 300, epoch: 4 | loss: 0.1471976\n",
      "\tspeed: 0.0253s/iter; left time: 44.2012s\n",
      "\titers: 400, epoch: 4 | loss: 0.2272861\n",
      "\tspeed: 0.0268s/iter; left time: 44.0717s\n",
      "\titers: 500, epoch: 4 | loss: 0.1143633\n",
      "\tspeed: 0.0271s/iter; left time: 41.8612s\n",
      "\titers: 600, epoch: 4 | loss: 0.1563718\n",
      "\tspeed: 0.0280s/iter; left time: 40.5463s\n",
      "Epoch: 4 cost time: 18.0886127948761\n",
      "Epoch: 4, Steps: 682 | Train Loss: 0.1640609 Vali Loss: 0.3102966 Test Loss: 0.2449769\n",
      "Validation loss decreased (0.316871 --> 0.310297).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1211885\n",
      "\tspeed: 0.0775s/iter; left time: 98.0566s\n",
      "\titers: 200, epoch: 5 | loss: 0.1901733\n",
      "\tspeed: 0.0272s/iter; left time: 31.6804s\n",
      "\titers: 300, epoch: 5 | loss: 0.1586401\n",
      "\tspeed: 0.0287s/iter; left time: 30.5717s\n",
      "\titers: 400, epoch: 5 | loss: 0.1322865\n",
      "\tspeed: 0.0274s/iter; left time: 26.4280s\n",
      "\titers: 500, epoch: 5 | loss: 0.2631758\n",
      "\tspeed: 0.0262s/iter; left time: 22.6314s\n",
      "\titers: 600, epoch: 5 | loss: 0.1234851\n",
      "\tspeed: 0.0272s/iter; left time: 20.8007s\n",
      "Epoch: 5 cost time: 18.40885281562805\n",
      "Epoch: 5, Steps: 682 | Train Loss: 0.1551735 Vali Loss: 0.3211028 Test Loss: 0.2485919\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1110352\n",
      "\tspeed: 0.0788s/iter; left time: 45.9608s\n",
      "\titers: 200, epoch: 6 | loss: 0.1796744\n",
      "\tspeed: 0.0283s/iter; left time: 13.6494s\n",
      "\titers: 300, epoch: 6 | loss: 0.2467086\n",
      "\tspeed: 0.0279s/iter; left time: 10.6813s\n",
      "\titers: 400, epoch: 6 | loss: 0.1088139\n",
      "\tspeed: 0.0272s/iter; left time: 7.6856s\n",
      "\titers: 500, epoch: 6 | loss: 0.1537783\n",
      "\tspeed: 0.0268s/iter; left time: 4.9013s\n",
      "\titers: 600, epoch: 6 | loss: 0.1159043\n",
      "\tspeed: 0.0269s/iter; left time: 2.2344s\n",
      "Epoch: 6 cost time: 18.854730129241943\n",
      "Epoch: 6, Steps: 682 | Train Loss: 0.1499638 Vali Loss: 0.3161690 Test Loss: 0.2446179\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "Test cost time: 1.7797s\n",
      "test shape: (182, 32, 6, 1) (182, 32, 6, 1)\n",
      "test shape: (5824, 6, 1) (5824, 6, 1)\n",
      "mse:0.24473460018634796, mae:0.3365687429904938\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1675.8876953125\n",
      "MAE:  27.85149574279785\n",
      "RMSE: 40.93760681152344\n",
      "MAPE: 0.3886964023113251\n",
      "MSPE: 0.7657821178436279\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24443\n",
      "[DEBUG] Original dataset length: 24443\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21825\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3399\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "\titers: 100, epoch: 1 | loss: 0.2889816\n",
      "\tspeed: 0.0269s/iter; left time: 107.2602s\n",
      "\titers: 200, epoch: 1 | loss: 0.2407607\n",
      "\tspeed: 0.0267s/iter; left time: 103.9310s\n",
      "\titers: 300, epoch: 1 | loss: 0.3196054\n",
      "\tspeed: 0.0286s/iter; left time: 108.4081s\n",
      "\titers: 400, epoch: 1 | loss: 0.1958838\n",
      "\tspeed: 0.0261s/iter; left time: 96.2947s\n",
      "\titers: 500, epoch: 1 | loss: 0.2380520\n",
      "\tspeed: 0.0261s/iter; left time: 93.7738s\n",
      "\titers: 600, epoch: 1 | loss: 0.2344562\n",
      "\tspeed: 0.0259s/iter; left time: 90.3671s\n",
      "Epoch: 1 cost time: 18.198083639144897\n",
      "Epoch: 1, Steps: 682 | Train Loss: 0.2798365 Vali Loss: 0.3296660 Test Loss: 0.2690667\n",
      "Validation loss decreased (inf --> 0.329666).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2119010\n",
      "\tspeed: 0.0793s/iter; left time: 262.5389s\n",
      "\titers: 200, epoch: 2 | loss: 0.1630715\n",
      "\tspeed: 0.0268s/iter; left time: 86.0052s\n",
      "\titers: 300, epoch: 2 | loss: 0.2157633\n",
      "\tspeed: 0.0270s/iter; left time: 84.0694s\n",
      "\titers: 400, epoch: 2 | loss: 0.2268048\n",
      "\tspeed: 0.0266s/iter; left time: 80.1794s\n",
      "\titers: 500, epoch: 2 | loss: 0.1184976\n",
      "\tspeed: 0.0261s/iter; left time: 75.8852s\n",
      "\titers: 600, epoch: 2 | loss: 0.1713092\n",
      "\tspeed: 0.0282s/iter; left time: 79.1520s\n",
      "Epoch: 2 cost time: 18.51788878440857\n",
      "Epoch: 2, Steps: 682 | Train Loss: 0.2059285 Vali Loss: 0.3129936 Test Loss: 0.2523659\n",
      "Validation loss decreased (0.329666 --> 0.312994).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1708834\n",
      "\tspeed: 0.0806s/iter; left time: 211.9895s\n",
      "\titers: 200, epoch: 3 | loss: 0.1836453\n",
      "\tspeed: 0.0263s/iter; left time: 66.4740s\n",
      "\titers: 300, epoch: 3 | loss: 0.1741126\n",
      "\tspeed: 0.0259s/iter; left time: 62.7925s\n",
      "\titers: 400, epoch: 3 | loss: 0.1664773\n",
      "\tspeed: 0.0304s/iter; left time: 70.7618s\n",
      "\titers: 500, epoch: 3 | loss: 0.2342499\n",
      "\tspeed: 0.0272s/iter; left time: 60.6910s\n",
      "\titers: 600, epoch: 3 | loss: 0.1440930\n",
      "\tspeed: 0.0260s/iter; left time: 55.3838s\n",
      "Epoch: 3 cost time: 18.52134346961975\n",
      "Epoch: 3, Steps: 682 | Train Loss: 0.1776431 Vali Loss: 0.3422354 Test Loss: 0.2695517\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1781950\n",
      "\tspeed: 0.0802s/iter; left time: 156.1792s\n",
      "\titers: 200, epoch: 4 | loss: 0.1069221\n",
      "\tspeed: 0.0280s/iter; left time: 51.7248s\n",
      "\titers: 300, epoch: 4 | loss: 0.2091790\n",
      "\tspeed: 0.0268s/iter; left time: 46.8479s\n",
      "\titers: 400, epoch: 4 | loss: 0.1109921\n",
      "\tspeed: 0.0263s/iter; left time: 43.3627s\n",
      "\titers: 500, epoch: 4 | loss: 0.2172171\n",
      "\tspeed: 0.0245s/iter; left time: 37.8648s\n",
      "\titers: 600, epoch: 4 | loss: 0.1737469\n",
      "\tspeed: 0.0264s/iter; left time: 38.1684s\n",
      "Epoch: 4 cost time: 18.34287667274475\n",
      "Epoch: 4, Steps: 682 | Train Loss: 0.1614814 Vali Loss: 0.3157085 Test Loss: 0.2573503\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1599268\n",
      "\tspeed: 0.0792s/iter; left time: 100.1516s\n",
      "\titers: 200, epoch: 5 | loss: 0.1642712\n",
      "\tspeed: 0.0271s/iter; left time: 31.5459s\n",
      "\titers: 300, epoch: 5 | loss: 0.2535574\n",
      "\tspeed: 0.0263s/iter; left time: 28.0390s\n",
      "\titers: 400, epoch: 5 | loss: 0.1786906\n",
      "\tspeed: 0.0272s/iter; left time: 26.2500s\n",
      "\titers: 500, epoch: 5 | loss: 0.1304851\n",
      "\tspeed: 0.0274s/iter; left time: 23.7262s\n",
      "\titers: 600, epoch: 5 | loss: 0.1236691\n",
      "\tspeed: 0.0269s/iter; left time: 20.6005s\n",
      "Epoch: 5 cost time: 18.219833374023438\n",
      "Epoch: 5, Steps: 682 | Train Loss: 0.1526555 Vali Loss: 0.3132805 Test Loss: 0.2557644\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "Test cost time: 1.8422s\n",
      "test shape: (182, 32, 6, 1) (182, 32, 6, 1)\n",
      "test shape: (5824, 6, 1) (5824, 6, 1)\n",
      "mse:0.2520036995410919, mae:0.3321656286716461\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1725.66455078125\n",
      "MAE:  27.48713493347168\n",
      "RMSE: 41.54111862182617\n",
      "MAPE: 0.33079060912132263\n",
      "MSPE: 0.4944353401660919\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24443\n",
      "[DEBUG] Original dataset length: 24443\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21825\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3399\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "\titers: 100, epoch: 1 | loss: 0.2561054\n",
      "\tspeed: 0.0279s/iter; left time: 111.2568s\n",
      "\titers: 200, epoch: 1 | loss: 0.3354536\n",
      "\tspeed: 0.0266s/iter; left time: 103.4111s\n",
      "\titers: 300, epoch: 1 | loss: 0.3387117\n",
      "\tspeed: 0.0267s/iter; left time: 101.3585s\n",
      "\titers: 400, epoch: 1 | loss: 0.2905919\n",
      "\tspeed: 0.0264s/iter; left time: 97.5811s\n",
      "\titers: 500, epoch: 1 | loss: 0.1364369\n",
      "\tspeed: 0.0271s/iter; left time: 97.2181s\n",
      "\titers: 600, epoch: 1 | loss: 0.2706970\n",
      "\tspeed: 0.0266s/iter; left time: 92.9758s\n",
      "Epoch: 1 cost time: 18.4986515045166\n",
      "Epoch: 1, Steps: 682 | Train Loss: 0.2822393 Vali Loss: 0.3331573 Test Loss: 0.2616528\n",
      "Validation loss decreased (inf --> 0.333157).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1995141\n",
      "\tspeed: 0.0799s/iter; left time: 264.4972s\n",
      "\titers: 200, epoch: 2 | loss: 0.1901543\n",
      "\tspeed: 0.0265s/iter; left time: 84.9748s\n",
      "\titers: 300, epoch: 2 | loss: 0.2669031\n",
      "\tspeed: 0.0270s/iter; left time: 84.0339s\n",
      "\titers: 400, epoch: 2 | loss: 0.2834808\n",
      "\tspeed: 0.0264s/iter; left time: 79.4100s\n",
      "\titers: 500, epoch: 2 | loss: 0.1600838\n",
      "\tspeed: 0.0299s/iter; left time: 87.0866s\n",
      "\titers: 600, epoch: 2 | loss: 0.1979321\n",
      "\tspeed: 0.0270s/iter; left time: 75.8359s\n",
      "Epoch: 2 cost time: 18.57162642478943\n",
      "Epoch: 2, Steps: 682 | Train Loss: 0.2077618 Vali Loss: 0.3367300 Test Loss: 0.2685486\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1345801\n",
      "\tspeed: 0.0781s/iter; left time: 205.4192s\n",
      "\titers: 200, epoch: 3 | loss: 0.1575339\n",
      "\tspeed: 0.0275s/iter; left time: 69.5166s\n",
      "\titers: 300, epoch: 3 | loss: 0.1432000\n",
      "\tspeed: 0.0272s/iter; left time: 66.1171s\n",
      "\titers: 400, epoch: 3 | loss: 0.2273189\n",
      "\tspeed: 0.0267s/iter; left time: 62.1768s\n",
      "\titers: 500, epoch: 3 | loss: 0.1053393\n",
      "\tspeed: 0.0269s/iter; left time: 60.0623s\n",
      "\titers: 600, epoch: 3 | loss: 0.1814971\n",
      "\tspeed: 0.0261s/iter; left time: 55.6097s\n",
      "Epoch: 3 cost time: 18.35117745399475\n",
      "Epoch: 3, Steps: 682 | Train Loss: 0.1809604 Vali Loss: 0.3343155 Test Loss: 0.2612623\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1449723\n",
      "\tspeed: 0.0796s/iter; left time: 155.0364s\n",
      "\titers: 200, epoch: 4 | loss: 0.2017076\n",
      "\tspeed: 0.0268s/iter; left time: 49.4357s\n",
      "\titers: 300, epoch: 4 | loss: 0.0782065\n",
      "\tspeed: 0.0260s/iter; left time: 45.5087s\n",
      "\titers: 400, epoch: 4 | loss: 0.1605918\n",
      "\tspeed: 0.0259s/iter; left time: 42.6005s\n",
      "\titers: 500, epoch: 4 | loss: 0.1302793\n",
      "\tspeed: 0.0275s/iter; left time: 42.5877s\n",
      "\titers: 600, epoch: 4 | loss: 0.2305760\n",
      "\tspeed: 0.0265s/iter; left time: 38.2881s\n",
      "Epoch: 4 cost time: 18.058135986328125\n",
      "Epoch: 4, Steps: 682 | Train Loss: 0.1656975 Vali Loss: 0.3304931 Test Loss: 0.2539751\n",
      "Validation loss decreased (0.333157 --> 0.330493).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0999633\n",
      "\tspeed: 0.0778s/iter; left time: 98.3686s\n",
      "\titers: 200, epoch: 5 | loss: 0.1447834\n",
      "\tspeed: 0.0260s/iter; left time: 30.3441s\n",
      "\titers: 300, epoch: 5 | loss: 0.1743520\n",
      "\tspeed: 0.0276s/iter; left time: 29.4399s\n",
      "\titers: 400, epoch: 5 | loss: 0.1478215\n",
      "\tspeed: 0.0267s/iter; left time: 25.7479s\n",
      "\titers: 500, epoch: 5 | loss: 0.1261974\n",
      "\tspeed: 0.0275s/iter; left time: 23.7696s\n",
      "\titers: 600, epoch: 5 | loss: 0.1834507\n",
      "\tspeed: 0.0280s/iter; left time: 21.4045s\n",
      "Epoch: 5 cost time: 18.435972452163696\n",
      "Epoch: 5, Steps: 682 | Train Loss: 0.1560498 Vali Loss: 0.3329927 Test Loss: 0.2576211\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1369951\n",
      "\tspeed: 0.0799s/iter; left time: 46.5765s\n",
      "\titers: 200, epoch: 6 | loss: 0.1358949\n",
      "\tspeed: 0.0262s/iter; left time: 12.6354s\n",
      "\titers: 300, epoch: 6 | loss: 0.1240617\n",
      "\tspeed: 0.0261s/iter; left time: 9.9926s\n",
      "\titers: 400, epoch: 6 | loss: 0.1434399\n",
      "\tspeed: 0.0264s/iter; left time: 7.4708s\n",
      "\titers: 500, epoch: 6 | loss: 0.1036578\n",
      "\tspeed: 0.0264s/iter; left time: 4.8352s\n",
      "\titers: 600, epoch: 6 | loss: 0.1484151\n",
      "\tspeed: 0.0276s/iter; left time: 2.2888s\n",
      "Epoch: 6 cost time: 18.492205381393433\n",
      "Epoch: 6, Steps: 682 | Train Loss: 0.1512564 Vali Loss: 0.3420986 Test Loss: 0.2581435\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "Test cost time: 1.8423s\n",
      "test shape: (182, 32, 6, 1) (182, 32, 6, 1)\n",
      "test shape: (5824, 6, 1) (5824, 6, 1)\n",
      "mse:0.2548108994960785, mae:0.3376655578613281\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1744.8878173828125\n",
      "MAE:  27.9422607421875\n",
      "RMSE: 41.771854400634766\n",
      "MAPE: 0.3433923125267029\n",
      "MSPE: 0.5365846157073975\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24443\n",
      "[DEBUG] Original dataset length: 24443\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21825\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3399\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "\titers: 100, epoch: 1 | loss: 0.3714706\n",
      "\tspeed: 0.0261s/iter; left time: 104.3727s\n",
      "\titers: 200, epoch: 1 | loss: 0.2642617\n",
      "\tspeed: 0.0261s/iter; left time: 101.6535s\n",
      "\titers: 300, epoch: 1 | loss: 0.1902532\n",
      "\tspeed: 0.0275s/iter; left time: 104.3786s\n",
      "\titers: 400, epoch: 1 | loss: 0.1227303\n",
      "\tspeed: 0.0272s/iter; left time: 100.4409s\n",
      "\titers: 500, epoch: 1 | loss: 0.1510050\n",
      "\tspeed: 0.0262s/iter; left time: 94.0080s\n",
      "\titers: 600, epoch: 1 | loss: 0.2921735\n",
      "\tspeed: 0.0271s/iter; left time: 94.5044s\n",
      "Epoch: 1 cost time: 18.19030737876892\n",
      "Epoch: 1, Steps: 682 | Train Loss: 0.2770900 Vali Loss: 0.3368185 Test Loss: 0.2739234\n",
      "Validation loss decreased (inf --> 0.336819).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2127772\n",
      "\tspeed: 0.0797s/iter; left time: 263.9534s\n",
      "\titers: 200, epoch: 2 | loss: 0.2055015\n",
      "\tspeed: 0.0266s/iter; left time: 85.3176s\n",
      "\titers: 300, epoch: 2 | loss: 0.2630712\n",
      "\tspeed: 0.0242s/iter; left time: 75.1882s\n",
      "\titers: 400, epoch: 2 | loss: 0.2216619\n",
      "\tspeed: 0.0259s/iter; left time: 78.0875s\n",
      "\titers: 500, epoch: 2 | loss: 0.2305723\n",
      "\tspeed: 0.0256s/iter; left time: 74.4722s\n",
      "\titers: 600, epoch: 2 | loss: 0.3636434\n",
      "\tspeed: 0.0274s/iter; left time: 77.0491s\n",
      "Epoch: 2 cost time: 18.056218147277832\n",
      "Epoch: 2, Steps: 682 | Train Loss: 0.2089598 Vali Loss: 0.3205567 Test Loss: 0.2694640\n",
      "Validation loss decreased (0.336819 --> 0.320557).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2441254\n",
      "\tspeed: 0.0786s/iter; left time: 206.7642s\n",
      "\titers: 200, epoch: 3 | loss: 0.1888618\n",
      "\tspeed: 0.0272s/iter; left time: 68.6845s\n",
      "\titers: 300, epoch: 3 | loss: 0.1300298\n",
      "\tspeed: 0.0265s/iter; left time: 64.3301s\n",
      "\titers: 400, epoch: 3 | loss: 0.1882397\n",
      "\tspeed: 0.0290s/iter; left time: 67.5290s\n",
      "\titers: 500, epoch: 3 | loss: 0.1532840\n",
      "\tspeed: 0.0269s/iter; left time: 60.0361s\n",
      "\titers: 600, epoch: 3 | loss: 0.1947490\n",
      "\tspeed: 0.0270s/iter; left time: 57.5248s\n",
      "Epoch: 3 cost time: 18.46679925918579\n",
      "Epoch: 3, Steps: 682 | Train Loss: 0.1810402 Vali Loss: 0.3157038 Test Loss: 0.2481829\n",
      "Validation loss decreased (0.320557 --> 0.315704).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2358089\n",
      "\tspeed: 0.0795s/iter; left time: 154.8580s\n",
      "\titers: 200, epoch: 4 | loss: 0.1678578\n",
      "\tspeed: 0.0283s/iter; left time: 52.2074s\n",
      "\titers: 300, epoch: 4 | loss: 0.1057266\n",
      "\tspeed: 0.0263s/iter; left time: 45.9440s\n",
      "\titers: 400, epoch: 4 | loss: 0.1001984\n",
      "\tspeed: 0.0258s/iter; left time: 42.5165s\n",
      "\titers: 500, epoch: 4 | loss: 0.1037369\n",
      "\tspeed: 0.0261s/iter; left time: 40.4380s\n",
      "\titers: 600, epoch: 4 | loss: 0.2581611\n",
      "\tspeed: 0.0261s/iter; left time: 37.8293s\n",
      "Epoch: 4 cost time: 18.127612352371216\n",
      "Epoch: 4, Steps: 682 | Train Loss: 0.1646342 Vali Loss: 0.3186758 Test Loss: 0.2448019\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1331299\n",
      "\tspeed: 0.0778s/iter; left time: 98.4612s\n",
      "\titers: 200, epoch: 5 | loss: 0.2175576\n",
      "\tspeed: 0.0269s/iter; left time: 31.3464s\n",
      "\titers: 300, epoch: 5 | loss: 0.0955700\n",
      "\tspeed: 0.0263s/iter; left time: 28.0283s\n",
      "\titers: 400, epoch: 5 | loss: 0.1051695\n",
      "\tspeed: 0.0272s/iter; left time: 26.2159s\n",
      "\titers: 500, epoch: 5 | loss: 0.1760837\n",
      "\tspeed: 0.0294s/iter; left time: 25.3954s\n",
      "\titers: 600, epoch: 5 | loss: 0.3371019\n",
      "\tspeed: 0.0270s/iter; left time: 20.6817s\n",
      "Epoch: 5 cost time: 18.474271059036255\n",
      "Epoch: 5, Steps: 682 | Train Loss: 0.1558503 Vali Loss: 0.3221482 Test Loss: 0.2440140\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3651761\n",
      "\tspeed: 0.0768s/iter; left time: 44.8008s\n",
      "\titers: 200, epoch: 6 | loss: 0.1575287\n",
      "\tspeed: 0.0270s/iter; left time: 13.0431s\n",
      "\titers: 300, epoch: 6 | loss: 0.1451578\n",
      "\tspeed: 0.0288s/iter; left time: 11.0484s\n",
      "\titers: 400, epoch: 6 | loss: 0.1313094\n",
      "\tspeed: 0.0269s/iter; left time: 7.6029s\n",
      "\titers: 500, epoch: 6 | loss: 0.0717535\n",
      "\tspeed: 0.0272s/iter; left time: 4.9763s\n",
      "\titers: 600, epoch: 6 | loss: 0.0845199\n",
      "\tspeed: 0.0264s/iter; left time: 2.1877s\n",
      "Epoch: 6 cost time: 18.41642951965332\n",
      "Epoch: 6, Steps: 682 | Train Loss: 0.1507185 Vali Loss: 0.3226632 Test Loss: 0.2444243\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "Test cost time: 1.8486s\n",
      "test shape: (182, 32, 6, 1) (182, 32, 6, 1)\n",
      "test shape: (5824, 6, 1) (5824, 6, 1)\n",
      "mse:0.2479049116373062, mae:0.33073338866233826\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1697.5970458984375\n",
      "MAE:  27.36861228942871\n",
      "RMSE: 41.201904296875\n",
      "MAPE: 0.3397752344608307\n",
      "MSPE: 0.578265905380249\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24443\n",
      "[DEBUG] Original dataset length: 24443\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21825\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3399\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "\titers: 100, epoch: 1 | loss: 0.3165544\n",
      "\tspeed: 0.0259s/iter; left time: 103.2990s\n",
      "\titers: 200, epoch: 1 | loss: 0.1972222\n",
      "\tspeed: 0.0276s/iter; left time: 107.4538s\n",
      "\titers: 300, epoch: 1 | loss: 0.3473387\n",
      "\tspeed: 0.0273s/iter; left time: 103.6064s\n",
      "\titers: 400, epoch: 1 | loss: 0.3760364\n",
      "\tspeed: 0.0272s/iter; left time: 100.5191s\n",
      "\titers: 500, epoch: 1 | loss: 0.2257225\n",
      "\tspeed: 0.0295s/iter; left time: 106.1417s\n",
      "\titers: 600, epoch: 1 | loss: 0.2509027\n",
      "\tspeed: 0.0286s/iter; left time: 99.7555s\n",
      "Epoch: 1 cost time: 18.941087245941162\n",
      "Epoch: 1, Steps: 682 | Train Loss: 0.2779901 Vali Loss: 0.3443411 Test Loss: 0.2837254\n",
      "Validation loss decreased (inf --> 0.344341).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1516568\n",
      "\tspeed: 0.0833s/iter; left time: 275.9013s\n",
      "\titers: 200, epoch: 2 | loss: 0.1553725\n",
      "\tspeed: 0.0295s/iter; left time: 94.8135s\n",
      "\titers: 300, epoch: 2 | loss: 0.2678145\n",
      "\tspeed: 0.0282s/iter; left time: 87.7289s\n",
      "\titers: 400, epoch: 2 | loss: 0.1790532\n",
      "\tspeed: 0.0286s/iter; left time: 86.1479s\n",
      "\titers: 500, epoch: 2 | loss: 0.2894240\n",
      "\tspeed: 0.0276s/iter; left time: 80.4030s\n",
      "\titers: 600, epoch: 2 | loss: 0.3504165\n",
      "\tspeed: 0.0275s/iter; left time: 77.3521s\n",
      "Epoch: 2 cost time: 19.210870027542114\n",
      "Epoch: 2, Steps: 682 | Train Loss: 0.2108609 Vali Loss: 0.3169678 Test Loss: 0.2645910\n",
      "Validation loss decreased (0.344341 --> 0.316968).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2110490\n",
      "\tspeed: 0.0784s/iter; left time: 206.1018s\n",
      "\titers: 200, epoch: 3 | loss: 0.2272308\n",
      "\tspeed: 0.0262s/iter; left time: 66.3465s\n",
      "\titers: 300, epoch: 3 | loss: 0.1536266\n",
      "\tspeed: 0.0269s/iter; left time: 65.2839s\n",
      "\titers: 400, epoch: 3 | loss: 0.1614529\n",
      "\tspeed: 0.0262s/iter; left time: 61.0551s\n",
      "\titers: 500, epoch: 3 | loss: 0.1857761\n",
      "\tspeed: 0.0284s/iter; left time: 63.3631s\n",
      "\titers: 600, epoch: 3 | loss: 0.1654629\n",
      "\tspeed: 0.0269s/iter; left time: 57.3471s\n",
      "Epoch: 3 cost time: 18.242027759552002\n",
      "Epoch: 3, Steps: 682 | Train Loss: 0.1817549 Vali Loss: 0.3129488 Test Loss: 0.2498384\n",
      "Validation loss decreased (0.316968 --> 0.312949).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1757537\n",
      "\tspeed: 0.0769s/iter; left time: 149.6515s\n",
      "\titers: 200, epoch: 4 | loss: 0.1113510\n",
      "\tspeed: 0.0267s/iter; left time: 49.3739s\n",
      "\titers: 300, epoch: 4 | loss: 0.2142215\n",
      "\tspeed: 0.0290s/iter; left time: 50.5955s\n",
      "\titers: 400, epoch: 4 | loss: 0.1644967\n",
      "\tspeed: 0.0265s/iter; left time: 43.6493s\n",
      "\titers: 500, epoch: 4 | loss: 0.0938500\n",
      "\tspeed: 0.0258s/iter; left time: 39.8592s\n",
      "\titers: 600, epoch: 4 | loss: 0.1156664\n",
      "\tspeed: 0.0273s/iter; left time: 39.5135s\n",
      "Epoch: 4 cost time: 18.20378565788269\n",
      "Epoch: 4, Steps: 682 | Train Loss: 0.1670165 Vali Loss: 0.3257425 Test Loss: 0.2545779\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2408505\n",
      "\tspeed: 0.0782s/iter; left time: 98.9480s\n",
      "\titers: 200, epoch: 5 | loss: 0.1381898\n",
      "\tspeed: 0.0264s/iter; left time: 30.7272s\n",
      "\titers: 300, epoch: 5 | loss: 0.2153209\n",
      "\tspeed: 0.0259s/iter; left time: 27.6048s\n",
      "\titers: 400, epoch: 5 | loss: 0.1507992\n",
      "\tspeed: 0.0271s/iter; left time: 26.1230s\n",
      "\titers: 500, epoch: 5 | loss: 0.1039045\n",
      "\tspeed: 0.0260s/iter; left time: 22.5138s\n",
      "\titers: 600, epoch: 5 | loss: 0.1044940\n",
      "\tspeed: 0.0288s/iter; left time: 21.9982s\n",
      "Epoch: 5 cost time: 18.457106351852417\n",
      "Epoch: 5, Steps: 682 | Train Loss: 0.1581261 Vali Loss: 0.3235669 Test Loss: 0.2552113\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1414226\n",
      "\tspeed: 0.0780s/iter; left time: 45.4822s\n",
      "\titers: 200, epoch: 6 | loss: 0.1399626\n",
      "\tspeed: 0.0287s/iter; left time: 13.8651s\n",
      "\titers: 300, epoch: 6 | loss: 0.1666801\n",
      "\tspeed: 0.0286s/iter; left time: 10.9693s\n",
      "\titers: 400, epoch: 6 | loss: 0.1384566\n",
      "\tspeed: 0.0284s/iter; left time: 8.0453s\n",
      "\titers: 500, epoch: 6 | loss: 0.1215099\n",
      "\tspeed: 0.0257s/iter; left time: 4.7042s\n",
      "\titers: 600, epoch: 6 | loss: 0.1435261\n",
      "\tspeed: 0.0279s/iter; left time: 2.3117s\n",
      "Epoch: 6 cost time: 18.678930044174194\n",
      "Epoch: 6, Steps: 682 | Train Loss: 0.1521719 Vali Loss: 0.3247287 Test Loss: 0.2554171\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "Test cost time: 1.7911s\n",
      "test shape: (182, 32, 6, 1) (182, 32, 6, 1)\n",
      "test shape: (5824, 6, 1) (5824, 6, 1)\n",
      "mse:0.24980705976486206, mae:0.3358624279499054\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1710.62255859375\n",
      "MAE:  27.793048858642578\n",
      "RMSE: 41.35967254638672\n",
      "MAPE: 0.33731046319007874\n",
      "MSPE: 0.4962155520915985\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24443\n",
      "[DEBUG] Original dataset length: 24443\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21825\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3399\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "\titers: 100, epoch: 1 | loss: 0.1899043\n",
      "\tspeed: 0.0284s/iter; left time: 113.4036s\n",
      "\titers: 200, epoch: 1 | loss: 0.3738380\n",
      "\tspeed: 0.0283s/iter; left time: 110.2400s\n",
      "\titers: 300, epoch: 1 | loss: 0.2462013\n",
      "\tspeed: 0.0291s/iter; left time: 110.4899s\n",
      "\titers: 400, epoch: 1 | loss: 0.2156356\n",
      "\tspeed: 0.0291s/iter; left time: 107.2877s\n",
      "\titers: 500, epoch: 1 | loss: 0.1599511\n",
      "\tspeed: 0.0275s/iter; left time: 98.7742s\n",
      "\titers: 600, epoch: 1 | loss: 0.1989864\n",
      "\tspeed: 0.0287s/iter; left time: 100.3179s\n",
      "Epoch: 1 cost time: 19.269129753112793\n",
      "Epoch: 1, Steps: 682 | Train Loss: 0.2857789 Vali Loss: 0.3345643 Test Loss: 0.2691937\n",
      "Validation loss decreased (inf --> 0.334564).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4132148\n",
      "\tspeed: 0.0779s/iter; left time: 258.0374s\n",
      "\titers: 200, epoch: 2 | loss: 0.1660288\n",
      "\tspeed: 0.0268s/iter; left time: 86.1569s\n",
      "\titers: 300, epoch: 2 | loss: 0.1879312\n",
      "\tspeed: 0.0274s/iter; left time: 85.1913s\n",
      "\titers: 400, epoch: 2 | loss: 0.2630319\n",
      "\tspeed: 0.0273s/iter; left time: 82.2500s\n",
      "\titers: 500, epoch: 2 | loss: 0.1770201\n",
      "\tspeed: 0.0267s/iter; left time: 77.6947s\n",
      "\titers: 600, epoch: 2 | loss: 0.1685830\n",
      "\tspeed: 0.0269s/iter; left time: 75.7309s\n",
      "Epoch: 2 cost time: 18.47166347503662\n",
      "Epoch: 2, Steps: 682 | Train Loss: 0.2103489 Vali Loss: 0.3166874 Test Loss: 0.2523125\n",
      "Validation loss decreased (0.334564 --> 0.316687).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1161624\n",
      "\tspeed: 0.0843s/iter; left time: 221.7124s\n",
      "\titers: 200, epoch: 3 | loss: 0.1604228\n",
      "\tspeed: 0.0350s/iter; left time: 88.6271s\n",
      "\titers: 300, epoch: 3 | loss: 0.1596742\n",
      "\tspeed: 0.0293s/iter; left time: 71.1715s\n",
      "\titers: 400, epoch: 3 | loss: 0.2001164\n",
      "\tspeed: 0.0276s/iter; left time: 64.3263s\n",
      "\titers: 500, epoch: 3 | loss: 0.1249386\n",
      "\tspeed: 0.0279s/iter; left time: 62.2148s\n",
      "\titers: 600, epoch: 3 | loss: 0.2188376\n",
      "\tspeed: 0.0271s/iter; left time: 57.6880s\n",
      "Epoch: 3 cost time: 19.795391082763672\n",
      "Epoch: 3, Steps: 682 | Train Loss: 0.1798211 Vali Loss: 0.3224898 Test Loss: 0.2543043\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0875032\n",
      "\tspeed: 0.0784s/iter; left time: 152.5752s\n",
      "\titers: 200, epoch: 4 | loss: 0.1398235\n",
      "\tspeed: 0.0263s/iter; left time: 48.5509s\n",
      "\titers: 300, epoch: 4 | loss: 0.1440236\n",
      "\tspeed: 0.0267s/iter; left time: 46.7253s\n",
      "\titers: 400, epoch: 4 | loss: 0.2119727\n",
      "\tspeed: 0.0285s/iter; left time: 46.8840s\n",
      "\titers: 500, epoch: 4 | loss: 0.1593795\n",
      "\tspeed: 0.0267s/iter; left time: 41.3371s\n",
      "\titers: 600, epoch: 4 | loss: 0.1409369\n",
      "\tspeed: 0.0258s/iter; left time: 37.3078s\n",
      "Epoch: 4 cost time: 18.432230234146118\n",
      "Epoch: 4, Steps: 682 | Train Loss: 0.1648326 Vali Loss: 0.3171203 Test Loss: 0.2499772\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1760938\n",
      "\tspeed: 0.0794s/iter; left time: 100.4082s\n",
      "\titers: 200, epoch: 5 | loss: 0.1917375\n",
      "\tspeed: 0.0268s/iter; left time: 31.2645s\n",
      "\titers: 300, epoch: 5 | loss: 0.1702748\n",
      "\tspeed: 0.0263s/iter; left time: 28.0058s\n",
      "\titers: 400, epoch: 5 | loss: 0.0777096\n",
      "\tspeed: 0.0263s/iter; left time: 25.4269s\n",
      "\titers: 500, epoch: 5 | loss: 0.2102502\n",
      "\tspeed: 0.0265s/iter; left time: 22.9473s\n",
      "\titers: 600, epoch: 5 | loss: 0.2252467\n",
      "\tspeed: 0.0264s/iter; left time: 20.1724s\n",
      "Epoch: 5 cost time: 18.413482427597046\n",
      "Epoch: 5, Steps: 682 | Train Loss: 0.1551710 Vali Loss: 0.3282226 Test Loss: 0.2505891\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "Test cost time: 1.8543s\n",
      "test shape: (182, 32, 6, 1) (182, 32, 6, 1)\n",
      "test shape: (5824, 6, 1) (5824, 6, 1)\n",
      "mse:0.25140658020973206, mae:0.33816689252853394\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1721.5758056640625\n",
      "MAE:  27.983749389648438\n",
      "RMSE: 41.49187469482422\n",
      "MAPE: 0.42343077063560486\n",
      "MSPE: 1.002115249633789\n",
      ">>>>>>>Running time saved<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Running seq_len=120\n",
      "Args in experiment:\n",
      "Namespace(model='informer', data='traffic_full', root_path='../', data_path='traffic_full.csv', features='S', target='flow', freq='h', checkpoints='./checkpoints/', seq_len=120, label_len=24, pred_len=6, enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=2, d_layers=1, s_layers=[3, 2, 1], d_ff=2048, factor=5, padding=0, distil=True, dropout=0.05, attn='prob', embed='timeF', activation='gelu', output_attention=False, do_predict=False, mix=True, cols=None, num_workers=0, itr=10, train_epochs=6, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, inverse=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', detail_freq='h')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24419\n",
      "[DEBUG] Original dataset length: 24419\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21417\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3375\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "\titers: 100, epoch: 1 | loss: 0.2775437\n",
      "\tspeed: 0.0432s/iter; left time: 169.2100s\n",
      "\titers: 200, epoch: 1 | loss: 0.3854808\n",
      "\tspeed: 0.0314s/iter; left time: 119.7533s\n",
      "\titers: 300, epoch: 1 | loss: 0.2519211\n",
      "\tspeed: 0.0289s/iter; left time: 107.4217s\n",
      "\titers: 400, epoch: 1 | loss: 0.1880044\n",
      "\tspeed: 0.0293s/iter; left time: 106.0943s\n",
      "\titers: 500, epoch: 1 | loss: 0.3217722\n",
      "\tspeed: 0.0301s/iter; left time: 105.7097s\n",
      "\titers: 600, epoch: 1 | loss: 0.3101066\n",
      "\tspeed: 0.0289s/iter; left time: 98.6926s\n",
      "Epoch: 1 cost time: 20.515965223312378\n",
      "Epoch: 1, Steps: 669 | Train Loss: 0.2671879 Vali Loss: 0.3432809 Test Loss: 0.2821105\n",
      "Validation loss decreased (inf --> 0.343281).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1976306\n",
      "\tspeed: 0.0849s/iter; left time: 275.5701s\n",
      "\titers: 200, epoch: 2 | loss: 0.2080810\n",
      "\tspeed: 0.0303s/iter; left time: 95.4702s\n",
      "\titers: 300, epoch: 2 | loss: 0.3059615\n",
      "\tspeed: 0.0298s/iter; left time: 90.6959s\n",
      "\titers: 400, epoch: 2 | loss: 0.3579123\n",
      "\tspeed: 0.0314s/iter; left time: 92.3671s\n",
      "\titers: 500, epoch: 2 | loss: 0.1496097\n",
      "\tspeed: 0.0295s/iter; left time: 83.9712s\n",
      "\titers: 600, epoch: 2 | loss: 0.1738634\n",
      "\tspeed: 0.0303s/iter; left time: 83.2658s\n",
      "Epoch: 2 cost time: 20.246329069137573\n",
      "Epoch: 2, Steps: 669 | Train Loss: 0.2038040 Vali Loss: 0.3302626 Test Loss: 0.2716062\n",
      "Validation loss decreased (0.343281 --> 0.330263).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1911066\n",
      "\tspeed: 0.0869s/iter; left time: 223.9728s\n",
      "\titers: 200, epoch: 3 | loss: 0.1172610\n",
      "\tspeed: 0.0303s/iter; left time: 75.1255s\n",
      "\titers: 300, epoch: 3 | loss: 0.1401329\n",
      "\tspeed: 0.0290s/iter; left time: 68.8978s\n",
      "\titers: 400, epoch: 3 | loss: 0.1603983\n",
      "\tspeed: 0.0305s/iter; left time: 69.3942s\n",
      "\titers: 500, epoch: 3 | loss: 0.2022779\n",
      "\tspeed: 0.0311s/iter; left time: 67.8111s\n",
      "\titers: 600, epoch: 3 | loss: 0.1597285\n",
      "\tspeed: 0.0323s/iter; left time: 67.0634s\n",
      "Epoch: 3 cost time: 20.597347497940063\n",
      "Epoch: 3, Steps: 669 | Train Loss: 0.1763249 Vali Loss: 0.3178843 Test Loss: 0.2603658\n",
      "Validation loss decreased (0.330263 --> 0.317884).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1874330\n",
      "\tspeed: 0.0847s/iter; left time: 161.5310s\n",
      "\titers: 200, epoch: 4 | loss: 0.2095532\n",
      "\tspeed: 0.0296s/iter; left time: 53.4971s\n",
      "\titers: 300, epoch: 4 | loss: 0.2718078\n",
      "\tspeed: 0.0312s/iter; left time: 53.3741s\n",
      "\titers: 400, epoch: 4 | loss: 0.2132269\n",
      "\tspeed: 0.0293s/iter; left time: 47.1484s\n",
      "\titers: 500, epoch: 4 | loss: 0.1531405\n",
      "\tspeed: 0.0298s/iter; left time: 44.9206s\n",
      "\titers: 600, epoch: 4 | loss: 0.1645782\n",
      "\tspeed: 0.0304s/iter; left time: 42.7333s\n",
      "Epoch: 4 cost time: 20.174452781677246\n",
      "Epoch: 4, Steps: 669 | Train Loss: 0.1607548 Vali Loss: 0.3240892 Test Loss: 0.2551031\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1143947\n",
      "\tspeed: 0.0857s/iter; left time: 106.2288s\n",
      "\titers: 200, epoch: 5 | loss: 0.1346461\n",
      "\tspeed: 0.0291s/iter; left time: 33.1613s\n",
      "\titers: 300, epoch: 5 | loss: 0.1228238\n",
      "\tspeed: 0.0287s/iter; left time: 29.8308s\n",
      "\titers: 400, epoch: 5 | loss: 0.2781194\n",
      "\tspeed: 0.0294s/iter; left time: 27.6534s\n",
      "\titers: 500, epoch: 5 | loss: 0.1671257\n",
      "\tspeed: 0.0290s/iter; left time: 24.3468s\n",
      "\titers: 600, epoch: 5 | loss: 0.3472005\n",
      "\tspeed: 0.0304s/iter; left time: 22.4311s\n",
      "Epoch: 5 cost time: 19.70596218109131\n",
      "Epoch: 5, Steps: 669 | Train Loss: 0.1506062 Vali Loss: 0.3153746 Test Loss: 0.2503872\n",
      "Validation loss decreased (0.317884 --> 0.315375).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1098132\n",
      "\tspeed: 0.0820s/iter; left time: 46.7163s\n",
      "\titers: 200, epoch: 6 | loss: 0.1989886\n",
      "\tspeed: 0.0302s/iter; left time: 14.2026s\n",
      "\titers: 300, epoch: 6 | loss: 0.0974840\n",
      "\tspeed: 0.0311s/iter; left time: 11.4996s\n",
      "\titers: 400, epoch: 6 | loss: 0.1158308\n",
      "\tspeed: 0.0290s/iter; left time: 7.8426s\n",
      "\titers: 500, epoch: 6 | loss: 0.1574945\n",
      "\tspeed: 0.0293s/iter; left time: 4.9755s\n",
      "\titers: 600, epoch: 6 | loss: 0.1291543\n",
      "\tspeed: 0.0293s/iter; left time: 2.0503s\n",
      "Epoch: 6 cost time: 19.804141521453857\n",
      "Epoch: 6, Steps: 669 | Train Loss: 0.1454971 Vali Loss: 0.3208154 Test Loss: 0.2548475\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "Test cost time: 2.0087s\n",
      "test shape: (177, 32, 6, 1) (177, 32, 6, 1)\n",
      "test shape: (5664, 6, 1) (5664, 6, 1)\n",
      "mse:0.25202882289886475, mae:0.3266088366508484\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1725.8369140625\n",
      "MAE:  27.027301788330078\n",
      "RMSE: 41.54319381713867\n",
      "MAPE: 0.3228450119495392\n",
      "MSPE: 0.4520597457885742\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24419\n",
      "[DEBUG] Original dataset length: 24419\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21417\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3375\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "\titers: 100, epoch: 1 | loss: 0.5353029\n",
      "\tspeed: 0.0287s/iter; left time: 112.2695s\n",
      "\titers: 200, epoch: 1 | loss: 0.2202507\n",
      "\tspeed: 0.0298s/iter; left time: 113.8730s\n",
      "\titers: 300, epoch: 1 | loss: 0.2817588\n",
      "\tspeed: 0.0289s/iter; left time: 107.3517s\n",
      "\titers: 400, epoch: 1 | loss: 0.2256988\n",
      "\tspeed: 0.0307s/iter; left time: 110.9448s\n",
      "\titers: 500, epoch: 1 | loss: 0.1377440\n",
      "\tspeed: 0.0293s/iter; left time: 103.1482s\n",
      "\titers: 600, epoch: 1 | loss: 0.3728626\n",
      "\tspeed: 0.0294s/iter; left time: 100.2658s\n",
      "Epoch: 1 cost time: 19.68725609779358\n",
      "Epoch: 1, Steps: 669 | Train Loss: 0.2835234 Vali Loss: 0.3193486 Test Loss: 0.2545001\n",
      "Validation loss decreased (inf --> 0.319349).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3293202\n",
      "\tspeed: 0.0830s/iter; left time: 269.3607s\n",
      "\titers: 200, epoch: 2 | loss: 0.2064656\n",
      "\tspeed: 0.0307s/iter; left time: 96.5318s\n",
      "\titers: 300, epoch: 2 | loss: 0.1816770\n",
      "\tspeed: 0.0296s/iter; left time: 90.2621s\n",
      "\titers: 400, epoch: 2 | loss: 0.1724292\n",
      "\tspeed: 0.0295s/iter; left time: 87.0413s\n",
      "\titers: 500, epoch: 2 | loss: 0.1883586\n",
      "\tspeed: 0.0291s/iter; left time: 82.6839s\n",
      "\titers: 600, epoch: 2 | loss: 0.1452887\n",
      "\tspeed: 0.0299s/iter; left time: 82.0971s\n",
      "Epoch: 2 cost time: 19.995731353759766\n",
      "Epoch: 2, Steps: 669 | Train Loss: 0.2025141 Vali Loss: 0.3225348 Test Loss: 0.2543524\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2369109\n",
      "\tspeed: 0.0847s/iter; left time: 218.1497s\n",
      "\titers: 200, epoch: 3 | loss: 0.2358586\n",
      "\tspeed: 0.0287s/iter; left time: 71.1507s\n",
      "\titers: 300, epoch: 3 | loss: 0.1286654\n",
      "\tspeed: 0.0300s/iter; left time: 71.3540s\n",
      "\titers: 400, epoch: 3 | loss: 0.1569397\n",
      "\tspeed: 0.0317s/iter; left time: 72.2176s\n",
      "\titers: 500, epoch: 3 | loss: 0.2378858\n",
      "\tspeed: 0.0298s/iter; left time: 64.8873s\n",
      "\titers: 600, epoch: 3 | loss: 0.1268125\n",
      "\tspeed: 0.0299s/iter; left time: 62.0426s\n",
      "Epoch: 3 cost time: 20.05463218688965\n",
      "Epoch: 3, Steps: 669 | Train Loss: 0.1764569 Vali Loss: 0.3140378 Test Loss: 0.2513151\n",
      "Validation loss decreased (0.319349 --> 0.314038).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0890388\n",
      "\tspeed: 0.0853s/iter; left time: 162.7977s\n",
      "\titers: 200, epoch: 4 | loss: 0.2339140\n",
      "\tspeed: 0.0288s/iter; left time: 52.0688s\n",
      "\titers: 300, epoch: 4 | loss: 0.2123974\n",
      "\tspeed: 0.0286s/iter; left time: 48.7838s\n",
      "\titers: 400, epoch: 4 | loss: 0.1333164\n",
      "\tspeed: 0.0290s/iter; left time: 46.5798s\n",
      "\titers: 500, epoch: 4 | loss: 0.2218991\n",
      "\tspeed: 0.0289s/iter; left time: 43.5590s\n",
      "\titers: 600, epoch: 4 | loss: 0.0966213\n",
      "\tspeed: 0.0309s/iter; left time: 43.5382s\n",
      "Epoch: 4 cost time: 19.773286819458008\n",
      "Epoch: 4, Steps: 669 | Train Loss: 0.1612962 Vali Loss: 0.3308921 Test Loss: 0.2601327\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1357725\n",
      "\tspeed: 0.0823s/iter; left time: 101.9814s\n",
      "\titers: 200, epoch: 5 | loss: 0.1945419\n",
      "\tspeed: 0.0286s/iter; left time: 32.5820s\n",
      "\titers: 300, epoch: 5 | loss: 0.1169321\n",
      "\tspeed: 0.0315s/iter; left time: 32.7349s\n",
      "\titers: 400, epoch: 5 | loss: 0.1361889\n",
      "\tspeed: 0.0286s/iter; left time: 26.8185s\n",
      "\titers: 500, epoch: 5 | loss: 0.1449561\n",
      "\tspeed: 0.0299s/iter; left time: 25.1196s\n",
      "\titers: 600, epoch: 5 | loss: 0.1638429\n",
      "\tspeed: 0.0296s/iter; left time: 21.8791s\n",
      "Epoch: 5 cost time: 19.743263959884644\n",
      "Epoch: 5, Steps: 669 | Train Loss: 0.1520652 Vali Loss: 0.3258638 Test Loss: 0.2532049\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0962587\n",
      "\tspeed: 0.0826s/iter; left time: 47.1025s\n",
      "\titers: 200, epoch: 6 | loss: 0.1794239\n",
      "\tspeed: 0.0297s/iter; left time: 13.9445s\n",
      "\titers: 300, epoch: 6 | loss: 0.1207270\n",
      "\tspeed: 0.0279s/iter; left time: 10.3411s\n",
      "\titers: 400, epoch: 6 | loss: 0.1576193\n",
      "\tspeed: 0.0286s/iter; left time: 7.7322s\n",
      "\titers: 500, epoch: 6 | loss: 0.1473337\n",
      "\tspeed: 0.0290s/iter; left time: 4.9348s\n",
      "\titers: 600, epoch: 6 | loss: 0.1149782\n",
      "\tspeed: 0.0313s/iter; left time: 2.1876s\n",
      "Epoch: 6 cost time: 19.737404823303223\n",
      "Epoch: 6, Steps: 669 | Train Loss: 0.1469598 Vali Loss: 0.3206567 Test Loss: 0.2542932\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "Test cost time: 2.0977s\n",
      "test shape: (177, 32, 6, 1) (177, 32, 6, 1)\n",
      "test shape: (5664, 6, 1) (5664, 6, 1)\n",
      "mse:0.25152868032455444, mae:0.33450156450271606\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1722.4117431640625\n",
      "MAE:  27.68043327331543\n",
      "RMSE: 41.501949310302734\n",
      "MAPE: 0.3777657747268677\n",
      "MSPE: 0.7317356467247009\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24419\n",
      "[DEBUG] Original dataset length: 24419\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21417\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3375\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "\titers: 100, epoch: 1 | loss: 0.3722519\n",
      "\tspeed: 0.0294s/iter; left time: 115.1401s\n",
      "\titers: 200, epoch: 1 | loss: 0.2078429\n",
      "\tspeed: 0.0312s/iter; left time: 119.0026s\n",
      "\titers: 300, epoch: 1 | loss: 0.1992542\n",
      "\tspeed: 0.0297s/iter; left time: 110.4590s\n",
      "\titers: 400, epoch: 1 | loss: 0.1959002\n",
      "\tspeed: 0.0284s/iter; left time: 102.8048s\n",
      "\titers: 500, epoch: 1 | loss: 0.2454617\n",
      "\tspeed: 0.0292s/iter; left time: 102.6795s\n",
      "\titers: 600, epoch: 1 | loss: 0.2298204\n",
      "\tspeed: 0.0289s/iter; left time: 98.6916s\n",
      "Epoch: 1 cost time: 19.82342219352722\n",
      "Epoch: 1, Steps: 669 | Train Loss: 0.2722199 Vali Loss: 0.3460421 Test Loss: 0.2811190\n",
      "Validation loss decreased (inf --> 0.346042).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1345122\n",
      "\tspeed: 0.0858s/iter; left time: 278.5615s\n",
      "\titers: 200, epoch: 2 | loss: 0.1781741\n",
      "\tspeed: 0.0309s/iter; left time: 97.1203s\n",
      "\titers: 300, epoch: 2 | loss: 0.1688313\n",
      "\tspeed: 0.0298s/iter; left time: 90.7331s\n",
      "\titers: 400, epoch: 2 | loss: 0.1567043\n",
      "\tspeed: 0.0322s/iter; left time: 94.8994s\n",
      "\titers: 500, epoch: 2 | loss: 0.1289862\n",
      "\tspeed: 0.0301s/iter; left time: 85.7472s\n",
      "\titers: 600, epoch: 2 | loss: 0.1606031\n",
      "\tspeed: 0.0296s/iter; left time: 81.2907s\n",
      "Epoch: 2 cost time: 20.461806297302246\n",
      "Epoch: 2, Steps: 669 | Train Loss: 0.2033413 Vali Loss: 0.3444316 Test Loss: 0.2736827\n",
      "Validation loss decreased (0.346042 --> 0.344432).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1336813\n",
      "\tspeed: 0.0836s/iter; left time: 215.4440s\n",
      "\titers: 200, epoch: 3 | loss: 0.1990564\n",
      "\tspeed: 0.0302s/iter; left time: 74.7788s\n",
      "\titers: 300, epoch: 3 | loss: 0.1341690\n",
      "\tspeed: 0.0298s/iter; left time: 70.8202s\n",
      "\titers: 400, epoch: 3 | loss: 0.1507725\n",
      "\tspeed: 0.0305s/iter; left time: 69.5228s\n",
      "\titers: 500, epoch: 3 | loss: 0.1556357\n",
      "\tspeed: 0.0302s/iter; left time: 65.7968s\n",
      "\titers: 600, epoch: 3 | loss: 0.1334959\n",
      "\tspeed: 0.0318s/iter; left time: 66.0478s\n",
      "Epoch: 3 cost time: 20.2076575756073\n",
      "Epoch: 3, Steps: 669 | Train Loss: 0.1777899 Vali Loss: 0.3137172 Test Loss: 0.2442333\n",
      "Validation loss decreased (0.344432 --> 0.313717).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2161897\n",
      "\tspeed: 0.0841s/iter; left time: 160.5332s\n",
      "\titers: 200, epoch: 4 | loss: 0.1258255\n",
      "\tspeed: 0.0306s/iter; left time: 55.3721s\n",
      "\titers: 300, epoch: 4 | loss: 0.2240745\n",
      "\tspeed: 0.0315s/iter; left time: 53.8771s\n",
      "\titers: 400, epoch: 4 | loss: 0.1221924\n",
      "\tspeed: 0.0289s/iter; left time: 46.4255s\n",
      "\titers: 500, epoch: 4 | loss: 0.1536993\n",
      "\tspeed: 0.0295s/iter; left time: 44.4526s\n",
      "\titers: 600, epoch: 4 | loss: 0.1682727\n",
      "\tspeed: 0.0301s/iter; left time: 42.4045s\n",
      "Epoch: 4 cost time: 20.15827775001526\n",
      "Epoch: 4, Steps: 669 | Train Loss: 0.1615465 Vali Loss: 0.3182318 Test Loss: 0.2458278\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1275859\n",
      "\tspeed: 0.0865s/iter; left time: 107.2235s\n",
      "\titers: 200, epoch: 5 | loss: 0.1459723\n",
      "\tspeed: 0.0288s/iter; left time: 32.7485s\n",
      "\titers: 300, epoch: 5 | loss: 0.1253775\n",
      "\tspeed: 0.0291s/iter; left time: 30.1922s\n",
      "\titers: 400, epoch: 5 | loss: 0.1553330\n",
      "\tspeed: 0.0282s/iter; left time: 26.5248s\n",
      "\titers: 500, epoch: 5 | loss: 0.2334034\n",
      "\tspeed: 0.0308s/iter; left time: 25.8070s\n",
      "\titers: 600, epoch: 5 | loss: 0.1953025\n",
      "\tspeed: 0.0302s/iter; left time: 22.3326s\n",
      "Epoch: 5 cost time: 19.784204483032227\n",
      "Epoch: 5, Steps: 669 | Train Loss: 0.1527169 Vali Loss: 0.3183437 Test Loss: 0.2484394\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1459051\n",
      "\tspeed: 0.0823s/iter; left time: 46.9220s\n",
      "\titers: 200, epoch: 6 | loss: 0.0881931\n",
      "\tspeed: 0.0301s/iter; left time: 14.1525s\n",
      "\titers: 300, epoch: 6 | loss: 0.1513776\n",
      "\tspeed: 0.0306s/iter; left time: 11.3291s\n",
      "\titers: 400, epoch: 6 | loss: 0.1046793\n",
      "\tspeed: 0.0301s/iter; left time: 8.1302s\n",
      "\titers: 500, epoch: 6 | loss: 0.1748990\n",
      "\tspeed: 0.0289s/iter; left time: 4.9114s\n",
      "\titers: 600, epoch: 6 | loss: 0.1783435\n",
      "\tspeed: 0.0295s/iter; left time: 2.0616s\n",
      "Epoch: 6 cost time: 19.856738328933716\n",
      "Epoch: 6, Steps: 669 | Train Loss: 0.1473295 Vali Loss: 0.3328100 Test Loss: 0.2570680\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "Test cost time: 2.0554s\n",
      "test shape: (177, 32, 6, 1) (177, 32, 6, 1)\n",
      "test shape: (5664, 6, 1) (5664, 6, 1)\n",
      "mse:0.24445855617523193, mae:0.32256603240966797\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1673.997314453125\n",
      "MAE:  26.692752838134766\n",
      "RMSE: 40.914512634277344\n",
      "MAPE: 0.30658742785453796\n",
      "MSPE: 0.408983051776886\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24419\n",
      "[DEBUG] Original dataset length: 24419\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21417\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3375\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "\titers: 100, epoch: 1 | loss: 0.1766875\n",
      "\tspeed: 0.0296s/iter; left time: 115.8071s\n",
      "\titers: 200, epoch: 1 | loss: 0.2898481\n",
      "\tspeed: 0.0293s/iter; left time: 111.7454s\n",
      "\titers: 300, epoch: 1 | loss: 0.1890761\n",
      "\tspeed: 0.0292s/iter; left time: 108.5209s\n",
      "\titers: 400, epoch: 1 | loss: 0.3579829\n",
      "\tspeed: 0.0317s/iter; left time: 114.5493s\n",
      "\titers: 500, epoch: 1 | loss: 0.2242780\n",
      "\tspeed: 0.0292s/iter; left time: 102.7072s\n",
      "\titers: 600, epoch: 1 | loss: 0.1969734\n",
      "\tspeed: 0.0295s/iter; left time: 100.7753s\n",
      "Epoch: 1 cost time: 19.8271963596344\n",
      "Epoch: 1, Steps: 669 | Train Loss: 0.2792591 Vali Loss: 0.3477232 Test Loss: 0.2717884\n",
      "Validation loss decreased (inf --> 0.347723).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2274358\n",
      "\tspeed: 0.0821s/iter; left time: 266.4467s\n",
      "\titers: 200, epoch: 2 | loss: 0.1619924\n",
      "\tspeed: 0.0290s/iter; left time: 91.3549s\n",
      "\titers: 300, epoch: 2 | loss: 0.2213582\n",
      "\tspeed: 0.0286s/iter; left time: 87.1551s\n",
      "\titers: 400, epoch: 2 | loss: 0.1845807\n",
      "\tspeed: 0.0295s/iter; left time: 86.8071s\n",
      "\titers: 500, epoch: 2 | loss: 0.1090104\n",
      "\tspeed: 0.0301s/iter; left time: 85.7097s\n",
      "\titers: 600, epoch: 2 | loss: 0.1955018\n",
      "\tspeed: 0.0308s/iter; left time: 84.6219s\n",
      "Epoch: 2 cost time: 19.763458967208862\n",
      "Epoch: 2, Steps: 669 | Train Loss: 0.2061150 Vali Loss: 0.3415181 Test Loss: 0.2717795\n",
      "Validation loss decreased (0.347723 --> 0.341518).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1305665\n",
      "\tspeed: 0.0827s/iter; left time: 213.1702s\n",
      "\titers: 200, epoch: 3 | loss: 0.3152400\n",
      "\tspeed: 0.0293s/iter; left time: 72.5801s\n",
      "\titers: 300, epoch: 3 | loss: 0.1867478\n",
      "\tspeed: 0.0298s/iter; left time: 70.7890s\n",
      "\titers: 400, epoch: 3 | loss: 0.1817921\n",
      "\tspeed: 0.0313s/iter; left time: 71.3483s\n",
      "\titers: 500, epoch: 3 | loss: 0.1659057\n",
      "\tspeed: 0.0291s/iter; left time: 63.4420s\n",
      "\titers: 600, epoch: 3 | loss: 0.1748783\n",
      "\tspeed: 0.0290s/iter; left time: 60.1359s\n",
      "Epoch: 3 cost time: 19.871044874191284\n",
      "Epoch: 3, Steps: 669 | Train Loss: 0.1777980 Vali Loss: 0.3171933 Test Loss: 0.2709894\n",
      "Validation loss decreased (0.341518 --> 0.317193).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1415166\n",
      "\tspeed: 0.0852s/iter; left time: 162.6109s\n",
      "\titers: 200, epoch: 4 | loss: 0.3948245\n",
      "\tspeed: 0.0297s/iter; left time: 53.6173s\n",
      "\titers: 300, epoch: 4 | loss: 0.1120557\n",
      "\tspeed: 0.0291s/iter; left time: 49.6209s\n",
      "\titers: 400, epoch: 4 | loss: 0.0839110\n",
      "\tspeed: 0.0294s/iter; left time: 47.2753s\n",
      "\titers: 500, epoch: 4 | loss: 0.1490628\n",
      "\tspeed: 0.0294s/iter; left time: 44.3397s\n",
      "\titers: 600, epoch: 4 | loss: 0.1540286\n",
      "\tspeed: 0.0306s/iter; left time: 43.1461s\n",
      "Epoch: 4 cost time: 19.867923259735107\n",
      "Epoch: 4, Steps: 669 | Train Loss: 0.1637007 Vali Loss: 0.3157906 Test Loss: 0.2489892\n",
      "Validation loss decreased (0.317193 --> 0.315791).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1293163\n",
      "\tspeed: 0.0821s/iter; left time: 101.7446s\n",
      "\titers: 200, epoch: 5 | loss: 0.1053158\n",
      "\tspeed: 0.0295s/iter; left time: 33.5606s\n",
      "\titers: 300, epoch: 5 | loss: 0.1356285\n",
      "\tspeed: 0.0314s/iter; left time: 32.6462s\n",
      "\titers: 400, epoch: 5 | loss: 0.1257097\n",
      "\tspeed: 0.0291s/iter; left time: 27.3035s\n",
      "\titers: 500, epoch: 5 | loss: 0.1213887\n",
      "\tspeed: 0.0299s/iter; left time: 25.0962s\n",
      "\titers: 600, epoch: 5 | loss: 0.1021550\n",
      "\tspeed: 0.0302s/iter; left time: 22.2878s\n",
      "Epoch: 5 cost time: 19.879157304763794\n",
      "Epoch: 5, Steps: 669 | Train Loss: 0.1534192 Vali Loss: 0.3290899 Test Loss: 0.2595619\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1696480\n",
      "\tspeed: 0.0841s/iter; left time: 47.9189s\n",
      "\titers: 200, epoch: 6 | loss: 0.1827508\n",
      "\tspeed: 0.0296s/iter; left time: 13.9113s\n",
      "\titers: 300, epoch: 6 | loss: 0.1492134\n",
      "\tspeed: 0.0303s/iter; left time: 11.2069s\n",
      "\titers: 400, epoch: 6 | loss: 0.1473132\n",
      "\tspeed: 0.0307s/iter; left time: 8.2769s\n",
      "\titers: 500, epoch: 6 | loss: 0.1199862\n",
      "\tspeed: 0.0314s/iter; left time: 5.3412s\n",
      "\titers: 600, epoch: 6 | loss: 0.1447994\n",
      "\tspeed: 0.0302s/iter; left time: 2.1168s\n",
      "Epoch: 6 cost time: 20.330076694488525\n",
      "Epoch: 6, Steps: 669 | Train Loss: 0.1479750 Vali Loss: 0.3305779 Test Loss: 0.2603847\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "Test cost time: 2.0830s\n",
      "test shape: (177, 32, 6, 1) (177, 32, 6, 1)\n",
      "test shape: (5664, 6, 1) (5664, 6, 1)\n",
      "mse:0.24830690026283264, mae:0.32285362482070923\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1700.35009765625\n",
      "MAE:  26.716552734375\n",
      "RMSE: 41.23530197143555\n",
      "MAPE: 0.32526084780693054\n",
      "MSPE: 0.5185482501983643\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24419\n",
      "[DEBUG] Original dataset length: 24419\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21417\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3375\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "\titers: 100, epoch: 1 | loss: 0.3129759\n",
      "\tspeed: 0.0308s/iter; left time: 120.5281s\n",
      "\titers: 200, epoch: 1 | loss: 0.3183265\n",
      "\tspeed: 0.0314s/iter; left time: 119.8452s\n",
      "\titers: 300, epoch: 1 | loss: 0.2155317\n",
      "\tspeed: 0.0302s/iter; left time: 112.0263s\n",
      "\titers: 400, epoch: 1 | loss: 0.1623970\n",
      "\tspeed: 0.0290s/iter; left time: 104.8507s\n",
      "\titers: 500, epoch: 1 | loss: 0.3066226\n",
      "\tspeed: 0.0292s/iter; left time: 102.7804s\n",
      "\titers: 600, epoch: 1 | loss: 0.1395139\n",
      "\tspeed: 0.0309s/iter; left time: 105.4476s\n",
      "Epoch: 1 cost time: 20.215270280838013\n",
      "Epoch: 1, Steps: 669 | Train Loss: 0.2814849 Vali Loss: 0.3367173 Test Loss: 0.2795452\n",
      "Validation loss decreased (inf --> 0.336717).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4737352\n",
      "\tspeed: 0.0831s/iter; left time: 269.7210s\n",
      "\titers: 200, epoch: 2 | loss: 0.1848485\n",
      "\tspeed: 0.0300s/iter; left time: 94.3635s\n",
      "\titers: 300, epoch: 2 | loss: 0.1400216\n",
      "\tspeed: 0.0304s/iter; left time: 92.5156s\n",
      "\titers: 400, epoch: 2 | loss: 0.3328413\n",
      "\tspeed: 0.0301s/iter; left time: 88.6974s\n",
      "\titers: 500, epoch: 2 | loss: 0.2249845\n",
      "\tspeed: 0.0291s/iter; left time: 82.7807s\n",
      "\titers: 600, epoch: 2 | loss: 0.2149262\n",
      "\tspeed: 0.0286s/iter; left time: 78.5552s\n",
      "Epoch: 2 cost time: 19.750216960906982\n",
      "Epoch: 2, Steps: 669 | Train Loss: 0.2089880 Vali Loss: 0.3343337 Test Loss: 0.2789277\n",
      "Validation loss decreased (0.336717 --> 0.334334).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2431273\n",
      "\tspeed: 0.0860s/iter; left time: 221.6141s\n",
      "\titers: 200, epoch: 3 | loss: 0.1977098\n",
      "\tspeed: 0.0292s/iter; left time: 72.3509s\n",
      "\titers: 300, epoch: 3 | loss: 0.1726256\n",
      "\tspeed: 0.0285s/iter; left time: 67.8065s\n",
      "\titers: 400, epoch: 3 | loss: 0.1581546\n",
      "\tspeed: 0.0287s/iter; left time: 65.2416s\n",
      "\titers: 500, epoch: 3 | loss: 0.2978215\n",
      "\tspeed: 0.0290s/iter; left time: 63.1750s\n",
      "\titers: 600, epoch: 3 | loss: 0.2591465\n",
      "\tspeed: 0.0310s/iter; left time: 64.3723s\n",
      "Epoch: 3 cost time: 19.970731496810913\n",
      "Epoch: 3, Steps: 669 | Train Loss: 0.1785396 Vali Loss: 0.3185647 Test Loss: 0.2581359\n",
      "Validation loss decreased (0.334334 --> 0.318565).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1771811\n",
      "\tspeed: 0.0844s/iter; left time: 161.1179s\n",
      "\titers: 200, epoch: 4 | loss: 0.1134176\n",
      "\tspeed: 0.0289s/iter; left time: 52.1938s\n",
      "\titers: 300, epoch: 4 | loss: 0.2656380\n",
      "\tspeed: 0.0306s/iter; left time: 52.1833s\n",
      "\titers: 400, epoch: 4 | loss: 0.1405503\n",
      "\tspeed: 0.0288s/iter; left time: 46.3140s\n",
      "\titers: 500, epoch: 4 | loss: 0.2711481\n",
      "\tspeed: 0.0289s/iter; left time: 43.5685s\n",
      "\titers: 600, epoch: 4 | loss: 0.1933218\n",
      "\tspeed: 0.0296s/iter; left time: 41.6899s\n",
      "Epoch: 4 cost time: 19.49726676940918\n",
      "Epoch: 4, Steps: 669 | Train Loss: 0.1619136 Vali Loss: 0.3220675 Test Loss: 0.2595217\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1651717\n",
      "\tspeed: 0.0820s/iter; left time: 101.5486s\n",
      "\titers: 200, epoch: 5 | loss: 0.1040614\n",
      "\tspeed: 0.0289s/iter; left time: 32.9685s\n",
      "\titers: 300, epoch: 5 | loss: 0.1625568\n",
      "\tspeed: 0.0289s/iter; left time: 29.9839s\n",
      "\titers: 400, epoch: 5 | loss: 0.1254661\n",
      "\tspeed: 0.0310s/iter; left time: 29.0693s\n",
      "\titers: 500, epoch: 5 | loss: 0.1224186\n",
      "\tspeed: 0.0307s/iter; left time: 25.7364s\n",
      "\titers: 600, epoch: 5 | loss: 0.1105497\n",
      "\tspeed: 0.0318s/iter; left time: 23.4847s\n",
      "Epoch: 5 cost time: 20.129689693450928\n",
      "Epoch: 5, Steps: 669 | Train Loss: 0.1524313 Vali Loss: 0.3248854 Test Loss: 0.2572644\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1269851\n",
      "\tspeed: 0.0839s/iter; left time: 47.8024s\n",
      "\titers: 200, epoch: 6 | loss: 0.2270852\n",
      "\tspeed: 0.0292s/iter; left time: 13.7311s\n",
      "\titers: 300, epoch: 6 | loss: 0.1456115\n",
      "\tspeed: 0.0309s/iter; left time: 11.4254s\n",
      "\titers: 400, epoch: 6 | loss: 0.1440899\n",
      "\tspeed: 0.0291s/iter; left time: 7.8500s\n",
      "\titers: 500, epoch: 6 | loss: 0.3186296\n",
      "\tspeed: 0.0294s/iter; left time: 4.9965s\n",
      "\titers: 600, epoch: 6 | loss: 0.1303986\n",
      "\tspeed: 0.0287s/iter; left time: 2.0102s\n",
      "Epoch: 6 cost time: 19.639769315719604\n",
      "Epoch: 6, Steps: 669 | Train Loss: 0.1476486 Vali Loss: 0.3225944 Test Loss: 0.2544409\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "Test cost time: 1.9958s\n",
      "test shape: (177, 32, 6, 1) (177, 32, 6, 1)\n",
      "test shape: (5664, 6, 1) (5664, 6, 1)\n",
      "mse:0.25720837712287903, mae:0.32841095328330994\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1761.3050537109375\n",
      "MAE:  27.176427841186523\n",
      "RMSE: 41.96790313720703\n",
      "MAPE: 0.31747156381607056\n",
      "MSPE: 0.4644535481929779\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24419\n",
      "[DEBUG] Original dataset length: 24419\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21417\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3375\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "\titers: 100, epoch: 1 | loss: 0.3175164\n",
      "\tspeed: 0.0283s/iter; left time: 110.6791s\n",
      "\titers: 200, epoch: 1 | loss: 0.2460282\n",
      "\tspeed: 0.0293s/iter; left time: 111.7100s\n",
      "\titers: 300, epoch: 1 | loss: 0.2169060\n",
      "\tspeed: 0.0290s/iter; left time: 107.6451s\n",
      "\titers: 400, epoch: 1 | loss: 0.2816267\n",
      "\tspeed: 0.0316s/iter; left time: 114.2832s\n",
      "\titers: 500, epoch: 1 | loss: 0.2790151\n",
      "\tspeed: 0.0308s/iter; left time: 108.2420s\n",
      "\titers: 600, epoch: 1 | loss: 0.4160570\n",
      "\tspeed: 0.0294s/iter; left time: 100.3294s\n",
      "Epoch: 1 cost time: 19.934784650802612\n",
      "Epoch: 1, Steps: 669 | Train Loss: 0.2755758 Vali Loss: 0.3420117 Test Loss: 0.2813919\n",
      "Validation loss decreased (inf --> 0.342012).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1903886\n",
      "\tspeed: 0.0856s/iter; left time: 278.0188s\n",
      "\titers: 200, epoch: 2 | loss: 0.2268245\n",
      "\tspeed: 0.0305s/iter; left time: 96.0655s\n",
      "\titers: 300, epoch: 2 | loss: 0.2251563\n",
      "\tspeed: 0.0294s/iter; left time: 89.6140s\n",
      "\titers: 400, epoch: 2 | loss: 0.2041740\n",
      "\tspeed: 0.0286s/iter; left time: 84.1513s\n",
      "\titers: 500, epoch: 2 | loss: 0.1849482\n",
      "\tspeed: 0.0298s/iter; left time: 84.7326s\n",
      "\titers: 600, epoch: 2 | loss: 0.1521134\n",
      "\tspeed: 0.0298s/iter; left time: 81.9549s\n",
      "Epoch: 2 cost time: 19.99004364013672\n",
      "Epoch: 2, Steps: 669 | Train Loss: 0.2056404 Vali Loss: 0.3295598 Test Loss: 0.2639320\n",
      "Validation loss decreased (0.342012 --> 0.329560).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1781307\n",
      "\tspeed: 0.0838s/iter; left time: 216.0203s\n",
      "\titers: 200, epoch: 3 | loss: 0.2166627\n",
      "\tspeed: 0.0288s/iter; left time: 71.4197s\n",
      "\titers: 300, epoch: 3 | loss: 0.1839844\n",
      "\tspeed: 0.0293s/iter; left time: 69.6889s\n",
      "\titers: 400, epoch: 3 | loss: 0.2134436\n",
      "\tspeed: 0.0304s/iter; left time: 69.3256s\n",
      "\titers: 500, epoch: 3 | loss: 0.1650638\n",
      "\tspeed: 0.0286s/iter; left time: 62.3048s\n",
      "\titers: 600, epoch: 3 | loss: 0.1389435\n",
      "\tspeed: 0.0285s/iter; left time: 59.2112s\n",
      "Epoch: 3 cost time: 19.468640327453613\n",
      "Epoch: 3, Steps: 669 | Train Loss: 0.1768164 Vali Loss: 0.3290736 Test Loss: 0.2496651\n",
      "Validation loss decreased (0.329560 --> 0.329074).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1700998\n",
      "\tspeed: 0.0847s/iter; left time: 161.5441s\n",
      "\titers: 200, epoch: 4 | loss: 0.1883674\n",
      "\tspeed: 0.0288s/iter; left time: 52.0590s\n",
      "\titers: 300, epoch: 4 | loss: 0.1378731\n",
      "\tspeed: 0.0294s/iter; left time: 50.2651s\n",
      "\titers: 400, epoch: 4 | loss: 0.2412249\n",
      "\tspeed: 0.0300s/iter; left time: 48.2076s\n",
      "\titers: 500, epoch: 4 | loss: 0.1179490\n",
      "\tspeed: 0.0294s/iter; left time: 44.2828s\n",
      "\titers: 600, epoch: 4 | loss: 0.1686318\n",
      "\tspeed: 0.0311s/iter; left time: 43.7782s\n",
      "Epoch: 4 cost time: 19.992467641830444\n",
      "Epoch: 4, Steps: 669 | Train Loss: 0.1613031 Vali Loss: 0.3274207 Test Loss: 0.2450488\n",
      "Validation loss decreased (0.329074 --> 0.327421).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1355752\n",
      "\tspeed: 0.0830s/iter; left time: 102.8797s\n",
      "\titers: 200, epoch: 5 | loss: 0.1340965\n",
      "\tspeed: 0.0292s/iter; left time: 33.2821s\n",
      "\titers: 300, epoch: 5 | loss: 0.1651927\n",
      "\tspeed: 0.0318s/iter; left time: 33.0710s\n",
      "\titers: 400, epoch: 5 | loss: 0.1535073\n",
      "\tspeed: 0.0298s/iter; left time: 27.9353s\n",
      "\titers: 500, epoch: 5 | loss: 0.1281655\n",
      "\tspeed: 0.0286s/iter; left time: 23.9570s\n",
      "\titers: 600, epoch: 5 | loss: 0.1093214\n",
      "\tspeed: 0.0289s/iter; left time: 21.3897s\n",
      "Epoch: 5 cost time: 19.603896617889404\n",
      "Epoch: 5, Steps: 669 | Train Loss: 0.1513299 Vali Loss: 0.3360975 Test Loss: 0.2464703\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1156439\n",
      "\tspeed: 0.0825s/iter; left time: 47.0011s\n",
      "\titers: 200, epoch: 6 | loss: 0.1227821\n",
      "\tspeed: 0.0280s/iter; left time: 13.1676s\n",
      "\titers: 300, epoch: 6 | loss: 0.1295363\n",
      "\tspeed: 0.0298s/iter; left time: 11.0418s\n",
      "\titers: 400, epoch: 6 | loss: 0.1316656\n",
      "\tspeed: 0.0369s/iter; left time: 9.9735s\n",
      "\titers: 500, epoch: 6 | loss: 0.1174205\n",
      "\tspeed: 0.0324s/iter; left time: 5.5160s\n",
      "\titers: 600, epoch: 6 | loss: 0.1590780\n",
      "\tspeed: 0.0300s/iter; left time: 2.1007s\n",
      "Epoch: 6 cost time: 20.793537139892578\n",
      "Epoch: 6, Steps: 669 | Train Loss: 0.1461874 Vali Loss: 0.3450511 Test Loss: 0.2517073\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "Test cost time: 1.9984s\n",
      "test shape: (177, 32, 6, 1) (177, 32, 6, 1)\n",
      "test shape: (5664, 6, 1) (5664, 6, 1)\n",
      "mse:0.24388404190540314, mae:0.3303932547569275\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1670.0631103515625\n",
      "MAE:  27.34046745300293\n",
      "RMSE: 40.86640548706055\n",
      "MAPE: 0.34752771258354187\n",
      "MSPE: 0.5988611578941345\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24419\n",
      "[DEBUG] Original dataset length: 24419\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21417\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3375\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "\titers: 100, epoch: 1 | loss: 0.2483055\n",
      "\tspeed: 0.0313s/iter; left time: 122.4440s\n",
      "\titers: 200, epoch: 1 | loss: 0.2184395\n",
      "\tspeed: 0.0291s/iter; left time: 111.1585s\n",
      "\titers: 300, epoch: 1 | loss: 0.3362479\n",
      "\tspeed: 0.0301s/iter; left time: 111.7839s\n",
      "\titers: 400, epoch: 1 | loss: 0.1719485\n",
      "\tspeed: 0.0299s/iter; left time: 108.0364s\n",
      "\titers: 500, epoch: 1 | loss: 0.2879986\n",
      "\tspeed: 0.0292s/iter; left time: 102.7952s\n",
      "\titers: 600, epoch: 1 | loss: 0.1799295\n",
      "\tspeed: 0.0310s/iter; left time: 105.9617s\n",
      "Epoch: 1 cost time: 20.065123081207275\n",
      "Epoch: 1, Steps: 669 | Train Loss: 0.2779948 Vali Loss: 0.3615663 Test Loss: 0.2974364\n",
      "Validation loss decreased (inf --> 0.361566).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2083639\n",
      "\tspeed: 0.0818s/iter; left time: 265.3878s\n",
      "\titers: 200, epoch: 2 | loss: 0.2779917\n",
      "\tspeed: 0.0293s/iter; left time: 92.2840s\n",
      "\titers: 300, epoch: 2 | loss: 0.2283624\n",
      "\tspeed: 0.0306s/iter; left time: 93.0614s\n",
      "\titers: 400, epoch: 2 | loss: 0.2376982\n",
      "\tspeed: 0.0305s/iter; left time: 89.8651s\n",
      "\titers: 500, epoch: 2 | loss: 0.1473158\n",
      "\tspeed: 0.0292s/iter; left time: 83.1350s\n",
      "\titers: 600, epoch: 2 | loss: 0.1933712\n",
      "\tspeed: 0.0297s/iter; left time: 81.6460s\n",
      "Epoch: 2 cost time: 19.80774474143982\n",
      "Epoch: 2, Steps: 669 | Train Loss: 0.2039512 Vali Loss: 0.3285629 Test Loss: 0.2609548\n",
      "Validation loss decreased (0.361566 --> 0.328563).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1916445\n",
      "\tspeed: 0.0854s/iter; left time: 220.1731s\n",
      "\titers: 200, epoch: 3 | loss: 0.1203380\n",
      "\tspeed: 0.0291s/iter; left time: 72.0709s\n",
      "\titers: 300, epoch: 3 | loss: 0.1825899\n",
      "\tspeed: 0.0311s/iter; left time: 74.0374s\n",
      "\titers: 400, epoch: 3 | loss: 0.1178923\n",
      "\tspeed: 0.0314s/iter; left time: 71.6047s\n",
      "\titers: 500, epoch: 3 | loss: 0.1693854\n",
      "\tspeed: 0.0302s/iter; left time: 65.7596s\n",
      "\titers: 600, epoch: 3 | loss: 0.1453839\n",
      "\tspeed: 0.0312s/iter; left time: 64.7248s\n",
      "Epoch: 3 cost time: 20.540021419525146\n",
      "Epoch: 3, Steps: 669 | Train Loss: 0.1752684 Vali Loss: 0.3160602 Test Loss: 0.2388015\n",
      "Validation loss decreased (0.328563 --> 0.316060).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1450907\n",
      "\tspeed: 0.0863s/iter; left time: 164.7084s\n",
      "\titers: 200, epoch: 4 | loss: 0.1507808\n",
      "\tspeed: 0.0305s/iter; left time: 55.1030s\n",
      "\titers: 300, epoch: 4 | loss: 0.1215773\n",
      "\tspeed: 0.0314s/iter; left time: 53.7132s\n",
      "\titers: 400, epoch: 4 | loss: 0.1039639\n",
      "\tspeed: 0.0296s/iter; left time: 47.6605s\n",
      "\titers: 500, epoch: 4 | loss: 0.1687682\n",
      "\tspeed: 0.0294s/iter; left time: 44.3306s\n",
      "\titers: 600, epoch: 4 | loss: 0.1373677\n",
      "\tspeed: 0.0299s/iter; left time: 42.0558s\n",
      "Epoch: 4 cost time: 20.181318044662476\n",
      "Epoch: 4, Steps: 669 | Train Loss: 0.1609861 Vali Loss: 0.3338525 Test Loss: 0.2516915\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1154382\n",
      "\tspeed: 0.0852s/iter; left time: 105.5120s\n",
      "\titers: 200, epoch: 5 | loss: 0.0716343\n",
      "\tspeed: 0.0289s/iter; left time: 32.8892s\n",
      "\titers: 300, epoch: 5 | loss: 0.1249299\n",
      "\tspeed: 0.0300s/iter; left time: 31.1317s\n",
      "\titers: 400, epoch: 5 | loss: 0.1378342\n",
      "\tspeed: 0.0285s/iter; left time: 26.7167s\n",
      "\titers: 500, epoch: 5 | loss: 0.1228136\n",
      "\tspeed: 0.0317s/iter; left time: 26.5867s\n",
      "\titers: 600, epoch: 5 | loss: 0.1019103\n",
      "\tspeed: 0.0298s/iter; left time: 22.0029s\n",
      "Epoch: 5 cost time: 19.90030026435852\n",
      "Epoch: 5, Steps: 669 | Train Loss: 0.1513874 Vali Loss: 0.3195185 Test Loss: 0.2450003\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1355816\n",
      "\tspeed: 0.0850s/iter; left time: 48.4327s\n",
      "\titers: 200, epoch: 6 | loss: 0.0998080\n",
      "\tspeed: 0.0322s/iter; left time: 15.1303s\n",
      "\titers: 300, epoch: 6 | loss: 0.2422763\n",
      "\tspeed: 0.0296s/iter; left time: 10.9567s\n",
      "\titers: 400, epoch: 6 | loss: 0.1175375\n",
      "\tspeed: 0.0307s/iter; left time: 8.2803s\n",
      "\titers: 500, epoch: 6 | loss: 0.1013665\n",
      "\tspeed: 0.0285s/iter; left time: 4.8454s\n",
      "\titers: 600, epoch: 6 | loss: 0.1016338\n",
      "\tspeed: 0.0279s/iter; left time: 1.9563s\n",
      "Epoch: 6 cost time: 20.197235107421875\n",
      "Epoch: 6, Steps: 669 | Train Loss: 0.1461930 Vali Loss: 0.3280589 Test Loss: 0.2447528\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "Test cost time: 2.0572s\n",
      "test shape: (177, 32, 6, 1) (177, 32, 6, 1)\n",
      "test shape: (5664, 6, 1) (5664, 6, 1)\n",
      "mse:0.23826181888580322, mae:0.32225674390792847\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1631.5635986328125\n",
      "MAE:  26.667160034179688\n",
      "RMSE: 40.392616271972656\n",
      "MAPE: 0.3717328906059265\n",
      "MSPE: 0.74078768491745\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24419\n",
      "[DEBUG] Original dataset length: 24419\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21417\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3375\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "\titers: 100, epoch: 1 | loss: 0.3367557\n",
      "\tspeed: 0.0292s/iter; left time: 114.3947s\n",
      "\titers: 200, epoch: 1 | loss: 0.3076052\n",
      "\tspeed: 0.0286s/iter; left time: 109.2354s\n",
      "\titers: 300, epoch: 1 | loss: 0.2676283\n",
      "\tspeed: 0.0304s/iter; left time: 113.0683s\n",
      "\titers: 400, epoch: 1 | loss: 0.2702767\n",
      "\tspeed: 0.0298s/iter; left time: 107.7858s\n",
      "\titers: 500, epoch: 1 | loss: 0.1744750\n",
      "\tspeed: 0.0297s/iter; left time: 104.3365s\n",
      "\titers: 600, epoch: 1 | loss: 0.2288814\n",
      "\tspeed: 0.0296s/iter; left time: 101.1642s\n",
      "Epoch: 1 cost time: 19.817902326583862\n",
      "Epoch: 1, Steps: 669 | Train Loss: 0.2823472 Vali Loss: 0.3467079 Test Loss: 0.2705573\n",
      "Validation loss decreased (inf --> 0.346708).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1400348\n",
      "\tspeed: 0.0854s/iter; left time: 277.1835s\n",
      "\titers: 200, epoch: 2 | loss: 0.1833047\n",
      "\tspeed: 0.0297s/iter; left time: 93.4298s\n",
      "\titers: 300, epoch: 2 | loss: 0.1757093\n",
      "\tspeed: 0.0285s/iter; left time: 86.8992s\n",
      "\titers: 400, epoch: 2 | loss: 0.2631150\n",
      "\tspeed: 0.0296s/iter; left time: 87.1818s\n",
      "\titers: 500, epoch: 2 | loss: 0.1416335\n",
      "\tspeed: 0.0308s/iter; left time: 87.6277s\n",
      "\titers: 600, epoch: 2 | loss: 0.1230639\n",
      "\tspeed: 0.0303s/iter; left time: 83.2218s\n",
      "Epoch: 2 cost time: 20.069616317749023\n",
      "Epoch: 2, Steps: 669 | Train Loss: 0.2044819 Vali Loss: 0.3232858 Test Loss: 0.2592351\n",
      "Validation loss decreased (0.346708 --> 0.323286).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1787371\n",
      "\tspeed: 0.0852s/iter; left time: 219.6384s\n",
      "\titers: 200, epoch: 3 | loss: 0.2500333\n",
      "\tspeed: 0.0303s/iter; left time: 74.9965s\n",
      "\titers: 300, epoch: 3 | loss: 0.1426336\n",
      "\tspeed: 0.0319s/iter; left time: 75.8018s\n",
      "\titers: 400, epoch: 3 | loss: 0.1429830\n",
      "\tspeed: 0.0292s/iter; left time: 66.3768s\n",
      "\titers: 500, epoch: 3 | loss: 0.1613368\n",
      "\tspeed: 0.0287s/iter; left time: 62.4292s\n",
      "\titers: 600, epoch: 3 | loss: 0.1646766\n",
      "\tspeed: 0.0288s/iter; left time: 59.7865s\n",
      "Epoch: 3 cost time: 19.93454122543335\n",
      "Epoch: 3, Steps: 669 | Train Loss: 0.1775021 Vali Loss: 0.3295041 Test Loss: 0.2579264\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1773598\n",
      "\tspeed: 0.0828s/iter; left time: 157.9148s\n",
      "\titers: 200, epoch: 4 | loss: 0.2588739\n",
      "\tspeed: 0.0294s/iter; left time: 53.1534s\n",
      "\titers: 300, epoch: 4 | loss: 0.1399405\n",
      "\tspeed: 0.0290s/iter; left time: 49.4664s\n",
      "\titers: 400, epoch: 4 | loss: 0.2040240\n",
      "\tspeed: 0.0291s/iter; left time: 46.7215s\n",
      "\titers: 500, epoch: 4 | loss: 0.1220358\n",
      "\tspeed: 0.0319s/iter; left time: 48.0999s\n",
      "\titers: 600, epoch: 4 | loss: 0.1222661\n",
      "\tspeed: 0.0311s/iter; left time: 43.7680s\n",
      "Epoch: 4 cost time: 20.022085189819336\n",
      "Epoch: 4, Steps: 669 | Train Loss: 0.1610487 Vali Loss: 0.3280000 Test Loss: 0.2524072\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1046434\n",
      "\tspeed: 0.0863s/iter; left time: 106.9123s\n",
      "\titers: 200, epoch: 5 | loss: 0.2330143\n",
      "\tspeed: 0.0321s/iter; left time: 36.6135s\n",
      "\titers: 300, epoch: 5 | loss: 0.1346420\n",
      "\tspeed: 0.0295s/iter; left time: 30.6341s\n",
      "\titers: 400, epoch: 5 | loss: 0.1001600\n",
      "\tspeed: 0.0287s/iter; left time: 26.9172s\n",
      "\titers: 500, epoch: 5 | loss: 0.0960345\n",
      "\tspeed: 0.0293s/iter; left time: 24.5648s\n",
      "\titers: 600, epoch: 5 | loss: 0.1024988\n",
      "\tspeed: 0.0293s/iter; left time: 21.6387s\n",
      "Epoch: 5 cost time: 20.298980236053467\n",
      "Epoch: 5, Steps: 669 | Train Loss: 0.1519645 Vali Loss: 0.3319539 Test Loss: 0.2553366\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "Test cost time: 2.0006s\n",
      "test shape: (177, 32, 6, 1) (177, 32, 6, 1)\n",
      "test shape: (5664, 6, 1) (5664, 6, 1)\n",
      "mse:0.25937169790267944, mae:0.3545036315917969\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1776.118896484375\n",
      "MAE:  29.335630416870117\n",
      "RMSE: 42.14402389526367\n",
      "MAPE: 0.4527857005596161\n",
      "MSPE: 1.2274961471557617\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24419\n",
      "[DEBUG] Original dataset length: 24419\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21417\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3375\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "\titers: 100, epoch: 1 | loss: 0.2770473\n",
      "\tspeed: 0.0291s/iter; left time: 113.7887s\n",
      "\titers: 200, epoch: 1 | loss: 0.2683533\n",
      "\tspeed: 0.0288s/iter; left time: 109.7170s\n",
      "\titers: 300, epoch: 1 | loss: 0.2365727\n",
      "\tspeed: 0.0304s/iter; left time: 112.8700s\n",
      "\titers: 400, epoch: 1 | loss: 0.2466895\n",
      "\tspeed: 0.0297s/iter; left time: 107.4453s\n",
      "\titers: 500, epoch: 1 | loss: 0.2726954\n",
      "\tspeed: 0.0291s/iter; left time: 102.4513s\n",
      "\titers: 600, epoch: 1 | loss: 0.2015069\n",
      "\tspeed: 0.0289s/iter; left time: 98.8126s\n",
      "Epoch: 1 cost time: 19.6478111743927\n",
      "Epoch: 1, Steps: 669 | Train Loss: 0.2846432 Vali Loss: 0.3199452 Test Loss: 0.2698288\n",
      "Validation loss decreased (inf --> 0.319945).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1698016\n",
      "\tspeed: 0.0849s/iter; left time: 275.4551s\n",
      "\titers: 200, epoch: 2 | loss: 0.2122671\n",
      "\tspeed: 0.0293s/iter; left time: 92.0884s\n",
      "\titers: 300, epoch: 2 | loss: 0.1559289\n",
      "\tspeed: 0.0290s/iter; left time: 88.3594s\n",
      "\titers: 400, epoch: 2 | loss: 0.2845930\n",
      "\tspeed: 0.0300s/iter; left time: 88.4086s\n",
      "\titers: 500, epoch: 2 | loss: 0.1610010\n",
      "\tspeed: 0.0293s/iter; left time: 83.3117s\n",
      "\titers: 600, epoch: 2 | loss: 0.1855573\n",
      "\tspeed: 0.0313s/iter; left time: 85.9682s\n",
      "Epoch: 2 cost time: 19.96553349494934\n",
      "Epoch: 2, Steps: 669 | Train Loss: 0.2074896 Vali Loss: 0.3268122 Test Loss: 0.2708579\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1441421\n",
      "\tspeed: 0.0823s/iter; left time: 212.1504s\n",
      "\titers: 200, epoch: 3 | loss: 0.2001697\n",
      "\tspeed: 0.0295s/iter; left time: 73.1609s\n",
      "\titers: 300, epoch: 3 | loss: 0.1969723\n",
      "\tspeed: 0.0314s/iter; left time: 74.5248s\n",
      "\titers: 400, epoch: 3 | loss: 0.1118765\n",
      "\tspeed: 0.0299s/iter; left time: 68.1285s\n",
      "\titers: 500, epoch: 3 | loss: 0.1576896\n",
      "\tspeed: 0.0288s/iter; left time: 62.6218s\n",
      "\titers: 600, epoch: 3 | loss: 0.2310714\n",
      "\tspeed: 0.0294s/iter; left time: 61.1587s\n",
      "Epoch: 3 cost time: 19.851097583770752\n",
      "Epoch: 3, Steps: 669 | Train Loss: 0.1773895 Vali Loss: 0.3194575 Test Loss: 0.2566895\n",
      "Validation loss decreased (0.319945 --> 0.319458).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1203125\n",
      "\tspeed: 0.0856s/iter; left time: 163.3930s\n",
      "\titers: 200, epoch: 4 | loss: 0.1252383\n",
      "\tspeed: 0.0283s/iter; left time: 51.2524s\n",
      "\titers: 300, epoch: 4 | loss: 0.1066315\n",
      "\tspeed: 0.0295s/iter; left time: 50.4020s\n",
      "\titers: 400, epoch: 4 | loss: 0.1966377\n",
      "\tspeed: 0.0294s/iter; left time: 47.2484s\n",
      "\titers: 500, epoch: 4 | loss: 0.1710977\n",
      "\tspeed: 0.0317s/iter; left time: 47.8118s\n",
      "\titers: 600, epoch: 4 | loss: 0.1970648\n",
      "\tspeed: 0.0293s/iter; left time: 41.2086s\n",
      "Epoch: 4 cost time: 19.88554835319519\n",
      "Epoch: 4, Steps: 669 | Train Loss: 0.1612354 Vali Loss: 0.3096708 Test Loss: 0.2454018\n",
      "Validation loss decreased (0.319458 --> 0.309671).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1283020\n",
      "\tspeed: 0.0844s/iter; left time: 104.5558s\n",
      "\titers: 200, epoch: 5 | loss: 0.1412129\n",
      "\tspeed: 0.0310s/iter; left time: 35.2581s\n",
      "\titers: 300, epoch: 5 | loss: 0.1555951\n",
      "\tspeed: 0.0299s/iter; left time: 31.0430s\n",
      "\titers: 400, epoch: 5 | loss: 0.1349823\n",
      "\tspeed: 0.0295s/iter; left time: 27.7365s\n",
      "\titers: 500, epoch: 5 | loss: 0.1046769\n",
      "\tspeed: 0.0291s/iter; left time: 24.4165s\n",
      "\titers: 600, epoch: 5 | loss: 0.1589835\n",
      "\tspeed: 0.0315s/iter; left time: 23.2871s\n",
      "Epoch: 5 cost time: 20.322624921798706\n",
      "Epoch: 5, Steps: 669 | Train Loss: 0.1516978 Vali Loss: 0.3099232 Test Loss: 0.2520621\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1383567\n",
      "\tspeed: 0.0854s/iter; left time: 48.6874s\n",
      "\titers: 200, epoch: 6 | loss: 0.0915017\n",
      "\tspeed: 0.0295s/iter; left time: 13.8779s\n",
      "\titers: 300, epoch: 6 | loss: 0.1030756\n",
      "\tspeed: 0.0306s/iter; left time: 11.3066s\n",
      "\titers: 400, epoch: 6 | loss: 0.1057058\n",
      "\tspeed: 0.0320s/iter; left time: 8.6470s\n",
      "\titers: 500, epoch: 6 | loss: 0.0999303\n",
      "\tspeed: 0.0299s/iter; left time: 5.0899s\n",
      "\titers: 600, epoch: 6 | loss: 0.1170566\n",
      "\tspeed: 0.0292s/iter; left time: 2.0470s\n",
      "Epoch: 6 cost time: 20.075517654418945\n",
      "Epoch: 6, Steps: 669 | Train Loss: 0.1472113 Vali Loss: 0.3210864 Test Loss: 0.2535749\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "Test cost time: 2.0226s\n",
      "test shape: (177, 32, 6, 1) (177, 32, 6, 1)\n",
      "test shape: (5664, 6, 1) (5664, 6, 1)\n",
      "mse:0.24447588622570038, mae:0.3284424841403961\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1674.115966796875\n",
      "MAE:  27.179035186767578\n",
      "RMSE: 40.91596221923828\n",
      "MAPE: 0.3561098277568817\n",
      "MSPE: 0.6358398795127869\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24419\n",
      "[DEBUG] Original dataset length: 24419\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21417\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3375\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "\titers: 100, epoch: 1 | loss: 0.3639414\n",
      "\tspeed: 0.0308s/iter; left time: 120.6017s\n",
      "\titers: 200, epoch: 1 | loss: 0.2070030\n",
      "\tspeed: 0.0288s/iter; left time: 109.9089s\n",
      "\titers: 300, epoch: 1 | loss: 0.1245842\n",
      "\tspeed: 0.0283s/iter; left time: 105.0894s\n",
      "\titers: 400, epoch: 1 | loss: 0.1947647\n",
      "\tspeed: 0.0285s/iter; left time: 103.1036s\n",
      "\titers: 500, epoch: 1 | loss: 0.1726383\n",
      "\tspeed: 0.0293s/iter; left time: 103.1607s\n",
      "\titers: 600, epoch: 1 | loss: 0.2076362\n",
      "\tspeed: 0.0309s/iter; left time: 105.4404s\n",
      "Epoch: 1 cost time: 19.665568828582764\n",
      "Epoch: 1, Steps: 669 | Train Loss: 0.2783534 Vali Loss: 0.3281251 Test Loss: 0.2691971\n",
      "Validation loss decreased (inf --> 0.328125).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2794638\n",
      "\tspeed: 0.0819s/iter; left time: 265.7673s\n",
      "\titers: 200, epoch: 2 | loss: 0.2165719\n",
      "\tspeed: 0.0295s/iter; left time: 92.6726s\n",
      "\titers: 300, epoch: 2 | loss: 0.1837499\n",
      "\tspeed: 0.0310s/iter; left time: 94.4319s\n",
      "\titers: 400, epoch: 2 | loss: 0.2363719\n",
      "\tspeed: 0.0301s/iter; left time: 88.5725s\n",
      "\titers: 500, epoch: 2 | loss: 0.1931095\n",
      "\tspeed: 0.0291s/iter; left time: 82.7111s\n",
      "\titers: 600, epoch: 2 | loss: 0.2333914\n",
      "\tspeed: 0.0292s/iter; left time: 80.0937s\n",
      "Epoch: 2 cost time: 19.759725093841553\n",
      "Epoch: 2, Steps: 669 | Train Loss: 0.2050948 Vali Loss: 0.3211983 Test Loss: 0.2610125\n",
      "Validation loss decreased (0.328125 --> 0.321198).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2924267\n",
      "\tspeed: 0.0841s/iter; left time: 216.7532s\n",
      "\titers: 200, epoch: 3 | loss: 0.1432790\n",
      "\tspeed: 0.0289s/iter; left time: 71.5195s\n",
      "\titers: 300, epoch: 3 | loss: 0.2009752\n",
      "\tspeed: 0.0290s/iter; left time: 68.9937s\n",
      "\titers: 400, epoch: 3 | loss: 0.1790746\n",
      "\tspeed: 0.0291s/iter; left time: 66.2201s\n",
      "\titers: 500, epoch: 3 | loss: 0.2408326\n",
      "\tspeed: 0.0304s/iter; left time: 66.2026s\n",
      "\titers: 600, epoch: 3 | loss: 0.1165665\n",
      "\tspeed: 0.0319s/iter; left time: 66.2177s\n",
      "Epoch: 3 cost time: 19.810590744018555\n",
      "Epoch: 3, Steps: 669 | Train Loss: 0.1753943 Vali Loss: 0.3261100 Test Loss: 0.2576358\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1178407\n",
      "\tspeed: 0.0827s/iter; left time: 157.7891s\n",
      "\titers: 200, epoch: 4 | loss: 0.1156313\n",
      "\tspeed: 0.0287s/iter; left time: 51.8779s\n",
      "\titers: 300, epoch: 4 | loss: 0.1119328\n",
      "\tspeed: 0.0316s/iter; left time: 53.9114s\n",
      "\titers: 400, epoch: 4 | loss: 0.1618928\n",
      "\tspeed: 0.0291s/iter; left time: 46.8416s\n",
      "\titers: 500, epoch: 4 | loss: 0.1220269\n",
      "\tspeed: 0.0298s/iter; left time: 44.9468s\n",
      "\titers: 600, epoch: 4 | loss: 0.1634695\n",
      "\tspeed: 0.0288s/iter; left time: 40.5699s\n",
      "Epoch: 4 cost time: 19.781186819076538\n",
      "Epoch: 4, Steps: 669 | Train Loss: 0.1605350 Vali Loss: 0.3262684 Test Loss: 0.2606266\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1679568\n",
      "\tspeed: 0.0828s/iter; left time: 102.6316s\n",
      "\titers: 200, epoch: 5 | loss: 0.1361800\n",
      "\tspeed: 0.0294s/iter; left time: 33.5345s\n",
      "\titers: 300, epoch: 5 | loss: 0.2512585\n",
      "\tspeed: 0.0288s/iter; left time: 29.9682s\n",
      "\titers: 400, epoch: 5 | loss: 0.1703084\n",
      "\tspeed: 0.0293s/iter; left time: 27.4665s\n",
      "\titers: 500, epoch: 5 | loss: 0.1169138\n",
      "\tspeed: 0.0310s/iter; left time: 26.0233s\n",
      "\titers: 600, epoch: 5 | loss: 0.1177534\n",
      "\tspeed: 0.0305s/iter; left time: 22.5265s\n",
      "Epoch: 5 cost time: 19.822612285614014\n",
      "Epoch: 5, Steps: 669 | Train Loss: 0.1519584 Vali Loss: 0.3284130 Test Loss: 0.2512243\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "Test cost time: 2.0611s\n",
      "test shape: (177, 32, 6, 1) (177, 32, 6, 1)\n",
      "test shape: (5664, 6, 1) (5664, 6, 1)\n",
      "mse:0.26095011830329895, mae:0.3362491726875305\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1786.927734375\n",
      "MAE:  27.82505226135254\n",
      "RMSE: 42.27206802368164\n",
      "MAPE: 0.35854241251945496\n",
      "MSPE: 0.6627781391143799\n",
      ">>>>>>>Running time saved<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Running seq_len=144\n",
      "Args in experiment:\n",
      "Namespace(model='informer', data='traffic_full', root_path='../', data_path='traffic_full.csv', features='S', target='flow', freq='h', checkpoints='./checkpoints/', seq_len=144, label_len=24, pred_len=6, enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=2, d_layers=1, s_layers=[3, 2, 1], d_ff=2048, factor=5, padding=0, distil=True, dropout=0.05, attn='prob', embed='timeF', activation='gelu', output_attention=False, do_predict=False, mix=True, cols=None, num_workers=0, itr=10, train_epochs=6, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, inverse=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', detail_freq='h')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24395\n",
      "[DEBUG] Original dataset length: 24395\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21009\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3351\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "\titers: 100, epoch: 1 | loss: 0.5773597\n",
      "\tspeed: 0.0465s/iter; left time: 178.3220s\n",
      "\titers: 200, epoch: 1 | loss: 0.2248472\n",
      "\tspeed: 0.0318s/iter; left time: 118.8166s\n",
      "\titers: 300, epoch: 1 | loss: 0.2949802\n",
      "\tspeed: 0.0326s/iter; left time: 118.7469s\n",
      "\titers: 400, epoch: 1 | loss: 0.2345624\n",
      "\tspeed: 0.0329s/iter; left time: 116.2416s\n",
      "\titers: 500, epoch: 1 | loss: 0.1736841\n",
      "\tspeed: 0.0333s/iter; left time: 114.3790s\n",
      "\titers: 600, epoch: 1 | loss: 0.1810509\n",
      "\tspeed: 0.0315s/iter; left time: 105.1391s\n",
      "Epoch: 1 cost time: 21.76258111000061\n",
      "Epoch: 1, Steps: 656 | Train Loss: 0.2915067 Vali Loss: 0.3236095 Test Loss: 0.2708859\n",
      "Validation loss decreased (inf --> 0.323610).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2659350\n",
      "\tspeed: 0.0869s/iter; left time: 276.5308s\n",
      "\titers: 200, epoch: 2 | loss: 0.2451571\n",
      "\tspeed: 0.0335s/iter; left time: 103.1786s\n",
      "\titers: 300, epoch: 2 | loss: 0.2036144\n",
      "\tspeed: 0.0324s/iter; left time: 96.5466s\n",
      "\titers: 400, epoch: 2 | loss: 0.2439407\n",
      "\tspeed: 0.0318s/iter; left time: 91.5526s\n",
      "\titers: 500, epoch: 2 | loss: 0.1507605\n",
      "\tspeed: 0.0328s/iter; left time: 91.1267s\n",
      "\titers: 600, epoch: 2 | loss: 0.1592151\n",
      "\tspeed: 0.0340s/iter; left time: 91.1180s\n",
      "Epoch: 2 cost time: 21.53081464767456\n",
      "Epoch: 2, Steps: 656 | Train Loss: 0.2042075 Vali Loss: 0.3095017 Test Loss: 0.2474790\n",
      "Validation loss decreased (0.323610 --> 0.309502).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2643145\n",
      "\tspeed: 0.0864s/iter; left time: 218.2259s\n",
      "\titers: 200, epoch: 3 | loss: 0.1391766\n",
      "\tspeed: 0.0321s/iter; left time: 77.7369s\n",
      "\titers: 300, epoch: 3 | loss: 0.2408876\n",
      "\tspeed: 0.0336s/iter; left time: 78.2249s\n",
      "\titers: 400, epoch: 3 | loss: 0.1058808\n",
      "\tspeed: 0.0325s/iter; left time: 72.2084s\n",
      "\titers: 500, epoch: 3 | loss: 0.1230905\n",
      "\tspeed: 0.0332s/iter; left time: 70.5224s\n",
      "\titers: 600, epoch: 3 | loss: 0.1376670\n",
      "\tspeed: 0.0324s/iter; left time: 65.5260s\n",
      "Epoch: 3 cost time: 21.37095355987549\n",
      "Epoch: 3, Steps: 656 | Train Loss: 0.1774441 Vali Loss: 0.3243236 Test Loss: 0.2582257\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2078511\n",
      "\tspeed: 0.0866s/iter; left time: 161.9470s\n",
      "\titers: 200, epoch: 4 | loss: 0.1513474\n",
      "\tspeed: 0.0323s/iter; left time: 57.1375s\n",
      "\titers: 300, epoch: 4 | loss: 0.1232958\n",
      "\tspeed: 0.0320s/iter; left time: 53.4611s\n",
      "\titers: 400, epoch: 4 | loss: 0.1249274\n",
      "\tspeed: 0.0332s/iter; left time: 52.1365s\n",
      "\titers: 500, epoch: 4 | loss: 0.1749458\n",
      "\tspeed: 0.0326s/iter; left time: 47.8447s\n",
      "\titers: 600, epoch: 4 | loss: 0.1450439\n",
      "\tspeed: 0.0322s/iter; left time: 44.1167s\n",
      "Epoch: 4 cost time: 21.200046062469482\n",
      "Epoch: 4, Steps: 656 | Train Loss: 0.1620556 Vali Loss: 0.3248985 Test Loss: 0.2599406\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2129422\n",
      "\tspeed: 0.0863s/iter; left time: 104.6535s\n",
      "\titers: 200, epoch: 5 | loss: 0.1326293\n",
      "\tspeed: 0.0330s/iter; left time: 36.7493s\n",
      "\titers: 300, epoch: 5 | loss: 0.0759179\n",
      "\tspeed: 0.0319s/iter; left time: 32.3395s\n",
      "\titers: 400, epoch: 5 | loss: 0.3566663\n",
      "\tspeed: 0.0314s/iter; left time: 28.6617s\n",
      "\titers: 500, epoch: 5 | loss: 0.1266163\n",
      "\tspeed: 0.0315s/iter; left time: 25.5798s\n",
      "\titers: 600, epoch: 5 | loss: 0.1562040\n",
      "\tspeed: 0.0357s/iter; left time: 25.4402s\n",
      "Epoch: 5 cost time: 21.4954891204834\n",
      "Epoch: 5, Steps: 656 | Train Loss: 0.1532734 Vali Loss: 0.3192654 Test Loss: 0.2553161\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "Test cost time: 2.1736s\n",
      "test shape: (171, 32, 6, 1) (171, 32, 6, 1)\n",
      "test shape: (5472, 6, 1) (5472, 6, 1)\n",
      "mse:0.2473912537097931, mae:0.3308350145816803\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1694.079833984375\n",
      "MAE:  27.377023696899414\n",
      "RMSE: 41.159202575683594\n",
      "MAPE: 0.36822906136512756\n",
      "MSPE: 0.7107917070388794\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24395\n",
      "[DEBUG] Original dataset length: 24395\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21009\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3351\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "\titers: 100, epoch: 1 | loss: 0.5202874\n",
      "\tspeed: 0.0324s/iter; left time: 124.3661s\n",
      "\titers: 200, epoch: 1 | loss: 0.2529262\n",
      "\tspeed: 0.0339s/iter; left time: 126.7821s\n",
      "\titers: 300, epoch: 1 | loss: 0.2244729\n",
      "\tspeed: 0.0326s/iter; left time: 118.4798s\n",
      "\titers: 400, epoch: 1 | loss: 0.1588057\n",
      "\tspeed: 0.0325s/iter; left time: 114.7997s\n",
      "\titers: 500, epoch: 1 | loss: 0.3115514\n",
      "\tspeed: 0.0319s/iter; left time: 109.6195s\n",
      "\titers: 600, epoch: 1 | loss: 0.1302193\n",
      "\tspeed: 0.0323s/iter; left time: 107.7499s\n",
      "Epoch: 1 cost time: 21.484659433364868\n",
      "Epoch: 1, Steps: 656 | Train Loss: 0.2923461 Vali Loss: 0.4264196 Test Loss: 0.3506412\n",
      "Validation loss decreased (inf --> 0.426420).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3181400\n",
      "\tspeed: 0.0876s/iter; left time: 278.7413s\n",
      "\titers: 200, epoch: 2 | loss: 0.2591125\n",
      "\tspeed: 0.0318s/iter; left time: 97.9560s\n",
      "\titers: 300, epoch: 2 | loss: 0.2657251\n",
      "\tspeed: 0.0318s/iter; left time: 94.8941s\n",
      "\titers: 400, epoch: 2 | loss: 0.1652795\n",
      "\tspeed: 0.0335s/iter; left time: 96.4786s\n",
      "\titers: 500, epoch: 2 | loss: 0.1891092\n",
      "\tspeed: 0.0316s/iter; left time: 87.9266s\n",
      "\titers: 600, epoch: 2 | loss: 0.2087853\n",
      "\tspeed: 0.0329s/iter; left time: 88.2012s\n",
      "Epoch: 2 cost time: 21.171385288238525\n",
      "Epoch: 2, Steps: 656 | Train Loss: 0.2065615 Vali Loss: 0.3105869 Test Loss: 0.2583423\n",
      "Validation loss decreased (0.426420 --> 0.310587).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1392770\n",
      "\tspeed: 0.0864s/iter; left time: 218.1888s\n",
      "\titers: 200, epoch: 3 | loss: 0.1337592\n",
      "\tspeed: 0.0318s/iter; left time: 77.0363s\n",
      "\titers: 300, epoch: 3 | loss: 0.4520859\n",
      "\tspeed: 0.0318s/iter; left time: 73.8375s\n",
      "\titers: 400, epoch: 3 | loss: 0.1435578\n",
      "\tspeed: 0.0332s/iter; left time: 73.8141s\n",
      "\titers: 500, epoch: 3 | loss: 0.1335852\n",
      "\tspeed: 0.0352s/iter; left time: 74.8253s\n",
      "\titers: 600, epoch: 3 | loss: 0.1757742\n",
      "\tspeed: 0.0318s/iter; left time: 64.3551s\n",
      "Epoch: 3 cost time: 21.321564197540283\n",
      "Epoch: 3, Steps: 656 | Train Loss: 0.1778551 Vali Loss: 0.3079953 Test Loss: 0.2421847\n",
      "Validation loss decreased (0.310587 --> 0.307995).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2146083\n",
      "\tspeed: 0.0861s/iter; left time: 160.8612s\n",
      "\titers: 200, epoch: 4 | loss: 0.1350423\n",
      "\tspeed: 0.0335s/iter; left time: 59.1841s\n",
      "\titers: 300, epoch: 4 | loss: 0.0978987\n",
      "\tspeed: 0.0332s/iter; left time: 55.3387s\n",
      "\titers: 400, epoch: 4 | loss: 0.1562371\n",
      "\tspeed: 0.0329s/iter; left time: 51.5490s\n",
      "\titers: 500, epoch: 4 | loss: 0.1897022\n",
      "\tspeed: 0.0314s/iter; left time: 46.1330s\n",
      "\titers: 600, epoch: 4 | loss: 0.1793880\n",
      "\tspeed: 0.0317s/iter; left time: 43.3534s\n",
      "Epoch: 4 cost time: 21.4914813041687\n",
      "Epoch: 4, Steps: 656 | Train Loss: 0.1617256 Vali Loss: 0.3184051 Test Loss: 0.2511179\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1367395\n",
      "\tspeed: 0.0879s/iter; left time: 106.5893s\n",
      "\titers: 200, epoch: 5 | loss: 0.1646073\n",
      "\tspeed: 0.0314s/iter; left time: 34.9985s\n",
      "\titers: 300, epoch: 5 | loss: 0.1639174\n",
      "\tspeed: 0.0321s/iter; left time: 32.4968s\n",
      "\titers: 400, epoch: 5 | loss: 0.0973565\n",
      "\tspeed: 0.0338s/iter; left time: 30.8219s\n",
      "\titers: 500, epoch: 5 | loss: 0.1265430\n",
      "\tspeed: 0.0329s/iter; left time: 26.7787s\n",
      "\titers: 600, epoch: 5 | loss: 0.1102843\n",
      "\tspeed: 0.0329s/iter; left time: 23.4611s\n",
      "Epoch: 5 cost time: 21.295121908187866\n",
      "Epoch: 5, Steps: 656 | Train Loss: 0.1525152 Vali Loss: 0.3226796 Test Loss: 0.2548923\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1711726\n",
      "\tspeed: 0.0878s/iter; left time: 48.9274s\n",
      "\titers: 200, epoch: 6 | loss: 0.1758771\n",
      "\tspeed: 0.0322s/iter; left time: 14.7212s\n",
      "\titers: 300, epoch: 6 | loss: 0.1159998\n",
      "\tspeed: 0.0325s/iter; left time: 11.6104s\n",
      "\titers: 400, epoch: 6 | loss: 0.1226210\n",
      "\tspeed: 0.0320s/iter; left time: 8.2215s\n",
      "\titers: 500, epoch: 6 | loss: 0.1432070\n",
      "\tspeed: 0.0339s/iter; left time: 5.3188s\n",
      "\titers: 600, epoch: 6 | loss: 0.1445169\n",
      "\tspeed: 0.0330s/iter; left time: 1.8818s\n",
      "Epoch: 6 cost time: 21.570029735565186\n",
      "Epoch: 6, Steps: 656 | Train Loss: 0.1476675 Vali Loss: 0.3178961 Test Loss: 0.2505395\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "Test cost time: 2.0037s\n",
      "test shape: (171, 32, 6, 1) (171, 32, 6, 1)\n",
      "test shape: (5472, 6, 1) (5472, 6, 1)\n",
      "mse:0.24241036176681519, mae:0.33062732219696045\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1659.9716796875\n",
      "MAE:  27.359840393066406\n",
      "RMSE: 40.74274826049805\n",
      "MAPE: 0.3918161988258362\n",
      "MSPE: 0.7807728052139282\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24395\n",
      "[DEBUG] Original dataset length: 24395\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21009\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3351\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "\titers: 100, epoch: 1 | loss: 0.2570846\n",
      "\tspeed: 0.0318s/iter; left time: 122.0381s\n",
      "\titers: 200, epoch: 1 | loss: 0.2482557\n",
      "\tspeed: 0.0314s/iter; left time: 117.4840s\n",
      "\titers: 300, epoch: 1 | loss: 0.2382472\n",
      "\tspeed: 0.0317s/iter; left time: 115.2959s\n",
      "\titers: 400, epoch: 1 | loss: 0.2037688\n",
      "\tspeed: 0.0321s/iter; left time: 113.6396s\n",
      "\titers: 500, epoch: 1 | loss: 0.1977069\n",
      "\tspeed: 0.0324s/iter; left time: 111.2736s\n",
      "\titers: 600, epoch: 1 | loss: 0.3040150\n",
      "\tspeed: 0.0343s/iter; left time: 114.5561s\n",
      "Epoch: 1 cost time: 21.187795162200928\n",
      "Epoch: 1, Steps: 656 | Train Loss: 0.2807286 Vali Loss: 0.3194149 Test Loss: 0.2605503\n",
      "Validation loss decreased (inf --> 0.319415).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1922045\n",
      "\tspeed: 0.0865s/iter; left time: 275.3067s\n",
      "\titers: 200, epoch: 2 | loss: 0.1726666\n",
      "\tspeed: 0.0343s/iter; left time: 105.7283s\n",
      "\titers: 300, epoch: 2 | loss: 0.3991269\n",
      "\tspeed: 0.0335s/iter; left time: 99.9879s\n",
      "\titers: 400, epoch: 2 | loss: 0.1488326\n",
      "\tspeed: 0.0326s/iter; left time: 93.8858s\n",
      "\titers: 500, epoch: 2 | loss: 0.1927002\n",
      "\tspeed: 0.0319s/iter; left time: 88.7195s\n",
      "\titers: 600, epoch: 2 | loss: 0.1453212\n",
      "\tspeed: 0.0318s/iter; left time: 85.3190s\n",
      "Epoch: 2 cost time: 21.465625047683716\n",
      "Epoch: 2, Steps: 656 | Train Loss: 0.2069821 Vali Loss: 0.3068630 Test Loss: 0.2439928\n",
      "Validation loss decreased (0.319415 --> 0.306863).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2578698\n",
      "\tspeed: 0.0876s/iter; left time: 221.0686s\n",
      "\titers: 200, epoch: 3 | loss: 0.1612262\n",
      "\tspeed: 0.0308s/iter; left time: 74.6148s\n",
      "\titers: 300, epoch: 3 | loss: 0.2674793\n",
      "\tspeed: 0.0325s/iter; left time: 75.5342s\n",
      "\titers: 400, epoch: 3 | loss: 0.1527422\n",
      "\tspeed: 0.0324s/iter; left time: 72.1909s\n",
      "\titers: 500, epoch: 3 | loss: 0.2474272\n",
      "\tspeed: 0.0340s/iter; left time: 72.2769s\n",
      "\titers: 600, epoch: 3 | loss: 0.1507257\n",
      "\tspeed: 0.0320s/iter; left time: 64.7327s\n",
      "Epoch: 3 cost time: 21.202395915985107\n",
      "Epoch: 3, Steps: 656 | Train Loss: 0.1769989 Vali Loss: 0.3079812 Test Loss: 0.2464832\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1338294\n",
      "\tspeed: 0.0872s/iter; left time: 162.8917s\n",
      "\titers: 200, epoch: 4 | loss: 0.1632125\n",
      "\tspeed: 0.0331s/iter; left time: 58.5865s\n",
      "\titers: 300, epoch: 4 | loss: 0.1377309\n",
      "\tspeed: 0.0324s/iter; left time: 53.9972s\n",
      "\titers: 400, epoch: 4 | loss: 0.1996593\n",
      "\tspeed: 0.0324s/iter; left time: 50.8837s\n",
      "\titers: 500, epoch: 4 | loss: 0.1181102\n",
      "\tspeed: 0.0330s/iter; left time: 48.5066s\n",
      "\titers: 600, epoch: 4 | loss: 0.1517173\n",
      "\tspeed: 0.0336s/iter; left time: 45.9624s\n",
      "Epoch: 4 cost time: 21.61107325553894\n",
      "Epoch: 4, Steps: 656 | Train Loss: 0.1614704 Vali Loss: 0.3073667 Test Loss: 0.2438443\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1883718\n",
      "\tspeed: 0.0858s/iter; left time: 104.1057s\n",
      "\titers: 200, epoch: 5 | loss: 0.1666218\n",
      "\tspeed: 0.0326s/iter; left time: 36.2451s\n",
      "\titers: 300, epoch: 5 | loss: 0.1837917\n",
      "\tspeed: 0.0341s/iter; left time: 34.5119s\n",
      "\titers: 400, epoch: 5 | loss: 0.1438666\n",
      "\tspeed: 0.0318s/iter; left time: 29.0283s\n",
      "\titers: 500, epoch: 5 | loss: 0.2279110\n",
      "\tspeed: 0.0320s/iter; left time: 25.9965s\n",
      "\titers: 600, epoch: 5 | loss: 0.0954488\n",
      "\tspeed: 0.0321s/iter; left time: 22.8568s\n",
      "Epoch: 5 cost time: 21.256062984466553\n",
      "Epoch: 5, Steps: 656 | Train Loss: 0.1528043 Vali Loss: 0.3160452 Test Loss: 0.2406316\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "Test cost time: 2.1622s\n",
      "test shape: (171, 32, 6, 1) (171, 32, 6, 1)\n",
      "test shape: (5472, 6, 1) (5472, 6, 1)\n",
      "mse:0.24379949271678925, mae:0.3338160812854767\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1669.4842529296875\n",
      "MAE:  27.623708724975586\n",
      "RMSE: 40.85932159423828\n",
      "MAPE: 0.37733444571495056\n",
      "MSPE: 0.7389913201332092\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24395\n",
      "[DEBUG] Original dataset length: 24395\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21009\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3351\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "\titers: 100, epoch: 1 | loss: 0.2182837\n",
      "\tspeed: 0.0318s/iter; left time: 121.9593s\n",
      "\titers: 200, epoch: 1 | loss: 0.1751437\n",
      "\tspeed: 0.0312s/iter; left time: 116.6317s\n",
      "\titers: 300, epoch: 1 | loss: 0.1735273\n",
      "\tspeed: 0.0318s/iter; left time: 115.7865s\n",
      "\titers: 400, epoch: 1 | loss: 0.2533305\n",
      "\tspeed: 0.0336s/iter; left time: 118.7304s\n",
      "\titers: 500, epoch: 1 | loss: 0.1751117\n",
      "\tspeed: 0.0315s/iter; left time: 108.2567s\n",
      "\titers: 600, epoch: 1 | loss: 0.2409586\n",
      "\tspeed: 0.0325s/iter; left time: 108.4694s\n",
      "Epoch: 1 cost time: 21.008002519607544\n",
      "Epoch: 1, Steps: 656 | Train Loss: 0.2820610 Vali Loss: 0.3405585 Test Loss: 0.2846715\n",
      "Validation loss decreased (inf --> 0.340558).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1877191\n",
      "\tspeed: 0.0877s/iter; left time: 278.9498s\n",
      "\titers: 200, epoch: 2 | loss: 0.1619586\n",
      "\tspeed: 0.0309s/iter; left time: 95.3495s\n",
      "\titers: 300, epoch: 2 | loss: 0.1549713\n",
      "\tspeed: 0.0307s/iter; left time: 91.4737s\n",
      "\titers: 400, epoch: 2 | loss: 0.1674839\n",
      "\tspeed: 0.0320s/iter; left time: 92.1423s\n",
      "\titers: 500, epoch: 2 | loss: 0.2822004\n",
      "\tspeed: 0.0324s/iter; left time: 90.1362s\n",
      "\titers: 600, epoch: 2 | loss: 0.2392451\n",
      "\tspeed: 0.0327s/iter; left time: 87.5420s\n",
      "Epoch: 2 cost time: 20.98350691795349\n",
      "Epoch: 2, Steps: 656 | Train Loss: 0.2065895 Vali Loss: 0.3001632 Test Loss: 0.2552680\n",
      "Validation loss decreased (0.340558 --> 0.300163).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1109193\n",
      "\tspeed: 0.0861s/iter; left time: 217.2796s\n",
      "\titers: 200, epoch: 3 | loss: 0.1828853\n",
      "\tspeed: 0.0324s/iter; left time: 78.6679s\n",
      "\titers: 300, epoch: 3 | loss: 0.1843476\n",
      "\tspeed: 0.0321s/iter; left time: 74.5961s\n",
      "\titers: 400, epoch: 3 | loss: 0.1464380\n",
      "\tspeed: 0.0321s/iter; left time: 71.4378s\n",
      "\titers: 500, epoch: 3 | loss: 0.2522005\n",
      "\tspeed: 0.0327s/iter; left time: 69.4140s\n",
      "\titers: 600, epoch: 3 | loss: 0.2003523\n",
      "\tspeed: 0.0323s/iter; left time: 65.3467s\n",
      "Epoch: 3 cost time: 21.26072406768799\n",
      "Epoch: 3, Steps: 656 | Train Loss: 0.1772387 Vali Loss: 0.3090435 Test Loss: 0.2568916\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1443746\n",
      "\tspeed: 0.0874s/iter; left time: 163.2667s\n",
      "\titers: 200, epoch: 4 | loss: 0.1165230\n",
      "\tspeed: 0.0316s/iter; left time: 55.8267s\n",
      "\titers: 300, epoch: 4 | loss: 0.1668504\n",
      "\tspeed: 0.0331s/iter; left time: 55.1660s\n",
      "\titers: 400, epoch: 4 | loss: 0.1844789\n",
      "\tspeed: 0.0334s/iter; left time: 52.4827s\n",
      "\titers: 500, epoch: 4 | loss: 0.1157616\n",
      "\tspeed: 0.0316s/iter; left time: 46.4300s\n",
      "\titers: 600, epoch: 4 | loss: 0.1308580\n",
      "\tspeed: 0.0335s/iter; left time: 45.8964s\n",
      "Epoch: 4 cost time: 21.356777667999268\n",
      "Epoch: 4, Steps: 656 | Train Loss: 0.1618986 Vali Loss: 0.3000285 Test Loss: 0.2469149\n",
      "Validation loss decreased (0.300163 --> 0.300029).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1526116\n",
      "\tspeed: 0.0875s/iter; left time: 106.1548s\n",
      "\titers: 200, epoch: 5 | loss: 0.1466545\n",
      "\tspeed: 0.0315s/iter; left time: 35.1096s\n",
      "\titers: 300, epoch: 5 | loss: 0.1603190\n",
      "\tspeed: 0.0313s/iter; left time: 31.7307s\n",
      "\titers: 400, epoch: 5 | loss: 0.1283255\n",
      "\tspeed: 0.0312s/iter; left time: 28.4840s\n",
      "\titers: 500, epoch: 5 | loss: 0.1349591\n",
      "\tspeed: 0.0322s/iter; left time: 26.2175s\n",
      "\titers: 600, epoch: 5 | loss: 0.1036943\n",
      "\tspeed: 0.0326s/iter; left time: 23.2755s\n",
      "Epoch: 5 cost time: 21.012609004974365\n",
      "Epoch: 5, Steps: 656 | Train Loss: 0.1530596 Vali Loss: 0.3067658 Test Loss: 0.2490044\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1770464\n",
      "\tspeed: 0.0849s/iter; left time: 47.2633s\n",
      "\titers: 200, epoch: 6 | loss: 0.1553153\n",
      "\tspeed: 0.0324s/iter; left time: 14.7875s\n",
      "\titers: 300, epoch: 6 | loss: 0.1164552\n",
      "\tspeed: 0.0331s/iter; left time: 11.8270s\n",
      "\titers: 400, epoch: 6 | loss: 0.1063500\n",
      "\tspeed: 0.0330s/iter; left time: 8.4934s\n",
      "\titers: 500, epoch: 6 | loss: 0.2270106\n",
      "\tspeed: 0.0326s/iter; left time: 5.1208s\n",
      "\titers: 600, epoch: 6 | loss: 0.1174443\n",
      "\tspeed: 0.0340s/iter; left time: 1.9385s\n",
      "Epoch: 6 cost time: 21.65643620491028\n",
      "Epoch: 6, Steps: 656 | Train Loss: 0.1482696 Vali Loss: 0.3106974 Test Loss: 0.2501840\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "Test cost time: 2.2442s\n",
      "test shape: (171, 32, 6, 1) (171, 32, 6, 1)\n",
      "test shape: (5472, 6, 1) (5472, 6, 1)\n",
      "mse:0.2472953498363495, mae:0.3334175646305084\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1693.4228515625\n",
      "MAE:  27.590730667114258\n",
      "RMSE: 41.15121841430664\n",
      "MAPE: 0.38321784138679504\n",
      "MSPE: 0.8108810782432556\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24395\n",
      "[DEBUG] Original dataset length: 24395\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21009\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3351\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "\titers: 100, epoch: 1 | loss: 0.4533430\n",
      "\tspeed: 0.0339s/iter; left time: 129.9147s\n",
      "\titers: 200, epoch: 1 | loss: 0.3357265\n",
      "\tspeed: 0.0327s/iter; left time: 122.0980s\n",
      "\titers: 300, epoch: 1 | loss: 0.1681057\n",
      "\tspeed: 0.0339s/iter; left time: 123.3772s\n",
      "\titers: 400, epoch: 1 | loss: 0.2521320\n",
      "\tspeed: 0.0337s/iter; left time: 119.2107s\n",
      "\titers: 500, epoch: 1 | loss: 0.1625538\n",
      "\tspeed: 0.0333s/iter; left time: 114.3460s\n",
      "\titers: 600, epoch: 1 | loss: 0.2709439\n",
      "\tspeed: 0.0318s/iter; left time: 106.1021s\n",
      "Epoch: 1 cost time: 21.707306146621704\n",
      "Epoch: 1, Steps: 656 | Train Loss: 0.2817353 Vali Loss: 0.3176092 Test Loss: 0.2668105\n",
      "Validation loss decreased (inf --> 0.317609).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2976071\n",
      "\tspeed: 0.0859s/iter; left time: 273.1232s\n",
      "\titers: 200, epoch: 2 | loss: 0.2504873\n",
      "\tspeed: 0.0316s/iter; left time: 97.3562s\n",
      "\titers: 300, epoch: 2 | loss: 0.2155575\n",
      "\tspeed: 0.0317s/iter; left time: 94.5230s\n",
      "\titers: 400, epoch: 2 | loss: 0.1412204\n",
      "\tspeed: 0.0320s/iter; left time: 92.1142s\n",
      "\titers: 500, epoch: 2 | loss: 0.1337893\n",
      "\tspeed: 0.0330s/iter; left time: 91.7693s\n",
      "\titers: 600, epoch: 2 | loss: 0.1330557\n",
      "\tspeed: 0.0327s/iter; left time: 87.7260s\n",
      "Epoch: 2 cost time: 21.21277379989624\n",
      "Epoch: 2, Steps: 656 | Train Loss: 0.2054136 Vali Loss: 0.3248751 Test Loss: 0.2711644\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1273565\n",
      "\tspeed: 0.0883s/iter; left time: 222.9173s\n",
      "\titers: 200, epoch: 3 | loss: 0.2009385\n",
      "\tspeed: 0.0336s/iter; left time: 81.3661s\n",
      "\titers: 300, epoch: 3 | loss: 0.2076006\n",
      "\tspeed: 0.0324s/iter; left time: 75.3022s\n",
      "\titers: 400, epoch: 3 | loss: 0.1313150\n",
      "\tspeed: 0.0316s/iter; left time: 70.2281s\n",
      "\titers: 500, epoch: 3 | loss: 0.2022340\n",
      "\tspeed: 0.0316s/iter; left time: 67.1038s\n",
      "\titers: 600, epoch: 3 | loss: 0.1879010\n",
      "\tspeed: 0.0338s/iter; left time: 68.4052s\n",
      "Epoch: 3 cost time: 21.481112957000732\n",
      "Epoch: 3, Steps: 656 | Train Loss: 0.1761408 Vali Loss: 0.3088647 Test Loss: 0.2495510\n",
      "Validation loss decreased (0.317609 --> 0.308865).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1385113\n",
      "\tspeed: 0.0869s/iter; left time: 162.3302s\n",
      "\titers: 200, epoch: 4 | loss: 0.1955617\n",
      "\tspeed: 0.0319s/iter; left time: 56.4111s\n",
      "\titers: 300, epoch: 4 | loss: 0.1958989\n",
      "\tspeed: 0.0344s/iter; left time: 57.3378s\n",
      "\titers: 400, epoch: 4 | loss: 0.1205724\n",
      "\tspeed: 0.0319s/iter; left time: 50.1105s\n",
      "\titers: 500, epoch: 4 | loss: 0.1366789\n",
      "\tspeed: 0.0314s/iter; left time: 46.0853s\n",
      "\titers: 600, epoch: 4 | loss: 0.1859898\n",
      "\tspeed: 0.0319s/iter; left time: 43.6210s\n",
      "Epoch: 4 cost time: 21.092772960662842\n",
      "Epoch: 4, Steps: 656 | Train Loss: 0.1610313 Vali Loss: 0.3132033 Test Loss: 0.2536923\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1505619\n",
      "\tspeed: 0.0856s/iter; left time: 103.8086s\n",
      "\titers: 200, epoch: 5 | loss: 0.1145787\n",
      "\tspeed: 0.0319s/iter; left time: 35.5396s\n",
      "\titers: 300, epoch: 5 | loss: 0.1305927\n",
      "\tspeed: 0.0330s/iter; left time: 33.4456s\n",
      "\titers: 400, epoch: 5 | loss: 0.1405850\n",
      "\tspeed: 0.0322s/iter; left time: 29.3776s\n",
      "\titers: 500, epoch: 5 | loss: 0.3225027\n",
      "\tspeed: 0.0333s/iter; left time: 27.0687s\n",
      "\titers: 600, epoch: 5 | loss: 0.0998598\n",
      "\tspeed: 0.0313s/iter; left time: 22.3267s\n",
      "Epoch: 5 cost time: 21.119280338287354\n",
      "Epoch: 5, Steps: 656 | Train Loss: 0.1519307 Vali Loss: 0.3078241 Test Loss: 0.2506665\n",
      "Validation loss decreased (0.308865 --> 0.307824).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1198894\n",
      "\tspeed: 0.0855s/iter; left time: 47.6246s\n",
      "\titers: 200, epoch: 6 | loss: 0.1307646\n",
      "\tspeed: 0.0332s/iter; left time: 15.1903s\n",
      "\titers: 300, epoch: 6 | loss: 0.0832964\n",
      "\tspeed: 0.0314s/iter; left time: 11.2175s\n",
      "\titers: 400, epoch: 6 | loss: 0.1459436\n",
      "\tspeed: 0.0323s/iter; left time: 8.3064s\n",
      "\titers: 500, epoch: 6 | loss: 0.1478643\n",
      "\tspeed: 0.0325s/iter; left time: 5.0985s\n",
      "\titers: 600, epoch: 6 | loss: 0.1780171\n",
      "\tspeed: 0.0323s/iter; left time: 1.8431s\n",
      "Epoch: 6 cost time: 21.25728178024292\n",
      "Epoch: 6, Steps: 656 | Train Loss: 0.1469934 Vali Loss: 0.3195954 Test Loss: 0.2549908\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "Test cost time: 2.0659s\n",
      "test shape: (171, 32, 6, 1) (171, 32, 6, 1)\n",
      "test shape: (5472, 6, 1) (5472, 6, 1)\n",
      "mse:0.25094932317733765, mae:0.32892411947250366\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1718.4444580078125\n",
      "MAE:  27.218891143798828\n",
      "RMSE: 41.454124450683594\n",
      "MAPE: 0.3496236503124237\n",
      "MSPE: 0.6073595881462097\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24395\n",
      "[DEBUG] Original dataset length: 24395\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21009\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3351\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "\titers: 100, epoch: 1 | loss: 0.4559557\n",
      "\tspeed: 0.0312s/iter; left time: 119.5465s\n",
      "\titers: 200, epoch: 1 | loss: 0.2925802\n",
      "\tspeed: 0.0321s/iter; left time: 119.8616s\n",
      "\titers: 300, epoch: 1 | loss: 0.2696863\n",
      "\tspeed: 0.0324s/iter; left time: 117.8434s\n",
      "\titers: 400, epoch: 1 | loss: 0.1977392\n",
      "\tspeed: 0.0313s/iter; left time: 110.8022s\n",
      "\titers: 500, epoch: 1 | loss: 0.2495583\n",
      "\tspeed: 0.0319s/iter; left time: 109.7295s\n",
      "\titers: 600, epoch: 1 | loss: 0.1558201\n",
      "\tspeed: 0.0324s/iter; left time: 108.1049s\n",
      "Epoch: 1 cost time: 20.98933696746826\n",
      "Epoch: 1, Steps: 656 | Train Loss: 0.2984924 Vali Loss: 0.3201454 Test Loss: 0.2702071\n",
      "Validation loss decreased (inf --> 0.320145).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2664364\n",
      "\tspeed: 0.0873s/iter; left time: 277.5507s\n",
      "\titers: 200, epoch: 2 | loss: 0.1827358\n",
      "\tspeed: 0.0318s/iter; left time: 98.0641s\n",
      "\titers: 300, epoch: 2 | loss: 0.2797287\n",
      "\tspeed: 0.0312s/iter; left time: 92.9708s\n",
      "\titers: 400, epoch: 2 | loss: 0.1162731\n",
      "\tspeed: 0.0337s/iter; left time: 97.1356s\n",
      "\titers: 500, epoch: 2 | loss: 0.2254053\n",
      "\tspeed: 0.0321s/iter; left time: 89.1720s\n",
      "\titers: 600, epoch: 2 | loss: 0.1095070\n",
      "\tspeed: 0.0316s/iter; left time: 84.6769s\n",
      "Epoch: 2 cost time: 21.083333492279053\n",
      "Epoch: 2, Steps: 656 | Train Loss: 0.2115741 Vali Loss: 0.3087421 Test Loss: 0.2607134\n",
      "Validation loss decreased (0.320145 --> 0.308742).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1613717\n",
      "\tspeed: 0.0877s/iter; left time: 221.4574s\n",
      "\titers: 200, epoch: 3 | loss: 0.1867044\n",
      "\tspeed: 0.0316s/iter; left time: 76.7480s\n",
      "\titers: 300, epoch: 3 | loss: 0.2047146\n",
      "\tspeed: 0.0321s/iter; left time: 74.6884s\n",
      "\titers: 400, epoch: 3 | loss: 0.1981609\n",
      "\tspeed: 0.0311s/iter; left time: 69.2775s\n",
      "\titers: 500, epoch: 3 | loss: 0.1202245\n",
      "\tspeed: 0.0314s/iter; left time: 66.7129s\n",
      "\titers: 600, epoch: 3 | loss: 0.1331491\n",
      "\tspeed: 0.0329s/iter; left time: 66.5964s\n",
      "Epoch: 3 cost time: 21.0702645778656\n",
      "Epoch: 3, Steps: 656 | Train Loss: 0.1808753 Vali Loss: 0.3162298 Test Loss: 0.2564309\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2150653\n",
      "\tspeed: 0.0837s/iter; left time: 156.4092s\n",
      "\titers: 200, epoch: 4 | loss: 0.4382178\n",
      "\tspeed: 0.0329s/iter; left time: 58.1467s\n",
      "\titers: 300, epoch: 4 | loss: 0.2860485\n",
      "\tspeed: 0.0345s/iter; left time: 57.5681s\n",
      "\titers: 400, epoch: 4 | loss: 0.2482043\n",
      "\tspeed: 0.0318s/iter; left time: 49.8857s\n",
      "\titers: 500, epoch: 4 | loss: 0.1666696\n",
      "\tspeed: 0.0322s/iter; left time: 47.2287s\n",
      "\titers: 600, epoch: 4 | loss: 0.1999657\n",
      "\tspeed: 0.0313s/iter; left time: 42.7883s\n",
      "Epoch: 4 cost time: 21.194647789001465\n",
      "Epoch: 4, Steps: 656 | Train Loss: 0.1641344 Vali Loss: 0.3106291 Test Loss: 0.2564653\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1213623\n",
      "\tspeed: 0.0867s/iter; left time: 105.1506s\n",
      "\titers: 200, epoch: 5 | loss: 0.1791154\n",
      "\tspeed: 0.0314s/iter; left time: 34.9909s\n",
      "\titers: 300, epoch: 5 | loss: 0.2896864\n",
      "\tspeed: 0.0315s/iter; left time: 31.9059s\n",
      "\titers: 400, epoch: 5 | loss: 0.1097997\n",
      "\tspeed: 0.0320s/iter; left time: 29.1811s\n",
      "\titers: 500, epoch: 5 | loss: 0.1229164\n",
      "\tspeed: 0.0309s/iter; left time: 25.1079s\n",
      "\titers: 600, epoch: 5 | loss: 0.1665802\n",
      "\tspeed: 0.0304s/iter; left time: 21.6919s\n",
      "Epoch: 5 cost time: 20.56212544441223\n",
      "Epoch: 5, Steps: 656 | Train Loss: 0.1548992 Vali Loss: 0.3199593 Test Loss: 0.2593756\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\titers: 200, epoch: 2 | loss: 0.1532303\n",
      "\tspeed: 0.0437s/iter; left time: 126.2771s\n",
      "\titers: 300, epoch: 2 | loss: 0.1194427\n",
      "\tspeed: 0.0421s/iter; left time: 117.3745s\n",
      "\titers: 400, epoch: 2 | loss: 0.1741949\n",
      "\tspeed: 0.0420s/iter; left time: 113.1091s\n",
      "\titers: 500, epoch: 2 | loss: 0.2344944\n",
      "\tspeed: 0.0424s/iter; left time: 109.8542s\n",
      "\titers: 600, epoch: 2 | loss: 0.2087820\n",
      "\tspeed: 0.0433s/iter; left time: 107.9172s\n",
      "Epoch: 2 cost time: 26.315322875976562\n",
      "Epoch: 2, Steps: 618 | Train Loss: 0.2002093 Vali Loss: 0.3317700 Test Loss: 0.2666194\n",
      "Validation loss decreased (0.349521 --> 0.331770).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1226939\n",
      "\tspeed: 0.0955s/iter; left time: 226.5762s\n",
      "\titers: 200, epoch: 3 | loss: 0.1673248\n",
      "\tspeed: 0.0435s/iter; left time: 98.8637s\n",
      "\titers: 300, epoch: 3 | loss: 0.1549045\n",
      "\tspeed: 0.0422s/iter; left time: 91.8031s\n",
      "\titers: 400, epoch: 3 | loss: 0.1939242\n",
      "\tspeed: 0.0417s/iter; left time: 86.5266s\n",
      "\titers: 500, epoch: 3 | loss: 0.1751583\n",
      "\tspeed: 0.0428s/iter; left time: 84.3885s\n",
      "\titers: 600, epoch: 3 | loss: 0.1781137\n",
      "\tspeed: 0.0424s/iter; left time: 79.4407s\n",
      "Epoch: 3 cost time: 26.27789568901062\n",
      "Epoch: 3, Steps: 618 | Train Loss: 0.1735032 Vali Loss: 0.3154289 Test Loss: 0.2426457\n",
      "Validation loss decreased (0.331770 --> 0.315429).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2534605\n",
      "\tspeed: 0.0956s/iter; left time: 167.8433s\n",
      "\titers: 200, epoch: 4 | loss: 0.1163494\n",
      "\tspeed: 0.0429s/iter; left time: 70.9199s\n",
      "\titers: 300, epoch: 4 | loss: 0.1868854\n",
      "\tspeed: 0.0416s/iter; left time: 64.7039s\n",
      "\titers: 400, epoch: 4 | loss: 0.1310972\n",
      "\tspeed: 0.0414s/iter; left time: 60.1999s\n",
      "\titers: 500, epoch: 4 | loss: 0.1387785\n",
      "\tspeed: 0.0427s/iter; left time: 57.8747s\n",
      "\titers: 600, epoch: 4 | loss: 0.0808690\n",
      "\tspeed: 0.0424s/iter; left time: 53.2694s\n",
      "Epoch: 4 cost time: 26.12479043006897\n",
      "Epoch: 4, Steps: 618 | Train Loss: 0.1586814 Vali Loss: 0.3029079 Test Loss: 0.2410731\n",
      "Validation loss decreased (0.315429 --> 0.302908).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 200, epoch: 5 | loss: 0.0849414\n",
      "\tspeed: 0.0432s/iter; left time: 44.7634s\n",
      "\titers: 300, epoch: 5 | loss: 0.1287156\n",
      "\tspeed: 0.0416s/iter; left time: 39.0016s\n",
      "\titers: 400, epoch: 5 | loss: 0.1166004\n",
      "\tspeed: 0.0418s/iter; left time: 34.9675s\n",
      "\titers: 500, epoch: 5 | loss: 0.0874473\n",
      "\tspeed: 0.0428s/iter; left time: 31.5130s\n",
      "\titers: 600, epoch: 5 | loss: 0.1388423\n",
      "\tspeed: 0.0422s/iter; left time: 26.8969s\n",
      "Epoch: 5 cost time: 26.13906168937683\n",
      "Epoch: 5, Steps: 618 | Train Loss: 0.1491766 Vali Loss: 0.3102446 Test Loss: 0.2453862\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1230433\n",
      "\tspeed: 0.0937s/iter; left time: 48.6393s\n",
      "\titers: 200, epoch: 6 | loss: 0.1286636\n",
      "\tspeed: 0.0422s/iter; left time: 17.6840s\n",
      "\titers: 300, epoch: 6 | loss: 0.1279359\n",
      "\tspeed: 0.0415s/iter; left time: 13.2457s\n",
      "\titers: 400, epoch: 6 | loss: 0.1358311\n",
      "\tspeed: 0.0423s/iter; left time: 9.2545s\n",
      "\titers: 500, epoch: 6 | loss: 0.1060025\n",
      "\tspeed: 0.0423s/iter; left time: 5.0370s\n",
      "\titers: 600, epoch: 6 | loss: 0.1155184\n",
      "\tspeed: 0.0417s/iter; left time: 0.7914s\n",
      "Epoch: 6 cost time: 25.971617698669434\n",
      "Epoch: 6, Steps: 618 | Train Loss: 0.1439702 Vali Loss: 0.3155705 Test Loss: 0.2457050\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl216_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4994\n",
      "Test cost time: 2.6807s\n",
      "test shape: (156, 32, 6, 1) (156, 32, 6, 1)\n",
      "test shape: (4992, 6, 1) (4992, 6, 1)\n",
      "mse:0.24078059196472168, mae:0.33161690831184387\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl216_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1648.811279296875\n",
      "MAE:  27.441726684570312\n",
      "RMSE: 40.60555648803711\n",
      "MAPE: 0.3915203809738159\n",
      "MSPE: 0.7362817525863647\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl216_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24323\n",
      "[DEBUG] Original dataset length: 24323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19785\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3279\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4994\n",
      "\titers: 100, epoch: 1 | loss: 0.2582921\n",
      "\tspeed: 0.0451s/iter; left time: 162.8793s\n",
      "\titers: 200, epoch: 1 | loss: 0.2142357\n",
      "\tspeed: 0.0421s/iter; left time: 147.5947s\n",
      "\titers: 300, epoch: 1 | loss: 0.2157873\n",
      "\tspeed: 0.0417s/iter; left time: 142.2499s\n",
      "\titers: 400, epoch: 1 | loss: 0.2203617\n",
      "\tspeed: 0.0421s/iter; left time: 139.1723s\n",
      "\titers: 500, epoch: 1 | loss: 0.3249401\n",
      "\tspeed: 0.0428s/iter; left time: 137.4800s\n",
      "\titers: 600, epoch: 1 | loss: 0.2049375\n",
      "\tspeed: 0.0416s/iter; left time: 129.3381s\n",
      "Epoch: 1 cost time: 26.302100658416748\n",
      "Epoch: 1, Steps: 618 | Train Loss: 0.2764520 Vali Loss: 0.3281155 Test Loss: 0.2700931\n",
      "Validation loss decreased (inf --> 0.328115).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4484720\n",
      "\tspeed: 0.0967s/iter; left time: 289.3618s\n",
      "\titers: 200, epoch: 2 | loss: 0.1137520\n",
      "\tspeed: 0.0419s/iter; left time: 121.0426s\n",
      "\titers: 300, epoch: 2 | loss: 0.1501827\n",
      "\tspeed: 0.0419s/iter; left time: 116.9573s\n",
      "\titers: 400, epoch: 2 | loss: 0.1383560\n",
      "\tspeed: 0.0425s/iter; left time: 114.4616s\n",
      "\titers: 500, epoch: 2 | loss: 0.2124247\n",
      "\tspeed: 0.0433s/iter; left time: 112.0890s\n",
      "\titers: 600, epoch: 2 | loss: 0.1524644\n",
      "\tspeed: 0.0421s/iter; left time: 104.7650s\n",
      "Epoch: 2 cost time: 26.13294219970703\n",
      "Epoch: 2, Steps: 618 | Train Loss: 0.1988230 Vali Loss: 0.3237361 Test Loss: 0.2629321\n",
      "Validation loss decreased (0.328115 --> 0.323736).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2649992\n",
      "\tspeed: 0.0946s/iter; left time: 224.4185s\n",
      "\titers: 200, epoch: 3 | loss: 0.1216606\n",
      "\tspeed: 0.0418s/iter; left time: 94.9054s\n",
      "\titers: 300, epoch: 3 | loss: 0.1789708\n",
      "\tspeed: 0.0420s/iter; left time: 91.2766s\n",
      "\titers: 400, epoch: 3 | loss: 0.1617068\n",
      "\tspeed: 0.0421s/iter; left time: 87.2330s\n",
      "\titers: 500, epoch: 3 | loss: 0.2519102\n",
      "\tspeed: 0.0431s/iter; left time: 85.0005s\n",
      "\titers: 600, epoch: 3 | loss: 0.1340184\n",
      "\tspeed: 0.0412s/iter; left time: 77.0970s\n",
      "Epoch: 3 cost time: 25.978017568588257\n",
      "Epoch: 3, Steps: 618 | Train Loss: 0.1711658 Vali Loss: 0.3152286 Test Loss: 0.2511558\n",
      "Validation loss decreased (0.323736 --> 0.315229).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1620352\n",
      "\tspeed: 0.0950s/iter; left time: 166.6920s\n",
      "\titers: 200, epoch: 4 | loss: 0.2392211\n",
      "\tspeed: 0.0418s/iter; left time: 69.1029s\n",
      "\titers: 300, epoch: 4 | loss: 0.2237509\n",
      "\tspeed: 0.0415s/iter; left time: 64.4813s\n",
      "\titers: 400, epoch: 4 | loss: 0.1197724\n",
      "\tspeed: 0.0423s/iter; left time: 61.5908s\n",
      "\titers: 500, epoch: 4 | loss: 0.2800475\n",
      "\tspeed: 0.0429s/iter; left time: 58.1166s\n",
      "\titers: 600, epoch: 4 | loss: 0.1265808\n",
      "\tspeed: 0.0414s/iter; left time: 51.9062s\n",
      "Epoch: 4 cost time: 25.92534112930298\n",
      "Epoch: 4, Steps: 618 | Train Loss: 0.1556970 Vali Loss: 0.3280012 Test Loss: 0.2467037\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1175876\n",
      "\tspeed: 0.0950s/iter; left time: 108.0636s\n",
      "\titers: 200, epoch: 5 | loss: 0.1346732\n",
      "\tspeed: 0.0421s/iter; left time: 43.6784s\n",
      "\titers: 300, epoch: 5 | loss: 0.1420895\n",
      "\tspeed: 0.0422s/iter; left time: 39.4998s\n",
      "\titers: 400, epoch: 5 | loss: 0.1223109\n",
      "\tspeed: 0.0420s/iter; left time: 35.1153s\n",
      "\titers: 500, epoch: 5 | loss: 0.0999613\n",
      "\tspeed: 0.0431s/iter; left time: 31.7287s\n",
      "\titers: 600, epoch: 5 | loss: 0.1041320\n",
      "\tspeed: 0.0423s/iter; left time: 26.9418s\n",
      "Epoch: 5 cost time: 26.20616364479065\n",
      "Epoch: 5, Steps: 618 | Train Loss: 0.1463247 Vali Loss: 0.3219205 Test Loss: 0.2489407\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1087956\n",
      "\tspeed: 0.0948s/iter; left time: 49.2257s\n",
      "\titers: 200, epoch: 6 | loss: 0.0775446\n",
      "\tspeed: 0.0420s/iter; left time: 17.6063s\n",
      "\titers: 300, epoch: 6 | loss: 0.1248596\n",
      "\tspeed: 0.0416s/iter; left time: 13.2851s\n",
      "\titers: 400, epoch: 6 | loss: 0.1436497\n",
      "\tspeed: 0.0418s/iter; left time: 9.1506s\n",
      "\titers: 500, epoch: 6 | loss: 0.1456562\n",
      "\tspeed: 0.0427s/iter; left time: 5.0775s\n",
      "\titers: 600, epoch: 6 | loss: 0.1503458\n",
      "\tspeed: 0.0423s/iter; left time: 0.8039s\n",
      "Epoch: 6 cost time: 26.18534016609192\n",
      "Epoch: 6, Steps: 618 | Train Loss: 0.1413288 Vali Loss: 0.3296981 Test Loss: 0.2491597\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl216_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4994\n",
      "Test cost time: 2.6836s\n",
      "test shape: (156, 32, 6, 1) (156, 32, 6, 1)\n",
      "test shape: (4992, 6, 1) (4992, 6, 1)\n",
      "mse:0.2527669668197632, mae:0.3346236050128937\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl216_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1730.8916015625\n",
      "MAE:  27.690536499023438\n",
      "RMSE: 41.60398483276367\n",
      "MAPE: 0.3959085941314697\n",
      "MSPE: 0.8075483441352844\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl216_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24323\n",
      "[DEBUG] Original dataset length: 24323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19785\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3279\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4994\n",
      "\titers: 100, epoch: 1 | loss: 0.3663201\n",
      "\tspeed: 0.0428s/iter; left time: 154.4336s\n",
      "\titers: 200, epoch: 1 | loss: 0.2607256\n",
      "\tspeed: 0.0421s/iter; left time: 147.6534s\n",
      "\titers: 300, epoch: 1 | loss: 0.1887660\n",
      "\tspeed: 0.0417s/iter; left time: 141.9904s\n",
      "\titers: 400, epoch: 1 | loss: 0.2481453\n",
      "\tspeed: 0.0433s/iter; left time: 143.2311s\n",
      "\titers: 500, epoch: 1 | loss: 0.2478992\n",
      "\tspeed: 0.0419s/iter; left time: 134.3465s\n",
      "\titers: 600, epoch: 1 | loss: 0.1865162\n",
      "\tspeed: 0.0424s/iter; left time: 131.7584s\n",
      "Epoch: 1 cost time: 26.200383186340332\n",
      "Epoch: 1, Steps: 618 | Train Loss: 0.2814964 Vali Loss: 0.3173611 Test Loss: 0.2574653\n",
      "Validation loss decreased (inf --> 0.317361).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3215540\n",
      "\tspeed: 0.0970s/iter; left time: 289.9786s\n",
      "\titers: 200, epoch: 2 | loss: 0.2299848\n",
      "\tspeed: 0.0427s/iter; left time: 123.3914s\n",
      "\titers: 300, epoch: 2 | loss: 0.2129880\n",
      "\tspeed: 0.0427s/iter; left time: 119.0485s\n",
      "\titers: 400, epoch: 2 | loss: 0.1368433\n",
      "\tspeed: 0.0442s/iter; left time: 118.9587s\n",
      "\titers: 500, epoch: 2 | loss: 0.1495978\n",
      "\tspeed: 0.0426s/iter; left time: 110.2804s\n",
      "\titers: 600, epoch: 2 | loss: 0.1436598\n",
      "\tspeed: 0.0427s/iter; left time: 106.3411s\n",
      "Epoch: 2 cost time: 26.53640651702881\n",
      "Epoch: 2, Steps: 618 | Train Loss: 0.2004114 Vali Loss: 0.3145812 Test Loss: 0.2562110\n",
      "Validation loss decreased (0.317361 --> 0.314581).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1717549\n",
      "\tspeed: 0.0974s/iter; left time: 231.2133s\n",
      "\titers: 200, epoch: 3 | loss: 0.1024798\n",
      "\tspeed: 0.0430s/iter; left time: 97.6568s\n",
      "\titers: 300, epoch: 3 | loss: 0.2018980\n",
      "\tspeed: 0.0431s/iter; left time: 93.6019s\n",
      "\titers: 400, epoch: 3 | loss: 0.1490218\n",
      "\tspeed: 0.0443s/iter; left time: 91.9208s\n",
      "\titers: 500, epoch: 3 | loss: 0.1148567\n",
      "\tspeed: 0.0430s/iter; left time: 84.7820s\n",
      "\titers: 600, epoch: 3 | loss: 0.1667985\n",
      "\tspeed: 0.0423s/iter; left time: 79.3211s\n",
      "Epoch: 3 cost time: 26.672253847122192\n",
      "Epoch: 3, Steps: 618 | Train Loss: 0.1719259 Vali Loss: 0.3079414 Test Loss: 0.2418546\n",
      "Validation loss decreased (0.314581 --> 0.307941).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1700431\n",
      "\tspeed: 0.0965s/iter; left time: 169.3316s\n",
      "\titers: 200, epoch: 4 | loss: 0.1768593\n",
      "\tspeed: 0.0429s/iter; left time: 70.9699s\n",
      "\titers: 300, epoch: 4 | loss: 0.2237493\n",
      "\tspeed: 0.0423s/iter; left time: 65.8503s\n",
      "\titers: 400, epoch: 4 | loss: 0.0976973\n",
      "\tspeed: 0.0437s/iter; left time: 63.5642s\n",
      "\titers: 500, epoch: 4 | loss: 0.1349014\n",
      "\tspeed: 0.0438s/iter; left time: 59.3496s\n",
      "\titers: 600, epoch: 4 | loss: 0.1642562\n",
      "\tspeed: 0.0434s/iter; left time: 54.4406s\n",
      "Epoch: 4 cost time: 26.598915815353394\n",
      "Epoch: 4, Steps: 618 | Train Loss: 0.1567625 Vali Loss: 0.3138925 Test Loss: 0.2492318\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1343656\n",
      "\tspeed: 0.0952s/iter; left time: 108.2618s\n",
      "\titers: 200, epoch: 5 | loss: 0.1559961\n",
      "\tspeed: 0.0430s/iter; left time: 44.6225s\n",
      "\titers: 300, epoch: 5 | loss: 0.1233110\n",
      "\tspeed: 0.0428s/iter; left time: 40.1123s\n",
      "\titers: 400, epoch: 5 | loss: 0.1776212\n",
      "\tspeed: 0.0438s/iter; left time: 36.6419s\n",
      "\titers: 500, epoch: 5 | loss: 0.1519401\n",
      "\tspeed: 0.0419s/iter; left time: 30.8620s\n",
      "\titers: 600, epoch: 5 | loss: 0.1732384\n",
      "\tspeed: 0.0429s/iter; left time: 27.3108s\n",
      "Epoch: 5 cost time: 26.45865821838379\n",
      "Epoch: 5, Steps: 618 | Train Loss: 0.1471789 Vali Loss: 0.3088903 Test Loss: 0.2510030\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2094733\n",
      "\tspeed: 0.0957s/iter; left time: 49.6894s\n",
      "\titers: 200, epoch: 6 | loss: 0.1189274\n",
      "\tspeed: 0.0424s/iter; left time: 17.7578s\n",
      "\titers: 300, epoch: 6 | loss: 0.1680369\n",
      "\tspeed: 0.0424s/iter; left time: 13.5268s\n",
      "\titers: 400, epoch: 6 | loss: 0.0696787\n",
      "\tspeed: 0.0433s/iter; left time: 9.4855s\n",
      "\titers: 500, epoch: 6 | loss: 0.1559110\n",
      "\tspeed: 0.0421s/iter; left time: 5.0054s\n",
      "\titers: 600, epoch: 6 | loss: 0.1555460\n",
      "\tspeed: 0.0425s/iter; left time: 0.8081s\n",
      "Epoch: 6 cost time: 26.276623487472534\n",
      "Epoch: 6, Steps: 618 | Train Loss: 0.1419787 Vali Loss: 0.3119181 Test Loss: 0.2509308\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl216_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4994\n",
      "Test cost time: 2.7332s\n",
      "test shape: (156, 32, 6, 1) (156, 32, 6, 1)\n",
      "test shape: (4992, 6, 1) (4992, 6, 1)\n",
      "mse:0.24249933660030365, mae:0.3270329535007477\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl216_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1660.5809326171875\n",
      "MAE:  27.06239891052246\n",
      "RMSE: 40.75022506713867\n",
      "MAPE: 0.38842013478279114\n",
      "MSPE: 0.7867160439491272\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl216_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24323\n",
      "[DEBUG] Original dataset length: 24323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19785\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3279\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4994\n",
      "\titers: 100, epoch: 1 | loss: 0.2032532\n",
      "\tspeed: 0.0450s/iter; left time: 162.5694s\n",
      "\titers: 200, epoch: 1 | loss: 0.1563274\n",
      "\tspeed: 0.0423s/iter; left time: 148.5683s\n",
      "\titers: 300, epoch: 1 | loss: 0.2232013\n",
      "\tspeed: 0.0436s/iter; left time: 148.6863s\n",
      "\titers: 400, epoch: 1 | loss: 0.2476838\n",
      "\tspeed: 0.0429s/iter; left time: 141.8675s\n",
      "\titers: 500, epoch: 1 | loss: 0.2196051\n",
      "\tspeed: 0.0425s/iter; left time: 136.3004s\n",
      "\titers: 600, epoch: 1 | loss: 0.1190104\n",
      "\tspeed: 0.0431s/iter; left time: 134.0178s\n",
      "Epoch: 1 cost time: 26.75853967666626\n",
      "Epoch: 1, Steps: 618 | Train Loss: 0.2769553 Vali Loss: 0.3341312 Test Loss: 0.2757868\n",
      "Validation loss decreased (inf --> 0.334131).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1786525\n",
      "\tspeed: 0.0983s/iter; left time: 294.0344s\n",
      "\titers: 200, epoch: 2 | loss: 0.1971705\n",
      "\tspeed: 0.0432s/iter; left time: 124.7719s\n",
      "\titers: 300, epoch: 2 | loss: 0.2869054\n",
      "\tspeed: 0.0433s/iter; left time: 120.8248s\n",
      "\titers: 400, epoch: 2 | loss: 0.2147620\n",
      "\tspeed: 0.0432s/iter; left time: 116.2839s\n",
      "\titers: 500, epoch: 2 | loss: 0.1511822\n",
      "\tspeed: 0.0432s/iter; left time: 111.9206s\n",
      "\titers: 600, epoch: 2 | loss: 0.2114589\n",
      "\tspeed: 0.0445s/iter; left time: 110.7365s\n",
      "Epoch: 2 cost time: 26.93069314956665\n",
      "Epoch: 2, Steps: 618 | Train Loss: 0.1954781 Vali Loss: 0.3158267 Test Loss: 0.2525209\n",
      "Validation loss decreased (0.334131 --> 0.315827).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1257085\n",
      "\tspeed: 0.0984s/iter; left time: 233.4402s\n",
      "\titers: 200, epoch: 3 | loss: 0.1782224\n",
      "\tspeed: 0.0446s/iter; left time: 101.3000s\n",
      "\titers: 300, epoch: 3 | loss: 0.1250286\n",
      "\tspeed: 0.0430s/iter; left time: 93.4854s\n",
      "\titers: 400, epoch: 3 | loss: 0.2739024\n",
      "\tspeed: 0.0432s/iter; left time: 89.4776s\n",
      "\titers: 500, epoch: 3 | loss: 0.1310438\n",
      "\tspeed: 0.0421s/iter; left time: 83.1595s\n",
      "\titers: 600, epoch: 3 | loss: 0.2279646\n",
      "\tspeed: 0.0479s/iter; left time: 89.7251s\n",
      "Epoch: 3 cost time: 27.228859186172485\n",
      "Epoch: 3, Steps: 618 | Train Loss: 0.1712560 Vali Loss: 0.3140414 Test Loss: 0.2479146\n",
      "Validation loss decreased (0.315827 --> 0.314041).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1319314\n",
      "\tspeed: 0.0984s/iter; left time: 172.6591s\n",
      "\titers: 200, epoch: 4 | loss: 0.1478963\n",
      "\tspeed: 0.0435s/iter; left time: 72.0454s\n",
      "\titers: 300, epoch: 4 | loss: 0.1752971\n",
      "\tspeed: 0.0419s/iter; left time: 65.0968s\n",
      "\titers: 400, epoch: 4 | loss: 0.1838036\n",
      "\tspeed: 0.0425s/iter; left time: 61.7918s\n",
      "\titers: 500, epoch: 4 | loss: 0.1232213\n",
      "\tspeed: 0.0422s/iter; left time: 57.1985s\n",
      "\titers: 600, epoch: 4 | loss: 0.3609026\n",
      "\tspeed: 0.0426s/iter; left time: 53.4668s\n",
      "Epoch: 4 cost time: 26.35153102874756\n",
      "Epoch: 4, Steps: 618 | Train Loss: 0.1557990 Vali Loss: 0.3134092 Test Loss: 0.2523001\n",
      "Validation loss decreased (0.314041 --> 0.313409).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1199196\n",
      "\tspeed: 0.0936s/iter; left time: 106.4205s\n",
      "\titers: 200, epoch: 5 | loss: 0.1493078\n",
      "\tspeed: 0.0426s/iter; left time: 44.2052s\n",
      "\titers: 300, epoch: 5 | loss: 0.1602696\n",
      "\tspeed: 0.0420s/iter; left time: 39.3506s\n",
      "\titers: 400, epoch: 5 | loss: 0.1826160\n",
      "\tspeed: 0.0414s/iter; left time: 34.6846s\n",
      "\titers: 500, epoch: 5 | loss: 0.1088535\n",
      "\tspeed: 0.0420s/iter; left time: 30.9399s\n",
      "\titers: 600, epoch: 5 | loss: 0.0920276\n",
      "\tspeed: 0.0437s/iter; left time: 27.8388s\n",
      "Epoch: 5 cost time: 26.047558307647705\n",
      "Epoch: 5, Steps: 618 | Train Loss: 0.1471018 Vali Loss: 0.3149575 Test Loss: 0.2584056\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0988151\n",
      "\tspeed: 0.0934s/iter; left time: 48.4630s\n",
      "\titers: 200, epoch: 6 | loss: 0.1204196\n",
      "\tspeed: 0.0430s/iter; left time: 18.0222s\n",
      "\titers: 300, epoch: 6 | loss: 0.1423402\n",
      "\tspeed: 0.0414s/iter; left time: 13.2097s\n",
      "\titers: 400, epoch: 6 | loss: 0.1468095\n",
      "\tspeed: 0.0413s/iter; left time: 9.0352s\n",
      "\titers: 500, epoch: 6 | loss: 0.2755381\n",
      "\tspeed: 0.0425s/iter; left time: 5.0620s\n",
      "\titers: 600, epoch: 6 | loss: 0.1499323\n",
      "\tspeed: 0.0418s/iter; left time: 0.7937s\n",
      "Epoch: 6 cost time: 25.98641014099121\n",
      "Epoch: 6, Steps: 618 | Train Loss: 0.1419851 Vali Loss: 0.3068340 Test Loss: 0.2524299\n",
      "Validation loss decreased (0.313409 --> 0.306834).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl216_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4994\n",
      "Test cost time: 2.6633s\n",
      "test shape: (156, 32, 6, 1) (156, 32, 6, 1)\n",
      "test shape: (4992, 6, 1) (4992, 6, 1)\n",
      "mse:0.2544175386428833, mae:0.3253953158855438\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl216_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1742.194091796875\n",
      "MAE:  26.926881790161133\n",
      "RMSE: 41.73959732055664\n",
      "MAPE: 0.344081848859787\n",
      "MSPE: 0.5385942459106445\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl216_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24323\n",
      "[DEBUG] Original dataset length: 24323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19785\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3279\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4994\n",
      "\titers: 100, epoch: 1 | loss: 0.4121531\n",
      "\tspeed: 0.0421s/iter; left time: 152.1127s\n",
      "\titers: 200, epoch: 1 | loss: 0.2414803\n",
      "\tspeed: 0.0417s/iter; left time: 146.3045s\n",
      "\titers: 300, epoch: 1 | loss: 0.2232457\n",
      "\tspeed: 0.0414s/iter; left time: 140.9967s\n",
      "\titers: 400, epoch: 1 | loss: 0.2618462\n",
      "\tspeed: 0.0414s/iter; left time: 136.9763s\n",
      "\titers: 500, epoch: 1 | loss: 0.2106108\n",
      "\tspeed: 0.0430s/iter; left time: 137.8668s\n",
      "\titers: 600, epoch: 1 | loss: 0.2415765\n",
      "\tspeed: 0.0420s/iter; left time: 130.5408s\n",
      "Epoch: 1 cost time: 25.92520236968994\n",
      "Epoch: 1, Steps: 618 | Train Loss: 0.2960583 Vali Loss: 0.3377845 Test Loss: 0.2846154\n",
      "Validation loss decreased (inf --> 0.337784).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1967784\n",
      "\tspeed: 0.0942s/iter; left time: 281.6610s\n",
      "\titers: 200, epoch: 2 | loss: 0.2142658\n",
      "\tspeed: 0.0414s/iter; left time: 119.6016s\n",
      "\titers: 300, epoch: 2 | loss: 0.1820853\n",
      "\tspeed: 0.0417s/iter; left time: 116.4305s\n",
      "\titers: 400, epoch: 2 | loss: 0.2328463\n",
      "\tspeed: 0.0415s/iter; left time: 111.6662s\n",
      "\titers: 500, epoch: 2 | loss: 0.4991306\n",
      "\tspeed: 0.0422s/iter; left time: 109.4036s\n",
      "\titers: 600, epoch: 2 | loss: 0.2701077\n",
      "\tspeed: 0.0416s/iter; left time: 103.5228s\n",
      "Epoch: 2 cost time: 25.725220203399658\n",
      "Epoch: 2, Steps: 618 | Train Loss: 0.2012755 Vali Loss: 0.3333133 Test Loss: 0.2670879\n",
      "Validation loss decreased (0.337784 --> 0.333313).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1551149\n",
      "\tspeed: 0.0949s/iter; left time: 225.0969s\n",
      "\titers: 200, epoch: 3 | loss: 0.1445478\n",
      "\tspeed: 0.0422s/iter; left time: 95.8995s\n",
      "\titers: 300, epoch: 3 | loss: 0.1368873\n",
      "\tspeed: 0.0415s/iter; left time: 90.1391s\n",
      "\titers: 400, epoch: 3 | loss: 0.1274137\n",
      "\tspeed: 0.0412s/iter; left time: 85.4666s\n",
      "\titers: 500, epoch: 3 | loss: 0.1286819\n",
      "\tspeed: 0.0428s/iter; left time: 84.4615s\n",
      "\titers: 600, epoch: 3 | loss: 0.0996899\n",
      "\tspeed: 0.0411s/iter; left time: 77.0488s\n",
      "Epoch: 3 cost time: 25.874960899353027\n",
      "Epoch: 3, Steps: 618 | Train Loss: 0.1729698 Vali Loss: 0.3082447 Test Loss: 0.2411761\n",
      "Validation loss decreased (0.333313 --> 0.308245).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1615661\n",
      "\tspeed: 0.0951s/iter; left time: 166.9414s\n",
      "\titers: 200, epoch: 4 | loss: 0.1111029\n",
      "\tspeed: 0.0425s/iter; left time: 70.2956s\n",
      "\titers: 300, epoch: 4 | loss: 0.0956634\n",
      "\tspeed: 0.0414s/iter; left time: 64.4114s\n",
      "\titers: 400, epoch: 4 | loss: 0.2307972\n",
      "\tspeed: 0.0417s/iter; left time: 60.6332s\n",
      "\titers: 500, epoch: 4 | loss: 0.1342136\n",
      "\tspeed: 0.0427s/iter; left time: 57.8943s\n",
      "\titers: 600, epoch: 4 | loss: 0.2959890\n",
      "\tspeed: 0.0425s/iter; left time: 53.3272s\n",
      "Epoch: 4 cost time: 26.101926565170288\n",
      "Epoch: 4, Steps: 618 | Train Loss: 0.1575196 Vali Loss: 0.3145727 Test Loss: 0.2482154\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1563228\n",
      "\tspeed: 0.0947s/iter; left time: 107.6481s\n",
      "\titers: 200, epoch: 5 | loss: 0.1583908\n",
      "\tspeed: 0.0420s/iter; left time: 43.5978s\n",
      "\titers: 300, epoch: 5 | loss: 0.1178816\n",
      "\tspeed: 0.0418s/iter; left time: 39.1659s\n",
      "\titers: 400, epoch: 5 | loss: 0.1281954\n",
      "\tspeed: 0.0417s/iter; left time: 34.8784s\n",
      "\titers: 500, epoch: 5 | loss: 0.1068196\n",
      "\tspeed: 0.0426s/iter; left time: 31.3633s\n",
      "\titers: 600, epoch: 5 | loss: 0.1602941\n",
      "\tspeed: 0.0412s/iter; left time: 26.2695s\n",
      "Epoch: 5 cost time: 25.89297652244568\n",
      "Epoch: 5, Steps: 618 | Train Loss: 0.1482549 Vali Loss: 0.3200294 Test Loss: 0.2549565\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2097220\n",
      "\tspeed: 0.0937s/iter; left time: 48.6064s\n",
      "\titers: 200, epoch: 6 | loss: 0.0853412\n",
      "\tspeed: 0.0429s/iter; left time: 17.9544s\n",
      "\titers: 300, epoch: 6 | loss: 0.1417271\n",
      "\tspeed: 0.0422s/iter; left time: 13.4533s\n",
      "\titers: 400, epoch: 6 | loss: 0.1316091\n",
      "\tspeed: 0.0415s/iter; left time: 9.0873s\n",
      "\titers: 500, epoch: 6 | loss: 0.1413137\n",
      "\tspeed: 0.0427s/iter; left time: 5.0833s\n",
      "\titers: 600, epoch: 6 | loss: 0.1131534\n",
      "\tspeed: 0.0420s/iter; left time: 0.7977s\n",
      "Epoch: 6 cost time: 26.076175689697266\n",
      "Epoch: 6, Steps: 618 | Train Loss: 0.1432047 Vali Loss: 0.3301705 Test Loss: 0.2569723\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl216_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4994\n",
      "Test cost time: 2.6871s\n",
      "test shape: (156, 32, 6, 1) (156, 32, 6, 1)\n",
      "test shape: (4992, 6, 1) (4992, 6, 1)\n",
      "mse:0.24254441261291504, mae:0.3337668478488922\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl216_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1660.8896484375\n",
      "MAE:  27.61963653564453\n",
      "RMSE: 40.75401306152344\n",
      "MAPE: 0.421096533536911\n",
      "MSPE: 0.8992426991462708\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl216_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24323\n",
      "[DEBUG] Original dataset length: 24323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19785\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3279\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4994\n",
      "\titers: 100, epoch: 1 | loss: 0.2675985\n",
      "\tspeed: 0.0495s/iter; left time: 178.5448s\n",
      "\titers: 200, epoch: 1 | loss: 0.2659911\n",
      "\tspeed: 0.0413s/iter; left time: 145.0514s\n",
      "\titers: 300, epoch: 1 | loss: 0.2630031\n",
      "\tspeed: 0.0412s/iter; left time: 140.4849s\n",
      "\titers: 400, epoch: 1 | loss: 0.1671163\n",
      "\tspeed: 0.0429s/iter; left time: 141.9724s\n",
      "\titers: 500, epoch: 1 | loss: 0.1804161\n",
      "\tspeed: 0.0425s/iter; left time: 136.2645s\n",
      "\titers: 600, epoch: 1 | loss: 0.2369458\n",
      "\tspeed: 0.0420s/iter; left time: 130.6081s\n",
      "Epoch: 1 cost time: 26.729716300964355\n",
      "Epoch: 1, Steps: 618 | Train Loss: 0.2941173 Vali Loss: 0.3402280 Test Loss: 0.2910387\n",
      "Validation loss decreased (inf --> 0.340228).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1987396\n",
      "\tspeed: 0.0973s/iter; left time: 290.9307s\n",
      "\titers: 200, epoch: 2 | loss: 0.2926353\n",
      "\tspeed: 0.0414s/iter; left time: 119.7629s\n",
      "\titers: 300, epoch: 2 | loss: 0.1864560\n",
      "\tspeed: 0.0412s/iter; left time: 115.0843s\n",
      "\titers: 400, epoch: 2 | loss: 0.1905792\n",
      "\tspeed: 0.0422s/iter; left time: 113.6864s\n",
      "\titers: 500, epoch: 2 | loss: 0.3763025\n",
      "\tspeed: 0.0425s/iter; left time: 110.1528s\n",
      "\titers: 600, epoch: 2 | loss: 0.1395880\n",
      "\tspeed: 0.0422s/iter; left time: 105.1735s\n",
      "Epoch: 2 cost time: 25.979896783828735\n",
      "Epoch: 2, Steps: 618 | Train Loss: 0.2025699 Vali Loss: 0.3245832 Test Loss: 0.2729788\n",
      "Validation loss decreased (0.340228 --> 0.324583).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2120875\n",
      "\tspeed: 0.0936s/iter; left time: 222.1688s\n",
      "\titers: 200, epoch: 3 | loss: 0.1325023\n",
      "\tspeed: 0.0416s/iter; left time: 94.4965s\n",
      "\titers: 300, epoch: 3 | loss: 0.1422473\n",
      "\tspeed: 0.0412s/iter; left time: 89.6357s\n",
      "\titers: 400, epoch: 3 | loss: 0.1364473\n",
      "\tspeed: 0.0419s/iter; left time: 86.9447s\n",
      "\titers: 500, epoch: 3 | loss: 0.1337636\n",
      "\tspeed: 0.0425s/iter; left time: 83.7929s\n",
      "\titers: 600, epoch: 3 | loss: 0.1595610\n",
      "\tspeed: 0.0424s/iter; left time: 79.3511s\n",
      "Epoch: 3 cost time: 25.852632522583008\n",
      "Epoch: 3, Steps: 618 | Train Loss: 0.1723179 Vali Loss: 0.3104116 Test Loss: 0.2505572\n",
      "Validation loss decreased (0.324583 --> 0.310412).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1719283\n",
      "\tspeed: 0.0955s/iter; left time: 167.6883s\n",
      "\titers: 200, epoch: 4 | loss: 0.1514657\n",
      "\tspeed: 0.0419s/iter; left time: 69.3207s\n",
      "\titers: 300, epoch: 4 | loss: 0.1412131\n",
      "\tspeed: 0.0414s/iter; left time: 64.3909s\n",
      "\titers: 400, epoch: 4 | loss: 0.1493793\n",
      "\tspeed: 0.0420s/iter; left time: 61.0640s\n",
      "\titers: 500, epoch: 4 | loss: 0.2003113\n",
      "\tspeed: 0.0422s/iter; left time: 57.1478s\n",
      "\titers: 600, epoch: 4 | loss: 0.1438348\n",
      "\tspeed: 0.0428s/iter; left time: 53.6775s\n",
      "Epoch: 4 cost time: 26.01955533027649\n",
      "Epoch: 4, Steps: 618 | Train Loss: 0.1562042 Vali Loss: 0.3063864 Test Loss: 0.2485543\n",
      "Validation loss decreased (0.310412 --> 0.306386).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1641852\n",
      "\tspeed: 0.0959s/iter; left time: 109.0284s\n",
      "\titers: 200, epoch: 5 | loss: 0.1286202\n",
      "\tspeed: 0.0416s/iter; left time: 43.0909s\n",
      "\titers: 300, epoch: 5 | loss: 0.1829571\n",
      "\tspeed: 0.0414s/iter; left time: 38.7885s\n",
      "\titers: 400, epoch: 5 | loss: 0.1691171\n",
      "\tspeed: 0.0421s/iter; left time: 35.1989s\n",
      "\titers: 500, epoch: 5 | loss: 0.1600448\n",
      "\tspeed: 0.0419s/iter; left time: 30.9171s\n",
      "\titers: 600, epoch: 5 | loss: 0.1593293\n",
      "\tspeed: 0.0417s/iter; left time: 26.5687s\n",
      "Epoch: 5 cost time: 25.9362690448761\n",
      "Epoch: 5, Steps: 618 | Train Loss: 0.1465654 Vali Loss: 0.3162679 Test Loss: 0.2543659\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1409432\n",
      "\tspeed: 0.0941s/iter; left time: 48.8203s\n",
      "\titers: 200, epoch: 6 | loss: 0.0957621\n",
      "\tspeed: 0.0420s/iter; left time: 17.5931s\n",
      "\titers: 300, epoch: 6 | loss: 0.1667231\n",
      "\tspeed: 0.0416s/iter; left time: 13.2666s\n",
      "\titers: 400, epoch: 6 | loss: 0.1415000\n",
      "\tspeed: 0.0417s/iter; left time: 9.1345s\n",
      "\titers: 500, epoch: 6 | loss: 0.1890998\n",
      "\tspeed: 0.0420s/iter; left time: 4.9987s\n",
      "\titers: 600, epoch: 6 | loss: 0.1198669\n",
      "\tspeed: 0.0425s/iter; left time: 0.8076s\n",
      "Epoch: 6 cost time: 26.004842281341553\n",
      "Epoch: 6, Steps: 618 | Train Loss: 0.1418650 Vali Loss: 0.3351026 Test Loss: 0.2559977\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl216_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4994\n",
      "Test cost time: 2.6917s\n",
      "test shape: (156, 32, 6, 1) (156, 32, 6, 1)\n",
      "test shape: (4992, 6, 1) (4992, 6, 1)\n",
      "mse:0.24835717678070068, mae:0.3331948220729828\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl216_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1700.6942138671875\n",
      "MAE:  27.57229995727539\n",
      "RMSE: 41.23947525024414\n",
      "MAPE: 0.3635236620903015\n",
      "MSPE: 0.6031321883201599\n",
      ">>>>>>>Running time saved<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Running seq_len=240\n",
      "Args in experiment:\n",
      "Namespace(model='informer', data='traffic_full', root_path='../', data_path='traffic_full.csv', features='S', target='flow', freq='h', checkpoints='./checkpoints/', seq_len=240, label_len=24, pred_len=6, enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=2, d_layers=1, s_layers=[3, 2, 1], d_ff=2048, factor=5, padding=0, distil=True, dropout=0.05, attn='prob', embed='timeF', activation='gelu', output_attention=False, do_predict=False, mix=True, cols=None, num_workers=0, itr=10, train_epochs=6, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, inverse=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', detail_freq='h')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24299\n",
      "[DEBUG] Original dataset length: 24299\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19377\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3255\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "\titers: 100, epoch: 1 | loss: 0.3546871\n",
      "\tspeed: 0.0589s/iter; left time: 207.9175s\n",
      "\titers: 200, epoch: 1 | loss: 0.2993786\n",
      "\tspeed: 0.0444s/iter; left time: 152.4810s\n",
      "\titers: 300, epoch: 1 | loss: 0.2675970\n",
      "\tspeed: 0.0449s/iter; left time: 149.5058s\n",
      "\titers: 400, epoch: 1 | loss: 0.2477891\n",
      "\tspeed: 0.0446s/iter; left time: 144.0266s\n",
      "\titers: 500, epoch: 1 | loss: 0.4545132\n",
      "\tspeed: 0.0443s/iter; left time: 138.8371s\n",
      "\titers: 600, epoch: 1 | loss: 0.2212815\n",
      "\tspeed: 0.0453s/iter; left time: 137.4480s\n",
      "Epoch: 1 cost time: 27.556166172027588\n",
      "Epoch: 1, Steps: 605 | Train Loss: 0.2871743 Vali Loss: 0.3479817 Test Loss: 0.3048871\n",
      "Validation loss decreased (inf --> 0.347982).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1546247\n",
      "\tspeed: 0.0933s/iter; left time: 273.1157s\n",
      "\titers: 200, epoch: 2 | loss: 0.4938394\n",
      "\tspeed: 0.0451s/iter; left time: 127.5372s\n",
      "\titers: 300, epoch: 2 | loss: 0.1789630\n",
      "\tspeed: 0.0447s/iter; left time: 121.7347s\n",
      "\titers: 400, epoch: 2 | loss: 0.2018030\n",
      "\tspeed: 0.0447s/iter; left time: 117.3492s\n",
      "\titers: 500, epoch: 2 | loss: 0.1464297\n",
      "\tspeed: 0.0445s/iter; left time: 112.3590s\n",
      "\titers: 600, epoch: 2 | loss: 0.1904877\n",
      "\tspeed: 0.0452s/iter; left time: 109.5393s\n",
      "Epoch: 2 cost time: 27.06833553314209\n",
      "Epoch: 2, Steps: 605 | Train Loss: 0.2010745 Vali Loss: 0.3595946 Test Loss: 0.2899222\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1282312\n",
      "\tspeed: 0.0925s/iter; left time: 214.7722s\n",
      "\titers: 200, epoch: 3 | loss: 0.1518289\n",
      "\tspeed: 0.0453s/iter; left time: 100.5373s\n",
      "\titers: 300, epoch: 3 | loss: 0.1745663\n",
      "\tspeed: 0.0443s/iter; left time: 93.9239s\n",
      "\titers: 400, epoch: 3 | loss: 0.2905336\n",
      "\tspeed: 0.0441s/iter; left time: 89.1863s\n",
      "\titers: 500, epoch: 3 | loss: 0.1416414\n",
      "\tspeed: 0.0450s/iter; left time: 86.4795s\n",
      "\titers: 600, epoch: 3 | loss: 0.3046931\n",
      "\tspeed: 0.0450s/iter; left time: 81.8683s\n",
      "Epoch: 3 cost time: 27.07199001312256\n",
      "Epoch: 3, Steps: 605 | Train Loss: 0.1694175 Vali Loss: 0.3199262 Test Loss: 0.2568452\n",
      "Validation loss decreased (0.347982 --> 0.319926).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0802445\n",
      "\tspeed: 0.0942s/iter; left time: 161.6598s\n",
      "\titers: 200, epoch: 4 | loss: 0.1307834\n",
      "\tspeed: 0.0457s/iter; left time: 73.8472s\n",
      "\titers: 300, epoch: 4 | loss: 0.2070717\n",
      "\tspeed: 0.0441s/iter; left time: 66.8270s\n",
      "\titers: 400, epoch: 4 | loss: 0.1654413\n",
      "\tspeed: 0.0446s/iter; left time: 63.1137s\n",
      "\titers: 500, epoch: 4 | loss: 0.1137933\n",
      "\tspeed: 0.0457s/iter; left time: 60.1489s\n",
      "\titers: 600, epoch: 4 | loss: 0.1222538\n",
      "\tspeed: 0.0438s/iter; left time: 53.2930s\n",
      "Epoch: 4 cost time: 27.09575605392456\n",
      "Epoch: 4, Steps: 605 | Train Loss: 0.1549409 Vali Loss: 0.3164373 Test Loss: 0.2522540\n",
      "Validation loss decreased (0.319926 --> 0.316437).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2000692\n",
      "\tspeed: 0.0934s/iter; left time: 103.7337s\n",
      "\titers: 200, epoch: 5 | loss: 0.1241776\n",
      "\tspeed: 0.0437s/iter; left time: 44.2195s\n",
      "\titers: 300, epoch: 5 | loss: 0.1543847\n",
      "\tspeed: 0.0443s/iter; left time: 40.3612s\n",
      "\titers: 400, epoch: 5 | loss: 0.0986403\n",
      "\tspeed: 0.0444s/iter; left time: 36.0142s\n",
      "\titers: 500, epoch: 5 | loss: 0.1071101\n",
      "\tspeed: 0.0454s/iter; left time: 32.2642s\n",
      "\titers: 600, epoch: 5 | loss: 0.1854616\n",
      "\tspeed: 0.0445s/iter; left time: 27.1939s\n",
      "Epoch: 5 cost time: 26.85697293281555\n",
      "Epoch: 5, Steps: 605 | Train Loss: 0.1461998 Vali Loss: 0.3233185 Test Loss: 0.2495452\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1583440\n",
      "\tspeed: 0.0935s/iter; left time: 47.3279s\n",
      "\titers: 200, epoch: 6 | loss: 0.1225656\n",
      "\tspeed: 0.0456s/iter; left time: 18.5020s\n",
      "\titers: 300, epoch: 6 | loss: 0.1298719\n",
      "\tspeed: 0.0447s/iter; left time: 13.6651s\n",
      "\titers: 400, epoch: 6 | loss: 0.2102426\n",
      "\tspeed: 0.0444s/iter; left time: 9.1392s\n",
      "\titers: 500, epoch: 6 | loss: 0.0827371\n",
      "\tspeed: 0.0446s/iter; left time: 4.7294s\n",
      "\titers: 600, epoch: 6 | loss: 0.2194119\n",
      "\tspeed: 0.0442s/iter; left time: 0.2650s\n",
      "Epoch: 6 cost time: 27.124669313430786\n",
      "Epoch: 6, Steps: 605 | Train Loss: 0.1414889 Vali Loss: 0.3273892 Test Loss: 0.2552150\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "Test cost time: 2.7801s\n",
      "test shape: (150, 32, 6, 1) (150, 32, 6, 1)\n",
      "test shape: (4800, 6, 1) (4800, 6, 1)\n",
      "mse:0.2512800395488739, mae:0.32814377546310425\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1720.7093505859375\n",
      "MAE:  27.15431785583496\n",
      "RMSE: 41.4814338684082\n",
      "MAPE: 0.3628509044647217\n",
      "MSPE: 0.6306906342506409\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24299\n",
      "[DEBUG] Original dataset length: 24299\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19377\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3255\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "\titers: 100, epoch: 1 | loss: 0.3504760\n",
      "\tspeed: 0.0442s/iter; left time: 156.0641s\n",
      "\titers: 200, epoch: 1 | loss: 0.3145763\n",
      "\tspeed: 0.0440s/iter; left time: 150.9054s\n",
      "\titers: 300, epoch: 1 | loss: 0.2003708\n",
      "\tspeed: 0.0442s/iter; left time: 147.3150s\n",
      "\titers: 400, epoch: 1 | loss: 0.2305922\n",
      "\tspeed: 0.0453s/iter; left time: 146.4796s\n",
      "\titers: 500, epoch: 1 | loss: 0.1543079\n",
      "\tspeed: 0.0453s/iter; left time: 141.7245s\n",
      "\titers: 600, epoch: 1 | loss: 0.2346435\n",
      "\tspeed: 0.0446s/iter; left time: 135.0746s\n",
      "Epoch: 1 cost time: 27.007298231124878\n",
      "Epoch: 1, Steps: 605 | Train Loss: 0.2898870 Vali Loss: 0.3304249 Test Loss: 0.2665307\n",
      "Validation loss decreased (inf --> 0.330425).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1209250\n",
      "\tspeed: 0.0961s/iter; left time: 281.0479s\n",
      "\titers: 200, epoch: 2 | loss: 0.2019567\n",
      "\tspeed: 0.0451s/iter; left time: 127.3339s\n",
      "\titers: 300, epoch: 2 | loss: 0.1537015\n",
      "\tspeed: 0.0459s/iter; left time: 125.2492s\n",
      "\titers: 400, epoch: 2 | loss: 0.2416111\n",
      "\tspeed: 0.0462s/iter; left time: 121.2809s\n",
      "\titers: 500, epoch: 2 | loss: 0.1263018\n",
      "\tspeed: 0.0452s/iter; left time: 114.0888s\n",
      "\titers: 600, epoch: 2 | loss: 0.2908061\n",
      "\tspeed: 0.0451s/iter; left time: 109.5236s\n",
      "Epoch: 2 cost time: 27.493525981903076\n",
      "Epoch: 2, Steps: 605 | Train Loss: 0.1969819 Vali Loss: 0.3213315 Test Loss: 0.2575419\n",
      "Validation loss decreased (0.330425 --> 0.321332).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1477247\n",
      "\tspeed: 0.0959s/iter; left time: 222.5145s\n",
      "\titers: 200, epoch: 3 | loss: 0.1456246\n",
      "\tspeed: 0.0450s/iter; left time: 99.9442s\n",
      "\titers: 300, epoch: 3 | loss: 0.1307080\n",
      "\tspeed: 0.0450s/iter; left time: 95.4184s\n",
      "\titers: 400, epoch: 3 | loss: 0.2041646\n",
      "\tspeed: 0.0450s/iter; left time: 90.9834s\n",
      "\titers: 500, epoch: 3 | loss: 0.1587016\n",
      "\tspeed: 0.0457s/iter; left time: 87.7337s\n",
      "\titers: 600, epoch: 3 | loss: 0.1153596\n",
      "\tspeed: 0.0463s/iter; left time: 84.2305s\n",
      "Epoch: 3 cost time: 27.455731630325317\n",
      "Epoch: 3, Steps: 605 | Train Loss: 0.1695223 Vali Loss: 0.3316666 Test Loss: 0.2576473\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1524941\n",
      "\tspeed: 0.0944s/iter; left time: 161.9324s\n",
      "\titers: 200, epoch: 4 | loss: 0.1457122\n",
      "\tspeed: 0.0453s/iter; left time: 73.2465s\n",
      "\titers: 300, epoch: 4 | loss: 0.1419670\n",
      "\tspeed: 0.0458s/iter; left time: 69.4525s\n",
      "\titers: 400, epoch: 4 | loss: 0.2018518\n",
      "\tspeed: 0.0456s/iter; left time: 64.5538s\n",
      "\titers: 500, epoch: 4 | loss: 0.1779337\n",
      "\tspeed: 0.0458s/iter; left time: 60.2101s\n",
      "\titers: 600, epoch: 4 | loss: 0.1989736\n",
      "\tspeed: 0.0463s/iter; left time: 56.3434s\n",
      "Epoch: 4 cost time: 27.641367197036743\n",
      "Epoch: 4, Steps: 605 | Train Loss: 0.1534309 Vali Loss: 0.3375521 Test Loss: 0.2641195\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1779419\n",
      "\tspeed: 0.0945s/iter; left time: 104.9938s\n",
      "\titers: 200, epoch: 5 | loss: 0.1681830\n",
      "\tspeed: 0.0463s/iter; left time: 46.8137s\n",
      "\titers: 300, epoch: 5 | loss: 0.1905485\n",
      "\tspeed: 0.0446s/iter; left time: 40.6182s\n",
      "\titers: 400, epoch: 5 | loss: 0.1573281\n",
      "\tspeed: 0.0448s/iter; left time: 36.3299s\n",
      "\titers: 500, epoch: 5 | loss: 0.0991551\n",
      "\tspeed: 0.0460s/iter; left time: 32.7123s\n",
      "\titers: 600, epoch: 5 | loss: 0.1500919\n",
      "\tspeed: 0.0442s/iter; left time: 27.0277s\n",
      "Epoch: 5 cost time: 27.350849628448486\n",
      "Epoch: 5, Steps: 605 | Train Loss: 0.1457710 Vali Loss: 0.3332706 Test Loss: 0.2492727\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "Test cost time: 2.7362s\n",
      "test shape: (150, 32, 6, 1) (150, 32, 6, 1)\n",
      "test shape: (4800, 6, 1) (4800, 6, 1)\n",
      "mse:0.25740060210227966, mae:0.34558525681495667\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1762.6217041015625\n",
      "MAE:  28.597625732421875\n",
      "RMSE: 41.98358917236328\n",
      "MAPE: 0.4253406524658203\n",
      "MSPE: 0.9769390225410461\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24299\n",
      "[DEBUG] Original dataset length: 24299\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19377\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3255\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "\titers: 100, epoch: 1 | loss: 0.3845879\n",
      "\tspeed: 0.0451s/iter; left time: 159.1652s\n",
      "\titers: 200, epoch: 1 | loss: 0.2349953\n",
      "\tspeed: 0.0448s/iter; left time: 153.5559s\n",
      "\titers: 300, epoch: 1 | loss: 0.3060913\n",
      "\tspeed: 0.0449s/iter; left time: 149.4989s\n",
      "\titers: 400, epoch: 1 | loss: 0.2179845\n",
      "\tspeed: 0.0452s/iter; left time: 145.9301s\n",
      "\titers: 500, epoch: 1 | loss: 0.1809912\n",
      "\tspeed: 0.0453s/iter; left time: 141.9873s\n",
      "\titers: 600, epoch: 1 | loss: 0.3051285\n",
      "\tspeed: 0.0449s/iter; left time: 136.0383s\n",
      "Epoch: 1 cost time: 27.259770393371582\n",
      "Epoch: 1, Steps: 605 | Train Loss: 0.2708194 Vali Loss: 0.3416645 Test Loss: 0.2784626\n",
      "Validation loss decreased (inf --> 0.341664).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1410696\n",
      "\tspeed: 0.0970s/iter; left time: 283.9418s\n",
      "\titers: 200, epoch: 2 | loss: 0.3050268\n",
      "\tspeed: 0.0446s/iter; left time: 125.9695s\n",
      "\titers: 300, epoch: 2 | loss: 0.2285542\n",
      "\tspeed: 0.0457s/iter; left time: 124.5160s\n",
      "\titers: 400, epoch: 2 | loss: 0.3973157\n",
      "\tspeed: 0.0470s/iter; left time: 123.3842s\n",
      "\titers: 500, epoch: 2 | loss: 0.2232391\n",
      "\tspeed: 0.0464s/iter; left time: 117.1704s\n",
      "\titers: 600, epoch: 2 | loss: 0.1358194\n",
      "\tspeed: 0.0468s/iter; left time: 113.5471s\n",
      "Epoch: 2 cost time: 27.859485864639282\n",
      "Epoch: 2, Steps: 605 | Train Loss: 0.1940281 Vali Loss: 0.3374898 Test Loss: 0.2670369\n",
      "Validation loss decreased (0.341664 --> 0.337490).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1551415\n",
      "\tspeed: 0.0969s/iter; left time: 224.9493s\n",
      "\titers: 200, epoch: 3 | loss: 0.1222430\n",
      "\tspeed: 0.0438s/iter; left time: 97.3795s\n",
      "\titers: 300, epoch: 3 | loss: 0.1699100\n",
      "\tspeed: 0.0447s/iter; left time: 94.8522s\n",
      "\titers: 400, epoch: 3 | loss: 0.1594872\n",
      "\tspeed: 0.0463s/iter; left time: 93.5939s\n",
      "\titers: 500, epoch: 3 | loss: 0.1668733\n",
      "\tspeed: 0.0450s/iter; left time: 86.3901s\n",
      "\titers: 600, epoch: 3 | loss: 0.2047323\n",
      "\tspeed: 0.0455s/iter; left time: 82.8904s\n",
      "Epoch: 3 cost time: 27.303165435791016\n",
      "Epoch: 3, Steps: 605 | Train Loss: 0.1669052 Vali Loss: 0.3344119 Test Loss: 0.2579402\n",
      "Validation loss decreased (0.337490 --> 0.334412).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1127484\n",
      "\tspeed: 0.0963s/iter; left time: 165.1783s\n",
      "\titers: 200, epoch: 4 | loss: 0.1269177\n",
      "\tspeed: 0.0455s/iter; left time: 73.5199s\n",
      "\titers: 300, epoch: 4 | loss: 0.1590138\n",
      "\tspeed: 0.0451s/iter; left time: 68.4002s\n",
      "\titers: 400, epoch: 4 | loss: 0.1151105\n",
      "\tspeed: 0.0449s/iter; left time: 63.5709s\n",
      "\titers: 500, epoch: 4 | loss: 0.1345040\n",
      "\tspeed: 0.0458s/iter; left time: 60.2672s\n",
      "\titers: 600, epoch: 4 | loss: 0.1037954\n",
      "\tspeed: 0.0451s/iter; left time: 54.8154s\n",
      "Epoch: 4 cost time: 27.410629510879517\n",
      "Epoch: 4, Steps: 605 | Train Loss: 0.1530664 Vali Loss: 0.3496295 Test Loss: 0.2683142\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1259331\n",
      "\tspeed: 0.0940s/iter; left time: 104.4690s\n",
      "\titers: 200, epoch: 5 | loss: 0.1619763\n",
      "\tspeed: 0.0450s/iter; left time: 45.4470s\n",
      "\titers: 300, epoch: 5 | loss: 0.1412233\n",
      "\tspeed: 0.0457s/iter; left time: 41.5972s\n",
      "\titers: 400, epoch: 5 | loss: 0.1177775\n",
      "\tspeed: 0.0447s/iter; left time: 36.2123s\n",
      "\titers: 500, epoch: 5 | loss: 0.1820581\n",
      "\tspeed: 0.0449s/iter; left time: 31.9363s\n",
      "\titers: 600, epoch: 5 | loss: 0.1594034\n",
      "\tspeed: 0.0451s/iter; left time: 27.5680s\n",
      "Epoch: 5 cost time: 27.233579635620117\n",
      "Epoch: 5, Steps: 605 | Train Loss: 0.1453740 Vali Loss: 0.3269091 Test Loss: 0.2504836\n",
      "Validation loss decreased (0.334412 --> 0.326909).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0973285\n",
      "\tspeed: 0.0949s/iter; left time: 48.0047s\n",
      "\titers: 200, epoch: 6 | loss: 0.1024074\n",
      "\tspeed: 0.0448s/iter; left time: 18.2030s\n",
      "\titers: 300, epoch: 6 | loss: 0.1143235\n",
      "\tspeed: 0.0453s/iter; left time: 13.8736s\n",
      "\titers: 400, epoch: 6 | loss: 0.1157825\n",
      "\tspeed: 0.0448s/iter; left time: 9.2334s\n",
      "\titers: 500, epoch: 6 | loss: 0.2217886\n",
      "\tspeed: 0.0445s/iter; left time: 4.7128s\n",
      "\titers: 600, epoch: 6 | loss: 0.1226147\n",
      "\tspeed: 0.0461s/iter; left time: 0.2763s\n",
      "Epoch: 6 cost time: 27.291992664337158\n",
      "Epoch: 6, Steps: 605 | Train Loss: 0.1403414 Vali Loss: 0.3298041 Test Loss: 0.2539586\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "Test cost time: 2.7584s\n",
      "test shape: (150, 32, 6, 1) (150, 32, 6, 1)\n",
      "test shape: (4800, 6, 1) (4800, 6, 1)\n",
      "mse:0.25005200505256653, mae:0.32281696796417236\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1712.300048828125\n",
      "MAE:  26.713520050048828\n",
      "RMSE: 41.379947662353516\n",
      "MAPE: 0.3428734540939331\n",
      "MSPE: 0.5319750905036926\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24299\n",
      "[DEBUG] Original dataset length: 24299\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19377\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3255\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "\titers: 100, epoch: 1 | loss: 0.3383255\n",
      "\tspeed: 0.0446s/iter; left time: 157.6084s\n",
      "\titers: 200, epoch: 1 | loss: 0.3753301\n",
      "\tspeed: 0.0462s/iter; left time: 158.5096s\n",
      "\titers: 300, epoch: 1 | loss: 0.2040434\n",
      "\tspeed: 0.0454s/iter; left time: 151.2684s\n",
      "\titers: 400, epoch: 1 | loss: 0.2604682\n",
      "\tspeed: 0.0453s/iter; left time: 146.2717s\n",
      "\titers: 500, epoch: 1 | loss: 0.4085920\n",
      "\tspeed: 0.0458s/iter; left time: 143.5309s\n",
      "\titers: 600, epoch: 1 | loss: 0.2126736\n",
      "\tspeed: 0.0455s/iter; left time: 138.0395s\n",
      "Epoch: 1 cost time: 27.539767742156982\n",
      "Epoch: 1, Steps: 605 | Train Loss: 0.2826215 Vali Loss: 0.3765716 Test Loss: 0.3153481\n",
      "Validation loss decreased (inf --> 0.376572).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1180116\n",
      "\tspeed: 0.0953s/iter; left time: 278.8036s\n",
      "\titers: 200, epoch: 2 | loss: 0.1763289\n",
      "\tspeed: 0.0455s/iter; left time: 128.6773s\n",
      "\titers: 300, epoch: 2 | loss: 0.1975053\n",
      "\tspeed: 0.0451s/iter; left time: 123.0217s\n",
      "\titers: 400, epoch: 2 | loss: 0.2278317\n",
      "\tspeed: 0.0448s/iter; left time: 117.6142s\n",
      "\titers: 500, epoch: 2 | loss: 0.1724010\n",
      "\tspeed: 0.0465s/iter; left time: 117.3488s\n",
      "\titers: 600, epoch: 2 | loss: 0.1713602\n",
      "\tspeed: 0.0451s/iter; left time: 109.3596s\n",
      "Epoch: 2 cost time: 27.501312255859375\n",
      "Epoch: 2, Steps: 605 | Train Loss: 0.1991847 Vali Loss: 0.3226936 Test Loss: 0.2700602\n",
      "Validation loss decreased (0.376572 --> 0.322694).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1747060\n",
      "\tspeed: 0.0954s/iter; left time: 221.4237s\n",
      "\titers: 200, epoch: 3 | loss: 0.1265258\n",
      "\tspeed: 0.0458s/iter; left time: 101.6190s\n",
      "\titers: 300, epoch: 3 | loss: 0.1977976\n",
      "\tspeed: 0.0457s/iter; left time: 96.8463s\n",
      "\titers: 400, epoch: 3 | loss: 0.0966218\n",
      "\tspeed: 0.0453s/iter; left time: 91.5299s\n",
      "\titers: 500, epoch: 3 | loss: 0.2202561\n",
      "\tspeed: 0.0452s/iter; left time: 86.8737s\n",
      "\titers: 600, epoch: 3 | loss: 0.1930201\n",
      "\tspeed: 0.0455s/iter; left time: 82.7995s\n",
      "Epoch: 3 cost time: 27.52275514602661\n",
      "Epoch: 3, Steps: 605 | Train Loss: 0.1711648 Vali Loss: 0.3254500 Test Loss: 0.2656896\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2097965\n",
      "\tspeed: 0.0952s/iter; left time: 163.2843s\n",
      "\titers: 200, epoch: 4 | loss: 0.2298828\n",
      "\tspeed: 0.0454s/iter; left time: 73.2923s\n",
      "\titers: 300, epoch: 4 | loss: 0.2922571\n",
      "\tspeed: 0.0453s/iter; left time: 68.6470s\n",
      "\titers: 400, epoch: 4 | loss: 0.1438338\n",
      "\tspeed: 0.0454s/iter; left time: 64.3361s\n",
      "\titers: 500, epoch: 4 | loss: 0.1462069\n",
      "\tspeed: 0.0451s/iter; left time: 59.3866s\n",
      "\titers: 600, epoch: 4 | loss: 0.1126169\n",
      "\tspeed: 0.0455s/iter; left time: 55.3145s\n",
      "Epoch: 4 cost time: 27.531158208847046\n",
      "Epoch: 4, Steps: 605 | Train Loss: 0.1568941 Vali Loss: 0.3174646 Test Loss: 0.2685977\n",
      "Validation loss decreased (0.322694 --> 0.317465).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1748972\n",
      "\tspeed: 0.0960s/iter; left time: 106.6754s\n",
      "\titers: 200, epoch: 5 | loss: 0.1176947\n",
      "\tspeed: 0.0454s/iter; left time: 45.8571s\n",
      "\titers: 300, epoch: 5 | loss: 0.1257904\n",
      "\tspeed: 0.0465s/iter; left time: 42.3213s\n",
      "\titers: 400, epoch: 5 | loss: 0.0974078\n",
      "\tspeed: 0.0455s/iter; left time: 36.9056s\n",
      "\titers: 500, epoch: 5 | loss: 0.1469759\n",
      "\tspeed: 0.0454s/iter; left time: 32.2471s\n",
      "\titers: 600, epoch: 5 | loss: 0.1203570\n",
      "\tspeed: 0.0452s/iter; left time: 27.6201s\n",
      "Epoch: 5 cost time: 27.543533325195312\n",
      "Epoch: 5, Steps: 605 | Train Loss: 0.1494165 Vali Loss: 0.3216069 Test Loss: 0.2675297\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1936310\n",
      "\tspeed: 0.0946s/iter; left time: 47.8602s\n",
      "\titers: 200, epoch: 6 | loss: 0.1385280\n",
      "\tspeed: 0.0453s/iter; left time: 18.3875s\n",
      "\titers: 300, epoch: 6 | loss: 0.0964164\n",
      "\tspeed: 0.0455s/iter; left time: 13.9173s\n",
      "\titers: 400, epoch: 6 | loss: 0.1216507\n",
      "\tspeed: 0.0448s/iter; left time: 9.2304s\n",
      "\titers: 500, epoch: 6 | loss: 0.1325035\n",
      "\tspeed: 0.0452s/iter; left time: 4.7952s\n",
      "\titers: 600, epoch: 6 | loss: 0.1275657\n",
      "\tspeed: 0.0453s/iter; left time: 0.2720s\n",
      "Epoch: 6 cost time: 27.379326581954956\n",
      "Epoch: 6, Steps: 605 | Train Loss: 0.1440462 Vali Loss: 0.3212618 Test Loss: 0.2644680\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "Test cost time: 2.7647s\n",
      "test shape: (150, 32, 6, 1) (150, 32, 6, 1)\n",
      "test shape: (4800, 6, 1) (4800, 6, 1)\n",
      "mse:0.26985716819763184, mae:0.3460264205932617\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1847.921142578125\n",
      "MAE:  28.634132385253906\n",
      "RMSE: 42.98745346069336\n",
      "MAPE: 0.35033249855041504\n",
      "MSPE: 0.48819345235824585\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24299\n",
      "[DEBUG] Original dataset length: 24299\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19377\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3255\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "\titers: 100, epoch: 1 | loss: 0.2524586\n",
      "\tspeed: 0.0461s/iter; left time: 162.7392s\n",
      "\titers: 200, epoch: 1 | loss: 0.2321238\n",
      "\tspeed: 0.0460s/iter; left time: 157.9127s\n",
      "\titers: 300, epoch: 1 | loss: 0.2113032\n",
      "\tspeed: 0.0451s/iter; left time: 150.0750s\n",
      "\titers: 400, epoch: 1 | loss: 0.2253240\n",
      "\tspeed: 0.0445s/iter; left time: 143.6532s\n",
      "\titers: 500, epoch: 1 | loss: 0.2695982\n",
      "\tspeed: 0.0453s/iter; left time: 141.9101s\n",
      "\titers: 600, epoch: 1 | loss: 0.2429025\n",
      "\tspeed: 0.0450s/iter; left time: 136.4777s\n",
      "Epoch: 1 cost time: 27.449835538864136\n",
      "Epoch: 1, Steps: 605 | Train Loss: 0.2750817 Vali Loss: 0.3294223 Test Loss: 0.2789281\n",
      "Validation loss decreased (inf --> 0.329422).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2049259\n",
      "\tspeed: 0.0950s/iter; left time: 277.9687s\n",
      "\titers: 200, epoch: 2 | loss: 0.1839683\n",
      "\tspeed: 0.0448s/iter; left time: 126.6765s\n",
      "\titers: 300, epoch: 2 | loss: 0.2754406\n",
      "\tspeed: 0.0445s/iter; left time: 121.2049s\n",
      "\titers: 400, epoch: 2 | loss: 0.1806444\n",
      "\tspeed: 0.0448s/iter; left time: 117.5657s\n",
      "\titers: 500, epoch: 2 | loss: 0.2406071\n",
      "\tspeed: 0.0456s/iter; left time: 115.1918s\n",
      "\titers: 600, epoch: 2 | loss: 0.2735046\n",
      "\tspeed: 0.0443s/iter; left time: 107.4708s\n",
      "Epoch: 2 cost time: 27.193928480148315\n",
      "Epoch: 2, Steps: 605 | Train Loss: 0.1980407 Vali Loss: 0.3281589 Test Loss: 0.2701092\n",
      "Validation loss decreased (0.329422 --> 0.328159).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1963482\n",
      "\tspeed: 0.0944s/iter; left time: 219.0537s\n",
      "\titers: 200, epoch: 3 | loss: 0.1298716\n",
      "\tspeed: 0.0458s/iter; left time: 101.7709s\n",
      "\titers: 300, epoch: 3 | loss: 0.1774404\n",
      "\tspeed: 0.0447s/iter; left time: 94.7594s\n",
      "\titers: 400, epoch: 3 | loss: 0.0989035\n",
      "\tspeed: 0.0441s/iter; left time: 89.1703s\n",
      "\titers: 500, epoch: 3 | loss: 0.1494391\n",
      "\tspeed: 0.0460s/iter; left time: 88.4072s\n",
      "\titers: 600, epoch: 3 | loss: 0.1866919\n",
      "\tspeed: 0.0454s/iter; left time: 82.6729s\n",
      "Epoch: 3 cost time: 27.33031988143921\n",
      "Epoch: 3, Steps: 605 | Train Loss: 0.1697416 Vali Loss: 0.3231154 Test Loss: 0.2556813\n",
      "Validation loss decreased (0.328159 --> 0.323115).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0715048\n",
      "\tspeed: 0.0948s/iter; left time: 162.7170s\n",
      "\titers: 200, epoch: 4 | loss: 0.1437663\n",
      "\tspeed: 0.0453s/iter; left time: 73.1800s\n",
      "\titers: 300, epoch: 4 | loss: 0.1235285\n",
      "\tspeed: 0.0450s/iter; left time: 68.2370s\n",
      "\titers: 400, epoch: 4 | loss: 0.1261751\n",
      "\tspeed: 0.0451s/iter; left time: 63.9180s\n",
      "\titers: 500, epoch: 4 | loss: 0.2103669\n",
      "\tspeed: 0.0452s/iter; left time: 59.5281s\n",
      "\titers: 600, epoch: 4 | loss: 0.1871294\n",
      "\tspeed: 0.0443s/iter; left time: 53.8896s\n",
      "Epoch: 4 cost time: 27.259241819381714\n",
      "Epoch: 4, Steps: 605 | Train Loss: 0.1551382 Vali Loss: 0.3349608 Test Loss: 0.2625583\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1097669\n",
      "\tspeed: 0.0938s/iter; left time: 104.2101s\n",
      "\titers: 200, epoch: 5 | loss: 0.1319301\n",
      "\tspeed: 0.0449s/iter; left time: 45.3845s\n",
      "\titers: 300, epoch: 5 | loss: 0.1581110\n",
      "\tspeed: 0.0446s/iter; left time: 40.6339s\n",
      "\titers: 400, epoch: 5 | loss: 0.1233631\n",
      "\tspeed: 0.0453s/iter; left time: 36.7553s\n",
      "\titers: 500, epoch: 5 | loss: 0.0979262\n",
      "\tspeed: 0.0452s/iter; left time: 32.1266s\n",
      "\titers: 600, epoch: 5 | loss: 0.1780928\n",
      "\tspeed: 0.0450s/iter; left time: 27.4802s\n",
      "Epoch: 5 cost time: 27.29565954208374\n",
      "Epoch: 5, Steps: 605 | Train Loss: 0.1469042 Vali Loss: 0.3309154 Test Loss: 0.2557194\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0835098\n",
      "\tspeed: 0.0928s/iter; left time: 46.9599s\n",
      "\titers: 200, epoch: 6 | loss: 0.1220840\n",
      "\tspeed: 0.0448s/iter; left time: 18.1886s\n",
      "\titers: 300, epoch: 6 | loss: 0.1329109\n",
      "\tspeed: 0.0451s/iter; left time: 13.8036s\n",
      "\titers: 400, epoch: 6 | loss: 0.1204978\n",
      "\tspeed: 0.0457s/iter; left time: 9.4100s\n",
      "\titers: 500, epoch: 6 | loss: 0.1085567\n",
      "\tspeed: 0.0453s/iter; left time: 4.8027s\n",
      "\titers: 600, epoch: 6 | loss: 0.2035782\n",
      "\tspeed: 0.0454s/iter; left time: 0.2721s\n",
      "Epoch: 6 cost time: 27.27722978591919\n",
      "Epoch: 6, Steps: 605 | Train Loss: 0.1420984 Vali Loss: 0.3284882 Test Loss: 0.2569660\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "Test cost time: 2.8982s\n",
      "test shape: (150, 32, 6, 1) (150, 32, 6, 1)\n",
      "test shape: (4800, 6, 1) (4800, 6, 1)\n",
      "mse:0.25461506843566895, mae:0.3217587471008301\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1743.5469970703125\n",
      "MAE:  26.625951766967773\n",
      "RMSE: 41.755802154541016\n",
      "MAPE: 0.34330233931541443\n",
      "MSPE: 0.5413418412208557\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24299\n",
      "[DEBUG] Original dataset length: 24299\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19377\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3255\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "\titers: 100, epoch: 1 | loss: 0.2893296\n",
      "\tspeed: 0.0442s/iter; left time: 156.0109s\n",
      "\titers: 200, epoch: 1 | loss: 0.2795418\n",
      "\tspeed: 0.0447s/iter; left time: 153.5194s\n",
      "\titers: 300, epoch: 1 | loss: 0.1843330\n",
      "\tspeed: 0.0455s/iter; left time: 151.4483s\n",
      "\titers: 400, epoch: 1 | loss: 0.2463661\n",
      "\tspeed: 0.0445s/iter; left time: 143.6641s\n",
      "\titers: 500, epoch: 1 | loss: 0.2157255\n",
      "\tspeed: 0.0448s/iter; left time: 140.1220s\n",
      "\titers: 600, epoch: 1 | loss: 0.2640129\n",
      "\tspeed: 0.0453s/iter; left time: 137.4128s\n",
      "Epoch: 1 cost time: 27.147366762161255\n",
      "Epoch: 1, Steps: 605 | Train Loss: 0.2764628 Vali Loss: 0.3310328 Test Loss: 0.2731429\n",
      "Validation loss decreased (inf --> 0.331033).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1891289\n",
      "\tspeed: 0.0959s/iter; left time: 280.7041s\n",
      "\titers: 200, epoch: 2 | loss: 0.1393946\n",
      "\tspeed: 0.0444s/iter; left time: 125.4894s\n",
      "\titers: 300, epoch: 2 | loss: 0.1221945\n",
      "\tspeed: 0.0458s/iter; left time: 124.9823s\n",
      "\titers: 400, epoch: 2 | loss: 0.2820367\n",
      "\tspeed: 0.0450s/iter; left time: 118.2572s\n",
      "\titers: 500, epoch: 2 | loss: 0.2330725\n",
      "\tspeed: 0.0444s/iter; left time: 112.2153s\n",
      "\titers: 600, epoch: 2 | loss: 0.1271834\n",
      "\tspeed: 0.0460s/iter; left time: 111.5336s\n",
      "Epoch: 2 cost time: 27.28860569000244\n",
      "Epoch: 2, Steps: 605 | Train Loss: 0.1923155 Vali Loss: 0.3229811 Test Loss: 0.2607305\n",
      "Validation loss decreased (0.331033 --> 0.322981).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2312613\n",
      "\tspeed: 0.0944s/iter; left time: 219.1410s\n",
      "\titers: 200, epoch: 3 | loss: 0.2346363\n",
      "\tspeed: 0.0455s/iter; left time: 101.0583s\n",
      "\titers: 300, epoch: 3 | loss: 0.1117663\n",
      "\tspeed: 0.0454s/iter; left time: 96.3145s\n",
      "\titers: 400, epoch: 3 | loss: 0.0964210\n",
      "\tspeed: 0.0449s/iter; left time: 90.6970s\n",
      "\titers: 500, epoch: 3 | loss: 0.1263062\n",
      "\tspeed: 0.0446s/iter; left time: 85.7311s\n",
      "\titers: 600, epoch: 3 | loss: 0.1978659\n",
      "\tspeed: 0.0455s/iter; left time: 82.9427s\n",
      "Epoch: 3 cost time: 27.27264165878296\n",
      "Epoch: 3, Steps: 605 | Train Loss: 0.1673639 Vali Loss: 0.3184876 Test Loss: 0.2473771\n",
      "Validation loss decreased (0.322981 --> 0.318488).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1656242\n",
      "\tspeed: 0.0937s/iter; left time: 160.8231s\n",
      "\titers: 200, epoch: 4 | loss: 0.1075492\n",
      "\tspeed: 0.0448s/iter; left time: 72.3310s\n",
      "\titers: 300, epoch: 4 | loss: 0.1335539\n",
      "\tspeed: 0.0455s/iter; left time: 68.9415s\n",
      "\titers: 400, epoch: 4 | loss: 0.1572973\n",
      "\tspeed: 0.0445s/iter; left time: 62.9455s\n",
      "\titers: 500, epoch: 4 | loss: 0.1301105\n",
      "\tspeed: 0.0453s/iter; left time: 59.6352s\n",
      "\titers: 600, epoch: 4 | loss: 0.3017600\n",
      "\tspeed: 0.0456s/iter; left time: 55.4834s\n",
      "Epoch: 4 cost time: 27.230005025863647\n",
      "Epoch: 4, Steps: 605 | Train Loss: 0.1530762 Vali Loss: 0.3093312 Test Loss: 0.2512638\n",
      "Validation loss decreased (0.318488 --> 0.309331).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2052740\n",
      "\tspeed: 0.0943s/iter; left time: 104.8030s\n",
      "\titers: 200, epoch: 5 | loss: 0.1250549\n",
      "\tspeed: 0.0458s/iter; left time: 46.3424s\n",
      "\titers: 300, epoch: 5 | loss: 0.2187440\n",
      "\tspeed: 0.0453s/iter; left time: 41.3072s\n",
      "\titers: 400, epoch: 5 | loss: 0.2073985\n",
      "\tspeed: 0.0454s/iter; left time: 36.7894s\n",
      "\titers: 500, epoch: 5 | loss: 0.2480398\n",
      "\tspeed: 0.0480s/iter; left time: 34.1467s\n",
      "\titers: 600, epoch: 5 | loss: 0.1897676\n",
      "\tspeed: 0.0458s/iter; left time: 27.9945s\n",
      "Epoch: 5 cost time: 27.749210357666016\n",
      "Epoch: 5, Steps: 605 | Train Loss: 0.1447793 Vali Loss: 0.3182001 Test Loss: 0.2547049\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1335582\n",
      "\tspeed: 0.0942s/iter; left time: 47.6779s\n",
      "\titers: 200, epoch: 6 | loss: 0.1262666\n",
      "\tspeed: 0.0461s/iter; left time: 18.7235s\n",
      "\titers: 300, epoch: 6 | loss: 0.1086114\n",
      "\tspeed: 0.0447s/iter; left time: 13.6787s\n",
      "\titers: 400, epoch: 6 | loss: 0.0935013\n",
      "\tspeed: 0.0453s/iter; left time: 9.3253s\n",
      "\titers: 500, epoch: 6 | loss: 0.1508603\n",
      "\tspeed: 0.0450s/iter; left time: 4.7722s\n",
      "\titers: 600, epoch: 6 | loss: 0.1085182\n",
      "\tspeed: 0.0445s/iter; left time: 0.2669s\n",
      "Epoch: 6 cost time: 27.30798029899597\n",
      "Epoch: 6, Steps: 605 | Train Loss: 0.1391254 Vali Loss: 0.3258884 Test Loss: 0.2570670\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "Test cost time: 2.6571s\n",
      "test shape: (150, 32, 6, 1) (150, 32, 6, 1)\n",
      "test shape: (4800, 6, 1) (4800, 6, 1)\n",
      "mse:0.2499544769525528, mae:0.3219849169254303\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1711.6319580078125\n",
      "MAE:  26.64466667175293\n",
      "RMSE: 41.37187576293945\n",
      "MAPE: 0.33616167306900024\n",
      "MSPE: 0.4974191188812256\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24299\n",
      "[DEBUG] Original dataset length: 24299\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19377\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3255\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "\titers: 100, epoch: 1 | loss: 0.3526778\n",
      "\tspeed: 0.0451s/iter; left time: 159.2603s\n",
      "\titers: 200, epoch: 1 | loss: 0.3649695\n",
      "\tspeed: 0.0454s/iter; left time: 155.6670s\n",
      "\titers: 300, epoch: 1 | loss: 0.2235704\n",
      "\tspeed: 0.0455s/iter; left time: 151.4926s\n",
      "\titers: 400, epoch: 1 | loss: 0.2800680\n",
      "\tspeed: 0.0465s/iter; left time: 150.2745s\n",
      "\titers: 500, epoch: 1 | loss: 0.2079461\n",
      "\tspeed: 0.0445s/iter; left time: 139.3114s\n",
      "\titers: 600, epoch: 1 | loss: 0.1799051\n",
      "\tspeed: 0.0454s/iter; left time: 137.4897s\n",
      "Epoch: 1 cost time: 27.480598211288452\n",
      "Epoch: 1, Steps: 605 | Train Loss: 0.2882375 Vali Loss: 0.3370455 Test Loss: 0.2944346\n",
      "Validation loss decreased (inf --> 0.337045).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1882566\n",
      "\tspeed: 0.0957s/iter; left time: 279.9391s\n",
      "\titers: 200, epoch: 2 | loss: 0.1807727\n",
      "\tspeed: 0.0454s/iter; left time: 128.4190s\n",
      "\titers: 300, epoch: 2 | loss: 0.1559089\n",
      "\tspeed: 0.0460s/iter; left time: 125.4772s\n",
      "\titers: 400, epoch: 2 | loss: 0.1354786\n",
      "\tspeed: 0.0451s/iter; left time: 118.4239s\n",
      "\titers: 500, epoch: 2 | loss: 0.1417190\n",
      "\tspeed: 0.0450s/iter; left time: 113.6212s\n",
      "\titers: 600, epoch: 2 | loss: 0.1008510\n",
      "\tspeed: 0.0454s/iter; left time: 110.2585s\n",
      "Epoch: 2 cost time: 27.50469732284546\n",
      "Epoch: 2, Steps: 605 | Train Loss: 0.1961357 Vali Loss: 0.3335454 Test Loss: 0.2677340\n",
      "Validation loss decreased (0.337045 --> 0.333545).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0926799\n",
      "\tspeed: 0.0953s/iter; left time: 221.2744s\n",
      "\titers: 200, epoch: 3 | loss: 0.1145839\n",
      "\tspeed: 0.0453s/iter; left time: 100.6343s\n",
      "\titers: 300, epoch: 3 | loss: 0.2861308\n",
      "\tspeed: 0.0450s/iter; left time: 95.4861s\n",
      "\titers: 400, epoch: 3 | loss: 0.1630567\n",
      "\tspeed: 0.0449s/iter; left time: 90.7831s\n",
      "\titers: 500, epoch: 3 | loss: 0.1155804\n",
      "\tspeed: 0.0447s/iter; left time: 85.8300s\n",
      "\titers: 600, epoch: 3 | loss: 0.2146022\n",
      "\tspeed: 0.0448s/iter; left time: 81.6670s\n",
      "Epoch: 3 cost time: 27.209857940673828\n",
      "Epoch: 3, Steps: 605 | Train Loss: 0.1663221 Vali Loss: 0.3185535 Test Loss: 0.2577396\n",
      "Validation loss decreased (0.333545 --> 0.318554).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1241129\n",
      "\tspeed: 0.0953s/iter; left time: 163.5188s\n",
      "\titers: 200, epoch: 4 | loss: 0.1488439\n",
      "\tspeed: 0.0453s/iter; left time: 73.2315s\n",
      "\titers: 300, epoch: 4 | loss: 0.1689079\n",
      "\tspeed: 0.0452s/iter; left time: 68.5418s\n",
      "\titers: 400, epoch: 4 | loss: 0.1549513\n",
      "\tspeed: 0.0446s/iter; left time: 63.2116s\n",
      "\titers: 500, epoch: 4 | loss: 0.1672726\n",
      "\tspeed: 0.0448s/iter; left time: 58.9897s\n",
      "\titers: 600, epoch: 4 | loss: 0.1725010\n",
      "\tspeed: 0.0448s/iter; left time: 54.5360s\n",
      "Epoch: 4 cost time: 27.226154565811157\n",
      "Epoch: 4, Steps: 605 | Train Loss: 0.1534790 Vali Loss: 0.3191174 Test Loss: 0.2490041\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1467252\n",
      "\tspeed: 0.0937s/iter; left time: 104.0466s\n",
      "\titers: 200, epoch: 5 | loss: 0.1787222\n",
      "\tspeed: 0.0453s/iter; left time: 45.7846s\n",
      "\titers: 300, epoch: 5 | loss: 0.1244202\n",
      "\tspeed: 0.0455s/iter; left time: 41.4229s\n",
      "\titers: 400, epoch: 5 | loss: 0.1162108\n",
      "\tspeed: 0.0444s/iter; left time: 36.0264s\n",
      "\titers: 500, epoch: 5 | loss: 0.1081113\n",
      "\tspeed: 0.0444s/iter; left time: 31.5913s\n",
      "\titers: 600, epoch: 5 | loss: 0.1337187\n",
      "\tspeed: 0.0467s/iter; left time: 28.5481s\n",
      "Epoch: 5 cost time: 27.393564701080322\n",
      "Epoch: 5, Steps: 605 | Train Loss: 0.1452046 Vali Loss: 0.3258006 Test Loss: 0.2540103\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2358718\n",
      "\tspeed: 0.0935s/iter; left time: 47.3020s\n",
      "\titers: 200, epoch: 6 | loss: 0.1373126\n",
      "\tspeed: 0.0451s/iter; left time: 18.3178s\n",
      "\titers: 300, epoch: 6 | loss: 0.1305677\n",
      "\tspeed: 0.0450s/iter; left time: 13.7843s\n",
      "\titers: 400, epoch: 6 | loss: 0.2796135\n",
      "\tspeed: 0.0446s/iter; left time: 9.1837s\n",
      "\titers: 500, epoch: 6 | loss: 0.1584738\n",
      "\tspeed: 0.0445s/iter; left time: 4.7160s\n",
      "\titers: 600, epoch: 6 | loss: 0.1110494\n",
      "\tspeed: 0.0455s/iter; left time: 0.2730s\n",
      "Epoch: 6 cost time: 27.20852541923523\n",
      "Epoch: 6, Steps: 605 | Train Loss: 0.1411290 Vali Loss: 0.3290641 Test Loss: 0.2529857\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "Test cost time: 2.7341s\n",
      "test shape: (150, 32, 6, 1) (150, 32, 6, 1)\n",
      "test shape: (4800, 6, 1) (4800, 6, 1)\n",
      "mse:0.2589043080806732, mae:0.33648204803466797\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1772.9183349609375\n",
      "MAE:  27.844322204589844\n",
      "RMSE: 42.10603713989258\n",
      "MAPE: 0.3970957398414612\n",
      "MSPE: 0.7859569191932678\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24299\n",
      "[DEBUG] Original dataset length: 24299\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19377\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3255\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "\titers: 100, epoch: 1 | loss: 0.3352110\n",
      "\tspeed: 0.0463s/iter; left time: 163.6540s\n",
      "\titers: 200, epoch: 1 | loss: 0.2302520\n",
      "\tspeed: 0.0448s/iter; left time: 153.8578s\n",
      "\titers: 300, epoch: 1 | loss: 0.2613030\n",
      "\tspeed: 0.0447s/iter; left time: 149.0243s\n",
      "\titers: 400, epoch: 1 | loss: 0.3102440\n",
      "\tspeed: 0.0443s/iter; left time: 143.0174s\n",
      "\titers: 500, epoch: 1 | loss: 0.2897158\n",
      "\tspeed: 0.0466s/iter; left time: 145.9141s\n",
      "\titers: 600, epoch: 1 | loss: 0.2651628\n",
      "\tspeed: 0.0453s/iter; left time: 137.1846s\n",
      "Epoch: 1 cost time: 27.455227613449097\n",
      "Epoch: 1, Steps: 605 | Train Loss: 0.2991514 Vali Loss: 0.3307997 Test Loss: 0.2662659\n",
      "Validation loss decreased (inf --> 0.330800).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1691494\n",
      "\tspeed: 0.0947s/iter; left time: 277.1685s\n",
      "\titers: 200, epoch: 2 | loss: 0.1380339\n",
      "\tspeed: 0.0443s/iter; left time: 125.2519s\n",
      "\titers: 300, epoch: 2 | loss: 0.2496153\n",
      "\tspeed: 0.0443s/iter; left time: 120.8768s\n",
      "\titers: 400, epoch: 2 | loss: 0.2829601\n",
      "\tspeed: 0.0446s/iter; left time: 117.0208s\n",
      "\titers: 500, epoch: 2 | loss: 0.1495031\n",
      "\tspeed: 0.0460s/iter; left time: 116.2267s\n",
      "\titers: 600, epoch: 2 | loss: 0.2282383\n",
      "\tspeed: 0.0451s/iter; left time: 109.4593s\n",
      "Epoch: 2 cost time: 27.214818239212036\n",
      "Epoch: 2, Steps: 605 | Train Loss: 0.1983571 Vali Loss: 0.3339989 Test Loss: 0.2701737\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2051028\n",
      "\tspeed: 0.0944s/iter; left time: 219.1710s\n",
      "\titers: 200, epoch: 3 | loss: 0.1960232\n",
      "\tspeed: 0.0444s/iter; left time: 98.5958s\n",
      "\titers: 300, epoch: 3 | loss: 0.2050721\n",
      "\tspeed: 0.0445s/iter; left time: 94.2906s\n",
      "\titers: 400, epoch: 3 | loss: 0.1511521\n",
      "\tspeed: 0.0455s/iter; left time: 92.0132s\n",
      "\titers: 500, epoch: 3 | loss: 0.1740494\n",
      "\tspeed: 0.0456s/iter; left time: 87.6474s\n",
      "\titers: 600, epoch: 3 | loss: 0.1250066\n",
      "\tspeed: 0.0452s/iter; left time: 82.3314s\n",
      "Epoch: 3 cost time: 27.35360074043274\n",
      "Epoch: 3, Steps: 605 | Train Loss: 0.1678025 Vali Loss: 0.3219097 Test Loss: 0.2581487\n",
      "Validation loss decreased (0.330800 --> 0.321910).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0882398\n",
      "\tspeed: 0.0959s/iter; left time: 164.6003s\n",
      "\titers: 200, epoch: 4 | loss: 0.1399671\n",
      "\tspeed: 0.0446s/iter; left time: 72.0908s\n",
      "\titers: 300, epoch: 4 | loss: 0.1197699\n",
      "\tspeed: 0.0444s/iter; left time: 67.3020s\n",
      "\titers: 400, epoch: 4 | loss: 0.2254175\n",
      "\tspeed: 0.0459s/iter; left time: 64.9895s\n",
      "\titers: 500, epoch: 4 | loss: 0.1997654\n",
      "\tspeed: 0.0452s/iter; left time: 59.4847s\n",
      "\titers: 600, epoch: 4 | loss: 0.1798957\n",
      "\tspeed: 0.0446s/iter; left time: 54.2727s\n",
      "Epoch: 4 cost time: 27.234737634658813\n",
      "Epoch: 4, Steps: 605 | Train Loss: 0.1536028 Vali Loss: 0.3268804 Test Loss: 0.2489832\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1484982\n",
      "\tspeed: 0.0944s/iter; left time: 104.8905s\n",
      "\titers: 200, epoch: 5 | loss: 0.1381795\n",
      "\tspeed: 0.0444s/iter; left time: 44.8808s\n",
      "\titers: 300, epoch: 5 | loss: 0.0966402\n",
      "\tspeed: 0.0445s/iter; left time: 40.4961s\n",
      "\titers: 400, epoch: 5 | loss: 0.1652716\n",
      "\tspeed: 0.0454s/iter; left time: 36.8436s\n",
      "\titers: 500, epoch: 5 | loss: 0.1801379\n",
      "\tspeed: 0.0456s/iter; left time: 32.4496s\n",
      "\titers: 600, epoch: 5 | loss: 0.1592477\n",
      "\tspeed: 0.0453s/iter; left time: 27.7012s\n",
      "Epoch: 5 cost time: 27.23875093460083\n",
      "Epoch: 5, Steps: 605 | Train Loss: 0.1440454 Vali Loss: 0.3319702 Test Loss: 0.2532677\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1055245\n",
      "\tspeed: 0.0947s/iter; left time: 47.9229s\n",
      "\titers: 200, epoch: 6 | loss: 0.2452242\n",
      "\tspeed: 0.0451s/iter; left time: 18.3199s\n",
      "\titers: 300, epoch: 6 | loss: 0.1013545\n",
      "\tspeed: 0.0458s/iter; left time: 14.0104s\n",
      "\titers: 400, epoch: 6 | loss: 0.1107864\n",
      "\tspeed: 0.0451s/iter; left time: 9.2993s\n",
      "\titers: 500, epoch: 6 | loss: 0.1687116\n",
      "\tspeed: 0.0443s/iter; left time: 4.6977s\n",
      "\titers: 600, epoch: 6 | loss: 0.1395633\n",
      "\tspeed: 0.0450s/iter; left time: 0.2702s\n",
      "Epoch: 6 cost time: 27.266362190246582\n",
      "Epoch: 6, Steps: 605 | Train Loss: 0.1393348 Vali Loss: 0.3322251 Test Loss: 0.2528682\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "Test cost time: 2.7310s\n",
      "test shape: (150, 32, 6, 1) (150, 32, 6, 1)\n",
      "test shape: (4800, 6, 1) (4800, 6, 1)\n",
      "mse:0.2555217742919922, mae:0.3512125313282013\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1749.755615234375\n",
      "MAE:  29.06328773498535\n",
      "RMSE: 41.830081939697266\n",
      "MAPE: 0.46158909797668457\n",
      "MSPE: 1.0409454107284546\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24299\n",
      "[DEBUG] Original dataset length: 24299\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19377\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3255\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "\titers: 100, epoch: 1 | loss: 0.2444936\n",
      "\tspeed: 0.0445s/iter; left time: 157.1529s\n",
      "\titers: 200, epoch: 1 | loss: 0.2886802\n",
      "\tspeed: 0.0453s/iter; left time: 155.4898s\n",
      "\titers: 300, epoch: 1 | loss: 0.1967928\n",
      "\tspeed: 0.0458s/iter; left time: 152.4098s\n",
      "\titers: 400, epoch: 1 | loss: 0.2048725\n",
      "\tspeed: 0.0446s/iter; left time: 144.0995s\n",
      "\titers: 500, epoch: 1 | loss: 0.2156819\n",
      "\tspeed: 0.0445s/iter; left time: 139.3247s\n",
      "\titers: 600, epoch: 1 | loss: 0.2485496\n",
      "\tspeed: 0.0454s/iter; left time: 137.6087s\n",
      "Epoch: 1 cost time: 27.26579713821411\n",
      "Epoch: 1, Steps: 605 | Train Loss: 0.2895597 Vali Loss: 0.3260750 Test Loss: 0.2666872\n",
      "Validation loss decreased (inf --> 0.326075).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2093935\n",
      "\tspeed: 0.0939s/iter; left time: 274.7414s\n",
      "\titers: 200, epoch: 2 | loss: 0.1343881\n",
      "\tspeed: 0.0454s/iter; left time: 128.3605s\n",
      "\titers: 300, epoch: 2 | loss: 0.2341161\n",
      "\tspeed: 0.0449s/iter; left time: 122.4410s\n",
      "\titers: 400, epoch: 2 | loss: 0.1380127\n",
      "\tspeed: 0.0450s/iter; left time: 118.2604s\n",
      "\titers: 500, epoch: 2 | loss: 0.1793060\n",
      "\tspeed: 0.0441s/iter; left time: 111.4984s\n",
      "\titers: 600, epoch: 2 | loss: 0.2336235\n",
      "\tspeed: 0.0449s/iter; left time: 109.0357s\n",
      "Epoch: 2 cost time: 27.165679931640625\n",
      "Epoch: 2, Steps: 605 | Train Loss: 0.1990543 Vali Loss: 0.3530603 Test Loss: 0.2855779\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2427450\n",
      "\tspeed: 0.0932s/iter; left time: 216.3186s\n",
      "\titers: 200, epoch: 3 | loss: 0.1584239\n",
      "\tspeed: 0.0461s/iter; left time: 102.3639s\n",
      "\titers: 300, epoch: 3 | loss: 0.1769095\n",
      "\tspeed: 0.0444s/iter; left time: 94.2239s\n",
      "\titers: 400, epoch: 3 | loss: 0.1607113\n",
      "\tspeed: 0.0446s/iter; left time: 90.0890s\n",
      "\titers: 500, epoch: 3 | loss: 0.1795007\n",
      "\tspeed: 0.0451s/iter; left time: 86.5468s\n",
      "\titers: 600, epoch: 3 | loss: 0.2487166\n",
      "\tspeed: 0.0448s/iter; left time: 81.6128s\n",
      "Epoch: 3 cost time: 27.222835063934326\n",
      "Epoch: 3, Steps: 605 | Train Loss: 0.1690354 Vali Loss: 0.3260676 Test Loss: 0.2626340\n",
      "Validation loss decreased (0.326075 --> 0.326068).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1430045\n",
      "\tspeed: 0.0946s/iter; left time: 162.2634s\n",
      "\titers: 200, epoch: 4 | loss: 0.1326330\n",
      "\tspeed: 0.0455s/iter; left time: 73.5046s\n",
      "\titers: 300, epoch: 4 | loss: 0.1851278\n",
      "\tspeed: 0.0448s/iter; left time: 67.8514s\n",
      "\titers: 400, epoch: 4 | loss: 0.1940961\n",
      "\tspeed: 0.0448s/iter; left time: 63.4695s\n",
      "\titers: 500, epoch: 4 | loss: 0.1343934\n",
      "\tspeed: 0.0456s/iter; left time: 60.0456s\n",
      "\titers: 600, epoch: 4 | loss: 0.1769715\n",
      "\tspeed: 0.0445s/iter; left time: 54.1147s\n",
      "Epoch: 4 cost time: 27.211086988449097\n",
      "Epoch: 4, Steps: 605 | Train Loss: 0.1559010 Vali Loss: 0.3408225 Test Loss: 0.2702345\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1349442\n",
      "\tspeed: 0.0939s/iter; left time: 104.2830s\n",
      "\titers: 200, epoch: 5 | loss: 0.2137940\n",
      "\tspeed: 0.0444s/iter; left time: 44.9217s\n",
      "\titers: 300, epoch: 5 | loss: 0.1061476\n",
      "\tspeed: 0.0447s/iter; left time: 40.7053s\n",
      "\titers: 400, epoch: 5 | loss: 0.1650436\n",
      "\tspeed: 0.0446s/iter; left time: 36.2023s\n",
      "\titers: 500, epoch: 5 | loss: 0.1374962\n",
      "\tspeed: 0.0458s/iter; left time: 32.5931s\n",
      "\titers: 600, epoch: 5 | loss: 0.1621935\n",
      "\tspeed: 0.0448s/iter; left time: 27.4012s\n",
      "Epoch: 5 cost time: 27.221896171569824\n",
      "Epoch: 5, Steps: 605 | Train Loss: 0.1471475 Vali Loss: 0.3328327 Test Loss: 0.2653012\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1850522\n",
      "\tspeed: 0.0937s/iter; left time: 47.3928s\n",
      "\titers: 200, epoch: 6 | loss: 0.1804969\n",
      "\tspeed: 0.0450s/iter; left time: 18.2670s\n",
      "\titers: 300, epoch: 6 | loss: 0.1209239\n",
      "\tspeed: 0.0448s/iter; left time: 13.6937s\n",
      "\titers: 400, epoch: 6 | loss: 0.0895312\n",
      "\tspeed: 0.0454s/iter; left time: 9.3482s\n",
      "\titers: 500, epoch: 6 | loss: 0.1107160\n",
      "\tspeed: 0.0450s/iter; left time: 4.7692s\n",
      "\titers: 600, epoch: 6 | loss: 0.2105376\n",
      "\tspeed: 0.0448s/iter; left time: 0.2690s\n",
      "Epoch: 6 cost time: 27.247360229492188\n",
      "Epoch: 6, Steps: 605 | Train Loss: 0.1420818 Vali Loss: 0.3310109 Test Loss: 0.2633401\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "Test cost time: 2.6218s\n",
      "test shape: (150, 32, 6, 1) (150, 32, 6, 1)\n",
      "test shape: (4800, 6, 1) (4800, 6, 1)\n",
      "mse:0.2621626555919647, mae:0.3361375033855438\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1795.2308349609375\n",
      "MAE:  27.815811157226562\n",
      "RMSE: 42.37016296386719\n",
      "MAPE: 0.40183261036872864\n",
      "MSPE: 0.8284310698509216\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24299\n",
      "[DEBUG] Original dataset length: 24299\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19377\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3255\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "\titers: 100, epoch: 1 | loss: 0.2743800\n",
      "\tspeed: 0.0437s/iter; left time: 154.1630s\n",
      "\titers: 200, epoch: 1 | loss: 0.1424820\n",
      "\tspeed: 0.0446s/iter; left time: 153.0692s\n",
      "\titers: 300, epoch: 1 | loss: 0.3647891\n",
      "\tspeed: 0.0462s/iter; left time: 153.7462s\n",
      "\titers: 400, epoch: 1 | loss: 0.1929086\n",
      "\tspeed: 0.0454s/iter; left time: 146.6878s\n",
      "\titers: 500, epoch: 1 | loss: 0.2667931\n",
      "\tspeed: 0.0454s/iter; left time: 142.1500s\n",
      "\titers: 600, epoch: 1 | loss: 0.1770555\n",
      "\tspeed: 0.0452s/iter; left time: 137.0530s\n",
      "Epoch: 1 cost time: 27.297075271606445\n",
      "Epoch: 1, Steps: 605 | Train Loss: 0.2925249 Vali Loss: 0.3253384 Test Loss: 0.2848671\n",
      "Validation loss decreased (inf --> 0.325338).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1512059\n",
      "\tspeed: 0.0961s/iter; left time: 281.1647s\n",
      "\titers: 200, epoch: 2 | loss: 0.1910280\n",
      "\tspeed: 0.0452s/iter; left time: 127.6575s\n",
      "\titers: 300, epoch: 2 | loss: 0.1979732\n",
      "\tspeed: 0.0452s/iter; left time: 123.2893s\n",
      "\titers: 400, epoch: 2 | loss: 0.1402903\n",
      "\tspeed: 0.0444s/iter; left time: 116.6661s\n",
      "\titers: 500, epoch: 2 | loss: 0.1396793\n",
      "\tspeed: 0.0448s/iter; left time: 113.0667s\n",
      "\titers: 600, epoch: 2 | loss: 0.1562613\n",
      "\tspeed: 0.0451s/iter; left time: 109.4571s\n",
      "Epoch: 2 cost time: 27.205952167510986\n",
      "Epoch: 2, Steps: 605 | Train Loss: 0.1986309 Vali Loss: 0.3085596 Test Loss: 0.2527148\n",
      "Validation loss decreased (0.325338 --> 0.308560).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1926406\n",
      "\tspeed: 0.0938s/iter; left time: 217.7121s\n",
      "\titers: 200, epoch: 3 | loss: 0.3027870\n",
      "\tspeed: 0.0451s/iter; left time: 100.2403s\n",
      "\titers: 300, epoch: 3 | loss: 0.1193113\n",
      "\tspeed: 0.0453s/iter; left time: 96.1347s\n",
      "\titers: 400, epoch: 3 | loss: 0.1410815\n",
      "\tspeed: 0.0449s/iter; left time: 90.7930s\n",
      "\titers: 500, epoch: 3 | loss: 0.2473280\n",
      "\tspeed: 0.0457s/iter; left time: 87.7805s\n",
      "\titers: 600, epoch: 3 | loss: 0.1431266\n",
      "\tspeed: 0.0461s/iter; left time: 83.9027s\n",
      "Epoch: 3 cost time: 27.414229154586792\n",
      "Epoch: 3, Steps: 605 | Train Loss: 0.1673268 Vali Loss: 0.3275316 Test Loss: 0.2615989\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1633880\n",
      "\tspeed: 0.0933s/iter; left time: 160.0945s\n",
      "\titers: 200, epoch: 4 | loss: 0.2627428\n",
      "\tspeed: 0.0457s/iter; left time: 73.7884s\n",
      "\titers: 300, epoch: 4 | loss: 0.1545046\n",
      "\tspeed: 0.0449s/iter; left time: 68.0840s\n",
      "\titers: 400, epoch: 4 | loss: 0.2204980\n",
      "\tspeed: 0.0452s/iter; left time: 64.0253s\n",
      "\titers: 500, epoch: 4 | loss: 0.1433716\n",
      "\tspeed: 0.0456s/iter; left time: 59.9549s\n",
      "\titers: 600, epoch: 4 | loss: 0.1525218\n",
      "\tspeed: 0.0461s/iter; left time: 56.0313s\n",
      "Epoch: 4 cost time: 27.460906982421875\n",
      "Epoch: 4, Steps: 605 | Train Loss: 0.1543064 Vali Loss: 0.3150260 Test Loss: 0.2576281\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1602184\n",
      "\tspeed: 0.0935s/iter; left time: 103.9130s\n",
      "\titers: 200, epoch: 5 | loss: 0.1344819\n",
      "\tspeed: 0.0456s/iter; left time: 46.1102s\n",
      "\titers: 300, epoch: 5 | loss: 0.1537964\n",
      "\tspeed: 0.0460s/iter; left time: 41.8677s\n",
      "\titers: 400, epoch: 5 | loss: 0.1059979\n",
      "\tspeed: 0.0449s/iter; left time: 36.3907s\n",
      "\titers: 500, epoch: 5 | loss: 0.1824389\n",
      "\tspeed: 0.0460s/iter; left time: 32.7287s\n",
      "\titers: 600, epoch: 5 | loss: 0.1348102\n",
      "\tspeed: 0.0451s/iter; left time: 27.5361s\n",
      "Epoch: 5 cost time: 27.458375453948975\n",
      "Epoch: 5, Steps: 605 | Train Loss: 0.1468033 Vali Loss: 0.3118684 Test Loss: 0.2587134\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "Test cost time: 2.6705s\n",
      "test shape: (150, 32, 6, 1) (150, 32, 6, 1)\n",
      "test shape: (4800, 6, 1) (4800, 6, 1)\n",
      "mse:0.2535964548587799, mae:0.332745224237442\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1736.5716552734375\n",
      "MAE:  27.53509521484375\n",
      "RMSE: 41.67219161987305\n",
      "MAPE: 0.3717930018901825\n",
      "MSPE: 0.7125029563903809\n",
      ">>>>>>>Running time saved<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Running seq_len=264\n",
      "Args in experiment:\n",
      "Namespace(model='informer', data='traffic_full', root_path='../', data_path='traffic_full.csv', features='S', target='flow', freq='h', checkpoints='./checkpoints/', seq_len=264, label_len=24, pred_len=6, enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=2, d_layers=1, s_layers=[3, 2, 1], d_ff=2048, factor=5, padding=0, distil=True, dropout=0.05, attn='prob', embed='timeF', activation='gelu', output_attention=False, do_predict=False, mix=True, cols=None, num_workers=0, itr=10, train_epochs=6, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, inverse=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', detail_freq='h')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl264_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24275\n",
      "[DEBUG] Original dataset length: 24275\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18969\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3231\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4658\n",
      "\titers: 100, epoch: 1 | loss: 0.4306395\n",
      "\tspeed: 0.0609s/iter; left time: 210.1296s\n",
      "\titers: 200, epoch: 1 | loss: 0.4636232\n",
      "\tspeed: 0.0482s/iter; left time: 161.5904s\n",
      "\titers: 300, epoch: 1 | loss: 0.2210943\n",
      "\tspeed: 0.0484s/iter; left time: 157.4097s\n",
      "\titers: 400, epoch: 1 | loss: 0.1962540\n",
      "\tspeed: 0.0478s/iter; left time: 150.7725s\n",
      "\titers: 500, epoch: 1 | loss: 0.1783828\n",
      "\tspeed: 0.0477s/iter; left time: 145.5300s\n",
      "Epoch: 1 cost time: 29.133559226989746\n",
      "Epoch: 1, Steps: 592 | Train Loss: 0.3062283 Vali Loss: 0.4390837 Test Loss: 0.3591432\n",
      "Validation loss decreased (inf --> 0.439084).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1169467\n",
      "\tspeed: 0.1445s/iter; left time: 413.4559s\n",
      "\titers: 200, epoch: 2 | loss: 0.1278029\n",
      "\tspeed: 0.0484s/iter; left time: 133.6702s\n",
      "\titers: 300, epoch: 2 | loss: 0.1556418\n",
      "\tspeed: 0.0478s/iter; left time: 127.2757s\n",
      "\titers: 400, epoch: 2 | loss: 0.1647757\n",
      "\tspeed: 0.0477s/iter; left time: 122.0400s\n",
      "\titers: 500, epoch: 2 | loss: 0.2149354\n",
      "\tspeed: 0.0483s/iter; left time: 118.8320s\n",
      "Epoch: 2 cost time: 28.52811598777771\n",
      "Epoch: 2, Steps: 592 | Train Loss: 0.2030981 Vali Loss: 0.3488366 Test Loss: 0.2901009\n",
      "Validation loss decreased (0.439084 --> 0.348837).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1143168\n",
      "\tspeed: 0.1452s/iter; left time: 329.4509s\n",
      "\titers: 200, epoch: 3 | loss: 0.1397138\n",
      "\tspeed: 0.0486s/iter; left time: 105.3629s\n",
      "\titers: 300, epoch: 3 | loss: 0.1509393\n",
      "\tspeed: 0.0478s/iter; left time: 98.8304s\n",
      "\titers: 400, epoch: 3 | loss: 0.2028084\n",
      "\tspeed: 0.0481s/iter; left time: 94.7584s\n",
      "\titers: 500, epoch: 3 | loss: 0.1768380\n",
      "\tspeed: 0.0483s/iter; left time: 90.3408s\n",
      "Epoch: 3 cost time: 28.58752417564392\n",
      "Epoch: 3, Steps: 592 | Train Loss: 0.1724957 Vali Loss: 0.3244339 Test Loss: 0.2709692\n",
      "Validation loss decreased (0.348837 --> 0.324434).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1344430\n",
      "\tspeed: 0.1432s/iter; left time: 240.1799s\n",
      "\titers: 200, epoch: 4 | loss: 0.0958128\n",
      "\tspeed: 0.0477s/iter; left time: 75.2085s\n",
      "\titers: 300, epoch: 4 | loss: 0.1067410\n",
      "\tspeed: 0.0480s/iter; left time: 70.8606s\n",
      "\titers: 400, epoch: 4 | loss: 0.0968442\n",
      "\tspeed: 0.0481s/iter; left time: 66.2165s\n",
      "\titers: 500, epoch: 4 | loss: 0.2000872\n",
      "\tspeed: 0.0481s/iter; left time: 61.3613s\n",
      "Epoch: 4 cost time: 28.385226726531982\n",
      "Epoch: 4, Steps: 592 | Train Loss: 0.1564530 Vali Loss: 0.3406805 Test Loss: 0.2663288\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1131562\n",
      "\tspeed: 0.1430s/iter; left time: 155.2003s\n",
      "\titers: 200, epoch: 5 | loss: 0.1340250\n",
      "\tspeed: 0.0476s/iter; left time: 46.8874s\n",
      "\titers: 300, epoch: 5 | loss: 0.1407220\n",
      "\tspeed: 0.0475s/iter; left time: 41.9976s\n",
      "\titers: 400, epoch: 5 | loss: 0.1576377\n",
      "\tspeed: 0.0495s/iter; left time: 38.8800s\n",
      "\titers: 500, epoch: 5 | loss: 0.1002384\n",
      "\tspeed: 0.0485s/iter; left time: 33.2148s\n",
      "Epoch: 5 cost time: 28.558305978775024\n",
      "Epoch: 5, Steps: 592 | Train Loss: 0.1487092 Vali Loss: 0.3307880 Test Loss: 0.2568153\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1225346\n",
      "\tspeed: 0.1425s/iter; left time: 70.2636s\n",
      "\titers: 200, epoch: 6 | loss: 0.2481631\n",
      "\tspeed: 0.0480s/iter; left time: 18.8548s\n",
      "\titers: 300, epoch: 6 | loss: 0.1261239\n",
      "\tspeed: 0.0486s/iter; left time: 14.2464s\n",
      "\titers: 400, epoch: 6 | loss: 0.1303389\n",
      "\tspeed: 0.0477s/iter; left time: 9.2094s\n",
      "\titers: 500, epoch: 6 | loss: 0.0981490\n",
      "\tspeed: 0.0479s/iter; left time: 4.4523s\n",
      "Epoch: 6 cost time: 28.44821786880493\n",
      "Epoch: 6, Steps: 592 | Train Loss: 0.1436069 Vali Loss: 0.3318109 Test Loss: 0.2603302\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl264_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4658\n",
      "Test cost time: 2.9620s\n",
      "test shape: (145, 32, 6, 1) (145, 32, 6, 1)\n",
      "test shape: (4640, 6, 1) (4640, 6, 1)\n",
      "mse:0.26877492666244507, mae:0.3392990231513977\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl264_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1840.5103759765625\n",
      "MAE:  28.07743263244629\n",
      "RMSE: 42.90116882324219\n",
      "MAPE: 0.38646194338798523\n",
      "MSPE: 0.675155520439148\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl264_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24275\n",
      "[DEBUG] Original dataset length: 24275\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18969\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3231\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4658\n",
      "\titers: 100, epoch: 1 | loss: 0.2474291\n",
      "\tspeed: 0.0477s/iter; left time: 164.6356s\n",
      "\titers: 200, epoch: 1 | loss: 0.3324211\n",
      "\tspeed: 0.0483s/iter; left time: 161.9056s\n",
      "\titers: 300, epoch: 1 | loss: 0.2283477\n",
      "\tspeed: 0.0478s/iter; left time: 155.3638s\n",
      "\titers: 400, epoch: 1 | loss: 0.2562098\n",
      "\tspeed: 0.0481s/iter; left time: 151.7547s\n",
      "\titers: 500, epoch: 1 | loss: 0.1543906\n",
      "\tspeed: 0.0488s/iter; left time: 148.9258s\n",
      "Epoch: 1 cost time: 28.48798131942749\n",
      "Epoch: 1, Steps: 592 | Train Loss: 0.2919944 Vali Loss: 0.3298880 Test Loss: 0.2818691\n",
      "Validation loss decreased (inf --> 0.329888).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2792772\n",
      "\tspeed: 0.1439s/iter; left time: 411.6612s\n",
      "\titers: 200, epoch: 2 | loss: 0.2789509\n",
      "\tspeed: 0.0477s/iter; left time: 131.6815s\n",
      "\titers: 300, epoch: 2 | loss: 0.2257012\n",
      "\tspeed: 0.0486s/iter; left time: 129.4133s\n",
      "\titers: 400, epoch: 2 | loss: 0.1908844\n",
      "\tspeed: 0.0492s/iter; left time: 126.0750s\n",
      "\titers: 500, epoch: 2 | loss: 0.1577266\n",
      "\tspeed: 0.0481s/iter; left time: 118.4340s\n",
      "Epoch: 2 cost time: 28.63974690437317\n",
      "Epoch: 2, Steps: 592 | Train Loss: 0.1991852 Vali Loss: 0.3315318 Test Loss: 0.2701449\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1629312\n",
      "\tspeed: 0.1430s/iter; left time: 324.5534s\n",
      "\titers: 200, epoch: 3 | loss: 0.2728530\n",
      "\tspeed: 0.0482s/iter; left time: 104.4561s\n",
      "\titers: 300, epoch: 3 | loss: 0.1203406\n",
      "\tspeed: 0.0479s/iter; left time: 99.1946s\n",
      "\titers: 400, epoch: 3 | loss: 0.2452630\n",
      "\tspeed: 0.0487s/iter; left time: 95.7936s\n",
      "\titers: 500, epoch: 3 | loss: 0.1691050\n",
      "\tspeed: 0.0482s/iter; left time: 90.0934s\n",
      "Epoch: 3 cost time: 28.49030351638794\n",
      "Epoch: 3, Steps: 592 | Train Loss: 0.1690470 Vali Loss: 0.3366002 Test Loss: 0.2785046\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2173315\n",
      "\tspeed: 0.1430s/iter; left time: 239.8463s\n",
      "\titers: 200, epoch: 4 | loss: 0.2009811\n",
      "\tspeed: 0.0482s/iter; left time: 75.9432s\n",
      "\titers: 300, epoch: 4 | loss: 0.1406435\n",
      "\tspeed: 0.0483s/iter; left time: 71.3402s\n",
      "\titers: 400, epoch: 4 | loss: 0.1045710\n",
      "\tspeed: 0.0480s/iter; left time: 66.1294s\n",
      "\titers: 500, epoch: 4 | loss: 0.1522595\n",
      "\tspeed: 0.0479s/iter; left time: 61.1509s\n",
      "Epoch: 4 cost time: 28.593512058258057\n",
      "Epoch: 4, Steps: 592 | Train Loss: 0.1537635 Vali Loss: 0.3370950 Test Loss: 0.2722970\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl264_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4658\n",
      "Test cost time: 2.9409s\n",
      "test shape: (145, 32, 6, 1) (145, 32, 6, 1)\n",
      "test shape: (4640, 6, 1) (4640, 6, 1)\n",
      "mse:0.2813633680343628, mae:0.35438263416290283\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl264_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1926.7132568359375\n",
      "MAE:  29.32561683654785\n",
      "RMSE: 43.89434051513672\n",
      "MAPE: 0.4326225221157074\n",
      "MSPE: 1.019912600517273\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl264_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24275\n",
      "[DEBUG] Original dataset length: 24275\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18969\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3231\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4658\n",
      "\titers: 100, epoch: 1 | loss: 0.2145619\n",
      "\tspeed: 0.0482s/iter; left time: 166.3952s\n",
      "\titers: 200, epoch: 1 | loss: 0.3094923\n",
      "\tspeed: 0.0488s/iter; left time: 163.5041s\n",
      "\titers: 300, epoch: 1 | loss: 0.1631017\n",
      "\tspeed: 0.0479s/iter; left time: 155.7971s\n",
      "\titers: 400, epoch: 1 | loss: 0.2345069\n",
      "\tspeed: 0.0481s/iter; left time: 151.5309s\n",
      "\titers: 500, epoch: 1 | loss: 0.2423766\n",
      "\tspeed: 0.0487s/iter; left time: 148.7798s\n",
      "Epoch: 1 cost time: 28.625557899475098\n",
      "Epoch: 1, Steps: 592 | Train Loss: 0.2924370 Vali Loss: 0.3458367 Test Loss: 0.2866786\n",
      "Validation loss decreased (inf --> 0.345837).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1610012\n",
      "\tspeed: 0.1437s/iter; left time: 411.1440s\n",
      "\titers: 200, epoch: 2 | loss: 0.1938104\n",
      "\tspeed: 0.0479s/iter; left time: 132.3586s\n",
      "\titers: 300, epoch: 2 | loss: 0.2936522\n",
      "\tspeed: 0.0477s/iter; left time: 126.8222s\n",
      "\titers: 400, epoch: 2 | loss: 0.1695487\n",
      "\tspeed: 0.0489s/iter; left time: 125.2886s\n",
      "\titers: 500, epoch: 2 | loss: 0.1510869\n",
      "\tspeed: 0.0482s/iter; left time: 118.5056s\n",
      "Epoch: 2 cost time: 28.524946689605713\n",
      "Epoch: 2, Steps: 592 | Train Loss: 0.1968359 Vali Loss: 0.3268798 Test Loss: 0.2703419\n",
      "Validation loss decreased (0.345837 --> 0.326880).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1793593\n",
      "\tspeed: 0.1443s/iter; left time: 327.4471s\n",
      "\titers: 200, epoch: 3 | loss: 0.2308128\n",
      "\tspeed: 0.0480s/iter; left time: 104.0972s\n",
      "\titers: 300, epoch: 3 | loss: 0.2420843\n",
      "\tspeed: 0.0491s/iter; left time: 101.6100s\n",
      "\titers: 400, epoch: 3 | loss: 0.1239342\n",
      "\tspeed: 0.0482s/iter; left time: 94.9336s\n",
      "\titers: 500, epoch: 3 | loss: 0.2173450\n",
      "\tspeed: 0.0480s/iter; left time: 89.7362s\n",
      "Epoch: 3 cost time: 28.62250566482544\n",
      "Epoch: 3, Steps: 592 | Train Loss: 0.1699812 Vali Loss: 0.3445376 Test Loss: 0.2784289\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1135305\n",
      "\tspeed: 0.1444s/iter; left time: 242.1704s\n",
      "\titers: 200, epoch: 4 | loss: 0.1097157\n",
      "\tspeed: 0.0486s/iter; left time: 76.6884s\n",
      "\titers: 300, epoch: 4 | loss: 0.1038989\n",
      "\tspeed: 0.0488s/iter; left time: 72.1435s\n",
      "\titers: 400, epoch: 4 | loss: 0.1769044\n",
      "\tspeed: 0.0482s/iter; left time: 66.3320s\n",
      "\titers: 500, epoch: 4 | loss: 0.1872030\n",
      "\tspeed: 0.0480s/iter; left time: 61.2699s\n",
      "Epoch: 4 cost time: 28.66681957244873\n",
      "Epoch: 4, Steps: 592 | Train Loss: 0.1539646 Vali Loss: 0.3289609 Test Loss: 0.2654064\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1629908\n",
      "\tspeed: 0.1437s/iter; left time: 155.8994s\n",
      "\titers: 200, epoch: 5 | loss: 0.2027259\n",
      "\tspeed: 0.0488s/iter; left time: 48.0658s\n",
      "\titers: 300, epoch: 5 | loss: 0.1268513\n",
      "\tspeed: 0.0483s/iter; left time: 42.7137s\n",
      "\titers: 400, epoch: 5 | loss: 0.1183283\n",
      "\tspeed: 0.0479s/iter; left time: 37.5734s\n",
      "\titers: 500, epoch: 5 | loss: 0.2195450\n",
      "\tspeed: 0.0482s/iter; left time: 33.0260s\n",
      "Epoch: 5 cost time: 28.48624610900879\n",
      "Epoch: 5, Steps: 592 | Train Loss: 0.1453150 Vali Loss: 0.3483689 Test Loss: 0.2770323\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl264_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4658\n",
      "Test cost time: 2.9699s\n",
      "test shape: (145, 32, 6, 1) (145, 32, 6, 1)\n",
      "test shape: (4640, 6, 1) (4640, 6, 1)\n",
      "mse:0.2698992192745209, mae:0.3445226848125458\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl264_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1848.209228515625\n",
      "MAE:  28.50969886779785\n",
      "RMSE: 42.99080276489258\n",
      "MAPE: 0.3558867275714874\n",
      "MSPE: 0.5540375709533691\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl264_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24275\n",
      "[DEBUG] Original dataset length: 24275\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18969\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3231\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4658\n",
      "\titers: 100, epoch: 1 | loss: 0.5122076\n",
      "\tspeed: 0.0479s/iter; left time: 165.5436s\n",
      "\titers: 200, epoch: 1 | loss: 0.3492249\n",
      "\tspeed: 0.0477s/iter; left time: 159.9224s\n",
      "\titers: 300, epoch: 1 | loss: 0.2759461\n",
      "\tspeed: 0.0478s/iter; left time: 155.6430s\n",
      "\titers: 400, epoch: 1 | loss: 0.1861750\n",
      "\tspeed: 0.0484s/iter; left time: 152.5923s\n",
      "\titers: 500, epoch: 1 | loss: 0.1903228\n",
      "\tspeed: 0.0478s/iter; left time: 146.0831s\n",
      "Epoch: 1 cost time: 28.372456312179565\n",
      "Epoch: 1, Steps: 592 | Train Loss: 0.2950817 Vali Loss: 0.3511243 Test Loss: 0.3076308\n",
      "Validation loss decreased (inf --> 0.351124).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3360974\n",
      "\tspeed: 0.1435s/iter; left time: 410.5263s\n",
      "\titers: 200, epoch: 2 | loss: 0.2317083\n",
      "\tspeed: 0.0477s/iter; left time: 131.7959s\n",
      "\titers: 300, epoch: 2 | loss: 0.1734289\n",
      "\tspeed: 0.0489s/iter; left time: 130.0278s\n",
      "\titers: 400, epoch: 2 | loss: 0.1511795\n",
      "\tspeed: 0.0479s/iter; left time: 122.6350s\n",
      "\titers: 500, epoch: 2 | loss: 0.2030900\n",
      "\tspeed: 0.0480s/iter; left time: 118.1485s\n",
      "Epoch: 2 cost time: 28.522156238555908\n",
      "Epoch: 2, Steps: 592 | Train Loss: 0.2032895 Vali Loss: 0.3307184 Test Loss: 0.2734164\n",
      "Validation loss decreased (0.351124 --> 0.330718).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1447168\n",
      "\tspeed: 0.1438s/iter; left time: 326.3711s\n",
      "\titers: 200, epoch: 3 | loss: 0.2481168\n",
      "\tspeed: 0.0487s/iter; left time: 105.7279s\n",
      "\titers: 300, epoch: 3 | loss: 0.1794223\n",
      "\tspeed: 0.0482s/iter; left time: 99.6722s\n",
      "\titers: 400, epoch: 3 | loss: 0.2239337\n",
      "\tspeed: 0.0493s/iter; left time: 97.1577s\n",
      "\titers: 500, epoch: 3 | loss: 0.1638076\n",
      "\tspeed: 0.0507s/iter; left time: 94.6972s\n",
      "Epoch: 3 cost time: 29.278634786605835\n",
      "Epoch: 3, Steps: 592 | Train Loss: 0.1709232 Vali Loss: 0.3242403 Test Loss: 0.2630625\n",
      "Validation loss decreased (0.330718 --> 0.324240).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0847816\n",
      "\tspeed: 0.1492s/iter; left time: 250.2154s\n",
      "\titers: 200, epoch: 4 | loss: 0.1426499\n",
      "\tspeed: 0.0488s/iter; left time: 76.9445s\n",
      "\titers: 300, epoch: 4 | loss: 0.1962283\n",
      "\tspeed: 0.0479s/iter; left time: 70.7093s\n",
      "\titers: 400, epoch: 4 | loss: 0.1166040\n",
      "\tspeed: 0.0484s/iter; left time: 66.7116s\n",
      "\titers: 500, epoch: 4 | loss: 0.1505607\n",
      "\tspeed: 0.0487s/iter; left time: 62.1282s\n",
      "Epoch: 4 cost time: 28.6310715675354\n",
      "Epoch: 4, Steps: 592 | Train Loss: 0.1592019 Vali Loss: 0.3319196 Test Loss: 0.2582124\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1135953\n",
      "\tspeed: 0.1423s/iter; left time: 154.3566s\n",
      "\titers: 200, epoch: 5 | loss: 0.1225982\n",
      "\tspeed: 0.0476s/iter; left time: 46.8580s\n",
      "\titers: 300, epoch: 5 | loss: 0.1198607\n",
      "\tspeed: 0.0481s/iter; left time: 42.5591s\n",
      "\titers: 400, epoch: 5 | loss: 0.1328245\n",
      "\tspeed: 0.0491s/iter; left time: 38.5400s\n",
      "\titers: 500, epoch: 5 | loss: 0.0953709\n",
      "\tspeed: 0.0478s/iter; left time: 32.7359s\n",
      "Epoch: 5 cost time: 28.540502548217773\n",
      "Epoch: 5, Steps: 592 | Train Loss: 0.1491875 Vali Loss: 0.3290828 Test Loss: 0.2572420\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1186251\n",
      "\tspeed: 0.1431s/iter; left time: 70.5261s\n",
      "\titers: 200, epoch: 6 | loss: 0.1407453\n",
      "\tspeed: 0.0480s/iter; left time: 18.8453s\n",
      "\titers: 300, epoch: 6 | loss: 0.1180855\n",
      "\tspeed: 0.0479s/iter; left time: 14.0395s\n",
      "\titers: 400, epoch: 6 | loss: 0.1590672\n",
      "\tspeed: 0.0482s/iter; left time: 9.3122s\n",
      "\titers: 500, epoch: 6 | loss: 0.2340609\n",
      "\tspeed: 0.0477s/iter; left time: 4.4378s\n",
      "Epoch: 6 cost time: 28.406505823135376\n",
      "Epoch: 6, Steps: 592 | Train Loss: 0.1448816 Vali Loss: 0.3358484 Test Loss: 0.2620377\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl264_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4658\n",
      "Test cost time: 2.9474s\n",
      "test shape: (145, 32, 6, 1) (145, 32, 6, 1)\n",
      "test shape: (4640, 6, 1) (4640, 6, 1)\n",
      "mse:0.2630928158760071, mae:0.32859447598457336\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl264_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1801.6005859375\n",
      "MAE:  27.191614151000977\n",
      "RMSE: 42.44526672363281\n",
      "MAPE: 0.3155776858329773\n",
      "MSPE: 0.3991551399230957\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl264_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24275\n",
      "[DEBUG] Original dataset length: 24275\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18969\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3231\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4658\n",
      "\titers: 100, epoch: 1 | loss: 0.2398197\n",
      "\tspeed: 0.0502s/iter; left time: 173.3017s\n",
      "\titers: 200, epoch: 1 | loss: 0.3099236\n",
      "\tspeed: 0.0490s/iter; left time: 164.3662s\n",
      "\titers: 300, epoch: 1 | loss: 0.2005686\n",
      "\tspeed: 0.0481s/iter; left time: 156.3287s\n",
      "\titers: 400, epoch: 1 | loss: 0.2934469\n",
      "\tspeed: 0.0479s/iter; left time: 151.0779s\n",
      "\titers: 500, epoch: 1 | loss: 0.2194093\n",
      "\tspeed: 0.0485s/iter; left time: 148.0813s\n",
      "Epoch: 1 cost time: 28.805402994155884\n",
      "Epoch: 1, Steps: 592 | Train Loss: 0.3087089 Vali Loss: 0.3339134 Test Loss: 0.2776230\n",
      "Validation loss decreased (inf --> 0.333913).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2780959\n",
      "\tspeed: 0.1434s/iter; left time: 410.2715s\n",
      "\titers: 200, epoch: 2 | loss: 0.1712196\n",
      "\tspeed: 0.0478s/iter; left time: 131.9904s\n",
      "\titers: 300, epoch: 2 | loss: 0.1787416\n",
      "\tspeed: 0.0475s/iter; left time: 126.5211s\n",
      "\titers: 400, epoch: 2 | loss: 0.2892125\n",
      "\tspeed: 0.0484s/iter; left time: 124.0532s\n",
      "\titers: 500, epoch: 2 | loss: 0.2073604\n",
      "\tspeed: 0.0485s/iter; left time: 119.4079s\n",
      "Epoch: 2 cost time: 28.494032621383667\n",
      "Epoch: 2, Steps: 592 | Train Loss: 0.2099880 Vali Loss: 0.3224824 Test Loss: 0.2656411\n",
      "Validation loss decreased (0.333913 --> 0.322482).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1380003\n",
      "\tspeed: 0.1436s/iter; left time: 325.9402s\n",
      "\titers: 200, epoch: 3 | loss: 0.1259315\n",
      "\tspeed: 0.0483s/iter; left time: 104.7575s\n",
      "\titers: 300, epoch: 3 | loss: 0.1109736\n",
      "\tspeed: 0.0479s/iter; left time: 99.1827s\n",
      "\titers: 400, epoch: 3 | loss: 0.2610424\n",
      "\tspeed: 0.0490s/iter; left time: 96.5304s\n",
      "\titers: 500, epoch: 3 | loss: 0.1504841\n",
      "\tspeed: 0.0479s/iter; left time: 89.5154s\n",
      "Epoch: 3 cost time: 28.609373807907104\n",
      "Epoch: 3, Steps: 592 | Train Loss: 0.1759042 Vali Loss: 0.3648201 Test Loss: 0.2963727\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1359264\n",
      "\tspeed: 0.1433s/iter; left time: 240.2984s\n",
      "\titers: 200, epoch: 4 | loss: 0.1178913\n",
      "\tspeed: 0.0479s/iter; left time: 75.5913s\n",
      "\titers: 300, epoch: 4 | loss: 0.1387924\n",
      "\tspeed: 0.0487s/iter; left time: 71.9966s\n",
      "\titers: 400, epoch: 4 | loss: 0.1434556\n",
      "\tspeed: 0.0484s/iter; left time: 66.5814s\n",
      "\titers: 500, epoch: 4 | loss: 0.2455255\n",
      "\tspeed: 0.0481s/iter; left time: 61.4006s\n",
      "Epoch: 4 cost time: 28.759352922439575\n",
      "Epoch: 4, Steps: 592 | Train Loss: 0.1595188 Vali Loss: 0.3287992 Test Loss: 0.2625940\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2438694\n",
      "\tspeed: 0.1449s/iter; left time: 157.1633s\n",
      "\titers: 200, epoch: 5 | loss: 0.0912696\n",
      "\tspeed: 0.0483s/iter; left time: 47.5309s\n",
      "\titers: 300, epoch: 5 | loss: 0.0829406\n",
      "\tspeed: 0.0482s/iter; left time: 42.6918s\n",
      "\titers: 400, epoch: 5 | loss: 0.2727914\n",
      "\tspeed: 0.0481s/iter; left time: 37.7533s\n",
      "\titers: 500, epoch: 5 | loss: 0.1229763\n",
      "\tspeed: 0.0481s/iter; left time: 32.9557s\n",
      "Epoch: 5 cost time: 28.52943444252014\n",
      "Epoch: 5, Steps: 592 | Train Loss: 0.1501977 Vali Loss: 0.3370742 Test Loss: 0.2627393\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl264_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4658\n",
      "Test cost time: 2.9445s\n",
      "test shape: (145, 32, 6, 1) (145, 32, 6, 1)\n",
      "test shape: (4640, 6, 1) (4640, 6, 1)\n",
      "mse:0.26690393686294556, mae:0.33992505073547363\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl264_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1827.697998046875\n",
      "MAE:  28.129234313964844\n",
      "RMSE: 42.751583099365234\n",
      "MAPE: 0.35695478320121765\n",
      "MSPE: 0.575295627117157\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl264_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24275\n",
      "[DEBUG] Original dataset length: 24275\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18969\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3231\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4658\n",
      "\titers: 100, epoch: 1 | loss: 0.2972556\n",
      "\tspeed: 0.0482s/iter; left time: 166.5009s\n",
      "\titers: 200, epoch: 1 | loss: 0.4008135\n",
      "\tspeed: 0.0475s/iter; left time: 159.3212s\n",
      "\titers: 300, epoch: 1 | loss: 0.2568896\n",
      "\tspeed: 0.0476s/iter; left time: 154.9801s\n",
      "\titers: 400, epoch: 1 | loss: 0.2382307\n",
      "\tspeed: 0.0490s/iter; left time: 154.4788s\n",
      "\titers: 500, epoch: 1 | loss: 0.3151295\n",
      "\tspeed: 0.0483s/iter; left time: 147.4016s\n",
      "Epoch: 1 cost time: 28.52566432952881\n",
      "Epoch: 1, Steps: 592 | Train Loss: 0.2814492 Vali Loss: 0.3297268 Test Loss: 0.2708221\n",
      "Validation loss decreased (inf --> 0.329727).  Saving model ...\n",
      "Updating learning rate to 0.0001\n"
     ]
    }
   ],
   "source": [
    "# full dataset\n",
    "# for seq_len in seq_lens:\n",
    "#     print(f\"Running seq_len={seq_len}\")\n",
    "#     !python -u main_informer.py --model informer --data traffic_full --root_path ../ --features S --seq_len {seq_len} --label_len 24 --pred_len 6 --e_layers 2 --d_layers 1 --attn prob --des 'Exp' --itr 10\n",
    "\n",
    "for seq_len in seq_lens:\n",
    "    # Calculate label_len: max(pred_len, seq_len // 3)\n",
    "    label_len = max(6, seq_len // 3)\n",
    "    \n",
    "    print(f\"Running seq_len={seq_len}, label_len={label_len}, pred_len=6\")\n",
    "    !python -u main_informer.py --model informer --data traffic_full --root_path ../ --features S --seq_len {seq_len} --label_len {label_len} --pred_len 6 --e_layers 2 --d_layers 1 --attn prob --des 'Exp' --itr 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c9fd36-f678-493b-9f93-f9cf55aad6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running seq_len=24\n",
      "Args in experiment:\n",
      "Namespace(model='informer', data='traffic_after_covid', root_path='../', data_path='traffic_after_covid.csv', features='S', target='flow', freq='h', checkpoints='./checkpoints/', seq_len=24, label_len=24, pred_len=6, enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=2, d_layers=1, s_layers=[3, 2, 1], d_ff=2048, factor=5, padding=0, distil=True, dropout=0.05, attn='prob', embed='timeF', activation='gelu', output_attention=False, do_predict=False, mix=True, cols=None, num_workers=0, itr=10, train_epochs=6, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, inverse=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', detail_freq='h')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6955\n",
      "[DEBUG] Original dataset length: 6955\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6881\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 2175\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1863\n",
      "\titers: 100, epoch: 1 | loss: 0.5162824\n",
      "\tspeed: 0.0402s/iter; left time: 47.8946s\n",
      "\titers: 200, epoch: 1 | loss: 0.3549145\n",
      "\tspeed: 0.0267s/iter; left time: 29.1501s\n",
      "Epoch: 1 cost time: 6.130732536315918\n",
      "Epoch: 1, Steps: 215 | Train Loss: 0.4387509 Vali Loss: 0.2325200 Test Loss: 0.1726395\n",
      "Validation loss decreased (inf --> 0.232520).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4277012\n",
      "\tspeed: 0.0402s/iter; left time: 39.2130s\n",
      "\titers: 200, epoch: 2 | loss: 0.1950328\n",
      "\tspeed: 0.0258s/iter; left time: 22.6234s\n",
      "Epoch: 2 cost time: 5.503387212753296\n",
      "Epoch: 2, Steps: 215 | Train Loss: 0.3410825 Vali Loss: 0.2527421 Test Loss: 0.1602899\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1778601\n",
      "\tspeed: 0.0422s/iter; left time: 32.1209s\n",
      "\titers: 200, epoch: 3 | loss: 0.2989773\n",
      "\tspeed: 0.0265s/iter; left time: 17.5192s\n",
      "Epoch: 3 cost time: 5.554285287857056\n",
      "Epoch: 3, Steps: 215 | Train Loss: 0.2944413 Vali Loss: 0.2348761 Test Loss: 0.1698185\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.4937202\n",
      "\tspeed: 0.0401s/iter; left time: 21.8958s\n",
      "\titers: 200, epoch: 4 | loss: 0.2001065\n",
      "\tspeed: 0.0269s/iter; left time: 12.0108s\n",
      "Epoch: 4 cost time: 5.662206172943115\n",
      "Epoch: 4, Steps: 215 | Train Loss: 0.2615297 Vali Loss: 0.2151705 Test Loss: 0.1712447\n",
      "Validation loss decreased (0.232520 --> 0.215170).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1520994\n",
      "\tspeed: 0.0428s/iter; left time: 14.1704s\n",
      "\titers: 200, epoch: 5 | loss: 0.2278013\n",
      "\tspeed: 0.0257s/iter; left time: 5.9301s\n",
      "Epoch: 5 cost time: 5.542980432510376\n",
      "Epoch: 5, Steps: 215 | Train Loss: 0.2422125 Vali Loss: 0.1980370 Test Loss: 0.1588305\n",
      "Validation loss decreased (0.215170 --> 0.198037).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1477621\n",
      "\tspeed: 0.0421s/iter; left time: 4.8835s\n",
      "\titers: 200, epoch: 6 | loss: 0.2459389\n",
      "\tspeed: 0.0286s/iter; left time: 0.4572s\n",
      "Epoch: 6 cost time: 5.837482213973999\n",
      "Epoch: 6, Steps: 215 | Train Loss: 0.2351431 Vali Loss: 0.1999870 Test Loss: 0.1697001\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1863\n",
      "Test cost time: 0.5033s\n",
      "test shape: (58, 32, 6, 1) (58, 32, 6, 1)\n",
      "test shape: (1856, 6, 1) (1856, 6, 1)\n",
      "mse:0.1595364511013031, mae:0.3064340651035309\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1032.27734375\n",
      "MAE:  24.649341583251953\n",
      "RMSE: 32.12907409667969\n",
      "MAPE: 0.2318008691072464\n",
      "MSPE: 0.1651020497083664\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6955\n",
      "[DEBUG] Original dataset length: 6955\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6881\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 2175\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1863\n",
      "\titers: 100, epoch: 1 | loss: 0.3162322\n",
      "\tspeed: 0.0264s/iter; left time: 31.4271s\n",
      "\titers: 200, epoch: 1 | loss: 0.7293786\n",
      "\tspeed: 0.0263s/iter; left time: 28.7101s\n",
      "Epoch: 1 cost time: 5.665544033050537\n",
      "Epoch: 1, Steps: 215 | Train Loss: 0.4376229 Vali Loss: 0.2184428 Test Loss: 0.2037670\n",
      "Validation loss decreased (inf --> 0.218443).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2660826\n",
      "\tspeed: 0.0422s/iter; left time: 41.1639s\n",
      "\titers: 200, epoch: 2 | loss: 0.5026156\n",
      "\tspeed: 0.0267s/iter; left time: 23.3493s\n",
      "Epoch: 2 cost time: 5.690564870834351\n",
      "Epoch: 2, Steps: 215 | Train Loss: 0.3295312 Vali Loss: 0.2179189 Test Loss: 0.1681736\n",
      "Validation loss decreased (0.218443 --> 0.217919).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2803642\n",
      "\tspeed: 0.0417s/iter; left time: 31.7517s\n",
      "\titers: 200, epoch: 3 | loss: 0.2733723\n",
      "\tspeed: 0.0258s/iter; left time: 17.0349s\n",
      "Epoch: 3 cost time: 5.500319957733154\n",
      "Epoch: 3, Steps: 215 | Train Loss: 0.2904095 Vali Loss: 0.2088463 Test Loss: 0.1819288\n",
      "Validation loss decreased (0.217919 --> 0.208846).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2124484\n",
      "\tspeed: 0.0409s/iter; left time: 22.3532s\n",
      "\titers: 200, epoch: 4 | loss: 0.2868900\n",
      "\tspeed: 0.0251s/iter; left time: 11.1750s\n",
      "Epoch: 4 cost time: 5.421701431274414\n",
      "Epoch: 4, Steps: 215 | Train Loss: 0.2569611 Vali Loss: 0.2058501 Test Loss: 0.1894853\n",
      "Validation loss decreased (0.208846 --> 0.205850).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3282282\n",
      "\tspeed: 0.0435s/iter; left time: 14.4116s\n",
      "\titers: 200, epoch: 5 | loss: 0.2801511\n",
      "\tspeed: 0.0242s/iter; left time: 5.5957s\n",
      "Epoch: 5 cost time: 5.329663515090942\n",
      "Epoch: 5, Steps: 215 | Train Loss: 0.2402750 Vali Loss: 0.2104189 Test Loss: 0.2004044\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1865076\n",
      "\tspeed: 0.0399s/iter; left time: 4.6259s\n",
      "\titers: 200, epoch: 6 | loss: 0.1605111\n",
      "\tspeed: 0.0245s/iter; left time: 0.3917s\n",
      "Epoch: 6 cost time: 5.300486087799072\n",
      "Epoch: 6, Steps: 215 | Train Loss: 0.2283866 Vali Loss: 0.2037382 Test Loss: 0.1992893\n",
      "Validation loss decreased (0.205850 --> 0.203738).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1863\n",
      "Test cost time: 0.5312s\n",
      "test shape: (58, 32, 6, 1) (58, 32, 6, 1)\n",
      "test shape: (1856, 6, 1) (1856, 6, 1)\n",
      "mse:0.19918744266033173, mae:0.3470924198627472\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1288.8385009765625\n",
      "MAE:  27.919872283935547\n",
      "RMSE: 35.90039825439453\n",
      "MAPE: 0.25395044684410095\n",
      "MSPE: 0.16795721650123596\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6955\n",
      "[DEBUG] Original dataset length: 6955\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6881\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 2175\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1863\n",
      "\titers: 100, epoch: 1 | loss: 0.5245978\n",
      "\tspeed: 0.0260s/iter; left time: 30.9269s\n",
      "\titers: 200, epoch: 1 | loss: 0.4680601\n",
      "\tspeed: 0.0256s/iter; left time: 27.8857s\n",
      "Epoch: 1 cost time: 5.555943965911865\n",
      "Epoch: 1, Steps: 215 | Train Loss: 0.4476965 Vali Loss: 0.2593484 Test Loss: 0.2773640\n",
      "Validation loss decreased (inf --> 0.259348).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2684078\n",
      "\tspeed: 0.0413s/iter; left time: 40.2718s\n",
      "\titers: 200, epoch: 2 | loss: 0.3430642\n",
      "\tspeed: 0.0251s/iter; left time: 21.9643s\n",
      "Epoch: 2 cost time: 5.408795595169067\n",
      "Epoch: 2, Steps: 215 | Train Loss: 0.3406410 Vali Loss: 0.2193029 Test Loss: 0.2017158\n",
      "Validation loss decreased (0.259348 --> 0.219303).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2766272\n",
      "\tspeed: 0.0439s/iter; left time: 33.4044s\n",
      "\titers: 200, epoch: 3 | loss: 0.1557271\n",
      "\tspeed: 0.0258s/iter; left time: 17.0209s\n",
      "Epoch: 3 cost time: 5.756260633468628\n",
      "Epoch: 3, Steps: 215 | Train Loss: 0.2879390 Vali Loss: 0.2031763 Test Loss: 0.1905992\n",
      "Validation loss decreased (0.219303 --> 0.203176).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2733049\n",
      "\tspeed: 0.0475s/iter; left time: 25.9299s\n",
      "\titers: 200, epoch: 4 | loss: 0.1499293\n",
      "\tspeed: 0.0255s/iter; left time: 11.3538s\n",
      "Epoch: 4 cost time: 5.884882211685181\n",
      "Epoch: 4, Steps: 215 | Train Loss: 0.2594672 Vali Loss: 0.2079567 Test Loss: 0.1911175\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2102455\n",
      "\tspeed: 0.0404s/iter; left time: 13.3676s\n",
      "\titers: 200, epoch: 5 | loss: 0.2526124\n",
      "\tspeed: 0.0266s/iter; left time: 6.1395s\n",
      "Epoch: 5 cost time: 5.554016828536987\n",
      "Epoch: 5, Steps: 215 | Train Loss: 0.2423529 Vali Loss: 0.2304046 Test Loss: 0.2219493\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2187160\n",
      "\tspeed: 0.0403s/iter; left time: 4.6753s\n",
      "\titers: 200, epoch: 6 | loss: 0.2381260\n",
      "\tspeed: 0.0250s/iter; left time: 0.4005s\n",
      "Epoch: 6 cost time: 5.398984670639038\n",
      "Epoch: 6, Steps: 215 | Train Loss: 0.2340485 Vali Loss: 0.2249390 Test Loss: 0.2263178\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1863\n",
      "Test cost time: 0.5669s\n",
      "test shape: (58, 32, 6, 1) (58, 32, 6, 1)\n",
      "test shape: (1856, 6, 1) (1856, 6, 1)\n",
      "mse:0.18948718905448914, mae:0.333988219499588\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1226.0731201171875\n",
      "MAE:  26.86577796936035\n",
      "RMSE: 35.01532745361328\n",
      "MAPE: 0.26148155331611633\n",
      "MSPE: 0.2748030722141266\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6955\n",
      "[DEBUG] Original dataset length: 6955\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6881\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 2175\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1863\n",
      "\titers: 100, epoch: 1 | loss: 0.2445383\n",
      "\tspeed: 0.0255s/iter; left time: 30.4118s\n",
      "\titers: 200, epoch: 1 | loss: 0.2543676\n",
      "\tspeed: 0.0279s/iter; left time: 30.4444s\n",
      "Epoch: 1 cost time: 5.74699854850769\n",
      "Epoch: 1, Steps: 215 | Train Loss: 0.4367231 Vali Loss: 0.2271746 Test Loss: 0.2391829\n",
      "Validation loss decreased (inf --> 0.227175).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2403483\n",
      "\tspeed: 0.0404s/iter; left time: 39.4202s\n",
      "\titers: 200, epoch: 2 | loss: 0.4818455\n",
      "\tspeed: 0.0251s/iter; left time: 22.0284s\n",
      "Epoch: 2 cost time: 5.2986109256744385\n",
      "Epoch: 2, Steps: 215 | Train Loss: 0.3255216 Vali Loss: 0.2302944 Test Loss: 0.1873032\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2207848\n",
      "\tspeed: 0.0400s/iter; left time: 30.4394s\n",
      "\titers: 200, epoch: 3 | loss: 0.2378398\n",
      "\tspeed: 0.0259s/iter; left time: 17.1009s\n",
      "Epoch: 3 cost time: 5.546850681304932\n",
      "Epoch: 3, Steps: 215 | Train Loss: 0.2839428 Vali Loss: 0.2086023 Test Loss: 0.1940363\n",
      "Validation loss decreased (0.227175 --> 0.208602).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1446127\n",
      "\tspeed: 0.0456s/iter; left time: 24.8871s\n",
      "\titers: 200, epoch: 4 | loss: 0.2249115\n",
      "\tspeed: 0.0262s/iter; left time: 11.6875s\n",
      "Epoch: 4 cost time: 5.689417839050293\n",
      "Epoch: 4, Steps: 215 | Train Loss: 0.2533763 Vali Loss: 0.2072035 Test Loss: 0.1830328\n",
      "Validation loss decreased (0.208602 --> 0.207203).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1676514\n",
      "\tspeed: 0.0410s/iter; left time: 13.5569s\n",
      "\titers: 200, epoch: 5 | loss: 0.2170376\n",
      "\tspeed: 0.0266s/iter; left time: 6.1431s\n",
      "Epoch: 5 cost time: 5.59142541885376\n",
      "Epoch: 5, Steps: 215 | Train Loss: 0.2345989 Vali Loss: 0.2224742 Test Loss: 0.2048438\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2018050\n",
      "\tspeed: 0.0429s/iter; left time: 4.9724s\n",
      "\titers: 200, epoch: 6 | loss: 0.2303346\n",
      "\tspeed: 0.0254s/iter; left time: 0.4063s\n",
      "Epoch: 6 cost time: 5.640910625457764\n",
      "Epoch: 6, Steps: 215 | Train Loss: 0.2243702 Vali Loss: 0.2086821 Test Loss: 0.2109471\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1863\n",
      "Test cost time: 0.5357s\n",
      "test shape: (58, 32, 6, 1) (58, 32, 6, 1)\n",
      "test shape: (1856, 6, 1) (1856, 6, 1)\n",
      "mse:0.18180020153522491, mae:0.32600730657577515\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1176.3345947265625\n",
      "MAE:  26.223798751831055\n",
      "RMSE: 34.297733306884766\n",
      "MAPE: 0.24157346785068512\n",
      "MSPE: 0.1533486396074295\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6955\n",
      "[DEBUG] Original dataset length: 6955\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6881\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 2175\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1863\n",
      "\titers: 100, epoch: 1 | loss: 0.3420252\n",
      "\tspeed: 0.0254s/iter; left time: 30.2065s\n",
      "\titers: 200, epoch: 1 | loss: 0.1935025\n",
      "\tspeed: 0.0260s/iter; left time: 28.4205s\n",
      "Epoch: 1 cost time: 5.559476137161255\n",
      "Epoch: 1, Steps: 215 | Train Loss: 0.4317195 Vali Loss: 0.2171429 Test Loss: 0.2098294\n",
      "Validation loss decreased (inf --> 0.217143).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1547732\n",
      "\tspeed: 0.0439s/iter; left time: 42.8499s\n",
      "\titers: 200, epoch: 2 | loss: 0.3112171\n",
      "\tspeed: 0.0249s/iter; left time: 21.8452s\n",
      "Epoch: 2 cost time: 5.559622764587402\n",
      "Epoch: 2, Steps: 215 | Train Loss: 0.3295716 Vali Loss: 0.2669652 Test Loss: 0.2635427\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2186987\n",
      "\tspeed: 0.0388s/iter; left time: 29.5478s\n",
      "\titers: 200, epoch: 3 | loss: 0.2203638\n",
      "\tspeed: 0.0246s/iter; left time: 16.2590s\n",
      "Epoch: 3 cost time: 5.211487054824829\n",
      "Epoch: 3, Steps: 215 | Train Loss: 0.2865150 Vali Loss: 0.2396023 Test Loss: 0.2167779\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3140422\n",
      "\tspeed: 0.0406s/iter; left time: 22.1848s\n",
      "\titers: 200, epoch: 4 | loss: 0.2887380\n",
      "\tspeed: 0.0275s/iter; left time: 12.2565s\n",
      "Epoch: 4 cost time: 5.753417730331421\n",
      "Epoch: 4, Steps: 215 | Train Loss: 0.2601748 Vali Loss: 0.2235112 Test Loss: 0.1995449\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1863\n",
      "Test cost time: 0.5035s\n",
      "test shape: (58, 32, 6, 1) (58, 32, 6, 1)\n",
      "test shape: (1856, 6, 1) (1856, 6, 1)\n",
      "mse:0.20900754630565643, mae:0.35155490040779114\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1352.379150390625\n",
      "MAE:  28.278831481933594\n",
      "RMSE: 36.77470779418945\n",
      "MAPE: 0.2589236795902252\n",
      "MSPE: 0.19283467531204224\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6955\n",
      "[DEBUG] Original dataset length: 6955\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6881\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 2175\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1863\n",
      "\titers: 100, epoch: 1 | loss: 0.3286736\n",
      "\tspeed: 0.0245s/iter; left time: 29.1996s\n",
      "\titers: 200, epoch: 1 | loss: 0.6784541\n",
      "\tspeed: 0.0251s/iter; left time: 27.3695s\n",
      "Epoch: 1 cost time: 5.404601573944092\n",
      "Epoch: 1, Steps: 215 | Train Loss: 0.4455152 Vali Loss: 0.2656208 Test Loss: 0.2526554\n",
      "Validation loss decreased (inf --> 0.265621).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6295542\n",
      "\tspeed: 0.0415s/iter; left time: 40.4663s\n",
      "\titers: 200, epoch: 2 | loss: 0.6823117\n",
      "\tspeed: 0.0263s/iter; left time: 23.0738s\n",
      "Epoch: 2 cost time: 5.6352527141571045\n",
      "Epoch: 2, Steps: 215 | Train Loss: 0.3512313 Vali Loss: 0.2230676 Test Loss: 0.2183683\n",
      "Validation loss decreased (0.265621 --> 0.223068).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2674829\n",
      "\tspeed: 0.0435s/iter; left time: 33.1149s\n",
      "\titers: 200, epoch: 3 | loss: 0.3056608\n",
      "\tspeed: 0.0240s/iter; left time: 15.8498s\n",
      "Epoch: 3 cost time: 5.44269585609436\n",
      "Epoch: 3, Steps: 215 | Train Loss: 0.2882063 Vali Loss: 0.2098102 Test Loss: 0.1969561\n",
      "Validation loss decreased (0.223068 --> 0.209810).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1912189\n",
      "\tspeed: 0.0422s/iter; left time: 23.0166s\n",
      "\titers: 200, epoch: 4 | loss: 0.1674391\n",
      "\tspeed: 0.0280s/iter; left time: 12.4820s\n",
      "Epoch: 4 cost time: 5.732387065887451\n",
      "Epoch: 4, Steps: 215 | Train Loss: 0.2653686 Vali Loss: 0.2093941 Test Loss: 0.1971244\n",
      "Validation loss decreased (0.209810 --> 0.209394).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3167815\n",
      "\tspeed: 0.0431s/iter; left time: 14.2673s\n",
      "\titers: 200, epoch: 5 | loss: 0.1885359\n",
      "\tspeed: 0.0252s/iter; left time: 5.8109s\n",
      "Epoch: 5 cost time: 5.553278923034668\n",
      "Epoch: 5, Steps: 215 | Train Loss: 0.2456001 Vali Loss: 0.2052008 Test Loss: 0.1833779\n",
      "Validation loss decreased (0.209394 --> 0.205201).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2607748\n",
      "\tspeed: 0.0413s/iter; left time: 4.7917s\n",
      "\titers: 200, epoch: 6 | loss: 0.3050763\n",
      "\tspeed: 0.0253s/iter; left time: 0.4053s\n",
      "Epoch: 6 cost time: 5.493426084518433\n",
      "Epoch: 6, Steps: 215 | Train Loss: 0.2354433 Vali Loss: 0.2059737 Test Loss: 0.1868995\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1863\n",
      "Test cost time: 0.5234s\n",
      "test shape: (58, 32, 6, 1) (58, 32, 6, 1)\n",
      "test shape: (1856, 6, 1) (1856, 6, 1)\n",
      "mse:0.18241950869560242, mae:0.3278161287307739\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1180.3419189453125\n",
      "MAE:  26.36929702758789\n",
      "RMSE: 34.35610580444336\n",
      "MAPE: 0.2403440773487091\n",
      "MSPE: 0.14217743277549744\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6955\n",
      "[DEBUG] Original dataset length: 6955\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6881\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 2175\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1863\n",
      "\titers: 100, epoch: 1 | loss: 0.2839018\n",
      "\tspeed: 0.0250s/iter; left time: 29.7269s\n",
      "\titers: 200, epoch: 1 | loss: 0.2667618\n",
      "\tspeed: 0.0249s/iter; left time: 27.2029s\n",
      "Epoch: 1 cost time: 5.3723554611206055\n",
      "Epoch: 1, Steps: 215 | Train Loss: 0.4422493 Vali Loss: 0.2777402 Test Loss: 0.3043950\n",
      "Validation loss decreased (inf --> 0.277740).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5035006\n",
      "\tspeed: 0.0401s/iter; left time: 39.1740s\n",
      "\titers: 200, epoch: 2 | loss: 0.1891019\n",
      "\tspeed: 0.0253s/iter; left time: 22.1302s\n",
      "Epoch: 2 cost time: 5.363896608352661\n",
      "Epoch: 2, Steps: 215 | Train Loss: 0.3342030 Vali Loss: 0.2054372 Test Loss: 0.1694149\n",
      "Validation loss decreased (0.277740 --> 0.205437).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1881626\n",
      "\tspeed: 0.0432s/iter; left time: 32.8910s\n",
      "\titers: 200, epoch: 3 | loss: 0.1750474\n",
      "\tspeed: 0.0257s/iter; left time: 16.9804s\n",
      "Epoch: 3 cost time: 5.581665992736816\n",
      "Epoch: 3, Steps: 215 | Train Loss: 0.2860305 Vali Loss: 0.2018351 Test Loss: 0.1847216\n",
      "Validation loss decreased (0.205437 --> 0.201835).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3281322\n",
      "\tspeed: 0.0412s/iter; left time: 22.4816s\n",
      "\titers: 200, epoch: 4 | loss: 0.2020148\n",
      "\tspeed: 0.0249s/iter; left time: 11.0934s\n",
      "Epoch: 4 cost time: 5.44157600402832\n",
      "Epoch: 4, Steps: 215 | Train Loss: 0.2560263 Vali Loss: 0.2020971 Test Loss: 0.1914564\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0817291\n",
      "\tspeed: 0.0512s/iter; left time: 16.9442s\n",
      "\titers: 200, epoch: 5 | loss: 0.2432159\n",
      "\tspeed: 0.0264s/iter; left time: 6.0933s\n",
      "Epoch: 5 cost time: 6.4087183475494385\n",
      "Epoch: 5, Steps: 215 | Train Loss: 0.2417876 Vali Loss: 0.2143170 Test Loss: 0.2129635\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1288132\n",
      "\tspeed: 0.0416s/iter; left time: 4.8276s\n",
      "\titers: 200, epoch: 6 | loss: 0.1454840\n",
      "\tspeed: 0.0251s/iter; left time: 0.4015s\n",
      "Epoch: 6 cost time: 5.500901937484741\n",
      "Epoch: 6, Steps: 215 | Train Loss: 0.2313984 Vali Loss: 0.2052402 Test Loss: 0.2163949\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1863\n",
      "Test cost time: 0.5142s\n",
      "test shape: (58, 32, 6, 1) (58, 32, 6, 1)\n",
      "test shape: (1856, 6, 1) (1856, 6, 1)\n",
      "mse:0.1845342218875885, mae:0.32248473167419434\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1194.0250244140625\n",
      "MAE:  25.940441131591797\n",
      "RMSE: 34.55466842651367\n",
      "MAPE: 0.2393726408481598\n",
      "MSPE: 0.17474591732025146\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6955\n",
      "[DEBUG] Original dataset length: 6955\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6881\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 2175\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1863\n",
      "\titers: 100, epoch: 1 | loss: 0.2933449\n",
      "\tspeed: 0.0279s/iter; left time: 33.1755s\n",
      "\titers: 200, epoch: 1 | loss: 0.4107658\n",
      "\tspeed: 0.0249s/iter; left time: 27.1474s\n",
      "Epoch: 1 cost time: 5.655304908752441\n",
      "Epoch: 1, Steps: 215 | Train Loss: 0.4544659 Vali Loss: 0.2282079 Test Loss: 0.2096146\n",
      "Validation loss decreased (inf --> 0.228208).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2687125\n",
      "\tspeed: 0.0402s/iter; left time: 39.2260s\n",
      "\titers: 200, epoch: 2 | loss: 0.2701237\n",
      "\tspeed: 0.0255s/iter; left time: 22.3617s\n",
      "Epoch: 2 cost time: 5.418144464492798\n",
      "Epoch: 2, Steps: 215 | Train Loss: 0.3320968 Vali Loss: 0.2248211 Test Loss: 0.2252802\n",
      "Validation loss decreased (0.228208 --> 0.224821).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3796724\n",
      "\tspeed: 0.0420s/iter; left time: 31.9422s\n",
      "\titers: 200, epoch: 3 | loss: 0.3424663\n",
      "\tspeed: 0.0262s/iter; left time: 17.3069s\n",
      "Epoch: 3 cost time: 5.579241991043091\n",
      "Epoch: 3, Steps: 215 | Train Loss: 0.2906098 Vali Loss: 0.2129011 Test Loss: 0.1771120\n",
      "Validation loss decreased (0.224821 --> 0.212901).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1826575\n",
      "\tspeed: 0.0393s/iter; left time: 21.4366s\n",
      "\titers: 200, epoch: 4 | loss: 0.2315037\n",
      "\tspeed: 0.0237s/iter; left time: 10.5597s\n",
      "Epoch: 4 cost time: 5.104186534881592\n",
      "Epoch: 4, Steps: 215 | Train Loss: 0.2611889 Vali Loss: 0.2220817 Test Loss: 0.2084484\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1871218\n",
      "\tspeed: 0.0376s/iter; left time: 12.4441s\n",
      "\titers: 200, epoch: 5 | loss: 0.1670443\n",
      "\tspeed: 0.0255s/iter; left time: 5.8974s\n",
      "Epoch: 5 cost time: 5.450331211090088\n",
      "Epoch: 5, Steps: 215 | Train Loss: 0.2399161 Vali Loss: 0.2233047 Test Loss: 0.2194982\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2906977\n",
      "\tspeed: 0.0405s/iter; left time: 4.7023s\n",
      "\titers: 200, epoch: 6 | loss: 0.1660552\n",
      "\tspeed: 0.0253s/iter; left time: 0.4045s\n",
      "Epoch: 6 cost time: 5.269939184188843\n",
      "Epoch: 6, Steps: 215 | Train Loss: 0.2326846 Vali Loss: 0.2128479 Test Loss: 0.2131750\n",
      "Validation loss decreased (0.212901 --> 0.212848).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1863\n",
      "Test cost time: 0.5221s\n",
      "test shape: (58, 32, 6, 1) (58, 32, 6, 1)\n",
      "test shape: (1856, 6, 1) (1856, 6, 1)\n",
      "mse:0.2123899608850479, mae:0.36081135272979736\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1374.2650146484375\n",
      "MAE:  29.023408889770508\n",
      "RMSE: 37.07107925415039\n",
      "MAPE: 0.2613552212715149\n",
      "MSPE: 0.15418867766857147\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6955\n",
      "[DEBUG] Original dataset length: 6955\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6881\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 2175\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1863\n",
      "\titers: 100, epoch: 1 | loss: 0.3344045\n",
      "\tspeed: 0.0244s/iter; left time: 29.0067s\n",
      "\titers: 200, epoch: 1 | loss: 0.5472962\n",
      "\tspeed: 0.0239s/iter; left time: 26.1029s\n",
      "Epoch: 1 cost time: 5.22812557220459\n",
      "Epoch: 1, Steps: 215 | Train Loss: 0.4173539 Vali Loss: 0.2433455 Test Loss: 0.2772397\n",
      "Validation loss decreased (inf --> 0.243346).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2259746\n",
      "\tspeed: 0.0456s/iter; left time: 44.4763s\n",
      "\titers: 200, epoch: 2 | loss: 0.6064977\n",
      "\tspeed: 0.0254s/iter; left time: 22.2185s\n",
      "Epoch: 2 cost time: 5.569180011749268\n",
      "Epoch: 2, Steps: 215 | Train Loss: 0.3332784 Vali Loss: 0.2381487 Test Loss: 0.1982481\n",
      "Validation loss decreased (0.243346 --> 0.238149).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.5413862\n",
      "\tspeed: 0.0387s/iter; left time: 29.4381s\n",
      "\titers: 200, epoch: 3 | loss: 0.3345062\n",
      "\tspeed: 0.0249s/iter; left time: 16.4548s\n",
      "Epoch: 3 cost time: 5.182901620864868\n",
      "Epoch: 3, Steps: 215 | Train Loss: 0.2788341 Vali Loss: 0.2040360 Test Loss: 0.1913821\n",
      "Validation loss decreased (0.238149 --> 0.204036).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1561608\n",
      "\tspeed: 0.0417s/iter; left time: 22.7940s\n",
      "\titers: 200, epoch: 4 | loss: 0.1675926\n",
      "\tspeed: 0.0257s/iter; left time: 11.4583s\n",
      "Epoch: 4 cost time: 5.61279296875\n",
      "Epoch: 4, Steps: 215 | Train Loss: 0.2526432 Vali Loss: 0.1996052 Test Loss: 0.1772459\n",
      "Validation loss decreased (0.204036 --> 0.199605).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1033357\n",
      "\tspeed: 0.0418s/iter; left time: 13.8459s\n",
      "\titers: 200, epoch: 5 | loss: 0.2547391\n",
      "\tspeed: 0.0255s/iter; left time: 5.8797s\n",
      "Epoch: 5 cost time: 5.4948670864105225\n",
      "Epoch: 5, Steps: 215 | Train Loss: 0.2372150 Vali Loss: 0.2063423 Test Loss: 0.1978275\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2876423\n",
      "\tspeed: 0.0393s/iter; left time: 4.5570s\n",
      "\titers: 200, epoch: 6 | loss: 0.1797347\n",
      "\tspeed: 0.0272s/iter; left time: 0.4350s\n",
      "Epoch: 6 cost time: 5.5852885246276855\n",
      "Epoch: 6, Steps: 215 | Train Loss: 0.2274001 Vali Loss: 0.1998841 Test Loss: 0.1820708\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1863\n",
      "Test cost time: 0.4989s\n",
      "test shape: (58, 32, 6, 1) (58, 32, 6, 1)\n",
      "test shape: (1856, 6, 1) (1856, 6, 1)\n",
      "mse:0.1775577962398529, mae:0.32700932025909424\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1148.8843994140625\n",
      "MAE:  26.304397583007812\n",
      "RMSE: 33.895198822021484\n",
      "MAPE: 0.24314898252487183\n",
      "MSPE: 0.1491364687681198\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6955\n",
      "[DEBUG] Original dataset length: 6955\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6881\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 2175\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1863\n",
      "\titers: 100, epoch: 1 | loss: 0.3901102\n",
      "\tspeed: 0.0247s/iter; left time: 29.3724s\n",
      "\titers: 200, epoch: 1 | loss: 0.2440770\n",
      "\tspeed: 0.0246s/iter; left time: 26.8487s\n",
      "Epoch: 1 cost time: 5.331273794174194\n",
      "Epoch: 1, Steps: 215 | Train Loss: 0.4390050 Vali Loss: 0.2699960 Test Loss: 0.2476866\n",
      "Validation loss decreased (inf --> 0.269996).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2798044\n",
      "\tspeed: 0.0407s/iter; left time: 39.7414s\n",
      "\titers: 200, epoch: 2 | loss: 0.2355775\n",
      "\tspeed: 0.0263s/iter; left time: 23.0255s\n",
      "Epoch: 2 cost time: 5.588651418685913\n",
      "Epoch: 2, Steps: 215 | Train Loss: 0.3337759 Vali Loss: 0.2614380 Test Loss: 0.2370135\n",
      "Validation loss decreased (0.269996 --> 0.261438).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2312229\n",
      "\tspeed: 0.0402s/iter; left time: 30.5954s\n",
      "\titers: 200, epoch: 3 | loss: 0.1837201\n",
      "\tspeed: 0.0245s/iter; left time: 16.1817s\n",
      "Epoch: 3 cost time: 5.2344911098480225\n",
      "Epoch: 3, Steps: 215 | Train Loss: 0.2878143 Vali Loss: 0.2211726 Test Loss: 0.2248169\n",
      "Validation loss decreased (0.261438 --> 0.221173).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1521301\n",
      "\tspeed: 0.0398s/iter; left time: 21.7491s\n",
      "\titers: 200, epoch: 4 | loss: 0.1734745\n",
      "\tspeed: 0.0236s/iter; left time: 10.5054s\n",
      "Epoch: 4 cost time: 5.148562431335449\n",
      "Epoch: 4, Steps: 215 | Train Loss: 0.2605431 Vali Loss: 0.2047920 Test Loss: 0.1907893\n",
      "Validation loss decreased (0.221173 --> 0.204792).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2109824\n",
      "\tspeed: 0.0420s/iter; left time: 13.9149s\n",
      "\titers: 200, epoch: 5 | loss: 0.2393023\n",
      "\tspeed: 0.0249s/iter; left time: 5.7501s\n",
      "Epoch: 5 cost time: 5.468430042266846\n",
      "Epoch: 5, Steps: 215 | Train Loss: 0.2415932 Vali Loss: 0.2212940 Test Loss: 0.2374999\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2864860\n",
      "\tspeed: 0.0387s/iter; left time: 4.4896s\n",
      "\titers: 200, epoch: 6 | loss: 0.1696749\n",
      "\tspeed: 0.0248s/iter; left time: 0.3969s\n",
      "Epoch: 6 cost time: 5.27986216545105\n",
      "Epoch: 6, Steps: 215 | Train Loss: 0.2310764 Vali Loss: 0.2066509 Test Loss: 0.2085306\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1863\n",
      "Test cost time: 0.4910s\n",
      "test shape: (58, 32, 6, 1) (58, 32, 6, 1)\n",
      "test shape: (1856, 6, 1) (1856, 6, 1)\n",
      "mse:0.19054818153381348, mae:0.3432507812976837\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1232.938232421875\n",
      "MAE:  27.610851287841797\n",
      "RMSE: 35.11322021484375\n",
      "MAPE: 0.2560257315635681\n",
      "MSPE: 0.17090584337711334\n",
      ">>>>>>>Running time saved<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Running seq_len=48\n",
      "Args in experiment:\n",
      "Namespace(model='informer', data='traffic_after_covid', root_path='../', data_path='traffic_after_covid.csv', features='S', target='flow', freq='h', checkpoints='./checkpoints/', seq_len=48, label_len=24, pred_len=6, enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=2, d_layers=1, s_layers=[3, 2, 1], d_ff=2048, factor=5, padding=0, distil=True, dropout=0.05, attn='prob', embed='timeF', activation='gelu', output_attention=False, do_predict=False, mix=True, cols=None, num_workers=0, itr=10, train_epochs=6, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, inverse=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', detail_freq='h')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6931\n",
      "[DEBUG] Original dataset length: 6931\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6809\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 2103\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1772\n",
      "\titers: 100, epoch: 1 | loss: 0.1922771\n",
      "\tspeed: 0.0398s/iter; left time: 46.6520s\n",
      "\titers: 200, epoch: 1 | loss: 0.6618557\n",
      "\tspeed: 0.0234s/iter; left time: 25.0879s\n",
      "Epoch: 1 cost time: 5.68380069732666\n",
      "Epoch: 1, Steps: 212 | Train Loss: 0.4676104 Vali Loss: 0.2607375 Test Loss: 0.2753598\n",
      "Validation loss decreased (inf --> 0.260738).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2894768\n",
      "\tspeed: 0.0406s/iter; left time: 39.0305s\n",
      "\titers: 200, epoch: 2 | loss: 0.3553082\n",
      "\tspeed: 0.0272s/iter; left time: 23.4318s\n",
      "Epoch: 2 cost time: 5.5302863121032715\n",
      "Epoch: 2, Steps: 212 | Train Loss: 0.3450151 Vali Loss: 0.2313460 Test Loss: 0.2631784\n",
      "Validation loss decreased (0.260738 --> 0.231346).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3658285\n",
      "\tspeed: 0.0419s/iter; left time: 31.4031s\n",
      "\titers: 200, epoch: 3 | loss: 0.2180944\n",
      "\tspeed: 0.0258s/iter; left time: 16.7622s\n",
      "Epoch: 3 cost time: 5.445475339889526\n",
      "Epoch: 3, Steps: 212 | Train Loss: 0.2909750 Vali Loss: 0.2295120 Test Loss: 0.2278399\n",
      "Validation loss decreased (0.231346 --> 0.229512).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2022018\n",
      "\tspeed: 0.0394s/iter; left time: 21.1502s\n",
      "\titers: 200, epoch: 4 | loss: 0.2586690\n",
      "\tspeed: 0.0249s/iter; left time: 10.8733s\n",
      "Epoch: 4 cost time: 5.258849382400513\n",
      "Epoch: 4, Steps: 212 | Train Loss: 0.2619146 Vali Loss: 0.2290261 Test Loss: 0.2278407\n",
      "Validation loss decreased (0.229512 --> 0.229026).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2489935\n",
      "\tspeed: 0.0433s/iter; left time: 14.0656s\n",
      "\titers: 200, epoch: 5 | loss: 0.2329048\n",
      "\tspeed: 0.0269s/iter; left time: 6.0442s\n",
      "Epoch: 5 cost time: 5.817137956619263\n",
      "Epoch: 5, Steps: 212 | Train Loss: 0.2451024 Vali Loss: 0.2189170 Test Loss: 0.2134642\n",
      "Validation loss decreased (0.229026 --> 0.218917).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1864749\n",
      "\tspeed: 0.0412s/iter; left time: 4.6516s\n",
      "\titers: 200, epoch: 6 | loss: 0.1873745\n",
      "\tspeed: 0.0258s/iter; left time: 0.3359s\n",
      "Epoch: 6 cost time: 5.487116575241089\n",
      "Epoch: 6, Steps: 212 | Train Loss: 0.2352174 Vali Loss: 0.2135167 Test Loss: 0.2123603\n",
      "Validation loss decreased (0.218917 --> 0.213517).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1772\n",
      "Test cost time: 0.4772s\n",
      "test shape: (55, 32, 6, 1) (55, 32, 6, 1)\n",
      "test shape: (1760, 6, 1) (1760, 6, 1)\n",
      "mse:0.21339666843414307, mae:0.35889872908592224\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1380.7789306640625\n",
      "MAE:  28.86956024169922\n",
      "RMSE: 37.15883255004883\n",
      "MAPE: 0.25650912523269653\n",
      "MSPE: 0.1581260859966278\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6931\n",
      "[DEBUG] Original dataset length: 6931\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6809\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 2103\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1772\n",
      "\titers: 100, epoch: 1 | loss: 0.4343347\n",
      "\tspeed: 0.0283s/iter; left time: 33.2333s\n",
      "\titers: 200, epoch: 1 | loss: 0.6694478\n",
      "\tspeed: 0.0256s/iter; left time: 27.4424s\n",
      "Epoch: 1 cost time: 5.751470327377319\n",
      "Epoch: 1, Steps: 212 | Train Loss: 0.4447919 Vali Loss: 0.2575519 Test Loss: 0.2889658\n",
      "Validation loss decreased (inf --> 0.257552).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6395894\n",
      "\tspeed: 0.0414s/iter; left time: 39.7659s\n",
      "\titers: 200, epoch: 2 | loss: 0.2151050\n",
      "\tspeed: 0.0251s/iter; left time: 21.6234s\n",
      "Epoch: 2 cost time: 5.403661012649536\n",
      "Epoch: 2, Steps: 212 | Train Loss: 0.3404560 Vali Loss: 0.2361798 Test Loss: 0.2506539\n",
      "Validation loss decreased (0.257552 --> 0.236180).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2851168\n",
      "\tspeed: 0.0435s/iter; left time: 32.5508s\n",
      "\titers: 200, epoch: 3 | loss: 0.3958948\n",
      "\tspeed: 0.0263s/iter; left time: 17.0798s\n",
      "Epoch: 3 cost time: 5.712318420410156\n",
      "Epoch: 3, Steps: 212 | Train Loss: 0.2908231 Vali Loss: 0.2314549 Test Loss: 0.2318608\n",
      "Validation loss decreased (0.236180 --> 0.231455).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2320657\n",
      "\tspeed: 0.0428s/iter; left time: 22.9816s\n",
      "\titers: 200, epoch: 4 | loss: 0.7465390\n",
      "\tspeed: 0.0261s/iter; left time: 11.4270s\n",
      "Epoch: 4 cost time: 5.654170274734497\n",
      "Epoch: 4, Steps: 212 | Train Loss: 0.2640507 Vali Loss: 0.2125168 Test Loss: 0.2133160\n",
      "Validation loss decreased (0.231455 --> 0.212517).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2923205\n",
      "\tspeed: 0.0428s/iter; left time: 13.9152s\n",
      "\titers: 200, epoch: 5 | loss: 0.2482500\n",
      "\tspeed: 0.0268s/iter; left time: 6.0236s\n",
      "Epoch: 5 cost time: 5.767531633377075\n",
      "Epoch: 5, Steps: 212 | Train Loss: 0.2437849 Vali Loss: 0.2253052 Test Loss: 0.2594411\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1629884\n",
      "\tspeed: 0.0410s/iter; left time: 4.6276s\n",
      "\titers: 200, epoch: 6 | loss: 0.3524162\n",
      "\tspeed: 0.0268s/iter; left time: 0.3483s\n",
      "Epoch: 6 cost time: 5.647865533828735\n",
      "Epoch: 6, Steps: 212 | Train Loss: 0.2344463 Vali Loss: 0.2229442 Test Loss: 0.2506882\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1772\n",
      "Test cost time: 0.5145s\n",
      "test shape: (55, 32, 6, 1) (55, 32, 6, 1)\n",
      "test shape: (1760, 6, 1) (1760, 6, 1)\n",
      "mse:0.2136974036693573, mae:0.35160738229751587\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1382.724853515625\n",
      "MAE:  28.283048629760742\n",
      "RMSE: 37.18500900268555\n",
      "MAPE: 0.24845696985721588\n",
      "MSPE: 0.13402587175369263\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6931\n",
      "[DEBUG] Original dataset length: 6931\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6809\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 2103\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1772\n",
      "\titers: 100, epoch: 1 | loss: 0.2097779\n",
      "\tspeed: 0.0272s/iter; left time: 31.9299s\n",
      "\titers: 200, epoch: 1 | loss: 0.2808102\n",
      "\tspeed: 0.0272s/iter; left time: 29.2175s\n",
      "Epoch: 1 cost time: 5.794337034225464\n",
      "Epoch: 1, Steps: 212 | Train Loss: 0.4290870 Vali Loss: 0.2403093 Test Loss: 0.2644334\n",
      "Validation loss decreased (inf --> 0.240309).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5980496\n",
      "\tspeed: 0.0435s/iter; left time: 41.8430s\n",
      "\titers: 200, epoch: 2 | loss: 0.4081695\n",
      "\tspeed: 0.0274s/iter; left time: 23.5753s\n",
      "Epoch: 2 cost time: 5.843776702880859\n",
      "Epoch: 2, Steps: 212 | Train Loss: 0.3413776 Vali Loss: 0.2187909 Test Loss: 0.2023725\n",
      "Validation loss decreased (0.240309 --> 0.218791).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3089202\n",
      "\tspeed: 0.0411s/iter; left time: 30.7678s\n",
      "\titers: 200, epoch: 3 | loss: 0.3524415\n",
      "\tspeed: 0.0268s/iter; left time: 17.4032s\n",
      "Epoch: 3 cost time: 5.684868812561035\n",
      "Epoch: 3, Steps: 212 | Train Loss: 0.2807163 Vali Loss: 0.2133841 Test Loss: 0.1894709\n",
      "Validation loss decreased (0.218791 --> 0.213384).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1092248\n",
      "\tspeed: 0.0429s/iter; left time: 23.0359s\n",
      "\titers: 200, epoch: 4 | loss: 0.3968860\n",
      "\tspeed: 0.0251s/iter; left time: 10.9743s\n",
      "Epoch: 4 cost time: 5.5073912143707275\n",
      "Epoch: 4, Steps: 212 | Train Loss: 0.2474566 Vali Loss: 0.2269349 Test Loss: 0.2098535\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2384892\n",
      "\tspeed: 0.0418s/iter; left time: 13.5870s\n",
      "\titers: 200, epoch: 5 | loss: 0.1635200\n",
      "\tspeed: 0.0269s/iter; left time: 6.0552s\n",
      "Epoch: 5 cost time: 5.799892902374268\n",
      "Epoch: 5, Steps: 212 | Train Loss: 0.2311151 Vali Loss: 0.2216312 Test Loss: 0.2007539\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3541284\n",
      "\tspeed: 0.0420s/iter; left time: 4.7491s\n",
      "\titers: 200, epoch: 6 | loss: 0.1874852\n",
      "\tspeed: 0.0269s/iter; left time: 0.3498s\n",
      "Epoch: 6 cost time: 5.714502573013306\n",
      "Epoch: 6, Steps: 212 | Train Loss: 0.2211596 Vali Loss: 0.2161465 Test Loss: 0.1953203\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1772\n",
      "Test cost time: 0.4355s\n",
      "test shape: (55, 32, 6, 1) (55, 32, 6, 1)\n",
      "test shape: (1760, 6, 1) (1760, 6, 1)\n",
      "mse:0.1885775774717331, mae:0.33351296186447144\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1220.1873779296875\n",
      "MAE:  26.827545166015625\n",
      "RMSE: 34.93117904663086\n",
      "MAPE: 0.24521170556545258\n",
      "MSPE: 0.15439747273921967\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6931\n",
      "[DEBUG] Original dataset length: 6931\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6809\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 2103\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1772\n",
      "\titers: 100, epoch: 1 | loss: 0.3589268\n",
      "\tspeed: 0.0269s/iter; left time: 31.6113s\n",
      "\titers: 200, epoch: 1 | loss: 0.2902199\n",
      "\tspeed: 0.0269s/iter; left time: 28.8651s\n",
      "Epoch: 1 cost time: 5.722201824188232\n",
      "Epoch: 1, Steps: 212 | Train Loss: 0.4445341 Vali Loss: 0.2345118 Test Loss: 0.2999917\n",
      "Validation loss decreased (inf --> 0.234512).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2984430\n",
      "\tspeed: 0.0463s/iter; left time: 44.5223s\n",
      "\titers: 200, epoch: 2 | loss: 0.3184031\n",
      "\tspeed: 0.0277s/iter; left time: 23.8691s\n",
      "Epoch: 2 cost time: 5.948513031005859\n",
      "Epoch: 2, Steps: 212 | Train Loss: 0.3373720 Vali Loss: 0.2282509 Test Loss: 0.2090541\n",
      "Validation loss decreased (0.234512 --> 0.228251).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3742073\n",
      "\tspeed: 0.0444s/iter; left time: 33.2906s\n",
      "\titers: 200, epoch: 3 | loss: 0.2966349\n",
      "\tspeed: 0.0284s/iter; left time: 18.4298s\n",
      "Epoch: 3 cost time: 6.039798736572266\n",
      "Epoch: 3, Steps: 212 | Train Loss: 0.2851771 Vali Loss: 0.2751865 Test Loss: 0.2613412\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2250732\n",
      "\tspeed: 0.0429s/iter; left time: 23.0211s\n",
      "\titers: 200, epoch: 4 | loss: 0.3552692\n",
      "\tspeed: 0.0276s/iter; left time: 12.0740s\n",
      "Epoch: 4 cost time: 5.866157293319702\n",
      "Epoch: 4, Steps: 212 | Train Loss: 0.2603331 Vali Loss: 0.2163503 Test Loss: 0.1931032\n",
      "Validation loss decreased (0.228251 --> 0.216350).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2114371\n",
      "\tspeed: 0.0388s/iter; left time: 12.6026s\n",
      "\titers: 200, epoch: 5 | loss: 0.1990358\n",
      "\tspeed: 0.0251s/iter; left time: 5.6453s\n",
      "Epoch: 5 cost time: 5.2265098094940186\n",
      "Epoch: 5, Steps: 212 | Train Loss: 0.2420755 Vali Loss: 0.2096494 Test Loss: 0.1942744\n",
      "Validation loss decreased (0.216350 --> 0.209649).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3059239\n",
      "\tspeed: 0.0429s/iter; left time: 4.8521s\n",
      "\titers: 200, epoch: 6 | loss: 0.3379324\n",
      "\tspeed: 0.0264s/iter; left time: 0.3426s\n",
      "Epoch: 6 cost time: 5.680015563964844\n",
      "Epoch: 6, Steps: 212 | Train Loss: 0.2292809 Vali Loss: 0.2090835 Test Loss: 0.1776650\n",
      "Validation loss decreased (0.209649 --> 0.209083).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1772\n",
      "Test cost time: 0.5050s\n",
      "test shape: (55, 32, 6, 1) (55, 32, 6, 1)\n",
      "test shape: (1760, 6, 1) (1760, 6, 1)\n",
      "mse:0.17788787186145782, mae:0.32167109847068787\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1151.0196533203125\n",
      "MAE:  25.8749942779541\n",
      "RMSE: 33.92668151855469\n",
      "MAPE: 0.2348518669605255\n",
      "MSPE: 0.12600216269493103\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6931\n",
      "[DEBUG] Original dataset length: 6931\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6809\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 2103\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1772\n",
      "\titers: 100, epoch: 1 | loss: 0.2413879\n",
      "\tspeed: 0.0279s/iter; left time: 32.7234s\n",
      "\titers: 200, epoch: 1 | loss: 0.3732551\n",
      "\tspeed: 0.0262s/iter; left time: 28.0610s\n",
      "Epoch: 1 cost time: 5.762735843658447\n",
      "Epoch: 1, Steps: 212 | Train Loss: 0.4413195 Vali Loss: 0.3291285 Test Loss: 0.4358156\n",
      "Validation loss decreased (inf --> 0.329129).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2924792\n",
      "\tspeed: 0.0438s/iter; left time: 42.0588s\n",
      "\titers: 200, epoch: 2 | loss: 0.4077465\n",
      "\tspeed: 0.0273s/iter; left time: 23.5266s\n",
      "Epoch: 2 cost time: 5.713232517242432\n",
      "Epoch: 2, Steps: 212 | Train Loss: 0.3326714 Vali Loss: 0.2228244 Test Loss: 0.2459073\n",
      "Validation loss decreased (0.329129 --> 0.222824).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3389129\n",
      "\tspeed: 0.0435s/iter; left time: 32.5835s\n",
      "\titers: 200, epoch: 3 | loss: 0.2466094\n",
      "\tspeed: 0.0274s/iter; left time: 17.7781s\n",
      "Epoch: 3 cost time: 5.786051034927368\n",
      "Epoch: 3, Steps: 212 | Train Loss: 0.2835892 Vali Loss: 0.2152882 Test Loss: 0.2028907\n",
      "Validation loss decreased (0.222824 --> 0.215288).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2646242\n",
      "\tspeed: 0.0451s/iter; left time: 24.2380s\n",
      "\titers: 200, epoch: 4 | loss: 0.1691727\n",
      "\tspeed: 0.0275s/iter; left time: 12.0125s\n",
      "Epoch: 4 cost time: 5.799776077270508\n",
      "Epoch: 4, Steps: 212 | Train Loss: 0.2536832 Vali Loss: 0.2078625 Test Loss: 0.1858463\n",
      "Validation loss decreased (0.215288 --> 0.207862).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1085273\n",
      "\tspeed: 0.0407s/iter; left time: 13.2309s\n",
      "\titers: 200, epoch: 5 | loss: 0.1387182\n",
      "\tspeed: 0.0267s/iter; left time: 6.0066s\n",
      "Epoch: 5 cost time: 5.567904472351074\n",
      "Epoch: 5, Steps: 212 | Train Loss: 0.2348841 Vali Loss: 0.2167518 Test Loss: 0.1840245\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2337981\n",
      "\tspeed: 0.0393s/iter; left time: 4.4439s\n",
      "\titers: 200, epoch: 6 | loss: 0.2220446\n",
      "\tspeed: 0.0236s/iter; left time: 0.3074s\n",
      "Epoch: 6 cost time: 5.209520101547241\n",
      "Epoch: 6, Steps: 212 | Train Loss: 0.2262272 Vali Loss: 0.2217461 Test Loss: 0.1918616\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1772\n",
      "Test cost time: 0.5138s\n",
      "test shape: (55, 32, 6, 1) (55, 32, 6, 1)\n",
      "test shape: (1760, 6, 1) (1760, 6, 1)\n",
      "mse:0.18528074026107788, mae:0.3234962821006775\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1198.8553466796875\n",
      "MAE:  26.02181053161621\n",
      "RMSE: 34.624488830566406\n",
      "MAPE: 0.23825718462467194\n",
      "MSPE: 0.13640029728412628\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6931\n",
      "[DEBUG] Original dataset length: 6931\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6809\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 2103\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1772\n",
      "\titers: 100, epoch: 1 | loss: 0.4166914\n",
      "\tspeed: 0.0243s/iter; left time: 28.5262s\n",
      "\titers: 200, epoch: 1 | loss: 0.2472698\n",
      "\tspeed: 0.0237s/iter; left time: 25.4652s\n",
      "Epoch: 1 cost time: 5.096708297729492\n",
      "Epoch: 1, Steps: 212 | Train Loss: 0.4564847 Vali Loss: 0.2706212 Test Loss: 0.3065354\n",
      "Validation loss decreased (inf --> 0.270621).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6896615\n",
      "\tspeed: 0.0391s/iter; left time: 37.5841s\n",
      "\titers: 200, epoch: 2 | loss: 0.1846523\n",
      "\tspeed: 0.0233s/iter; left time: 20.0646s\n",
      "Epoch: 2 cost time: 5.102092981338501\n",
      "Epoch: 2, Steps: 212 | Train Loss: 0.3424035 Vali Loss: 0.2353336 Test Loss: 0.2306504\n",
      "Validation loss decreased (0.270621 --> 0.235334).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2666184\n",
      "\tspeed: 0.0406s/iter; left time: 30.3752s\n",
      "\titers: 200, epoch: 3 | loss: 0.2135503\n",
      "\tspeed: 0.0257s/iter; left time: 16.6627s\n",
      "Epoch: 3 cost time: 5.502208948135376\n",
      "Epoch: 3, Steps: 212 | Train Loss: 0.2837084 Vali Loss: 0.2264576 Test Loss: 0.2198520\n",
      "Validation loss decreased (0.235334 --> 0.226458).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2073469\n",
      "\tspeed: 0.0389s/iter; left time: 20.8800s\n",
      "\titers: 200, epoch: 4 | loss: 0.2980768\n",
      "\tspeed: 0.0253s/iter; left time: 11.0401s\n",
      "Epoch: 4 cost time: 5.234314918518066\n",
      "Epoch: 4, Steps: 212 | Train Loss: 0.2562151 Vali Loss: 0.2121183 Test Loss: 0.2009154\n",
      "Validation loss decreased (0.226458 --> 0.212118).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1665994\n",
      "\tspeed: 0.0408s/iter; left time: 13.2702s\n",
      "\titers: 200, epoch: 5 | loss: 0.3422891\n",
      "\tspeed: 0.0270s/iter; left time: 6.0851s\n",
      "Epoch: 5 cost time: 5.643975734710693\n",
      "Epoch: 5, Steps: 212 | Train Loss: 0.2388215 Vali Loss: 0.2037585 Test Loss: 0.1788961\n",
      "Validation loss decreased (0.212118 --> 0.203759).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3152097\n",
      "\tspeed: 0.0407s/iter; left time: 4.5938s\n",
      "\titers: 200, epoch: 6 | loss: 0.1655193\n",
      "\tspeed: 0.0263s/iter; left time: 0.3420s\n",
      "Epoch: 6 cost time: 5.551643371582031\n",
      "Epoch: 6, Steps: 212 | Train Loss: 0.2268741 Vali Loss: 0.2161594 Test Loss: 0.1921617\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1772\n",
      "Test cost time: 0.4833s\n",
      "test shape: (55, 32, 6, 1) (55, 32, 6, 1)\n",
      "test shape: (1760, 6, 1) (1760, 6, 1)\n",
      "mse:0.17916718125343323, mae:0.3233780860900879\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1159.2977294921875\n",
      "MAE:  26.012304306030273\n",
      "RMSE: 34.0484619140625\n",
      "MAPE: 0.23421227931976318\n",
      "MSPE: 0.1358141154050827\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6931\n",
      "[DEBUG] Original dataset length: 6931\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6809\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 2103\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1772\n",
      "\titers: 100, epoch: 1 | loss: 0.5308746\n",
      "\tspeed: 0.0244s/iter; left time: 28.5818s\n",
      "\titers: 200, epoch: 1 | loss: 0.3626549\n",
      "\tspeed: 0.0267s/iter; left time: 28.6308s\n",
      "Epoch: 1 cost time: 5.413498401641846\n",
      "Epoch: 1, Steps: 212 | Train Loss: 0.4514147 Vali Loss: 0.2347876 Test Loss: 0.2095546\n",
      "Validation loss decreased (inf --> 0.234788).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3086127\n",
      "\tspeed: 0.0375s/iter; left time: 36.0484s\n",
      "\titers: 200, epoch: 2 | loss: 0.2574741\n",
      "\tspeed: 0.0240s/iter; left time: 20.6711s\n",
      "Epoch: 2 cost time: 4.936005353927612\n",
      "Epoch: 2, Steps: 212 | Train Loss: 0.3372125 Vali Loss: 0.2602533 Test Loss: 0.2223536\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1426125\n",
      "\tspeed: 0.0362s/iter; left time: 27.1166s\n",
      "\titers: 200, epoch: 3 | loss: 0.2227053\n",
      "\tspeed: 0.0246s/iter; left time: 15.9611s\n",
      "Epoch: 3 cost time: 5.112645864486694\n",
      "Epoch: 3, Steps: 212 | Train Loss: 0.2888082 Vali Loss: 0.2231150 Test Loss: 0.2145204\n",
      "Validation loss decreased (0.234788 --> 0.223115).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2895339\n",
      "\tspeed: 0.0408s/iter; left time: 21.9006s\n",
      "\titers: 200, epoch: 4 | loss: 0.1685161\n",
      "\tspeed: 0.0256s/iter; left time: 11.1964s\n",
      "Epoch: 4 cost time: 5.47443699836731\n",
      "Epoch: 4, Steps: 212 | Train Loss: 0.2564732 Vali Loss: 0.2061330 Test Loss: 0.1958973\n",
      "Validation loss decreased (0.223115 --> 0.206133).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1011553\n",
      "\tspeed: 0.0386s/iter; left time: 12.5578s\n",
      "\titers: 200, epoch: 5 | loss: 0.2400020\n",
      "\tspeed: 0.0245s/iter; left time: 5.5168s\n",
      "Epoch: 5 cost time: 5.149515628814697\n",
      "Epoch: 5, Steps: 212 | Train Loss: 0.2400474 Vali Loss: 0.2103238 Test Loss: 0.2095100\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2589784\n",
      "\tspeed: 0.0391s/iter; left time: 4.4131s\n",
      "\titers: 200, epoch: 6 | loss: 0.2467082\n",
      "\tspeed: 0.0253s/iter; left time: 0.3284s\n",
      "Epoch: 6 cost time: 5.35810661315918\n",
      "Epoch: 6, Steps: 212 | Train Loss: 0.2310219 Vali Loss: 0.2214202 Test Loss: 0.2431557\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1772\n",
      "Test cost time: 0.4751s\n",
      "test shape: (55, 32, 6, 1) (55, 32, 6, 1)\n",
      "test shape: (1760, 6, 1) (1760, 6, 1)\n",
      "mse:0.19619722664356232, mae:0.33794036507606506\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1269.4903564453125\n",
      "MAE:  27.183683395385742\n",
      "RMSE: 35.62990951538086\n",
      "MAPE: 0.25064605474472046\n",
      "MSPE: 0.17694300413131714\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6931\n",
      "[DEBUG] Original dataset length: 6931\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6809\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 2103\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1772\n",
      "\titers: 100, epoch: 1 | loss: 0.4627654\n",
      "\tspeed: 0.0236s/iter; left time: 27.6556s\n",
      "\titers: 200, epoch: 1 | loss: 0.2119480\n",
      "\tspeed: 0.0244s/iter; left time: 26.1708s\n",
      "Epoch: 1 cost time: 5.114100217819214\n",
      "Epoch: 1, Steps: 212 | Train Loss: 0.4460720 Vali Loss: 0.2278672 Test Loss: 0.1896330\n",
      "Validation loss decreased (inf --> 0.227867).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3211785\n",
      "\tspeed: 0.0386s/iter; left time: 37.1035s\n",
      "\titers: 200, epoch: 2 | loss: 0.2059171\n",
      "\tspeed: 0.0260s/iter; left time: 22.3879s\n",
      "Epoch: 2 cost time: 5.335639238357544\n",
      "Epoch: 2, Steps: 212 | Train Loss: 0.3348397 Vali Loss: 0.2169442 Test Loss: 0.1965414\n",
      "Validation loss decreased (0.227867 --> 0.216944).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2518466\n",
      "\tspeed: 0.0420s/iter; left time: 31.4781s\n",
      "\titers: 200, epoch: 3 | loss: 0.2465802\n",
      "\tspeed: 0.0244s/iter; left time: 15.8255s\n",
      "Epoch: 3 cost time: 5.5256853103637695\n",
      "Epoch: 3, Steps: 212 | Train Loss: 0.2823311 Vali Loss: 0.2135495 Test Loss: 0.2193298\n",
      "Validation loss decreased (0.216944 --> 0.213549).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2541520\n",
      "\tspeed: 0.0382s/iter; left time: 20.5071s\n",
      "\titers: 200, epoch: 4 | loss: 0.1797939\n",
      "\tspeed: 0.0242s/iter; left time: 10.5954s\n",
      "Epoch: 4 cost time: 5.096222639083862\n",
      "Epoch: 4, Steps: 212 | Train Loss: 0.2536461 Vali Loss: 0.2246332 Test Loss: 0.2101899\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2430274\n",
      "\tspeed: 0.0383s/iter; left time: 12.4545s\n",
      "\titers: 200, epoch: 5 | loss: 0.2299034\n",
      "\tspeed: 0.0235s/iter; left time: 5.2948s\n",
      "Epoch: 5 cost time: 5.040811061859131\n",
      "Epoch: 5, Steps: 212 | Train Loss: 0.2368031 Vali Loss: 0.2088329 Test Loss: 0.1960528\n",
      "Validation loss decreased (0.213549 --> 0.208833).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1797287\n",
      "\tspeed: 0.0368s/iter; left time: 4.1569s\n",
      "\titers: 200, epoch: 6 | loss: 0.1405615\n",
      "\tspeed: 0.0235s/iter; left time: 0.3061s\n",
      "Epoch: 6 cost time: 4.9204535484313965\n",
      "Epoch: 6, Steps: 212 | Train Loss: 0.2301920 Vali Loss: 0.2084441 Test Loss: 0.2059100\n",
      "Validation loss decreased (0.208833 --> 0.208444).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1772\n",
      "Test cost time: 0.4551s\n",
      "test shape: (55, 32, 6, 1) (55, 32, 6, 1)\n",
      "test shape: (1760, 6, 1) (1760, 6, 1)\n",
      "mse:0.2063988447189331, mae:0.34838423132896423\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1335.499755859375\n",
      "MAE:  28.023780822753906\n",
      "RMSE: 36.544490814208984\n",
      "MAPE: 0.2498958259820938\n",
      "MSPE: 0.14226774871349335\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6931\n",
      "[DEBUG] Original dataset length: 6931\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6809\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 2103\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1772\n",
      "\titers: 100, epoch: 1 | loss: 0.3092454\n",
      "\tspeed: 0.0242s/iter; left time: 28.4205s\n",
      "\titers: 200, epoch: 1 | loss: 0.3950968\n",
      "\tspeed: 0.0240s/iter; left time: 25.7793s\n",
      "Epoch: 1 cost time: 5.115987539291382\n",
      "Epoch: 1, Steps: 212 | Train Loss: 0.4678225 Vali Loss: 0.2642722 Test Loss: 0.2879914\n",
      "Validation loss decreased (inf --> 0.264272).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5292869\n",
      "\tspeed: 0.0389s/iter; left time: 37.3440s\n",
      "\titers: 200, epoch: 2 | loss: 0.1976936\n",
      "\tspeed: 0.0237s/iter; left time: 20.4412s\n",
      "Epoch: 2 cost time: 5.157712459564209\n",
      "Epoch: 2, Steps: 212 | Train Loss: 0.3512096 Vali Loss: 0.2334855 Test Loss: 0.2772494\n",
      "Validation loss decreased (0.264272 --> 0.233485).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2142501\n",
      "\tspeed: 0.0385s/iter; left time: 28.8271s\n",
      "\titers: 200, epoch: 3 | loss: 0.1921144\n",
      "\tspeed: 0.0261s/iter; left time: 16.9307s\n",
      "Epoch: 3 cost time: 5.263505697250366\n",
      "Epoch: 3, Steps: 212 | Train Loss: 0.2913129 Vali Loss: 0.2165049 Test Loss: 0.2359012\n",
      "Validation loss decreased (0.233485 --> 0.216505).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1159160\n",
      "\tspeed: 0.0389s/iter; left time: 20.9123s\n",
      "\titers: 200, epoch: 4 | loss: 0.1779505\n",
      "\tspeed: 0.0253s/iter; left time: 11.0656s\n",
      "Epoch: 4 cost time: 5.254295825958252\n",
      "Epoch: 4, Steps: 212 | Train Loss: 0.2613559 Vali Loss: 0.2232423 Test Loss: 0.2254653\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2033341\n",
      "\tspeed: 0.0374s/iter; left time: 12.1606s\n",
      "\titers: 200, epoch: 5 | loss: 0.1667524\n",
      "\tspeed: 0.0233s/iter; left time: 5.2316s\n",
      "Epoch: 5 cost time: 5.013173341751099\n",
      "Epoch: 5, Steps: 212 | Train Loss: 0.2433791 Vali Loss: 0.2138936 Test Loss: 0.2336686\n",
      "Validation loss decreased (0.216505 --> 0.213894).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.4453170\n",
      "\tspeed: 0.0391s/iter; left time: 4.4196s\n",
      "\titers: 200, epoch: 6 | loss: 0.1497088\n",
      "\tspeed: 0.0206s/iter; left time: 0.2682s\n",
      "Epoch: 6 cost time: 4.750020980834961\n",
      "Epoch: 6, Steps: 212 | Train Loss: 0.2355284 Vali Loss: 0.2107140 Test Loss: 0.2335413\n",
      "Validation loss decreased (0.213894 --> 0.210714).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1772\n",
      "Test cost time: 0.5079s\n",
      "test shape: (55, 32, 6, 1) (55, 32, 6, 1)\n",
      "test shape: (1760, 6, 1) (1760, 6, 1)\n",
      "mse:0.2335612028837204, mae:0.3726073205471039\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1511.253173828125\n",
      "MAE:  29.97226905822754\n",
      "RMSE: 38.874839782714844\n",
      "MAPE: 0.26552483439445496\n",
      "MSPE: 0.1346733123064041\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6931\n",
      "[DEBUG] Original dataset length: 6931\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6809\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 2103\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1772\n",
      "\titers: 100, epoch: 1 | loss: 0.3143016\n",
      "\tspeed: 0.0236s/iter; left time: 27.6363s\n",
      "\titers: 200, epoch: 1 | loss: 0.2205226\n",
      "\tspeed: 0.0241s/iter; left time: 25.8606s\n",
      "Epoch: 1 cost time: 5.067504405975342\n",
      "Epoch: 1, Steps: 212 | Train Loss: 0.4513948 Vali Loss: 0.2688808 Test Loss: 0.2292626\n",
      "Validation loss decreased (inf --> 0.268881).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1858135\n",
      "\tspeed: 0.0398s/iter; left time: 38.2460s\n",
      "\titers: 200, epoch: 2 | loss: 0.6336803\n",
      "\tspeed: 0.0260s/iter; left time: 22.4111s\n",
      "Epoch: 2 cost time: 5.318290948867798\n",
      "Epoch: 2, Steps: 212 | Train Loss: 0.3376681 Vali Loss: 0.2559454 Test Loss: 0.2934365\n",
      "Validation loss decreased (0.268881 --> 0.255945).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3320358\n",
      "\tspeed: 0.0383s/iter; left time: 28.7071s\n",
      "\titers: 200, epoch: 3 | loss: 0.2544699\n",
      "\tspeed: 0.0247s/iter; left time: 16.0334s\n",
      "Epoch: 3 cost time: 5.255045175552368\n",
      "Epoch: 3, Steps: 212 | Train Loss: 0.2873773 Vali Loss: 0.2197958 Test Loss: 0.2079013\n",
      "Validation loss decreased (0.255945 --> 0.219796).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1803062\n",
      "\tspeed: 0.0399s/iter; left time: 21.4019s\n",
      "\titers: 200, epoch: 4 | loss: 0.3551810\n",
      "\tspeed: 0.0253s/iter; left time: 11.0637s\n",
      "Epoch: 4 cost time: 5.392748594284058\n",
      "Epoch: 4, Steps: 212 | Train Loss: 0.2534570 Vali Loss: 0.2250574 Test Loss: 0.2363113\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1702367\n",
      "\tspeed: 0.0395s/iter; left time: 12.8279s\n",
      "\titers: 200, epoch: 5 | loss: 0.1878346\n",
      "\tspeed: 0.0240s/iter; left time: 5.3907s\n",
      "Epoch: 5 cost time: 5.163343906402588\n",
      "Epoch: 5, Steps: 212 | Train Loss: 0.2367022 Vali Loss: 0.2308401 Test Loss: 0.2563651\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1481029\n",
      "\tspeed: 0.0379s/iter; left time: 4.2833s\n",
      "\titers: 200, epoch: 6 | loss: 0.1466186\n",
      "\tspeed: 0.0248s/iter; left time: 0.3225s\n",
      "Epoch: 6 cost time: 5.204195022583008\n",
      "Epoch: 6, Steps: 212 | Train Loss: 0.2284177 Vali Loss: 0.2313734 Test Loss: 0.2576924\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1772\n",
      "Test cost time: 0.5007s\n",
      "test shape: (55, 32, 6, 1) (55, 32, 6, 1)\n",
      "test shape: (1760, 6, 1) (1760, 6, 1)\n",
      "mse:0.20704761147499084, mae:0.3542596399784088\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1339.697509765625\n",
      "MAE:  28.49639892578125\n",
      "RMSE: 36.60187911987305\n",
      "MAPE: 0.26861372590065\n",
      "MSPE: 0.23894844949245453\n",
      ">>>>>>>Running time saved<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Running seq_len=72\n",
      "Args in experiment:\n",
      "Namespace(model='informer', data='traffic_after_covid', root_path='../', data_path='traffic_after_covid.csv', features='S', target='flow', freq='h', checkpoints='./checkpoints/', seq_len=72, label_len=24, pred_len=6, enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=2, d_layers=1, s_layers=[3, 2, 1], d_ff=2048, factor=5, padding=0, distil=True, dropout=0.05, attn='prob', embed='timeF', activation='gelu', output_attention=False, do_predict=False, mix=True, cols=None, num_workers=0, itr=10, train_epochs=6, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, inverse=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', detail_freq='h')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6907\n",
      "[DEBUG] Original dataset length: 6907\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6737\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 2031\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1700\n",
      "\titers: 100, epoch: 1 | loss: 0.4625257\n",
      "\tspeed: 0.0403s/iter; left time: 46.8363s\n",
      "\titers: 200, epoch: 1 | loss: 0.2770066\n",
      "\tspeed: 0.0254s/iter; left time: 26.9788s\n",
      "Epoch: 1 cost time: 5.960400342941284\n",
      "Epoch: 1, Steps: 210 | Train Loss: 0.4529612 Vali Loss: 0.2359484 Test Loss: 0.1800160\n",
      "Validation loss decreased (inf --> 0.235948).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2796887\n",
      "\tspeed: 0.0419s/iter; left time: 39.8457s\n",
      "\titers: 200, epoch: 2 | loss: 0.2077676\n",
      "\tspeed: 0.0287s/iter; left time: 24.3855s\n",
      "Epoch: 2 cost time: 5.8287317752838135\n",
      "Epoch: 2, Steps: 210 | Train Loss: 0.3409866 Vali Loss: 0.2513146 Test Loss: 0.1877697\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2309759\n",
      "\tspeed: 0.0401s/iter; left time: 29.7015s\n",
      "\titers: 200, epoch: 3 | loss: 0.1453035\n",
      "\tspeed: 0.0262s/iter; left time: 16.7653s\n",
      "Epoch: 3 cost time: 5.553554058074951\n",
      "Epoch: 3, Steps: 210 | Train Loss: 0.2794333 Vali Loss: 0.2139244 Test Loss: 0.1945928\n",
      "Validation loss decreased (0.235948 --> 0.213924).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1917292\n",
      "\tspeed: 0.0413s/iter; left time: 21.9075s\n",
      "\titers: 200, epoch: 4 | loss: 0.2012913\n",
      "\tspeed: 0.0277s/iter; left time: 11.9352s\n",
      "Epoch: 4 cost time: 5.644661903381348\n",
      "Epoch: 4, Steps: 210 | Train Loss: 0.2542590 Vali Loss: 0.2109412 Test Loss: 0.1873426\n",
      "Validation loss decreased (0.213924 --> 0.210941).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3626400\n",
      "\tspeed: 0.0418s/iter; left time: 13.4195s\n",
      "\titers: 200, epoch: 5 | loss: 0.1658583\n",
      "\tspeed: 0.0255s/iter; left time: 5.6390s\n",
      "Epoch: 5 cost time: 5.480419874191284\n",
      "Epoch: 5, Steps: 210 | Train Loss: 0.2374977 Vali Loss: 0.2268320 Test Loss: 0.2107965\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2416522\n",
      "\tspeed: 0.0409s/iter; left time: 4.5353s\n",
      "\titers: 200, epoch: 6 | loss: 0.1618692\n",
      "\tspeed: 0.0271s/iter; left time: 0.2980s\n",
      "Epoch: 6 cost time: 5.7001793384552\n",
      "Epoch: 6, Steps: 210 | Train Loss: 0.2257553 Vali Loss: 0.2207843 Test Loss: 0.2101861\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1700\n",
      "Test cost time: 0.6126s\n",
      "test shape: (53, 32, 6, 1) (53, 32, 6, 1)\n",
      "test shape: (1696, 6, 1) (1696, 6, 1)\n",
      "mse:0.1865285187959671, mae:0.3282296657562256\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1206.9290771484375\n",
      "MAE:  26.402559280395508\n",
      "RMSE: 34.74088668823242\n",
      "MAPE: 0.23865485191345215\n",
      "MSPE: 0.12895378470420837\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6907\n",
      "[DEBUG] Original dataset length: 6907\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6737\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 2031\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1700\n",
      "\titers: 100, epoch: 1 | loss: 0.4482923\n",
      "\tspeed: 0.0263s/iter; left time: 30.5376s\n",
      "\titers: 200, epoch: 1 | loss: 0.2939540\n",
      "\tspeed: 0.0255s/iter; left time: 27.0411s\n",
      "Epoch: 1 cost time: 5.438552618026733\n",
      "Epoch: 1, Steps: 210 | Train Loss: 0.4703400 Vali Loss: 0.2512165 Test Loss: 0.2779967\n",
      "Validation loss decreased (inf --> 0.251217).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3030589\n",
      "\tspeed: 0.0399s/iter; left time: 37.9012s\n",
      "\titers: 200, epoch: 2 | loss: 0.2423451\n",
      "\tspeed: 0.0270s/iter; left time: 23.0195s\n",
      "Epoch: 2 cost time: 5.510112524032593\n",
      "Epoch: 2, Steps: 210 | Train Loss: 0.3451410 Vali Loss: 0.2226939 Test Loss: 0.2618420\n",
      "Validation loss decreased (0.251217 --> 0.222694).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2569661\n",
      "\tspeed: 0.0426s/iter; left time: 31.5691s\n",
      "\titers: 200, epoch: 3 | loss: 0.2756438\n",
      "\tspeed: 0.0262s/iter; left time: 16.7806s\n",
      "Epoch: 3 cost time: 5.6293065547943115\n",
      "Epoch: 3, Steps: 210 | Train Loss: 0.2936688 Vali Loss: 0.2191145 Test Loss: 0.2448035\n",
      "Validation loss decreased (0.222694 --> 0.219114).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2097249\n",
      "\tspeed: 0.0408s/iter; left time: 21.6691s\n",
      "\titers: 200, epoch: 4 | loss: 0.1912603\n",
      "\tspeed: 0.0255s/iter; left time: 10.9933s\n",
      "Epoch: 4 cost time: 5.362566709518433\n",
      "Epoch: 4, Steps: 210 | Train Loss: 0.2630308 Vali Loss: 0.2222335 Test Loss: 0.2564479\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2696223\n",
      "\tspeed: 0.0414s/iter; left time: 13.3039s\n",
      "\titers: 200, epoch: 5 | loss: 0.1324687\n",
      "\tspeed: 0.0274s/iter; left time: 6.0624s\n",
      "Epoch: 5 cost time: 5.776872873306274\n",
      "Epoch: 5, Steps: 210 | Train Loss: 0.2475785 Vali Loss: 0.2062287 Test Loss: 0.2130722\n",
      "Validation loss decreased (0.219114 --> 0.206229).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2257795\n",
      "\tspeed: 0.0418s/iter; left time: 4.6381s\n",
      "\titers: 200, epoch: 6 | loss: 0.2872845\n",
      "\tspeed: 0.0259s/iter; left time: 0.2848s\n",
      "Epoch: 6 cost time: 5.481824636459351\n",
      "Epoch: 6, Steps: 210 | Train Loss: 0.2383449 Vali Loss: 0.2146436 Test Loss: 0.2477017\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1700\n",
      "Test cost time: 0.5494s\n",
      "test shape: (53, 32, 6, 1) (53, 32, 6, 1)\n",
      "test shape: (1696, 6, 1) (1696, 6, 1)\n",
      "mse:0.21106182038784027, mae:0.3563579320907593\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1365.6712646484375\n",
      "MAE:  28.665180206298828\n",
      "RMSE: 36.95499038696289\n",
      "MAPE: 0.26677262783050537\n",
      "MSPE: 0.2120748609304428\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6907\n",
      "[DEBUG] Original dataset length: 6907\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6737\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 2031\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1700\n",
      "\titers: 100, epoch: 1 | loss: 0.4663399\n",
      "\tspeed: 0.0263s/iter; left time: 30.4883s\n",
      "\titers: 200, epoch: 1 | loss: 0.3534878\n",
      "\tspeed: 0.0286s/iter; left time: 30.3640s\n",
      "Epoch: 1 cost time: 5.7719385623931885\n",
      "Epoch: 1, Steps: 210 | Train Loss: 0.4686670 Vali Loss: 0.2471717 Test Loss: 0.2241347\n",
      "Validation loss decreased (inf --> 0.247172).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1809949\n",
      "\tspeed: 0.0393s/iter; left time: 37.3982s\n",
      "\titers: 200, epoch: 2 | loss: 0.1964261\n",
      "\tspeed: 0.0254s/iter; left time: 21.6462s\n",
      "Epoch: 2 cost time: 5.309023380279541\n",
      "Epoch: 2, Steps: 210 | Train Loss: 0.3453135 Vali Loss: 0.2509233 Test Loss: 0.3208237\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 200, epoch: 6 | loss: 0.1705361\n",
      "\tspeed: 0.0265s/iter; left time: 0.2914s\n",
      "Epoch: 6 cost time: 5.716252326965332\n",
      "Epoch: 6, Steps: 210 | Train Loss: 0.2222427 Vali Loss: 0.2102430 Test Loss: 0.2072414\n",
      "Validation loss decreased (0.212951 --> 0.210243).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1700\n",
      "Test cost time: 0.5529s\n",
      "test shape: (53, 32, 6, 1) (53, 32, 6, 1)\n",
      "test shape: (1696, 6, 1) (1696, 6, 1)\n",
      "mse:0.2057671695947647, mae:0.3518877923488617\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1331.4124755859375\n",
      "MAE:  28.30560874938965\n",
      "RMSE: 36.488525390625\n",
      "MAPE: 0.2683066129684448\n",
      "MSPE: 0.1899678260087967\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6907\n",
      "[DEBUG] Original dataset length: 6907\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6737\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 2031\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1700\n",
      "\titers: 100, epoch: 1 | loss: 0.3163131\n",
      "\tspeed: 0.0291s/iter; left time: 33.8068s\n",
      "\titers: 200, epoch: 1 | loss: 0.5129413\n",
      "\tspeed: 0.0280s/iter; left time: 29.6934s\n",
      "Epoch: 1 cost time: 6.043952465057373\n",
      "Epoch: 1, Steps: 210 | Train Loss: 0.4521462 Vali Loss: 0.2618688 Test Loss: 0.2501191\n",
      "Validation loss decreased (inf --> 0.261869).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1585929\n",
      "\tspeed: 0.0473s/iter; left time: 45.0270s\n",
      "\titers: 200, epoch: 2 | loss: 0.1739568\n",
      "\tspeed: 0.0284s/iter; left time: 24.1598s\n",
      "Epoch: 2 cost time: 6.094632148742676\n",
      "Epoch: 2, Steps: 210 | Train Loss: 0.3362913 Vali Loss: 0.2311594 Test Loss: 0.2637455\n",
      "Validation loss decreased (0.261869 --> 0.231159).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2328160\n",
      "\tspeed: 0.0449s/iter; left time: 33.2466s\n",
      "\titers: 200, epoch: 3 | loss: 0.1677213\n",
      "\tspeed: 0.0259s/iter; left time: 16.5849s\n",
      "Epoch: 3 cost time: 5.650326728820801\n",
      "Epoch: 3, Steps: 210 | Train Loss: 0.2847118 Vali Loss: 0.2067180 Test Loss: 0.2048585\n",
      "Validation loss decreased (0.231159 --> 0.206718).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.5323437\n",
      "\tspeed: 0.0402s/iter; left time: 21.3615s\n",
      "\titers: 200, epoch: 4 | loss: 0.3330250\n",
      "\tspeed: 0.0238s/iter; left time: 10.2411s\n",
      "Epoch: 4 cost time: 5.132784128189087\n",
      "Epoch: 4, Steps: 210 | Train Loss: 0.2576916 Vali Loss: 0.2365530 Test Loss: 0.2559262\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1110314\n",
      "\tspeed: 0.0353s/iter; left time: 11.3396s\n",
      "\titers: 200, epoch: 5 | loss: 0.6031935\n",
      "\tspeed: 0.0269s/iter; left time: 5.9413s\n",
      "Epoch: 5 cost time: 5.243958234786987\n",
      "Epoch: 5, Steps: 210 | Train Loss: 0.2405965 Vali Loss: 0.2050513 Test Loss: 0.2035559\n",
      "Validation loss decreased (0.206718 --> 0.205051).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3544803\n",
      "\tspeed: 0.0407s/iter; left time: 4.5165s\n",
      "\titers: 200, epoch: 6 | loss: 0.1476271\n",
      "\tspeed: 0.0260s/iter; left time: 0.2859s\n",
      "Epoch: 6 cost time: 5.445548057556152\n",
      "Epoch: 6, Steps: 210 | Train Loss: 0.2325474 Vali Loss: 0.2055807 Test Loss: 0.2057540\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1700\n",
      "Test cost time: 0.5152s\n",
      "test shape: (53, 32, 6, 1) (53, 32, 6, 1)\n",
      "test shape: (1696, 6, 1) (1696, 6, 1)\n",
      "mse:0.2050410807132721, mae:0.35194480419158936\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1326.7142333984375\n",
      "MAE:  28.31019401550293\n",
      "RMSE: 36.42408752441406\n",
      "MAPE: 0.26224732398986816\n",
      "MSPE: 0.17786546051502228\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6907\n",
      "[DEBUG] Original dataset length: 6907\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6737\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 2031\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1700\n",
      "\titers: 100, epoch: 1 | loss: 0.5936497\n",
      "\tspeed: 0.0264s/iter; left time: 30.6104s\n",
      "\titers: 200, epoch: 1 | loss: 0.2159920\n",
      "\tspeed: 0.0286s/iter; left time: 30.3394s\n",
      "Epoch: 1 cost time: 5.771627426147461\n",
      "Epoch: 1, Steps: 210 | Train Loss: 0.4633402 Vali Loss: 0.2667791 Test Loss: 0.2702354\n",
      "Validation loss decreased (inf --> 0.266779).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2950492\n",
      "\tspeed: 0.0407s/iter; left time: 38.6832s\n",
      "\titers: 200, epoch: 2 | loss: 0.3205973\n",
      "\tspeed: 0.0255s/iter; left time: 21.6754s\n",
      "Epoch: 2 cost time: 5.376547574996948\n",
      "Epoch: 2, Steps: 210 | Train Loss: 0.3359268 Vali Loss: 0.2355951 Test Loss: 0.2032601\n",
      "Validation loss decreased (0.266779 --> 0.235595).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2663478\n",
      "\tspeed: 0.0397s/iter; left time: 29.3981s\n",
      "\titers: 200, epoch: 3 | loss: 0.8375865\n",
      "\tspeed: 0.0267s/iter; left time: 17.0855s\n",
      "Epoch: 3 cost time: 5.504775047302246\n",
      "Epoch: 3, Steps: 210 | Train Loss: 0.2910758 Vali Loss: 0.2332239 Test Loss: 0.3037654\n",
      "Validation loss decreased (0.235595 --> 0.233224).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2492638\n",
      "\tspeed: 0.0423s/iter; left time: 22.4521s\n",
      "\titers: 200, epoch: 4 | loss: 0.1884495\n",
      "\tspeed: 0.0265s/iter; left time: 11.4260s\n",
      "Epoch: 4 cost time: 5.518310785293579\n",
      "Epoch: 4, Steps: 210 | Train Loss: 0.2613226 Vali Loss: 0.2174887 Test Loss: 0.2385805\n",
      "Validation loss decreased (0.233224 --> 0.217489).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1308192\n",
      "\tspeed: 0.0410s/iter; left time: 13.1450s\n",
      "\titers: 200, epoch: 5 | loss: 0.1599402\n",
      "\tspeed: 0.0263s/iter; left time: 5.8168s\n",
      "Epoch: 5 cost time: 5.510134220123291\n",
      "Epoch: 5, Steps: 210 | Train Loss: 0.2407416 Vali Loss: 0.2297779 Test Loss: 0.2727599\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2140291\n",
      "\tspeed: 0.0412s/iter; left time: 4.5756s\n",
      "\titers: 200, epoch: 6 | loss: 0.3101321\n",
      "\tspeed: 0.0260s/iter; left time: 0.2864s\n",
      "Epoch: 6 cost time: 5.60467267036438\n",
      "Epoch: 6, Steps: 210 | Train Loss: 0.2329680 Vali Loss: 0.2182925 Test Loss: 0.2641971\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1700\n",
      "Test cost time: 0.5044s\n",
      "test shape: (53, 32, 6, 1) (53, 32, 6, 1)\n",
      "test shape: (1696, 6, 1) (1696, 6, 1)\n",
      "mse:0.2401258796453476, mae:0.3819730281829834\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1553.729736328125\n",
      "MAE:  30.72564125061035\n",
      "RMSE: 39.41737747192383\n",
      "MAPE: 0.2862931787967682\n",
      "MSPE: 0.19856782257556915\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6907\n",
      "[DEBUG] Original dataset length: 6907\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6737\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 2031\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1700\n",
      "\titers: 100, epoch: 1 | loss: 0.2055777\n",
      "\tspeed: 0.0259s/iter; left time: 30.1035s\n",
      "\titers: 200, epoch: 1 | loss: 0.2766789\n",
      "\tspeed: 0.0254s/iter; left time: 26.9394s\n",
      "Epoch: 1 cost time: 5.385910987854004\n",
      "Epoch: 1, Steps: 210 | Train Loss: 0.4595635 Vali Loss: 0.3260448 Test Loss: 0.2364220\n",
      "Validation loss decreased (inf --> 0.326045).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2393774\n",
      "\tspeed: 0.0408s/iter; left time: 38.8209s\n",
      "\titers: 200, epoch: 2 | loss: 0.3054100\n",
      "\tspeed: 0.0269s/iter; left time: 22.8576s\n",
      "Epoch: 2 cost time: 5.574346542358398\n",
      "Epoch: 2, Steps: 210 | Train Loss: 0.3490957 Vali Loss: 0.2391103 Test Loss: 0.2231900\n",
      "Validation loss decreased (0.326045 --> 0.239110).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3448477\n",
      "\tspeed: 0.0394s/iter; left time: 29.1691s\n",
      "\titers: 200, epoch: 3 | loss: 0.3806893\n",
      "\tspeed: 0.0283s/iter; left time: 18.1609s\n",
      "Epoch: 3 cost time: 5.59320855140686\n",
      "Epoch: 3, Steps: 210 | Train Loss: 0.2913387 Vali Loss: 0.2274532 Test Loss: 0.2602286\n",
      "Validation loss decreased (0.239110 --> 0.227453).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.5317705\n",
      "\tspeed: 0.0420s/iter; left time: 22.2839s\n",
      "\titers: 200, epoch: 4 | loss: 0.2951648\n",
      "\tspeed: 0.0267s/iter; left time: 11.4976s\n",
      "Epoch: 4 cost time: 5.5568788051605225\n",
      "Epoch: 4, Steps: 210 | Train Loss: 0.2682440 Vali Loss: 0.2345135 Test Loss: 0.2113393\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1937836\n",
      "\tspeed: 0.0395s/iter; left time: 12.6701s\n",
      "\titers: 200, epoch: 5 | loss: 0.1862708\n",
      "\tspeed: 0.0247s/iter; left time: 5.4666s\n",
      "Epoch: 5 cost time: 5.3434247970581055\n",
      "Epoch: 5, Steps: 210 | Train Loss: 0.2493409 Vali Loss: 0.2230679 Test Loss: 0.1986415\n",
      "Validation loss decreased (0.227453 --> 0.223068).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1159064\n",
      "\tspeed: 0.0402s/iter; left time: 4.4631s\n",
      "\titers: 200, epoch: 6 | loss: 0.2937322\n",
      "\tspeed: 0.0256s/iter; left time: 0.2811s\n",
      "Epoch: 6 cost time: 5.373409986495972\n",
      "Epoch: 6, Steps: 210 | Train Loss: 0.2391583 Vali Loss: 0.2090457 Test Loss: 0.1787826\n",
      "Validation loss decreased (0.223068 --> 0.209046).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1700\n",
      "Test cost time: 0.5343s\n",
      "test shape: (53, 32, 6, 1) (53, 32, 6, 1)\n",
      "test shape: (1696, 6, 1) (1696, 6, 1)\n",
      "mse:0.1798965185880661, mae:0.3255782127380371\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1164.016845703125\n",
      "MAE:  26.189281463623047\n",
      "RMSE: 34.11769104003906\n",
      "MAPE: 0.25307440757751465\n",
      "MSPE: 0.22559833526611328\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6907\n",
      "[DEBUG] Original dataset length: 6907\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6737\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 2031\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1700\n",
      "\titers: 100, epoch: 1 | loss: 0.6239879\n",
      "\tspeed: 0.0280s/iter; left time: 32.5472s\n",
      "\titers: 200, epoch: 1 | loss: 0.3069433\n",
      "\tspeed: 0.0261s/iter; left time: 27.6844s\n",
      "Epoch: 1 cost time: 5.6742658615112305\n",
      "Epoch: 1, Steps: 210 | Train Loss: 0.4641091 Vali Loss: 0.2379488 Test Loss: 0.2592501\n",
      "Validation loss decreased (inf --> 0.237949).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2510275\n",
      "\tspeed: 0.0403s/iter; left time: 38.2894s\n",
      "\titers: 200, epoch: 2 | loss: 0.3807706\n",
      "\tspeed: 0.0273s/iter; left time: 23.2631s\n",
      "Epoch: 2 cost time: 5.579884052276611\n",
      "Epoch: 2, Steps: 210 | Train Loss: 0.3310381 Vali Loss: 0.2259470 Test Loss: 0.2463323\n",
      "Validation loss decreased (0.237949 --> 0.225947).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2533996\n",
      "\tspeed: 0.0451s/iter; left time: 33.4240s\n",
      "\titers: 200, epoch: 3 | loss: 0.2339940\n",
      "\tspeed: 0.0300s/iter; left time: 19.1982s\n",
      "Epoch: 3 cost time: 6.192440986633301\n",
      "Epoch: 3, Steps: 210 | Train Loss: 0.2886464 Vali Loss: 0.2362402 Test Loss: 0.2761580\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2241046\n",
      "\tspeed: 0.0420s/iter; left time: 22.3126s\n",
      "\titers: 200, epoch: 4 | loss: 0.3639627\n",
      "\tspeed: 0.0268s/iter; left time: 11.5517s\n",
      "Epoch: 4 cost time: 5.7150774002075195\n",
      "Epoch: 4, Steps: 210 | Train Loss: 0.2570887 Vali Loss: 0.2184796 Test Loss: 0.2766021\n",
      "Validation loss decreased (0.225947 --> 0.218480).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1471989\n",
      "\tspeed: 0.0425s/iter; left time: 13.6325s\n",
      "\titers: 200, epoch: 5 | loss: 0.2138787\n",
      "\tspeed: 0.0270s/iter; left time: 5.9576s\n",
      "Epoch: 5 cost time: 5.738646984100342\n",
      "Epoch: 5, Steps: 210 | Train Loss: 0.2430226 Vali Loss: 0.2403413 Test Loss: 0.2970506\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2293034\n",
      "\tspeed: 0.0416s/iter; left time: 4.6228s\n",
      "\titers: 200, epoch: 6 | loss: 0.2280588\n",
      "\tspeed: 0.0265s/iter; left time: 0.2919s\n",
      "Epoch: 6 cost time: 5.675430536270142\n",
      "Epoch: 6, Steps: 210 | Train Loss: 0.2337190 Vali Loss: 0.2270590 Test Loss: 0.2621401\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1700\n",
      "Test cost time: 0.5149s\n",
      "test shape: (53, 32, 6, 1) (53, 32, 6, 1)\n",
      "test shape: (1696, 6, 1) (1696, 6, 1)\n",
      "mse:0.27726343274116516, mae:0.412030965089798\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1794.0274658203125\n",
      "MAE:  33.14348220825195\n",
      "RMSE: 42.355960845947266\n",
      "MAPE: 0.3075060546398163\n",
      "MSPE: 0.19775503873825073\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6907\n",
      "[DEBUG] Original dataset length: 6907\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6737\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 2031\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1700\n",
      "\titers: 100, epoch: 1 | loss: 0.5592067\n",
      "\tspeed: 0.0253s/iter; left time: 29.3548s\n",
      "\titers: 200, epoch: 1 | loss: 0.1935133\n",
      "\tspeed: 0.0264s/iter; left time: 28.0238s\n",
      "Epoch: 1 cost time: 5.428743124008179\n",
      "Epoch: 1, Steps: 210 | Train Loss: 0.4757841 Vali Loss: 0.2593895 Test Loss: 0.2232837\n",
      "Validation loss decreased (inf --> 0.259390).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2510242\n",
      "\tspeed: 0.0393s/iter; left time: 37.3393s\n",
      "\titers: 200, epoch: 2 | loss: 0.5536783\n",
      "\tspeed: 0.0248s/iter; left time: 21.1193s\n",
      "Epoch: 2 cost time: 5.184155702590942\n",
      "Epoch: 2, Steps: 210 | Train Loss: 0.3414545 Vali Loss: 0.2139175 Test Loss: 0.2350275\n",
      "Validation loss decreased (0.259390 --> 0.213918).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2246716\n",
      "\tspeed: 0.0406s/iter; left time: 30.0991s\n",
      "\titers: 200, epoch: 3 | loss: 0.1391098\n",
      "\tspeed: 0.0252s/iter; left time: 16.1594s\n",
      "Epoch: 3 cost time: 5.356802225112915\n",
      "Epoch: 3, Steps: 210 | Train Loss: 0.2899687 Vali Loss: 0.2385393 Test Loss: 0.2662710\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1661227\n",
      "\tspeed: 0.0409s/iter; left time: 21.7429s\n",
      "\titers: 200, epoch: 4 | loss: 0.2588603\n",
      "\tspeed: 0.0262s/iter; left time: 11.2846s\n",
      "Epoch: 4 cost time: 5.53034234046936\n",
      "Epoch: 4, Steps: 210 | Train Loss: 0.2622187 Vali Loss: 0.2389231 Test Loss: 0.3128350\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3195544\n",
      "\tspeed: 0.0394s/iter; left time: 12.6498s\n",
      "\titers: 200, epoch: 5 | loss: 0.2914354\n",
      "\tspeed: 0.0253s/iter; left time: 5.5936s\n",
      "Epoch: 5 cost time: 5.365303993225098\n",
      "Epoch: 5, Steps: 210 | Train Loss: 0.2463640 Vali Loss: 0.2205981 Test Loss: 0.2658748\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1700\n",
      "Test cost time: 0.5132s\n",
      "test shape: (53, 32, 6, 1) (53, 32, 6, 1)\n",
      "test shape: (1696, 6, 1) (1696, 6, 1)\n",
      "mse:0.2333381474018097, mae:0.371440052986145\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1509.8096923828125\n",
      "MAE:  29.87837791442871\n",
      "RMSE: 38.85626983642578\n",
      "MAPE: 0.2919074594974518\n",
      "MSPE: 0.2602265477180481\n",
      ">>>>>>>Running time saved<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Running seq_len=96\n",
      "Args in experiment:\n",
      "Namespace(model='informer', data='traffic_after_covid', root_path='../', data_path='traffic_after_covid.csv', features='S', target='flow', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=24, pred_len=6, enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=2, d_layers=1, s_layers=[3, 2, 1], d_ff=2048, factor=5, padding=0, distil=True, dropout=0.05, attn='prob', embed='timeF', activation='gelu', output_attention=False, do_predict=False, mix=True, cols=None, num_workers=0, itr=10, train_epochs=6, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, inverse=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', detail_freq='h')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6883\n",
      "[DEBUG] Original dataset length: 6883\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6665\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1959\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1628\n",
      "\titers: 100, epoch: 1 | loss: 0.2981547\n",
      "\tspeed: 0.0454s/iter; left time: 52.2187s\n",
      "\titers: 200, epoch: 1 | loss: 0.1983911\n",
      "\tspeed: 0.0288s/iter; left time: 30.2253s\n",
      "Epoch: 1 cost time: 6.761640310287476\n",
      "Epoch: 1, Steps: 208 | Train Loss: 0.4773811 Vali Loss: 0.2529981 Test Loss: 0.2930162\n",
      "Validation loss decreased (inf --> 0.252998).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2823138\n",
      "\tspeed: 0.0446s/iter; left time: 41.9388s\n",
      "\titers: 200, epoch: 2 | loss: 0.4986804\n",
      "\tspeed: 0.0303s/iter; left time: 25.5164s\n",
      "Epoch: 2 cost time: 6.1493775844573975\n",
      "Epoch: 2, Steps: 208 | Train Loss: 0.3471130 Vali Loss: 0.2347288 Test Loss: 0.3067385\n",
      "Validation loss decreased (0.252998 --> 0.234729).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2012626\n",
      "\tspeed: 0.0455s/iter; left time: 33.3351s\n",
      "\titers: 200, epoch: 3 | loss: 0.2238178\n",
      "\tspeed: 0.0281s/iter; left time: 17.8137s\n",
      "Epoch: 3 cost time: 6.0223612785339355\n",
      "Epoch: 3, Steps: 208 | Train Loss: 0.2866512 Vali Loss: 0.2077118 Test Loss: 0.2384585\n",
      "Validation loss decreased (0.234729 --> 0.207712).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2016658\n",
      "\tspeed: 0.0428s/iter; left time: 22.4454s\n",
      "\titers: 200, epoch: 4 | loss: 0.2438720\n",
      "\tspeed: 0.0303s/iter; left time: 12.8699s\n",
      "Epoch: 4 cost time: 6.007761478424072\n",
      "Epoch: 4, Steps: 208 | Train Loss: 0.2615688 Vali Loss: 0.2147417 Test Loss: 0.2554143\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1990754\n",
      "\tspeed: 0.0429s/iter; left time: 13.5948s\n",
      "\titers: 200, epoch: 5 | loss: 0.1306639\n",
      "\tspeed: 0.0280s/iter; left time: 6.0845s\n",
      "Epoch: 5 cost time: 5.917264461517334\n",
      "Epoch: 5, Steps: 208 | Train Loss: 0.2444368 Vali Loss: 0.2094051 Test Loss: 0.2463873\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1287848\n",
      "\tspeed: 0.0420s/iter; left time: 4.5749s\n",
      "\titers: 200, epoch: 6 | loss: 0.3476034\n",
      "\tspeed: 0.0293s/iter; left time: 0.2637s\n",
      "Epoch: 6 cost time: 6.010917663574219\n",
      "Epoch: 6, Steps: 208 | Train Loss: 0.2373718 Vali Loss: 0.2096563 Test Loss: 0.2459169\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1628\n",
      "Test cost time: 0.5133s\n",
      "test shape: (50, 32, 6, 1) (50, 32, 6, 1)\n",
      "test shape: (1600, 6, 1) (1600, 6, 1)\n",
      "mse:0.2386070191860199, mae:0.3762994408607483\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1543.902099609375\n",
      "MAE:  30.269264221191406\n",
      "RMSE: 39.292518615722656\n",
      "MAPE: 0.28806859254837036\n",
      "MSPE: 0.22630716860294342\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6883\n",
      "[DEBUG] Original dataset length: 6883\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6665\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1959\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1628\n",
      "\titers: 100, epoch: 1 | loss: 0.3520072\n",
      "\tspeed: 0.0289s/iter; left time: 33.1804s\n",
      "\titers: 200, epoch: 1 | loss: 0.3275375\n",
      "\tspeed: 0.0298s/iter; left time: 31.2450s\n",
      "Epoch: 1 cost time: 6.120724678039551\n",
      "Epoch: 1, Steps: 208 | Train Loss: 0.4890859 Vali Loss: 0.2376315 Test Loss: 0.2910177\n",
      "Validation loss decreased (inf --> 0.237631).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5545331\n",
      "\tspeed: 0.0449s/iter; left time: 42.2444s\n",
      "\titers: 200, epoch: 2 | loss: 0.2384491\n",
      "\tspeed: 0.0296s/iter; left time: 24.8645s\n",
      "Epoch: 2 cost time: 6.171056509017944\n",
      "Epoch: 2, Steps: 208 | Train Loss: 0.3511703 Vali Loss: 0.2299646 Test Loss: 0.2276492\n",
      "Validation loss decreased (0.237631 --> 0.229965).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3293180\n",
      "\tspeed: 0.0451s/iter; left time: 33.0342s\n",
      "\titers: 200, epoch: 3 | loss: 0.2213334\n",
      "\tspeed: 0.0298s/iter; left time: 18.8472s\n",
      "Epoch: 3 cost time: 6.039942979812622\n",
      "Epoch: 3, Steps: 208 | Train Loss: 0.2944219 Vali Loss: 0.2181447 Test Loss: 0.1977663\n",
      "Validation loss decreased (0.229965 --> 0.218145).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1481644\n",
      "\tspeed: 0.0421s/iter; left time: 22.1042s\n",
      "\titers: 200, epoch: 4 | loss: 0.1709232\n",
      "\tspeed: 0.0266s/iter; left time: 11.3212s\n",
      "Epoch: 4 cost time: 5.5892415046691895\n",
      "Epoch: 4, Steps: 208 | Train Loss: 0.2606249 Vali Loss: 0.2303381 Test Loss: 0.3000790\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.8251015\n",
      "\tspeed: 0.0448s/iter; left time: 14.2055s\n",
      "\titers: 200, epoch: 5 | loss: 0.2742540\n",
      "\tspeed: 0.0321s/iter; left time: 6.9714s\n",
      "Epoch: 5 cost time: 6.518912076950073\n",
      "Epoch: 5, Steps: 208 | Train Loss: 0.2434607 Vali Loss: 0.2106136 Test Loss: 0.2620849\n",
      "Validation loss decreased (0.218145 --> 0.210614).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2283429\n",
      "\tspeed: 0.0439s/iter; left time: 4.7865s\n",
      "\titers: 200, epoch: 6 | loss: 0.2057499\n",
      "\tspeed: 0.0272s/iter; left time: 0.2444s\n",
      "Epoch: 6 cost time: 5.781976938247681\n",
      "Epoch: 6, Steps: 208 | Train Loss: 0.2327979 Vali Loss: 0.2215110 Test Loss: 0.2803303\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1628\n",
      "Test cost time: 0.5444s\n",
      "test shape: (50, 32, 6, 1) (50, 32, 6, 1)\n",
      "test shape: (1600, 6, 1) (1600, 6, 1)\n",
      "mse:0.26053065061569214, mae:0.3998233377933502\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1685.758544921875\n",
      "MAE:  32.16150665283203\n",
      "RMSE: 41.05799102783203\n",
      "MAPE: 0.29097437858581543\n",
      "MSPE: 0.19210538268089294\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6883\n",
      "[DEBUG] Original dataset length: 6883\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6665\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1959\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1628\n",
      "\titers: 100, epoch: 1 | loss: 0.2232625\n",
      "\tspeed: 0.0284s/iter; left time: 32.6307s\n",
      "\titers: 200, epoch: 1 | loss: 0.2234761\n",
      "\tspeed: 0.0287s/iter; left time: 30.1063s\n",
      "Epoch: 1 cost time: 5.943903923034668\n",
      "Epoch: 1, Steps: 208 | Train Loss: 0.5068327 Vali Loss: 0.2729237 Test Loss: 0.3174922\n",
      "Validation loss decreased (inf --> 0.272924).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3503035\n",
      "\tspeed: 0.0421s/iter; left time: 39.6105s\n",
      "\titers: 200, epoch: 2 | loss: 0.2422067\n",
      "\tspeed: 0.0274s/iter; left time: 23.0500s\n",
      "Epoch: 2 cost time: 5.7210657596588135\n",
      "Epoch: 2, Steps: 208 | Train Loss: 0.3497229 Vali Loss: 0.2716765 Test Loss: 0.1942648\n",
      "Validation loss decreased (0.272924 --> 0.271677).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2375133\n",
      "\tspeed: 0.0446s/iter; left time: 32.6702s\n",
      "\titers: 200, epoch: 3 | loss: 0.2119699\n",
      "\tspeed: 0.0276s/iter; left time: 17.4682s\n",
      "Epoch: 3 cost time: 5.94283390045166\n",
      "Epoch: 3, Steps: 208 | Train Loss: 0.2909989 Vali Loss: 0.2339911 Test Loss: 0.2153931\n",
      "Validation loss decreased (0.271677 --> 0.233991).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2289164\n",
      "\tspeed: 0.0427s/iter; left time: 22.3954s\n",
      "\titers: 200, epoch: 4 | loss: 0.1894915\n",
      "\tspeed: 0.0291s/iter; left time: 12.3752s\n",
      "Epoch: 4 cost time: 5.916109800338745\n",
      "Epoch: 4, Steps: 208 | Train Loss: 0.2667507 Vali Loss: 0.2181877 Test Loss: 0.2995796\n",
      "Validation loss decreased (0.233991 --> 0.218188).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2234181\n",
      "\tspeed: 0.0437s/iter; left time: 13.8541s\n",
      "\titers: 200, epoch: 5 | loss: 0.2025796\n",
      "\tspeed: 0.0286s/iter; left time: 6.2162s\n",
      "Epoch: 5 cost time: 5.925762176513672\n",
      "Epoch: 5, Steps: 208 | Train Loss: 0.2479085 Vali Loss: 0.2160394 Test Loss: 0.2845470\n",
      "Validation loss decreased (0.218188 --> 0.216039).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.4380566\n",
      "\tspeed: 0.0428s/iter; left time: 4.6631s\n",
      "\titers: 200, epoch: 6 | loss: 0.2112242\n",
      "\tspeed: 0.0279s/iter; left time: 0.2512s\n",
      "Epoch: 6 cost time: 5.795063495635986\n",
      "Epoch: 6, Steps: 208 | Train Loss: 0.2400129 Vali Loss: 0.2089335 Test Loss: 0.2869777\n",
      "Validation loss decreased (0.216039 --> 0.208933).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1628\n",
      "Test cost time: 0.5159s\n",
      "test shape: (50, 32, 6, 1) (50, 32, 6, 1)\n",
      "test shape: (1600, 6, 1) (1600, 6, 1)\n",
      "mse:0.28650781512260437, mae:0.4206206500530243\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1853.8433837890625\n",
      "MAE:  33.83442687988281\n",
      "RMSE: 43.05628204345703\n",
      "MAPE: 0.3137625753879547\n",
      "MSPE: 0.2487325519323349\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6883\n",
      "[DEBUG] Original dataset length: 6883\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6665\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1959\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1628\n",
      "\titers: 100, epoch: 1 | loss: 0.3848621\n",
      "\tspeed: 0.0293s/iter; left time: 33.6848s\n",
      "\titers: 200, epoch: 1 | loss: 0.3436210\n",
      "\tspeed: 0.0295s/iter; left time: 30.9832s\n",
      "Epoch: 1 cost time: 6.110512971878052\n",
      "Epoch: 1, Steps: 208 | Train Loss: 0.4662911 Vali Loss: 0.2431899 Test Loss: 0.2520760\n",
      "Validation loss decreased (inf --> 0.243190).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2096965\n",
      "\tspeed: 0.0434s/iter; left time: 40.8410s\n",
      "\titers: 200, epoch: 2 | loss: 0.3276133\n",
      "\tspeed: 0.0275s/iter; left time: 23.1410s\n",
      "Epoch: 2 cost time: 5.818617820739746\n",
      "Epoch: 2, Steps: 208 | Train Loss: 0.3357769 Vali Loss: 0.2364611 Test Loss: 0.2340904\n",
      "Validation loss decreased (0.243190 --> 0.236461).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2060016\n",
      "\tspeed: 0.0424s/iter; left time: 31.0543s\n",
      "\titers: 200, epoch: 3 | loss: 0.3198140\n",
      "\tspeed: 0.0297s/iter; left time: 18.7975s\n",
      "Epoch: 3 cost time: 5.972231149673462\n",
      "Epoch: 3, Steps: 208 | Train Loss: 0.2883364 Vali Loss: 0.2295006 Test Loss: 0.2341514\n",
      "Validation loss decreased (0.236461 --> 0.229501).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.4324708\n",
      "\tspeed: 0.0420s/iter; left time: 22.0574s\n",
      "\titers: 200, epoch: 4 | loss: 0.1242778\n",
      "\tspeed: 0.0272s/iter; left time: 11.5727s\n",
      "Epoch: 4 cost time: 5.646748781204224\n",
      "Epoch: 4, Steps: 208 | Train Loss: 0.2632903 Vali Loss: 0.2253441 Test Loss: 0.2450020\n",
      "Validation loss decreased (0.229501 --> 0.225344).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2251445\n",
      "\tspeed: 0.0424s/iter; left time: 13.4524s\n",
      "\titers: 200, epoch: 5 | loss: 0.5636913\n",
      "\tspeed: 0.0286s/iter; left time: 6.2147s\n",
      "Epoch: 5 cost time: 5.896704912185669\n",
      "Epoch: 5, Steps: 208 | Train Loss: 0.2428529 Vali Loss: 0.2248512 Test Loss: 0.2348746\n",
      "Validation loss decreased (0.225344 --> 0.224851).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1577908\n",
      "\tspeed: 0.0441s/iter; left time: 4.8092s\n",
      "\titers: 200, epoch: 6 | loss: 0.2129937\n",
      "\tspeed: 0.0260s/iter; left time: 0.2342s\n",
      "Epoch: 6 cost time: 5.597584009170532\n",
      "Epoch: 6, Steps: 208 | Train Loss: 0.2343393 Vali Loss: 0.2144405 Test Loss: 0.2231531\n",
      "Validation loss decreased (0.224851 --> 0.214440).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1628\n",
      "Test cost time: 0.5149s\n",
      "test shape: (50, 32, 6, 1) (50, 32, 6, 1)\n",
      "test shape: (1600, 6, 1) (1600, 6, 1)\n",
      "mse:0.22422215342521667, mae:0.3708977699279785\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1450.8250732421875\n",
      "MAE:  29.834758758544922\n",
      "RMSE: 38.089698791503906\n",
      "MAPE: 0.276442289352417\n",
      "MSPE: 0.19117793440818787\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6883\n",
      "[DEBUG] Original dataset length: 6883\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6665\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1959\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1628\n",
      "\titers: 100, epoch: 1 | loss: 0.2900329\n",
      "\tspeed: 0.0301s/iter; left time: 34.6093s\n",
      "\titers: 200, epoch: 1 | loss: 0.4324976\n",
      "\tspeed: 0.0291s/iter; left time: 30.5130s\n",
      "Epoch: 1 cost time: 6.179968357086182\n",
      "Epoch: 1, Steps: 208 | Train Loss: 0.4807529 Vali Loss: 0.2608418 Test Loss: 0.2173091\n",
      "Validation loss decreased (inf --> 0.260842).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3299838\n",
      "\tspeed: 0.0437s/iter; left time: 41.1068s\n",
      "\titers: 200, epoch: 2 | loss: 0.3535943\n",
      "\tspeed: 0.0282s/iter; left time: 23.7192s\n",
      "Epoch: 2 cost time: 5.804328918457031\n",
      "Epoch: 2, Steps: 208 | Train Loss: 0.3432966 Vali Loss: 0.2477700 Test Loss: 0.3130846\n",
      "Validation loss decreased (0.260842 --> 0.247770).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1777608\n",
      "\tspeed: 0.0427s/iter; left time: 31.2897s\n",
      "\titers: 200, epoch: 3 | loss: 0.2266776\n",
      "\tspeed: 0.0297s/iter; left time: 18.7714s\n",
      "Epoch: 3 cost time: 5.957107782363892\n",
      "Epoch: 3, Steps: 208 | Train Loss: 0.2986044 Vali Loss: 0.2270797 Test Loss: 0.2733453\n",
      "Validation loss decreased (0.247770 --> 0.227080).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3104978\n",
      "\tspeed: 0.0435s/iter; left time: 22.8363s\n",
      "\titers: 200, epoch: 4 | loss: 0.1632470\n",
      "\tspeed: 0.0269s/iter; left time: 11.4331s\n",
      "Epoch: 4 cost time: 5.7172369956970215\n",
      "Epoch: 4, Steps: 208 | Train Loss: 0.2661627 Vali Loss: 0.2227017 Test Loss: 0.2647924\n",
      "Validation loss decreased (0.227080 --> 0.222702).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1628825\n",
      "\tspeed: 0.0420s/iter; left time: 13.3260s\n",
      "\titers: 200, epoch: 5 | loss: 0.2683581\n",
      "\tspeed: 0.0278s/iter; left time: 6.0427s\n",
      "Epoch: 5 cost time: 5.733180999755859\n",
      "Epoch: 5, Steps: 208 | Train Loss: 0.2486780 Vali Loss: 0.2223662 Test Loss: 0.2735446\n",
      "Validation loss decreased (0.222702 --> 0.222366).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1952845\n",
      "\tspeed: 0.0437s/iter; left time: 4.7647s\n",
      "\titers: 200, epoch: 6 | loss: 0.2232231\n",
      "\tspeed: 0.0270s/iter; left time: 0.2426s\n",
      "Epoch: 6 cost time: 5.862537384033203\n",
      "Epoch: 6, Steps: 208 | Train Loss: 0.2390516 Vali Loss: 0.2171890 Test Loss: 0.2440025\n",
      "Validation loss decreased (0.222366 --> 0.217189).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1628\n",
      "Test cost time: 0.5228s\n",
      "test shape: (50, 32, 6, 1) (50, 32, 6, 1)\n",
      "test shape: (1600, 6, 1) (1600, 6, 1)\n",
      "mse:0.24388223886489868, mae:0.38041263818740845\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1578.03515625\n",
      "MAE:  30.60012435913086\n",
      "RMSE: 39.724491119384766\n",
      "MAPE: 0.27484044432640076\n",
      "MSPE: 0.19614093005657196\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6883\n",
      "[DEBUG] Original dataset length: 6883\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6665\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1959\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1628\n",
      "\titers: 100, epoch: 1 | loss: 0.2726795\n",
      "\tspeed: 0.0269s/iter; left time: 30.8639s\n",
      "\titers: 200, epoch: 1 | loss: 0.3356063\n",
      "\tspeed: 0.0268s/iter; left time: 28.1616s\n",
      "Epoch: 1 cost time: 5.600298881530762\n",
      "Epoch: 1, Steps: 208 | Train Loss: 0.4553293 Vali Loss: 0.3412887 Test Loss: 0.2486457\n",
      "Validation loss decreased (inf --> 0.341289).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2470848\n",
      "\tspeed: 0.0434s/iter; left time: 40.8814s\n",
      "\titers: 200, epoch: 2 | loss: 0.2041364\n",
      "\tspeed: 0.0277s/iter; left time: 23.3247s\n",
      "Epoch: 2 cost time: 5.905814170837402\n",
      "Epoch: 2, Steps: 208 | Train Loss: 0.3341477 Vali Loss: 0.2151708 Test Loss: 0.2339696\n",
      "Validation loss decreased (0.341289 --> 0.215171).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2928954\n",
      "\tspeed: 0.0420s/iter; left time: 30.7950s\n",
      "\titers: 200, epoch: 3 | loss: 0.3609901\n",
      "\tspeed: 0.0267s/iter; left time: 16.8848s\n",
      "Epoch: 3 cost time: 5.655877590179443\n",
      "Epoch: 3, Steps: 208 | Train Loss: 0.2944029 Vali Loss: 0.2537928 Test Loss: 0.2181722\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3768511\n",
      "\tspeed: 0.0411s/iter; left time: 21.5558s\n",
      "\titers: 200, epoch: 4 | loss: 0.3273070\n",
      "\tspeed: 0.0294s/iter; left time: 12.4866s\n",
      "Epoch: 4 cost time: 5.912750482559204\n",
      "Epoch: 4, Steps: 208 | Train Loss: 0.2659330 Vali Loss: 0.2208571 Test Loss: 0.2539035\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2736482\n",
      "\tspeed: 0.0418s/iter; left time: 13.2595s\n",
      "\titers: 200, epoch: 5 | loss: 0.1930985\n",
      "\tspeed: 0.0284s/iter; left time: 6.1522s\n",
      "Epoch: 5 cost time: 5.823614120483398\n",
      "Epoch: 5, Steps: 208 | Train Loss: 0.2478573 Vali Loss: 0.2147698 Test Loss: 0.2440421\n",
      "Validation loss decreased (0.215171 --> 0.214770).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3163607\n",
      "\tspeed: 0.0424s/iter; left time: 4.6240s\n",
      "\titers: 200, epoch: 6 | loss: 0.1514609\n",
      "\tspeed: 0.0293s/iter; left time: 0.2635s\n",
      "Epoch: 6 cost time: 5.86309814453125\n",
      "Epoch: 6, Steps: 208 | Train Loss: 0.2393846 Vali Loss: 0.2098385 Test Loss: 0.2284702\n",
      "Validation loss decreased (0.214770 --> 0.209838).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1628\n",
      "Test cost time: 0.5623s\n",
      "test shape: (50, 32, 6, 1) (50, 32, 6, 1)\n",
      "test shape: (1600, 6, 1) (1600, 6, 1)\n",
      "mse:0.22977666556835175, mae:0.37565186619758606\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1486.7652587890625\n",
      "MAE:  30.21717071533203\n",
      "RMSE: 38.55859375\n",
      "MAPE: 0.2797144949436188\n",
      "MSPE: 0.18434952199459076\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6883\n",
      "[DEBUG] Original dataset length: 6883\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6665\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1959\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1628\n",
      "\titers: 100, epoch: 1 | loss: 0.3227603\n",
      "\tspeed: 0.0293s/iter; left time: 33.7014s\n",
      "\titers: 200, epoch: 1 | loss: 0.2975962\n",
      "\tspeed: 0.0281s/iter; left time: 29.5156s\n",
      "Epoch: 1 cost time: 5.961329698562622\n",
      "Epoch: 1, Steps: 208 | Train Loss: 0.4646632 Vali Loss: 0.2517142 Test Loss: 0.3110637\n",
      "Validation loss decreased (inf --> 0.251714).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2755558\n",
      "\tspeed: 0.0421s/iter; left time: 39.6238s\n",
      "\titers: 200, epoch: 2 | loss: 0.2900018\n",
      "\tspeed: 0.0283s/iter; left time: 23.8052s\n",
      "Epoch: 2 cost time: 5.8710455894470215\n",
      "Epoch: 2, Steps: 208 | Train Loss: 0.3376525 Vali Loss: 0.2202727 Test Loss: 0.2601115\n",
      "Validation loss decreased (0.251714 --> 0.220273).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1878721\n",
      "\tspeed: 0.0442s/iter; left time: 32.3904s\n",
      "\titers: 200, epoch: 3 | loss: 0.2480587\n",
      "\tspeed: 0.0272s/iter; left time: 17.2487s\n",
      "Epoch: 3 cost time: 5.8709800243377686\n",
      "Epoch: 3, Steps: 208 | Train Loss: 0.2860206 Vali Loss: 0.2246919 Test Loss: 0.2271697\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2048887\n",
      "\tspeed: 0.0421s/iter; left time: 22.0763s\n",
      "\titers: 200, epoch: 4 | loss: 0.2118921\n",
      "\tspeed: 0.0288s/iter; left time: 12.2216s\n",
      "Epoch: 4 cost time: 5.9117231369018555\n",
      "Epoch: 4, Steps: 208 | Train Loss: 0.2567925 Vali Loss: 0.2118327 Test Loss: 0.2221466\n",
      "Validation loss decreased (0.220273 --> 0.211833).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2794926\n",
      "\tspeed: 0.0423s/iter; left time: 13.3999s\n",
      "\titers: 200, epoch: 5 | loss: 0.1457726\n",
      "\tspeed: 0.0272s/iter; left time: 5.9003s\n",
      "Epoch: 5 cost time: 5.609769821166992\n",
      "Epoch: 5, Steps: 208 | Train Loss: 0.2415640 Vali Loss: 0.2101968 Test Loss: 0.2238349\n",
      "Validation loss decreased (0.211833 --> 0.210197).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1893190\n",
      "\tspeed: 0.0420s/iter; left time: 4.5820s\n",
      "\titers: 200, epoch: 6 | loss: 0.1776092\n",
      "\tspeed: 0.0276s/iter; left time: 0.2485s\n",
      "Epoch: 6 cost time: 5.741939067840576\n",
      "Epoch: 6, Steps: 208 | Train Loss: 0.2342106 Vali Loss: 0.2041610 Test Loss: 0.2012470\n",
      "Validation loss decreased (0.210197 --> 0.204161).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1628\n",
      "Test cost time: 0.5520s\n",
      "test shape: (50, 32, 6, 1) (50, 32, 6, 1)\n",
      "test shape: (1600, 6, 1) (1600, 6, 1)\n",
      "mse:0.20094072818756104, mae:0.3423227071762085\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1300.18310546875\n",
      "MAE:  27.53619384765625\n",
      "RMSE: 36.05805206298828\n",
      "MAPE: 0.25740042328834534\n",
      "MSPE: 0.16674162447452545\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6883\n",
      "[DEBUG] Original dataset length: 6883\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6665\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1959\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1628\n",
      "\titers: 100, epoch: 1 | loss: 0.4308149\n",
      "\tspeed: 0.0280s/iter; left time: 32.1325s\n",
      "\titers: 200, epoch: 1 | loss: 0.3007051\n",
      "\tspeed: 0.0277s/iter; left time: 29.0584s\n",
      "Epoch: 1 cost time: 5.795875787734985\n",
      "Epoch: 1, Steps: 208 | Train Loss: 0.4734003 Vali Loss: 0.2458469 Test Loss: 0.3734883\n",
      "Validation loss decreased (inf --> 0.245847).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3842282\n",
      "\tspeed: 0.0431s/iter; left time: 40.5970s\n",
      "\titers: 200, epoch: 2 | loss: 0.4187706\n",
      "\tspeed: 0.0252s/iter; left time: 21.1978s\n",
      "Epoch: 2 cost time: 5.475962162017822\n",
      "Epoch: 2, Steps: 208 | Train Loss: 0.3399428 Vali Loss: 0.2270483 Test Loss: 0.2037561\n",
      "Validation loss decreased (0.245847 --> 0.227048).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3784841\n",
      "\tspeed: 0.0441s/iter; left time: 32.3598s\n",
      "\titers: 200, epoch: 3 | loss: 0.5945437\n",
      "\tspeed: 0.0285s/iter; left time: 18.0239s\n",
      "Epoch: 3 cost time: 5.949992895126343\n",
      "Epoch: 3, Steps: 208 | Train Loss: 0.2957109 Vali Loss: 0.2223037 Test Loss: 0.2779775\n",
      "Validation loss decreased (0.227048 --> 0.222304).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3054965\n",
      "\tspeed: 0.0441s/iter; left time: 23.1454s\n",
      "\titers: 200, epoch: 4 | loss: 0.2939703\n",
      "\tspeed: 0.0287s/iter; left time: 12.1913s\n",
      "Epoch: 4 cost time: 6.013690948486328\n",
      "Epoch: 4, Steps: 208 | Train Loss: 0.2635645 Vali Loss: 0.2162009 Test Loss: 0.2319323\n",
      "Validation loss decreased (0.222304 --> 0.216201).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1731167\n",
      "\tspeed: 0.0449s/iter; left time: 14.2286s\n",
      "\titers: 200, epoch: 5 | loss: 0.2153622\n",
      "\tspeed: 0.0284s/iter; left time: 6.1701s\n",
      "Epoch: 5 cost time: 6.032618999481201\n",
      "Epoch: 5, Steps: 208 | Train Loss: 0.2447828 Vali Loss: 0.2046819 Test Loss: 0.2456507\n",
      "Validation loss decreased (0.216201 --> 0.204682).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1504398\n",
      "\tspeed: 0.0412s/iter; left time: 4.4944s\n",
      "\titers: 200, epoch: 6 | loss: 0.1835735\n",
      "\tspeed: 0.0283s/iter; left time: 0.2545s\n",
      "Epoch: 6 cost time: 5.737766742706299\n",
      "Epoch: 6, Steps: 208 | Train Loss: 0.2351826 Vali Loss: 0.2037330 Test Loss: 0.2402116\n",
      "Validation loss decreased (0.204682 --> 0.203733).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1628\n",
      "Test cost time: 0.5129s\n",
      "test shape: (50, 32, 6, 1) (50, 32, 6, 1)\n",
      "test shape: (1600, 6, 1) (1600, 6, 1)\n",
      "mse:0.24120737612247467, mae:0.3841158151626587\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1560.7275390625\n",
      "MAE:  30.898008346557617\n",
      "RMSE: 39.50604248046875\n",
      "MAPE: 0.28539198637008667\n",
      "MSPE: 0.19534766674041748\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6883\n",
      "[DEBUG] Original dataset length: 6883\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6665\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1959\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1628\n",
      "\titers: 100, epoch: 1 | loss: 0.4218441\n",
      "\tspeed: 0.0285s/iter; left time: 32.7148s\n",
      "\titers: 200, epoch: 1 | loss: 0.3516141\n",
      "\tspeed: 0.0276s/iter; left time: 28.9634s\n",
      "Epoch: 1 cost time: 5.847535610198975\n",
      "Epoch: 1, Steps: 208 | Train Loss: 0.4467287 Vali Loss: 0.2780440 Test Loss: 0.3588011\n",
      "Validation loss decreased (inf --> 0.278044).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1769376\n",
      "\tspeed: 0.0424s/iter; left time: 39.8547s\n",
      "\titers: 200, epoch: 2 | loss: 0.3120639\n",
      "\tspeed: 0.0287s/iter; left time: 24.1409s\n",
      "Epoch: 2 cost time: 5.825609922409058\n",
      "Epoch: 2, Steps: 208 | Train Loss: 0.3270796 Vali Loss: 0.2313238 Test Loss: 0.1919640\n",
      "Validation loss decreased (0.278044 --> 0.231324).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1708427\n",
      "\tspeed: 0.0433s/iter; left time: 31.7377s\n",
      "\titers: 200, epoch: 3 | loss: 0.1829911\n",
      "\tspeed: 0.0293s/iter; left time: 18.5342s\n",
      "Epoch: 3 cost time: 5.972045183181763\n",
      "Epoch: 3, Steps: 208 | Train Loss: 0.2797769 Vali Loss: 0.2146236 Test Loss: 0.2220188\n",
      "Validation loss decreased (0.231324 --> 0.214624).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.5575268\n",
      "\tspeed: 0.0425s/iter; left time: 22.3335s\n",
      "\titers: 200, epoch: 4 | loss: 0.3741994\n",
      "\tspeed: 0.0272s/iter; left time: 11.5526s\n",
      "Epoch: 4 cost time: 5.740279674530029\n",
      "Epoch: 4, Steps: 208 | Train Loss: 0.2479084 Vali Loss: 0.2164439 Test Loss: 0.2350374\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2316085\n",
      "\tspeed: 0.0418s/iter; left time: 13.2411s\n",
      "\titers: 200, epoch: 5 | loss: 0.1358743\n",
      "\tspeed: 0.0287s/iter; left time: 6.2266s\n",
      "Epoch: 5 cost time: 5.8940839767456055\n",
      "Epoch: 5, Steps: 208 | Train Loss: 0.2320723 Vali Loss: 0.2063026 Test Loss: 0.2016573\n",
      "Validation loss decreased (0.214624 --> 0.206303).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2672146\n",
      "\tspeed: 0.0424s/iter; left time: 4.6257s\n",
      "\titers: 200, epoch: 6 | loss: 0.1511497\n",
      "\tspeed: 0.0283s/iter; left time: 0.2547s\n",
      "Epoch: 6 cost time: 5.736217975616455\n",
      "Epoch: 6, Steps: 208 | Train Loss: 0.2216999 Vali Loss: 0.2093234 Test Loss: 0.2106104\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1628\n",
      "Test cost time: 0.5236s\n",
      "test shape: (50, 32, 6, 1) (50, 32, 6, 1)\n",
      "test shape: (1600, 6, 1) (1600, 6, 1)\n",
      "mse:0.20143504440784454, mae:0.347057580947876\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1303.3814697265625\n",
      "MAE:  27.917064666748047\n",
      "RMSE: 36.10237503051758\n",
      "MAPE: 0.271628201007843\n",
      "MSPE: 0.23611551523208618\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6883\n",
      "[DEBUG] Original dataset length: 6883\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6665\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1959\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1628\n",
      "\titers: 100, epoch: 1 | loss: 0.3687292\n",
      "\tspeed: 0.0269s/iter; left time: 30.9650s\n",
      "\titers: 200, epoch: 1 | loss: 0.4863934\n",
      "\tspeed: 0.0274s/iter; left time: 28.7782s\n",
      "Epoch: 1 cost time: 5.692256927490234\n",
      "Epoch: 1, Steps: 208 | Train Loss: 0.4764803 Vali Loss: 0.2991188 Test Loss: 0.3410648\n",
      "Validation loss decreased (inf --> 0.299119).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2679611\n",
      "\tspeed: 0.0427s/iter; left time: 40.1508s\n",
      "\titers: 200, epoch: 2 | loss: 0.4412416\n",
      "\tspeed: 0.0268s/iter; left time: 22.5158s\n",
      "Epoch: 2 cost time: 5.595852613449097\n",
      "Epoch: 2, Steps: 208 | Train Loss: 0.3363907 Vali Loss: 0.2304077 Test Loss: 0.2444791\n",
      "Validation loss decreased (0.299119 --> 0.230408).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.4224978\n",
      "\tspeed: 0.0405s/iter; left time: 29.6858s\n",
      "\titers: 200, epoch: 3 | loss: 0.3302363\n",
      "\tspeed: 0.0272s/iter; left time: 17.2489s\n",
      "Epoch: 3 cost time: 5.56552529335022\n",
      "Epoch: 3, Steps: 208 | Train Loss: 0.2916302 Vali Loss: 0.2231520 Test Loss: 0.2483229\n",
      "Validation loss decreased (0.230408 --> 0.223152).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3449999\n",
      "\tspeed: 0.0442s/iter; left time: 23.2067s\n",
      "\titers: 200, epoch: 4 | loss: 0.2217189\n",
      "\tspeed: 0.0280s/iter; left time: 11.8855s\n",
      "Epoch: 4 cost time: 5.964233636856079\n",
      "Epoch: 4, Steps: 208 | Train Loss: 0.2650380 Vali Loss: 0.2205051 Test Loss: 0.2226103\n",
      "Validation loss decreased (0.223152 --> 0.220505).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1349565\n",
      "\tspeed: 0.0426s/iter; left time: 13.5131s\n",
      "\titers: 200, epoch: 5 | loss: 0.2155786\n",
      "\tspeed: 0.0270s/iter; left time: 5.8605s\n",
      "Epoch: 5 cost time: 5.664016246795654\n",
      "Epoch: 5, Steps: 208 | Train Loss: 0.2458764 Vali Loss: 0.2202265 Test Loss: 0.2332142\n",
      "Validation loss decreased (0.220505 --> 0.220226).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1313780\n",
      "\tspeed: 0.0435s/iter; left time: 4.7413s\n",
      "\titers: 200, epoch: 6 | loss: 0.4380071\n",
      "\tspeed: 0.0291s/iter; left time: 0.2617s\n",
      "Epoch: 6 cost time: 6.011794090270996\n",
      "Epoch: 6, Steps: 208 | Train Loss: 0.2363335 Vali Loss: 0.2175487 Test Loss: 0.2151686\n",
      "Validation loss decreased (0.220226 --> 0.217549).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1628\n",
      "Test cost time: 0.5256s\n",
      "test shape: (50, 32, 6, 1) (50, 32, 6, 1)\n",
      "test shape: (1600, 6, 1) (1600, 6, 1)\n",
      "mse:0.2158421128988266, mae:0.3593718111515045\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1396.60205078125\n",
      "MAE:  28.907617568969727\n",
      "RMSE: 37.37113952636719\n",
      "MAPE: 0.2633015811443329\n",
      "MSPE: 0.15964479744434357\n",
      ">>>>>>>Running time saved<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Running seq_len=120\n",
      "Args in experiment:\n",
      "Namespace(model='informer', data='traffic_after_covid', root_path='../', data_path='traffic_after_covid.csv', features='S', target='flow', freq='h', checkpoints='./checkpoints/', seq_len=120, label_len=24, pred_len=6, enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=2, d_layers=1, s_layers=[3, 2, 1], d_ff=2048, factor=5, padding=0, distil=True, dropout=0.05, attn='prob', embed='timeF', activation='gelu', output_attention=False, do_predict=False, mix=True, cols=None, num_workers=0, itr=10, train_epochs=6, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, inverse=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', detail_freq='h')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6859\n",
      "[DEBUG] Original dataset length: 6859\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6593\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1887\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1556\n",
      "\titers: 100, epoch: 1 | loss: 0.4964618\n",
      "\tspeed: 0.0489s/iter; left time: 55.5595s\n",
      "\titers: 200, epoch: 1 | loss: 1.0284461\n",
      "\tspeed: 0.0330s/iter; left time: 34.1988s\n",
      "Epoch: 1 cost time: 7.41248631477356\n",
      "Epoch: 1, Steps: 206 | Train Loss: 0.4988046 Vali Loss: 0.2540796 Test Loss: 0.2933343\n",
      "Validation loss decreased (inf --> 0.254080).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2469164\n",
      "\tspeed: 0.0467s/iter; left time: 43.4910s\n",
      "\titers: 200, epoch: 2 | loss: 0.2946783\n",
      "\tspeed: 0.0314s/iter; left time: 26.0748s\n",
      "Epoch: 2 cost time: 6.456884860992432\n",
      "Epoch: 2, Steps: 206 | Train Loss: 0.3442776 Vali Loss: 0.2653270 Test Loss: 0.3283116\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2820634\n",
      "\tspeed: 0.0470s/iter; left time: 34.0498s\n",
      "\titers: 200, epoch: 3 | loss: 0.3353964\n",
      "\tspeed: 0.0318s/iter; left time: 19.8568s\n",
      "Epoch: 3 cost time: 6.582083225250244\n",
      "Epoch: 3, Steps: 206 | Train Loss: 0.2961278 Vali Loss: 0.2117733 Test Loss: 0.2058035\n",
      "Validation loss decreased (0.254080 --> 0.211773).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1966299\n",
      "\tspeed: 0.0478s/iter; left time: 24.8102s\n",
      "\titers: 200, epoch: 4 | loss: 0.2141175\n",
      "\tspeed: 0.0313s/iter; left time: 13.1188s\n",
      "Epoch: 4 cost time: 6.485208749771118\n",
      "Epoch: 4, Steps: 206 | Train Loss: 0.2665963 Vali Loss: 0.2276311 Test Loss: 0.2425716\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1598346\n",
      "\tspeed: 0.0484s/iter; left time: 15.1391s\n",
      "\titers: 200, epoch: 5 | loss: 0.1759432\n",
      "\tspeed: 0.0330s/iter; left time: 7.0373s\n",
      "Epoch: 5 cost time: 6.78534197807312\n",
      "Epoch: 5, Steps: 206 | Train Loss: 0.2511727 Vali Loss: 0.2370356 Test Loss: 0.2760687\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3543189\n",
      "\tspeed: 0.0446s/iter; left time: 4.7678s\n",
      "\titers: 200, epoch: 6 | loss: 0.0871699\n",
      "\tspeed: 0.0299s/iter; left time: 0.2094s\n",
      "Epoch: 6 cost time: 6.171228408813477\n",
      "Epoch: 6, Steps: 206 | Train Loss: 0.2423293 Vali Loss: 0.2305812 Test Loss: 0.2636323\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1556\n",
      "Test cost time: 0.4932s\n",
      "test shape: (48, 32, 6, 1) (48, 32, 6, 1)\n",
      "test shape: (1536, 6, 1) (1536, 6, 1)\n",
      "mse:0.2055155485868454, mae:0.3496553301811218\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1329.7843017578125\n",
      "MAE:  28.126028060913086\n",
      "RMSE: 36.466209411621094\n",
      "MAPE: 0.28234541416168213\n",
      "MSPE: 0.3314502239227295\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6859\n",
      "[DEBUG] Original dataset length: 6859\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6593\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1887\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1556\n",
      "\titers: 100, epoch: 1 | loss: 0.4875158\n",
      "\tspeed: 0.0307s/iter; left time: 34.8892s\n",
      "\titers: 200, epoch: 1 | loss: 0.3087386\n",
      "\tspeed: 0.0309s/iter; left time: 32.0311s\n",
      "Epoch: 1 cost time: 6.348733425140381\n",
      "Epoch: 1, Steps: 206 | Train Loss: 0.5127589 Vali Loss: 0.2685693 Test Loss: 0.2603434\n",
      "Validation loss decreased (inf --> 0.268569).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1954298\n",
      "\tspeed: 0.0459s/iter; left time: 42.7775s\n",
      "\titers: 200, epoch: 2 | loss: 0.1908585\n",
      "\tspeed: 0.0311s/iter; left time: 25.8266s\n",
      "Epoch: 2 cost time: 6.419729471206665\n",
      "Epoch: 2, Steps: 206 | Train Loss: 0.3578551 Vali Loss: 0.2298573 Test Loss: 0.1924724\n",
      "Validation loss decreased (0.268569 --> 0.229857).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.4563297\n",
      "\tspeed: 0.0477s/iter; left time: 34.6016s\n",
      "\titers: 200, epoch: 3 | loss: 0.1554976\n",
      "\tspeed: 0.0315s/iter; left time: 19.6613s\n",
      "Epoch: 3 cost time: 6.529805660247803\n",
      "Epoch: 3, Steps: 206 | Train Loss: 0.2990345 Vali Loss: 0.2169765 Test Loss: 0.2372782\n",
      "Validation loss decreased (0.229857 --> 0.216976).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2105534\n",
      "\tspeed: 0.0482s/iter; left time: 25.0378s\n",
      "\titers: 200, epoch: 4 | loss: 0.1660059\n",
      "\tspeed: 0.0345s/iter; left time: 14.4711s\n",
      "Epoch: 4 cost time: 6.882339000701904\n",
      "Epoch: 4, Steps: 206 | Train Loss: 0.2650748 Vali Loss: 0.2071045 Test Loss: 0.2249623\n",
      "Validation loss decreased (0.216976 --> 0.207104).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1973301\n",
      "\tspeed: 0.0507s/iter; left time: 15.8793s\n",
      "\titers: 200, epoch: 5 | loss: 0.1458008\n",
      "\tspeed: 0.0306s/iter; left time: 6.5252s\n",
      "Epoch: 5 cost time: 6.54144024848938\n",
      "Epoch: 5, Steps: 206 | Train Loss: 0.2475568 Vali Loss: 0.2108761 Test Loss: 0.2372298\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.4271470\n",
      "\tspeed: 0.0428s/iter; left time: 4.5777s\n",
      "\titers: 200, epoch: 6 | loss: 0.1683272\n",
      "\tspeed: 0.0282s/iter; left time: 0.1974s\n",
      "Epoch: 6 cost time: 5.8780035972595215\n",
      "Epoch: 6, Steps: 206 | Train Loss: 0.2391332 Vali Loss: 0.2093299 Test Loss: 0.2174286\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1556\n",
      "Test cost time: 0.5554s\n",
      "test shape: (48, 32, 6, 1) (48, 32, 6, 1)\n",
      "test shape: (1536, 6, 1) (1536, 6, 1)\n",
      "mse:0.22638291120529175, mae:0.3660021424293518\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1464.8062744140625\n",
      "MAE:  29.44095230102539\n",
      "RMSE: 38.272789001464844\n",
      "MAPE: 0.2935461401939392\n",
      "MSPE: 0.3187941908836365\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6859\n",
      "[DEBUG] Original dataset length: 6859\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6593\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1887\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1556\n",
      "\titers: 100, epoch: 1 | loss: 0.3657319\n",
      "\tspeed: 0.0311s/iter; left time: 35.3498s\n",
      "\titers: 200, epoch: 1 | loss: 0.5909373\n",
      "\tspeed: 0.0295s/iter; left time: 30.6172s\n",
      "Epoch: 1 cost time: 6.273531913757324\n",
      "Epoch: 1, Steps: 206 | Train Loss: 0.4951065 Vali Loss: 0.2491436 Test Loss: 0.3773488\n",
      "Validation loss decreased (inf --> 0.249144).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2587844\n",
      "\tspeed: 0.0452s/iter; left time: 42.0523s\n",
      "\titers: 200, epoch: 2 | loss: 0.2113489\n",
      "\tspeed: 0.0295s/iter; left time: 24.4852s\n",
      "Epoch: 2 cost time: 6.1212286949157715\n",
      "Epoch: 2, Steps: 206 | Train Loss: 0.3484162 Vali Loss: 0.2504812 Test Loss: 0.3181295\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3320769\n",
      "\tspeed: 0.0443s/iter; left time: 32.1158s\n",
      "\titers: 200, epoch: 3 | loss: 0.2532097\n",
      "\tspeed: 0.0304s/iter; left time: 19.0243s\n",
      "Epoch: 3 cost time: 6.210242986679077\n",
      "Epoch: 3, Steps: 206 | Train Loss: 0.2974361 Vali Loss: 0.2581435 Test Loss: 0.4006648\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.4738665\n",
      "\tspeed: 0.0439s/iter; left time: 22.7648s\n",
      "\titers: 200, epoch: 4 | loss: 0.2226703\n",
      "\tspeed: 0.0296s/iter; left time: 12.4048s\n",
      "Epoch: 4 cost time: 6.123301267623901\n",
      "Epoch: 4, Steps: 206 | Train Loss: 0.2688217 Vali Loss: 0.2174500 Test Loss: 0.2623639\n",
      "Validation loss decreased (0.249144 --> 0.217450).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3679318\n",
      "\tspeed: 0.0462s/iter; left time: 14.4497s\n",
      "\titers: 200, epoch: 5 | loss: 0.2353945\n",
      "\tspeed: 0.0298s/iter; left time: 6.3384s\n",
      "Epoch: 5 cost time: 6.2826173305511475\n",
      "Epoch: 5, Steps: 206 | Train Loss: 0.2559613 Vali Loss: 0.2295818 Test Loss: 0.3155797\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2593192\n",
      "\tspeed: 0.0460s/iter; left time: 4.9200s\n",
      "\titers: 200, epoch: 6 | loss: 0.2458671\n",
      "\tspeed: 0.0314s/iter; left time: 0.2198s\n",
      "Epoch: 6 cost time: 6.491871356964111\n",
      "Epoch: 6, Steps: 206 | Train Loss: 0.2453500 Vali Loss: 0.2205537 Test Loss: 0.2885888\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1556\n",
      "Test cost time: 0.5662s\n",
      "test shape: (48, 32, 6, 1) (48, 32, 6, 1)\n",
      "test shape: (1536, 6, 1) (1536, 6, 1)\n",
      "mse:0.26230618357658386, mae:0.39179906249046326\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1697.2469482421875\n",
      "MAE:  31.516042709350586\n",
      "RMSE: 41.19765853881836\n",
      "MAPE: 0.30304038524627686\n",
      "MSPE: 0.23207823932170868\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6859\n",
      "[DEBUG] Original dataset length: 6859\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6593\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1887\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1556\n",
      "\titers: 100, epoch: 1 | loss: 0.2678536\n",
      "\tspeed: 0.0325s/iter; left time: 36.9679s\n",
      "\titers: 200, epoch: 1 | loss: 0.6649536\n",
      "\tspeed: 0.0309s/iter; left time: 32.0647s\n",
      "Epoch: 1 cost time: 6.523356199264526\n",
      "Epoch: 1, Steps: 206 | Train Loss: 0.4804927 Vali Loss: 0.2403176 Test Loss: 0.2368216\n",
      "Validation loss decreased (inf --> 0.240318).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2182279\n",
      "\tspeed: 0.0451s/iter; left time: 42.0229s\n",
      "\titers: 200, epoch: 2 | loss: 0.4216872\n",
      "\tspeed: 0.0295s/iter; left time: 24.4776s\n",
      "Epoch: 2 cost time: 6.132267475128174\n",
      "Epoch: 2, Steps: 206 | Train Loss: 0.3446150 Vali Loss: 0.2314548 Test Loss: 0.2634974\n",
      "Validation loss decreased (0.240318 --> 0.231455).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1642213\n",
      "\tspeed: 0.0468s/iter; left time: 33.9546s\n",
      "\titers: 200, epoch: 3 | loss: 0.2999509\n",
      "\tspeed: 0.0291s/iter; left time: 18.2075s\n",
      "Epoch: 3 cost time: 6.274568796157837\n",
      "Epoch: 3, Steps: 206 | Train Loss: 0.2897141 Vali Loss: 0.2280937 Test Loss: 0.2716291\n",
      "Validation loss decreased (0.231455 --> 0.228094).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3759951\n",
      "\tspeed: 0.0448s/iter; left time: 23.2728s\n",
      "\titers: 200, epoch: 4 | loss: 0.2056178\n",
      "\tspeed: 0.0301s/iter; left time: 12.6076s\n",
      "Epoch: 4 cost time: 6.099624156951904\n",
      "Epoch: 4, Steps: 206 | Train Loss: 0.2594817 Vali Loss: 0.2209795 Test Loss: 0.2612581\n",
      "Validation loss decreased (0.228094 --> 0.220980).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1497036\n",
      "\tspeed: 0.0462s/iter; left time: 14.4677s\n",
      "\titers: 200, epoch: 5 | loss: 0.4097594\n",
      "\tspeed: 0.0287s/iter; left time: 6.1207s\n",
      "Epoch: 5 cost time: 6.214131593704224\n",
      "Epoch: 5, Steps: 206 | Train Loss: 0.2403592 Vali Loss: 0.2204440 Test Loss: 0.2586779\n",
      "Validation loss decreased (0.220980 --> 0.220444).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2514730\n",
      "\tspeed: 0.0440s/iter; left time: 4.7054s\n",
      "\titers: 200, epoch: 6 | loss: 0.1718186\n",
      "\tspeed: 0.0288s/iter; left time: 0.2018s\n",
      "Epoch: 6 cost time: 5.974181175231934\n",
      "Epoch: 6, Steps: 206 | Train Loss: 0.2297448 Vali Loss: 0.2298254 Test Loss: 0.2841685\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1556\n",
      "Test cost time: 0.5568s\n",
      "test shape: (48, 32, 6, 1) (48, 32, 6, 1)\n",
      "test shape: (1536, 6, 1) (1536, 6, 1)\n",
      "mse:0.2589019238948822, mae:0.3943082094192505\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1675.2198486328125\n",
      "MAE:  31.717872619628906\n",
      "RMSE: 40.92945098876953\n",
      "MAPE: 0.3123073875904083\n",
      "MSPE: 0.2530531585216522\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6859\n",
      "[DEBUG] Original dataset length: 6859\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6593\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1887\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1556\n",
      "\titers: 100, epoch: 1 | loss: 0.5887684\n",
      "\tspeed: 0.0364s/iter; left time: 41.3395s\n",
      "\titers: 200, epoch: 1 | loss: 0.2872599\n",
      "\tspeed: 0.0303s/iter; left time: 31.3835s\n",
      "Epoch: 1 cost time: 6.853339672088623\n",
      "Epoch: 1, Steps: 206 | Train Loss: 0.4809988 Vali Loss: 0.2307634 Test Loss: 0.2969951\n",
      "Validation loss decreased (inf --> 0.230763).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3720875\n",
      "\tspeed: 0.0441s/iter; left time: 41.0813s\n",
      "\titers: 200, epoch: 2 | loss: 0.2007380\n",
      "\tspeed: 0.0290s/iter; left time: 24.0794s\n",
      "Epoch: 2 cost time: 5.979487657546997\n",
      "Epoch: 2, Steps: 206 | Train Loss: 0.3344164 Vali Loss: 0.2753722 Test Loss: 0.3418930\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1686169\n",
      "\tspeed: 0.0457s/iter; left time: 33.1013s\n",
      "\titers: 200, epoch: 3 | loss: 0.3270120\n",
      "\tspeed: 0.0298s/iter; left time: 18.6183s\n",
      "Epoch: 3 cost time: 6.297277212142944\n",
      "Epoch: 3, Steps: 206 | Train Loss: 0.2892010 Vali Loss: 0.2497994 Test Loss: 0.3642335\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2336145\n",
      "\tspeed: 0.0436s/iter; left time: 22.6283s\n",
      "\titers: 200, epoch: 4 | loss: 0.3699363\n",
      "\tspeed: 0.0304s/iter; left time: 12.7475s\n",
      "Epoch: 4 cost time: 6.2027037143707275\n",
      "Epoch: 4, Steps: 206 | Train Loss: 0.2541478 Vali Loss: 0.2271888 Test Loss: 0.3036640\n",
      "Validation loss decreased (0.230763 --> 0.227189).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2653783\n",
      "\tspeed: 0.0473s/iter; left time: 14.7895s\n",
      "\titers: 200, epoch: 5 | loss: 0.1785106\n",
      "\tspeed: 0.0289s/iter; left time: 6.1556s\n",
      "Epoch: 5 cost time: 6.230723142623901\n",
      "Epoch: 5, Steps: 206 | Train Loss: 0.2344450 Vali Loss: 0.2358704 Test Loss: 0.3346334\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1566446\n",
      "\tspeed: 0.0424s/iter; left time: 4.5353s\n",
      "\titers: 200, epoch: 6 | loss: 0.1393084\n",
      "\tspeed: 0.0299s/iter; left time: 0.2095s\n",
      "Epoch: 6 cost time: 6.05917501449585\n",
      "Epoch: 6, Steps: 206 | Train Loss: 0.2240041 Vali Loss: 0.2357731 Test Loss: 0.3376677\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1556\n",
      "Test cost time: 0.5370s\n",
      "test shape: (48, 32, 6, 1) (48, 32, 6, 1)\n",
      "test shape: (1536, 6, 1) (1536, 6, 1)\n",
      "mse:0.30356794595718384, mae:0.4225820302963257\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1964.23046875\n",
      "MAE:  33.99220275878906\n",
      "RMSE: 44.31964111328125\n",
      "MAPE: 0.3268253803253174\n",
      "MSPE: 0.24009370803833008\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6859\n",
      "[DEBUG] Original dataset length: 6859\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6593\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1887\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1556\n",
      "\titers: 100, epoch: 1 | loss: 0.8099766\n",
      "\tspeed: 0.0345s/iter; left time: 39.1816s\n",
      "\titers: 200, epoch: 1 | loss: 0.3885010\n",
      "\tspeed: 0.0295s/iter; left time: 30.5982s\n",
      "Epoch: 1 cost time: 6.58819055557251\n",
      "Epoch: 1, Steps: 206 | Train Loss: 0.4908211 Vali Loss: 0.2659800 Test Loss: 0.2965125\n",
      "Validation loss decreased (inf --> 0.265980).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2599029\n",
      "\tspeed: 0.0440s/iter; left time: 40.9402s\n",
      "\titers: 200, epoch: 2 | loss: 0.4177896\n",
      "\tspeed: 0.0288s/iter; left time: 23.9296s\n",
      "Epoch: 2 cost time: 6.022058963775635\n",
      "Epoch: 2, Steps: 206 | Train Loss: 0.3423422 Vali Loss: 0.2440464 Test Loss: 0.2118204\n",
      "Validation loss decreased (0.265980 --> 0.244046).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2874538\n",
      "\tspeed: 0.0464s/iter; left time: 33.6573s\n",
      "\titers: 200, epoch: 3 | loss: 0.6550028\n",
      "\tspeed: 0.0299s/iter; left time: 18.6665s\n",
      "Epoch: 3 cost time: 6.270205736160278\n",
      "Epoch: 3, Steps: 206 | Train Loss: 0.2982784 Vali Loss: 0.2326608 Test Loss: 0.2740715\n",
      "Validation loss decreased (0.244046 --> 0.232661).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3095300\n",
      "\tspeed: 0.0447s/iter; left time: 23.1815s\n",
      "\titers: 200, epoch: 4 | loss: 0.1442705\n",
      "\tspeed: 0.0287s/iter; left time: 12.0142s\n",
      "Epoch: 4 cost time: 5.983922958374023\n",
      "Epoch: 4, Steps: 206 | Train Loss: 0.2635424 Vali Loss: 0.2154030 Test Loss: 0.2304755\n",
      "Validation loss decreased (0.232661 --> 0.215403).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1082614\n",
      "\tspeed: 0.0450s/iter; left time: 14.0699s\n",
      "\titers: 200, epoch: 5 | loss: 0.2087682\n",
      "\tspeed: 0.0301s/iter; left time: 6.4107s\n",
      "Epoch: 5 cost time: 6.16124415397644\n",
      "Epoch: 5, Steps: 206 | Train Loss: 0.2469874 Vali Loss: 0.2055370 Test Loss: 0.2244253\n",
      "Validation loss decreased (0.215403 --> 0.205537).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2763563\n",
      "\tspeed: 0.0445s/iter; left time: 4.7647s\n",
      "\titers: 200, epoch: 6 | loss: 0.2960817\n",
      "\tspeed: 0.0285s/iter; left time: 0.1993s\n",
      "Epoch: 6 cost time: 5.971331834793091\n",
      "Epoch: 6, Steps: 206 | Train Loss: 0.2367196 Vali Loss: 0.2136316 Test Loss: 0.2516260\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1556\n",
      "Test cost time: 0.5608s\n",
      "test shape: (48, 32, 6, 1) (48, 32, 6, 1)\n",
      "test shape: (1536, 6, 1) (1536, 6, 1)\n",
      "mse:0.22550484538078308, mae:0.37028151750564575\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1459.124755859375\n",
      "MAE:  29.78518295288086\n",
      "RMSE: 38.198490142822266\n",
      "MAPE: 0.29747045040130615\n",
      "MSPE: 0.2947036027908325\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6859\n",
      "[DEBUG] Original dataset length: 6859\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6593\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1887\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1556\n",
      "\titers: 100, epoch: 1 | loss: 0.3685831\n",
      "\tspeed: 0.0300s/iter; left time: 34.1434s\n",
      "\titers: 200, epoch: 1 | loss: 0.3313242\n",
      "\tspeed: 0.0291s/iter; left time: 30.1281s\n",
      "Epoch: 1 cost time: 6.0866429805755615\n",
      "Epoch: 1, Steps: 206 | Train Loss: 0.4854306 Vali Loss: 0.2567882 Test Loss: 0.2585383\n",
      "Validation loss decreased (inf --> 0.256788).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1299600\n",
      "\tspeed: 0.0432s/iter; left time: 40.2625s\n",
      "\titers: 200, epoch: 2 | loss: 0.3350506\n",
      "\tspeed: 0.0298s/iter; left time: 24.7706s\n",
      "Epoch: 2 cost time: 6.066210508346558\n",
      "Epoch: 2, Steps: 206 | Train Loss: 0.3492744 Vali Loss: 0.2170817 Test Loss: 0.2334421\n",
      "Validation loss decreased (0.256788 --> 0.217082).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3241193\n",
      "\tspeed: 0.0459s/iter; left time: 33.2947s\n",
      "\titers: 200, epoch: 3 | loss: 0.3272670\n",
      "\tspeed: 0.0302s/iter; left time: 18.9042s\n",
      "Epoch: 3 cost time: 6.2986650466918945\n",
      "Epoch: 3, Steps: 206 | Train Loss: 0.2900933 Vali Loss: 0.2234349 Test Loss: 0.2220422\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3692373\n",
      "\tspeed: 0.0458s/iter; left time: 23.7479s\n",
      "\titers: 200, epoch: 4 | loss: 0.2489655\n",
      "\tspeed: 0.0295s/iter; left time: 12.3757s\n",
      "Epoch: 4 cost time: 6.270977258682251\n",
      "Epoch: 4, Steps: 206 | Train Loss: 0.2586767 Vali Loss: 0.2113082 Test Loss: 0.2099771\n",
      "Validation loss decreased (0.217082 --> 0.211308).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1447193\n",
      "\tspeed: 0.0453s/iter; left time: 14.1828s\n",
      "\titers: 200, epoch: 5 | loss: 0.2087400\n",
      "\tspeed: 0.0306s/iter; left time: 6.5075s\n",
      "Epoch: 5 cost time: 6.243149995803833\n",
      "Epoch: 5, Steps: 206 | Train Loss: 0.2422086 Vali Loss: 0.2106320 Test Loss: 0.2196867\n",
      "Validation loss decreased (0.211308 --> 0.210632).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2418813\n",
      "\tspeed: 0.0444s/iter; left time: 4.7465s\n",
      "\titers: 200, epoch: 6 | loss: 0.1786923\n",
      "\tspeed: 0.0285s/iter; left time: 0.1998s\n",
      "Epoch: 6 cost time: 5.954991102218628\n",
      "Epoch: 6, Steps: 206 | Train Loss: 0.2337085 Vali Loss: 0.2100104 Test Loss: 0.2246736\n",
      "Validation loss decreased (0.210632 --> 0.210010).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1556\n",
      "Test cost time: 0.5514s\n",
      "test shape: (48, 32, 6, 1) (48, 32, 6, 1)\n",
      "test shape: (1536, 6, 1) (1536, 6, 1)\n",
      "mse:0.22262562811374664, mae:0.36587661504745483\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1440.4947509765625\n",
      "MAE:  29.430856704711914\n",
      "RMSE: 37.95384979248047\n",
      "MAPE: 0.28142648935317993\n",
      "MSPE: 0.21972157061100006\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6859\n",
      "[DEBUG] Original dataset length: 6859\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6593\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1887\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1556\n",
      "\titers: 100, epoch: 1 | loss: 0.5752984\n",
      "\tspeed: 0.0311s/iter; left time: 35.3150s\n",
      "\titers: 200, epoch: 1 | loss: 0.2471205\n",
      "\tspeed: 0.0293s/iter; left time: 30.3722s\n",
      "Epoch: 1 cost time: 6.235276460647583\n",
      "Epoch: 1, Steps: 206 | Train Loss: 0.4816631 Vali Loss: 0.2161394 Test Loss: 0.2356376\n",
      "Validation loss decreased (inf --> 0.216139).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3886417\n",
      "\tspeed: 0.0441s/iter; left time: 41.0922s\n",
      "\titers: 200, epoch: 2 | loss: 0.3283903\n",
      "\tspeed: 0.0292s/iter; left time: 24.2506s\n",
      "Epoch: 2 cost time: 6.014324903488159\n",
      "Epoch: 2, Steps: 206 | Train Loss: 0.3441302 Vali Loss: 0.2275837 Test Loss: 0.2139506\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.4275824\n",
      "\tspeed: 0.0439s/iter; left time: 31.8276s\n",
      "\titers: 200, epoch: 3 | loss: 0.2916708\n",
      "\tspeed: 0.0299s/iter; left time: 18.6809s\n",
      "Epoch: 3 cost time: 6.1670920848846436\n",
      "Epoch: 3, Steps: 206 | Train Loss: 0.2899094 Vali Loss: 0.2083018 Test Loss: 0.1882915\n",
      "Validation loss decreased (0.216139 --> 0.208302).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2434188\n",
      "\tspeed: 0.0442s/iter; left time: 22.9166s\n",
      "\titers: 200, epoch: 4 | loss: 0.2731038\n",
      "\tspeed: 0.0304s/iter; left time: 12.7399s\n",
      "Epoch: 4 cost time: 6.153332948684692\n",
      "Epoch: 4, Steps: 206 | Train Loss: 0.2602690 Vali Loss: 0.2073111 Test Loss: 0.1977926\n",
      "Validation loss decreased (0.208302 --> 0.207311).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3994671\n",
      "\tspeed: 0.0465s/iter; left time: 14.5643s\n",
      "\titers: 200, epoch: 5 | loss: 0.2000120\n",
      "\tspeed: 0.0308s/iter; left time: 6.5507s\n",
      "Epoch: 5 cost time: 6.341076850891113\n",
      "Epoch: 5, Steps: 206 | Train Loss: 0.2384417 Vali Loss: 0.2067587 Test Loss: 0.2162997\n",
      "Validation loss decreased (0.207311 --> 0.206759).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2715912\n",
      "\tspeed: 0.0442s/iter; left time: 4.7254s\n",
      "\titers: 200, epoch: 6 | loss: 0.1566887\n",
      "\tspeed: 0.0301s/iter; left time: 0.2105s\n",
      "Epoch: 6 cost time: 6.11687445640564\n",
      "Epoch: 6, Steps: 206 | Train Loss: 0.2291320 Vali Loss: 0.2047396 Test Loss: 0.2105476\n",
      "Validation loss decreased (0.206759 --> 0.204740).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1556\n",
      "Test cost time: 0.5404s\n",
      "test shape: (48, 32, 6, 1) (48, 32, 6, 1)\n",
      "test shape: (1536, 6, 1) (1536, 6, 1)\n",
      "mse:0.2094970941543579, mae:0.35170891880989075\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1355.5467529296875\n",
      "MAE:  28.291217803955078\n",
      "RMSE: 36.8177490234375\n",
      "MAPE: 0.26792100071907043\n",
      "MSPE: 0.2099880874156952\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6859\n",
      "[DEBUG] Original dataset length: 6859\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6593\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1887\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1556\n",
      "\titers: 100, epoch: 1 | loss: 0.5889376\n",
      "\tspeed: 0.0300s/iter; left time: 34.0773s\n",
      "\titers: 200, epoch: 1 | loss: 0.8748710\n",
      "\tspeed: 0.0301s/iter; left time: 31.2597s\n",
      "Epoch: 1 cost time: 6.207305192947388\n",
      "Epoch: 1, Steps: 206 | Train Loss: 0.4910037 Vali Loss: 0.2942064 Test Loss: 0.4420772\n",
      "Validation loss decreased (inf --> 0.294206).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3319393\n",
      "\tspeed: 0.0451s/iter; left time: 42.0070s\n",
      "\titers: 200, epoch: 2 | loss: 0.2740881\n",
      "\tspeed: 0.0300s/iter; left time: 24.8895s\n",
      "Epoch: 2 cost time: 6.206786870956421\n",
      "Epoch: 2, Steps: 206 | Train Loss: 0.3414508 Vali Loss: 0.2287834 Test Loss: 0.2573518\n",
      "Validation loss decreased (0.294206 --> 0.228783).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1486166\n",
      "\tspeed: 0.0460s/iter; left time: 33.3246s\n",
      "\titers: 200, epoch: 3 | loss: 0.2649686\n",
      "\tspeed: 0.0296s/iter; left time: 18.5252s\n",
      "Epoch: 3 cost time: 6.244127511978149\n",
      "Epoch: 3, Steps: 206 | Train Loss: 0.2853156 Vali Loss: 0.2102681 Test Loss: 0.2638235\n",
      "Validation loss decreased (0.228783 --> 0.210268).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2945259\n",
      "\tspeed: 0.0446s/iter; left time: 23.1263s\n",
      "\titers: 200, epoch: 4 | loss: 0.4000382\n",
      "\tspeed: 0.0290s/iter; left time: 12.1579s\n",
      "Epoch: 4 cost time: 6.0212249755859375\n",
      "Epoch: 4, Steps: 206 | Train Loss: 0.2567614 Vali Loss: 0.2186953 Test Loss: 0.2751011\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1248302\n",
      "\tspeed: 0.0441s/iter; left time: 13.8085s\n",
      "\titers: 200, epoch: 5 | loss: 0.2197615\n",
      "\tspeed: 0.0304s/iter; left time: 6.4663s\n",
      "Epoch: 5 cost time: 6.258644104003906\n",
      "Epoch: 5, Steps: 206 | Train Loss: 0.2403013 Vali Loss: 0.2183653 Test Loss: 0.2518974\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1709083\n",
      "\tspeed: 0.0435s/iter; left time: 4.6546s\n",
      "\titers: 200, epoch: 6 | loss: 0.2131264\n",
      "\tspeed: 0.0310s/iter; left time: 0.2168s\n",
      "Epoch: 6 cost time: 6.219650745391846\n",
      "Epoch: 6, Steps: 206 | Train Loss: 0.2336836 Vali Loss: 0.2098176 Test Loss: 0.2397923\n",
      "Validation loss decreased (0.210268 --> 0.209818).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1556\n",
      "Test cost time: 0.5603s\n",
      "test shape: (48, 32, 6, 1) (48, 32, 6, 1)\n",
      "test shape: (1536, 6, 1) (1536, 6, 1)\n",
      "mse:0.24210572242736816, mae:0.38433679938316345\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1566.5401611328125\n",
      "MAE:  30.91577911376953\n",
      "RMSE: 39.57954406738281\n",
      "MAPE: 0.3039657175540924\n",
      "MSPE: 0.2753258943557739\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6859\n",
      "[DEBUG] Original dataset length: 6859\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6593\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1887\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1556\n",
      "\titers: 100, epoch: 1 | loss: 0.2112795\n",
      "\tspeed: 0.0323s/iter; left time: 36.7011s\n",
      "\titers: 200, epoch: 1 | loss: 0.3094864\n",
      "\tspeed: 0.0295s/iter; left time: 30.5941s\n",
      "Epoch: 1 cost time: 6.371693849563599\n",
      "Epoch: 1, Steps: 206 | Train Loss: 0.4705478 Vali Loss: 0.2450913 Test Loss: 0.2591116\n",
      "Validation loss decreased (inf --> 0.245091).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4038182\n",
      "\tspeed: 0.0465s/iter; left time: 43.3196s\n",
      "\titers: 200, epoch: 2 | loss: 0.2075260\n",
      "\tspeed: 0.0292s/iter; left time: 24.2381s\n",
      "Epoch: 2 cost time: 6.040003061294556\n",
      "Epoch: 2, Steps: 206 | Train Loss: 0.3390371 Vali Loss: 0.2150846 Test Loss: 0.2642763\n",
      "Validation loss decreased (0.245091 --> 0.215085).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3102934\n",
      "\tspeed: 0.0470s/iter; left time: 34.0449s\n",
      "\titers: 200, epoch: 3 | loss: 0.2218506\n",
      "\tspeed: 0.0288s/iter; left time: 17.9746s\n",
      "Epoch: 3 cost time: 6.244991302490234\n",
      "Epoch: 3, Steps: 206 | Train Loss: 0.2874342 Vali Loss: 0.2341964 Test Loss: 0.3064071\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2498211\n",
      "\tspeed: 0.0430s/iter; left time: 22.3172s\n",
      "\titers: 200, epoch: 4 | loss: 0.3631477\n",
      "\tspeed: 0.0289s/iter; left time: 12.1130s\n",
      "Epoch: 4 cost time: 5.91745400428772\n",
      "Epoch: 4, Steps: 206 | Train Loss: 0.2578405 Vali Loss: 0.2227967 Test Loss: 0.3009007\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1860311\n",
      "\tspeed: 0.0443s/iter; left time: 13.8507s\n",
      "\titers: 200, epoch: 5 | loss: 0.1367216\n",
      "\tspeed: 0.0288s/iter; left time: 6.1313s\n",
      "Epoch: 5 cost time: 6.1147966384887695\n",
      "Epoch: 5, Steps: 206 | Train Loss: 0.2409098 Vali Loss: 0.2289696 Test Loss: 0.3011994\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1556\n",
      "Test cost time: 0.5479s\n",
      "test shape: (48, 32, 6, 1) (48, 32, 6, 1)\n",
      "test shape: (1536, 6, 1) (1536, 6, 1)\n",
      "mse:0.26391029357910156, mae:0.4016288220882416\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1707.6263427734375\n",
      "MAE:  32.306739807128906\n",
      "RMSE: 41.32343673706055\n",
      "MAPE: 0.3157850503921509\n",
      "MSPE: 0.30626147985458374\n",
      ">>>>>>>Running time saved<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Running seq_len=144\n",
      "Args in experiment:\n",
      "Namespace(model='informer', data='traffic_after_covid', root_path='../', data_path='traffic_after_covid.csv', features='S', target='flow', freq='h', checkpoints='./checkpoints/', seq_len=144, label_len=24, pred_len=6, enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=2, d_layers=1, s_layers=[3, 2, 1], d_ff=2048, factor=5, padding=0, distil=True, dropout=0.05, attn='prob', embed='timeF', activation='gelu', output_attention=False, do_predict=False, mix=True, cols=None, num_workers=0, itr=10, train_epochs=6, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, inverse=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', detail_freq='h')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6835\n",
      "[DEBUG] Original dataset length: 6835\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6521\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1815\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1484\n",
      "\titers: 100, epoch: 1 | loss: 0.3687506\n",
      "\tspeed: 0.0471s/iter; left time: 52.7344s\n",
      "\titers: 200, epoch: 1 | loss: 0.1629388\n",
      "\tspeed: 0.0339s/iter; left time: 34.5600s\n",
      "Epoch: 1 cost time: 7.318171262741089\n",
      "Epoch: 1, Steps: 203 | Train Loss: 0.4977378 Vali Loss: 0.2612581 Test Loss: 0.4005397\n",
      "Validation loss decreased (inf --> 0.261258).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2208322\n",
      "\tspeed: 0.0469s/iter; left time: 42.9563s\n",
      "\titers: 200, epoch: 2 | loss: 0.2564150\n",
      "\tspeed: 0.0335s/iter; left time: 27.3040s\n",
      "Epoch: 2 cost time: 6.64479923248291\n",
      "Epoch: 2, Steps: 203 | Train Loss: 0.3453104 Vali Loss: 0.2383727 Test Loss: 0.2827041\n",
      "Validation loss decreased (0.261258 --> 0.238373).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2787078\n",
      "\tspeed: 0.0479s/iter; left time: 34.1594s\n",
      "\titers: 200, epoch: 3 | loss: 0.4461797\n",
      "\tspeed: 0.0340s/iter; left time: 20.8428s\n",
      "Epoch: 3 cost time: 6.749755144119263\n",
      "Epoch: 3, Steps: 203 | Train Loss: 0.2953101 Vali Loss: 0.2453393 Test Loss: 0.3062162\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1228520\n",
      "\tspeed: 0.0470s/iter; left time: 23.9906s\n",
      "\titers: 200, epoch: 4 | loss: 0.1294042\n",
      "\tspeed: 0.0323s/iter; left time: 13.2401s\n",
      "Epoch: 4 cost time: 6.641263723373413\n",
      "Epoch: 4, Steps: 203 | Train Loss: 0.2652058 Vali Loss: 0.2271294 Test Loss: 0.2627013\n",
      "Validation loss decreased (0.238373 --> 0.227129).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2501325\n",
      "\tspeed: 0.0485s/iter; left time: 14.9010s\n",
      "\titers: 200, epoch: 5 | loss: 0.3715917\n",
      "\tspeed: 0.0348s/iter; left time: 7.2009s\n",
      "Epoch: 5 cost time: 6.914370059967041\n",
      "Epoch: 5, Steps: 203 | Train Loss: 0.2470493 Vali Loss: 0.2260300 Test Loss: 0.2618279\n",
      "Validation loss decreased (0.227129 --> 0.226030).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1511349\n",
      "\tspeed: 0.0490s/iter; left time: 5.1002s\n",
      "\titers: 200, epoch: 6 | loss: 0.4732822\n",
      "\tspeed: 0.0326s/iter; left time: 0.1304s\n",
      "Epoch: 6 cost time: 6.705587148666382\n",
      "Epoch: 6, Steps: 203 | Train Loss: 0.2367201 Vali Loss: 0.2231405 Test Loss: 0.2833914\n",
      "Validation loss decreased (0.226030 --> 0.223140).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1484\n",
      "Test cost time: 0.5978s\n",
      "test shape: (46, 32, 6, 1) (46, 32, 6, 1)\n",
      "test shape: (1472, 6, 1) (1472, 6, 1)\n",
      "mse:0.28256478905677795, mae:0.43135228753089905\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1828.3299560546875\n",
      "MAE:  34.69767379760742\n",
      "RMSE: 42.758975982666016\n",
      "MAPE: 0.3437148928642273\n",
      "MSPE: 0.521959125995636\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6835\n",
      "[DEBUG] Original dataset length: 6835\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6521\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1815\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1484\n",
      "\titers: 100, epoch: 1 | loss: 0.4177848\n",
      "\tspeed: 0.0340s/iter; left time: 38.0965s\n",
      "\titers: 200, epoch: 1 | loss: 0.3725899\n",
      "\tspeed: 0.0320s/iter; left time: 32.6203s\n",
      "Epoch: 1 cost time: 6.729960918426514\n",
      "Epoch: 1, Steps: 203 | Train Loss: 0.4626601 Vali Loss: 0.2480424 Test Loss: 0.2696160\n",
      "Validation loss decreased (inf --> 0.248042).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7205651\n",
      "\tspeed: 0.0468s/iter; left time: 42.9115s\n",
      "\titers: 200, epoch: 2 | loss: 0.2618845\n",
      "\tspeed: 0.0320s/iter; left time: 26.1324s\n",
      "Epoch: 2 cost time: 6.4993908405303955\n",
      "Epoch: 2, Steps: 203 | Train Loss: 0.3365145 Vali Loss: 0.2641059 Test Loss: 0.3020885\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.4124723\n",
      "\tspeed: 0.0480s/iter; left time: 34.2364s\n",
      "\titers: 200, epoch: 3 | loss: 0.2430637\n",
      "\tspeed: 0.0327s/iter; left time: 20.0531s\n",
      "Epoch: 3 cost time: 6.71734619140625\n",
      "Epoch: 3, Steps: 203 | Train Loss: 0.2816070 Vali Loss: 0.2208039 Test Loss: 0.2652678\n",
      "Validation loss decreased (0.248042 --> 0.220804).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1288344\n",
      "\tspeed: 0.0476s/iter; left time: 24.2894s\n",
      "\titers: 200, epoch: 4 | loss: 0.1262672\n",
      "\tspeed: 0.0322s/iter; left time: 13.1993s\n",
      "Epoch: 4 cost time: 6.584528923034668\n",
      "Epoch: 4, Steps: 203 | Train Loss: 0.2524036 Vali Loss: 0.2091654 Test Loss: 0.2727928\n",
      "Validation loss decreased (0.220804 --> 0.209165).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1493552\n",
      "\tspeed: 0.0496s/iter; left time: 15.2194s\n",
      "\titers: 200, epoch: 5 | loss: 0.1340890\n",
      "\tspeed: 0.0330s/iter; left time: 6.8239s\n",
      "Epoch: 5 cost time: 6.773979187011719\n",
      "Epoch: 5, Steps: 203 | Train Loss: 0.2337167 Vali Loss: 0.2124389 Test Loss: 0.2987266\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2199564\n",
      "\tspeed: 0.0463s/iter; left time: 4.8181s\n",
      "\titers: 200, epoch: 6 | loss: 0.2463014\n",
      "\tspeed: 0.0330s/iter; left time: 0.1318s\n",
      "Epoch: 6 cost time: 6.603792428970337\n",
      "Epoch: 6, Steps: 203 | Train Loss: 0.2244466 Vali Loss: 0.2118824 Test Loss: 0.3156835\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1484\n",
      "Test cost time: 0.5876s\n",
      "test shape: (46, 32, 6, 1) (46, 32, 6, 1)\n",
      "test shape: (1472, 6, 1) (1472, 6, 1)\n",
      "mse:0.2728572189807892, mae:0.41510841250419617\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1765.517578125\n",
      "MAE:  33.391029357910156\n",
      "RMSE: 42.018062591552734\n",
      "MAPE: 0.30885037779808044\n",
      "MSPE: 0.1963380128145218\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6835\n",
      "[DEBUG] Original dataset length: 6835\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6521\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1815\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1484\n",
      "\titers: 100, epoch: 1 | loss: 0.9487160\n",
      "\tspeed: 0.0323s/iter; left time: 36.1550s\n",
      "\titers: 200, epoch: 1 | loss: 0.3543596\n",
      "\tspeed: 0.0324s/iter; left time: 33.0350s\n",
      "Epoch: 1 cost time: 6.588727712631226\n",
      "Epoch: 1, Steps: 203 | Train Loss: 0.4788458 Vali Loss: 0.2580419 Test Loss: 0.3312749\n",
      "Validation loss decreased (inf --> 0.258042).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3276971\n",
      "\tspeed: 0.0468s/iter; left time: 42.8987s\n",
      "\titers: 200, epoch: 2 | loss: 0.3446789\n",
      "\tspeed: 0.0338s/iter; left time: 27.5518s\n",
      "Epoch: 2 cost time: 6.701716184616089\n",
      "Epoch: 2, Steps: 203 | Train Loss: 0.3314066 Vali Loss: 0.2360987 Test Loss: 0.2481477\n",
      "Validation loss decreased (0.258042 --> 0.236099).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1249357\n",
      "\tspeed: 0.0473s/iter; left time: 33.7250s\n",
      "\titers: 200, epoch: 3 | loss: 0.3792590\n",
      "\tspeed: 0.0322s/iter; left time: 19.7304s\n",
      "Epoch: 3 cost time: 6.539045095443726\n",
      "Epoch: 3, Steps: 203 | Train Loss: 0.2846731 Vali Loss: 0.2570069 Test Loss: 0.2850082\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1427154\n",
      "\tspeed: 0.0456s/iter; left time: 23.2607s\n",
      "\titers: 200, epoch: 4 | loss: 0.2071974\n",
      "\tspeed: 0.0346s/iter; left time: 14.1785s\n",
      "Epoch: 4 cost time: 6.72248649597168\n",
      "Epoch: 4, Steps: 203 | Train Loss: 0.2499181 Vali Loss: 0.2115930 Test Loss: 0.2790179\n",
      "Validation loss decreased (0.236099 --> 0.211593).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1935496\n",
      "\tspeed: 0.0474s/iter; left time: 14.5664s\n",
      "\titers: 200, epoch: 5 | loss: 0.2342270\n",
      "\tspeed: 0.0320s/iter; left time: 6.6335s\n",
      "Epoch: 5 cost time: 6.53615665435791\n",
      "Epoch: 5, Steps: 203 | Train Loss: 0.2322010 Vali Loss: 0.2062998 Test Loss: 0.2585147\n",
      "Validation loss decreased (0.211593 --> 0.206300).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1968444\n",
      "\tspeed: 0.0482s/iter; left time: 5.0105s\n",
      "\titers: 200, epoch: 6 | loss: 0.1419303\n",
      "\tspeed: 0.0333s/iter; left time: 0.1332s\n",
      "Epoch: 6 cost time: 6.716846466064453\n",
      "Epoch: 6, Steps: 203 | Train Loss: 0.2261074 Vali Loss: 0.2054004 Test Loss: 0.2565601\n",
      "Validation loss decreased (0.206300 --> 0.205400).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_after_covid_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1484\n",
      "Test cost time: 0.6268s\n",
      "test shape: (46, 32, 6, 1) (46, 32, 6, 1)\n",
      "test shape: (1472, 6, 1) (1472, 6, 1)\n",
      "mse:0.25519201159477234, mae:0.39293941855430603\n",
      ">>>>>>>inverse results : informer_traffic_after_covid_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1651.2147216796875\n",
      "MAE:  31.607769012451172\n",
      "RMSE: 40.6351432800293\n",
      "MAPE: 0.2975916564464569\n",
      "MSPE: 0.2556307315826416\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_after_covid_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 6835\n",
      "[DEBUG] Original dataset length: 6835\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6521\n",
      "val 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1815\n",
      "test 2323\n",
      "[DEBUG] Original dataset length: 2323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 1484\n",
      "\titers: 100, epoch: 1 | loss: 0.2404628\n",
      "\tspeed: 0.0323s/iter; left time: 36.1550s\n",
      "\titers: 200, epoch: 1 | loss: 0.4266952\n",
      "\tspeed: 0.0325s/iter; left time: 33.1296s\n",
      "Epoch: 1 cost time: 6.590394020080566\n",
      "Epoch: 1, Steps: 203 | Train Loss: 0.5158298 Vali Loss: 0.3105322 Test Loss: 0.2933567\n",
      "Validation loss decreased (inf --> 0.310532).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2344279\n",
      "\tspeed: 0.0490s/iter; left time: 44.8513s\n",
      "\titers: 200, epoch: 2 | loss: 0.3021324\n",
      "\tspeed: 0.0324s/iter; left time: 26.4179s\n",
      "Epoch: 2 cost time: 6.752136707305908\n",
      "Epoch: 2, Steps: 203 | Train Loss: 0.3435750 Vali Loss: 0.2395811 Test Loss: 0.2132926\n",
      "Validation loss decreased (0.310532 --> 0.239581).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.5179273\n",
      "\tspeed: 0.0481s/iter; left time: 34.3008s\n",
      "\titers: 200, epoch: 3 | loss: 0.2289384\n",
      "\tspeed: 0.0321s/iter; left time: 19.6638s\n",
      "Epoch: 3 cost time: 6.540564060211182\n",
      "Epoch: 3, Steps: 203 | Train Loss: 0.2729938 Vali Loss: 0.2375523 Test Loss: 0.2817337\n",
      "Validation loss decreased (0.239581 --> 0.237552).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1939323\n",
      "\tspeed: 0.0491s/iter; left time: 25.0193s\n"
     ]
    }
   ],
   "source": [
    "# after covid dataset\n",
    "for seq_len in seq_lens:\n",
    "    print(f\"Running seq_len={seq_len}\")\n",
    "    !python -u main_informer.py --model informer --data traffic_after_covid --root_path ../ --features S --seq_len {seq_len} --label_len 24 --pred_len 6 --e_layers 2 --d_layers 1 --attn prob --des 'Exp' --itr 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b6691ac-0a81-4ead-a255-8904e5bafeb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.38114933, 0.54586172])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load(\"./results/running_time_24.npy\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1a4d2e-92ac-41f1-bb1f-31c42347b0f7",
   "metadata": {},
   "source": [
    "## Calculate the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51ae6507-049c-48f1-afe2-9636d77bb319",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract seq_len and run number from directory name\n",
    "# Example:\n",
    "# informer_traffic_full_ftS_sl24_ll24_pl6_dm512_..._Exp_3\n",
    "# seq_len = 24, run_num = 3\n",
    "def extract_info(dirname):\n",
    "    seq_match = re.search(r\"sl(\\d+)\", dirname)\n",
    "    run_match = re.search(r\"Exp_(\\d+)\", dirname)\n",
    "\n",
    "    seq_len = int(seq_match.group(1)) if seq_match else None\n",
    "    run_num = int(run_match.group(1)) + 1 if run_match else None  # Exp_0 → run 1\n",
    "\n",
    "    return seq_len, run_num\n",
    "\n",
    "# Compute metrics for each of 6 prediction steps\n",
    "# pred, true shape: (N, 6, 1)\n",
    "def compute_step_metrics(pred, true):\n",
    "    steps = pred.shape[1]\n",
    "    rows = []\n",
    "\n",
    "    for step in range(steps):\n",
    "        p = pred[:, step, 0]\n",
    "        g = true[:, step, 0]\n",
    "\n",
    "        mae = mean_absolute_error(g, p)\n",
    "        rmse = root_mean_squared_error(g, p)\n",
    "        mape = mean_absolute_percentage_error(g, p) * 100  # convert to percentage\n",
    "        rows.append((step + 1, mae, rmse, mape))\n",
    "        \n",
    "    return rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8514c65-aa46-4bef-ae18-9e98e73b50b6",
   "metadata": {},
   "source": [
    "Metrics of each run and each step (6×10×21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "242c9ab5-6767-4be6-8edf-4ef54f8594b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping missing: .ipynb_checkpoints\n"
     ]
    }
   ],
   "source": [
    "def whole_metrics(target_dataset):\n",
    "    all_rows = []\n",
    "    \n",
    "    # your result directories (you can replace this with auto-search)\n",
    "    result_dirs = sorted([\n",
    "        d for d in os.listdir(\"results\")\n",
    "        if os.path.isdir(os.path.join(\"results\", d)) and f\"informer_{target_dataset}_\" in d  # <<< key filtering step\n",
    "    ])\n",
    "    \n",
    "    for d in result_dirs:\n",
    "        seq_len, run_num = extract_info(d)\n",
    "    \n",
    "        pred_path = os.path.join(\"results\", d, \"pred_inverse.npy\")\n",
    "        true_path = os.path.join(\"results\", d, \"true_inverse.npy\")\n",
    "    \n",
    "        if not (os.path.exists(pred_path) and os.path.exists(true_path)):\n",
    "            print(f\"Skipping missing: {d}\")\n",
    "            continue\n",
    "    \n",
    "        pred = np.load(pred_path)\n",
    "        true = np.load(true_path)\n",
    "    \n",
    "        metrics = compute_step_metrics(pred, true)\n",
    "    \n",
    "        for step, mae, rmse, mape in metrics:\n",
    "            all_rows.append({\n",
    "                \"input_len\": seq_len,\n",
    "                \"run_num\": run_num,\n",
    "                \"pre_step\": step,\n",
    "                \"MAE_test\": mae,\n",
    "                \"RMSE_test\": rmse,\n",
    "                \"MAPE (%)_test\": mape\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(all_rows)\n",
    "    df = df.sort_values(by=[\"input_len\", \"run_num\", \"pre_step\"]).reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f390323-f2f0-4450-a8ed-fd8b5a4e8eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_full = whole_metrics(\"traffic_full\")\n",
    "#metrics_full.to_csv('../all_metrics_informer_entire_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437a83fa-3f03-4f90-9475-1274f44feb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_metrics(\"traffic_after_covid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4dea85-9b0a-4e8a-a13e-b83d5de5c7b5",
   "metadata": {},
   "source": [
    "Metrics of each input length (21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "151ef470-abfe-4360-8a2c-334c5bedd5a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_len</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>26.827424</td>\n",
       "      <td>40.091506</td>\n",
       "      <td>33.976340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>27.086889</td>\n",
       "      <td>40.371117</td>\n",
       "      <td>35.322956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>27.484757</td>\n",
       "      <td>40.414853</td>\n",
       "      <td>37.142969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96</td>\n",
       "      <td>27.565523</td>\n",
       "      <td>41.038521</td>\n",
       "      <td>35.855909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>27.364081</td>\n",
       "      <td>41.213944</td>\n",
       "      <td>35.366292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>144</td>\n",
       "      <td>27.528013</td>\n",
       "      <td>41.292334</td>\n",
       "      <td>35.943623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>168</td>\n",
       "      <td>27.900328</td>\n",
       "      <td>41.459094</td>\n",
       "      <td>37.013240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>192</td>\n",
       "      <td>27.311530</td>\n",
       "      <td>41.252090</td>\n",
       "      <td>34.981317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>216</td>\n",
       "      <td>27.348362</td>\n",
       "      <td>40.972219</td>\n",
       "      <td>37.868599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>240</td>\n",
       "      <td>27.662873</td>\n",
       "      <td>41.741723</td>\n",
       "      <td>37.931720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>264</td>\n",
       "      <td>27.909886</td>\n",
       "      <td>42.613484</td>\n",
       "      <td>36.033699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>288</td>\n",
       "      <td>28.428512</td>\n",
       "      <td>42.839811</td>\n",
       "      <td>38.538594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>312</td>\n",
       "      <td>27.657373</td>\n",
       "      <td>42.875749</td>\n",
       "      <td>34.077934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>336</td>\n",
       "      <td>28.042166</td>\n",
       "      <td>42.898795</td>\n",
       "      <td>35.931267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>360</td>\n",
       "      <td>28.378985</td>\n",
       "      <td>43.788344</td>\n",
       "      <td>34.976826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>384</td>\n",
       "      <td>28.860072</td>\n",
       "      <td>44.196937</td>\n",
       "      <td>36.085584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>408</td>\n",
       "      <td>29.124343</td>\n",
       "      <td>44.124789</td>\n",
       "      <td>38.010948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>432</td>\n",
       "      <td>28.937098</td>\n",
       "      <td>44.651621</td>\n",
       "      <td>36.279675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>456</td>\n",
       "      <td>29.117829</td>\n",
       "      <td>44.748922</td>\n",
       "      <td>37.068310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>480</td>\n",
       "      <td>29.624438</td>\n",
       "      <td>46.003536</td>\n",
       "      <td>36.347774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>504</td>\n",
       "      <td>29.368494</td>\n",
       "      <td>46.124282</td>\n",
       "      <td>36.350152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    input_len   MAE_test  RMSE_test  MAPE (%)_test\n",
       "0          24  26.827424  40.091506      33.976340\n",
       "1          48  27.086889  40.371117      35.322956\n",
       "2          72  27.484757  40.414853      37.142969\n",
       "3          96  27.565523  41.038521      35.855909\n",
       "4         120  27.364081  41.213944      35.366292\n",
       "5         144  27.528013  41.292334      35.943623\n",
       "6         168  27.900328  41.459094      37.013240\n",
       "7         192  27.311530  41.252090      34.981317\n",
       "8         216  27.348362  40.972219      37.868599\n",
       "9         240  27.662873  41.741723      37.931720\n",
       "10        264  27.909886  42.613484      36.033699\n",
       "11        288  28.428512  42.839811      38.538594\n",
       "12        312  27.657373  42.875749      34.077934\n",
       "13        336  28.042166  42.898795      35.931267\n",
       "14        360  28.378985  43.788344      34.976826\n",
       "15        384  28.860072  44.196937      36.085584\n",
       "16        408  29.124343  44.124789      38.010948\n",
       "17        432  28.937098  44.651621      36.279675\n",
       "18        456  29.117829  44.748922      37.068310\n",
       "19        480  29.624438  46.003536      36.347774\n",
       "20        504  29.368494  46.124282      36.350152"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_seq = metrics_full.groupby(\"input_len\")[[\"MAE_test\", \"RMSE_test\", \"MAPE (%)_test\"]].mean().reset_index()\n",
    "#avg_by_seq.to_csv('../metrics_informer_entire_data.csv', index=False)\n",
    "avg_by_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cd8d93-030e-48fe-a222-b8caea3294c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b194aac0-3818-4daf-8c74-6f7cdb1b488a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] Missing metrics_inverse.npy in results/.ipynb_checkpoints\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_len</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>26.827423</td>\n",
       "      <td>40.248596</td>\n",
       "      <td>33.976345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>27.086889</td>\n",
       "      <td>40.532936</td>\n",
       "      <td>35.322960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>27.484756</td>\n",
       "      <td>40.567635</td>\n",
       "      <td>37.142967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96</td>\n",
       "      <td>27.565521</td>\n",
       "      <td>41.195618</td>\n",
       "      <td>35.855907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>27.364080</td>\n",
       "      <td>41.375389</td>\n",
       "      <td>35.366291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>144</td>\n",
       "      <td>27.528015</td>\n",
       "      <td>41.451664</td>\n",
       "      <td>35.943626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>168</td>\n",
       "      <td>27.900330</td>\n",
       "      <td>41.608902</td>\n",
       "      <td>37.013237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>192</td>\n",
       "      <td>27.311533</td>\n",
       "      <td>41.407749</td>\n",
       "      <td>34.981316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>216</td>\n",
       "      <td>27.348362</td>\n",
       "      <td>41.117546</td>\n",
       "      <td>37.868603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>240</td>\n",
       "      <td>27.662872</td>\n",
       "      <td>41.893860</td>\n",
       "      <td>37.931721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>264</td>\n",
       "      <td>27.909887</td>\n",
       "      <td>42.781487</td>\n",
       "      <td>36.033703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>288</td>\n",
       "      <td>28.428513</td>\n",
       "      <td>43.016197</td>\n",
       "      <td>38.538597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>312</td>\n",
       "      <td>27.657373</td>\n",
       "      <td>43.059753</td>\n",
       "      <td>34.077934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>336</td>\n",
       "      <td>28.042166</td>\n",
       "      <td>43.075539</td>\n",
       "      <td>35.931267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>360</td>\n",
       "      <td>28.378986</td>\n",
       "      <td>43.971962</td>\n",
       "      <td>34.976826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>384</td>\n",
       "      <td>28.860071</td>\n",
       "      <td>44.398430</td>\n",
       "      <td>36.085587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>408</td>\n",
       "      <td>29.124344</td>\n",
       "      <td>44.320198</td>\n",
       "      <td>38.010944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>432</td>\n",
       "      <td>28.937099</td>\n",
       "      <td>44.846455</td>\n",
       "      <td>36.279671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>456</td>\n",
       "      <td>29.117828</td>\n",
       "      <td>44.940174</td>\n",
       "      <td>37.068310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>480</td>\n",
       "      <td>29.624439</td>\n",
       "      <td>46.211472</td>\n",
       "      <td>36.347771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>504</td>\n",
       "      <td>29.368494</td>\n",
       "      <td>46.341087</td>\n",
       "      <td>36.350151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    input_len   MAE_test  RMSE_test  MAPE (%)_test\n",
       "0          24  26.827423  40.248596      33.976345\n",
       "1          48  27.086889  40.532936      35.322960\n",
       "2          72  27.484756  40.567635      37.142967\n",
       "3          96  27.565521  41.195618      35.855907\n",
       "4         120  27.364080  41.375389      35.366291\n",
       "5         144  27.528015  41.451664      35.943626\n",
       "6         168  27.900330  41.608902      37.013237\n",
       "7         192  27.311533  41.407749      34.981316\n",
       "8         216  27.348362  41.117546      37.868603\n",
       "9         240  27.662872  41.893860      37.931721\n",
       "10        264  27.909887  42.781487      36.033703\n",
       "11        288  28.428513  43.016197      38.538597\n",
       "12        312  27.657373  43.059753      34.077934\n",
       "13        336  28.042166  43.075539      35.931267\n",
       "14        360  28.378986  43.971962      34.976826\n",
       "15        384  28.860071  44.398430      36.085587\n",
       "16        408  29.124344  44.320198      38.010944\n",
       "17        432  28.937099  44.846455      36.279671\n",
       "18        456  29.117828  44.940174      37.068310\n",
       "19        480  29.624439  46.211472      36.347771\n",
       "20        504  29.368494  46.341087      36.350151"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect all result directories\n",
    "target_dataset = \"traffic_full\"\n",
    "result_dirs = sorted([\n",
    "    d for d in os.listdir(\"results\")\n",
    "    if os.path.isdir(os.path.join(\"results\", d)) and f\"informer_{target_dataset}_\" in d  # <<< key filtering step\n",
    "])\n",
    "\n",
    "# Dictionary to store metrics per seq_len\n",
    "metrics_dict = {}\n",
    "\n",
    "for d in result_dirs:\n",
    "    folder_path = os.path.join(\"results\", d)\n",
    "    \n",
    "    metrics_path = os.path.join(folder_path, \"metrics_inverse.npy\")\n",
    "    if not os.path.exists(metrics_path):\n",
    "        print(f\"[WARNING] Missing metrics_inverse.npy in {folder_path}\")\n",
    "        continue\n",
    "    \n",
    "    metrics = np.load(metrics_path)  # [MAE, MSE, RMSE, MAPE, MSPE]\n",
    "    \n",
    "    # Extract seq_len from folder name (assuming folder name contains 'sl<seq_len>_run<run_num>')\n",
    "    seq_len = int([s for s in d.split(\"_\") if s.startswith(\"sl\")][0][2:])\n",
    "    \n",
    "    if seq_len not in metrics_dict:\n",
    "        metrics_dict[seq_len] = {\"MAE\": [], \"RMSE\": [], \"MAPE\": []}\n",
    "    \n",
    "    metrics_dict[seq_len][\"MAE\"].append(metrics[0])\n",
    "    metrics_dict[seq_len][\"RMSE\"].append(metrics[2])\n",
    "    metrics_dict[seq_len][\"MAPE\"].append(metrics[3])\n",
    "\n",
    "# Calculate mean over all runs per seq_len\n",
    "rows = []\n",
    "for seq_len, vals in metrics_dict.items():\n",
    "    rows.append({\n",
    "        \"input_len\": seq_len,\n",
    "        \"MAE_test\": np.mean(vals[\"MAE\"]),\n",
    "        \"RMSE_test\": np.mean(vals[\"RMSE\"]),\n",
    "        \"MAPE (%)_test\": np.mean(vals[\"MAPE\"]) *100\n",
    "    })\n",
    "\n",
    "df_inverse_avg = pd.DataFrame(rows).sort_values(\"input_len\").reset_index(drop=True)\n",
    "df_inverse_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2571b057-b72b-4a49-b779-a68eb3a3466c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_seq.equals(df_inverse_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ceab08c1-73bd-47ef-a8a2-9ea741bfe525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAE_test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RMSE_test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>self</th>\n",
       "      <th>other</th>\n",
       "      <th>self</th>\n",
       "      <th>other</th>\n",
       "      <th>self</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.827424</td>\n",
       "      <td>26.827423</td>\n",
       "      <td>40.091506</td>\n",
       "      <td>40.248596</td>\n",
       "      <td>33.976340</td>\n",
       "      <td>33.976345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.086889</td>\n",
       "      <td>27.086889</td>\n",
       "      <td>40.371117</td>\n",
       "      <td>40.532936</td>\n",
       "      <td>35.322956</td>\n",
       "      <td>35.322960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.484757</td>\n",
       "      <td>27.484756</td>\n",
       "      <td>40.414853</td>\n",
       "      <td>40.567635</td>\n",
       "      <td>37.142969</td>\n",
       "      <td>37.142967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.565523</td>\n",
       "      <td>27.565521</td>\n",
       "      <td>41.038521</td>\n",
       "      <td>41.195618</td>\n",
       "      <td>35.855909</td>\n",
       "      <td>35.855907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.364081</td>\n",
       "      <td>27.364080</td>\n",
       "      <td>41.213944</td>\n",
       "      <td>41.375389</td>\n",
       "      <td>35.366292</td>\n",
       "      <td>35.366291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27.528013</td>\n",
       "      <td>27.528015</td>\n",
       "      <td>41.292334</td>\n",
       "      <td>41.451664</td>\n",
       "      <td>35.943623</td>\n",
       "      <td>35.943626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27.900328</td>\n",
       "      <td>27.900330</td>\n",
       "      <td>41.459094</td>\n",
       "      <td>41.608902</td>\n",
       "      <td>37.013240</td>\n",
       "      <td>37.013237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>27.311530</td>\n",
       "      <td>27.311533</td>\n",
       "      <td>41.252090</td>\n",
       "      <td>41.407749</td>\n",
       "      <td>34.981317</td>\n",
       "      <td>34.981316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27.348362</td>\n",
       "      <td>27.348362</td>\n",
       "      <td>40.972219</td>\n",
       "      <td>41.117546</td>\n",
       "      <td>37.868599</td>\n",
       "      <td>37.868603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>27.662873</td>\n",
       "      <td>27.662872</td>\n",
       "      <td>41.741723</td>\n",
       "      <td>41.893860</td>\n",
       "      <td>37.931720</td>\n",
       "      <td>37.931721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>27.909886</td>\n",
       "      <td>27.909887</td>\n",
       "      <td>42.613484</td>\n",
       "      <td>42.781487</td>\n",
       "      <td>36.033699</td>\n",
       "      <td>36.033703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>28.428512</td>\n",
       "      <td>28.428513</td>\n",
       "      <td>42.839811</td>\n",
       "      <td>43.016197</td>\n",
       "      <td>38.538594</td>\n",
       "      <td>38.538597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>27.657373</td>\n",
       "      <td>27.657373</td>\n",
       "      <td>42.875749</td>\n",
       "      <td>43.059753</td>\n",
       "      <td>34.077934</td>\n",
       "      <td>34.077934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>28.042166</td>\n",
       "      <td>28.042166</td>\n",
       "      <td>42.898795</td>\n",
       "      <td>43.075539</td>\n",
       "      <td>35.931267</td>\n",
       "      <td>35.931267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>28.378985</td>\n",
       "      <td>28.378986</td>\n",
       "      <td>43.788344</td>\n",
       "      <td>43.971962</td>\n",
       "      <td>34.976826</td>\n",
       "      <td>34.976826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>28.860072</td>\n",
       "      <td>28.860071</td>\n",
       "      <td>44.196937</td>\n",
       "      <td>44.398430</td>\n",
       "      <td>36.085584</td>\n",
       "      <td>36.085587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>29.124343</td>\n",
       "      <td>29.124344</td>\n",
       "      <td>44.124789</td>\n",
       "      <td>44.320198</td>\n",
       "      <td>38.010948</td>\n",
       "      <td>38.010944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>28.937098</td>\n",
       "      <td>28.937099</td>\n",
       "      <td>44.651621</td>\n",
       "      <td>44.846455</td>\n",
       "      <td>36.279675</td>\n",
       "      <td>36.279671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>29.117829</td>\n",
       "      <td>29.117828</td>\n",
       "      <td>44.748922</td>\n",
       "      <td>44.940174</td>\n",
       "      <td>37.068310</td>\n",
       "      <td>37.068310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>29.624438</td>\n",
       "      <td>29.624439</td>\n",
       "      <td>46.003536</td>\n",
       "      <td>46.211472</td>\n",
       "      <td>36.347774</td>\n",
       "      <td>36.347771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>29.368494</td>\n",
       "      <td>29.368494</td>\n",
       "      <td>46.124282</td>\n",
       "      <td>46.341087</td>\n",
       "      <td>36.350152</td>\n",
       "      <td>36.350151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAE_test             RMSE_test            MAPE (%)_test           \n",
       "         self      other       self      other          self      other\n",
       "0   26.827424  26.827423  40.091506  40.248596     33.976340  33.976345\n",
       "1   27.086889  27.086889  40.371117  40.532936     35.322956  35.322960\n",
       "2   27.484757  27.484756  40.414853  40.567635     37.142969  37.142967\n",
       "3   27.565523  27.565521  41.038521  41.195618     35.855909  35.855907\n",
       "4   27.364081  27.364080  41.213944  41.375389     35.366292  35.366291\n",
       "5   27.528013  27.528015  41.292334  41.451664     35.943623  35.943626\n",
       "6   27.900328  27.900330  41.459094  41.608902     37.013240  37.013237\n",
       "7   27.311530  27.311533  41.252090  41.407749     34.981317  34.981316\n",
       "8   27.348362  27.348362  40.972219  41.117546     37.868599  37.868603\n",
       "9   27.662873  27.662872  41.741723  41.893860     37.931720  37.931721\n",
       "10  27.909886  27.909887  42.613484  42.781487     36.033699  36.033703\n",
       "11  28.428512  28.428513  42.839811  43.016197     38.538594  38.538597\n",
       "12  27.657373  27.657373  42.875749  43.059753     34.077934  34.077934\n",
       "13  28.042166  28.042166  42.898795  43.075539     35.931267  35.931267\n",
       "14  28.378985  28.378986  43.788344  43.971962     34.976826  34.976826\n",
       "15  28.860072  28.860071  44.196937  44.398430     36.085584  36.085587\n",
       "16  29.124343  29.124344  44.124789  44.320198     38.010948  38.010944\n",
       "17  28.937098  28.937099  44.651621  44.846455     36.279675  36.279671\n",
       "18  29.117829  29.117828  44.748922  44.940174     37.068310  37.068310\n",
       "19  29.624438  29.624439  46.003536  46.211472     36.347774  36.347771\n",
       "20  29.368494  29.368494  46.124282  46.341087     36.350152  36.350151"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_seq.compare(df_inverse_avg)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7620b5f-c4b8-436b-8c89-6ee474c5d53b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "transformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
