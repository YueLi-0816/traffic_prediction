{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67f7f33-1987-4932-9803-883ede914b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/zhouhaoyi/Informer2020.git\n",
    "#!git clone https://github.com/zhouhaoyi/ETDataset.git\n",
    "# modify the code based on my dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e4301a-419a-40b0-98e8-eea762441e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !{sys.executable} -m pip install matplotlib\n",
    "# !{sys.executable} -m pip install pandas\n",
    "# !{sys.executable} -m pip install scikit_learn\n",
    "# !{sys.executable} -m pip install torch\n",
    "# !{sys.executable} -m pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb6cc0a2-7f97-4bc2-b439-c7b775a9cd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from argparse import Namespace\n",
    "import re\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    root_mean_squared_error,\n",
    "    mean_absolute_percentage_error\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60a07922-9f8e-44bb-825a-b576a86a90e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not 'Informer2020' in sys.path:\n",
    "    sys.path += ['Informer2020']\n",
    "\n",
    "from data.data_loader import Dataset_Custom\n",
    "from utils.metrics import metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd148590-d5a3-4a2b-afa4-77b77d84a671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cu128\n",
      "12.8\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6373961a-d2b9-4fbb-96a5-9ad2c3fbdc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 1\n",
      "GPU 0: NVIDIA A30\n"
     ]
    }
   ],
   "source": [
    "num_gpus = torch.cuda.device_count()\n",
    "print(\"Number of GPUs available:\", num_gpus)\n",
    "\n",
    "for i in range(num_gpus):\n",
    "    gpu_name = torch.cuda.get_device_name(i)\n",
    "    print(f\"GPU {i}: {gpu_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd1c08a-8be5-4e5c-a69c-b838fc3803d5",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d5eb9c8-e5e9-43e4-b287-564297d0b25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = pd.read_csv('../GD030A_S.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e02c837f-f057-48fc-ad77-aa5d7c99d36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the recover_timestamp function\n",
    "def recover_timestamp(data):\n",
    "    # Combine 'date' and 'time' to form a datetime column\n",
    "    data['datetime'] = pd.to_datetime(data['date'] + ' ' + data['time'].astype(str) + ':00', format='%Y-%m-%d %H:%M')\n",
    "\n",
    "    # Set 'datetime' as index\n",
    "    data = data.set_index('datetime')\n",
    "\n",
    "    # Create a complete range of timestamps with hourly frequency\n",
    "    full_time_range = pd.date_range(start=data.index.min(), end=data.index.max(), freq='H')\n",
    "\n",
    "    # Reindex the data to include all timestamps, filling missing rows with NaN\n",
    "    data_full = data.reindex(full_time_range)\n",
    "\n",
    "    return data_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fb2e9e-0912-4c8a-8ccd-bca7f1fc91d9",
   "metadata": {},
   "source": [
    "Custom data (xxx.csv) has to include at least 2 features: date(format: YYYY-MM-DD hh:mm:ss) and target feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fa5669-e577-40ea-9c59-6e998abacda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_full = recover_timestamp(my_data)\n",
    "traffic_full.drop(['date', 'time'], axis=1, inplace=True)\n",
    "traffic_full = traffic_full.reset_index(names='date')\n",
    "traffic_full['date'] = traffic_full['date'].astype(str)\n",
    "traffic_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e64353-3a50-4922-b0ae-81f1f592c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#traffic_full.to_csv('traffic_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04616932-2190-4b35-bceb-1bf11fa3e582",
   "metadata": {},
   "source": [
    "## Run training directly using bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6890335e-1970-46ea-a2f0-9f3a9fb4938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure the shell commands below using the current Python environment\n",
    "os.environ[\"PATH\"] = f\"{sys.prefix}/bin:\" + os.environ[\"PATH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adf9133b-3e63-4228-8340-98bc089bf852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/transformer/Informer2020\n"
     ]
    }
   ],
   "source": [
    "cd Informer2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ce82bd-438d-4fec-b166-87b2984ae0f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test\n",
    "#!python -u main_informer.py --model informer --data traffic_full --root_path ../ --features S --seq_len 24 --label_len 24 --pred_len 6 --e_layers 2 --d_layers 1 --attn prob --des 'Exp' --itr 1 #--inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "297f6900-cd2b-4569-8ef9-4b2e4dd2b144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24, 48, 72, 96, 120, 144, 168, 192, 216, 240, 264, 288, 312, 336, 360, 384, 408, 432, 456, 480, 504]\n"
     ]
    }
   ],
   "source": [
    "seq_lens = [24 * i for i in range(1, 22)]\n",
    "print(seq_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97623185-1858-4ecd-99d3-bb9f6ff19c6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running seq_len=24\n",
      "Args in experiment:\n",
      "Namespace(model='informer', data='traffic_full', root_path='../', data_path='traffic_full.csv', features='S', target='flow', freq='h', checkpoints='./checkpoints/', seq_len=24, label_len=24, pred_len=6, enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=2, d_layers=1, s_layers=[3, 2, 1], d_ff=2048, factor=5, padding=0, distil=True, dropout=0.05, attn='prob', embed='timeF', activation='gelu', output_attention=False, do_predict=False, mix=True, cols=None, num_workers=0, itr=10, train_epochs=6, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, inverse=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', detail_freq='h')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24515\n",
      "[DEBUG] Original dataset length: 24515\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 23049\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3471\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.5087171\n",
      "\tspeed: 0.0341s/iter; left time: 143.8689s\n",
      "\titers: 200, epoch: 1 | loss: 0.2924829\n",
      "\tspeed: 0.0241s/iter; left time: 99.2028s\n",
      "\titers: 300, epoch: 1 | loss: 0.2128198\n",
      "\tspeed: 0.0236s/iter; left time: 95.0376s\n",
      "\titers: 400, epoch: 1 | loss: 0.2423227\n",
      "\tspeed: 0.0243s/iter; left time: 95.1359s\n",
      "\titers: 500, epoch: 1 | loss: 0.1456409\n",
      "\tspeed: 0.0222s/iter; left time: 84.6965s\n",
      "\titers: 600, epoch: 1 | loss: 0.2169240\n",
      "\tspeed: 0.0263s/iter; left time: 97.6984s\n",
      "\titers: 700, epoch: 1 | loss: 0.1754534\n",
      "\tspeed: 0.0220s/iter; left time: 79.6601s\n",
      "Epoch: 1 cost time: 17.29293417930603\n",
      "Epoch: 1, Steps: 720 | Train Loss: 0.2715616 Vali Loss: 0.3496845 Test Loss: 0.2752833\n",
      "Validation loss decreased (inf --> 0.349685).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2565038\n",
      "\tspeed: 0.0572s/iter; left time: 200.3111s\n",
      "\titers: 200, epoch: 2 | loss: 0.1470400\n",
      "\tspeed: 0.0240s/iter; left time: 81.5308s\n",
      "\titers: 300, epoch: 2 | loss: 0.1972954\n",
      "\tspeed: 0.0222s/iter; left time: 73.2054s\n",
      "\titers: 400, epoch: 2 | loss: 0.2398903\n",
      "\tspeed: 0.0263s/iter; left time: 84.1974s\n",
      "\titers: 500, epoch: 2 | loss: 0.1779394\n",
      "\tspeed: 0.0235s/iter; left time: 72.8122s\n",
      "\titers: 600, epoch: 2 | loss: 0.1817638\n",
      "\tspeed: 0.0235s/iter; left time: 70.6369s\n",
      "\titers: 700, epoch: 2 | loss: 0.1919735\n",
      "\tspeed: 0.0226s/iter; left time: 65.6352s\n",
      "Epoch: 2 cost time: 16.97560739517212\n",
      "Epoch: 2, Steps: 720 | Train Loss: 0.2118871 Vali Loss: 0.3276516 Test Loss: 0.2484862\n",
      "Validation loss decreased (0.349685 --> 0.327652).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1172348\n",
      "\tspeed: 0.0553s/iter; left time: 153.8786s\n",
      "\titers: 200, epoch: 3 | loss: 0.2515314\n",
      "\tspeed: 0.0220s/iter; left time: 58.9480s\n",
      "\titers: 300, epoch: 3 | loss: 0.2703438\n",
      "\tspeed: 0.0231s/iter; left time: 59.6129s\n",
      "\titers: 400, epoch: 3 | loss: 0.2363581\n",
      "\tspeed: 0.0228s/iter; left time: 56.5113s\n",
      "\titers: 500, epoch: 3 | loss: 0.2137282\n",
      "\tspeed: 0.0239s/iter; left time: 56.8561s\n",
      "\titers: 600, epoch: 3 | loss: 0.4114272\n",
      "\tspeed: 0.0245s/iter; left time: 55.8818s\n",
      "\titers: 700, epoch: 3 | loss: 0.1659668\n",
      "\tspeed: 0.0247s/iter; left time: 53.7709s\n",
      "Epoch: 3 cost time: 16.90793490409851\n",
      "Epoch: 3, Steps: 720 | Train Loss: 0.1870971 Vali Loss: 0.3257646 Test Loss: 0.2409789\n",
      "Validation loss decreased (0.327652 --> 0.325765).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0879828\n",
      "\tspeed: 0.0581s/iter; left time: 119.7336s\n",
      "\titers: 200, epoch: 4 | loss: 0.1431465\n",
      "\tspeed: 0.0228s/iter; left time: 44.7471s\n",
      "\titers: 300, epoch: 4 | loss: 0.1361479\n",
      "\tspeed: 0.0238s/iter; left time: 44.3729s\n",
      "\titers: 400, epoch: 4 | loss: 0.1462383\n",
      "\tspeed: 0.0223s/iter; left time: 39.3123s\n",
      "\titers: 500, epoch: 4 | loss: 0.1556001\n",
      "\tspeed: 0.0229s/iter; left time: 37.9951s\n",
      "\titers: 600, epoch: 4 | loss: 0.1562320\n",
      "\tspeed: 0.0245s/iter; left time: 38.2767s\n",
      "\titers: 700, epoch: 4 | loss: 0.1500027\n",
      "\tspeed: 0.0222s/iter; left time: 32.4283s\n",
      "Epoch: 4 cost time: 16.663687467575073\n",
      "Epoch: 4, Steps: 720 | Train Loss: 0.1722991 Vali Loss: 0.3180571 Test Loss: 0.2378705\n",
      "Validation loss decreased (0.325765 --> 0.318057).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1926964\n",
      "\tspeed: 0.0555s/iter; left time: 74.3926s\n",
      "\titers: 200, epoch: 5 | loss: 0.1673174\n",
      "\tspeed: 0.0225s/iter; left time: 27.9566s\n",
      "\titers: 300, epoch: 5 | loss: 0.1978714\n",
      "\tspeed: 0.0223s/iter; left time: 25.4341s\n",
      "\titers: 400, epoch: 5 | loss: 0.1349317\n",
      "\tspeed: 0.0220s/iter; left time: 22.8741s\n",
      "\titers: 500, epoch: 5 | loss: 0.1320693\n",
      "\tspeed: 0.0247s/iter; left time: 23.2258s\n",
      "\titers: 600, epoch: 5 | loss: 0.1040730\n",
      "\tspeed: 0.0229s/iter; left time: 19.2183s\n",
      "\titers: 700, epoch: 5 | loss: 0.1999601\n",
      "\tspeed: 0.0229s/iter; left time: 17.0013s\n",
      "Epoch: 5 cost time: 16.506165981292725\n",
      "Epoch: 5, Steps: 720 | Train Loss: 0.1636747 Vali Loss: 0.3183323 Test Loss: 0.2414027\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1471926\n",
      "\tspeed: 0.0539s/iter; left time: 33.4794s\n",
      "\titers: 200, epoch: 6 | loss: 0.1814853\n",
      "\tspeed: 0.0235s/iter; left time: 12.2299s\n",
      "\titers: 300, epoch: 6 | loss: 0.1218549\n",
      "\tspeed: 0.0265s/iter; left time: 11.1516s\n",
      "\titers: 400, epoch: 6 | loss: 0.1131911\n",
      "\tspeed: 0.0235s/iter; left time: 7.5513s\n",
      "\titers: 500, epoch: 6 | loss: 0.1738588\n",
      "\tspeed: 0.0231s/iter; left time: 5.1067s\n",
      "\titers: 600, epoch: 6 | loss: 0.1474309\n",
      "\tspeed: 0.0236s/iter; left time: 2.8557s\n",
      "\titers: 700, epoch: 6 | loss: 0.1403441\n",
      "\tspeed: 0.0243s/iter; left time: 0.5113s\n",
      "Epoch: 6 cost time: 17.193161725997925\n",
      "Epoch: 6, Steps: 720 | Train Loss: 0.1585589 Vali Loss: 0.3199352 Test Loss: 0.2386226\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "Test cost time: 1.8817s\n",
      "test shape: (198, 32, 6, 1) (198, 32, 6, 1)\n",
      "test shape: (6336, 6, 1) (6336, 6, 1)\n",
      "mse:0.2376120239496231, mae:0.3280346095561981\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1627.11376953125\n",
      "MAE:  27.14528465270996\n",
      "RMSE: 40.33749771118164\n",
      "MAPE: 0.3675115406513214\n",
      "MSPE: 0.6534509062767029\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24515\n",
      "[DEBUG] Original dataset length: 24515\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 23049\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3471\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.2865759\n",
      "\tspeed: 0.0236s/iter; left time: 99.7769s\n",
      "\titers: 200, epoch: 1 | loss: 0.3600346\n",
      "\tspeed: 0.0238s/iter; left time: 97.9845s\n",
      "\titers: 300, epoch: 1 | loss: 0.2039701\n",
      "\tspeed: 0.0237s/iter; left time: 95.1521s\n",
      "\titers: 400, epoch: 1 | loss: 0.3763814\n",
      "\tspeed: 0.0236s/iter; left time: 92.3728s\n",
      "\titers: 500, epoch: 1 | loss: 0.2703598\n",
      "\tspeed: 0.0236s/iter; left time: 90.0435s\n",
      "\titers: 600, epoch: 1 | loss: 0.3783150\n",
      "\tspeed: 0.0255s/iter; left time: 94.8344s\n",
      "\titers: 700, epoch: 1 | loss: 0.2756423\n",
      "\tspeed: 0.0236s/iter; left time: 85.2891s\n",
      "Epoch: 1 cost time: 17.170438766479492\n",
      "Epoch: 1, Steps: 720 | Train Loss: 0.2675003 Vali Loss: 0.3315566 Test Loss: 0.2526740\n",
      "Validation loss decreased (inf --> 0.331557).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1252775\n",
      "\tspeed: 0.0562s/iter; left time: 196.8064s\n",
      "\titers: 200, epoch: 2 | loss: 0.1523359\n",
      "\tspeed: 0.0234s/iter; left time: 79.6576s\n",
      "\titers: 300, epoch: 2 | loss: 0.1905691\n",
      "\tspeed: 0.0231s/iter; left time: 76.3832s\n",
      "\titers: 400, epoch: 2 | loss: 0.2672682\n",
      "\tspeed: 0.0261s/iter; left time: 83.6065s\n",
      "\titers: 500, epoch: 2 | loss: 0.2054070\n",
      "\tspeed: 0.0242s/iter; left time: 75.0744s\n",
      "\titers: 600, epoch: 2 | loss: 0.1443106\n",
      "\tspeed: 0.0244s/iter; left time: 73.3293s\n",
      "\titers: 700, epoch: 2 | loss: 0.1974154\n",
      "\tspeed: 0.0237s/iter; left time: 68.8963s\n",
      "Epoch: 2 cost time: 17.27440071105957\n",
      "Epoch: 2, Steps: 720 | Train Loss: 0.2120125 Vali Loss: 0.3197114 Test Loss: 0.2475138\n",
      "Validation loss decreased (0.331557 --> 0.319711).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1647746\n",
      "\tspeed: 0.0564s/iter; left time: 156.7232s\n",
      "\titers: 200, epoch: 3 | loss: 0.1546676\n",
      "\tspeed: 0.0243s/iter; left time: 65.2342s\n",
      "\titers: 300, epoch: 3 | loss: 0.3313934\n",
      "\tspeed: 0.0248s/iter; left time: 63.9427s\n",
      "\titers: 400, epoch: 3 | loss: 0.3056658\n",
      "\tspeed: 0.0234s/iter; left time: 58.0973s\n",
      "\titers: 500, epoch: 3 | loss: 0.1591436\n",
      "\tspeed: 0.0239s/iter; left time: 56.9790s\n",
      "\titers: 600, epoch: 3 | loss: 0.1645430\n",
      "\tspeed: 0.0232s/iter; left time: 52.9655s\n",
      "\titers: 700, epoch: 3 | loss: 0.1868242\n",
      "\tspeed: 0.0252s/iter; left time: 54.9011s\n",
      "Epoch: 3 cost time: 17.362776279449463\n",
      "Epoch: 3, Steps: 720 | Train Loss: 0.1876903 Vali Loss: 0.3170635 Test Loss: 0.2469709\n",
      "Validation loss decreased (0.319711 --> 0.317063).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1220028\n",
      "\tspeed: 0.0611s/iter; left time: 125.8416s\n",
      "\titers: 200, epoch: 4 | loss: 0.1805813\n",
      "\tspeed: 0.0244s/iter; left time: 47.9187s\n",
      "\titers: 300, epoch: 4 | loss: 0.2149364\n",
      "\tspeed: 0.0240s/iter; left time: 44.5997s\n",
      "\titers: 400, epoch: 4 | loss: 0.1268175\n",
      "\tspeed: 0.0239s/iter; left time: 42.0292s\n",
      "\titers: 500, epoch: 4 | loss: 0.1782756\n",
      "\tspeed: 0.0233s/iter; left time: 38.6561s\n",
      "\titers: 600, epoch: 4 | loss: 0.1206533\n",
      "\tspeed: 0.0234s/iter; left time: 36.4537s\n",
      "\titers: 700, epoch: 4 | loss: 0.1106179\n",
      "\tspeed: 0.0259s/iter; left time: 37.8287s\n",
      "Epoch: 4 cost time: 17.669017791748047\n",
      "Epoch: 4, Steps: 720 | Train Loss: 0.1737786 Vali Loss: 0.3060316 Test Loss: 0.2337235\n",
      "Validation loss decreased (0.317063 --> 0.306032).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1621804\n",
      "\tspeed: 0.0567s/iter; left time: 76.0390s\n",
      "\titers: 200, epoch: 5 | loss: 0.1920145\n",
      "\tspeed: 0.0230s/iter; left time: 28.5471s\n",
      "\titers: 300, epoch: 5 | loss: 0.1459103\n",
      "\tspeed: 0.0242s/iter; left time: 27.5705s\n",
      "\titers: 400, epoch: 5 | loss: 0.1800229\n",
      "\tspeed: 0.0230s/iter; left time: 23.8948s\n",
      "\titers: 500, epoch: 5 | loss: 0.1570787\n",
      "\tspeed: 0.0257s/iter; left time: 24.2246s\n",
      "\titers: 600, epoch: 5 | loss: 0.1529829\n",
      "\tspeed: 0.0243s/iter; left time: 20.4375s\n",
      "\titers: 700, epoch: 5 | loss: 0.1487933\n",
      "\tspeed: 0.0222s/iter; left time: 16.4661s\n",
      "Epoch: 5 cost time: 17.125006437301636\n",
      "Epoch: 5, Steps: 720 | Train Loss: 0.1657011 Vali Loss: 0.3056881 Test Loss: 0.2338295\n",
      "Validation loss decreased (0.306032 --> 0.305688).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1198038\n",
      "\tspeed: 0.0563s/iter; left time: 34.9792s\n",
      "\titers: 200, epoch: 6 | loss: 0.1056487\n",
      "\tspeed: 0.0257s/iter; left time: 13.3963s\n",
      "\titers: 300, epoch: 6 | loss: 0.3691839\n",
      "\tspeed: 0.0254s/iter; left time: 10.7092s\n",
      "\titers: 400, epoch: 6 | loss: 0.0901388\n",
      "\tspeed: 0.0236s/iter; left time: 7.5597s\n",
      "\titers: 500, epoch: 6 | loss: 0.1602312\n",
      "\tspeed: 0.0228s/iter; left time: 5.0383s\n",
      "\titers: 600, epoch: 6 | loss: 0.1277051\n",
      "\tspeed: 0.0240s/iter; left time: 2.9031s\n",
      "\titers: 700, epoch: 6 | loss: 0.1304263\n",
      "\tspeed: 0.0225s/iter; left time: 0.4720s\n",
      "Epoch: 6 cost time: 17.267051935195923\n",
      "Epoch: 6, Steps: 720 | Train Loss: 0.1614326 Vali Loss: 0.3104371 Test Loss: 0.2371754\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "Test cost time: 1.8827s\n",
      "test shape: (198, 32, 6, 1) (198, 32, 6, 1)\n",
      "test shape: (6336, 6, 1) (6336, 6, 1)\n",
      "mse:0.23437808454036713, mae:0.32244306802749634\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1604.968505859375\n",
      "MAE:  26.682580947875977\n",
      "RMSE: 40.06205749511719\n",
      "MAPE: 0.3333260416984558\n",
      "MSPE: 0.5486890077590942\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24515\n",
      "[DEBUG] Original dataset length: 24515\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 23049\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3471\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.2744650\n",
      "\tspeed: 0.0257s/iter; left time: 108.6816s\n",
      "\titers: 200, epoch: 1 | loss: 0.2896386\n",
      "\tspeed: 0.0222s/iter; left time: 91.6704s\n",
      "\titers: 300, epoch: 1 | loss: 0.1667687\n",
      "\tspeed: 0.0242s/iter; left time: 97.4852s\n",
      "\titers: 400, epoch: 1 | loss: 0.2906582\n",
      "\tspeed: 0.0232s/iter; left time: 90.8604s\n",
      "\titers: 500, epoch: 1 | loss: 0.2721714\n",
      "\tspeed: 0.0235s/iter; left time: 89.8949s\n",
      "\titers: 600, epoch: 1 | loss: 0.3078634\n",
      "\tspeed: 0.0244s/iter; left time: 90.6703s\n",
      "\titers: 700, epoch: 1 | loss: 0.1628935\n",
      "\tspeed: 0.0234s/iter; left time: 84.8593s\n",
      "Epoch: 1 cost time: 17.19787073135376\n",
      "Epoch: 1, Steps: 720 | Train Loss: 0.2719501 Vali Loss: 0.3297973 Test Loss: 0.2573735\n",
      "Validation loss decreased (inf --> 0.329797).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3001851\n",
      "\tspeed: 0.0548s/iter; left time: 191.9943s\n",
      "\titers: 200, epoch: 2 | loss: 0.2518544\n",
      "\tspeed: 0.0238s/iter; left time: 80.8378s\n",
      "\titers: 300, epoch: 2 | loss: 0.1061586\n",
      "\tspeed: 0.0245s/iter; left time: 80.9013s\n",
      "\titers: 400, epoch: 2 | loss: 0.1308330\n",
      "\tspeed: 0.0264s/iter; left time: 84.5648s\n",
      "\titers: 500, epoch: 2 | loss: 0.1324591\n",
      "\tspeed: 0.0236s/iter; left time: 73.1132s\n",
      "\titers: 600, epoch: 2 | loss: 0.1751156\n",
      "\tspeed: 0.0234s/iter; left time: 70.1532s\n",
      "\titers: 700, epoch: 2 | loss: 0.1699983\n",
      "\tspeed: 0.0233s/iter; left time: 67.6783s\n",
      "Epoch: 2 cost time: 17.326830863952637\n",
      "Epoch: 2, Steps: 720 | Train Loss: 0.2163521 Vali Loss: 0.3210734 Test Loss: 0.2566946\n",
      "Validation loss decreased (0.329797 --> 0.321073).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1544362\n",
      "\tspeed: 0.0565s/iter; left time: 157.0100s\n",
      "\titers: 200, epoch: 3 | loss: 0.1541156\n",
      "\tspeed: 0.0259s/iter; left time: 69.3319s\n",
      "\titers: 300, epoch: 3 | loss: 0.2368840\n",
      "\tspeed: 0.0235s/iter; left time: 60.7802s\n",
      "\titers: 400, epoch: 3 | loss: 0.2679690\n",
      "\tspeed: 0.0236s/iter; left time: 58.5740s\n",
      "\titers: 500, epoch: 3 | loss: 0.2408451\n",
      "\tspeed: 0.0224s/iter; left time: 53.3475s\n",
      "\titers: 600, epoch: 3 | loss: 0.2103211\n",
      "\tspeed: 0.0238s/iter; left time: 54.2424s\n",
      "\titers: 700, epoch: 3 | loss: 0.1659282\n",
      "\tspeed: 0.0238s/iter; left time: 51.9129s\n",
      "Epoch: 3 cost time: 17.151901721954346\n",
      "Epoch: 3, Steps: 720 | Train Loss: 0.1884750 Vali Loss: 0.3357567 Test Loss: 0.2538561\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2896501\n",
      "\tspeed: 0.0584s/iter; left time: 120.3813s\n",
      "\titers: 200, epoch: 4 | loss: 0.1649207\n",
      "\tspeed: 0.0226s/iter; left time: 44.2827s\n",
      "\titers: 300, epoch: 4 | loss: 0.2061916\n",
      "\tspeed: 0.0237s/iter; left time: 44.0484s\n",
      "\titers: 400, epoch: 4 | loss: 0.1754446\n",
      "\tspeed: 0.0221s/iter; left time: 38.9405s\n",
      "\titers: 500, epoch: 4 | loss: 0.1536574\n",
      "\tspeed: 0.0230s/iter; left time: 38.1721s\n",
      "\titers: 600, epoch: 4 | loss: 0.1597869\n",
      "\tspeed: 0.0237s/iter; left time: 37.0185s\n",
      "\titers: 700, epoch: 4 | loss: 0.1866713\n",
      "\tspeed: 0.0237s/iter; left time: 34.5633s\n",
      "Epoch: 4 cost time: 16.87447237968445\n",
      "Epoch: 4, Steps: 720 | Train Loss: 0.1751381 Vali Loss: 0.3102418 Test Loss: 0.2352545\n",
      "Validation loss decreased (0.321073 --> 0.310242).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2251854\n",
      "\tspeed: 0.0541s/iter; left time: 72.5179s\n",
      "\titers: 200, epoch: 5 | loss: 0.1805743\n",
      "\tspeed: 0.0225s/iter; left time: 27.9402s\n",
      "\titers: 300, epoch: 5 | loss: 0.1773625\n",
      "\tspeed: 0.0221s/iter; left time: 25.2044s\n",
      "\titers: 400, epoch: 5 | loss: 0.1136182\n",
      "\tspeed: 0.0238s/iter; left time: 24.7791s\n",
      "\titers: 500, epoch: 5 | loss: 0.1537762\n",
      "\tspeed: 0.0280s/iter; left time: 26.3667s\n",
      "\titers: 600, epoch: 5 | loss: 0.1588420\n",
      "\tspeed: 0.0231s/iter; left time: 19.4282s\n",
      "\titers: 700, epoch: 5 | loss: 0.2164289\n",
      "\tspeed: 0.0236s/iter; left time: 17.4630s\n",
      "Epoch: 5 cost time: 17.08813762664795\n",
      "Epoch: 5, Steps: 720 | Train Loss: 0.1664495 Vali Loss: 0.3087876 Test Loss: 0.2400967\n",
      "Validation loss decreased (0.310242 --> 0.308788).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1690407\n",
      "\tspeed: 0.0564s/iter; left time: 35.0524s\n",
      "\titers: 200, epoch: 6 | loss: 0.1302037\n",
      "\tspeed: 0.0246s/iter; left time: 12.8142s\n",
      "\titers: 300, epoch: 6 | loss: 0.1850041\n",
      "\tspeed: 0.0244s/iter; left time: 10.2554s\n",
      "\titers: 400, epoch: 6 | loss: 0.1728292\n",
      "\tspeed: 0.0228s/iter; left time: 7.3201s\n",
      "\titers: 500, epoch: 6 | loss: 0.1521309\n",
      "\tspeed: 0.0225s/iter; left time: 4.9637s\n",
      "\titers: 600, epoch: 6 | loss: 0.1067053\n",
      "\tspeed: 0.0235s/iter; left time: 2.8461s\n",
      "\titers: 700, epoch: 6 | loss: 0.1677564\n",
      "\tspeed: 0.0238s/iter; left time: 0.5004s\n",
      "Epoch: 6 cost time: 17.090779304504395\n",
      "Epoch: 6, Steps: 720 | Train Loss: 0.1624983 Vali Loss: 0.3019986 Test Loss: 0.2360453\n",
      "Validation loss decreased (0.308788 --> 0.301999).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "Test cost time: 1.8895s\n",
      "test shape: (198, 32, 6, 1) (198, 32, 6, 1)\n",
      "test shape: (6336, 6, 1) (6336, 6, 1)\n",
      "mse:0.2356889843940735, mae:0.3247763514518738\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1613.945068359375\n",
      "MAE:  26.875661849975586\n",
      "RMSE: 40.17393493652344\n",
      "MAPE: 0.3408617675304413\n",
      "MSPE: 0.5721623301506042\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24515\n",
      "[DEBUG] Original dataset length: 24515\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 23049\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3471\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.2650527\n",
      "\tspeed: 0.0239s/iter; left time: 100.8915s\n",
      "\titers: 200, epoch: 1 | loss: 0.2219979\n",
      "\tspeed: 0.0229s/iter; left time: 94.5158s\n",
      "\titers: 300, epoch: 1 | loss: 0.2025732\n",
      "\tspeed: 0.0231s/iter; left time: 92.9999s\n",
      "\titers: 400, epoch: 1 | loss: 0.2251877\n",
      "\tspeed: 0.0237s/iter; left time: 93.0771s\n",
      "\titers: 500, epoch: 1 | loss: 0.2039747\n",
      "\tspeed: 0.0226s/iter; left time: 86.3022s\n",
      "\titers: 600, epoch: 1 | loss: 0.3058737\n",
      "\tspeed: 0.0263s/iter; left time: 98.0357s\n",
      "\titers: 700, epoch: 1 | loss: 0.3038377\n",
      "\tspeed: 0.0233s/iter; left time: 84.4925s\n",
      "Epoch: 1 cost time: 17.09080934524536\n",
      "Epoch: 1, Steps: 720 | Train Loss: 0.2718620 Vali Loss: 0.3364227 Test Loss: 0.2603308\n",
      "Validation loss decreased (inf --> 0.336423).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3192947\n",
      "\tspeed: 0.0578s/iter; left time: 202.5318s\n",
      "\titers: 200, epoch: 2 | loss: 0.3446273\n",
      "\tspeed: 0.0239s/iter; left time: 81.3909s\n",
      "\titers: 300, epoch: 2 | loss: 0.2148699\n",
      "\tspeed: 0.0236s/iter; left time: 77.8234s\n",
      "\titers: 400, epoch: 2 | loss: 0.1366628\n",
      "\tspeed: 0.0257s/iter; left time: 82.2395s\n",
      "\titers: 500, epoch: 2 | loss: 0.1799138\n",
      "\tspeed: 0.0229s/iter; left time: 70.9257s\n",
      "\titers: 600, epoch: 2 | loss: 0.1781433\n",
      "\tspeed: 0.0233s/iter; left time: 70.0401s\n",
      "\titers: 700, epoch: 2 | loss: 0.2341565\n",
      "\tspeed: 0.0255s/iter; left time: 73.9521s\n",
      "Epoch: 2 cost time: 17.30075454711914\n",
      "Epoch: 2, Steps: 720 | Train Loss: 0.2106485 Vali Loss: 0.3270538 Test Loss: 0.2547030\n",
      "Validation loss decreased (0.336423 --> 0.327054).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1174722\n",
      "\tspeed: 0.0598s/iter; left time: 166.1896s\n",
      "\titers: 200, epoch: 3 | loss: 0.1492120\n",
      "\tspeed: 0.0251s/iter; left time: 67.2539s\n",
      "\titers: 300, epoch: 3 | loss: 0.1613349\n",
      "\tspeed: 0.0220s/iter; left time: 56.8117s\n",
      "\titers: 400, epoch: 3 | loss: 0.1661272\n",
      "\tspeed: 0.0229s/iter; left time: 56.9226s\n",
      "\titers: 500, epoch: 3 | loss: 0.1898852\n",
      "\tspeed: 0.0231s/iter; left time: 54.9675s\n",
      "\titers: 600, epoch: 3 | loss: 0.1583087\n",
      "\tspeed: 0.0246s/iter; left time: 56.0503s\n",
      "\titers: 700, epoch: 3 | loss: 0.1923200\n",
      "\tspeed: 0.0244s/iter; left time: 53.2403s\n",
      "Epoch: 3 cost time: 17.232905864715576\n",
      "Epoch: 3, Steps: 720 | Train Loss: 0.1881493 Vali Loss: 0.3286547 Test Loss: 0.2491727\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1887914\n",
      "\tspeed: 0.0526s/iter; left time: 108.5047s\n",
      "\titers: 200, epoch: 4 | loss: 0.1533822\n",
      "\tspeed: 0.0213s/iter; left time: 41.8435s\n",
      "\titers: 300, epoch: 4 | loss: 0.2594321\n",
      "\tspeed: 0.0235s/iter; left time: 43.6740s\n",
      "\titers: 400, epoch: 4 | loss: 0.1869736\n",
      "\tspeed: 0.0240s/iter; left time: 42.3321s\n",
      "\titers: 500, epoch: 4 | loss: 0.1373258\n",
      "\tspeed: 0.0244s/iter; left time: 40.4907s\n",
      "\titers: 600, epoch: 4 | loss: 0.1089822\n",
      "\tspeed: 0.0252s/iter; left time: 39.4098s\n",
      "\titers: 700, epoch: 4 | loss: 0.1608785\n",
      "\tspeed: 0.0238s/iter; left time: 34.7855s\n",
      "Epoch: 4 cost time: 16.706403493881226\n",
      "Epoch: 4, Steps: 720 | Train Loss: 0.1730316 Vali Loss: 0.3165959 Test Loss: 0.2357844\n",
      "Validation loss decreased (0.327054 --> 0.316596).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1621994\n",
      "\tspeed: 0.0555s/iter; left time: 74.4800s\n",
      "\titers: 200, epoch: 5 | loss: 0.1842579\n",
      "\tspeed: 0.0226s/iter; left time: 28.0036s\n",
      "\titers: 300, epoch: 5 | loss: 0.1382771\n",
      "\tspeed: 0.0242s/iter; left time: 27.6334s\n",
      "\titers: 400, epoch: 5 | loss: 0.1971953\n",
      "\tspeed: 0.0259s/iter; left time: 26.9555s\n",
      "\titers: 500, epoch: 5 | loss: 0.1952503\n",
      "\tspeed: 0.0228s/iter; left time: 21.4133s\n",
      "\titers: 600, epoch: 5 | loss: 0.2498008\n",
      "\tspeed: 0.0235s/iter; left time: 19.7881s\n",
      "\titers: 700, epoch: 5 | loss: 0.1059090\n",
      "\tspeed: 0.0229s/iter; left time: 16.9371s\n",
      "Epoch: 5 cost time: 17.073793411254883\n",
      "Epoch: 5, Steps: 720 | Train Loss: 0.1649060 Vali Loss: 0.3213950 Test Loss: 0.2349425\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2616539\n",
      "\tspeed: 0.0557s/iter; left time: 34.6114s\n",
      "\titers: 200, epoch: 6 | loss: 0.1339238\n",
      "\tspeed: 0.0258s/iter; left time: 13.4249s\n",
      "\titers: 300, epoch: 6 | loss: 0.1539618\n",
      "\tspeed: 0.0246s/iter; left time: 10.3710s\n",
      "\titers: 400, epoch: 6 | loss: 0.1656114\n",
      "\tspeed: 0.0238s/iter; left time: 7.6308s\n",
      "\titers: 500, epoch: 6 | loss: 0.1363162\n",
      "\tspeed: 0.0231s/iter; left time: 5.1014s\n",
      "\titers: 600, epoch: 6 | loss: 0.1754659\n",
      "\tspeed: 0.0254s/iter; left time: 3.0771s\n",
      "\titers: 700, epoch: 6 | loss: 0.0997948\n",
      "\tspeed: 0.0240s/iter; left time: 0.5032s\n",
      "Epoch: 6 cost time: 17.539247035980225\n",
      "Epoch: 6, Steps: 720 | Train Loss: 0.1606391 Vali Loss: 0.3143761 Test Loss: 0.2341927\n",
      "Validation loss decreased (0.316596 --> 0.314376).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "Test cost time: 1.7630s\n",
      "test shape: (198, 32, 6, 1) (198, 32, 6, 1)\n",
      "test shape: (6336, 6, 1) (6336, 6, 1)\n",
      "mse:0.2336292415857315, mae:0.3213922381401062\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1599.840576171875\n",
      "MAE:  26.595619201660156\n",
      "RMSE: 39.998008728027344\n",
      "MAPE: 0.32498419284820557\n",
      "MSPE: 0.4747970402240753\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24515\n",
      "[DEBUG] Original dataset length: 24515\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 23049\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3471\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.5527468\n",
      "\tspeed: 0.0273s/iter; left time: 115.3552s\n",
      "\titers: 200, epoch: 1 | loss: 0.3311287\n",
      "\tspeed: 0.0245s/iter; left time: 100.8024s\n",
      "\titers: 300, epoch: 1 | loss: 0.2049724\n",
      "\tspeed: 0.0248s/iter; left time: 99.6629s\n",
      "\titers: 400, epoch: 1 | loss: 0.3211198\n",
      "\tspeed: 0.0234s/iter; left time: 91.7675s\n",
      "\titers: 500, epoch: 1 | loss: 0.1992905\n",
      "\tspeed: 0.0263s/iter; left time: 100.4708s\n",
      "\titers: 600, epoch: 1 | loss: 0.2566380\n",
      "\tspeed: 0.0230s/iter; left time: 85.6767s\n",
      "\titers: 700, epoch: 1 | loss: 0.2303926\n",
      "\tspeed: 0.0226s/iter; left time: 81.6786s\n",
      "Epoch: 1 cost time: 17.638620853424072\n",
      "Epoch: 1, Steps: 720 | Train Loss: 0.2682772 Vali Loss: 0.3367246 Test Loss: 0.2646706\n",
      "Validation loss decreased (inf --> 0.336725).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1566275\n",
      "\tspeed: 0.0545s/iter; left time: 190.6684s\n",
      "\titers: 200, epoch: 2 | loss: 0.1531208\n",
      "\tspeed: 0.0231s/iter; left time: 78.7137s\n",
      "\titers: 300, epoch: 2 | loss: 0.2799466\n",
      "\tspeed: 0.0255s/iter; left time: 84.1659s\n",
      "\titers: 400, epoch: 2 | loss: 0.1289977\n",
      "\tspeed: 0.0229s/iter; left time: 73.2419s\n",
      "\titers: 500, epoch: 2 | loss: 0.1932125\n",
      "\tspeed: 0.0231s/iter; left time: 71.7581s\n",
      "\titers: 600, epoch: 2 | loss: 0.2274318\n",
      "\tspeed: 0.0243s/iter; left time: 72.9586s\n",
      "\titers: 700, epoch: 2 | loss: 0.1344557\n",
      "\tspeed: 0.0241s/iter; left time: 69.8268s\n",
      "Epoch: 2 cost time: 17.0900559425354\n",
      "Epoch: 2, Steps: 720 | Train Loss: 0.2138353 Vali Loss: 0.3882794 Test Loss: 0.3128722\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1562793\n",
      "\tspeed: 0.0572s/iter; left time: 159.0634s\n",
      "\titers: 200, epoch: 3 | loss: 0.1347074\n",
      "\tspeed: 0.0240s/iter; left time: 64.4192s\n",
      "\titers: 300, epoch: 3 | loss: 0.2022909\n",
      "\tspeed: 0.0232s/iter; left time: 59.9630s\n",
      "\titers: 400, epoch: 3 | loss: 0.1361892\n",
      "\tspeed: 0.0228s/iter; left time: 56.4432s\n",
      "\titers: 500, epoch: 3 | loss: 0.1614300\n",
      "\tspeed: 0.0244s/iter; left time: 58.2054s\n",
      "\titers: 600, epoch: 3 | loss: 0.2304744\n",
      "\tspeed: 0.0233s/iter; left time: 53.1492s\n",
      "\titers: 700, epoch: 3 | loss: 0.1427994\n",
      "\tspeed: 0.0242s/iter; left time: 52.8613s\n",
      "Epoch: 3 cost time: 17.334230184555054\n",
      "Epoch: 3, Steps: 720 | Train Loss: 0.1861552 Vali Loss: 0.3251782 Test Loss: 0.2577867\n",
      "Validation loss decreased (0.336725 --> 0.325178).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2071881\n",
      "\tspeed: 0.0561s/iter; left time: 115.6852s\n",
      "\titers: 200, epoch: 4 | loss: 0.2575551\n",
      "\tspeed: 0.0238s/iter; left time: 46.6454s\n",
      "\titers: 300, epoch: 4 | loss: 0.1590323\n",
      "\tspeed: 0.0234s/iter; left time: 43.4992s\n",
      "\titers: 400, epoch: 4 | loss: 0.2344529\n",
      "\tspeed: 0.0241s/iter; left time: 42.3898s\n",
      "\titers: 500, epoch: 4 | loss: 0.1380359\n",
      "\tspeed: 0.0248s/iter; left time: 41.2331s\n",
      "\titers: 600, epoch: 4 | loss: 0.1637898\n",
      "\tspeed: 0.0251s/iter; left time: 39.1088s\n",
      "\titers: 700, epoch: 4 | loss: 0.1887952\n",
      "\tspeed: 0.0234s/iter; left time: 34.2184s\n",
      "Epoch: 4 cost time: 17.278543949127197\n",
      "Epoch: 4, Steps: 720 | Train Loss: 0.1725929 Vali Loss: 0.3219385 Test Loss: 0.2412459\n",
      "Validation loss decreased (0.325178 --> 0.321939).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2666981\n",
      "\tspeed: 0.0553s/iter; left time: 74.1070s\n",
      "\titers: 200, epoch: 5 | loss: 0.2087873\n",
      "\tspeed: 0.0233s/iter; left time: 28.9714s\n",
      "\titers: 300, epoch: 5 | loss: 0.1229014\n",
      "\tspeed: 0.0242s/iter; left time: 27.6303s\n",
      "\titers: 400, epoch: 5 | loss: 0.2954988\n",
      "\tspeed: 0.0260s/iter; left time: 27.0799s\n",
      "\titers: 500, epoch: 5 | loss: 0.1447592\n",
      "\tspeed: 0.0240s/iter; left time: 22.5647s\n",
      "\titers: 600, epoch: 5 | loss: 0.1152863\n",
      "\tspeed: 0.0237s/iter; left time: 19.8998s\n",
      "\titers: 700, epoch: 5 | loss: 0.1453368\n",
      "\tspeed: 0.0284s/iter; left time: 21.0112s\n",
      "Epoch: 5 cost time: 17.706292152404785\n",
      "Epoch: 5, Steps: 720 | Train Loss: 0.1634190 Vali Loss: 0.3107994 Test Loss: 0.2360738\n",
      "Validation loss decreased (0.321939 --> 0.310799).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2448484\n",
      "\tspeed: 0.0588s/iter; left time: 36.4903s\n",
      "\titers: 200, epoch: 6 | loss: 0.2627458\n",
      "\tspeed: 0.0238s/iter; left time: 12.3848s\n",
      "\titers: 300, epoch: 6 | loss: 0.1049539\n",
      "\tspeed: 0.0248s/iter; left time: 10.4351s\n",
      "\titers: 400, epoch: 6 | loss: 0.1866700\n",
      "\tspeed: 0.0239s/iter; left time: 7.6563s\n",
      "\titers: 500, epoch: 6 | loss: 0.1325213\n",
      "\tspeed: 0.0238s/iter; left time: 5.2701s\n",
      "\titers: 600, epoch: 6 | loss: 0.1152547\n",
      "\tspeed: 0.0238s/iter; left time: 2.8784s\n",
      "\titers: 300, epoch: 6 | loss: 0.1056100\n",
      "\tspeed: 0.0241s/iter; left time: 10.1512s\n",
      "\titers: 400, epoch: 6 | loss: 0.1469253\n",
      "\tspeed: 0.0226s/iter; left time: 7.2405s\n",
      "\titers: 500, epoch: 6 | loss: 0.1085294\n",
      "\tspeed: 0.0245s/iter; left time: 5.4175s\n",
      "\titers: 600, epoch: 6 | loss: 0.1695757\n",
      "\tspeed: 0.0226s/iter; left time: 2.7358s\n",
      "\titers: 700, epoch: 6 | loss: 0.0930622\n",
      "\tspeed: 0.0235s/iter; left time: 0.4925s\n",
      "Epoch: 6 cost time: 17.251235723495483\n",
      "Epoch: 6, Steps: 720 | Train Loss: 0.1611039 Vali Loss: 0.3092542 Test Loss: 0.2373717\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "Test cost time: 1.7897s\n",
      "test shape: (198, 32, 6, 1) (198, 32, 6, 1)\n",
      "test shape: (6336, 6, 1) (6336, 6, 1)\n",
      "mse:0.2303667962551117, mae:0.32790979743003845\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1577.5\n",
      "MAE:  27.13495635986328\n",
      "RMSE: 39.71775436401367\n",
      "MAPE: 0.3835509717464447\n",
      "MSPE: 0.7522261738777161\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24515\n",
      "[DEBUG] Original dataset length: 24515\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 23049\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3471\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.2623928\n",
      "\tspeed: 0.0241s/iter; left time: 101.8891s\n",
      "\titers: 200, epoch: 1 | loss: 0.2864740\n",
      "\tspeed: 0.0227s/iter; left time: 93.5551s\n",
      "\titers: 300, epoch: 1 | loss: 0.2192387\n",
      "\tspeed: 0.0221s/iter; left time: 88.9559s\n",
      "\titers: 400, epoch: 1 | loss: 0.1847513\n",
      "\tspeed: 0.0227s/iter; left time: 88.9984s\n",
      "\titers: 500, epoch: 1 | loss: 0.2801117\n",
      "\tspeed: 0.0251s/iter; left time: 95.7606s\n",
      "\titers: 600, epoch: 1 | loss: 0.2317281\n",
      "\tspeed: 0.0233s/iter; left time: 86.5145s\n",
      "\titers: 700, epoch: 1 | loss: 0.1556594\n",
      "\tspeed: 0.0220s/iter; left time: 79.5060s\n",
      "Epoch: 1 cost time: 16.603269815444946\n",
      "Epoch: 1, Steps: 720 | Train Loss: 0.2711262 Vali Loss: 0.3246966 Test Loss: 0.2513530\n",
      "Validation loss decreased (inf --> 0.324697).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1855732\n",
      "\tspeed: 0.0535s/iter; left time: 187.2394s\n",
      "\titers: 200, epoch: 2 | loss: 0.3065771\n",
      "\tspeed: 0.0225s/iter; left time: 76.3924s\n",
      "\titers: 300, epoch: 2 | loss: 0.1691128\n",
      "\tspeed: 0.0254s/iter; left time: 83.9270s\n",
      "\titers: 400, epoch: 2 | loss: 0.1108337\n",
      "\tspeed: 0.0248s/iter; left time: 79.2890s\n",
      "\titers: 500, epoch: 2 | loss: 0.2266400\n",
      "\tspeed: 0.0247s/iter; left time: 76.4562s\n",
      "\titers: 600, epoch: 2 | loss: 0.2419759\n",
      "\tspeed: 0.0236s/iter; left time: 70.7452s\n",
      "\titers: 700, epoch: 2 | loss: 0.1529615\n",
      "\tspeed: 0.0231s/iter; left time: 66.8967s\n",
      "Epoch: 2 cost time: 17.08172059059143\n",
      "Epoch: 2, Steps: 720 | Train Loss: 0.2130737 Vali Loss: 0.3353275 Test Loss: 0.2646066\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1763416\n",
      "\tspeed: 0.0583s/iter; left time: 162.0179s\n",
      "\titers: 200, epoch: 3 | loss: 0.1129971\n",
      "\tspeed: 0.0260s/iter; left time: 69.8190s\n",
      "\titers: 300, epoch: 3 | loss: 0.1638777\n",
      "\tspeed: 0.0243s/iter; left time: 62.8087s\n",
      "\titers: 400, epoch: 3 | loss: 0.2111806\n",
      "\tspeed: 0.0250s/iter; left time: 62.0663s\n",
      "\titers: 500, epoch: 3 | loss: 0.1769844\n",
      "\tspeed: 0.0259s/iter; left time: 61.5706s\n",
      "\titers: 600, epoch: 3 | loss: 0.2558082\n",
      "\tspeed: 0.0250s/iter; left time: 57.0643s\n",
      "\titers: 700, epoch: 3 | loss: 0.1396273\n",
      "\tspeed: 0.0286s/iter; left time: 62.4221s\n",
      "Epoch: 3 cost time: 18.6716570854187\n",
      "Epoch: 3, Steps: 720 | Train Loss: 0.1892953 Vali Loss: 0.3130230 Test Loss: 0.2433610\n",
      "Validation loss decreased (0.324697 --> 0.313023).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1437805\n",
      "\tspeed: 0.0614s/iter; left time: 126.4934s\n",
      "\titers: 200, epoch: 4 | loss: 0.1527761\n",
      "\tspeed: 0.0251s/iter; left time: 49.3085s\n",
      "\titers: 300, epoch: 4 | loss: 0.3058494\n",
      "\tspeed: 0.0262s/iter; left time: 48.7487s\n",
      "\titers: 400, epoch: 4 | loss: 0.1736861\n",
      "\tspeed: 0.0267s/iter; left time: 46.9396s\n",
      "\titers: 500, epoch: 4 | loss: 0.1563891\n",
      "\tspeed: 0.0281s/iter; left time: 46.7170s\n",
      "\titers: 600, epoch: 4 | loss: 0.1766855\n",
      "\tspeed: 0.0252s/iter; left time: 39.3473s\n",
      "\titers: 700, epoch: 4 | loss: 0.1883417\n",
      "\tspeed: 0.0232s/iter; left time: 33.8954s\n",
      "Epoch: 4 cost time: 18.528445959091187\n",
      "Epoch: 4, Steps: 720 | Train Loss: 0.1740954 Vali Loss: 0.3204594 Test Loss: 0.2483284\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1350636\n",
      "\tspeed: 0.0539s/iter; left time: 72.2764s\n",
      "\titers: 200, epoch: 5 | loss: 0.1391133\n",
      "\tspeed: 0.0251s/iter; left time: 31.1405s\n",
      "\titers: 300, epoch: 5 | loss: 0.1425400\n",
      "\tspeed: 0.0234s/iter; left time: 26.6940s\n",
      "\titers: 400, epoch: 5 | loss: 0.2509716\n",
      "\tspeed: 0.0229s/iter; left time: 23.8695s\n",
      "\titers: 500, epoch: 5 | loss: 0.2204332\n",
      "\tspeed: 0.0248s/iter; left time: 23.3225s\n",
      "\titers: 600, epoch: 5 | loss: 0.1883734\n",
      "\tspeed: 0.0236s/iter; left time: 19.8496s\n",
      "\titers: 700, epoch: 5 | loss: 0.1775103\n",
      "\tspeed: 0.0239s/iter; left time: 17.6845s\n",
      "Epoch: 5 cost time: 17.218992948532104\n",
      "Epoch: 5, Steps: 720 | Train Loss: 0.1655226 Vali Loss: 0.3101983 Test Loss: 0.2417996\n",
      "Validation loss decreased (0.313023 --> 0.310198).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1783492\n",
      "\tspeed: 0.0561s/iter; left time: 34.8252s\n",
      "\titers: 200, epoch: 6 | loss: 0.1266442\n",
      "\tspeed: 0.0235s/iter; left time: 12.2436s\n",
      "\titers: 300, epoch: 6 | loss: 0.1495442\n",
      "\tspeed: 0.0228s/iter; left time: 9.6018s\n",
      "\titers: 400, epoch: 6 | loss: 0.3149518\n",
      "\tspeed: 0.0235s/iter; left time: 7.5396s\n",
      "\titers: 500, epoch: 6 | loss: 0.1058590\n",
      "\tspeed: 0.0236s/iter; left time: 5.2141s\n",
      "\titers: 600, epoch: 6 | loss: 0.1137586\n",
      "\tspeed: 0.0234s/iter; left time: 2.8299s\n",
      "\titers: 700, epoch: 6 | loss: 0.1570315\n",
      "\tspeed: 0.0260s/iter; left time: 0.5465s\n",
      "Epoch: 6 cost time: 17.030725240707397\n",
      "Epoch: 6, Steps: 720 | Train Loss: 0.1605665 Vali Loss: 0.3124329 Test Loss: 0.2401771\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "Test cost time: 1.6797s\n",
      "test shape: (198, 32, 6, 1) (198, 32, 6, 1)\n",
      "test shape: (6336, 6, 1) (6336, 6, 1)\n",
      "mse:0.24249285459518433, mae:0.3238699436187744\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1660.536865234375\n",
      "MAE:  26.8006534576416\n",
      "RMSE: 40.74968719482422\n",
      "MAPE: 0.313726007938385\n",
      "MSPE: 0.43038856983184814\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24515\n",
      "[DEBUG] Original dataset length: 24515\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 23049\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3471\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.3414311\n",
      "\tspeed: 0.0219s/iter; left time: 92.4278s\n",
      "\titers: 200, epoch: 1 | loss: 0.1899702\n",
      "\tspeed: 0.0227s/iter; left time: 93.7322s\n",
      "\titers: 300, epoch: 1 | loss: 0.2339462\n",
      "\tspeed: 0.0226s/iter; left time: 90.7795s\n",
      "\titers: 400, epoch: 1 | loss: 0.2228068\n",
      "\tspeed: 0.0253s/iter; left time: 99.3953s\n",
      "\titers: 500, epoch: 1 | loss: 0.1567868\n",
      "\tspeed: 0.0244s/iter; left time: 93.1369s\n",
      "\titers: 600, epoch: 1 | loss: 0.2777991\n",
      "\tspeed: 0.0235s/iter; left time: 87.4861s\n",
      "\titers: 700, epoch: 1 | loss: 0.1768854\n",
      "\tspeed: 0.0217s/iter; left time: 78.5222s\n",
      "Epoch: 1 cost time: 16.676010847091675\n",
      "Epoch: 1, Steps: 720 | Train Loss: 0.2715081 Vali Loss: 0.3351253 Test Loss: 0.2570457\n",
      "Validation loss decreased (inf --> 0.335125).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2987531\n",
      "\tspeed: 0.0549s/iter; left time: 192.0420s\n",
      "\titers: 200, epoch: 2 | loss: 0.4505640\n",
      "\tspeed: 0.0242s/iter; left time: 82.4242s\n",
      "\titers: 300, epoch: 2 | loss: 0.1858991\n",
      "\tspeed: 0.0251s/iter; left time: 82.9982s\n",
      "\titers: 400, epoch: 2 | loss: 0.2055973\n",
      "\tspeed: 0.0250s/iter; left time: 80.0075s\n",
      "\titers: 500, epoch: 2 | loss: 0.2106659\n",
      "\tspeed: 0.0268s/iter; left time: 83.1349s\n",
      "\titers: 600, epoch: 2 | loss: 0.1065798\n",
      "\tspeed: 0.0259s/iter; left time: 77.7714s\n",
      "\titers: 700, epoch: 2 | loss: 0.3444892\n",
      "\tspeed: 0.0223s/iter; left time: 64.5613s\n",
      "Epoch: 2 cost time: 17.693127870559692\n",
      "Epoch: 2, Steps: 720 | Train Loss: 0.2146620 Vali Loss: 0.3338602 Test Loss: 0.2582022\n",
      "Validation loss decreased (0.335125 --> 0.333860).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0934819\n",
      "\tspeed: 0.0564s/iter; left time: 156.8257s\n",
      "\titers: 200, epoch: 3 | loss: 0.2109388\n",
      "\tspeed: 0.0234s/iter; left time: 62.7316s\n",
      "\titers: 300, epoch: 3 | loss: 0.1623186\n",
      "\tspeed: 0.0232s/iter; left time: 59.8882s\n",
      "\titers: 400, epoch: 3 | loss: 0.2894626\n",
      "\tspeed: 0.0233s/iter; left time: 57.6873s\n",
      "\titers: 500, epoch: 3 | loss: 0.1152503\n",
      "\tspeed: 0.0220s/iter; left time: 52.4149s\n",
      "\titers: 600, epoch: 3 | loss: 0.1225025\n",
      "\tspeed: 0.0222s/iter; left time: 50.5520s\n",
      "\titers: 700, epoch: 3 | loss: 0.1353572\n",
      "\tspeed: 0.0255s/iter; left time: 55.6173s\n",
      "Epoch: 3 cost time: 16.710644245147705\n",
      "Epoch: 3, Steps: 720 | Train Loss: 0.1905959 Vali Loss: 0.3129626 Test Loss: 0.2473625\n",
      "Validation loss decreased (0.333860 --> 0.312963).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1344570\n",
      "\tspeed: 0.0571s/iter; left time: 117.7200s\n",
      "\titers: 200, epoch: 4 | loss: 0.1686296\n",
      "\tspeed: 0.0239s/iter; left time: 46.9037s\n",
      "\titers: 300, epoch: 4 | loss: 0.1198684\n",
      "\tspeed: 0.0221s/iter; left time: 41.1459s\n",
      "\titers: 400, epoch: 4 | loss: 0.2628645\n",
      "\tspeed: 0.0250s/iter; left time: 44.0978s\n",
      "\titers: 500, epoch: 4 | loss: 0.1682374\n",
      "\tspeed: 0.0252s/iter; left time: 41.8111s\n",
      "\titers: 600, epoch: 4 | loss: 0.1190256\n",
      "\tspeed: 0.0237s/iter; left time: 37.0205s\n",
      "\titers: 700, epoch: 4 | loss: 0.1724586\n",
      "\tspeed: 0.0232s/iter; left time: 33.9242s\n",
      "Epoch: 4 cost time: 17.22277545928955\n",
      "Epoch: 4, Steps: 720 | Train Loss: 0.1757924 Vali Loss: 0.3037810 Test Loss: 0.2367902\n",
      "Validation loss decreased (0.312963 --> 0.303781).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1478476\n",
      "\tspeed: 0.0581s/iter; left time: 77.9771s\n",
      "\titers: 200, epoch: 5 | loss: 0.1326227\n",
      "\tspeed: 0.0232s/iter; left time: 28.8008s\n",
      "\titers: 300, epoch: 5 | loss: 0.1508033\n",
      "\tspeed: 0.0271s/iter; left time: 30.9347s\n",
      "\titers: 400, epoch: 5 | loss: 0.2109952\n",
      "\tspeed: 0.0239s/iter; left time: 24.9128s\n",
      "\titers: 500, epoch: 5 | loss: 0.1942344\n",
      "\tspeed: 0.0235s/iter; left time: 22.1147s\n",
      "\titers: 600, epoch: 5 | loss: 0.1613557\n",
      "\tspeed: 0.0237s/iter; left time: 19.9718s\n",
      "\titers: 700, epoch: 5 | loss: 0.1786553\n",
      "\tspeed: 0.0228s/iter; left time: 16.9001s\n",
      "Epoch: 5 cost time: 17.284706354141235\n",
      "Epoch: 5, Steps: 720 | Train Loss: 0.1667632 Vali Loss: 0.3163776 Test Loss: 0.2397199\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2221625\n",
      "\tspeed: 0.0572s/iter; left time: 35.5184s\n",
      "\titers: 200, epoch: 6 | loss: 0.1382099\n",
      "\tspeed: 0.0235s/iter; left time: 12.2262s\n",
      "\titers: 300, epoch: 6 | loss: 0.3008234\n",
      "\tspeed: 0.0229s/iter; left time: 9.6496s\n",
      "\titers: 400, epoch: 6 | loss: 0.0952990\n",
      "\tspeed: 0.0241s/iter; left time: 7.7519s\n",
      "\titers: 500, epoch: 6 | loss: 0.2238376\n",
      "\tspeed: 0.0230s/iter; left time: 5.0819s\n",
      "\titers: 600, epoch: 6 | loss: 0.1833549\n",
      "\tspeed: 0.0232s/iter; left time: 2.8060s\n",
      "\titers: 700, epoch: 6 | loss: 0.1252413\n",
      "\tspeed: 0.0263s/iter; left time: 0.5516s\n",
      "Epoch: 6 cost time: 17.37981367111206\n",
      "Epoch: 6, Steps: 720 | Train Loss: 0.1619495 Vali Loss: 0.3131686 Test Loss: 0.2429099\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "Test cost time: 1.7413s\n",
      "test shape: (198, 32, 6, 1) (198, 32, 6, 1)\n",
      "test shape: (6336, 6, 1) (6336, 6, 1)\n",
      "mse:0.23721960186958313, mae:0.3236594796180725\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1624.426513671875\n",
      "MAE:  26.783235549926758\n",
      "RMSE: 40.304176330566406\n",
      "MAPE: 0.3481487035751343\n",
      "MSPE: 0.585425078868866\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24515\n",
      "[DEBUG] Original dataset length: 24515\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 23049\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3471\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.2095406\n",
      "\tspeed: 0.0237s/iter; left time: 99.9963s\n",
      "\titers: 200, epoch: 1 | loss: 0.3680976\n",
      "\tspeed: 0.0232s/iter; left time: 95.5156s\n",
      "\titers: 300, epoch: 1 | loss: 0.2528623\n",
      "\tspeed: 0.0228s/iter; left time: 91.8696s\n",
      "\titers: 400, epoch: 1 | loss: 0.1550481\n",
      "\tspeed: 0.0259s/iter; left time: 101.6257s\n",
      "\titers: 500, epoch: 1 | loss: 0.2939257\n",
      "\tspeed: 0.0226s/iter; left time: 86.4118s\n",
      "\titers: 600, epoch: 1 | loss: 0.3265004\n",
      "\tspeed: 0.0226s/iter; left time: 84.0225s\n",
      "\titers: 700, epoch: 1 | loss: 0.1744516\n",
      "\tspeed: 0.0175s/iter; left time: 63.4609s\n",
      "Epoch: 1 cost time: 16.163893222808838\n",
      "Epoch: 1, Steps: 720 | Train Loss: 0.2724532 Vali Loss: 0.3339336 Test Loss: 0.2619038\n",
      "Validation loss decreased (inf --> 0.333934).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2605522\n",
      "\tspeed: 0.0525s/iter; left time: 183.6673s\n",
      "\titers: 200, epoch: 2 | loss: 0.1692313\n",
      "\tspeed: 0.0250s/iter; left time: 84.9114s\n",
      "\titers: 300, epoch: 2 | loss: 0.1547834\n",
      "\tspeed: 0.0262s/iter; left time: 86.4543s\n",
      "\titers: 400, epoch: 2 | loss: 0.3553451\n",
      "\tspeed: 0.0238s/iter; left time: 76.1255s\n",
      "\titers: 500, epoch: 2 | loss: 0.1434582\n",
      "\tspeed: 0.0235s/iter; left time: 72.9234s\n",
      "\titers: 600, epoch: 2 | loss: 0.2930814\n",
      "\tspeed: 0.0235s/iter; left time: 70.6482s\n",
      "\titers: 700, epoch: 2 | loss: 0.2578700\n",
      "\tspeed: 0.0231s/iter; left time: 66.8967s\n",
      "Epoch: 2 cost time: 17.243138551712036\n",
      "Epoch: 2, Steps: 720 | Train Loss: 0.2163328 Vali Loss: 0.3121336 Test Loss: 0.2501607\n",
      "Validation loss decreased (0.333934 --> 0.312134).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1632709\n",
      "\tspeed: 0.0592s/iter; left time: 164.5605s\n",
      "\titers: 200, epoch: 3 | loss: 0.1394314\n",
      "\tspeed: 0.0234s/iter; left time: 62.6164s\n",
      "\titers: 300, epoch: 3 | loss: 0.1221570\n",
      "\tspeed: 0.0230s/iter; left time: 59.3103s\n",
      "\titers: 400, epoch: 3 | loss: 0.1482583\n",
      "\tspeed: 0.0241s/iter; left time: 59.8954s\n",
      "\titers: 500, epoch: 3 | loss: 0.1701573\n",
      "\tspeed: 0.0236s/iter; left time: 56.2994s\n",
      "\titers: 600, epoch: 3 | loss: 0.1325508\n",
      "\tspeed: 0.0240s/iter; left time: 54.8388s\n",
      "\titers: 700, epoch: 3 | loss: 0.2224279\n",
      "\tspeed: 0.0255s/iter; left time: 55.6730s\n",
      "Epoch: 3 cost time: 17.32090926170349\n",
      "Epoch: 3, Steps: 720 | Train Loss: 0.1874845 Vali Loss: 0.3126444 Test Loss: 0.2540839\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1805493\n",
      "\tspeed: 0.0535s/iter; left time: 110.1825s\n",
      "\titers: 200, epoch: 4 | loss: 0.1811765\n",
      "\tspeed: 0.0228s/iter; left time: 44.7183s\n",
      "\titers: 300, epoch: 4 | loss: 0.0797887\n",
      "\tspeed: 0.0234s/iter; left time: 43.5931s\n",
      "\titers: 400, epoch: 4 | loss: 0.1427653\n",
      "\tspeed: 0.0227s/iter; left time: 40.0412s\n",
      "\titers: 500, epoch: 4 | loss: 0.0813835\n",
      "\tspeed: 0.0266s/iter; left time: 44.2643s\n",
      "\titers: 600, epoch: 4 | loss: 0.1861085\n",
      "\tspeed: 0.0231s/iter; left time: 36.1131s\n",
      "\titers: 700, epoch: 4 | loss: 0.2181343\n",
      "\tspeed: 0.0239s/iter; left time: 34.8905s\n",
      "Epoch: 4 cost time: 17.11237072944641\n",
      "Epoch: 4, Steps: 720 | Train Loss: 0.1742397 Vali Loss: 0.3057671 Test Loss: 0.2386443\n",
      "Validation loss decreased (0.312134 --> 0.305767).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1590848\n",
      "\tspeed: 0.0554s/iter; left time: 74.2978s\n",
      "\titers: 200, epoch: 5 | loss: 0.2364831\n",
      "\tspeed: 0.0235s/iter; left time: 29.1286s\n",
      "\titers: 300, epoch: 5 | loss: 0.1418073\n",
      "\tspeed: 0.0253s/iter; left time: 28.8514s\n",
      "\titers: 400, epoch: 5 | loss: 0.1251081\n",
      "\tspeed: 0.0252s/iter; left time: 26.2196s\n",
      "\titers: 500, epoch: 5 | loss: 0.1622922\n",
      "\tspeed: 0.0232s/iter; left time: 21.8418s\n",
      "\titers: 600, epoch: 5 | loss: 0.1210797\n",
      "\tspeed: 0.0239s/iter; left time: 20.0659s\n",
      "\titers: 700, epoch: 5 | loss: 0.1207851\n",
      "\tspeed: 0.0237s/iter; left time: 17.5329s\n",
      "Epoch: 5 cost time: 17.30023193359375\n",
      "Epoch: 5, Steps: 720 | Train Loss: 0.1659484 Vali Loss: 0.3023714 Test Loss: 0.2387340\n",
      "Validation loss decreased (0.305767 --> 0.302371).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1459343\n",
      "\tspeed: 0.0588s/iter; left time: 36.5101s\n",
      "\titers: 200, epoch: 6 | loss: 0.1696891\n",
      "\tspeed: 0.0228s/iter; left time: 11.8653s\n",
      "\titers: 300, epoch: 6 | loss: 0.1633240\n",
      "\tspeed: 0.0222s/iter; left time: 9.3257s\n",
      "\titers: 400, epoch: 6 | loss: 0.1348028\n",
      "\tspeed: 0.0241s/iter; left time: 7.7492s\n",
      "\titers: 500, epoch: 6 | loss: 0.1136203\n",
      "\tspeed: 0.0226s/iter; left time: 4.9845s\n",
      "\titers: 600, epoch: 6 | loss: 0.0934504\n",
      "\tspeed: 0.0230s/iter; left time: 2.7815s\n",
      "\titers: 700, epoch: 6 | loss: 0.1588615\n",
      "\tspeed: 0.0249s/iter; left time: 0.5232s\n",
      "Epoch: 6 cost time: 17.092089653015137\n",
      "Epoch: 6, Steps: 720 | Train Loss: 0.1607868 Vali Loss: 0.3073252 Test Loss: 0.2407584\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "Test cost time: 1.6340s\n",
      "test shape: (198, 32, 6, 1) (198, 32, 6, 1)\n",
      "test shape: (6336, 6, 1) (6336, 6, 1)\n",
      "mse:0.23889628052711487, mae:0.32353052496910095\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1635.9080810546875\n",
      "MAE:  26.77256965637207\n",
      "RMSE: 40.44636154174805\n",
      "MAPE: 0.316813200712204\n",
      "MSPE: 0.45653998851776123\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24515\n",
      "[DEBUG] Original dataset length: 24515\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 23049\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3471\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.2363328\n",
      "\tspeed: 0.0241s/iter; left time: 101.5339s\n",
      "\titers: 200, epoch: 1 | loss: 0.3365135\n",
      "\tspeed: 0.0250s/iter; left time: 102.8387s\n",
      "\titers: 300, epoch: 1 | loss: 0.2770802\n",
      "\tspeed: 0.0234s/iter; left time: 93.9482s\n",
      "\titers: 400, epoch: 1 | loss: 0.2811079\n",
      "\tspeed: 0.0254s/iter; left time: 99.7621s\n",
      "\titers: 500, epoch: 1 | loss: 0.1877128\n",
      "\tspeed: 0.0246s/iter; left time: 93.9853s\n",
      "\titers: 600, epoch: 1 | loss: 0.2600272\n",
      "\tspeed: 0.0239s/iter; left time: 88.9503s\n",
      "\titers: 700, epoch: 1 | loss: 0.1489640\n",
      "\tspeed: 0.0223s/iter; left time: 80.5823s\n",
      "Epoch: 1 cost time: 17.300275087356567\n",
      "Epoch: 1, Steps: 720 | Train Loss: 0.2685788 Vali Loss: 0.3278439 Test Loss: 0.2556056\n",
      "Validation loss decreased (inf --> 0.327844).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1440834\n",
      "\tspeed: 0.0563s/iter; left time: 196.9384s\n",
      "\titers: 200, epoch: 2 | loss: 0.1496831\n",
      "\tspeed: 0.0260s/iter; left time: 88.5556s\n",
      "\titers: 300, epoch: 2 | loss: 0.2025033\n",
      "\tspeed: 0.0234s/iter; left time: 77.2715s\n",
      "\titers: 400, epoch: 2 | loss: 0.1285628\n",
      "\tspeed: 0.0233s/iter; left time: 74.4252s\n",
      "\titers: 500, epoch: 2 | loss: 0.2302941\n",
      "\tspeed: 0.0237s/iter; left time: 73.5845s\n",
      "\titers: 600, epoch: 2 | loss: 0.2207744\n",
      "\tspeed: 0.0226s/iter; left time: 67.8980s\n",
      "\titers: 700, epoch: 2 | loss: 0.1772367\n",
      "\tspeed: 0.0233s/iter; left time: 67.6746s\n",
      "Epoch: 2 cost time: 17.05386185646057\n",
      "Epoch: 2, Steps: 720 | Train Loss: 0.2155362 Vali Loss: 0.3380999 Test Loss: 0.2630863\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1724974\n",
      "\tspeed: 0.0550s/iter; left time: 153.0133s\n",
      "\titers: 200, epoch: 3 | loss: 0.1823882\n",
      "\tspeed: 0.0236s/iter; left time: 63.2095s\n",
      "\titers: 300, epoch: 3 | loss: 0.1806660\n",
      "\tspeed: 0.0241s/iter; left time: 62.0858s\n",
      "\titers: 400, epoch: 3 | loss: 0.2218558\n",
      "\tspeed: 0.0227s/iter; left time: 56.3988s\n",
      "\titers: 500, epoch: 3 | loss: 0.1658197\n",
      "\tspeed: 0.0241s/iter; left time: 57.2805s\n",
      "\titers: 600, epoch: 3 | loss: 0.1470765\n",
      "\tspeed: 0.0237s/iter; left time: 54.1414s\n",
      "\titers: 700, epoch: 3 | loss: 0.1589901\n",
      "\tspeed: 0.0257s/iter; left time: 55.9875s\n",
      "Epoch: 3 cost time: 17.252692937850952\n",
      "Epoch: 3, Steps: 720 | Train Loss: 0.1904237 Vali Loss: 0.3296501 Test Loss: 0.2754223\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1778895\n",
      "\tspeed: 0.0546s/iter; left time: 112.5700s\n",
      "\titers: 200, epoch: 4 | loss: 0.1789588\n",
      "\tspeed: 0.0225s/iter; left time: 44.2178s\n",
      "\titers: 300, epoch: 4 | loss: 0.1910141\n",
      "\tspeed: 0.0220s/iter; left time: 40.9653s\n",
      "\titers: 400, epoch: 4 | loss: 0.1264728\n",
      "\tspeed: 0.0226s/iter; left time: 39.8824s\n",
      "\titers: 500, epoch: 4 | loss: 0.1202404\n",
      "\tspeed: 0.0264s/iter; left time: 43.8401s\n",
      "\titers: 600, epoch: 4 | loss: 0.1668287\n",
      "\tspeed: 0.0235s/iter; left time: 36.6444s\n",
      "\titers: 700, epoch: 4 | loss: 0.1828644\n",
      "\tspeed: 0.0231s/iter; left time: 33.7379s\n",
      "Epoch: 4 cost time: 16.894968271255493\n",
      "Epoch: 4, Steps: 720 | Train Loss: 0.1762035 Vali Loss: 0.3027068 Test Loss: 0.2406115\n",
      "Validation loss decreased (0.327844 --> 0.302707).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1850672\n",
      "\tspeed: 0.0568s/iter; left time: 76.2134s\n",
      "\titers: 200, epoch: 5 | loss: 0.1287893\n",
      "\tspeed: 0.0230s/iter; left time: 28.5745s\n",
      "\titers: 300, epoch: 5 | loss: 0.1777712\n",
      "\tspeed: 0.0282s/iter; left time: 32.1203s\n",
      "\titers: 400, epoch: 5 | loss: 0.2494338\n",
      "\tspeed: 0.0240s/iter; left time: 24.9357s\n",
      "\titers: 500, epoch: 5 | loss: 0.1151850\n",
      "\tspeed: 0.0230s/iter; left time: 21.6263s\n",
      "\titers: 600, epoch: 5 | loss: 0.2260147\n",
      "\tspeed: 0.0243s/iter; left time: 20.3999s\n",
      "\titers: 700, epoch: 5 | loss: 0.1898606\n",
      "\tspeed: 0.0242s/iter; left time: 17.9381s\n",
      "Epoch: 5 cost time: 17.51840877532959\n",
      "Epoch: 5, Steps: 720 | Train Loss: 0.1672058 Vali Loss: 0.3083397 Test Loss: 0.2436474\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1243304\n",
      "\tspeed: 0.0574s/iter; left time: 35.6224s\n",
      "\titers: 200, epoch: 6 | loss: 0.2118607\n",
      "\tspeed: 0.0233s/iter; left time: 12.1384s\n",
      "\titers: 300, epoch: 6 | loss: 0.1241337\n",
      "\tspeed: 0.0245s/iter; left time: 10.3020s\n",
      "\titers: 400, epoch: 6 | loss: 0.1316978\n",
      "\tspeed: 0.0245s/iter; left time: 7.8635s\n",
      "\titers: 500, epoch: 6 | loss: 0.1916963\n",
      "\tspeed: 0.0231s/iter; left time: 5.1116s\n",
      "\titers: 600, epoch: 6 | loss: 0.1652163\n",
      "\tspeed: 0.0234s/iter; left time: 2.8347s\n",
      "\titers: 700, epoch: 6 | loss: 0.1501549\n",
      "\tspeed: 0.0263s/iter; left time: 0.5523s\n",
      "Epoch: 6 cost time: 17.649580478668213\n",
      "Epoch: 6, Steps: 720 | Train Loss: 0.1616795 Vali Loss: 0.3042971 Test Loss: 0.2395506\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "Test cost time: 1.6244s\n",
      "test shape: (198, 32, 6, 1) (198, 32, 6, 1)\n",
      "test shape: (6336, 6, 1) (6336, 6, 1)\n",
      "mse:0.23971359431743622, mae:0.322177529335022\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1641.504638671875\n",
      "MAE:  26.66060447692871\n",
      "RMSE: 40.51548767089844\n",
      "MAPE: 0.31655874848365784\n",
      "MSPE: 0.4469534754753113\n",
      ">>>>>>>Running time saved<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Running seq_len=48\n",
      "Args in experiment:\n",
      "Namespace(model='informer', data='traffic_full', root_path='../', data_path='traffic_full.csv', features='S', target='flow', freq='h', checkpoints='./checkpoints/', seq_len=48, label_len=24, pred_len=6, enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=2, d_layers=1, s_layers=[3, 2, 1], d_ff=2048, factor=5, padding=0, distil=True, dropout=0.05, attn='prob', embed='timeF', activation='gelu', output_attention=False, do_predict=False, mix=True, cols=None, num_workers=0, itr=10, train_epochs=6, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, inverse=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', detail_freq='h')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24491\n",
      "[DEBUG] Original dataset length: 24491\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22641\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3447\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "\titers: 100, epoch: 1 | loss: 0.4210311\n",
      "\tspeed: 0.0383s/iter; left time: 158.4818s\n",
      "\titers: 200, epoch: 1 | loss: 0.3457952\n",
      "\tspeed: 0.0270s/iter; left time: 109.2311s\n",
      "\titers: 300, epoch: 1 | loss: 0.1513244\n",
      "\tspeed: 0.0251s/iter; left time: 98.9940s\n",
      "\titers: 400, epoch: 1 | loss: 0.2177240\n",
      "\tspeed: 0.0246s/iter; left time: 94.3818s\n",
      "\titers: 500, epoch: 1 | loss: 0.4256431\n",
      "\tspeed: 0.0233s/iter; left time: 87.2379s\n",
      "\titers: 600, epoch: 1 | loss: 0.2885630\n",
      "\tspeed: 0.0236s/iter; left time: 86.1039s\n",
      "\titers: 700, epoch: 1 | loss: 0.1595648\n",
      "\tspeed: 0.0232s/iter; left time: 82.2992s\n",
      "Epoch: 1 cost time: 17.807585954666138\n",
      "Epoch: 1, Steps: 707 | Train Loss: 0.2804786 Vali Loss: 0.3333379 Test Loss: 0.2599899\n",
      "Validation loss decreased (inf --> 0.333338).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3905847\n",
      "\tspeed: 0.0556s/iter; left time: 190.9797s\n",
      "\titers: 200, epoch: 2 | loss: 0.1405668\n",
      "\tspeed: 0.0240s/iter; left time: 79.9787s\n",
      "\titers: 300, epoch: 2 | loss: 0.1045581\n",
      "\tspeed: 0.0250s/iter; left time: 81.0538s\n",
      "\titers: 400, epoch: 2 | loss: 0.3019554\n",
      "\tspeed: 0.0237s/iter; left time: 74.3569s\n",
      "\titers: 500, epoch: 2 | loss: 0.2593046\n",
      "\tspeed: 0.0235s/iter; left time: 71.2186s\n",
      "\titers: 600, epoch: 2 | loss: 0.2665177\n",
      "\tspeed: 0.0252s/iter; left time: 73.9049s\n",
      "\titers: 700, epoch: 2 | loss: 0.2768565\n",
      "\tspeed: 0.0264s/iter; left time: 74.8195s\n",
      "Epoch: 2 cost time: 17.495580673217773\n",
      "Epoch: 2, Steps: 707 | Train Loss: 0.2114408 Vali Loss: 0.3176592 Test Loss: 0.2518454\n",
      "Validation loss decreased (0.333338 --> 0.317659).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2002572\n",
      "\tspeed: 0.0525s/iter; left time: 143.2258s\n",
      "\titers: 200, epoch: 3 | loss: 0.2935592\n",
      "\tspeed: 0.0239s/iter; left time: 62.8512s\n",
      "\titers: 300, epoch: 3 | loss: 0.2452094\n",
      "\tspeed: 0.0247s/iter; left time: 62.4923s\n",
      "\titers: 400, epoch: 3 | loss: 0.1751938\n",
      "\tspeed: 0.0247s/iter; left time: 60.0598s\n",
      "\titers: 500, epoch: 3 | loss: 0.2048770\n",
      "\tspeed: 0.0287s/iter; left time: 66.8183s\n",
      "\titers: 600, epoch: 3 | loss: 0.1291269\n",
      "\tspeed: 0.0239s/iter; left time: 53.2691s\n",
      "\titers: 700, epoch: 3 | loss: 0.1791790\n",
      "\tspeed: 0.0232s/iter; left time: 49.4615s\n",
      "Epoch: 3 cost time: 17.511465311050415\n",
      "Epoch: 3, Steps: 707 | Train Loss: 0.1859855 Vali Loss: 0.3070369 Test Loss: 0.2368643\n",
      "Validation loss decreased (0.317659 --> 0.307037).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1564780\n",
      "\tspeed: 0.0532s/iter; left time: 107.6137s\n",
      "\titers: 200, epoch: 4 | loss: 0.1667581\n",
      "\tspeed: 0.0250s/iter; left time: 48.0428s\n",
      "\titers: 300, epoch: 4 | loss: 0.1477265\n",
      "\tspeed: 0.0258s/iter; left time: 47.0434s\n",
      "\titers: 400, epoch: 4 | loss: 0.1481032\n",
      "\tspeed: 0.0239s/iter; left time: 41.1474s\n",
      "\titers: 500, epoch: 4 | loss: 0.1348788\n",
      "\tspeed: 0.0250s/iter; left time: 40.4989s\n",
      "\titers: 600, epoch: 4 | loss: 0.1294691\n",
      "\tspeed: 0.0244s/iter; left time: 37.0727s\n",
      "\titers: 700, epoch: 4 | loss: 0.1531549\n",
      "\tspeed: 0.0248s/iter; left time: 35.2060s\n",
      "Epoch: 4 cost time: 17.43866753578186\n",
      "Epoch: 4, Steps: 707 | Train Loss: 0.1710407 Vali Loss: 0.3080489 Test Loss: 0.2389767\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0991146\n",
      "\tspeed: 0.0540s/iter; left time: 70.9450s\n",
      "\titers: 200, epoch: 5 | loss: 0.1438493\n",
      "\tspeed: 0.0248s/iter; left time: 30.1200s\n",
      "\titers: 300, epoch: 5 | loss: 0.0933202\n",
      "\tspeed: 0.0247s/iter; left time: 27.5472s\n",
      "\titers: 400, epoch: 5 | loss: 0.0841533\n",
      "\tspeed: 0.0238s/iter; left time: 24.1759s\n",
      "\titers: 500, epoch: 5 | loss: 0.1186457\n",
      "\tspeed: 0.0245s/iter; left time: 22.4377s\n",
      "\titers: 600, epoch: 5 | loss: 0.2508901\n",
      "\tspeed: 0.0252s/iter; left time: 20.5340s\n",
      "\titers: 700, epoch: 5 | loss: 0.1364281\n",
      "\tspeed: 0.0266s/iter; left time: 19.0191s\n",
      "Epoch: 5 cost time: 17.737491130828857\n",
      "Epoch: 5, Steps: 707 | Train Loss: 0.1620446 Vali Loss: 0.3012838 Test Loss: 0.2373968\n",
      "Validation loss decreased (0.307037 --> 0.301284).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1858535\n",
      "\tspeed: 0.0536s/iter; left time: 32.5811s\n",
      "\titers: 200, epoch: 6 | loss: 0.1200128\n",
      "\tspeed: 0.0243s/iter; left time: 12.3531s\n",
      "\titers: 300, epoch: 6 | loss: 0.2558707\n",
      "\tspeed: 0.0250s/iter; left time: 10.1886s\n",
      "\titers: 400, epoch: 6 | loss: 0.0860212\n",
      "\tspeed: 0.0254s/iter; left time: 7.8140s\n",
      "\titers: 500, epoch: 6 | loss: 0.1418271\n",
      "\tspeed: 0.0250s/iter; left time: 5.2016s\n",
      "\titers: 600, epoch: 6 | loss: 0.1010118\n",
      "\tspeed: 0.0240s/iter; left time: 2.5956s\n",
      "\titers: 700, epoch: 6 | loss: 0.1927746\n",
      "\tspeed: 0.0239s/iter; left time: 0.1916s\n",
      "Epoch: 6 cost time: 17.434693574905396\n",
      "Epoch: 6, Steps: 707 | Train Loss: 0.1567271 Vali Loss: 0.3222309 Test Loss: 0.2441462\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "Test cost time: 1.7408s\n",
      "test shape: (192, 32, 6, 1) (192, 32, 6, 1)\n",
      "test shape: (6144, 6, 1) (6144, 6, 1)\n",
      "mse:0.23733316361904144, mae:0.3256560266017914\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1625.2042236328125\n",
      "MAE:  26.94845199584961\n",
      "RMSE: 40.313819885253906\n",
      "MAPE: 0.3423309326171875\n",
      "MSPE: 0.5607410669326782\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24491\n",
      "[DEBUG] Original dataset length: 24491\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22641\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3447\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "\titers: 100, epoch: 1 | loss: 0.4390069\n",
      "\tspeed: 0.0261s/iter; left time: 108.1554s\n",
      "\titers: 200, epoch: 1 | loss: 0.2514298\n",
      "\tspeed: 0.0251s/iter; left time: 101.4952s\n",
      "\titers: 300, epoch: 1 | loss: 0.2287695\n",
      "\tspeed: 0.0238s/iter; left time: 94.0039s\n",
      "\titers: 400, epoch: 1 | loss: 0.2228647\n",
      "\tspeed: 0.0251s/iter; left time: 96.3374s\n",
      "\titers: 500, epoch: 1 | loss: 0.3023682\n",
      "\tspeed: 0.0242s/iter; left time: 90.7072s\n",
      "\titers: 600, epoch: 1 | loss: 0.1733539\n",
      "\tspeed: 0.0248s/iter; left time: 90.3469s\n",
      "\titers: 700, epoch: 1 | loss: 0.1486857\n",
      "\tspeed: 0.0267s/iter; left time: 94.5472s\n",
      "Epoch: 1 cost time: 17.807084560394287\n",
      "Epoch: 1, Steps: 707 | Train Loss: 0.2753465 Vali Loss: 0.3358818 Test Loss: 0.2625759\n",
      "Validation loss decreased (inf --> 0.335882).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2089699\n",
      "\tspeed: 0.0547s/iter; left time: 188.1047s\n",
      "\titers: 200, epoch: 2 | loss: 0.2221625\n",
      "\tspeed: 0.0241s/iter; left time: 80.5167s\n",
      "\titers: 300, epoch: 2 | loss: 0.2049545\n",
      "\tspeed: 0.0243s/iter; left time: 78.5491s\n",
      "\titers: 400, epoch: 2 | loss: 0.2321509\n",
      "\tspeed: 0.0245s/iter; left time: 76.7277s\n",
      "\titers: 500, epoch: 2 | loss: 0.1381558\n",
      "\tspeed: 0.0270s/iter; left time: 82.0353s\n",
      "\titers: 600, epoch: 2 | loss: 0.1520614\n",
      "\tspeed: 0.0238s/iter; left time: 69.9116s\n",
      "\titers: 700, epoch: 2 | loss: 0.2239976\n",
      "\tspeed: 0.0237s/iter; left time: 67.3424s\n",
      "Epoch: 2 cost time: 17.442261219024658\n",
      "Epoch: 2, Steps: 707 | Train Loss: 0.2111526 Vali Loss: 0.3217575 Test Loss: 0.2536869\n",
      "Validation loss decreased (0.335882 --> 0.321758).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1364773\n",
      "\tspeed: 0.0540s/iter; left time: 147.3980s\n",
      "\titers: 200, epoch: 3 | loss: 0.2409610\n",
      "\tspeed: 0.0247s/iter; left time: 65.0290s\n",
      "\titers: 300, epoch: 3 | loss: 0.1257214\n",
      "\tspeed: 0.0274s/iter; left time: 69.2603s\n",
      "\titers: 400, epoch: 3 | loss: 0.1675286\n",
      "\tspeed: 0.0266s/iter; left time: 64.5114s\n",
      "\titers: 500, epoch: 3 | loss: 0.1347077\n",
      "\tspeed: 0.0258s/iter; left time: 60.2023s\n",
      "\titers: 600, epoch: 3 | loss: 0.1661098\n",
      "\tspeed: 0.0247s/iter; left time: 55.0093s\n",
      "\titers: 700, epoch: 3 | loss: 0.1089203\n",
      "\tspeed: 0.0239s/iter; left time: 50.9358s\n",
      "Epoch: 3 cost time: 17.85577893257141\n",
      "Epoch: 3, Steps: 707 | Train Loss: 0.1843082 Vali Loss: 0.3294305 Test Loss: 0.2671072\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1299461\n",
      "\tspeed: 0.0550s/iter; left time: 111.2203s\n",
      "\titers: 200, epoch: 4 | loss: 0.1347720\n",
      "\tspeed: 0.0245s/iter; left time: 47.0022s\n",
      "\titers: 300, epoch: 4 | loss: 0.1330140\n",
      "\tspeed: 0.0242s/iter; left time: 44.1729s\n",
      "\titers: 400, epoch: 4 | loss: 0.1948192\n",
      "\tspeed: 0.0249s/iter; left time: 42.9100s\n",
      "\titers: 500, epoch: 4 | loss: 0.1727332\n",
      "\tspeed: 0.0244s/iter; left time: 39.6106s\n",
      "\titers: 600, epoch: 4 | loss: 0.1938460\n",
      "\tspeed: 0.0252s/iter; left time: 38.3807s\n",
      "\titers: 700, epoch: 4 | loss: 0.1064410\n",
      "\tspeed: 0.0271s/iter; left time: 38.5130s\n",
      "Epoch: 4 cost time: 17.874019861221313\n",
      "Epoch: 4, Steps: 707 | Train Loss: 0.1717788 Vali Loss: 0.3170339 Test Loss: 0.2434676\n",
      "Validation loss decreased (0.321758 --> 0.317034).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1455170\n",
      "\tspeed: 0.0549s/iter; left time: 72.2490s\n",
      "\titers: 200, epoch: 5 | loss: 0.1549000\n",
      "\tspeed: 0.0236s/iter; left time: 28.6521s\n",
      "\titers: 300, epoch: 5 | loss: 0.1402128\n",
      "\tspeed: 0.0243s/iter; left time: 27.1430s\n",
      "\titers: 400, epoch: 5 | loss: 0.1134744\n",
      "\tspeed: 0.0248s/iter; left time: 25.2017s\n",
      "\titers: 500, epoch: 5 | loss: 0.1262564\n",
      "\tspeed: 0.0270s/iter; left time: 24.7486s\n",
      "\titers: 600, epoch: 5 | loss: 0.1395959\n",
      "\tspeed: 0.0246s/iter; left time: 20.0882s\n",
      "\titers: 700, epoch: 5 | loss: 0.1280554\n",
      "\tspeed: 0.0244s/iter; left time: 17.4223s\n",
      "Epoch: 5 cost time: 17.606274127960205\n",
      "Epoch: 5, Steps: 707 | Train Loss: 0.1615815 Vali Loss: 0.3096191 Test Loss: 0.2373020\n",
      "Validation loss decreased (0.317034 --> 0.309619).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1940884\n",
      "\tspeed: 0.0551s/iter; left time: 33.5286s\n",
      "\titers: 200, epoch: 6 | loss: 0.1898064\n",
      "\tspeed: 0.0246s/iter; left time: 12.5180s\n",
      "\titers: 300, epoch: 6 | loss: 0.3149776\n",
      "\tspeed: 0.0258s/iter; left time: 10.5446s\n",
      "\titers: 400, epoch: 6 | loss: 0.2096702\n",
      "\tspeed: 0.0238s/iter; left time: 7.3331s\n",
      "\titers: 500, epoch: 6 | loss: 0.1424762\n",
      "\tspeed: 0.0247s/iter; left time: 5.1304s\n",
      "\titers: 600, epoch: 6 | loss: 0.1819395\n",
      "\tspeed: 0.0234s/iter; left time: 2.5292s\n",
      "\titers: 700, epoch: 6 | loss: 0.1783880\n",
      "\tspeed: 0.0250s/iter; left time: 0.1999s\n",
      "Epoch: 6 cost time: 17.34546399116516\n",
      "Epoch: 6, Steps: 707 | Train Loss: 0.1563585 Vali Loss: 0.3135792 Test Loss: 0.2407655\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "Test cost time: 1.9008s\n",
      "test shape: (192, 32, 6, 1) (192, 32, 6, 1)\n",
      "test shape: (6144, 6, 1) (6144, 6, 1)\n",
      "mse:0.23867511749267578, mae:0.32231882214546204\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1634.3936767578125\n",
      "MAE:  26.67229652404785\n",
      "RMSE: 40.427635192871094\n",
      "MAPE: 0.32730603218078613\n",
      "MSPE: 0.48404496908187866\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24491\n",
      "[DEBUG] Original dataset length: 24491\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22641\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3447\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "\titers: 100, epoch: 1 | loss: 0.1704289\n",
      "\tspeed: 0.0266s/iter; left time: 110.3374s\n",
      "\titers: 200, epoch: 1 | loss: 0.2835771\n",
      "\tspeed: 0.0249s/iter; left time: 100.5798s\n",
      "\titers: 300, epoch: 1 | loss: 0.2850280\n",
      "\tspeed: 0.0237s/iter; left time: 93.5739s\n",
      "\titers: 400, epoch: 1 | loss: 0.2920347\n",
      "\tspeed: 0.0245s/iter; left time: 94.2281s\n",
      "\titers: 500, epoch: 1 | loss: 0.1958680\n",
      "\tspeed: 0.0243s/iter; left time: 90.8143s\n",
      "\titers: 600, epoch: 1 | loss: 0.2792860\n",
      "\tspeed: 0.0263s/iter; left time: 95.9120s\n",
      "\titers: 700, epoch: 1 | loss: 0.1850270\n",
      "\tspeed: 0.0236s/iter; left time: 83.5442s\n",
      "Epoch: 1 cost time: 17.562478065490723\n",
      "Epoch: 1, Steps: 707 | Train Loss: 0.2785999 Vali Loss: 0.3357542 Test Loss: 0.2677054\n",
      "Validation loss decreased (inf --> 0.335754).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2084626\n",
      "\tspeed: 0.0536s/iter; left time: 184.2814s\n",
      "\titers: 200, epoch: 2 | loss: 0.3886803\n",
      "\tspeed: 0.0251s/iter; left time: 83.7394s\n",
      "\titers: 300, epoch: 2 | loss: 0.1933730\n",
      "\tspeed: 0.0265s/iter; left time: 85.8617s\n",
      "\titers: 400, epoch: 2 | loss: 0.1982645\n",
      "\tspeed: 0.0266s/iter; left time: 83.4135s\n",
      "\titers: 500, epoch: 2 | loss: 0.1970346\n",
      "\tspeed: 0.0240s/iter; left time: 72.9749s\n",
      "\titers: 600, epoch: 2 | loss: 0.2151261\n",
      "\tspeed: 0.0249s/iter; left time: 72.9969s\n",
      "\titers: 700, epoch: 2 | loss: 0.2453477\n",
      "\tspeed: 0.0244s/iter; left time: 69.2992s\n",
      "Epoch: 2 cost time: 17.765398502349854\n",
      "Epoch: 2, Steps: 707 | Train Loss: 0.2146884 Vali Loss: 0.3046222 Test Loss: 0.2396729\n",
      "Validation loss decreased (0.335754 --> 0.304622).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1312850\n",
      "\tspeed: 0.0565s/iter; left time: 154.3200s\n",
      "\titers: 200, epoch: 3 | loss: 0.1794149\n",
      "\tspeed: 0.0252s/iter; left time: 66.2990s\n",
      "\titers: 300, epoch: 3 | loss: 0.1696878\n",
      "\tspeed: 0.0247s/iter; left time: 62.3799s\n",
      "\titers: 400, epoch: 3 | loss: 0.2421931\n",
      "\tspeed: 0.0235s/iter; left time: 57.0257s\n",
      "\titers: 500, epoch: 3 | loss: 0.2663363\n",
      "\tspeed: 0.0234s/iter; left time: 54.5860s\n",
      "\titers: 600, epoch: 3 | loss: 0.1547637\n",
      "\tspeed: 0.0256s/iter; left time: 57.1633s\n",
      "\titers: 700, epoch: 3 | loss: 0.2589108\n",
      "\tspeed: 0.0241s/iter; left time: 51.3881s\n",
      "Epoch: 3 cost time: 17.495702981948853\n",
      "Epoch: 3, Steps: 707 | Train Loss: 0.1842913 Vali Loss: 0.3125278 Test Loss: 0.2504686\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1227972\n",
      "\tspeed: 0.0574s/iter; left time: 116.0030s\n",
      "\titers: 200, epoch: 4 | loss: 0.2047904\n",
      "\tspeed: 0.0251s/iter; left time: 48.1879s\n",
      "\titers: 300, epoch: 4 | loss: 0.1599318\n",
      "\tspeed: 0.0246s/iter; left time: 44.8585s\n",
      "\titers: 400, epoch: 4 | loss: 0.1832275\n",
      "\tspeed: 0.0247s/iter; left time: 42.5947s\n",
      "\titers: 500, epoch: 4 | loss: 0.2185615\n",
      "\tspeed: 0.0262s/iter; left time: 42.5699s\n",
      "\titers: 600, epoch: 4 | loss: 0.1075266\n",
      "\tspeed: 0.0270s/iter; left time: 41.1325s\n",
      "\titers: 700, epoch: 4 | loss: 0.1197308\n",
      "\tspeed: 0.0255s/iter; left time: 36.2436s\n",
      "Epoch: 4 cost time: 18.12224268913269\n",
      "Epoch: 4, Steps: 707 | Train Loss: 0.1696726 Vali Loss: 0.3089542 Test Loss: 0.2398634\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1262471\n",
      "\tspeed: 0.0529s/iter; left time: 69.5015s\n",
      "\titers: 200, epoch: 5 | loss: 0.1710974\n",
      "\tspeed: 0.0244s/iter; left time: 29.6961s\n",
      "\titers: 300, epoch: 5 | loss: 0.1221268\n",
      "\tspeed: 0.0256s/iter; left time: 28.5178s\n",
      "\titers: 400, epoch: 5 | loss: 0.1425094\n",
      "\tspeed: 0.0240s/iter; left time: 24.3903s\n",
      "\titers: 500, epoch: 5 | loss: 0.1597150\n",
      "\tspeed: 0.0235s/iter; left time: 21.4926s\n",
      "\titers: 600, epoch: 5 | loss: 0.1187080\n",
      "\tspeed: 0.0241s/iter; left time: 19.6008s\n",
      "\titers: 700, epoch: 5 | loss: 0.1614824\n",
      "\tspeed: 0.0244s/iter; left time: 17.4462s\n",
      "Epoch: 5 cost time: 17.260797262191772\n",
      "Epoch: 5, Steps: 707 | Train Loss: 0.1606578 Vali Loss: 0.3172571 Test Loss: 0.2420775\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "Test cost time: 1.7372s\n",
      "test shape: (192, 32, 6, 1) (192, 32, 6, 1)\n",
      "test shape: (6144, 6, 1) (6144, 6, 1)\n",
      "mse:0.23908965289592743, mae:0.3309538662433624\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1637.232177734375\n",
      "MAE:  27.386857986450195\n",
      "RMSE: 40.46272659301758\n",
      "MAPE: 0.3898947536945343\n",
      "MSPE: 0.8209624886512756\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24491\n",
      "[DEBUG] Original dataset length: 24491\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22641\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3447\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "\titers: 100, epoch: 1 | loss: 0.2430533\n",
      "\tspeed: 0.0260s/iter; left time: 107.8957s\n",
      "\titers: 200, epoch: 1 | loss: 0.1424895\n",
      "\tspeed: 0.0243s/iter; left time: 98.0450s\n",
      "\titers: 300, epoch: 1 | loss: 0.2473363\n",
      "\tspeed: 0.0246s/iter; left time: 97.1037s\n",
      "\titers: 400, epoch: 1 | loss: 0.2519385\n",
      "\tspeed: 0.0242s/iter; left time: 92.9891s\n",
      "\titers: 500, epoch: 1 | loss: 0.2512153\n",
      "\tspeed: 0.0243s/iter; left time: 90.7827s\n",
      "\titers: 600, epoch: 1 | loss: 0.1901112\n",
      "\tspeed: 0.0256s/iter; left time: 93.2156s\n",
      "\titers: 700, epoch: 1 | loss: 0.1946077\n",
      "\tspeed: 0.0271s/iter; left time: 95.9216s\n",
      "Epoch: 1 cost time: 17.785075664520264\n",
      "Epoch: 1, Steps: 707 | Train Loss: 0.2758938 Vali Loss: 0.3558323 Test Loss: 0.2794919\n",
      "Validation loss decreased (inf --> 0.355832).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2309200\n",
      "\tspeed: 0.0540s/iter; left time: 185.5004s\n",
      "\titers: 200, epoch: 2 | loss: 0.1952427\n",
      "\tspeed: 0.0247s/iter; left time: 82.4404s\n",
      "\titers: 300, epoch: 2 | loss: 0.2590996\n",
      "\tspeed: 0.0275s/iter; left time: 88.8469s\n",
      "\titers: 400, epoch: 2 | loss: 0.2715459\n",
      "\tspeed: 0.0257s/iter; left time: 80.4603s\n",
      "\titers: 500, epoch: 2 | loss: 0.2971887\n",
      "\tspeed: 0.0260s/iter; left time: 78.7946s\n",
      "\titers: 600, epoch: 2 | loss: 0.2728703\n",
      "\tspeed: 0.0258s/iter; left time: 75.8717s\n",
      "\titers: 700, epoch: 2 | loss: 0.2956288\n",
      "\tspeed: 0.0243s/iter; left time: 68.9709s\n",
      "Epoch: 2 cost time: 18.021286249160767\n",
      "Epoch: 2, Steps: 707 | Train Loss: 0.2139078 Vali Loss: 0.3153602 Test Loss: 0.2464489\n",
      "Validation loss decreased (0.355832 --> 0.315360).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1681241\n",
      "\tspeed: 0.0532s/iter; left time: 145.2683s\n",
      "\titers: 200, epoch: 3 | loss: 0.1768613\n",
      "\tspeed: 0.0253s/iter; left time: 66.4574s\n",
      "\titers: 300, epoch: 3 | loss: 0.1515778\n",
      "\tspeed: 0.0241s/iter; left time: 60.8544s\n",
      "\titers: 400, epoch: 3 | loss: 0.1265035\n",
      "\tspeed: 0.0239s/iter; left time: 58.0695s\n",
      "\titers: 500, epoch: 3 | loss: 0.1581320\n",
      "\tspeed: 0.0241s/iter; left time: 56.2217s\n",
      "\titers: 600, epoch: 3 | loss: 0.1567674\n",
      "\tspeed: 0.0242s/iter; left time: 54.0407s\n",
      "\titers: 700, epoch: 3 | loss: 0.3244480\n",
      "\tspeed: 0.0241s/iter; left time: 51.3176s\n",
      "Epoch: 3 cost time: 17.184513568878174\n",
      "Epoch: 3, Steps: 707 | Train Loss: 0.1864818 Vali Loss: 0.3070256 Test Loss: 0.2450765\n",
      "Validation loss decreased (0.315360 --> 0.307026).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2119829\n",
      "\tspeed: 0.0555s/iter; left time: 112.1403s\n",
      "\titers: 200, epoch: 4 | loss: 0.1771836\n",
      "\tspeed: 0.0238s/iter; left time: 45.6923s\n",
      "\titers: 300, epoch: 4 | loss: 0.2999492\n",
      "\tspeed: 0.0241s/iter; left time: 43.8770s\n",
      "\titers: 400, epoch: 4 | loss: 0.3825095\n",
      "\tspeed: 0.0244s/iter; left time: 42.0087s\n",
      "\titers: 500, epoch: 4 | loss: 0.1672008\n",
      "\tspeed: 0.0240s/iter; left time: 38.9851s\n",
      "\titers: 600, epoch: 4 | loss: 0.1223279\n",
      "\tspeed: 0.0275s/iter; left time: 41.9001s\n",
      "\titers: 700, epoch: 4 | loss: 0.1807597\n",
      "\tspeed: 0.0254s/iter; left time: 36.0739s\n",
      "Epoch: 4 cost time: 17.5449275970459\n",
      "Epoch: 4, Steps: 707 | Train Loss: 0.1721883 Vali Loss: 0.3172728 Test Loss: 0.2490414\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1500980\n",
      "\tspeed: 0.0524s/iter; left time: 68.9156s\n",
      "\titers: 200, epoch: 5 | loss: 0.1349578\n",
      "\tspeed: 0.0253s/iter; left time: 30.7526s\n",
      "\titers: 300, epoch: 5 | loss: 0.1126065\n",
      "\tspeed: 0.0251s/iter; left time: 28.0206s\n",
      "\titers: 400, epoch: 5 | loss: 0.1088059\n",
      "\tspeed: 0.0276s/iter; left time: 28.0204s\n",
      "\titers: 500, epoch: 5 | loss: 0.1740093\n",
      "\tspeed: 0.0247s/iter; left time: 22.6394s\n",
      "\titers: 600, epoch: 5 | loss: 0.1469314\n",
      "\tspeed: 0.0236s/iter; left time: 19.2114s\n",
      "\titers: 700, epoch: 5 | loss: 0.3842281\n",
      "\tspeed: 0.0240s/iter; left time: 17.1677s\n",
      "Epoch: 5 cost time: 17.738157510757446\n",
      "Epoch: 5, Steps: 707 | Train Loss: 0.1623764 Vali Loss: 0.3075360 Test Loss: 0.2486005\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1886922\n",
      "\tspeed: 0.0530s/iter; left time: 32.2079s\n",
      "\titers: 200, epoch: 6 | loss: 0.2606882\n",
      "\tspeed: 0.0271s/iter; left time: 13.7700s\n",
      "\titers: 300, epoch: 6 | loss: 0.1584214\n",
      "\tspeed: 0.0247s/iter; left time: 10.0838s\n",
      "\titers: 400, epoch: 6 | loss: 0.1660562\n",
      "\tspeed: 0.0253s/iter; left time: 7.7895s\n",
      "\titers: 500, epoch: 6 | loss: 0.1014401\n",
      "\tspeed: 0.0267s/iter; left time: 5.5581s\n",
      "\titers: 600, epoch: 6 | loss: 0.1193060\n",
      "\tspeed: 0.0256s/iter; left time: 2.7686s\n",
      "\titers: 700, epoch: 6 | loss: 0.1573971\n",
      "\tspeed: 0.0245s/iter; left time: 0.1963s\n",
      "Epoch: 6 cost time: 18.011592149734497\n",
      "Epoch: 6, Steps: 707 | Train Loss: 0.1571155 Vali Loss: 0.3113485 Test Loss: 0.2481628\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "Test cost time: 1.6594s\n",
      "test shape: (192, 32, 6, 1) (192, 32, 6, 1)\n",
      "test shape: (6144, 6, 1) (6144, 6, 1)\n",
      "mse:0.2454405426979065, mae:0.33689382672309875\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1680.7216796875\n",
      "MAE:  27.87839698791504\n",
      "RMSE: 40.996604919433594\n",
      "MAPE: 0.39872029423713684\n",
      "MSPE: 0.8084724545478821\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24491\n",
      "[DEBUG] Original dataset length: 24491\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22641\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3447\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "\titers: 100, epoch: 1 | loss: 0.1970214\n",
      "\tspeed: 0.0248s/iter; left time: 102.5401s\n",
      "\titers: 200, epoch: 1 | loss: 0.4251861\n",
      "\tspeed: 0.0243s/iter; left time: 98.4007s\n",
      "\titers: 300, epoch: 1 | loss: 0.1874111\n",
      "\tspeed: 0.0250s/iter; left time: 98.7128s\n",
      "\titers: 400, epoch: 1 | loss: 0.1989802\n",
      "\tspeed: 0.0237s/iter; left time: 90.9912s\n",
      "\titers: 500, epoch: 1 | loss: 0.3984332\n",
      "\tspeed: 0.0274s/iter; left time: 102.5194s\n",
      "\titers: 600, epoch: 1 | loss: 0.2959691\n",
      "\tspeed: 0.0248s/iter; left time: 90.4085s\n",
      "\titers: 700, epoch: 1 | loss: 0.2260772\n",
      "\tspeed: 0.0249s/iter; left time: 88.2073s\n",
      "Epoch: 1 cost time: 17.693063497543335\n",
      "Epoch: 1, Steps: 707 | Train Loss: 0.2742888 Vali Loss: 0.3475755 Test Loss: 0.2840088\n",
      "Validation loss decreased (inf --> 0.347575).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1092309\n",
      "\tspeed: 0.0559s/iter; left time: 191.9771s\n",
      "\titers: 200, epoch: 2 | loss: 0.1888814\n",
      "\tspeed: 0.0261s/iter; left time: 87.1144s\n",
      "\titers: 300, epoch: 2 | loss: 0.1963721\n",
      "\tspeed: 0.0259s/iter; left time: 83.6764s\n",
      "\titers: 400, epoch: 2 | loss: 0.2408742\n",
      "\tspeed: 0.0240s/iter; left time: 75.1243s\n",
      "\titers: 500, epoch: 2 | loss: 0.1968239\n",
      "\tspeed: 0.0245s/iter; left time: 74.4447s\n",
      "\titers: 600, epoch: 2 | loss: 0.1582304\n",
      "\tspeed: 0.0246s/iter; left time: 72.2853s\n",
      "\titers: 700, epoch: 2 | loss: 0.2588986\n",
      "\tspeed: 0.0244s/iter; left time: 69.0997s\n",
      "Epoch: 2 cost time: 17.77568507194519\n",
      "Epoch: 2, Steps: 707 | Train Loss: 0.2121581 Vali Loss: 0.3269618 Test Loss: 0.2509369\n",
      "Validation loss decreased (0.347575 --> 0.326962).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1274087\n",
      "\tspeed: 0.0568s/iter; left time: 154.8916s\n",
      "\titers: 200, epoch: 3 | loss: 0.2098148\n",
      "\tspeed: 0.0237s/iter; left time: 62.3291s\n",
      "\titers: 300, epoch: 3 | loss: 0.1968028\n",
      "\tspeed: 0.0246s/iter; left time: 62.2476s\n",
      "\titers: 400, epoch: 3 | loss: 0.1446634\n",
      "\tspeed: 0.0234s/iter; left time: 56.8582s\n",
      "\titers: 500, epoch: 3 | loss: 0.2836033\n",
      "\tspeed: 0.0251s/iter; left time: 58.4894s\n",
      "\titers: 600, epoch: 3 | loss: 0.1563994\n",
      "\tspeed: 0.0257s/iter; left time: 57.3008s\n",
      "\titers: 700, epoch: 3 | loss: 0.1906391\n",
      "\tspeed: 0.0254s/iter; left time: 54.0501s\n",
      "Epoch: 3 cost time: 17.598198652267456\n",
      "Epoch: 3, Steps: 707 | Train Loss: 0.1850122 Vali Loss: 0.3126726 Test Loss: 0.2398090\n",
      "Validation loss decreased (0.326962 --> 0.312673).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1490543\n",
      "\tspeed: 0.0518s/iter; left time: 104.6908s\n",
      "\titers: 200, epoch: 4 | loss: 0.1509530\n",
      "\tspeed: 0.0246s/iter; left time: 47.3097s\n",
      "\titers: 300, epoch: 4 | loss: 0.1538040\n",
      "\tspeed: 0.0243s/iter; left time: 44.2209s\n",
      "\titers: 400, epoch: 4 | loss: 0.1713613\n",
      "\tspeed: 0.0257s/iter; left time: 44.2619s\n",
      "\titers: 500, epoch: 4 | loss: 0.1697745\n",
      "\tspeed: 0.0247s/iter; left time: 40.1355s\n",
      "\titers: 600, epoch: 4 | loss: 0.1506352\n",
      "\tspeed: 0.0246s/iter; left time: 37.3740s\n",
      "\titers: 700, epoch: 4 | loss: 0.1572773\n",
      "\tspeed: 0.0236s/iter; left time: 33.5079s\n",
      "Epoch: 4 cost time: 17.25846791267395\n",
      "Epoch: 4, Steps: 707 | Train Loss: 0.1704296 Vali Loss: 0.3124579 Test Loss: 0.2461192\n",
      "Validation loss decreased (0.312673 --> 0.312458).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2018645\n",
      "\tspeed: 0.0561s/iter; left time: 73.7496s\n",
      "\titers: 200, epoch: 5 | loss: 0.1390464\n",
      "\tspeed: 0.0267s/iter; left time: 32.4759s\n",
      "\titers: 300, epoch: 5 | loss: 0.1701632\n",
      "\tspeed: 0.0253s/iter; left time: 28.2065s\n",
      "\titers: 400, epoch: 5 | loss: 0.1334925\n",
      "\tspeed: 0.0252s/iter; left time: 25.5940s\n",
      "\titers: 500, epoch: 5 | loss: 0.1128838\n",
      "\tspeed: 0.0243s/iter; left time: 22.2295s\n",
      "\titers: 600, epoch: 5 | loss: 0.1860691\n",
      "\tspeed: 0.0244s/iter; left time: 19.9048s\n",
      "\titers: 700, epoch: 5 | loss: 0.1570954\n",
      "\tspeed: 0.0246s/iter; left time: 17.5722s\n",
      "Epoch: 5 cost time: 17.84394860267639\n",
      "Epoch: 5, Steps: 707 | Train Loss: 0.1614289 Vali Loss: 0.3191210 Test Loss: 0.2433257\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2862533\n",
      "\tspeed: 0.0573s/iter; left time: 34.8211s\n",
      "\titers: 200, epoch: 6 | loss: 0.1610891\n",
      "\tspeed: 0.0250s/iter; left time: 12.7114s\n",
      "\titers: 300, epoch: 6 | loss: 0.1552901\n",
      "\tspeed: 0.0249s/iter; left time: 10.1724s\n",
      "\titers: 400, epoch: 6 | loss: 0.1426588\n",
      "\tspeed: 0.0246s/iter; left time: 7.5795s\n",
      "\titers: 500, epoch: 6 | loss: 0.1016404\n",
      "\tspeed: 0.0249s/iter; left time: 5.1889s\n",
      "\titers: 600, epoch: 6 | loss: 0.1821592\n",
      "\tspeed: 0.0263s/iter; left time: 2.8364s\n",
      "\titers: 700, epoch: 6 | loss: 0.1188483\n",
      "\tspeed: 0.0245s/iter; left time: 0.1960s\n",
      "Epoch: 6 cost time: 17.817920923233032\n",
      "Epoch: 6, Steps: 707 | Train Loss: 0.1564801 Vali Loss: 0.3141914 Test Loss: 0.2393989\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "Test cost time: 1.7597s\n",
      "test shape: (192, 32, 6, 1) (192, 32, 6, 1)\n",
      "test shape: (6144, 6, 1) (6144, 6, 1)\n",
      "mse:0.24619068205356598, mae:0.32886335253715515\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1685.8585205078125\n",
      "MAE:  27.213865280151367\n",
      "RMSE: 41.059207916259766\n",
      "MAPE: 0.33019569516181946\n",
      "MSPE: 0.5152744650840759\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24491\n",
      "[DEBUG] Original dataset length: 24491\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22641\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3447\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "\titers: 100, epoch: 1 | loss: 0.2624912\n",
      "\tspeed: 0.0247s/iter; left time: 102.1436s\n",
      "\titers: 200, epoch: 1 | loss: 0.2369553\n",
      "\tspeed: 0.0237s/iter; left time: 95.7844s\n",
      "\titers: 300, epoch: 1 | loss: 0.2169856\n",
      "\tspeed: 0.0269s/iter; left time: 106.0649s\n",
      "\titers: 400, epoch: 1 | loss: 0.3148388\n",
      "\tspeed: 0.0247s/iter; left time: 94.9850s\n",
      "\titers: 500, epoch: 1 | loss: 0.3694952\n",
      "\tspeed: 0.0245s/iter; left time: 91.7928s\n",
      "\titers: 600, epoch: 1 | loss: 0.2361464\n",
      "\tspeed: 0.0243s/iter; left time: 88.4088s\n",
      "\titers: 700, epoch: 1 | loss: 0.2035276\n",
      "\tspeed: 0.0239s/iter; left time: 84.7495s\n",
      "Epoch: 1 cost time: 17.432974576950073\n",
      "Epoch: 1, Steps: 707 | Train Loss: 0.2721716 Vali Loss: 0.3411190 Test Loss: 0.2728106\n",
      "Validation loss decreased (inf --> 0.341119).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2627454\n",
      "\tspeed: 0.0554s/iter; left time: 190.4766s\n",
      "\titers: 200, epoch: 2 | loss: 0.2151890\n",
      "\tspeed: 0.0247s/iter; left time: 82.5313s\n",
      "\titers: 300, epoch: 2 | loss: 0.1368666\n",
      "\tspeed: 0.0238s/iter; left time: 76.9915s\n",
      "\titers: 400, epoch: 2 | loss: 0.1597940\n",
      "\tspeed: 0.0240s/iter; left time: 75.1395s\n",
      "\titers: 500, epoch: 2 | loss: 0.1648803\n",
      "\tspeed: 0.0240s/iter; left time: 72.7135s\n",
      "\titers: 600, epoch: 2 | loss: 0.1642832\n",
      "\tspeed: 0.0242s/iter; left time: 71.1399s\n",
      "\titers: 700, epoch: 2 | loss: 0.2267364\n",
      "\tspeed: 0.0258s/iter; left time: 73.2197s\n",
      "Epoch: 2 cost time: 17.420536994934082\n",
      "Epoch: 2, Steps: 707 | Train Loss: 0.2112080 Vali Loss: 0.3273308 Test Loss: 0.2597895\n",
      "Validation loss decreased (0.341119 --> 0.327331).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1678623\n",
      "\tspeed: 0.0525s/iter; left time: 143.2082s\n",
      "\titers: 200, epoch: 3 | loss: 0.1520821\n",
      "\tspeed: 0.0240s/iter; left time: 63.2254s\n",
      "\titers: 300, epoch: 3 | loss: 0.1390667\n",
      "\tspeed: 0.0239s/iter; left time: 60.3851s\n",
      "\titers: 400, epoch: 3 | loss: 0.1898718\n",
      "\tspeed: 0.0236s/iter; left time: 57.3212s\n",
      "\titers: 500, epoch: 3 | loss: 0.1458736\n",
      "\tspeed: 0.0273s/iter; left time: 63.5776s\n",
      "\titers: 600, epoch: 3 | loss: 0.1588878\n",
      "\tspeed: 0.0243s/iter; left time: 54.1518s\n",
      "\titers: 700, epoch: 3 | loss: 0.1248506\n",
      "\tspeed: 0.0239s/iter; left time: 50.9163s\n",
      "Epoch: 3 cost time: 17.257029056549072\n",
      "Epoch: 3, Steps: 707 | Train Loss: 0.1826997 Vali Loss: 0.3161964 Test Loss: 0.2429049\n",
      "Validation loss decreased (0.327331 --> 0.316196).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1300473\n",
      "\tspeed: 0.0538s/iter; left time: 108.7439s\n",
      "\titers: 200, epoch: 4 | loss: 0.1548194\n",
      "\tspeed: 0.0247s/iter; left time: 47.4614s\n",
      "\titers: 300, epoch: 4 | loss: 0.1670357\n",
      "\tspeed: 0.0281s/iter; left time: 51.1900s\n",
      "\titers: 400, epoch: 4 | loss: 0.2520872\n",
      "\tspeed: 0.0245s/iter; left time: 42.2644s\n",
      "\titers: 500, epoch: 4 | loss: 0.1647621\n",
      "\tspeed: 0.0241s/iter; left time: 39.1399s\n",
      "\titers: 600, epoch: 4 | loss: 0.1650347\n",
      "\tspeed: 0.0239s/iter; left time: 36.3445s\n",
      "\titers: 700, epoch: 4 | loss: 0.3114057\n",
      "\tspeed: 0.0250s/iter; left time: 35.6043s\n",
      "Epoch: 4 cost time: 17.64459538459778\n",
      "Epoch: 4, Steps: 707 | Train Loss: 0.1690125 Vali Loss: 0.3120865 Test Loss: 0.2389791\n",
      "Validation loss decreased (0.316196 --> 0.312086).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1810688\n",
      "\tspeed: 0.0559s/iter; left time: 73.4740s\n",
      "\titers: 200, epoch: 5 | loss: 0.1316139\n",
      "\tspeed: 0.0238s/iter; left time: 28.9762s\n",
      "\titers: 300, epoch: 5 | loss: 0.1087866\n",
      "\tspeed: 0.0237s/iter; left time: 26.4241s\n",
      "\titers: 400, epoch: 5 | loss: 0.1764771\n",
      "\tspeed: 0.0231s/iter; left time: 23.4650s\n",
      "\titers: 500, epoch: 5 | loss: 0.1000698\n",
      "\tspeed: 0.0239s/iter; left time: 21.9102s\n",
      "\titers: 600, epoch: 5 | loss: 0.1314719\n",
      "\tspeed: 0.0235s/iter; left time: 19.1204s\n",
      "\titers: 700, epoch: 5 | loss: 0.1175073\n",
      "\tspeed: 0.0285s/iter; left time: 20.3848s\n",
      "Epoch: 5 cost time: 17.420719623565674\n",
      "Epoch: 5, Steps: 707 | Train Loss: 0.1604316 Vali Loss: 0.3101284 Test Loss: 0.2367099\n",
      "Validation loss decreased (0.312086 --> 0.310128).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1360691\n",
      "\tspeed: 0.0548s/iter; left time: 33.3245s\n",
      "\titers: 200, epoch: 6 | loss: 0.1458851\n",
      "\tspeed: 0.0245s/iter; left time: 12.4490s\n",
      "\titers: 300, epoch: 6 | loss: 0.1260959\n",
      "\tspeed: 0.0241s/iter; left time: 9.8445s\n",
      "\titers: 400, epoch: 6 | loss: 0.1483242\n",
      "\tspeed: 0.0249s/iter; left time: 7.6841s\n",
      "\titers: 500, epoch: 6 | loss: 0.1880873\n",
      "\tspeed: 0.0255s/iter; left time: 5.3076s\n",
      "\titers: 600, epoch: 6 | loss: 0.1582057\n",
      "\tspeed: 0.0241s/iter; left time: 2.6006s\n",
      "\titers: 700, epoch: 6 | loss: 0.1079631\n",
      "\tspeed: 0.0241s/iter; left time: 0.1928s\n",
      "Epoch: 6 cost time: 17.429052352905273\n",
      "Epoch: 6, Steps: 707 | Train Loss: 0.1559147 Vali Loss: 0.3082407 Test Loss: 0.2395293\n",
      "Validation loss decreased (0.310128 --> 0.308241).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "Test cost time: 1.7133s\n",
      "test shape: (192, 32, 6, 1) (192, 32, 6, 1)\n",
      "test shape: (6144, 6, 1) (6144, 6, 1)\n",
      "mse:0.23957432806491852, mae:0.3197039067745209\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1640.55126953125\n",
      "MAE:  26.45590591430664\n",
      "RMSE: 40.503719329833984\n",
      "MAPE: 0.31858599185943604\n",
      "MSPE: 0.47728538513183594\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24491\n",
      "[DEBUG] Original dataset length: 24491\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22641\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3447\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "\titers: 100, epoch: 1 | loss: 0.4347847\n",
      "\tspeed: 0.0255s/iter; left time: 105.7032s\n",
      "\titers: 200, epoch: 1 | loss: 0.2799309\n",
      "\tspeed: 0.0263s/iter; left time: 106.3076s\n",
      "\titers: 300, epoch: 1 | loss: 0.1381925\n",
      "\tspeed: 0.0241s/iter; left time: 94.8367s\n",
      "\titers: 400, epoch: 1 | loss: 0.2589496\n",
      "\tspeed: 0.0239s/iter; left time: 91.8054s\n",
      "\titers: 500, epoch: 1 | loss: 0.1651228\n",
      "\tspeed: 0.0257s/iter; left time: 96.0346s\n",
      "\titers: 600, epoch: 1 | loss: 0.1733509\n",
      "\tspeed: 0.0245s/iter; left time: 89.2646s\n",
      "\titers: 700, epoch: 1 | loss: 0.2441595\n",
      "\tspeed: 0.0245s/iter; left time: 86.8490s\n",
      "Epoch: 1 cost time: 17.64698362350464\n",
      "Epoch: 1, Steps: 707 | Train Loss: 0.2739784 Vali Loss: 0.3525349 Test Loss: 0.2802344\n",
      "Validation loss decreased (inf --> 0.352535).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1569619\n",
      "\tspeed: 0.0571s/iter; left time: 196.2650s\n",
      "\titers: 200, epoch: 2 | loss: 0.2432044\n",
      "\tspeed: 0.0240s/iter; left time: 80.0048s\n",
      "\titers: 300, epoch: 2 | loss: 0.1202563\n",
      "\tspeed: 0.0241s/iter; left time: 77.9889s\n",
      "\titers: 400, epoch: 2 | loss: 0.1763499\n",
      "\tspeed: 0.0240s/iter; left time: 75.4032s\n",
      "\titers: 500, epoch: 2 | loss: 0.1657115\n",
      "\tspeed: 0.0243s/iter; left time: 73.6679s\n",
      "\titers: 600, epoch: 2 | loss: 0.2131277\n",
      "\tspeed: 0.0255s/iter; left time: 74.8286s\n",
      "\titers: 700, epoch: 2 | loss: 0.1473228\n",
      "\tspeed: 0.0254s/iter; left time: 72.0566s\n",
      "Epoch: 2 cost time: 17.419663906097412\n",
      "Epoch: 2, Steps: 707 | Train Loss: 0.2136463 Vali Loss: 0.3185003 Test Loss: 0.2460039\n",
      "Validation loss decreased (0.352535 --> 0.318500).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2504796\n",
      "\tspeed: 0.0530s/iter; left time: 144.6367s\n",
      "\titers: 200, epoch: 3 | loss: 0.1585726\n",
      "\tspeed: 0.0236s/iter; left time: 61.9374s\n",
      "\titers: 300, epoch: 3 | loss: 0.1674569\n",
      "\tspeed: 0.0253s/iter; left time: 64.0779s\n",
      "\titers: 400, epoch: 3 | loss: 0.1519075\n",
      "\tspeed: 0.0261s/iter; left time: 63.4324s\n",
      "\titers: 500, epoch: 3 | loss: 0.1065861\n",
      "\tspeed: 0.0250s/iter; left time: 58.1165s\n",
      "\titers: 600, epoch: 3 | loss: 0.1400174\n",
      "\tspeed: 0.0250s/iter; left time: 55.7403s\n",
      "\titers: 700, epoch: 3 | loss: 0.2040760\n",
      "\tspeed: 0.0245s/iter; left time: 52.1000s\n",
      "Epoch: 3 cost time: 17.56024694442749\n",
      "Epoch: 3, Steps: 707 | Train Loss: 0.1838965 Vali Loss: 0.3228337 Test Loss: 0.2455083\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3292779\n",
      "\tspeed: 0.0531s/iter; left time: 107.3606s\n",
      "\titers: 200, epoch: 4 | loss: 0.1572879\n",
      "\tspeed: 0.0273s/iter; left time: 52.4479s\n",
      "\titers: 300, epoch: 4 | loss: 0.1893162\n",
      "\tspeed: 0.0269s/iter; left time: 48.9792s\n",
      "\titers: 400, epoch: 4 | loss: 0.1697016\n",
      "\tspeed: 0.0322s/iter; left time: 55.5004s\n",
      "\titers: 500, epoch: 4 | loss: 0.1870130\n",
      "\tspeed: 0.0272s/iter; left time: 44.1895s\n",
      "\titers: 600, epoch: 4 | loss: 0.1696181\n",
      "\tspeed: 0.0259s/iter; left time: 39.4652s\n",
      "\titers: 700, epoch: 4 | loss: 0.2477964\n",
      "\tspeed: 0.0270s/iter; left time: 38.4534s\n",
      "Epoch: 4 cost time: 19.42985439300537\n",
      "Epoch: 4, Steps: 707 | Train Loss: 0.1699004 Vali Loss: 0.3286503 Test Loss: 0.2577085\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2063034\n",
      "\tspeed: 0.0525s/iter; left time: 69.0373s\n",
      "\titers: 200, epoch: 5 | loss: 0.1278777\n",
      "\tspeed: 0.0230s/iter; left time: 27.9401s\n",
      "\titers: 300, epoch: 5 | loss: 0.1492589\n",
      "\tspeed: 0.0234s/iter; left time: 26.0460s\n",
      "\titers: 400, epoch: 5 | loss: 0.1562801\n",
      "\tspeed: 0.0236s/iter; left time: 23.9998s\n",
      "\titers: 500, epoch: 5 | loss: 0.1800235\n",
      "\tspeed: 0.0265s/iter; left time: 24.2418s\n",
      "\titers: 600, epoch: 5 | loss: 0.2775350\n",
      "\tspeed: 0.0246s/iter; left time: 20.0873s\n",
      "\titers: 700, epoch: 5 | loss: 0.2317110\n",
      "\tspeed: 0.0244s/iter; left time: 17.4782s\n",
      "Epoch: 5 cost time: 17.156316995620728\n",
      "Epoch: 5, Steps: 707 | Train Loss: 0.1625201 Vali Loss: 0.3087347 Test Loss: 0.2455607\n",
      "Validation loss decreased (0.318500 --> 0.308735).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1463667\n",
      "\tspeed: 0.0544s/iter; left time: 33.1012s\n",
      "\titers: 200, epoch: 6 | loss: 0.1767887\n",
      "\tspeed: 0.0248s/iter; left time: 12.5852s\n",
      "\titers: 300, epoch: 6 | loss: 0.3152606\n",
      "\tspeed: 0.0255s/iter; left time: 10.3891s\n",
      "\titers: 400, epoch: 6 | loss: 0.2291121\n",
      "\tspeed: 0.0245s/iter; left time: 7.5596s\n",
      "\titers: 500, epoch: 6 | loss: 0.0999497\n",
      "\tspeed: 0.0237s/iter; left time: 4.9205s\n",
      "\titers: 600, epoch: 6 | loss: 0.3937173\n",
      "\tspeed: 0.0241s/iter; left time: 2.5978s\n",
      "\titers: 700, epoch: 6 | loss: 0.0919181\n",
      "\tspeed: 0.0230s/iter; left time: 0.1841s\n",
      "Epoch: 6 cost time: 17.248618602752686\n",
      "Epoch: 6, Steps: 707 | Train Loss: 0.1562946 Vali Loss: 0.3124709 Test Loss: 0.2443756\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "Test cost time: 1.8130s\n",
      "test shape: (192, 32, 6, 1) (192, 32, 6, 1)\n",
      "test shape: (6144, 6, 1) (6144, 6, 1)\n",
      "mse:0.24426259100437164, mae:0.3260432779788971\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1672.6552734375\n",
      "MAE:  26.980499267578125\n",
      "RMSE: 40.898109436035156\n",
      "MAPE: 0.34664440155029297\n",
      "MSPE: 0.5899494886398315\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24491\n",
      "[DEBUG] Original dataset length: 24491\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22641\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3447\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "\titers: 100, epoch: 1 | loss: 0.4444768\n",
      "\tspeed: 0.0242s/iter; left time: 100.3790s\n",
      "\titers: 200, epoch: 1 | loss: 0.1867145\n",
      "\tspeed: 0.0225s/iter; left time: 91.0537s\n",
      "\titers: 300, epoch: 1 | loss: 0.1943837\n",
      "\tspeed: 0.0242s/iter; left time: 95.5145s\n",
      "\titers: 400, epoch: 1 | loss: 0.2124525\n",
      "\tspeed: 0.0246s/iter; left time: 94.4245s\n",
      "\titers: 500, epoch: 1 | loss: 0.1608633\n",
      "\tspeed: 0.0239s/iter; left time: 89.3569s\n",
      "\titers: 600, epoch: 1 | loss: 0.1335092\n",
      "\tspeed: 0.0272s/iter; left time: 98.9934s\n",
      "\titers: 700, epoch: 1 | loss: 0.2394415\n",
      "\tspeed: 0.0245s/iter; left time: 86.8625s\n",
      "Epoch: 1 cost time: 17.29081630706787\n",
      "Epoch: 1, Steps: 707 | Train Loss: 0.2734672 Vali Loss: 0.3392263 Test Loss: 0.2619780\n",
      "Validation loss decreased (inf --> 0.339226).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2403276\n",
      "\tspeed: 0.0524s/iter; left time: 180.0361s\n",
      "\titers: 200, epoch: 2 | loss: 0.1553921\n",
      "\tspeed: 0.0232s/iter; left time: 77.3340s\n",
      "\titers: 300, epoch: 2 | loss: 0.2274613\n",
      "\tspeed: 0.0232s/iter; left time: 74.9185s\n",
      "\titers: 400, epoch: 2 | loss: 0.2178148\n",
      "\tspeed: 0.0256s/iter; left time: 80.3302s\n",
      "\titers: 500, epoch: 2 | loss: 0.2029242\n",
      "\tspeed: 0.0240s/iter; left time: 72.8762s\n",
      "\titers: 600, epoch: 2 | loss: 0.1173687\n",
      "\tspeed: 0.0251s/iter; left time: 73.6310s\n",
      "\titers: 700, epoch: 2 | loss: 0.3229123\n",
      "\tspeed: 0.0234s/iter; left time: 66.2569s\n",
      "Epoch: 2 cost time: 17.010798454284668\n",
      "Epoch: 2, Steps: 707 | Train Loss: 0.2123449 Vali Loss: 0.3260555 Test Loss: 0.2543950\n",
      "Validation loss decreased (0.339226 --> 0.326055).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1304518\n",
      "\tspeed: 0.0530s/iter; left time: 144.6212s\n",
      "\titers: 200, epoch: 3 | loss: 0.1404077\n",
      "\tspeed: 0.0266s/iter; left time: 69.8259s\n",
      "\titers: 300, epoch: 3 | loss: 0.1044299\n",
      "\tspeed: 0.0233s/iter; left time: 58.8345s\n",
      "\titers: 400, epoch: 3 | loss: 0.2172906\n",
      "\tspeed: 0.0237s/iter; left time: 57.6385s\n",
      "\titers: 500, epoch: 3 | loss: 0.1820336\n",
      "\tspeed: 0.0234s/iter; left time: 54.5105s\n",
      "\titers: 600, epoch: 3 | loss: 0.1431874\n",
      "\tspeed: 0.0234s/iter; left time: 52.2220s\n",
      "\titers: 700, epoch: 3 | loss: 0.2323357\n",
      "\tspeed: 0.0232s/iter; left time: 49.3209s\n",
      "Epoch: 3 cost time: 16.880901098251343\n",
      "Epoch: 3, Steps: 707 | Train Loss: 0.1836145 Vali Loss: 0.3317371 Test Loss: 0.2705674\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1609260\n",
      "\tspeed: 0.0547s/iter; left time: 110.6088s\n",
      "\titers: 200, epoch: 4 | loss: 0.1281888\n",
      "\tspeed: 0.0232s/iter; left time: 44.6697s\n",
      "\titers: 300, epoch: 4 | loss: 0.2045579\n",
      "\tspeed: 0.0233s/iter; left time: 42.3739s\n",
      "\titers: 400, epoch: 4 | loss: 0.1887595\n",
      "\tspeed: 0.0240s/iter; left time: 41.2490s\n",
      "\titers: 500, epoch: 4 | loss: 0.1701044\n",
      "\tspeed: 0.0241s/iter; left time: 39.1399s\n",
      "\titers: 600, epoch: 4 | loss: 0.1101347\n",
      "\tspeed: 0.0253s/iter; left time: 38.4570s\n",
      "\titers: 700, epoch: 4 | loss: 0.2121885\n",
      "\tspeed: 0.0246s/iter; left time: 35.0052s\n",
      "Epoch: 4 cost time: 17.065297603607178\n",
      "Epoch: 4, Steps: 707 | Train Loss: 0.1701137 Vali Loss: 0.3065315 Test Loss: 0.2452988\n",
      "Validation loss decreased (0.326055 --> 0.306532).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1337014\n",
      "\tspeed: 0.0515s/iter; left time: 67.7698s\n",
      "\titers: 200, epoch: 5 | loss: 0.1256626\n",
      "\tspeed: 0.0238s/iter; left time: 28.9429s\n",
      "\titers: 300, epoch: 5 | loss: 0.2063122\n",
      "\tspeed: 0.0227s/iter; left time: 25.3411s\n",
      "\titers: 400, epoch: 5 | loss: 0.1513298\n",
      "\tspeed: 0.0247s/iter; left time: 25.1048s\n",
      "\titers: 500, epoch: 5 | loss: 0.2019028\n",
      "\tspeed: 0.0247s/iter; left time: 22.5860s\n",
      "\titers: 600, epoch: 5 | loss: 0.0781524\n",
      "\tspeed: 0.0234s/iter; left time: 19.0626s\n",
      "\titers: 700, epoch: 5 | loss: 0.1288430\n",
      "\tspeed: 0.0231s/iter; left time: 16.5461s\n",
      "Epoch: 5 cost time: 16.85559582710266\n",
      "Epoch: 5, Steps: 707 | Train Loss: 0.1610021 Vali Loss: 0.3073981 Test Loss: 0.2417869\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2682326\n",
      "\tspeed: 0.0521s/iter; left time: 31.6622s\n",
      "\titers: 200, epoch: 6 | loss: 0.1734485\n",
      "\tspeed: 0.0256s/iter; left time: 12.9908s\n",
      "\titers: 300, epoch: 6 | loss: 0.1911126\n",
      "\tspeed: 0.0261s/iter; left time: 10.6465s\n",
      "\titers: 400, epoch: 6 | loss: 0.1840685\n",
      "\tspeed: 0.0239s/iter; left time: 7.3568s\n",
      "\titers: 500, epoch: 6 | loss: 0.1722349\n",
      "\tspeed: 0.0233s/iter; left time: 4.8416s\n",
      "\titers: 600, epoch: 6 | loss: 0.2045480\n",
      "\tspeed: 0.0237s/iter; left time: 2.5581s\n",
      "\titers: 700, epoch: 6 | loss: 0.2645633\n",
      "\tspeed: 0.0237s/iter; left time: 0.1900s\n",
      "Epoch: 6 cost time: 17.212225198745728\n",
      "Epoch: 6, Steps: 707 | Train Loss: 0.1559452 Vali Loss: 0.3009671 Test Loss: 0.2388863\n",
      "Validation loss decreased (0.306532 --> 0.300967).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "Test cost time: 1.7911s\n",
      "test shape: (192, 32, 6, 1) (192, 32, 6, 1)\n",
      "test shape: (6144, 6, 1) (6144, 6, 1)\n",
      "mse:0.23904983699321747, mae:0.33136463165283203\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1636.9595947265625\n",
      "MAE:  27.42085075378418\n",
      "RMSE: 40.45935821533203\n",
      "MAPE: 0.3696584701538086\n",
      "MSPE: 0.6598142981529236\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24491\n",
      "[DEBUG] Original dataset length: 24491\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22641\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3447\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "\titers: 100, epoch: 1 | loss: 0.2069304\n",
      "\tspeed: 0.0256s/iter; left time: 105.9648s\n",
      "\titers: 200, epoch: 1 | loss: 0.2207269\n",
      "\tspeed: 0.0259s/iter; left time: 104.5737s\n",
      "\titers: 300, epoch: 1 | loss: 0.1673749\n",
      "\tspeed: 0.0249s/iter; left time: 98.0354s\n",
      "\titers: 400, epoch: 1 | loss: 0.2241232\n",
      "\tspeed: 0.0244s/iter; left time: 93.7241s\n",
      "\titers: 500, epoch: 1 | loss: 0.1215394\n",
      "\tspeed: 0.0247s/iter; left time: 92.4298s\n",
      "\titers: 600, epoch: 1 | loss: 0.1740339\n",
      "\tspeed: 0.0257s/iter; left time: 93.5772s\n",
      "\titers: 700, epoch: 1 | loss: 0.2077230\n",
      "\tspeed: 0.0246s/iter; left time: 87.1827s\n",
      "Epoch: 1 cost time: 17.73860454559326\n",
      "Epoch: 1, Steps: 707 | Train Loss: 0.2760056 Vali Loss: 0.3381428 Test Loss: 0.2689813\n",
      "Validation loss decreased (inf --> 0.338143).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1603798\n",
      "\tspeed: 0.0507s/iter; left time: 174.3492s\n",
      "\titers: 200, epoch: 2 | loss: 0.1843710\n",
      "\tspeed: 0.0243s/iter; left time: 81.0943s\n",
      "\titers: 300, epoch: 2 | loss: 0.1770642\n",
      "\tspeed: 0.0229s/iter; left time: 74.2358s\n",
      "\titers: 400, epoch: 2 | loss: 0.1333831\n",
      "\tspeed: 0.0261s/iter; left time: 81.8177s\n",
      "\titers: 500, epoch: 2 | loss: 0.1778959\n",
      "\tspeed: 0.0230s/iter; left time: 69.8148s\n",
      "\titers: 600, epoch: 2 | loss: 0.0964809\n",
      "\tspeed: 0.0237s/iter; left time: 69.5971s\n",
      "\titers: 700, epoch: 2 | loss: 0.1615749\n",
      "\tspeed: 0.0236s/iter; left time: 67.0044s\n",
      "Epoch: 2 cost time: 16.84212851524353\n",
      "Epoch: 2, Steps: 707 | Train Loss: 0.2109457 Vali Loss: 0.3495789 Test Loss: 0.2724959\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1770540\n",
      "\tspeed: 0.0527s/iter; left time: 143.7675s\n",
      "\titers: 200, epoch: 3 | loss: 0.1440943\n",
      "\tspeed: 0.0253s/iter; left time: 66.5773s\n",
      "\titers: 300, epoch: 3 | loss: 0.1807164\n",
      "\tspeed: 0.0231s/iter; left time: 58.3442s\n",
      "\titers: 400, epoch: 3 | loss: 0.2671335\n",
      "\tspeed: 0.0235s/iter; left time: 57.1461s\n",
      "\titers: 500, epoch: 3 | loss: 0.1022030\n",
      "\tspeed: 0.0225s/iter; left time: 52.3981s\n",
      "\titers: 600, epoch: 3 | loss: 0.1648515\n",
      "\tspeed: 0.0231s/iter; left time: 51.3889s\n",
      "\titers: 700, epoch: 3 | loss: 0.1632743\n",
      "\tspeed: 0.0237s/iter; left time: 50.5155s\n",
      "Epoch: 3 cost time: 16.778504133224487\n",
      "Epoch: 3, Steps: 707 | Train Loss: 0.1847990 Vali Loss: 0.3105043 Test Loss: 0.2462937\n",
      "Validation loss decreased (0.338143 --> 0.310504).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0977050\n",
      "\tspeed: 0.0534s/iter; left time: 108.0356s\n",
      "\titers: 200, epoch: 4 | loss: 0.1873662\n",
      "\tspeed: 0.0235s/iter; left time: 45.1862s\n",
      "\titers: 300, epoch: 4 | loss: 0.1542448\n",
      "\tspeed: 0.0233s/iter; left time: 42.3914s\n",
      "\titers: 400, epoch: 4 | loss: 0.1173169\n",
      "\tspeed: 0.0226s/iter; left time: 38.9054s\n",
      "\titers: 500, epoch: 4 | loss: 0.1171046\n",
      "\tspeed: 0.0236s/iter; left time: 38.2048s\n",
      "\titers: 600, epoch: 4 | loss: 0.2594963\n",
      "\tspeed: 0.0253s/iter; left time: 38.4861s\n",
      "\titers: 700, epoch: 4 | loss: 0.1381603\n",
      "\tspeed: 0.0245s/iter; left time: 34.8425s\n",
      "Epoch: 4 cost time: 16.851014614105225\n",
      "Epoch: 4, Steps: 707 | Train Loss: 0.1701056 Vali Loss: 0.3061250 Test Loss: 0.2382746\n",
      "Validation loss decreased (0.310504 --> 0.306125).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1370104\n",
      "\tspeed: 0.0524s/iter; left time: 68.9699s\n",
      "\titers: 200, epoch: 5 | loss: 0.1258017\n",
      "\tspeed: 0.0235s/iter; left time: 28.5887s\n",
      "\titers: 300, epoch: 5 | loss: 0.1354257\n",
      "\tspeed: 0.0234s/iter; left time: 26.0853s\n",
      "\titers: 400, epoch: 5 | loss: 0.2373091\n",
      "\tspeed: 0.0246s/iter; left time: 25.0187s\n",
      "\titers: 500, epoch: 5 | loss: 0.2226449\n",
      "\tspeed: 0.0244s/iter; left time: 22.3581s\n",
      "\titers: 600, epoch: 5 | loss: 0.1507330\n",
      "\tspeed: 0.0244s/iter; left time: 19.9000s\n",
      "\titers: 700, epoch: 5 | loss: 0.1192460\n",
      "\tspeed: 0.0236s/iter; left time: 16.8656s\n",
      "Epoch: 5 cost time: 16.966277360916138\n",
      "Epoch: 5, Steps: 707 | Train Loss: 0.1602845 Vali Loss: 0.3132819 Test Loss: 0.2416231\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1146820\n",
      "\tspeed: 0.0514s/iter; left time: 31.2534s\n",
      "\titers: 200, epoch: 6 | loss: 0.1561900\n",
      "\tspeed: 0.0260s/iter; left time: 13.2223s\n",
      "\titers: 300, epoch: 6 | loss: 0.1411964\n",
      "\tspeed: 0.0253s/iter; left time: 10.3384s\n",
      "\titers: 400, epoch: 6 | loss: 0.1901719\n",
      "\tspeed: 0.0241s/iter; left time: 7.4149s\n",
      "\titers: 500, epoch: 6 | loss: 0.0970124\n",
      "\tspeed: 0.0238s/iter; left time: 4.9576s\n",
      "\titers: 600, epoch: 6 | loss: 0.1240107\n",
      "\tspeed: 0.0245s/iter; left time: 2.6412s\n",
      "\titers: 700, epoch: 6 | loss: 0.1784009\n",
      "\tspeed: 0.0230s/iter; left time: 0.1842s\n",
      "Epoch: 6 cost time: 17.218780040740967\n",
      "Epoch: 6, Steps: 707 | Train Loss: 0.1550268 Vali Loss: 0.3082604 Test Loss: 0.2409915\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "Test cost time: 1.5155s\n",
      "test shape: (192, 32, 6, 1) (192, 32, 6, 1)\n",
      "test shape: (6144, 6, 1) (6144, 6, 1)\n",
      "mse:0.2383483201265335, mae:0.32866477966308594\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1632.15576171875\n",
      "MAE:  27.197431564331055\n",
      "RMSE: 40.39994812011719\n",
      "MAPE: 0.3533102869987488\n",
      "MSPE: 0.601075291633606\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24491\n",
      "[DEBUG] Original dataset length: 24491\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22641\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3447\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "\titers: 100, epoch: 1 | loss: 0.3443511\n",
      "\tspeed: 0.0218s/iter; left time: 90.4828s\n",
      "\titers: 200, epoch: 1 | loss: 0.3228079\n",
      "\tspeed: 0.0227s/iter; left time: 91.6936s\n",
      "\titers: 300, epoch: 1 | loss: 0.2898109\n",
      "\tspeed: 0.0238s/iter; left time: 93.8525s\n",
      "\titers: 400, epoch: 1 | loss: 0.2541541\n",
      "\tspeed: 0.0237s/iter; left time: 91.1528s\n",
      "\titers: 500, epoch: 1 | loss: 0.1554191\n",
      "\tspeed: 0.0221s/iter; left time: 82.8579s\n",
      "\titers: 600, epoch: 1 | loss: 0.1276112\n",
      "\tspeed: 0.0256s/iter; left time: 93.2910s\n",
      "\titers: 700, epoch: 1 | loss: 0.1918742\n",
      "\tspeed: 0.0239s/iter; left time: 84.5402s\n",
      "Epoch: 1 cost time: 16.56454825401306\n",
      "Epoch: 1, Steps: 707 | Train Loss: 0.2702211 Vali Loss: 0.3436641 Test Loss: 0.2692783\n",
      "Validation loss decreased (inf --> 0.343664).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3337280\n",
      "\tspeed: 0.0501s/iter; left time: 172.2597s\n",
      "\titers: 200, epoch: 2 | loss: 0.1512230\n",
      "\tspeed: 0.0231s/iter; left time: 77.0985s\n",
      "\titers: 300, epoch: 2 | loss: 0.1764552\n",
      "\tspeed: 0.0224s/iter; left time: 72.3926s\n",
      "\titers: 400, epoch: 2 | loss: 0.1551416\n",
      "\tspeed: 0.0259s/iter; left time: 81.0791s\n",
      "\titers: 500, epoch: 2 | loss: 0.1714434\n",
      "\tspeed: 0.0243s/iter; left time: 73.8643s\n",
      "\titers: 600, epoch: 2 | loss: 0.2570945\n",
      "\tspeed: 0.0234s/iter; left time: 68.6536s\n",
      "\titers: 700, epoch: 2 | loss: 0.1650399\n",
      "\tspeed: 0.0235s/iter; left time: 66.7167s\n",
      "Epoch: 2 cost time: 16.725465536117554\n",
      "Epoch: 2, Steps: 707 | Train Loss: 0.2118833 Vali Loss: 0.3238188 Test Loss: 0.2478859\n",
      "Validation loss decreased (0.343664 --> 0.323819).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1234771\n",
      "\tspeed: 0.0511s/iter; left time: 139.4234s\n",
      "\titers: 200, epoch: 3 | loss: 0.1362148\n",
      "\tspeed: 0.0238s/iter; left time: 62.5958s\n",
      "\titers: 300, epoch: 3 | loss: 0.1341481\n",
      "\tspeed: 0.0253s/iter; left time: 63.9616s\n",
      "\titers: 400, epoch: 3 | loss: 0.1355446\n",
      "\tspeed: 0.0230s/iter; left time: 55.9349s\n",
      "\titers: 500, epoch: 3 | loss: 0.1282422\n",
      "\tspeed: 0.0234s/iter; left time: 54.5296s\n",
      "\titers: 600, epoch: 3 | loss: 0.1581760\n",
      "\tspeed: 0.0227s/iter; left time: 50.5047s\n",
      "\titers: 700, epoch: 3 | loss: 0.2171392\n",
      "\tspeed: 0.0232s/iter; left time: 49.3969s\n",
      "Epoch: 3 cost time: 16.712137699127197\n",
      "Epoch: 3, Steps: 707 | Train Loss: 0.1853145 Vali Loss: 0.3132448 Test Loss: 0.2397132\n",
      "Validation loss decreased (0.323819 --> 0.313245).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1348236\n",
      "\tspeed: 0.0539s/iter; left time: 109.0465s\n",
      "\titers: 200, epoch: 4 | loss: 0.2336283\n",
      "\tspeed: 0.0236s/iter; left time: 45.3641s\n",
      "\titers: 300, epoch: 4 | loss: 0.2336453\n",
      "\tspeed: 0.0237s/iter; left time: 43.1377s\n",
      "\titers: 400, epoch: 4 | loss: 0.2518083\n",
      "\tspeed: 0.0253s/iter; left time: 43.5671s\n",
      "\titers: 500, epoch: 4 | loss: 0.2181557\n",
      "\tspeed: 0.0244s/iter; left time: 39.5160s\n",
      "\titers: 600, epoch: 4 | loss: 0.2393189\n",
      "\tspeed: 0.0236s/iter; left time: 35.9545s\n",
      "\titers: 700, epoch: 4 | loss: 0.1496485\n",
      "\tspeed: 0.0265s/iter; left time: 37.6639s\n",
      "Epoch: 4 cost time: 17.400020122528076\n",
      "Epoch: 4, Steps: 707 | Train Loss: 0.1706601 Vali Loss: 0.3098186 Test Loss: 0.2318932\n",
      "Validation loss decreased (0.313245 --> 0.309819).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1557507\n",
      "\tspeed: 0.0525s/iter; left time: 69.0382s\n",
      "\titers: 200, epoch: 5 | loss: 0.1737061\n",
      "\tspeed: 0.0237s/iter; left time: 28.8223s\n",
      "\titers: 300, epoch: 5 | loss: 0.1028371\n",
      "\tspeed: 0.0235s/iter; left time: 26.2452s\n",
      "\titers: 400, epoch: 5 | loss: 0.1671810\n",
      "\tspeed: 0.0258s/iter; left time: 26.1908s\n",
      "\titers: 500, epoch: 5 | loss: 0.1786633\n",
      "\tspeed: 0.0272s/iter; left time: 24.9169s\n",
      "\titers: 600, epoch: 5 | loss: 0.1797329\n",
      "\tspeed: 0.0262s/iter; left time: 21.3128s\n",
      "\titers: 700, epoch: 5 | loss: 0.1907196\n",
      "\tspeed: 0.0251s/iter; left time: 17.9716s\n",
      "Epoch: 5 cost time: 17.654631853103638\n",
      "Epoch: 5, Steps: 707 | Train Loss: 0.1615465 Vali Loss: 0.3163817 Test Loss: 0.2401454\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1628708\n",
      "\tspeed: 0.0533s/iter; left time: 32.4055s\n",
      "\titers: 200, epoch: 6 | loss: 0.2006470\n",
      "\tspeed: 0.0264s/iter; left time: 13.4283s\n",
      "\titers: 300, epoch: 6 | loss: 0.1438445\n",
      "\tspeed: 0.0261s/iter; left time: 10.6555s\n",
      "\titers: 400, epoch: 6 | loss: 0.1193108\n",
      "\tspeed: 0.0264s/iter; left time: 8.1326s\n",
      "\titers: 500, epoch: 6 | loss: 0.1528928\n",
      "\tspeed: 0.0254s/iter; left time: 5.2930s\n",
      "\titers: 600, epoch: 6 | loss: 0.1361716\n",
      "\tspeed: 0.0266s/iter; left time: 2.8748s\n",
      "\titers: 700, epoch: 6 | loss: 0.0988534\n",
      "\tspeed: 0.0259s/iter; left time: 0.2072s\n",
      "Epoch: 6 cost time: 18.431868076324463\n",
      "Epoch: 6, Steps: 707 | Train Loss: 0.1564602 Vali Loss: 0.3133753 Test Loss: 0.2398692\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "Test cost time: 1.7423s\n",
      "test shape: (192, 32, 6, 1) (192, 32, 6, 1)\n",
      "test shape: (6144, 6, 1) (6144, 6, 1)\n",
      "mse:0.2314179241657257, mae:0.32282671332359314\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl48_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1584.69775390625\n",
      "MAE:  26.714326858520508\n",
      "RMSE: 39.80826187133789\n",
      "MAPE: 0.35564878582954407\n",
      "MSPE: 0.6074320077896118\n",
      ">>>>>>>Running time saved<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Running seq_len=72\n",
      "Args in experiment:\n",
      "Namespace(model='informer', data='traffic_full', root_path='../', data_path='traffic_full.csv', features='S', target='flow', freq='h', checkpoints='./checkpoints/', seq_len=72, label_len=24, pred_len=6, enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=2, d_layers=1, s_layers=[3, 2, 1], d_ff=2048, factor=5, padding=0, distil=True, dropout=0.05, attn='prob', embed='timeF', activation='gelu', output_attention=False, do_predict=False, mix=True, cols=None, num_workers=0, itr=10, train_epochs=6, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, inverse=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', detail_freq='h')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24467\n",
      "[DEBUG] Original dataset length: 24467\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22233\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3423\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "\titers: 100, epoch: 1 | loss: 0.3409803\n",
      "\tspeed: 0.0419s/iter; left time: 170.1732s\n",
      "\titers: 200, epoch: 1 | loss: 0.3249234\n",
      "\tspeed: 0.0271s/iter; left time: 107.4833s\n",
      "\titers: 300, epoch: 1 | loss: 0.3158022\n",
      "\tspeed: 0.0279s/iter; left time: 107.8389s\n",
      "\titers: 400, epoch: 1 | loss: 0.2243023\n",
      "\tspeed: 0.0275s/iter; left time: 103.3922s\n",
      "\titers: 500, epoch: 1 | loss: 0.1964700\n",
      "\tspeed: 0.0283s/iter; left time: 103.5904s\n",
      "\titers: 600, epoch: 1 | loss: 0.1899345\n",
      "\tspeed: 0.0273s/iter; left time: 97.4365s\n",
      "Epoch: 1 cost time: 19.748058080673218\n",
      "Epoch: 1, Steps: 694 | Train Loss: 0.2750601 Vali Loss: 0.3228438 Test Loss: 0.2607255\n",
      "Validation loss decreased (inf --> 0.322844).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1707512\n",
      "\tspeed: 0.0870s/iter; left time: 293.2824s\n",
      "\titers: 200, epoch: 2 | loss: 0.2462886\n",
      "\tspeed: 0.0275s/iter; left time: 90.0039s\n",
      "\titers: 300, epoch: 2 | loss: 0.1854431\n",
      "\tspeed: 0.0274s/iter; left time: 86.9603s\n",
      "\titers: 400, epoch: 2 | loss: 0.1778743\n",
      "\tspeed: 0.0273s/iter; left time: 83.8823s\n",
      "\titers: 500, epoch: 2 | loss: 0.2379427\n",
      "\tspeed: 0.0277s/iter; left time: 82.3826s\n",
      "\titers: 600, epoch: 2 | loss: 0.1998719\n",
      "\tspeed: 0.0292s/iter; left time: 83.7152s\n",
      "Epoch: 2 cost time: 19.411123752593994\n",
      "Epoch: 2, Steps: 694 | Train Loss: 0.2093997 Vali Loss: 0.3249131 Test Loss: 0.2761189\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2533138\n",
      "\tspeed: 0.0828s/iter; left time: 221.6611s\n",
      "\titers: 200, epoch: 3 | loss: 0.1102644\n",
      "\tspeed: 0.0279s/iter; left time: 71.9019s\n",
      "\titers: 300, epoch: 3 | loss: 0.1108884\n",
      "\tspeed: 0.0293s/iter; left time: 72.5775s\n",
      "\titers: 400, epoch: 3 | loss: 0.1204173\n",
      "\tspeed: 0.0277s/iter; left time: 65.7980s\n",
      "\titers: 500, epoch: 3 | loss: 0.1953272\n",
      "\tspeed: 0.0256s/iter; left time: 58.3637s\n",
      "\titers: 600, epoch: 3 | loss: 0.1584853\n",
      "\tspeed: 0.0255s/iter; left time: 55.5185s\n",
      "Epoch: 3 cost time: 18.682666778564453\n",
      "Epoch: 3, Steps: 694 | Train Loss: 0.1826182 Vali Loss: 0.3059770 Test Loss: 0.2380106\n",
      "Validation loss decreased (0.322844 --> 0.305977).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1428984\n",
      "\tspeed: 0.0810s/iter; left time: 160.6471s\n",
      "\titers: 200, epoch: 4 | loss: 0.1095511\n",
      "\tspeed: 0.0264s/iter; left time: 49.7250s\n",
      "\titers: 300, epoch: 4 | loss: 0.1426825\n",
      "\tspeed: 0.0258s/iter; left time: 45.9454s\n",
      "\titers: 400, epoch: 4 | loss: 0.1223251\n",
      "\tspeed: 0.0254s/iter; left time: 42.7371s\n",
      "\titers: 500, epoch: 4 | loss: 0.1480007\n",
      "\tspeed: 0.0252s/iter; left time: 39.9684s\n",
      "\titers: 600, epoch: 4 | loss: 0.1286352\n",
      "\tspeed: 0.0272s/iter; left time: 40.2785s\n",
      "Epoch: 4 cost time: 18.2106716632843\n",
      "Epoch: 4, Steps: 694 | Train Loss: 0.1672368 Vali Loss: 0.3068192 Test Loss: 0.2370473\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1538067\n",
      "\tspeed: 0.0811s/iter; left time: 104.5716s\n",
      "\titers: 200, epoch: 5 | loss: 0.2235938\n",
      "\tspeed: 0.0257s/iter; left time: 30.5507s\n",
      "\titers: 300, epoch: 5 | loss: 0.2415203\n",
      "\tspeed: 0.0253s/iter; left time: 27.5554s\n",
      "\titers: 400, epoch: 5 | loss: 0.1012496\n",
      "\tspeed: 0.0284s/iter; left time: 28.0733s\n",
      "\titers: 500, epoch: 5 | loss: 0.1793437\n",
      "\tspeed: 0.0274s/iter; left time: 24.3861s\n",
      "\titers: 600, epoch: 5 | loss: 0.2219589\n",
      "\tspeed: 0.0267s/iter; left time: 21.0467s\n",
      "Epoch: 5 cost time: 18.526186227798462\n",
      "Epoch: 5, Steps: 694 | Train Loss: 0.1574704 Vali Loss: 0.3136614 Test Loss: 0.2434279\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1953224\n",
      "\tspeed: 0.0810s/iter; left time: 48.1692s\n",
      "\titers: 200, epoch: 6 | loss: 0.1743095\n",
      "\tspeed: 0.0276s/iter; left time: 13.6560s\n",
      "\titers: 300, epoch: 6 | loss: 0.1481417\n",
      "\tspeed: 0.0261s/iter; left time: 10.3109s\n",
      "\titers: 400, epoch: 6 | loss: 0.2112621\n",
      "\tspeed: 0.0272s/iter; left time: 8.0346s\n",
      "\titers: 500, epoch: 6 | loss: 0.0925858\n",
      "\tspeed: 0.0260s/iter; left time: 5.0689s\n",
      "\titers: 600, epoch: 6 | loss: 0.1559274\n",
      "\tspeed: 0.0262s/iter; left time: 2.4862s\n",
      "Epoch: 6 cost time: 18.769315719604492\n",
      "Epoch: 6, Steps: 694 | Train Loss: 0.1530985 Vali Loss: 0.3108674 Test Loss: 0.2368336\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "Test cost time: 1.7034s\n",
      "test shape: (187, 32, 6, 1) (187, 32, 6, 1)\n",
      "test shape: (5984, 6, 1) (5984, 6, 1)\n",
      "mse:0.23736533522605896, mae:0.33197182416915894\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1625.424560546875\n",
      "MAE:  27.47109603881836\n",
      "RMSE: 40.31655502319336\n",
      "MAPE: 0.3683173358440399\n",
      "MSPE: 0.6663653254508972\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24467\n",
      "[DEBUG] Original dataset length: 24467\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22233\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3423\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "\titers: 100, epoch: 1 | loss: 0.2554073\n",
      "\tspeed: 0.0259s/iter; left time: 105.1534s\n",
      "\titers: 200, epoch: 1 | loss: 0.2202873\n",
      "\tspeed: 0.0251s/iter; left time: 99.5296s\n",
      "\titers: 300, epoch: 1 | loss: 0.2358459\n",
      "\tspeed: 0.0248s/iter; left time: 95.9019s\n",
      "\titers: 400, epoch: 1 | loss: 0.5838127\n",
      "\tspeed: 0.0279s/iter; left time: 104.8645s\n",
      "\titers: 500, epoch: 1 | loss: 0.2087775\n",
      "\tspeed: 0.0262s/iter; left time: 95.8889s\n",
      "\titers: 600, epoch: 1 | loss: 0.1991445\n",
      "\tspeed: 0.0260s/iter; left time: 92.5773s\n",
      "Epoch: 1 cost time: 18.016213178634644\n",
      "Epoch: 1, Steps: 694 | Train Loss: 0.2838688 Vali Loss: 0.3665615 Test Loss: 0.2970460\n",
      "Validation loss decreased (inf --> 0.366561).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1751004\n",
      "\tspeed: 0.0779s/iter; left time: 262.4764s\n",
      "\titers: 200, epoch: 2 | loss: 0.1429845\n",
      "\tspeed: 0.0272s/iter; left time: 88.8617s\n",
      "\titers: 300, epoch: 2 | loss: 0.1636482\n",
      "\tspeed: 0.0257s/iter; left time: 81.3791s\n",
      "\titers: 400, epoch: 2 | loss: 0.1642084\n",
      "\tspeed: 0.0248s/iter; left time: 76.2046s\n",
      "\titers: 500, epoch: 2 | loss: 0.2900245\n",
      "\tspeed: 0.0263s/iter; left time: 78.1700s\n",
      "\titers: 600, epoch: 2 | loss: 0.1741308\n",
      "\tspeed: 0.0252s/iter; left time: 72.3686s\n",
      "Epoch: 2 cost time: 18.160690546035767\n",
      "Epoch: 2, Steps: 694 | Train Loss: 0.2112950 Vali Loss: 0.3247822 Test Loss: 0.2585439\n",
      "Validation loss decreased (0.366561 --> 0.324782).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3061223\n",
      "\tspeed: 0.0846s/iter; left time: 226.5510s\n",
      "\titers: 200, epoch: 3 | loss: 0.1641892\n",
      "\tspeed: 0.0288s/iter; left time: 74.1987s\n",
      "\titers: 300, epoch: 3 | loss: 0.1212871\n",
      "\tspeed: 0.0301s/iter; left time: 74.4933s\n",
      "\titers: 400, epoch: 3 | loss: 0.1567393\n",
      "\tspeed: 0.0288s/iter; left time: 68.5572s\n",
      "\titers: 500, epoch: 3 | loss: 0.2686582\n",
      "\tspeed: 0.0294s/iter; left time: 66.8648s\n",
      "\titers: 600, epoch: 3 | loss: 0.1277671\n",
      "\tspeed: 0.0291s/iter; left time: 63.4230s\n",
      "Epoch: 3 cost time: 19.98784589767456\n",
      "Epoch: 3, Steps: 694 | Train Loss: 0.1831953 Vali Loss: 0.3286192 Test Loss: 0.2463432\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1405466\n",
      "\tspeed: 0.0857s/iter; left time: 169.9159s\n",
      "\titers: 200, epoch: 4 | loss: 0.2673686\n",
      "\tspeed: 0.0292s/iter; left time: 54.9264s\n",
      "\titers: 300, epoch: 4 | loss: 0.1614974\n",
      "\tspeed: 0.0285s/iter; left time: 50.8447s\n",
      "\titers: 400, epoch: 4 | loss: 0.1259707\n",
      "\tspeed: 0.0296s/iter; left time: 49.8825s\n",
      "\titers: 500, epoch: 4 | loss: 0.3040917\n",
      "\tspeed: 0.0284s/iter; left time: 45.0010s\n",
      "\titers: 600, epoch: 4 | loss: 0.1425252\n",
      "\tspeed: 0.0287s/iter; left time: 42.6074s\n",
      "Epoch: 4 cost time: 20.323758840560913\n",
      "Epoch: 4, Steps: 694 | Train Loss: 0.1687365 Vali Loss: 0.3234550 Test Loss: 0.2470015\n",
      "Validation loss decreased (0.324782 --> 0.323455).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2250851\n",
      "\tspeed: 0.0880s/iter; left time: 113.4535s\n",
      "\titers: 200, epoch: 5 | loss: 0.2518476\n",
      "\tspeed: 0.0287s/iter; left time: 34.1789s\n",
      "\titers: 300, epoch: 5 | loss: 0.1178036\n",
      "\tspeed: 0.0281s/iter; left time: 30.5805s\n",
      "\titers: 400, epoch: 5 | loss: 0.1146093\n",
      "\tspeed: 0.0302s/iter; left time: 29.8830s\n",
      "\titers: 500, epoch: 5 | loss: 0.1415918\n",
      "\tspeed: 0.0288s/iter; left time: 25.5692s\n",
      "\titers: 600, epoch: 5 | loss: 0.2009168\n",
      "\tspeed: 0.0272s/iter; left time: 21.4348s\n",
      "Epoch: 5 cost time: 19.720893621444702\n",
      "Epoch: 5, Steps: 694 | Train Loss: 0.1607693 Vali Loss: 0.3145719 Test Loss: 0.2356632\n",
      "Validation loss decreased (0.323455 --> 0.314572).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2928079\n",
      "\tspeed: 0.0863s/iter; left time: 51.3447s\n",
      "\titers: 200, epoch: 6 | loss: 0.1930345\n",
      "\tspeed: 0.0284s/iter; left time: 14.0390s\n",
      "\titers: 300, epoch: 6 | loss: 0.1461954\n",
      "\tspeed: 0.0276s/iter; left time: 10.9211s\n",
      "\titers: 400, epoch: 6 | loss: 0.1396809\n",
      "\tspeed: 0.0282s/iter; left time: 8.3227s\n",
      "\titers: 500, epoch: 6 | loss: 0.1170337\n",
      "\tspeed: 0.0272s/iter; left time: 5.2955s\n",
      "\titers: 600, epoch: 6 | loss: 0.1873637\n",
      "\tspeed: 0.0284s/iter; left time: 2.7027s\n",
      "Epoch: 6 cost time: 19.623568058013916\n",
      "Epoch: 6, Steps: 694 | Train Loss: 0.1554905 Vali Loss: 0.3099656 Test Loss: 0.2400856\n",
      "Validation loss decreased (0.314572 --> 0.309966).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "Test cost time: 2.0154s\n",
      "test shape: (187, 32, 6, 1) (187, 32, 6, 1)\n",
      "test shape: (5984, 6, 1) (5984, 6, 1)\n",
      "mse:0.23947328329086304, mae:0.3311498761177063\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1639.859130859375\n",
      "MAE:  27.403078079223633\n",
      "RMSE: 40.495174407958984\n",
      "MAPE: 0.3791086673736572\n",
      "MSPE: 0.7401858568191528\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24467\n",
      "[DEBUG] Original dataset length: 24467\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22233\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3423\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "\titers: 100, epoch: 1 | loss: 0.2739085\n",
      "\tspeed: 0.0273s/iter; left time: 110.9584s\n",
      "\titers: 200, epoch: 1 | loss: 0.2268024\n",
      "\tspeed: 0.0281s/iter; left time: 111.2449s\n",
      "\titers: 300, epoch: 1 | loss: 0.2424552\n",
      "\tspeed: 0.0303s/iter; left time: 117.2250s\n",
      "\titers: 400, epoch: 1 | loss: 0.2597516\n",
      "\tspeed: 0.0278s/iter; left time: 104.6058s\n",
      "\titers: 500, epoch: 1 | loss: 0.1403150\n",
      "\tspeed: 0.0280s/iter; left time: 102.7568s\n",
      "\titers: 600, epoch: 1 | loss: 0.2060911\n",
      "\tspeed: 0.0282s/iter; left time: 100.6236s\n",
      "Epoch: 1 cost time: 19.63163137435913\n",
      "Epoch: 1, Steps: 694 | Train Loss: 0.2768373 Vali Loss: 0.3288804 Test Loss: 0.2575395\n",
      "Validation loss decreased (inf --> 0.328880).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2306541\n",
      "\tspeed: 0.0884s/iter; left time: 297.8774s\n",
      "\titers: 200, epoch: 2 | loss: 0.1454096\n",
      "\tspeed: 0.0286s/iter; left time: 93.6291s\n",
      "\titers: 300, epoch: 2 | loss: 0.1731234\n",
      "\tspeed: 0.0281s/iter; left time: 89.0816s\n",
      "\titers: 400, epoch: 2 | loss: 0.2206531\n",
      "\tspeed: 0.0279s/iter; left time: 85.6019s\n",
      "\titers: 500, epoch: 2 | loss: 0.2684555\n",
      "\tspeed: 0.0264s/iter; left time: 78.3981s\n",
      "\titers: 600, epoch: 2 | loss: 0.1268166\n",
      "\tspeed: 0.0298s/iter; left time: 85.4490s\n",
      "Epoch: 2 cost time: 19.592257976531982\n",
      "Epoch: 2, Steps: 694 | Train Loss: 0.2084381 Vali Loss: 0.3193984 Test Loss: 0.2598117\n",
      "Validation loss decreased (0.328880 --> 0.319398).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2393579\n",
      "\tspeed: 0.0846s/iter; left time: 226.5405s\n",
      "\titers: 200, epoch: 3 | loss: 0.1869743\n",
      "\tspeed: 0.0295s/iter; left time: 76.1458s\n",
      "\titers: 300, epoch: 3 | loss: 0.1416301\n",
      "\tspeed: 0.0290s/iter; left time: 71.8369s\n",
      "\titers: 400, epoch: 3 | loss: 0.2244770\n",
      "\tspeed: 0.0265s/iter; left time: 62.8909s\n",
      "\titers: 500, epoch: 3 | loss: 0.1632283\n",
      "\tspeed: 0.0258s/iter; left time: 58.7510s\n",
      "\titers: 600, epoch: 3 | loss: 0.1625172\n",
      "\tspeed: 0.0246s/iter; left time: 53.6216s\n",
      "Epoch: 3 cost time: 18.576581478118896\n",
      "Epoch: 3, Steps: 694 | Train Loss: 0.1811600 Vali Loss: 0.3258228 Test Loss: 0.2494970\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1378765\n",
      "\tspeed: 0.0773s/iter; left time: 153.2415s\n",
      "\titers: 200, epoch: 4 | loss: 0.1688460\n",
      "\tspeed: 0.0250s/iter; left time: 47.1456s\n",
      "\titers: 300, epoch: 4 | loss: 0.1946570\n",
      "\tspeed: 0.0247s/iter; left time: 44.0345s\n",
      "\titers: 400, epoch: 4 | loss: 0.1831186\n",
      "\tspeed: 0.0249s/iter; left time: 41.9562s\n",
      "\titers: 500, epoch: 4 | loss: 0.1160598\n",
      "\tspeed: 0.0246s/iter; left time: 38.8852s\n",
      "\titers: 600, epoch: 4 | loss: 0.1670714\n",
      "\tspeed: 0.0249s/iter; left time: 36.9523s\n",
      "Epoch: 4 cost time: 17.734740495681763\n",
      "Epoch: 4, Steps: 694 | Train Loss: 0.1670601 Vali Loss: 0.3034357 Test Loss: 0.2382189\n",
      "Validation loss decreased (0.319398 --> 0.303436).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1277345\n",
      "\tspeed: 0.0795s/iter; left time: 102.4213s\n",
      "\titers: 200, epoch: 5 | loss: 0.1664719\n",
      "\tspeed: 0.0259s/iter; left time: 30.7762s\n",
      "\titers: 300, epoch: 5 | loss: 0.0815004\n",
      "\tspeed: 0.0251s/iter; left time: 27.3194s\n",
      "\titers: 400, epoch: 5 | loss: 0.2226363\n",
      "\tspeed: 0.0270s/iter; left time: 26.6602s\n",
      "\titers: 500, epoch: 5 | loss: 0.2092995\n",
      "\tspeed: 0.0263s/iter; left time: 23.3563s\n",
      "\titers: 600, epoch: 5 | loss: 0.1025684\n",
      "\tspeed: 0.0279s/iter; left time: 22.0079s\n",
      "Epoch: 5 cost time: 18.31456756591797\n",
      "Epoch: 5, Steps: 694 | Train Loss: 0.1583078 Vali Loss: 0.3199582 Test Loss: 0.2430761\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1216970\n",
      "\tspeed: 0.0782s/iter; left time: 46.5537s\n",
      "\titers: 200, epoch: 6 | loss: 0.1207305\n",
      "\tspeed: 0.0279s/iter; left time: 13.8175s\n",
      "\titers: 300, epoch: 6 | loss: 0.2060488\n",
      "\tspeed: 0.0267s/iter; left time: 10.5390s\n",
      "\titers: 400, epoch: 6 | loss: 0.2013859\n",
      "\tspeed: 0.0271s/iter; left time: 8.0032s\n",
      "\titers: 500, epoch: 6 | loss: 0.0923580\n",
      "\tspeed: 0.0267s/iter; left time: 5.1997s\n",
      "\titers: 600, epoch: 6 | loss: 0.2225401\n",
      "\tspeed: 0.0278s/iter; left time: 2.6417s\n",
      "Epoch: 6 cost time: 18.669161558151245\n",
      "Epoch: 6, Steps: 694 | Train Loss: 0.1529242 Vali Loss: 0.3358340 Test Loss: 0.2455351\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "Test cost time: 1.7384s\n",
      "test shape: (187, 32, 6, 1) (187, 32, 6, 1)\n",
      "test shape: (5984, 6, 1) (5984, 6, 1)\n",
      "mse:0.2383033037185669, mae:0.32584506273269653\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1631.8475341796875\n",
      "MAE:  26.964096069335938\n",
      "RMSE: 40.39613342285156\n",
      "MAPE: 0.3437339961528778\n",
      "MSPE: 0.5634836554527283\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24467\n",
      "[DEBUG] Original dataset length: 24467\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22233\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3423\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "\titers: 100, epoch: 1 | loss: 0.2398250\n",
      "\tspeed: 0.0269s/iter; left time: 109.4991s\n",
      "\titers: 200, epoch: 1 | loss: 0.3750010\n",
      "\tspeed: 0.0261s/iter; left time: 103.4208s\n",
      "\titers: 300, epoch: 1 | loss: 0.3206716\n",
      "\tspeed: 0.0262s/iter; left time: 101.1402s\n",
      "\titers: 400, epoch: 1 | loss: 0.1452438\n",
      "\tspeed: 0.0273s/iter; left time: 102.7869s\n",
      "\titers: 500, epoch: 1 | loss: 0.3335423\n",
      "\tspeed: 0.0255s/iter; left time: 93.4649s\n",
      "\titers: 600, epoch: 1 | loss: 0.1938671\n",
      "\tspeed: 0.0250s/iter; left time: 89.2536s\n",
      "Epoch: 1 cost time: 18.194655179977417\n",
      "Epoch: 1, Steps: 694 | Train Loss: 0.2790796 Vali Loss: 0.3366759 Test Loss: 0.2627607\n",
      "Validation loss decreased (inf --> 0.336676).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1338491\n",
      "\tspeed: 0.0802s/iter; left time: 270.3508s\n",
      "\titers: 200, epoch: 2 | loss: 0.2062624\n",
      "\tspeed: 0.0277s/iter; left time: 90.5497s\n",
      "\titers: 300, epoch: 2 | loss: 0.1540320\n",
      "\tspeed: 0.0272s/iter; left time: 86.1765s\n",
      "\titers: 400, epoch: 2 | loss: 0.2014459\n",
      "\tspeed: 0.0275s/iter; left time: 84.5062s\n",
      "\titers: 500, epoch: 2 | loss: 0.1456095\n",
      "\tspeed: 0.0275s/iter; left time: 81.7812s\n",
      "\titers: 600, epoch: 2 | loss: 0.1376741\n",
      "\tspeed: 0.0273s/iter; left time: 78.4247s\n",
      "Epoch: 2 cost time: 19.029186248779297\n",
      "Epoch: 2, Steps: 694 | Train Loss: 0.2088604 Vali Loss: 0.3284555 Test Loss: 0.2662525\n",
      "Validation loss decreased (0.336676 --> 0.328456).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3118194\n",
      "\tspeed: 0.0860s/iter; left time: 230.1034s\n",
      "\titers: 200, epoch: 3 | loss: 0.1852860\n",
      "\tspeed: 0.0273s/iter; left time: 70.3303s\n",
      "\titers: 300, epoch: 3 | loss: 0.1195199\n",
      "\tspeed: 0.0268s/iter; left time: 66.2796s\n",
      "\titers: 400, epoch: 3 | loss: 0.1548421\n",
      "\tspeed: 0.0270s/iter; left time: 64.1000s\n",
      "\titers: 500, epoch: 3 | loss: 0.2896580\n",
      "\tspeed: 0.0279s/iter; left time: 63.5942s\n",
      "\titers: 600, epoch: 3 | loss: 0.2804622\n",
      "\tspeed: 0.0276s/iter; left time: 60.1367s\n",
      "Epoch: 3 cost time: 18.908578395843506\n",
      "Epoch: 3, Steps: 694 | Train Loss: 0.1822909 Vali Loss: 0.3187012 Test Loss: 0.2401760\n",
      "Validation loss decreased (0.328456 --> 0.318701).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2386431\n",
      "\tspeed: 0.0784s/iter; left time: 155.4469s\n",
      "\titers: 200, epoch: 4 | loss: 0.2948148\n",
      "\tspeed: 0.0251s/iter; left time: 47.2633s\n",
      "\titers: 300, epoch: 4 | loss: 0.1503429\n",
      "\tspeed: 0.0257s/iter; left time: 45.9078s\n",
      "\titers: 400, epoch: 4 | loss: 0.1134693\n",
      "\tspeed: 0.0251s/iter; left time: 42.2750s\n",
      "\titers: 500, epoch: 4 | loss: 0.1269138\n",
      "\tspeed: 0.0258s/iter; left time: 40.7973s\n",
      "\titers: 600, epoch: 4 | loss: 0.1642206\n",
      "\tspeed: 0.0261s/iter; left time: 38.6716s\n",
      "Epoch: 4 cost time: 17.66938042640686\n",
      "Epoch: 4, Steps: 694 | Train Loss: 0.1665739 Vali Loss: 0.3218368 Test Loss: 0.2417678\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1477699\n",
      "\tspeed: 0.0790s/iter; left time: 101.8309s\n",
      "\titers: 200, epoch: 5 | loss: 0.1609240\n",
      "\tspeed: 0.0253s/iter; left time: 30.0908s\n",
      "\titers: 300, epoch: 5 | loss: 0.1582191\n",
      "\tspeed: 0.0249s/iter; left time: 27.1313s\n",
      "\titers: 400, epoch: 5 | loss: 0.1337576\n",
      "\tspeed: 0.0254s/iter; left time: 25.1568s\n",
      "\titers: 500, epoch: 5 | loss: 0.1432281\n",
      "\tspeed: 0.0255s/iter; left time: 22.6398s\n",
      "\titers: 600, epoch: 5 | loss: 0.1425126\n",
      "\tspeed: 0.0270s/iter; left time: 21.3418s\n",
      "Epoch: 5 cost time: 17.86085796356201\n",
      "Epoch: 5, Steps: 694 | Train Loss: 0.1577262 Vali Loss: 0.3234591 Test Loss: 0.2395599\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1432002\n",
      "\tspeed: 0.0761s/iter; left time: 45.2678s\n",
      "\titers: 200, epoch: 6 | loss: 0.1726767\n",
      "\tspeed: 0.0252s/iter; left time: 12.4937s\n",
      "\titers: 300, epoch: 6 | loss: 0.3174859\n",
      "\tspeed: 0.0250s/iter; left time: 9.8905s\n",
      "\titers: 400, epoch: 6 | loss: 0.0875717\n",
      "\tspeed: 0.0267s/iter; left time: 7.8870s\n",
      "\titers: 500, epoch: 6 | loss: 0.1538558\n",
      "\tspeed: 0.0256s/iter; left time: 4.9889s\n",
      "\titers: 600, epoch: 6 | loss: 0.1255595\n",
      "\tspeed: 0.0257s/iter; left time: 2.4380s\n",
      "Epoch: 6 cost time: 17.65100121498108\n",
      "Epoch: 6, Steps: 694 | Train Loss: 0.1523285 Vali Loss: 0.3204748 Test Loss: 0.2385073\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "Test cost time: 1.7218s\n",
      "test shape: (187, 32, 6, 1) (187, 32, 6, 1)\n",
      "test shape: (5984, 6, 1) (5984, 6, 1)\n",
      "mse:0.2399367094039917, mae:0.33067265152931213\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1643.0325927734375\n",
      "MAE:  27.363588333129883\n",
      "RMSE: 40.534339904785156\n",
      "MAPE: 0.40778595209121704\n",
      "MSPE: 0.8901311755180359\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24467\n",
      "[DEBUG] Original dataset length: 24467\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22233\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3423\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "\titers: 100, epoch: 1 | loss: 0.2805995\n",
      "\tspeed: 0.0275s/iter; left time: 111.7323s\n",
      "\titers: 200, epoch: 1 | loss: 0.4294890\n",
      "\tspeed: 0.0251s/iter; left time: 99.4275s\n",
      "\titers: 300, epoch: 1 | loss: 0.2490106\n",
      "\tspeed: 0.0252s/iter; left time: 97.3940s\n",
      "\titers: 400, epoch: 1 | loss: 0.1243879\n",
      "\tspeed: 0.0271s/iter; left time: 101.9165s\n",
      "\titers: 500, epoch: 1 | loss: 0.3166933\n",
      "\tspeed: 0.0272s/iter; left time: 99.7979s\n",
      "\titers: 600, epoch: 1 | loss: 0.3576617\n",
      "\tspeed: 0.0250s/iter; left time: 89.3010s\n",
      "Epoch: 1 cost time: 18.3642840385437\n",
      "Epoch: 1, Steps: 694 | Train Loss: 0.2782673 Vali Loss: 0.3300421 Test Loss: 0.2684274\n",
      "Validation loss decreased (inf --> 0.330042).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1386864\n",
      "\tspeed: 0.0802s/iter; left time: 270.2497s\n",
      "\titers: 200, epoch: 2 | loss: 0.4441116\n",
      "\tspeed: 0.0255s/iter; left time: 83.3167s\n",
      "\titers: 300, epoch: 2 | loss: 0.1347870\n",
      "\tspeed: 0.0250s/iter; left time: 79.1426s\n",
      "\titers: 400, epoch: 2 | loss: 0.1548928\n",
      "\tspeed: 0.0262s/iter; left time: 80.3834s\n",
      "\titers: 500, epoch: 2 | loss: 0.3336773\n",
      "\tspeed: 0.0270s/iter; left time: 80.3219s\n",
      "\titers: 600, epoch: 2 | loss: 0.1483292\n",
      "\tspeed: 0.0266s/iter; left time: 76.4897s\n",
      "Epoch: 2 cost time: 17.958589553833008\n",
      "Epoch: 2, Steps: 694 | Train Loss: 0.2079321 Vali Loss: 0.3286662 Test Loss: 0.2642932\n",
      "Validation loss decreased (0.330042 --> 0.328666).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2411736\n",
      "\tspeed: 0.0781s/iter; left time: 209.1082s\n",
      "\titers: 200, epoch: 3 | loss: 0.1469842\n",
      "\tspeed: 0.0277s/iter; left time: 71.4585s\n",
      "\titers: 300, epoch: 3 | loss: 0.2469993\n",
      "\tspeed: 0.0249s/iter; left time: 61.6963s\n",
      "\titers: 400, epoch: 3 | loss: 0.1850833\n",
      "\tspeed: 0.0251s/iter; left time: 59.7641s\n",
      "\titers: 500, epoch: 3 | loss: 0.2876591\n",
      "\tspeed: 0.0249s/iter; left time: 56.7004s\n",
      "\titers: 600, epoch: 3 | loss: 0.1276360\n",
      "\tspeed: 0.0252s/iter; left time: 54.7600s\n",
      "Epoch: 3 cost time: 17.63895082473755\n",
      "Epoch: 3, Steps: 694 | Train Loss: 0.1800883 Vali Loss: 0.3197890 Test Loss: 0.2419029\n",
      "Validation loss decreased (0.328666 --> 0.319789).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2010656\n",
      "\tspeed: 0.0797s/iter; left time: 158.0921s\n",
      "\titers: 200, epoch: 4 | loss: 0.1362626\n",
      "\tspeed: 0.0248s/iter; left time: 46.7886s\n",
      "\titers: 300, epoch: 4 | loss: 0.1647512\n",
      "\tspeed: 0.0257s/iter; left time: 45.7669s\n",
      "\titers: 400, epoch: 4 | loss: 0.1655477\n",
      "\tspeed: 0.0255s/iter; left time: 42.9735s\n",
      "\titers: 500, epoch: 4 | loss: 0.1909936\n",
      "\tspeed: 0.0242s/iter; left time: 38.3638s\n",
      "\titers: 600, epoch: 4 | loss: 0.2216070\n",
      "\tspeed: 0.0284s/iter; left time: 42.1036s\n",
      "Epoch: 4 cost time: 17.738229751586914\n",
      "Epoch: 4, Steps: 694 | Train Loss: 0.1667426 Vali Loss: 0.3309865 Test Loss: 0.2453883\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1276904\n",
      "\tspeed: 0.0763s/iter; left time: 98.4141s\n",
      "\titers: 200, epoch: 5 | loss: 0.1270677\n",
      "\tspeed: 0.0259s/iter; left time: 30.7996s\n",
      "\titers: 300, epoch: 5 | loss: 0.0941413\n",
      "\tspeed: 0.0257s/iter; left time: 27.9344s\n",
      "\titers: 400, epoch: 5 | loss: 0.1441821\n",
      "\tspeed: 0.0275s/iter; left time: 27.1796s\n",
      "\titers: 500, epoch: 5 | loss: 0.2025261\n",
      "\tspeed: 0.0248s/iter; left time: 22.0571s\n",
      "\titers: 600, epoch: 5 | loss: 0.1271688\n",
      "\tspeed: 0.0246s/iter; left time: 19.3868s\n",
      "Epoch: 5 cost time: 17.665274620056152\n",
      "Epoch: 5, Steps: 694 | Train Loss: 0.1575203 Vali Loss: 0.3081074 Test Loss: 0.2340420\n",
      "Validation loss decreased (0.319789 --> 0.308107).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1480437\n",
      "\tspeed: 0.0783s/iter; left time: 46.5944s\n",
      "\titers: 200, epoch: 6 | loss: 0.1025378\n",
      "\tspeed: 0.0257s/iter; left time: 12.7075s\n",
      "\titers: 300, epoch: 6 | loss: 0.1078293\n",
      "\tspeed: 0.0255s/iter; left time: 10.0536s\n",
      "\titers: 400, epoch: 6 | loss: 0.0851918\n",
      "\tspeed: 0.0248s/iter; left time: 7.3298s\n",
      "\titers: 500, epoch: 6 | loss: 0.0897382\n",
      "\tspeed: 0.0251s/iter; left time: 4.9039s\n",
      "\titers: 600, epoch: 6 | loss: 0.1337751\n",
      "\tspeed: 0.0248s/iter; left time: 2.3565s\n",
      "Epoch: 6 cost time: 17.834206342697144\n",
      "Epoch: 6, Steps: 694 | Train Loss: 0.1535926 Vali Loss: 0.3162490 Test Loss: 0.2377120\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "Test cost time: 2.0050s\n",
      "test shape: (187, 32, 6, 1) (187, 32, 6, 1)\n",
      "test shape: (5984, 6, 1) (5984, 6, 1)\n",
      "mse:0.23353160917758942, mae:0.3243888020515442\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1599.1722412109375\n",
      "MAE:  26.84358787536621\n",
      "RMSE: 39.98965072631836\n",
      "MAPE: 0.3651878535747528\n",
      "MSPE: 0.6687847375869751\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24467\n",
      "[DEBUG] Original dataset length: 24467\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22233\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3423\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "\titers: 100, epoch: 1 | loss: 0.4039428\n",
      "\tspeed: 0.0261s/iter; left time: 106.0763s\n",
      "\titers: 200, epoch: 1 | loss: 0.2784571\n",
      "\tspeed: 0.0253s/iter; left time: 100.1432s\n",
      "\titers: 300, epoch: 1 | loss: 0.5253747\n",
      "\tspeed: 0.0246s/iter; left time: 95.1055s\n",
      "\titers: 400, epoch: 1 | loss: 0.2525510\n",
      "\tspeed: 0.0277s/iter; left time: 104.1290s\n",
      "\titers: 500, epoch: 1 | loss: 0.1487749\n",
      "\tspeed: 0.0238s/iter; left time: 87.3545s\n",
      "\titers: 600, epoch: 1 | loss: 0.1662580\n",
      "\tspeed: 0.0260s/iter; left time: 92.5867s\n",
      "Epoch: 1 cost time: 17.72886347770691\n",
      "Epoch: 1, Steps: 694 | Train Loss: 0.2805522 Vali Loss: 0.3566460 Test Loss: 0.2844678\n",
      "Validation loss decreased (inf --> 0.356646).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1525078\n",
      "\tspeed: 0.0773s/iter; left time: 260.5867s\n",
      "\titers: 200, epoch: 2 | loss: 0.2582366\n",
      "\tspeed: 0.0276s/iter; left time: 90.2092s\n",
      "\titers: 300, epoch: 2 | loss: 0.1612046\n",
      "\tspeed: 0.0246s/iter; left time: 77.9337s\n",
      "\titers: 400, epoch: 2 | loss: 0.2719455\n",
      "\tspeed: 0.0251s/iter; left time: 77.0899s\n",
      "\titers: 500, epoch: 2 | loss: 0.2029378\n",
      "\tspeed: 0.0243s/iter; left time: 72.2550s\n",
      "\titers: 600, epoch: 2 | loss: 0.1531312\n",
      "\tspeed: 0.0256s/iter; left time: 73.4107s\n",
      "Epoch: 2 cost time: 17.5896577835083\n",
      "Epoch: 2, Steps: 694 | Train Loss: 0.2109424 Vali Loss: 0.3318719 Test Loss: 0.2763963\n",
      "Validation loss decreased (0.356646 --> 0.331872).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2234626\n",
      "\tspeed: 0.0802s/iter; left time: 214.7872s\n",
      "\titers: 200, epoch: 3 | loss: 0.1726478\n",
      "\tspeed: 0.0257s/iter; left time: 66.1543s\n",
      "\titers: 300, epoch: 3 | loss: 0.2923040\n",
      "\tspeed: 0.0249s/iter; left time: 61.5766s\n",
      "\titers: 400, epoch: 3 | loss: 0.2046906\n",
      "\tspeed: 0.0246s/iter; left time: 58.4860s\n",
      "\titers: 500, epoch: 3 | loss: 0.1344467\n",
      "\tspeed: 0.0245s/iter; left time: 55.7617s\n",
      "\titers: 600, epoch: 3 | loss: 0.1798038\n",
      "\tspeed: 0.0274s/iter; left time: 59.6498s\n",
      "Epoch: 3 cost time: 17.744879007339478\n",
      "Epoch: 3, Steps: 694 | Train Loss: 0.1829494 Vali Loss: 0.3307178 Test Loss: 0.2538470\n",
      "Validation loss decreased (0.331872 --> 0.330718).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1745115\n",
      "\tspeed: 0.0778s/iter; left time: 154.2143s\n",
      "\titers: 200, epoch: 4 | loss: 0.1453253\n",
      "\tspeed: 0.0252s/iter; left time: 47.4762s\n",
      "\titers: 300, epoch: 4 | loss: 0.1029684\n",
      "\tspeed: 0.0258s/iter; left time: 45.9812s\n",
      "\titers: 400, epoch: 4 | loss: 0.1685903\n",
      "\tspeed: 0.0254s/iter; left time: 42.8291s\n",
      "\titers: 500, epoch: 4 | loss: 0.1788940\n",
      "\tspeed: 0.0255s/iter; left time: 40.3456s\n",
      "\titers: 600, epoch: 4 | loss: 0.1607517\n",
      "\tspeed: 0.0265s/iter; left time: 39.3515s\n",
      "Epoch: 4 cost time: 17.690192222595215\n",
      "Epoch: 4, Steps: 694 | Train Loss: 0.1655909 Vali Loss: 0.3132521 Test Loss: 0.2513395\n",
      "Validation loss decreased (0.330718 --> 0.313252).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1221849\n",
      "\tspeed: 0.0810s/iter; left time: 104.3892s\n",
      "\titers: 200, epoch: 5 | loss: 0.1333274\n",
      "\tspeed: 0.0249s/iter; left time: 29.6607s\n",
      "\titers: 300, epoch: 5 | loss: 0.1628592\n",
      "\tspeed: 0.0259s/iter; left time: 28.1839s\n",
      "\titers: 400, epoch: 5 | loss: 0.1389243\n",
      "\tspeed: 0.0244s/iter; left time: 24.1126s\n",
      "\titers: 500, epoch: 5 | loss: 0.1563036\n",
      "\tspeed: 0.0250s/iter; left time: 22.2687s\n",
      "\titers: 600, epoch: 5 | loss: 0.1103525\n",
      "\tspeed: 0.0246s/iter; left time: 19.4107s\n",
      "Epoch: 5 cost time: 17.835129499435425\n",
      "Epoch: 5, Steps: 694 | Train Loss: 0.1570376 Vali Loss: 0.3166039 Test Loss: 0.2532886\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1888971\n",
      "\tspeed: 0.0780s/iter; left time: 46.4186s\n",
      "\titers: 200, epoch: 6 | loss: 0.1433958\n",
      "\tspeed: 0.0243s/iter; left time: 12.0087s\n",
      "\titers: 300, epoch: 6 | loss: 0.1081636\n",
      "\tspeed: 0.0250s/iter; left time: 9.8647s\n",
      "\titers: 400, epoch: 6 | loss: 0.1674747\n",
      "\tspeed: 0.0235s/iter; left time: 6.9450s\n",
      "\titers: 500, epoch: 6 | loss: 0.1313142\n",
      "\tspeed: 0.0261s/iter; left time: 5.0954s\n",
      "\titers: 600, epoch: 6 | loss: 0.1951635\n",
      "\tspeed: 0.0247s/iter; left time: 2.3419s\n",
      "Epoch: 6 cost time: 17.24839949607849\n",
      "Epoch: 6, Steps: 694 | Train Loss: 0.1514911 Vali Loss: 0.3133951 Test Loss: 0.2441896\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "Test cost time: 1.7891s\n",
      "test shape: (187, 32, 6, 1) (187, 32, 6, 1)\n",
      "test shape: (5984, 6, 1) (5984, 6, 1)\n",
      "mse:0.25086772441864014, mae:0.3563700318336487\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1717.8857421875\n",
      "MAE:  29.49007797241211\n",
      "RMSE: 41.447383880615234\n",
      "MAPE: 0.424684077501297\n",
      "MSPE: 0.8837221264839172\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24467\n",
      "[DEBUG] Original dataset length: 24467\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22233\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3423\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "\titers: 100, epoch: 1 | loss: 0.3430603\n",
      "\tspeed: 0.0258s/iter; left time: 104.9223s\n",
      "\titers: 200, epoch: 1 | loss: 0.2786937\n",
      "\tspeed: 0.0277s/iter; left time: 109.7649s\n",
      "\titers: 300, epoch: 1 | loss: 0.3571873\n",
      "\tspeed: 0.0256s/iter; left time: 98.9042s\n",
      "\titers: 400, epoch: 1 | loss: 0.2765152\n",
      "\tspeed: 0.0256s/iter; left time: 96.2553s\n",
      "\titers: 500, epoch: 1 | loss: 0.1967268\n",
      "\tspeed: 0.0264s/iter; left time: 96.6679s\n",
      "\titers: 600, epoch: 1 | loss: 0.2906364\n",
      "\tspeed: 0.0275s/iter; left time: 98.0908s\n",
      "Epoch: 1 cost time: 18.235947608947754\n",
      "Epoch: 1, Steps: 694 | Train Loss: 0.2796847 Vali Loss: 0.3214990 Test Loss: 0.2571988\n",
      "Validation loss decreased (inf --> 0.321499).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1462784\n",
      "\tspeed: 0.0785s/iter; left time: 264.6677s\n",
      "\titers: 200, epoch: 2 | loss: 0.2050264\n",
      "\tspeed: 0.0249s/iter; left time: 81.3494s\n",
      "\titers: 300, epoch: 2 | loss: 0.3074270\n",
      "\tspeed: 0.0245s/iter; left time: 77.5654s\n",
      "\titers: 400, epoch: 2 | loss: 0.1745635\n",
      "\tspeed: 0.0255s/iter; left time: 78.4095s\n",
      "\titers: 500, epoch: 2 | loss: 0.2850451\n",
      "\tspeed: 0.0264s/iter; left time: 78.3969s\n",
      "\titers: 600, epoch: 2 | loss: 0.2449945\n",
      "\tspeed: 0.0263s/iter; left time: 75.6113s\n",
      "Epoch: 2 cost time: 17.550727128982544\n",
      "Epoch: 2, Steps: 694 | Train Loss: 0.2107213 Vali Loss: 0.3115512 Test Loss: 0.2541990\n",
      "Validation loss decreased (0.321499 --> 0.311551).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1786151\n",
      "\tspeed: 0.0788s/iter; left time: 210.8951s\n",
      "\titers: 200, epoch: 3 | loss: 0.1594016\n",
      "\tspeed: 0.0270s/iter; left time: 69.4894s\n",
      "\titers: 300, epoch: 3 | loss: 0.1585838\n",
      "\tspeed: 0.0283s/iter; left time: 70.0566s\n",
      "\titers: 400, epoch: 3 | loss: 0.1406007\n",
      "\tspeed: 0.0249s/iter; left time: 59.1820s\n",
      "\titers: 500, epoch: 3 | loss: 0.1066036\n",
      "\tspeed: 0.0242s/iter; left time: 55.0028s\n",
      "\titers: 600, epoch: 3 | loss: 0.3447418\n",
      "\tspeed: 0.0247s/iter; left time: 53.8206s\n",
      "Epoch: 3 cost time: 17.91805148124695\n",
      "Epoch: 3, Steps: 694 | Train Loss: 0.1822421 Vali Loss: 0.3092482 Test Loss: 0.2440545\n",
      "Validation loss decreased (0.311551 --> 0.309248).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1849459\n",
      "\tspeed: 0.0797s/iter; left time: 158.1170s\n",
      "\titers: 200, epoch: 4 | loss: 0.1542125\n",
      "\tspeed: 0.0239s/iter; left time: 45.0122s\n",
      "\titers: 300, epoch: 4 | loss: 0.1585336\n",
      "\tspeed: 0.0248s/iter; left time: 44.2266s\n",
      "\titers: 400, epoch: 4 | loss: 0.1399030\n",
      "\tspeed: 0.0242s/iter; left time: 40.7567s\n",
      "\titers: 500, epoch: 4 | loss: 0.1654800\n",
      "\tspeed: 0.0240s/iter; left time: 38.0234s\n",
      "\titers: 600, epoch: 4 | loss: 0.1322191\n",
      "\tspeed: 0.0254s/iter; left time: 37.7305s\n",
      "Epoch: 4 cost time: 17.63982319831848\n",
      "Epoch: 4, Steps: 694 | Train Loss: 0.1682125 Vali Loss: 0.2996341 Test Loss: 0.2372149\n",
      "Validation loss decreased (0.309248 --> 0.299634).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1566457\n",
      "\tspeed: 0.0797s/iter; left time: 102.7262s\n",
      "\titers: 200, epoch: 5 | loss: 0.1067985\n",
      "\tspeed: 0.0245s/iter; left time: 29.1318s\n",
      "\titers: 300, epoch: 5 | loss: 0.1019668\n",
      "\tspeed: 0.0255s/iter; left time: 27.7750s\n",
      "\titers: 400, epoch: 5 | loss: 0.1526161\n",
      "\tspeed: 0.0239s/iter; left time: 23.6772s\n",
      "\titers: 500, epoch: 5 | loss: 0.1158882\n",
      "\tspeed: 0.0263s/iter; left time: 23.4200s\n",
      "\titers: 600, epoch: 5 | loss: 0.1516984\n",
      "\tspeed: 0.0246s/iter; left time: 19.4327s\n",
      "Epoch: 5 cost time: 17.508138179779053\n",
      "Epoch: 5, Steps: 694 | Train Loss: 0.1592099 Vali Loss: 0.3102481 Test Loss: 0.2398724\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1385091\n",
      "\tspeed: 0.0769s/iter; left time: 45.7462s\n",
      "\titers: 200, epoch: 6 | loss: 0.1556720\n",
      "\tspeed: 0.0271s/iter; left time: 13.3956s\n",
      "\titers: 300, epoch: 6 | loss: 0.1272038\n",
      "\tspeed: 0.0266s/iter; left time: 10.5018s\n",
      "\titers: 400, epoch: 6 | loss: 0.1107124\n",
      "\tspeed: 0.0245s/iter; left time: 7.2296s\n",
      "\titers: 500, epoch: 6 | loss: 0.1103693\n",
      "\tspeed: 0.0256s/iter; left time: 4.9932s\n",
      "\titers: 600, epoch: 6 | loss: 0.1576822\n",
      "\tspeed: 0.0252s/iter; left time: 2.3904s\n",
      "Epoch: 6 cost time: 17.729400396347046\n",
      "Epoch: 6, Steps: 694 | Train Loss: 0.1533890 Vali Loss: 0.3063022 Test Loss: 0.2375571\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "Test cost time: 1.7955s\n",
      "test shape: (187, 32, 6, 1) (187, 32, 6, 1)\n",
      "test shape: (5984, 6, 1) (5984, 6, 1)\n",
      "mse:0.23631250858306885, mae:0.3261943757534027\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1618.2149658203125\n",
      "MAE:  26.993003845214844\n",
      "RMSE: 40.22704315185547\n",
      "MAPE: 0.3336186408996582\n",
      "MSPE: 0.49564218521118164\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24467\n",
      "[DEBUG] Original dataset length: 24467\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22233\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3423\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "\titers: 100, epoch: 1 | loss: 0.3797213\n",
      "\tspeed: 0.0254s/iter; left time: 103.3534s\n",
      "\titers: 200, epoch: 1 | loss: 0.2658587\n",
      "\tspeed: 0.0240s/iter; left time: 95.1690s\n",
      "\titers: 300, epoch: 1 | loss: 0.2774786\n",
      "\tspeed: 0.0253s/iter; left time: 97.7378s\n",
      "\titers: 400, epoch: 1 | loss: 0.2616599\n",
      "\tspeed: 0.0241s/iter; left time: 90.8215s\n",
      "\titers: 500, epoch: 1 | loss: 0.1479681\n",
      "\tspeed: 0.0269s/iter; left time: 98.5676s\n",
      "\titers: 600, epoch: 1 | loss: 0.2252750\n",
      "\tspeed: 0.0258s/iter; left time: 91.9946s\n",
      "Epoch: 1 cost time: 17.603575229644775\n",
      "Epoch: 1, Steps: 694 | Train Loss: 0.2701321 Vali Loss: 0.3307036 Test Loss: 0.2640558\n",
      "Validation loss decreased (inf --> 0.330704).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1827703\n",
      "\tspeed: 0.0780s/iter; left time: 262.9795s\n",
      "\titers: 200, epoch: 2 | loss: 0.1555070\n",
      "\tspeed: 0.0235s/iter; left time: 76.8177s\n",
      "\titers: 300, epoch: 2 | loss: 0.2358910\n",
      "\tspeed: 0.0266s/iter; left time: 84.2985s\n",
      "\titers: 400, epoch: 2 | loss: 0.1895819\n",
      "\tspeed: 0.0259s/iter; left time: 79.5376s\n",
      "\titers: 500, epoch: 2 | loss: 0.3034494\n",
      "\tspeed: 0.0251s/iter; left time: 74.4971s\n",
      "\titers: 600, epoch: 2 | loss: 0.2377888\n",
      "\tspeed: 0.0247s/iter; left time: 71.0326s\n",
      "Epoch: 2 cost time: 17.52108335494995\n",
      "Epoch: 2, Steps: 694 | Train Loss: 0.2082006 Vali Loss: 0.3650741 Test Loss: 0.2866856\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1330291\n",
      "\tspeed: 0.0787s/iter; left time: 210.7586s\n",
      "\titers: 200, epoch: 3 | loss: 0.1535851\n",
      "\tspeed: 0.0251s/iter; left time: 64.6841s\n",
      "\titers: 300, epoch: 3 | loss: 0.1597961\n",
      "\tspeed: 0.0246s/iter; left time: 60.8911s\n",
      "\titers: 400, epoch: 3 | loss: 0.1834296\n",
      "\tspeed: 0.0251s/iter; left time: 59.7623s\n",
      "\titers: 500, epoch: 3 | loss: 0.1039628\n",
      "\tspeed: 0.0252s/iter; left time: 57.3726s\n",
      "\titers: 600, epoch: 3 | loss: 0.3041816\n",
      "\tspeed: 0.0244s/iter; left time: 53.1780s\n",
      "Epoch: 3 cost time: 17.673607349395752\n",
      "Epoch: 3, Steps: 694 | Train Loss: 0.1811571 Vali Loss: 0.3062214 Test Loss: 0.2410927\n",
      "Validation loss decreased (0.330704 --> 0.306221).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1470412\n",
      "\tspeed: 0.0782s/iter; left time: 155.1098s\n",
      "\titers: 200, epoch: 4 | loss: 0.0982060\n",
      "\tspeed: 0.0245s/iter; left time: 46.1356s\n",
      "\titers: 300, epoch: 4 | loss: 0.1559468\n",
      "\tspeed: 0.0250s/iter; left time: 44.6374s\n",
      "\titers: 400, epoch: 4 | loss: 0.1886702\n",
      "\tspeed: 0.0242s/iter; left time: 40.6676s\n",
      "\titers: 500, epoch: 4 | loss: 0.1240326\n",
      "\tspeed: 0.0269s/iter; left time: 42.6446s\n",
      "\titers: 600, epoch: 4 | loss: 0.1241009\n",
      "\tspeed: 0.0259s/iter; left time: 38.4714s\n",
      "Epoch: 4 cost time: 17.594051361083984\n",
      "Epoch: 4, Steps: 694 | Train Loss: 0.1659106 Vali Loss: 0.3102137 Test Loss: 0.2393160\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1419973\n",
      "\tspeed: 0.0774s/iter; left time: 99.7194s\n",
      "\titers: 200, epoch: 5 | loss: 0.2202415\n",
      "\tspeed: 0.0248s/iter; left time: 29.4599s\n",
      "\titers: 300, epoch: 5 | loss: 0.1255039\n",
      "\tspeed: 0.0265s/iter; left time: 28.8223s\n",
      "\titers: 400, epoch: 5 | loss: 0.1939327\n",
      "\tspeed: 0.0249s/iter; left time: 24.6057s\n",
      "\titers: 500, epoch: 5 | loss: 0.1403320\n",
      "\tspeed: 0.0245s/iter; left time: 21.7571s\n",
      "\titers: 600, epoch: 5 | loss: 0.2212058\n",
      "\tspeed: 0.0247s/iter; left time: 19.5040s\n",
      "Epoch: 5 cost time: 17.382118701934814\n",
      "Epoch: 5, Steps: 694 | Train Loss: 0.1569570 Vali Loss: 0.3106359 Test Loss: 0.2450630\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0970709\n",
      "\tspeed: 0.0765s/iter; left time: 45.5134s\n",
      "\titers: 200, epoch: 6 | loss: 0.1573481\n",
      "\tspeed: 0.0251s/iter; left time: 12.4203s\n",
      "\titers: 300, epoch: 6 | loss: 0.1065111\n",
      "\tspeed: 0.0248s/iter; left time: 9.7978s\n",
      "\titers: 400, epoch: 6 | loss: 0.1247957\n",
      "\tspeed: 0.0263s/iter; left time: 7.7557s\n",
      "\titers: 500, epoch: 6 | loss: 0.1928040\n",
      "\tspeed: 0.0247s/iter; left time: 4.8119s\n",
      "\titers: 600, epoch: 6 | loss: 0.2334690\n",
      "\tspeed: 0.0252s/iter; left time: 2.3894s\n",
      "Epoch: 6 cost time: 17.698272466659546\n",
      "Epoch: 6, Steps: 694 | Train Loss: 0.1518171 Vali Loss: 0.3097943 Test Loss: 0.2445479\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "Test cost time: 1.7307s\n",
      "test shape: (187, 32, 6, 1) (187, 32, 6, 1)\n",
      "test shape: (5984, 6, 1) (5984, 6, 1)\n",
      "mse:0.24168165028095245, mae:0.34000831842422485\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1654.9814453125\n",
      "MAE:  28.136123657226562\n",
      "RMSE: 40.681461334228516\n",
      "MAPE: 0.4224822223186493\n",
      "MSPE: 0.9310972690582275\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24467\n",
      "[DEBUG] Original dataset length: 24467\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22233\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3423\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "\titers: 100, epoch: 1 | loss: 0.2827383\n",
      "\tspeed: 0.0250s/iter; left time: 101.7105s\n",
      "\titers: 200, epoch: 1 | loss: 0.3517233\n",
      "\tspeed: 0.0238s/iter; left time: 94.4457s\n",
      "\titers: 300, epoch: 1 | loss: 0.4336426\n",
      "\tspeed: 0.0253s/iter; left time: 97.7774s\n",
      "\titers: 400, epoch: 1 | loss: 0.1709739\n",
      "\tspeed: 0.0274s/iter; left time: 103.0733s\n",
      "\titers: 500, epoch: 1 | loss: 0.2204542\n",
      "\tspeed: 0.0257s/iter; left time: 94.1625s\n",
      "\titers: 600, epoch: 1 | loss: 0.1877696\n",
      "\tspeed: 0.0270s/iter; left time: 96.0944s\n",
      "Epoch: 1 cost time: 17.802618741989136\n",
      "Epoch: 1, Steps: 694 | Train Loss: 0.2819516 Vali Loss: 0.3740912 Test Loss: 0.3092308\n",
      "Validation loss decreased (inf --> 0.374091).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2559817\n",
      "\tspeed: 0.0788s/iter; left time: 265.6787s\n",
      "\titers: 200, epoch: 2 | loss: 0.2341548\n",
      "\tspeed: 0.0257s/iter; left time: 83.9941s\n",
      "\titers: 300, epoch: 2 | loss: 0.2535928\n",
      "\tspeed: 0.0257s/iter; left time: 81.4820s\n",
      "\titers: 400, epoch: 2 | loss: 0.3300191\n",
      "\tspeed: 0.0264s/iter; left time: 81.0659s\n",
      "\titers: 500, epoch: 2 | loss: 0.1838703\n",
      "\tspeed: 0.0268s/iter; left time: 79.6587s\n",
      "\titers: 600, epoch: 2 | loss: 0.1710252\n",
      "\tspeed: 0.0271s/iter; left time: 77.7796s\n",
      "Epoch: 2 cost time: 18.259507179260254\n",
      "Epoch: 2, Steps: 694 | Train Loss: 0.2100893 Vali Loss: 0.3219248 Test Loss: 0.2545097\n",
      "Validation loss decreased (0.374091 --> 0.321925).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1799448\n",
      "\tspeed: 0.0814s/iter; left time: 217.7980s\n",
      "\titers: 200, epoch: 3 | loss: 0.3036849\n",
      "\tspeed: 0.0278s/iter; left time: 71.5190s\n",
      "\titers: 300, epoch: 3 | loss: 0.2459312\n",
      "\tspeed: 0.0263s/iter; left time: 65.1392s\n",
      "\titers: 400, epoch: 3 | loss: 0.1464523\n",
      "\tspeed: 0.0273s/iter; left time: 64.8374s\n",
      "\titers: 500, epoch: 3 | loss: 0.1344627\n",
      "\tspeed: 0.0274s/iter; left time: 62.4429s\n",
      "\titers: 600, epoch: 3 | loss: 0.1662224\n",
      "\tspeed: 0.0260s/iter; left time: 56.5715s\n",
      "Epoch: 3 cost time: 18.64191699028015\n",
      "Epoch: 3, Steps: 694 | Train Loss: 0.1804822 Vali Loss: 0.3290612 Test Loss: 0.2620697\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2229205\n",
      "\tspeed: 0.0768s/iter; left time: 152.3699s\n",
      "\titers: 200, epoch: 4 | loss: 0.1698362\n",
      "\tspeed: 0.0251s/iter; left time: 47.3403s\n",
      "\titers: 300, epoch: 4 | loss: 0.1427078\n",
      "\tspeed: 0.0242s/iter; left time: 43.1364s\n",
      "\titers: 400, epoch: 4 | loss: 0.2358326\n",
      "\tspeed: 0.0254s/iter; left time: 42.7760s\n",
      "\titers: 500, epoch: 4 | loss: 0.1264798\n",
      "\tspeed: 0.0247s/iter; left time: 39.1408s\n",
      "\titers: 600, epoch: 4 | loss: 0.2011376\n",
      "\tspeed: 0.0259s/iter; left time: 38.3818s\n",
      "Epoch: 4 cost time: 17.39179491996765\n",
      "Epoch: 4, Steps: 694 | Train Loss: 0.1653732 Vali Loss: 0.3256924 Test Loss: 0.2605685\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1208988\n",
      "\tspeed: 0.0784s/iter; left time: 100.9947s\n",
      "\titers: 200, epoch: 5 | loss: 0.1106549\n",
      "\tspeed: 0.0246s/iter; left time: 29.3011s\n",
      "\titers: 300, epoch: 5 | loss: 0.2252755\n",
      "\tspeed: 0.0242s/iter; left time: 26.4003s\n",
      "\titers: 400, epoch: 5 | loss: 0.1708536\n",
      "\tspeed: 0.0249s/iter; left time: 24.6041s\n",
      "\titers: 500, epoch: 5 | loss: 0.1338071\n",
      "\tspeed: 0.0241s/iter; left time: 21.4468s\n",
      "\titers: 600, epoch: 5 | loss: 0.0914249\n",
      "\tspeed: 0.0251s/iter; left time: 19.8081s\n",
      "Epoch: 5 cost time: 17.083539247512817\n",
      "Epoch: 5, Steps: 694 | Train Loss: 0.1568119 Vali Loss: 0.3106067 Test Loss: 0.2450749\n",
      "Validation loss decreased (0.321925 --> 0.310607).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3333494\n",
      "\tspeed: 0.0767s/iter; left time: 45.6358s\n",
      "\titers: 200, epoch: 6 | loss: 0.1965306\n",
      "\tspeed: 0.0268s/iter; left time: 13.2725s\n",
      "\titers: 300, epoch: 6 | loss: 0.1555898\n",
      "\tspeed: 0.0249s/iter; left time: 9.8459s\n",
      "\titers: 400, epoch: 6 | loss: 0.1360691\n",
      "\tspeed: 0.0269s/iter; left time: 7.9285s\n",
      "\titers: 500, epoch: 6 | loss: 0.1151728\n",
      "\tspeed: 0.0246s/iter; left time: 4.7916s\n",
      "\titers: 600, epoch: 6 | loss: 0.1145430\n",
      "\tspeed: 0.0250s/iter; left time: 2.3725s\n",
      "Epoch: 6 cost time: 17.684844493865967\n",
      "Epoch: 6, Steps: 694 | Train Loss: 0.1523245 Vali Loss: 0.3070359 Test Loss: 0.2465052\n",
      "Validation loss decreased (0.310607 --> 0.307036).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "Test cost time: 1.7157s\n",
      "test shape: (187, 32, 6, 1) (187, 32, 6, 1)\n",
      "test shape: (5984, 6, 1) (5984, 6, 1)\n",
      "mse:0.24552392959594727, mae:0.3262248635292053\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1681.292724609375\n",
      "MAE:  26.995525360107422\n",
      "RMSE: 41.003570556640625\n",
      "MAPE: 0.3214244544506073\n",
      "MSPE: 0.4447535574436188\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24467\n",
      "[DEBUG] Original dataset length: 24467\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 22233\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3423\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "\titers: 100, epoch: 1 | loss: 0.2119062\n",
      "\tspeed: 0.0285s/iter; left time: 115.9234s\n",
      "\titers: 200, epoch: 1 | loss: 0.1774032\n",
      "\tspeed: 0.0250s/iter; left time: 99.2653s\n",
      "\titers: 300, epoch: 1 | loss: 0.1809429\n",
      "\tspeed: 0.0243s/iter; left time: 94.0961s\n",
      "\titers: 400, epoch: 1 | loss: 0.2875485\n",
      "\tspeed: 0.0241s/iter; left time: 90.7050s\n",
      "\titers: 500, epoch: 1 | loss: 0.2138849\n",
      "\tspeed: 0.0242s/iter; left time: 88.6536s\n",
      "\titers: 600, epoch: 1 | loss: 0.1619875\n",
      "\tspeed: 0.0251s/iter; left time: 89.4988s\n",
      "Epoch: 1 cost time: 17.509568452835083\n",
      "Epoch: 1, Steps: 694 | Train Loss: 0.2715796 Vali Loss: 0.3164892 Test Loss: 0.2604108\n",
      "Validation loss decreased (inf --> 0.316489).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1720259\n",
      "\tspeed: 0.0760s/iter; left time: 256.3537s\n",
      "\titers: 200, epoch: 2 | loss: 0.1845128\n",
      "\tspeed: 0.0240s/iter; left time: 78.4058s\n",
      "\titers: 300, epoch: 2 | loss: 0.1788667\n",
      "\tspeed: 0.0252s/iter; left time: 79.8012s\n",
      "\titers: 400, epoch: 2 | loss: 0.1648845\n",
      "\tspeed: 0.0242s/iter; left time: 74.3116s\n",
      "\titers: 500, epoch: 2 | loss: 0.2234200\n",
      "\tspeed: 0.0267s/iter; left time: 79.3823s\n",
      "\titers: 600, epoch: 2 | loss: 0.2498256\n",
      "\tspeed: 0.0256s/iter; left time: 73.3815s\n",
      "Epoch: 2 cost time: 17.313865900039673\n",
      "Epoch: 2, Steps: 694 | Train Loss: 0.2065717 Vali Loss: 0.3243748 Test Loss: 0.2625147\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2054175\n",
      "\tspeed: 0.0779s/iter; left time: 208.5018s\n",
      "\titers: 200, epoch: 3 | loss: 0.1868033\n",
      "\tspeed: 0.0262s/iter; left time: 67.5972s\n",
      "\titers: 300, epoch: 3 | loss: 0.1451205\n",
      "\tspeed: 0.0259s/iter; left time: 64.2671s\n",
      "\titers: 400, epoch: 3 | loss: 0.2474605\n",
      "\tspeed: 0.0239s/iter; left time: 56.7394s\n",
      "\titers: 500, epoch: 3 | loss: 0.1491046\n",
      "\tspeed: 0.0241s/iter; left time: 54.9177s\n",
      "\titers: 600, epoch: 3 | loss: 0.1880092\n",
      "\tspeed: 0.0243s/iter; left time: 52.8902s\n",
      "Epoch: 3 cost time: 17.353620052337646\n",
      "Epoch: 3, Steps: 694 | Train Loss: 0.1798715 Vali Loss: 0.3043353 Test Loss: 0.2447154\n",
      "Validation loss decreased (0.316489 --> 0.304335).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1423759\n",
      "\tspeed: 0.0785s/iter; left time: 155.7194s\n",
      "\titers: 200, epoch: 4 | loss: 0.1602405\n",
      "\tspeed: 0.0247s/iter; left time: 46.6025s\n",
      "\titers: 300, epoch: 4 | loss: 0.1673132\n",
      "\tspeed: 0.0249s/iter; left time: 44.3482s\n",
      "\titers: 400, epoch: 4 | loss: 0.2239697\n",
      "\tspeed: 0.0254s/iter; left time: 42.7612s\n",
      "\titers: 500, epoch: 4 | loss: 0.1514246\n",
      "\tspeed: 0.0243s/iter; left time: 38.4109s\n",
      "\titers: 600, epoch: 4 | loss: 0.1440474\n",
      "\tspeed: 0.0261s/iter; left time: 38.7536s\n",
      "Epoch: 4 cost time: 17.78390121459961\n",
      "Epoch: 4, Steps: 694 | Train Loss: 0.1656133 Vali Loss: 0.2957860 Test Loss: 0.2439236\n",
      "Validation loss decreased (0.304335 --> 0.295786).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1901167\n",
      "\tspeed: 0.0801s/iter; left time: 103.2698s\n",
      "\titers: 200, epoch: 5 | loss: 0.1065632\n",
      "\tspeed: 0.0241s/iter; left time: 28.6085s\n",
      "\titers: 300, epoch: 5 | loss: 0.1012249\n",
      "\tspeed: 0.0246s/iter; left time: 26.8112s\n",
      "\titers: 400, epoch: 5 | loss: 0.1135660\n",
      "\tspeed: 0.0255s/iter; left time: 25.2435s\n",
      "\titers: 500, epoch: 5 | loss: 0.1072739\n",
      "\tspeed: 0.0263s/iter; left time: 23.4148s\n",
      "\titers: 600, epoch: 5 | loss: 0.1858619\n",
      "\tspeed: 0.0243s/iter; left time: 19.2112s\n",
      "Epoch: 5 cost time: 17.463953256607056\n",
      "Epoch: 5, Steps: 694 | Train Loss: 0.1569550 Vali Loss: 0.3125770 Test Loss: 0.2501730\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1072491\n",
      "\tspeed: 0.0770s/iter; left time: 45.8327s\n",
      "\titers: 200, epoch: 6 | loss: 0.1196335\n",
      "\tspeed: 0.0270s/iter; left time: 13.3731s\n",
      "\titers: 300, epoch: 6 | loss: 0.1228994\n",
      "\tspeed: 0.0257s/iter; left time: 10.1677s\n",
      "\titers: 400, epoch: 6 | loss: 0.1587921\n",
      "\tspeed: 0.0247s/iter; left time: 7.2940s\n",
      "\titers: 500, epoch: 6 | loss: 0.1584047\n",
      "\tspeed: 0.0257s/iter; left time: 5.0049s\n",
      "\titers: 600, epoch: 6 | loss: 0.1401382\n",
      "\tspeed: 0.0240s/iter; left time: 2.2816s\n",
      "Epoch: 6 cost time: 17.60878896713257\n",
      "Epoch: 6, Steps: 694 | Train Loss: 0.1519130 Vali Loss: 0.2952696 Test Loss: 0.2404821\n",
      "Validation loss decreased (0.295786 --> 0.295270).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "Test cost time: 1.7329s\n",
      "test shape: (187, 32, 6, 1) (187, 32, 6, 1)\n",
      "test shape: (5984, 6, 1) (5984, 6, 1)\n",
      "mse:0.24053698778152466, mae:0.328543484210968\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1647.1435546875\n",
      "MAE:  27.187397003173828\n",
      "RMSE: 40.585018157958984\n",
      "MAPE: 0.3479536473751068\n",
      "MSPE: 0.5949198007583618\n",
      ">>>>>>>Running time saved<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Running seq_len=96\n",
      "Args in experiment:\n",
      "Namespace(model='informer', data='traffic_full', root_path='../', data_path='traffic_full.csv', features='S', target='flow', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=24, pred_len=6, enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=2, d_layers=1, s_layers=[3, 2, 1], d_ff=2048, factor=5, padding=0, distil=True, dropout=0.05, attn='prob', embed='timeF', activation='gelu', output_attention=False, do_predict=False, mix=True, cols=None, num_workers=0, itr=10, train_epochs=6, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, inverse=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', detail_freq='h')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24443\n",
      "[DEBUG] Original dataset length: 24443\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21825\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3399\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "\titers: 100, epoch: 1 | loss: 0.2606433\n",
      "\tspeed: 0.0414s/iter; left time: 165.3887s\n",
      "\titers: 200, epoch: 1 | loss: 0.2226450\n",
      "\tspeed: 0.0275s/iter; left time: 107.0616s\n",
      "\titers: 300, epoch: 1 | loss: 0.2953896\n",
      "\tspeed: 0.0299s/iter; left time: 113.3767s\n",
      "\titers: 400, epoch: 1 | loss: 0.1607261\n",
      "\tspeed: 0.0280s/iter; left time: 103.4055s\n",
      "\titers: 500, epoch: 1 | loss: 0.2511277\n",
      "\tspeed: 0.0273s/iter; left time: 98.0036s\n",
      "\titers: 600, epoch: 1 | loss: 0.2617537\n",
      "\tspeed: 0.0284s/iter; left time: 99.1990s\n",
      "Epoch: 1 cost time: 19.632600784301758\n",
      "Epoch: 1, Steps: 682 | Train Loss: 0.2787509 Vali Loss: 0.3212744 Test Loss: 0.2682815\n",
      "Validation loss decreased (inf --> 0.321274).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2218069\n",
      "\tspeed: 0.0822s/iter; left time: 272.1905s\n",
      "\titers: 200, epoch: 2 | loss: 0.2460992\n",
      "\tspeed: 0.0275s/iter; left time: 88.4030s\n",
      "\titers: 300, epoch: 2 | loss: 0.1526352\n",
      "\tspeed: 0.0276s/iter; left time: 85.7390s\n",
      "\titers: 400, epoch: 2 | loss: 0.1645587\n",
      "\tspeed: 0.0285s/iter; left time: 85.8953s\n",
      "\titers: 500, epoch: 2 | loss: 0.1623849\n",
      "\tspeed: 0.0272s/iter; left time: 79.1368s\n",
      "\titers: 600, epoch: 2 | loss: 0.1824595\n",
      "\tspeed: 0.0295s/iter; left time: 82.8313s\n",
      "Epoch: 2 cost time: 19.03902816772461\n",
      "Epoch: 2, Steps: 682 | Train Loss: 0.2106340 Vali Loss: 0.3376380 Test Loss: 0.2839659\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1137042\n",
      "\tspeed: 0.0808s/iter; left time: 212.4746s\n",
      "\titers: 200, epoch: 3 | loss: 0.2215439\n",
      "\tspeed: 0.0283s/iter; left time: 71.5737s\n",
      "\titers: 300, epoch: 3 | loss: 0.1838679\n",
      "\tspeed: 0.0293s/iter; left time: 71.1557s\n",
      "\titers: 400, epoch: 3 | loss: 0.1761702\n",
      "\tspeed: 0.0281s/iter; left time: 65.3393s\n",
      "\titers: 500, epoch: 3 | loss: 0.1404851\n",
      "\tspeed: 0.0275s/iter; left time: 61.2320s\n",
      "\titers: 600, epoch: 3 | loss: 0.2454724\n",
      "\tspeed: 0.0277s/iter; left time: 58.9877s\n",
      "Epoch: 3 cost time: 19.09357976913452\n",
      "Epoch: 3, Steps: 682 | Train Loss: 0.1795995 Vali Loss: 0.3076297 Test Loss: 0.2493220\n",
      "Validation loss decreased (0.321274 --> 0.307630).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1465688\n",
      "\tspeed: 0.0809s/iter; left time: 157.5168s\n",
      "\titers: 200, epoch: 4 | loss: 0.1719520\n",
      "\tspeed: 0.0275s/iter; left time: 50.7957s\n",
      "\titers: 300, epoch: 4 | loss: 0.1352011\n",
      "\tspeed: 0.0271s/iter; left time: 47.4098s\n",
      "\titers: 400, epoch: 4 | loss: 0.1210611\n",
      "\tspeed: 0.0278s/iter; left time: 45.7567s\n",
      "\titers: 500, epoch: 4 | loss: 0.1455963\n",
      "\tspeed: 0.0286s/iter; left time: 44.2058s\n",
      "\titers: 600, epoch: 4 | loss: 0.1083719\n",
      "\tspeed: 0.0288s/iter; left time: 41.7039s\n",
      "Epoch: 4 cost time: 19.06682014465332\n",
      "Epoch: 4, Steps: 682 | Train Loss: 0.1650796 Vali Loss: 0.3081255 Test Loss: 0.2477869\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1332861\n",
      "\tspeed: 0.0803s/iter; left time: 101.5477s\n",
      "\titers: 200, epoch: 5 | loss: 0.2968110\n",
      "\tspeed: 0.0274s/iter; left time: 31.8754s\n",
      "\titers: 300, epoch: 5 | loss: 0.1907922\n",
      "\tspeed: 0.0287s/iter; left time: 30.6147s\n",
      "\titers: 400, epoch: 5 | loss: 0.1441205\n",
      "\tspeed: 0.0288s/iter; left time: 27.7818s\n",
      "\titers: 500, epoch: 5 | loss: 0.1242176\n",
      "\tspeed: 0.0277s/iter; left time: 23.9345s\n",
      "\titers: 600, epoch: 5 | loss: 0.3008566\n",
      "\tspeed: 0.0266s/iter; left time: 20.3326s\n",
      "Epoch: 5 cost time: 18.988184928894043\n",
      "Epoch: 5, Steps: 682 | Train Loss: 0.1572779 Vali Loss: 0.3097733 Test Loss: 0.2452164\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1416904\n",
      "\tspeed: 0.0787s/iter; left time: 45.8818s\n",
      "\titers: 200, epoch: 6 | loss: 0.1988188\n",
      "\tspeed: 0.0268s/iter; left time: 12.9389s\n",
      "\titers: 300, epoch: 6 | loss: 0.1289576\n",
      "\tspeed: 0.0280s/iter; left time: 10.7397s\n",
      "\titers: 400, epoch: 6 | loss: 0.2322101\n",
      "\tspeed: 0.0264s/iter; left time: 7.4734s\n",
      "\titers: 500, epoch: 6 | loss: 0.0988267\n",
      "\tspeed: 0.0270s/iter; left time: 4.9403s\n",
      "\titers: 600, epoch: 6 | loss: 0.1260689\n",
      "\tspeed: 0.0273s/iter; left time: 2.2623s\n",
      "Epoch: 6 cost time: 18.586328983306885\n",
      "Epoch: 6, Steps: 682 | Train Loss: 0.1514850 Vali Loss: 0.3069593 Test Loss: 0.2444064\n",
      "Validation loss decreased (0.307630 --> 0.306959).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "Test cost time: 1.8368s\n",
      "test shape: (182, 32, 6, 1) (182, 32, 6, 1)\n",
      "test shape: (5824, 6, 1) (5824, 6, 1)\n",
      "mse:0.2452978938817978, mae:0.3370445668697357\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1679.744873046875\n",
      "MAE:  27.890871047973633\n",
      "RMSE: 40.98469161987305\n",
      "MAPE: 0.3945625424385071\n",
      "MSPE: 0.8041302561759949\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24443\n",
      "[DEBUG] Original dataset length: 24443\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21825\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3399\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "\titers: 100, epoch: 1 | loss: 0.2940768\n",
      "\tspeed: 0.0257s/iter; left time: 102.4516s\n",
      "\titers: 200, epoch: 1 | loss: 0.3284296\n",
      "\tspeed: 0.0266s/iter; left time: 103.3708s\n",
      "\titers: 300, epoch: 1 | loss: 0.5083297\n",
      "\tspeed: 0.0276s/iter; left time: 104.7453s\n",
      "\titers: 400, epoch: 1 | loss: 0.1898585\n",
      "\tspeed: 0.0267s/iter; left time: 98.6148s\n",
      "\titers: 500, epoch: 1 | loss: 0.1682469\n",
      "\tspeed: 0.0249s/iter; left time: 89.5333s\n",
      "\titers: 600, epoch: 1 | loss: 0.1467154\n",
      "\tspeed: 0.0268s/iter; left time: 93.7603s\n",
      "Epoch: 1 cost time: 18.010262966156006\n",
      "Epoch: 1, Steps: 682 | Train Loss: 0.2857738 Vali Loss: 0.3609137 Test Loss: 0.3039478\n",
      "Validation loss decreased (inf --> 0.360914).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2223784\n",
      "\tspeed: 0.0800s/iter; left time: 264.7392s\n",
      "\titers: 200, epoch: 2 | loss: 0.3151253\n",
      "\tspeed: 0.0269s/iter; left time: 86.3957s\n",
      "\titers: 300, epoch: 2 | loss: 0.1210879\n",
      "\tspeed: 0.0268s/iter; left time: 83.3667s\n",
      "\titers: 400, epoch: 2 | loss: 0.1714990\n",
      "\tspeed: 0.0263s/iter; left time: 79.1732s\n",
      "\titers: 500, epoch: 2 | loss: 0.1932441\n",
      "\tspeed: 0.0259s/iter; left time: 75.3372s\n",
      "\titers: 600, epoch: 2 | loss: 0.2078588\n",
      "\tspeed: 0.0281s/iter; left time: 78.9516s\n",
      "Epoch: 2 cost time: 18.466484785079956\n",
      "Epoch: 2, Steps: 682 | Train Loss: 0.2089195 Vali Loss: 0.3131611 Test Loss: 0.2527855\n",
      "Validation loss decreased (0.360914 --> 0.313161).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1654541\n",
      "\tspeed: 0.0786s/iter; left time: 206.6171s\n",
      "\titers: 200, epoch: 3 | loss: 0.0893412\n",
      "\tspeed: 0.0270s/iter; left time: 68.2615s\n",
      "\titers: 300, epoch: 3 | loss: 0.1162733\n",
      "\tspeed: 0.0279s/iter; left time: 67.7551s\n",
      "\titers: 400, epoch: 3 | loss: 0.1921985\n",
      "\tspeed: 0.0290s/iter; left time: 67.4881s\n",
      "\titers: 500, epoch: 3 | loss: 0.1814862\n",
      "\tspeed: 0.0264s/iter; left time: 58.8584s\n",
      "\titers: 600, epoch: 3 | loss: 0.1275392\n",
      "\tspeed: 0.0267s/iter; left time: 56.8359s\n",
      "Epoch: 3 cost time: 18.505163431167603\n",
      "Epoch: 3, Steps: 682 | Train Loss: 0.1821936 Vali Loss: 0.3138882 Test Loss: 0.2507607\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1736947\n",
      "\tspeed: 0.0792s/iter; left time: 154.1064s\n",
      "\titers: 200, epoch: 4 | loss: 0.1360120\n",
      "\tspeed: 0.0289s/iter; left time: 53.3379s\n",
      "\titers: 300, epoch: 4 | loss: 0.1910107\n",
      "\tspeed: 0.0265s/iter; left time: 46.2876s\n",
      "\titers: 400, epoch: 4 | loss: 0.1642022\n",
      "\tspeed: 0.0264s/iter; left time: 43.5525s\n",
      "\titers: 500, epoch: 4 | loss: 0.1855784\n",
      "\tspeed: 0.0260s/iter; left time: 40.2177s\n",
      "\titers: 600, epoch: 4 | loss: 0.1623384\n",
      "\tspeed: 0.0265s/iter; left time: 38.2758s\n",
      "Epoch: 4 cost time: 18.4733304977417\n",
      "Epoch: 4, Steps: 682 | Train Loss: 0.1658855 Vali Loss: 0.3121462 Test Loss: 0.2434208\n",
      "Validation loss decreased (0.313161 --> 0.312146).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1242552\n",
      "\tspeed: 0.0806s/iter; left time: 101.9761s\n",
      "\titers: 200, epoch: 5 | loss: 0.1874044\n",
      "\tspeed: 0.0264s/iter; left time: 30.8087s\n",
      "\titers: 300, epoch: 5 | loss: 0.1062739\n",
      "\tspeed: 0.0266s/iter; left time: 28.2808s\n",
      "\titers: 400, epoch: 5 | loss: 0.1269882\n",
      "\tspeed: 0.0264s/iter; left time: 25.4604s\n",
      "\titers: 500, epoch: 5 | loss: 0.1628805\n",
      "\tspeed: 0.0286s/iter; left time: 24.7203s\n",
      "\titers: 600, epoch: 5 | loss: 0.1510099\n",
      "\tspeed: 0.0266s/iter; left time: 20.3348s\n",
      "Epoch: 5 cost time: 18.371346950531006\n",
      "Epoch: 5, Steps: 682 | Train Loss: 0.1569139 Vali Loss: 0.3144073 Test Loss: 0.2473753\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1386060\n",
      "\tspeed: 0.0779s/iter; left time: 45.3938s\n",
      "\titers: 200, epoch: 6 | loss: 0.2467897\n",
      "\tspeed: 0.0274s/iter; left time: 13.2347s\n",
      "\titers: 300, epoch: 6 | loss: 0.1108377\n",
      "\tspeed: 0.0280s/iter; left time: 10.7156s\n",
      "\titers: 400, epoch: 6 | loss: 0.1117009\n",
      "\tspeed: 0.0260s/iter; left time: 7.3636s\n",
      "\titers: 500, epoch: 6 | loss: 0.1212313\n",
      "\tspeed: 0.0266s/iter; left time: 4.8743s\n",
      "\titers: 600, epoch: 6 | loss: 0.1741684\n",
      "\tspeed: 0.0270s/iter; left time: 2.2396s\n",
      "Epoch: 6 cost time: 18.455265998840332\n",
      "Epoch: 6, Steps: 682 | Train Loss: 0.1520439 Vali Loss: 0.3249802 Test Loss: 0.2523081\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "Test cost time: 1.8658s\n",
      "test shape: (182, 32, 6, 1) (182, 32, 6, 1)\n",
      "test shape: (5824, 6, 1) (5824, 6, 1)\n",
      "mse:0.24344871938228607, mae:0.3267466723918915\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1667.08203125\n",
      "MAE:  27.038705825805664\n",
      "RMSE: 40.82991409301758\n",
      "MAPE: 0.3438272476196289\n",
      "MSPE: 0.5520040988922119\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24443\n",
      "[DEBUG] Original dataset length: 24443\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21825\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3399\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "\titers: 100, epoch: 1 | loss: 0.3914268\n",
      "\tspeed: 0.0251s/iter; left time: 100.2737s\n",
      "\titers: 200, epoch: 1 | loss: 0.3169215\n",
      "\tspeed: 0.0282s/iter; left time: 109.6387s\n",
      "\titers: 300, epoch: 1 | loss: 0.1993535\n",
      "\tspeed: 0.0272s/iter; left time: 103.3323s\n",
      "\titers: 400, epoch: 1 | loss: 0.2100082\n",
      "\tspeed: 0.0278s/iter; left time: 102.8325s\n",
      "\titers: 500, epoch: 1 | loss: 0.1210216\n",
      "\tspeed: 0.0279s/iter; left time: 100.3737s\n",
      "\titers: 600, epoch: 1 | loss: 0.1677409\n",
      "\tspeed: 0.0266s/iter; left time: 93.0625s\n",
      "Epoch: 1 cost time: 18.50019335746765\n",
      "Epoch: 1, Steps: 682 | Train Loss: 0.2717152 Vali Loss: 0.3567911 Test Loss: 0.2830093\n",
      "Validation loss decreased (inf --> 0.356791).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3299569\n",
      "\tspeed: 0.0782s/iter; left time: 258.9585s\n",
      "\titers: 200, epoch: 2 | loss: 0.2402012\n",
      "\tspeed: 0.0280s/iter; left time: 89.8181s\n",
      "\titers: 300, epoch: 2 | loss: 0.1678945\n",
      "\tspeed: 0.0273s/iter; left time: 84.8499s\n",
      "\titers: 400, epoch: 2 | loss: 0.2878558\n",
      "\tspeed: 0.0260s/iter; left time: 78.4105s\n",
      "\titers: 500, epoch: 2 | loss: 0.2569010\n",
      "\tspeed: 0.0260s/iter; left time: 75.5888s\n",
      "\titers: 600, epoch: 2 | loss: 0.2058196\n",
      "\tspeed: 0.0264s/iter; left time: 74.2727s\n",
      "Epoch: 2 cost time: 18.161364316940308\n",
      "Epoch: 2, Steps: 682 | Train Loss: 0.2093011 Vali Loss: 0.3234760 Test Loss: 0.2588948\n",
      "Validation loss decreased (0.356791 --> 0.323476).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1470298\n",
      "\tspeed: 0.0797s/iter; left time: 209.5220s\n",
      "\titers: 200, epoch: 3 | loss: 0.1539797\n",
      "\tspeed: 0.0264s/iter; left time: 66.8510s\n",
      "\titers: 300, epoch: 3 | loss: 0.1360152\n",
      "\tspeed: 0.0262s/iter; left time: 63.5847s\n",
      "\titers: 400, epoch: 3 | loss: 0.2463717\n",
      "\tspeed: 0.0267s/iter; left time: 62.2772s\n",
      "\titers: 500, epoch: 3 | loss: 0.1551952\n",
      "\tspeed: 0.0270s/iter; left time: 60.2808s\n",
      "\titers: 600, epoch: 3 | loss: 0.1432827\n",
      "\tspeed: 0.0288s/iter; left time: 61.3914s\n",
      "Epoch: 3 cost time: 18.38491988182068\n",
      "Epoch: 3, Steps: 682 | Train Loss: 0.1783461 Vali Loss: 0.3262539 Test Loss: 0.2552591\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2348202\n",
      "\tspeed: 0.0784s/iter; left time: 152.6552s\n",
      "\titers: 200, epoch: 4 | loss: 0.2473141\n",
      "\tspeed: 0.0261s/iter; left time: 48.1407s\n",
      "\titers: 300, epoch: 4 | loss: 0.1219146\n",
      "\tspeed: 0.0290s/iter; left time: 50.6390s\n",
      "\titers: 400, epoch: 4 | loss: 0.1861583\n",
      "\tspeed: 0.0281s/iter; left time: 46.3072s\n",
      "\titers: 500, epoch: 4 | loss: 0.1194806\n",
      "\tspeed: 0.0269s/iter; left time: 41.6455s\n",
      "\titers: 600, epoch: 4 | loss: 0.2481789\n",
      "\tspeed: 0.0271s/iter; left time: 39.2317s\n",
      "Epoch: 4 cost time: 18.6368145942688\n",
      "Epoch: 4, Steps: 682 | Train Loss: 0.1630023 Vali Loss: 0.3154365 Test Loss: 0.2514522\n",
      "Validation loss decreased (0.323476 --> 0.315436).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1430224\n",
      "\tspeed: 0.0813s/iter; left time: 102.8574s\n",
      "\titers: 200, epoch: 5 | loss: 0.1843556\n",
      "\tspeed: 0.0275s/iter; left time: 32.0123s\n",
      "\titers: 300, epoch: 5 | loss: 0.1501911\n",
      "\tspeed: 0.0258s/iter; left time: 27.5160s\n",
      "\titers: 400, epoch: 5 | loss: 0.2035828\n",
      "\tspeed: 0.0275s/iter; left time: 26.5335s\n",
      "\titers: 500, epoch: 5 | loss: 0.1367852\n",
      "\tspeed: 0.0268s/iter; left time: 23.1937s\n",
      "\titers: 600, epoch: 5 | loss: 0.1492642\n",
      "\tspeed: 0.0277s/iter; left time: 21.2096s\n",
      "Epoch: 5 cost time: 18.70152997970581\n",
      "Epoch: 5, Steps: 682 | Train Loss: 0.1540852 Vali Loss: 0.3231741 Test Loss: 0.2548727\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1349524\n",
      "\tspeed: 0.0812s/iter; left time: 47.3579s\n",
      "\titers: 200, epoch: 6 | loss: 0.1449327\n",
      "\tspeed: 0.0274s/iter; left time: 13.2468s\n",
      "\titers: 300, epoch: 6 | loss: 0.1317154\n",
      "\tspeed: 0.0283s/iter; left time: 10.8274s\n",
      "\titers: 400, epoch: 6 | loss: 0.1102458\n",
      "\tspeed: 0.0292s/iter; left time: 8.2598s\n",
      "\titers: 500, epoch: 6 | loss: 0.1080158\n",
      "\tspeed: 0.0287s/iter; left time: 5.2483s\n",
      "\titers: 600, epoch: 6 | loss: 0.1031846\n",
      "\tspeed: 0.0278s/iter; left time: 2.3077s\n",
      "Epoch: 6 cost time: 19.171125888824463\n",
      "Epoch: 6, Steps: 682 | Train Loss: 0.1487281 Vali Loss: 0.3124165 Test Loss: 0.2462950\n",
      "Validation loss decreased (0.315436 --> 0.312416).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "Test cost time: 1.9958s\n",
      "test shape: (182, 32, 6, 1) (182, 32, 6, 1)\n",
      "test shape: (5824, 6, 1) (5824, 6, 1)\n",
      "mse:0.2440548539161682, mae:0.3249792158603668\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1671.2327880859375\n",
      "MAE:  26.89244842529297\n",
      "RMSE: 40.880714416503906\n",
      "MAPE: 0.33580875396728516\n",
      "MSPE: 0.5370451211929321\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24443\n",
      "[DEBUG] Original dataset length: 24443\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21825\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3399\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "\titers: 100, epoch: 1 | loss: 0.4324952\n",
      "\tspeed: 0.0286s/iter; left time: 114.1048s\n",
      "\titers: 200, epoch: 1 | loss: 0.3408072\n",
      "\tspeed: 0.0284s/iter; left time: 110.6863s\n",
      "\titers: 300, epoch: 1 | loss: 0.3254747\n",
      "\tspeed: 0.0288s/iter; left time: 109.1560s\n",
      "\titers: 400, epoch: 1 | loss: 0.2945028\n",
      "\tspeed: 0.0276s/iter; left time: 102.0407s\n",
      "\titers: 500, epoch: 1 | loss: 0.2341836\n",
      "\tspeed: 0.0270s/iter; left time: 96.9329s\n",
      "\titers: 600, epoch: 1 | loss: 0.2238352\n",
      "\tspeed: 0.0280s/iter; left time: 97.6514s\n",
      "Epoch: 1 cost time: 19.054199695587158\n",
      "Epoch: 1, Steps: 682 | Train Loss: 0.2802956 Vali Loss: 0.3205932 Test Loss: 0.2552159\n",
      "Validation loss decreased (inf --> 0.320593).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2017215\n",
      "\tspeed: 0.0805s/iter; left time: 266.4874s\n",
      "\titers: 200, epoch: 2 | loss: 0.2939855\n",
      "\tspeed: 0.0272s/iter; left time: 87.2818s\n",
      "\titers: 300, epoch: 2 | loss: 0.1400082\n",
      "\tspeed: 0.0289s/iter; left time: 90.0449s\n",
      "\titers: 400, epoch: 2 | loss: 0.1599213\n",
      "\tspeed: 0.0283s/iter; left time: 85.1908s\n",
      "\titers: 500, epoch: 2 | loss: 0.2712924\n",
      "\tspeed: 0.0261s/iter; left time: 75.9413s\n",
      "\titers: 600, epoch: 2 | loss: 0.1740143\n",
      "\tspeed: 0.0265s/iter; left time: 74.5024s\n",
      "Epoch: 2 cost time: 18.64768385887146\n",
      "Epoch: 2, Steps: 682 | Train Loss: 0.2121295 Vali Loss: 0.3136516 Test Loss: 0.2512748\n",
      "Validation loss decreased (0.320593 --> 0.313652).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1921326\n",
      "\tspeed: 0.0814s/iter; left time: 213.9256s\n",
      "\titers: 200, epoch: 3 | loss: 0.1833236\n",
      "\tspeed: 0.0263s/iter; left time: 66.4202s\n",
      "\titers: 300, epoch: 3 | loss: 0.1580416\n",
      "\tspeed: 0.0270s/iter; left time: 65.5483s\n",
      "\titers: 400, epoch: 3 | loss: 0.2103072\n",
      "\tspeed: 0.0287s/iter; left time: 66.9548s\n",
      "\titers: 500, epoch: 3 | loss: 0.1469759\n",
      "\tspeed: 0.0278s/iter; left time: 61.9361s\n",
      "\titers: 600, epoch: 3 | loss: 0.2304848\n",
      "\tspeed: 0.0284s/iter; left time: 60.3942s\n",
      "Epoch: 3 cost time: 18.885687351226807\n",
      "Epoch: 3, Steps: 682 | Train Loss: 0.1819781 Vali Loss: 0.3126324 Test Loss: 0.2525743\n",
      "Validation loss decreased (0.313652 --> 0.312632).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1842825\n",
      "\tspeed: 0.0789s/iter; left time: 153.5456s\n",
      "\titers: 200, epoch: 4 | loss: 0.1957416\n",
      "\tspeed: 0.0266s/iter; left time: 49.1838s\n",
      "\titers: 300, epoch: 4 | loss: 0.1098425\n",
      "\tspeed: 0.0272s/iter; left time: 47.4671s\n",
      "\titers: 400, epoch: 4 | loss: 0.1839446\n",
      "\tspeed: 0.0278s/iter; left time: 45.8092s\n",
      "\titers: 500, epoch: 4 | loss: 0.1164912\n",
      "\tspeed: 0.0271s/iter; left time: 41.9548s\n",
      "\titers: 600, epoch: 4 | loss: 0.1387854\n",
      "\tspeed: 0.0259s/iter; left time: 37.5260s\n",
      "Epoch: 4 cost time: 18.393566608428955\n",
      "Epoch: 4, Steps: 682 | Train Loss: 0.1646754 Vali Loss: 0.3084505 Test Loss: 0.2425210\n",
      "Validation loss decreased (0.312632 --> 0.308451).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1302898\n",
      "\tspeed: 0.0814s/iter; left time: 102.9821s\n",
      "\titers: 200, epoch: 5 | loss: 0.1216965\n",
      "\tspeed: 0.0267s/iter; left time: 31.1094s\n",
      "\titers: 300, epoch: 5 | loss: 0.2433997\n",
      "\tspeed: 0.0266s/iter; left time: 28.3041s\n",
      "\titers: 400, epoch: 5 | loss: 0.1547792\n",
      "\tspeed: 0.0265s/iter; left time: 25.5409s\n",
      "\titers: 500, epoch: 5 | loss: 0.2531561\n",
      "\tspeed: 0.0270s/iter; left time: 23.3809s\n",
      "\titers: 600, epoch: 5 | loss: 0.1486559\n",
      "\tspeed: 0.0258s/iter; left time: 19.7277s\n",
      "Epoch: 5 cost time: 18.607064962387085\n",
      "Epoch: 5, Steps: 682 | Train Loss: 0.1555343 Vali Loss: 0.3143842 Test Loss: 0.2463649\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1122835\n",
      "\tspeed: 0.0807s/iter; left time: 47.0277s\n",
      "\titers: 200, epoch: 6 | loss: 0.2777311\n",
      "\tspeed: 0.0265s/iter; left time: 12.8110s\n",
      "\titers: 300, epoch: 6 | loss: 0.1019590\n",
      "\tspeed: 0.0261s/iter; left time: 10.0139s\n",
      "\titers: 400, epoch: 6 | loss: 0.2058817\n",
      "\tspeed: 0.0274s/iter; left time: 7.7637s\n",
      "\titers: 500, epoch: 6 | loss: 0.1917352\n",
      "\tspeed: 0.0285s/iter; left time: 5.2231s\n",
      "\titers: 600, epoch: 6 | loss: 0.1314170\n",
      "\tspeed: 0.0265s/iter; left time: 2.2025s\n",
      "Epoch: 6 cost time: 18.402477741241455\n",
      "Epoch: 6, Steps: 682 | Train Loss: 0.1492492 Vali Loss: 0.3199969 Test Loss: 0.2496009\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "Test cost time: 1.8945s\n",
      "test shape: (182, 32, 6, 1) (182, 32, 6, 1)\n",
      "test shape: (5824, 6, 1) (5824, 6, 1)\n",
      "mse:0.24496403336524963, mae:0.3311961591243744\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1677.4586181640625\n",
      "MAE:  27.406906127929688\n",
      "RMSE: 40.956790924072266\n",
      "MAPE: 0.34799647331237793\n",
      "MSPE: 0.5666613578796387\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24443\n",
      "[DEBUG] Original dataset length: 24443\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21825\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3399\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "\titers: 100, epoch: 1 | loss: 0.3628126\n",
      "\tspeed: 0.0274s/iter; left time: 109.3850s\n",
      "\titers: 200, epoch: 1 | loss: 0.3142911\n",
      "\tspeed: 0.0273s/iter; left time: 106.2559s\n",
      "\titers: 300, epoch: 1 | loss: 0.2002925\n",
      "\tspeed: 0.0264s/iter; left time: 100.1871s\n",
      "\titers: 400, epoch: 1 | loss: 0.1739843\n",
      "\tspeed: 0.0259s/iter; left time: 95.5818s\n",
      "\titers: 500, epoch: 1 | loss: 0.4382226\n",
      "\tspeed: 0.0263s/iter; left time: 94.4727s\n",
      "\titers: 600, epoch: 1 | loss: 0.2589644\n",
      "\tspeed: 0.0267s/iter; left time: 93.1241s\n",
      "Epoch: 1 cost time: 18.396898984909058\n",
      "Epoch: 1, Steps: 682 | Train Loss: 0.2822062 Vali Loss: 0.3398049 Test Loss: 0.2729686\n",
      "Validation loss decreased (inf --> 0.339805).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1535294\n",
      "\tspeed: 0.0809s/iter; left time: 267.9655s\n",
      "\titers: 200, epoch: 2 | loss: 0.2238385\n",
      "\tspeed: 0.0271s/iter; left time: 86.9837s\n",
      "\titers: 300, epoch: 2 | loss: 0.1326815\n",
      "\tspeed: 0.0263s/iter; left time: 81.8605s\n",
      "\titers: 400, epoch: 2 | loss: 0.2571022\n",
      "\tspeed: 0.0273s/iter; left time: 82.3026s\n",
      "\titers: 500, epoch: 2 | loss: 0.2825384\n",
      "\tspeed: 0.0276s/iter; left time: 80.2159s\n",
      "\titers: 600, epoch: 2 | loss: 0.2129160\n",
      "\tspeed: 0.0261s/iter; left time: 73.3059s\n",
      "Epoch: 2 cost time: 18.293596744537354\n",
      "Epoch: 2, Steps: 682 | Train Loss: 0.2076172 Vali Loss: 0.3244736 Test Loss: 0.2622795\n",
      "Validation loss decreased (0.339805 --> 0.324474).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1113952\n",
      "\tspeed: 0.0787s/iter; left time: 206.8203s\n",
      "\titers: 200, epoch: 3 | loss: 0.1742168\n",
      "\tspeed: 0.0285s/iter; left time: 72.1262s\n",
      "\titers: 300, epoch: 3 | loss: 0.2389468\n",
      "\tspeed: 0.0270s/iter; left time: 65.6587s\n",
      "\titers: 400, epoch: 3 | loss: 0.1581928\n",
      "\tspeed: 0.0265s/iter; left time: 61.8010s\n",
      "\titers: 500, epoch: 3 | loss: 0.2971312\n",
      "\tspeed: 0.0263s/iter; left time: 58.6925s\n",
      "\titers: 600, epoch: 3 | loss: 0.3088046\n",
      "\tspeed: 0.0267s/iter; left time: 56.7817s\n",
      "Epoch: 3 cost time: 18.301929235458374\n",
      "Epoch: 3, Steps: 682 | Train Loss: 0.1806525 Vali Loss: 0.3168712 Test Loss: 0.2521790\n",
      "Validation loss decreased (0.324474 --> 0.316871).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2108514\n",
      "\tspeed: 0.0771s/iter; left time: 150.0257s\n",
      "\titers: 200, epoch: 4 | loss: 0.1158560\n",
      "\tspeed: 0.0265s/iter; left time: 49.0311s\n",
      "\titers: 300, epoch: 4 | loss: 0.1471976\n",
      "\tspeed: 0.0253s/iter; left time: 44.2012s\n",
      "\titers: 400, epoch: 4 | loss: 0.2272861\n",
      "\tspeed: 0.0268s/iter; left time: 44.0717s\n",
      "\titers: 500, epoch: 4 | loss: 0.1143633\n",
      "\tspeed: 0.0271s/iter; left time: 41.8612s\n",
      "\titers: 600, epoch: 4 | loss: 0.1563718\n",
      "\tspeed: 0.0280s/iter; left time: 40.5463s\n",
      "Epoch: 4 cost time: 18.0886127948761\n",
      "Epoch: 4, Steps: 682 | Train Loss: 0.1640609 Vali Loss: 0.3102966 Test Loss: 0.2449769\n",
      "Validation loss decreased (0.316871 --> 0.310297).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1211885\n",
      "\tspeed: 0.0775s/iter; left time: 98.0566s\n",
      "\titers: 200, epoch: 5 | loss: 0.1901733\n",
      "\tspeed: 0.0272s/iter; left time: 31.6804s\n",
      "\titers: 300, epoch: 5 | loss: 0.1586401\n",
      "\tspeed: 0.0287s/iter; left time: 30.5717s\n",
      "\titers: 400, epoch: 5 | loss: 0.1322865\n",
      "\tspeed: 0.0274s/iter; left time: 26.4280s\n",
      "\titers: 500, epoch: 5 | loss: 0.2631758\n",
      "\tspeed: 0.0262s/iter; left time: 22.6314s\n",
      "\titers: 600, epoch: 5 | loss: 0.1234851\n",
      "\tspeed: 0.0272s/iter; left time: 20.8007s\n",
      "Epoch: 5 cost time: 18.40885281562805\n",
      "Epoch: 5, Steps: 682 | Train Loss: 0.1551735 Vali Loss: 0.3211028 Test Loss: 0.2485919\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1110352\n",
      "\tspeed: 0.0788s/iter; left time: 45.9608s\n",
      "\titers: 200, epoch: 6 | loss: 0.1796744\n",
      "\tspeed: 0.0283s/iter; left time: 13.6494s\n",
      "\titers: 300, epoch: 6 | loss: 0.2467086\n",
      "\tspeed: 0.0279s/iter; left time: 10.6813s\n",
      "\titers: 400, epoch: 6 | loss: 0.1088139\n",
      "\tspeed: 0.0272s/iter; left time: 7.6856s\n",
      "\titers: 500, epoch: 6 | loss: 0.1537783\n",
      "\tspeed: 0.0268s/iter; left time: 4.9013s\n",
      "\titers: 600, epoch: 6 | loss: 0.1159043\n",
      "\tspeed: 0.0269s/iter; left time: 2.2344s\n",
      "Epoch: 6 cost time: 18.854730129241943\n",
      "Epoch: 6, Steps: 682 | Train Loss: 0.1499638 Vali Loss: 0.3161690 Test Loss: 0.2446179\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "Test cost time: 1.7797s\n",
      "test shape: (182, 32, 6, 1) (182, 32, 6, 1)\n",
      "test shape: (5824, 6, 1) (5824, 6, 1)\n",
      "mse:0.24473460018634796, mae:0.3365687429904938\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1675.8876953125\n",
      "MAE:  27.85149574279785\n",
      "RMSE: 40.93760681152344\n",
      "MAPE: 0.3886964023113251\n",
      "MSPE: 0.7657821178436279\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24443\n",
      "[DEBUG] Original dataset length: 24443\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21825\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3399\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "\titers: 100, epoch: 1 | loss: 0.2889816\n",
      "\tspeed: 0.0269s/iter; left time: 107.2602s\n",
      "\titers: 200, epoch: 1 | loss: 0.2407607\n",
      "\tspeed: 0.0267s/iter; left time: 103.9310s\n",
      "\titers: 300, epoch: 1 | loss: 0.3196054\n",
      "\tspeed: 0.0286s/iter; left time: 108.4081s\n",
      "\titers: 400, epoch: 1 | loss: 0.1958838\n",
      "\tspeed: 0.0261s/iter; left time: 96.2947s\n",
      "\titers: 500, epoch: 1 | loss: 0.2380520\n",
      "\tspeed: 0.0261s/iter; left time: 93.7738s\n",
      "\titers: 600, epoch: 1 | loss: 0.2344562\n",
      "\tspeed: 0.0259s/iter; left time: 90.3671s\n",
      "Epoch: 1 cost time: 18.198083639144897\n",
      "Epoch: 1, Steps: 682 | Train Loss: 0.2798365 Vali Loss: 0.3296660 Test Loss: 0.2690667\n",
      "Validation loss decreased (inf --> 0.329666).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2119010\n",
      "\tspeed: 0.0793s/iter; left time: 262.5389s\n",
      "\titers: 200, epoch: 2 | loss: 0.1630715\n",
      "\tspeed: 0.0268s/iter; left time: 86.0052s\n",
      "\titers: 300, epoch: 2 | loss: 0.2157633\n",
      "\tspeed: 0.0270s/iter; left time: 84.0694s\n",
      "\titers: 400, epoch: 2 | loss: 0.2268048\n",
      "\tspeed: 0.0266s/iter; left time: 80.1794s\n",
      "\titers: 500, epoch: 2 | loss: 0.1184976\n",
      "\tspeed: 0.0261s/iter; left time: 75.8852s\n",
      "\titers: 600, epoch: 2 | loss: 0.1713092\n",
      "\tspeed: 0.0282s/iter; left time: 79.1520s\n",
      "Epoch: 2 cost time: 18.51788878440857\n",
      "Epoch: 2, Steps: 682 | Train Loss: 0.2059285 Vali Loss: 0.3129936 Test Loss: 0.2523659\n",
      "Validation loss decreased (0.329666 --> 0.312994).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1708834\n",
      "\tspeed: 0.0806s/iter; left time: 211.9895s\n",
      "\titers: 200, epoch: 3 | loss: 0.1836453\n",
      "\tspeed: 0.0263s/iter; left time: 66.4740s\n",
      "\titers: 300, epoch: 3 | loss: 0.1741126\n",
      "\tspeed: 0.0259s/iter; left time: 62.7925s\n",
      "\titers: 400, epoch: 3 | loss: 0.1664773\n",
      "\tspeed: 0.0304s/iter; left time: 70.7618s\n",
      "\titers: 500, epoch: 3 | loss: 0.2342499\n",
      "\tspeed: 0.0272s/iter; left time: 60.6910s\n",
      "\titers: 600, epoch: 3 | loss: 0.1440930\n",
      "\tspeed: 0.0260s/iter; left time: 55.3838s\n",
      "Epoch: 3 cost time: 18.52134346961975\n",
      "Epoch: 3, Steps: 682 | Train Loss: 0.1776431 Vali Loss: 0.3422354 Test Loss: 0.2695517\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1781950\n",
      "\tspeed: 0.0802s/iter; left time: 156.1792s\n",
      "\titers: 200, epoch: 4 | loss: 0.1069221\n",
      "\tspeed: 0.0280s/iter; left time: 51.7248s\n",
      "\titers: 300, epoch: 4 | loss: 0.2091790\n",
      "\tspeed: 0.0268s/iter; left time: 46.8479s\n",
      "\titers: 400, epoch: 4 | loss: 0.1109921\n",
      "\tspeed: 0.0263s/iter; left time: 43.3627s\n",
      "\titers: 500, epoch: 4 | loss: 0.2172171\n",
      "\tspeed: 0.0245s/iter; left time: 37.8648s\n",
      "\titers: 600, epoch: 4 | loss: 0.1737469\n",
      "\tspeed: 0.0264s/iter; left time: 38.1684s\n",
      "Epoch: 4 cost time: 18.34287667274475\n",
      "Epoch: 4, Steps: 682 | Train Loss: 0.1614814 Vali Loss: 0.3157085 Test Loss: 0.2573503\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1599268\n",
      "\tspeed: 0.0792s/iter; left time: 100.1516s\n",
      "\titers: 200, epoch: 5 | loss: 0.1642712\n",
      "\tspeed: 0.0271s/iter; left time: 31.5459s\n",
      "\titers: 300, epoch: 5 | loss: 0.2535574\n",
      "\tspeed: 0.0263s/iter; left time: 28.0390s\n",
      "\titers: 400, epoch: 5 | loss: 0.1786906\n",
      "\tspeed: 0.0272s/iter; left time: 26.2500s\n",
      "\titers: 500, epoch: 5 | loss: 0.1304851\n",
      "\tspeed: 0.0274s/iter; left time: 23.7262s\n",
      "\titers: 600, epoch: 5 | loss: 0.1236691\n",
      "\tspeed: 0.0269s/iter; left time: 20.6005s\n",
      "Epoch: 5 cost time: 18.219833374023438\n",
      "Epoch: 5, Steps: 682 | Train Loss: 0.1526555 Vali Loss: 0.3132805 Test Loss: 0.2557644\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "Test cost time: 1.8422s\n",
      "test shape: (182, 32, 6, 1) (182, 32, 6, 1)\n",
      "test shape: (5824, 6, 1) (5824, 6, 1)\n",
      "mse:0.2520036995410919, mae:0.3321656286716461\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1725.66455078125\n",
      "MAE:  27.48713493347168\n",
      "RMSE: 41.54111862182617\n",
      "MAPE: 0.33079060912132263\n",
      "MSPE: 0.4944353401660919\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24443\n",
      "[DEBUG] Original dataset length: 24443\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21825\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3399\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "\titers: 100, epoch: 1 | loss: 0.2561054\n",
      "\tspeed: 0.0279s/iter; left time: 111.2568s\n",
      "\titers: 200, epoch: 1 | loss: 0.3354536\n",
      "\tspeed: 0.0266s/iter; left time: 103.4111s\n",
      "\titers: 300, epoch: 1 | loss: 0.3387117\n",
      "\tspeed: 0.0267s/iter; left time: 101.3585s\n",
      "\titers: 400, epoch: 1 | loss: 0.2905919\n",
      "\tspeed: 0.0264s/iter; left time: 97.5811s\n",
      "\titers: 500, epoch: 1 | loss: 0.1364369\n",
      "\tspeed: 0.0271s/iter; left time: 97.2181s\n",
      "\titers: 600, epoch: 1 | loss: 0.2706970\n",
      "\tspeed: 0.0266s/iter; left time: 92.9758s\n",
      "Epoch: 1 cost time: 18.4986515045166\n",
      "Epoch: 1, Steps: 682 | Train Loss: 0.2822393 Vali Loss: 0.3331573 Test Loss: 0.2616528\n",
      "Validation loss decreased (inf --> 0.333157).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1995141\n",
      "\tspeed: 0.0799s/iter; left time: 264.4972s\n",
      "\titers: 200, epoch: 2 | loss: 0.1901543\n",
      "\tspeed: 0.0265s/iter; left time: 84.9748s\n",
      "\titers: 300, epoch: 2 | loss: 0.2669031\n",
      "\tspeed: 0.0270s/iter; left time: 84.0339s\n",
      "\titers: 400, epoch: 2 | loss: 0.2834808\n",
      "\tspeed: 0.0264s/iter; left time: 79.4100s\n",
      "\titers: 500, epoch: 2 | loss: 0.1600838\n",
      "\tspeed: 0.0299s/iter; left time: 87.0866s\n",
      "\titers: 600, epoch: 2 | loss: 0.1979321\n",
      "\tspeed: 0.0270s/iter; left time: 75.8359s\n",
      "Epoch: 2 cost time: 18.57162642478943\n",
      "Epoch: 2, Steps: 682 | Train Loss: 0.2077618 Vali Loss: 0.3367300 Test Loss: 0.2685486\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1345801\n",
      "\tspeed: 0.0781s/iter; left time: 205.4192s\n",
      "\titers: 200, epoch: 3 | loss: 0.1575339\n",
      "\tspeed: 0.0275s/iter; left time: 69.5166s\n",
      "\titers: 300, epoch: 3 | loss: 0.1432000\n",
      "\tspeed: 0.0272s/iter; left time: 66.1171s\n",
      "\titers: 400, epoch: 3 | loss: 0.2273189\n",
      "\tspeed: 0.0267s/iter; left time: 62.1768s\n",
      "\titers: 500, epoch: 3 | loss: 0.1053393\n",
      "\tspeed: 0.0269s/iter; left time: 60.0623s\n",
      "\titers: 600, epoch: 3 | loss: 0.1814971\n",
      "\tspeed: 0.0261s/iter; left time: 55.6097s\n",
      "Epoch: 3 cost time: 18.35117745399475\n",
      "Epoch: 3, Steps: 682 | Train Loss: 0.1809604 Vali Loss: 0.3343155 Test Loss: 0.2612623\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1449723\n",
      "\tspeed: 0.0796s/iter; left time: 155.0364s\n",
      "\titers: 200, epoch: 4 | loss: 0.2017076\n",
      "\tspeed: 0.0268s/iter; left time: 49.4357s\n",
      "\titers: 300, epoch: 4 | loss: 0.0782065\n",
      "\tspeed: 0.0260s/iter; left time: 45.5087s\n",
      "\titers: 400, epoch: 4 | loss: 0.1605918\n",
      "\tspeed: 0.0259s/iter; left time: 42.6005s\n",
      "\titers: 500, epoch: 4 | loss: 0.1302793\n",
      "\tspeed: 0.0275s/iter; left time: 42.5877s\n",
      "\titers: 600, epoch: 4 | loss: 0.2305760\n",
      "\tspeed: 0.0265s/iter; left time: 38.2881s\n",
      "Epoch: 4 cost time: 18.058135986328125\n",
      "Epoch: 4, Steps: 682 | Train Loss: 0.1656975 Vali Loss: 0.3304931 Test Loss: 0.2539751\n",
      "Validation loss decreased (0.333157 --> 0.330493).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0999633\n",
      "\tspeed: 0.0778s/iter; left time: 98.3686s\n",
      "\titers: 200, epoch: 5 | loss: 0.1447834\n",
      "\tspeed: 0.0260s/iter; left time: 30.3441s\n",
      "\titers: 300, epoch: 5 | loss: 0.1743520\n",
      "\tspeed: 0.0276s/iter; left time: 29.4399s\n",
      "\titers: 400, epoch: 5 | loss: 0.1478215\n",
      "\tspeed: 0.0267s/iter; left time: 25.7479s\n",
      "\titers: 500, epoch: 5 | loss: 0.1261974\n",
      "\tspeed: 0.0275s/iter; left time: 23.7696s\n",
      "\titers: 600, epoch: 5 | loss: 0.1834507\n",
      "\tspeed: 0.0280s/iter; left time: 21.4045s\n",
      "Epoch: 5 cost time: 18.435972452163696\n",
      "Epoch: 5, Steps: 682 | Train Loss: 0.1560498 Vali Loss: 0.3329927 Test Loss: 0.2576211\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1369951\n",
      "\tspeed: 0.0799s/iter; left time: 46.5765s\n",
      "\titers: 200, epoch: 6 | loss: 0.1358949\n",
      "\tspeed: 0.0262s/iter; left time: 12.6354s\n",
      "\titers: 300, epoch: 6 | loss: 0.1240617\n",
      "\tspeed: 0.0261s/iter; left time: 9.9926s\n",
      "\titers: 400, epoch: 6 | loss: 0.1434399\n",
      "\tspeed: 0.0264s/iter; left time: 7.4708s\n",
      "\titers: 500, epoch: 6 | loss: 0.1036578\n",
      "\tspeed: 0.0264s/iter; left time: 4.8352s\n",
      "\titers: 600, epoch: 6 | loss: 0.1484151\n",
      "\tspeed: 0.0276s/iter; left time: 2.2888s\n",
      "Epoch: 6 cost time: 18.492205381393433\n",
      "Epoch: 6, Steps: 682 | Train Loss: 0.1512564 Vali Loss: 0.3420986 Test Loss: 0.2581435\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "Test cost time: 1.8423s\n",
      "test shape: (182, 32, 6, 1) (182, 32, 6, 1)\n",
      "test shape: (5824, 6, 1) (5824, 6, 1)\n",
      "mse:0.2548108994960785, mae:0.3376655578613281\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1744.8878173828125\n",
      "MAE:  27.9422607421875\n",
      "RMSE: 41.771854400634766\n",
      "MAPE: 0.3433923125267029\n",
      "MSPE: 0.5365846157073975\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24443\n",
      "[DEBUG] Original dataset length: 24443\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21825\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3399\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "\titers: 100, epoch: 1 | loss: 0.3714706\n",
      "\tspeed: 0.0261s/iter; left time: 104.3727s\n",
      "\titers: 200, epoch: 1 | loss: 0.2642617\n",
      "\tspeed: 0.0261s/iter; left time: 101.6535s\n",
      "\titers: 300, epoch: 1 | loss: 0.1902532\n",
      "\tspeed: 0.0275s/iter; left time: 104.3786s\n",
      "\titers: 400, epoch: 1 | loss: 0.1227303\n",
      "\tspeed: 0.0272s/iter; left time: 100.4409s\n",
      "\titers: 500, epoch: 1 | loss: 0.1510050\n",
      "\tspeed: 0.0262s/iter; left time: 94.0080s\n",
      "\titers: 600, epoch: 1 | loss: 0.2921735\n",
      "\tspeed: 0.0271s/iter; left time: 94.5044s\n",
      "Epoch: 1 cost time: 18.19030737876892\n",
      "Epoch: 1, Steps: 682 | Train Loss: 0.2770900 Vali Loss: 0.3368185 Test Loss: 0.2739234\n",
      "Validation loss decreased (inf --> 0.336819).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2127772\n",
      "\tspeed: 0.0797s/iter; left time: 263.9534s\n",
      "\titers: 200, epoch: 2 | loss: 0.2055015\n",
      "\tspeed: 0.0266s/iter; left time: 85.3176s\n",
      "\titers: 300, epoch: 2 | loss: 0.2630712\n",
      "\tspeed: 0.0242s/iter; left time: 75.1882s\n",
      "\titers: 400, epoch: 2 | loss: 0.2216619\n",
      "\tspeed: 0.0259s/iter; left time: 78.0875s\n",
      "\titers: 500, epoch: 2 | loss: 0.2305723\n",
      "\tspeed: 0.0256s/iter; left time: 74.4722s\n",
      "\titers: 600, epoch: 2 | loss: 0.3636434\n",
      "\tspeed: 0.0274s/iter; left time: 77.0491s\n",
      "Epoch: 2 cost time: 18.056218147277832\n",
      "Epoch: 2, Steps: 682 | Train Loss: 0.2089598 Vali Loss: 0.3205567 Test Loss: 0.2694640\n",
      "Validation loss decreased (0.336819 --> 0.320557).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2441254\n",
      "\tspeed: 0.0786s/iter; left time: 206.7642s\n",
      "\titers: 200, epoch: 3 | loss: 0.1888618\n",
      "\tspeed: 0.0272s/iter; left time: 68.6845s\n",
      "\titers: 300, epoch: 3 | loss: 0.1300298\n",
      "\tspeed: 0.0265s/iter; left time: 64.3301s\n",
      "\titers: 400, epoch: 3 | loss: 0.1882397\n",
      "\tspeed: 0.0290s/iter; left time: 67.5290s\n",
      "\titers: 500, epoch: 3 | loss: 0.1532840\n",
      "\tspeed: 0.0269s/iter; left time: 60.0361s\n",
      "\titers: 600, epoch: 3 | loss: 0.1947490\n",
      "\tspeed: 0.0270s/iter; left time: 57.5248s\n",
      "Epoch: 3 cost time: 18.46679925918579\n",
      "Epoch: 3, Steps: 682 | Train Loss: 0.1810402 Vali Loss: 0.3157038 Test Loss: 0.2481829\n",
      "Validation loss decreased (0.320557 --> 0.315704).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2358089\n",
      "\tspeed: 0.0795s/iter; left time: 154.8580s\n",
      "\titers: 200, epoch: 4 | loss: 0.1678578\n",
      "\tspeed: 0.0283s/iter; left time: 52.2074s\n",
      "\titers: 300, epoch: 4 | loss: 0.1057266\n",
      "\tspeed: 0.0263s/iter; left time: 45.9440s\n",
      "\titers: 400, epoch: 4 | loss: 0.1001984\n",
      "\tspeed: 0.0258s/iter; left time: 42.5165s\n",
      "\titers: 500, epoch: 4 | loss: 0.1037369\n",
      "\tspeed: 0.0261s/iter; left time: 40.4380s\n",
      "\titers: 600, epoch: 4 | loss: 0.2581611\n",
      "\tspeed: 0.0261s/iter; left time: 37.8293s\n",
      "Epoch: 4 cost time: 18.127612352371216\n",
      "Epoch: 4, Steps: 682 | Train Loss: 0.1646342 Vali Loss: 0.3186758 Test Loss: 0.2448019\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1331299\n",
      "\tspeed: 0.0778s/iter; left time: 98.4612s\n",
      "\titers: 200, epoch: 5 | loss: 0.2175576\n",
      "\tspeed: 0.0269s/iter; left time: 31.3464s\n",
      "\titers: 300, epoch: 5 | loss: 0.0955700\n",
      "\tspeed: 0.0263s/iter; left time: 28.0283s\n",
      "\titers: 400, epoch: 5 | loss: 0.1051695\n",
      "\tspeed: 0.0272s/iter; left time: 26.2159s\n",
      "\titers: 500, epoch: 5 | loss: 0.1760837\n",
      "\tspeed: 0.0294s/iter; left time: 25.3954s\n",
      "\titers: 600, epoch: 5 | loss: 0.3371019\n",
      "\tspeed: 0.0270s/iter; left time: 20.6817s\n",
      "Epoch: 5 cost time: 18.474271059036255\n",
      "Epoch: 5, Steps: 682 | Train Loss: 0.1558503 Vali Loss: 0.3221482 Test Loss: 0.2440140\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3651761\n",
      "\tspeed: 0.0768s/iter; left time: 44.8008s\n",
      "\titers: 200, epoch: 6 | loss: 0.1575287\n",
      "\tspeed: 0.0270s/iter; left time: 13.0431s\n",
      "\titers: 300, epoch: 6 | loss: 0.1451578\n",
      "\tspeed: 0.0288s/iter; left time: 11.0484s\n",
      "\titers: 400, epoch: 6 | loss: 0.1313094\n",
      "\tspeed: 0.0269s/iter; left time: 7.6029s\n",
      "\titers: 500, epoch: 6 | loss: 0.0717535\n",
      "\tspeed: 0.0272s/iter; left time: 4.9763s\n",
      "\titers: 600, epoch: 6 | loss: 0.0845199\n",
      "\tspeed: 0.0264s/iter; left time: 2.1877s\n",
      "Epoch: 6 cost time: 18.41642951965332\n",
      "Epoch: 6, Steps: 682 | Train Loss: 0.1507185 Vali Loss: 0.3226632 Test Loss: 0.2444243\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "Test cost time: 1.8486s\n",
      "test shape: (182, 32, 6, 1) (182, 32, 6, 1)\n",
      "test shape: (5824, 6, 1) (5824, 6, 1)\n",
      "mse:0.2479049116373062, mae:0.33073338866233826\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1697.5970458984375\n",
      "MAE:  27.36861228942871\n",
      "RMSE: 41.201904296875\n",
      "MAPE: 0.3397752344608307\n",
      "MSPE: 0.578265905380249\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24443\n",
      "[DEBUG] Original dataset length: 24443\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21825\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3399\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "\titers: 100, epoch: 1 | loss: 0.3165544\n",
      "\tspeed: 0.0259s/iter; left time: 103.2990s\n",
      "\titers: 200, epoch: 1 | loss: 0.1972222\n",
      "\tspeed: 0.0276s/iter; left time: 107.4538s\n",
      "\titers: 300, epoch: 1 | loss: 0.3473387\n",
      "\tspeed: 0.0273s/iter; left time: 103.6064s\n",
      "\titers: 400, epoch: 1 | loss: 0.3760364\n",
      "\tspeed: 0.0272s/iter; left time: 100.5191s\n",
      "\titers: 500, epoch: 1 | loss: 0.2257225\n",
      "\tspeed: 0.0295s/iter; left time: 106.1417s\n",
      "\titers: 600, epoch: 1 | loss: 0.2509027\n",
      "\tspeed: 0.0286s/iter; left time: 99.7555s\n",
      "Epoch: 1 cost time: 18.941087245941162\n",
      "Epoch: 1, Steps: 682 | Train Loss: 0.2779901 Vali Loss: 0.3443411 Test Loss: 0.2837254\n",
      "Validation loss decreased (inf --> 0.344341).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1516568\n",
      "\tspeed: 0.0833s/iter; left time: 275.9013s\n",
      "\titers: 200, epoch: 2 | loss: 0.1553725\n",
      "\tspeed: 0.0295s/iter; left time: 94.8135s\n",
      "\titers: 300, epoch: 2 | loss: 0.2678145\n",
      "\tspeed: 0.0282s/iter; left time: 87.7289s\n",
      "\titers: 400, epoch: 2 | loss: 0.1790532\n",
      "\tspeed: 0.0286s/iter; left time: 86.1479s\n",
      "\titers: 500, epoch: 2 | loss: 0.2894240\n",
      "\tspeed: 0.0276s/iter; left time: 80.4030s\n",
      "\titers: 600, epoch: 2 | loss: 0.3504165\n",
      "\tspeed: 0.0275s/iter; left time: 77.3521s\n",
      "Epoch: 2 cost time: 19.210870027542114\n",
      "Epoch: 2, Steps: 682 | Train Loss: 0.2108609 Vali Loss: 0.3169678 Test Loss: 0.2645910\n",
      "Validation loss decreased (0.344341 --> 0.316968).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2110490\n",
      "\tspeed: 0.0784s/iter; left time: 206.1018s\n",
      "\titers: 200, epoch: 3 | loss: 0.2272308\n",
      "\tspeed: 0.0262s/iter; left time: 66.3465s\n",
      "\titers: 300, epoch: 3 | loss: 0.1536266\n",
      "\tspeed: 0.0269s/iter; left time: 65.2839s\n",
      "\titers: 400, epoch: 3 | loss: 0.1614529\n",
      "\tspeed: 0.0262s/iter; left time: 61.0551s\n",
      "\titers: 500, epoch: 3 | loss: 0.1857761\n",
      "\tspeed: 0.0284s/iter; left time: 63.3631s\n",
      "\titers: 600, epoch: 3 | loss: 0.1654629\n",
      "\tspeed: 0.0269s/iter; left time: 57.3471s\n",
      "Epoch: 3 cost time: 18.242027759552002\n",
      "Epoch: 3, Steps: 682 | Train Loss: 0.1817549 Vali Loss: 0.3129488 Test Loss: 0.2498384\n",
      "Validation loss decreased (0.316968 --> 0.312949).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1757537\n",
      "\tspeed: 0.0769s/iter; left time: 149.6515s\n",
      "\titers: 200, epoch: 4 | loss: 0.1113510\n",
      "\tspeed: 0.0267s/iter; left time: 49.3739s\n",
      "\titers: 300, epoch: 4 | loss: 0.2142215\n",
      "\tspeed: 0.0290s/iter; left time: 50.5955s\n",
      "\titers: 400, epoch: 4 | loss: 0.1644967\n",
      "\tspeed: 0.0265s/iter; left time: 43.6493s\n",
      "\titers: 500, epoch: 4 | loss: 0.0938500\n",
      "\tspeed: 0.0258s/iter; left time: 39.8592s\n",
      "\titers: 600, epoch: 4 | loss: 0.1156664\n",
      "\tspeed: 0.0273s/iter; left time: 39.5135s\n",
      "Epoch: 4 cost time: 18.20378565788269\n",
      "Epoch: 4, Steps: 682 | Train Loss: 0.1670165 Vali Loss: 0.3257425 Test Loss: 0.2545779\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2408505\n",
      "\tspeed: 0.0782s/iter; left time: 98.9480s\n",
      "\titers: 200, epoch: 5 | loss: 0.1381898\n",
      "\tspeed: 0.0264s/iter; left time: 30.7272s\n",
      "\titers: 300, epoch: 5 | loss: 0.2153209\n",
      "\tspeed: 0.0259s/iter; left time: 27.6048s\n",
      "\titers: 400, epoch: 5 | loss: 0.1507992\n",
      "\tspeed: 0.0271s/iter; left time: 26.1230s\n",
      "\titers: 500, epoch: 5 | loss: 0.1039045\n",
      "\tspeed: 0.0260s/iter; left time: 22.5138s\n",
      "\titers: 600, epoch: 5 | loss: 0.1044940\n",
      "\tspeed: 0.0288s/iter; left time: 21.9982s\n",
      "Epoch: 5 cost time: 18.457106351852417\n",
      "Epoch: 5, Steps: 682 | Train Loss: 0.1581261 Vali Loss: 0.3235669 Test Loss: 0.2552113\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1414226\n",
      "\tspeed: 0.0780s/iter; left time: 45.4822s\n",
      "\titers: 200, epoch: 6 | loss: 0.1399626\n",
      "\tspeed: 0.0287s/iter; left time: 13.8651s\n",
      "\titers: 300, epoch: 6 | loss: 0.1666801\n",
      "\tspeed: 0.0286s/iter; left time: 10.9693s\n",
      "\titers: 400, epoch: 6 | loss: 0.1384566\n",
      "\tspeed: 0.0284s/iter; left time: 8.0453s\n",
      "\titers: 500, epoch: 6 | loss: 0.1215099\n",
      "\tspeed: 0.0257s/iter; left time: 4.7042s\n",
      "\titers: 600, epoch: 6 | loss: 0.1435261\n",
      "\tspeed: 0.0279s/iter; left time: 2.3117s\n",
      "Epoch: 6 cost time: 18.678930044174194\n",
      "Epoch: 6, Steps: 682 | Train Loss: 0.1521719 Vali Loss: 0.3247287 Test Loss: 0.2554171\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "Test cost time: 1.7911s\n",
      "test shape: (182, 32, 6, 1) (182, 32, 6, 1)\n",
      "test shape: (5824, 6, 1) (5824, 6, 1)\n",
      "mse:0.24980705976486206, mae:0.3358624279499054\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1710.62255859375\n",
      "MAE:  27.793048858642578\n",
      "RMSE: 41.35967254638672\n",
      "MAPE: 0.33731046319007874\n",
      "MSPE: 0.4962155520915985\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24443\n",
      "[DEBUG] Original dataset length: 24443\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21825\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3399\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "\titers: 100, epoch: 1 | loss: 0.1899043\n",
      "\tspeed: 0.0284s/iter; left time: 113.4036s\n",
      "\titers: 200, epoch: 1 | loss: 0.3738380\n",
      "\tspeed: 0.0283s/iter; left time: 110.2400s\n",
      "\titers: 300, epoch: 1 | loss: 0.2462013\n",
      "\tspeed: 0.0291s/iter; left time: 110.4899s\n",
      "\titers: 400, epoch: 1 | loss: 0.2156356\n",
      "\tspeed: 0.0291s/iter; left time: 107.2877s\n",
      "\titers: 500, epoch: 1 | loss: 0.1599511\n",
      "\tspeed: 0.0275s/iter; left time: 98.7742s\n",
      "\titers: 600, epoch: 1 | loss: 0.1989864\n",
      "\tspeed: 0.0287s/iter; left time: 100.3179s\n",
      "Epoch: 1 cost time: 19.269129753112793\n",
      "Epoch: 1, Steps: 682 | Train Loss: 0.2857789 Vali Loss: 0.3345643 Test Loss: 0.2691937\n",
      "Validation loss decreased (inf --> 0.334564).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4132148\n",
      "\tspeed: 0.0779s/iter; left time: 258.0374s\n",
      "\titers: 200, epoch: 2 | loss: 0.1660288\n",
      "\tspeed: 0.0268s/iter; left time: 86.1569s\n",
      "\titers: 300, epoch: 2 | loss: 0.1879312\n",
      "\tspeed: 0.0274s/iter; left time: 85.1913s\n",
      "\titers: 400, epoch: 2 | loss: 0.2630319\n",
      "\tspeed: 0.0273s/iter; left time: 82.2500s\n",
      "\titers: 500, epoch: 2 | loss: 0.1770201\n",
      "\tspeed: 0.0267s/iter; left time: 77.6947s\n",
      "\titers: 600, epoch: 2 | loss: 0.1685830\n",
      "\tspeed: 0.0269s/iter; left time: 75.7309s\n",
      "Epoch: 2 cost time: 18.47166347503662\n",
      "Epoch: 2, Steps: 682 | Train Loss: 0.2103489 Vali Loss: 0.3166874 Test Loss: 0.2523125\n",
      "Validation loss decreased (0.334564 --> 0.316687).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1161624\n",
      "\tspeed: 0.0843s/iter; left time: 221.7124s\n",
      "\titers: 200, epoch: 3 | loss: 0.1604228\n",
      "\tspeed: 0.0350s/iter; left time: 88.6271s\n",
      "\titers: 300, epoch: 3 | loss: 0.1596742\n",
      "\tspeed: 0.0293s/iter; left time: 71.1715s\n",
      "\titers: 400, epoch: 3 | loss: 0.2001164\n",
      "\tspeed: 0.0276s/iter; left time: 64.3263s\n",
      "\titers: 500, epoch: 3 | loss: 0.1249386\n",
      "\tspeed: 0.0279s/iter; left time: 62.2148s\n",
      "\titers: 600, epoch: 3 | loss: 0.2188376\n",
      "\tspeed: 0.0271s/iter; left time: 57.6880s\n",
      "Epoch: 3 cost time: 19.795391082763672\n",
      "Epoch: 3, Steps: 682 | Train Loss: 0.1798211 Vali Loss: 0.3224898 Test Loss: 0.2543043\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0875032\n",
      "\tspeed: 0.0784s/iter; left time: 152.5752s\n",
      "\titers: 200, epoch: 4 | loss: 0.1398235\n",
      "\tspeed: 0.0263s/iter; left time: 48.5509s\n",
      "\titers: 300, epoch: 4 | loss: 0.1440236\n",
      "\tspeed: 0.0267s/iter; left time: 46.7253s\n",
      "\titers: 400, epoch: 4 | loss: 0.2119727\n",
      "\tspeed: 0.0285s/iter; left time: 46.8840s\n",
      "\titers: 500, epoch: 4 | loss: 0.1593795\n",
      "\tspeed: 0.0267s/iter; left time: 41.3371s\n",
      "\titers: 600, epoch: 4 | loss: 0.1409369\n",
      "\tspeed: 0.0258s/iter; left time: 37.3078s\n",
      "Epoch: 4 cost time: 18.432230234146118\n",
      "Epoch: 4, Steps: 682 | Train Loss: 0.1648326 Vali Loss: 0.3171203 Test Loss: 0.2499772\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1760938\n",
      "\tspeed: 0.0794s/iter; left time: 100.4082s\n",
      "\titers: 200, epoch: 5 | loss: 0.1917375\n",
      "\tspeed: 0.0268s/iter; left time: 31.2645s\n",
      "\titers: 300, epoch: 5 | loss: 0.1702748\n",
      "\tspeed: 0.0263s/iter; left time: 28.0058s\n",
      "\titers: 400, epoch: 5 | loss: 0.0777096\n",
      "\tspeed: 0.0263s/iter; left time: 25.4269s\n",
      "\titers: 500, epoch: 5 | loss: 0.2102502\n",
      "\tspeed: 0.0265s/iter; left time: 22.9473s\n",
      "\titers: 600, epoch: 5 | loss: 0.2252467\n",
      "\tspeed: 0.0264s/iter; left time: 20.1724s\n",
      "Epoch: 5 cost time: 18.413482427597046\n",
      "Epoch: 5, Steps: 682 | Train Loss: 0.1551710 Vali Loss: 0.3282226 Test Loss: 0.2505891\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "Test cost time: 1.8543s\n",
      "test shape: (182, 32, 6, 1) (182, 32, 6, 1)\n",
      "test shape: (5824, 6, 1) (5824, 6, 1)\n",
      "mse:0.25140658020973206, mae:0.33816689252853394\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl96_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1721.5758056640625\n",
      "MAE:  27.983749389648438\n",
      "RMSE: 41.49187469482422\n",
      "MAPE: 0.42343077063560486\n",
      "MSPE: 1.002115249633789\n",
      ">>>>>>>Running time saved<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Running seq_len=120\n",
      "Args in experiment:\n",
      "Namespace(model='informer', data='traffic_full', root_path='../', data_path='traffic_full.csv', features='S', target='flow', freq='h', checkpoints='./checkpoints/', seq_len=120, label_len=24, pred_len=6, enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=2, d_layers=1, s_layers=[3, 2, 1], d_ff=2048, factor=5, padding=0, distil=True, dropout=0.05, attn='prob', embed='timeF', activation='gelu', output_attention=False, do_predict=False, mix=True, cols=None, num_workers=0, itr=10, train_epochs=6, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, inverse=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', detail_freq='h')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24419\n",
      "[DEBUG] Original dataset length: 24419\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21417\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3375\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "\titers: 100, epoch: 1 | loss: 0.2775437\n",
      "\tspeed: 0.0432s/iter; left time: 169.2100s\n",
      "\titers: 200, epoch: 1 | loss: 0.3854808\n",
      "\tspeed: 0.0314s/iter; left time: 119.7533s\n",
      "\titers: 300, epoch: 1 | loss: 0.2519211\n",
      "\tspeed: 0.0289s/iter; left time: 107.4217s\n",
      "\titers: 400, epoch: 1 | loss: 0.1880044\n",
      "\tspeed: 0.0293s/iter; left time: 106.0943s\n",
      "\titers: 500, epoch: 1 | loss: 0.3217722\n",
      "\tspeed: 0.0301s/iter; left time: 105.7097s\n",
      "\titers: 600, epoch: 1 | loss: 0.3101066\n",
      "\tspeed: 0.0289s/iter; left time: 98.6926s\n",
      "Epoch: 1 cost time: 20.515965223312378\n",
      "Epoch: 1, Steps: 669 | Train Loss: 0.2671879 Vali Loss: 0.3432809 Test Loss: 0.2821105\n",
      "Validation loss decreased (inf --> 0.343281).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1976306\n",
      "\tspeed: 0.0849s/iter; left time: 275.5701s\n",
      "\titers: 200, epoch: 2 | loss: 0.2080810\n",
      "\tspeed: 0.0303s/iter; left time: 95.4702s\n",
      "\titers: 300, epoch: 2 | loss: 0.3059615\n",
      "\tspeed: 0.0298s/iter; left time: 90.6959s\n",
      "\titers: 400, epoch: 2 | loss: 0.3579123\n",
      "\tspeed: 0.0314s/iter; left time: 92.3671s\n",
      "\titers: 500, epoch: 2 | loss: 0.1496097\n",
      "\tspeed: 0.0295s/iter; left time: 83.9712s\n",
      "\titers: 600, epoch: 2 | loss: 0.1738634\n",
      "\tspeed: 0.0303s/iter; left time: 83.2658s\n",
      "Epoch: 2 cost time: 20.246329069137573\n",
      "Epoch: 2, Steps: 669 | Train Loss: 0.2038040 Vali Loss: 0.3302626 Test Loss: 0.2716062\n",
      "Validation loss decreased (0.343281 --> 0.330263).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1911066\n",
      "\tspeed: 0.0869s/iter; left time: 223.9728s\n",
      "\titers: 200, epoch: 3 | loss: 0.1172610\n",
      "\tspeed: 0.0303s/iter; left time: 75.1255s\n",
      "\titers: 300, epoch: 3 | loss: 0.1401329\n",
      "\tspeed: 0.0290s/iter; left time: 68.8978s\n",
      "\titers: 400, epoch: 3 | loss: 0.1603983\n",
      "\tspeed: 0.0305s/iter; left time: 69.3942s\n",
      "\titers: 500, epoch: 3 | loss: 0.2022779\n",
      "\tspeed: 0.0311s/iter; left time: 67.8111s\n",
      "\titers: 600, epoch: 3 | loss: 0.1597285\n",
      "\tspeed: 0.0323s/iter; left time: 67.0634s\n",
      "Epoch: 3 cost time: 20.597347497940063\n",
      "Epoch: 3, Steps: 669 | Train Loss: 0.1763249 Vali Loss: 0.3178843 Test Loss: 0.2603658\n",
      "Validation loss decreased (0.330263 --> 0.317884).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1874330\n",
      "\tspeed: 0.0847s/iter; left time: 161.5310s\n",
      "\titers: 200, epoch: 4 | loss: 0.2095532\n",
      "\tspeed: 0.0296s/iter; left time: 53.4971s\n",
      "\titers: 300, epoch: 4 | loss: 0.2718078\n",
      "\tspeed: 0.0312s/iter; left time: 53.3741s\n",
      "\titers: 400, epoch: 4 | loss: 0.2132269\n",
      "\tspeed: 0.0293s/iter; left time: 47.1484s\n",
      "\titers: 500, epoch: 4 | loss: 0.1531405\n",
      "\tspeed: 0.0298s/iter; left time: 44.9206s\n",
      "\titers: 600, epoch: 4 | loss: 0.1645782\n",
      "\tspeed: 0.0304s/iter; left time: 42.7333s\n",
      "Epoch: 4 cost time: 20.174452781677246\n",
      "Epoch: 4, Steps: 669 | Train Loss: 0.1607548 Vali Loss: 0.3240892 Test Loss: 0.2551031\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1143947\n",
      "\tspeed: 0.0857s/iter; left time: 106.2288s\n",
      "\titers: 200, epoch: 5 | loss: 0.1346461\n",
      "\tspeed: 0.0291s/iter; left time: 33.1613s\n",
      "\titers: 300, epoch: 5 | loss: 0.1228238\n",
      "\tspeed: 0.0287s/iter; left time: 29.8308s\n",
      "\titers: 400, epoch: 5 | loss: 0.2781194\n",
      "\tspeed: 0.0294s/iter; left time: 27.6534s\n",
      "\titers: 500, epoch: 5 | loss: 0.1671257\n",
      "\tspeed: 0.0290s/iter; left time: 24.3468s\n",
      "\titers: 600, epoch: 5 | loss: 0.3472005\n",
      "\tspeed: 0.0304s/iter; left time: 22.4311s\n",
      "Epoch: 5 cost time: 19.70596218109131\n",
      "Epoch: 5, Steps: 669 | Train Loss: 0.1506062 Vali Loss: 0.3153746 Test Loss: 0.2503872\n",
      "Validation loss decreased (0.317884 --> 0.315375).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1098132\n",
      "\tspeed: 0.0820s/iter; left time: 46.7163s\n",
      "\titers: 200, epoch: 6 | loss: 0.1989886\n",
      "\tspeed: 0.0302s/iter; left time: 14.2026s\n",
      "\titers: 300, epoch: 6 | loss: 0.0974840\n",
      "\tspeed: 0.0311s/iter; left time: 11.4996s\n",
      "\titers: 400, epoch: 6 | loss: 0.1158308\n",
      "\tspeed: 0.0290s/iter; left time: 7.8426s\n",
      "\titers: 500, epoch: 6 | loss: 0.1574945\n",
      "\tspeed: 0.0293s/iter; left time: 4.9755s\n",
      "\titers: 600, epoch: 6 | loss: 0.1291543\n",
      "\tspeed: 0.0293s/iter; left time: 2.0503s\n",
      "Epoch: 6 cost time: 19.804141521453857\n",
      "Epoch: 6, Steps: 669 | Train Loss: 0.1454971 Vali Loss: 0.3208154 Test Loss: 0.2548475\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "Test cost time: 2.0087s\n",
      "test shape: (177, 32, 6, 1) (177, 32, 6, 1)\n",
      "test shape: (5664, 6, 1) (5664, 6, 1)\n",
      "mse:0.25202882289886475, mae:0.3266088366508484\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1725.8369140625\n",
      "MAE:  27.027301788330078\n",
      "RMSE: 41.54319381713867\n",
      "MAPE: 0.3228450119495392\n",
      "MSPE: 0.4520597457885742\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24419\n",
      "[DEBUG] Original dataset length: 24419\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21417\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3375\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "\titers: 100, epoch: 1 | loss: 0.5353029\n",
      "\tspeed: 0.0287s/iter; left time: 112.2695s\n",
      "\titers: 200, epoch: 1 | loss: 0.2202507\n",
      "\tspeed: 0.0298s/iter; left time: 113.8730s\n",
      "\titers: 300, epoch: 1 | loss: 0.2817588\n",
      "\tspeed: 0.0289s/iter; left time: 107.3517s\n",
      "\titers: 400, epoch: 1 | loss: 0.2256988\n",
      "\tspeed: 0.0307s/iter; left time: 110.9448s\n",
      "\titers: 500, epoch: 1 | loss: 0.1377440\n",
      "\tspeed: 0.0293s/iter; left time: 103.1482s\n",
      "\titers: 600, epoch: 1 | loss: 0.3728626\n",
      "\tspeed: 0.0294s/iter; left time: 100.2658s\n",
      "Epoch: 1 cost time: 19.68725609779358\n",
      "Epoch: 1, Steps: 669 | Train Loss: 0.2835234 Vali Loss: 0.3193486 Test Loss: 0.2545001\n",
      "Validation loss decreased (inf --> 0.319349).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3293202\n",
      "\tspeed: 0.0830s/iter; left time: 269.3607s\n",
      "\titers: 200, epoch: 2 | loss: 0.2064656\n",
      "\tspeed: 0.0307s/iter; left time: 96.5318s\n",
      "\titers: 300, epoch: 2 | loss: 0.1816770\n",
      "\tspeed: 0.0296s/iter; left time: 90.2621s\n",
      "\titers: 400, epoch: 2 | loss: 0.1724292\n",
      "\tspeed: 0.0295s/iter; left time: 87.0413s\n",
      "\titers: 500, epoch: 2 | loss: 0.1883586\n",
      "\tspeed: 0.0291s/iter; left time: 82.6839s\n",
      "\titers: 600, epoch: 2 | loss: 0.1452887\n",
      "\tspeed: 0.0299s/iter; left time: 82.0971s\n",
      "Epoch: 2 cost time: 19.995731353759766\n",
      "Epoch: 2, Steps: 669 | Train Loss: 0.2025141 Vali Loss: 0.3225348 Test Loss: 0.2543524\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2369109\n",
      "\tspeed: 0.0847s/iter; left time: 218.1497s\n",
      "\titers: 200, epoch: 3 | loss: 0.2358586\n",
      "\tspeed: 0.0287s/iter; left time: 71.1507s\n",
      "\titers: 300, epoch: 3 | loss: 0.1286654\n",
      "\tspeed: 0.0300s/iter; left time: 71.3540s\n",
      "\titers: 400, epoch: 3 | loss: 0.1569397\n",
      "\tspeed: 0.0317s/iter; left time: 72.2176s\n",
      "\titers: 500, epoch: 3 | loss: 0.2378858\n",
      "\tspeed: 0.0298s/iter; left time: 64.8873s\n",
      "\titers: 600, epoch: 3 | loss: 0.1268125\n",
      "\tspeed: 0.0299s/iter; left time: 62.0426s\n",
      "Epoch: 3 cost time: 20.05463218688965\n",
      "Epoch: 3, Steps: 669 | Train Loss: 0.1764569 Vali Loss: 0.3140378 Test Loss: 0.2513151\n",
      "Validation loss decreased (0.319349 --> 0.314038).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0890388\n",
      "\tspeed: 0.0853s/iter; left time: 162.7977s\n",
      "\titers: 200, epoch: 4 | loss: 0.2339140\n",
      "\tspeed: 0.0288s/iter; left time: 52.0688s\n",
      "\titers: 300, epoch: 4 | loss: 0.2123974\n",
      "\tspeed: 0.0286s/iter; left time: 48.7838s\n",
      "\titers: 400, epoch: 4 | loss: 0.1333164\n",
      "\tspeed: 0.0290s/iter; left time: 46.5798s\n",
      "\titers: 500, epoch: 4 | loss: 0.2218991\n",
      "\tspeed: 0.0289s/iter; left time: 43.5590s\n",
      "\titers: 600, epoch: 4 | loss: 0.0966213\n",
      "\tspeed: 0.0309s/iter; left time: 43.5382s\n",
      "Epoch: 4 cost time: 19.773286819458008\n",
      "Epoch: 4, Steps: 669 | Train Loss: 0.1612962 Vali Loss: 0.3308921 Test Loss: 0.2601327\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1357725\n",
      "\tspeed: 0.0823s/iter; left time: 101.9814s\n",
      "\titers: 200, epoch: 5 | loss: 0.1945419\n",
      "\tspeed: 0.0286s/iter; left time: 32.5820s\n",
      "\titers: 300, epoch: 5 | loss: 0.1169321\n",
      "\tspeed: 0.0315s/iter; left time: 32.7349s\n",
      "\titers: 400, epoch: 5 | loss: 0.1361889\n",
      "\tspeed: 0.0286s/iter; left time: 26.8185s\n",
      "\titers: 500, epoch: 5 | loss: 0.1449561\n",
      "\tspeed: 0.0299s/iter; left time: 25.1196s\n",
      "\titers: 600, epoch: 5 | loss: 0.1638429\n",
      "\tspeed: 0.0296s/iter; left time: 21.8791s\n",
      "Epoch: 5 cost time: 19.743263959884644\n",
      "Epoch: 5, Steps: 669 | Train Loss: 0.1520652 Vali Loss: 0.3258638 Test Loss: 0.2532049\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0962587\n",
      "\tspeed: 0.0826s/iter; left time: 47.1025s\n",
      "\titers: 200, epoch: 6 | loss: 0.1794239\n",
      "\tspeed: 0.0297s/iter; left time: 13.9445s\n",
      "\titers: 300, epoch: 6 | loss: 0.1207270\n",
      "\tspeed: 0.0279s/iter; left time: 10.3411s\n",
      "\titers: 400, epoch: 6 | loss: 0.1576193\n",
      "\tspeed: 0.0286s/iter; left time: 7.7322s\n",
      "\titers: 500, epoch: 6 | loss: 0.1473337\n",
      "\tspeed: 0.0290s/iter; left time: 4.9348s\n",
      "\titers: 600, epoch: 6 | loss: 0.1149782\n",
      "\tspeed: 0.0313s/iter; left time: 2.1876s\n",
      "Epoch: 6 cost time: 19.737404823303223\n",
      "Epoch: 6, Steps: 669 | Train Loss: 0.1469598 Vali Loss: 0.3206567 Test Loss: 0.2542932\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "Test cost time: 2.0977s\n",
      "test shape: (177, 32, 6, 1) (177, 32, 6, 1)\n",
      "test shape: (5664, 6, 1) (5664, 6, 1)\n",
      "mse:0.25152868032455444, mae:0.33450156450271606\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1722.4117431640625\n",
      "MAE:  27.68043327331543\n",
      "RMSE: 41.501949310302734\n",
      "MAPE: 0.3777657747268677\n",
      "MSPE: 0.7317356467247009\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24419\n",
      "[DEBUG] Original dataset length: 24419\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21417\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3375\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "\titers: 100, epoch: 1 | loss: 0.3722519\n",
      "\tspeed: 0.0294s/iter; left time: 115.1401s\n",
      "\titers: 200, epoch: 1 | loss: 0.2078429\n",
      "\tspeed: 0.0312s/iter; left time: 119.0026s\n",
      "\titers: 300, epoch: 1 | loss: 0.1992542\n",
      "\tspeed: 0.0297s/iter; left time: 110.4590s\n",
      "\titers: 400, epoch: 1 | loss: 0.1959002\n",
      "\tspeed: 0.0284s/iter; left time: 102.8048s\n",
      "\titers: 500, epoch: 1 | loss: 0.2454617\n",
      "\tspeed: 0.0292s/iter; left time: 102.6795s\n",
      "\titers: 600, epoch: 1 | loss: 0.2298204\n",
      "\tspeed: 0.0289s/iter; left time: 98.6916s\n",
      "Epoch: 1 cost time: 19.82342219352722\n",
      "Epoch: 1, Steps: 669 | Train Loss: 0.2722199 Vali Loss: 0.3460421 Test Loss: 0.2811190\n",
      "Validation loss decreased (inf --> 0.346042).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1345122\n",
      "\tspeed: 0.0858s/iter; left time: 278.5615s\n",
      "\titers: 200, epoch: 2 | loss: 0.1781741\n",
      "\tspeed: 0.0309s/iter; left time: 97.1203s\n",
      "\titers: 300, epoch: 2 | loss: 0.1688313\n",
      "\tspeed: 0.0298s/iter; left time: 90.7331s\n",
      "\titers: 400, epoch: 2 | loss: 0.1567043\n",
      "\tspeed: 0.0322s/iter; left time: 94.8994s\n",
      "\titers: 500, epoch: 2 | loss: 0.1289862\n",
      "\tspeed: 0.0301s/iter; left time: 85.7472s\n",
      "\titers: 600, epoch: 2 | loss: 0.1606031\n",
      "\tspeed: 0.0296s/iter; left time: 81.2907s\n",
      "Epoch: 2 cost time: 20.461806297302246\n",
      "Epoch: 2, Steps: 669 | Train Loss: 0.2033413 Vali Loss: 0.3444316 Test Loss: 0.2736827\n",
      "Validation loss decreased (0.346042 --> 0.344432).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1336813\n",
      "\tspeed: 0.0836s/iter; left time: 215.4440s\n",
      "\titers: 200, epoch: 3 | loss: 0.1990564\n",
      "\tspeed: 0.0302s/iter; left time: 74.7788s\n",
      "\titers: 300, epoch: 3 | loss: 0.1341690\n",
      "\tspeed: 0.0298s/iter; left time: 70.8202s\n",
      "\titers: 400, epoch: 3 | loss: 0.1507725\n",
      "\tspeed: 0.0305s/iter; left time: 69.5228s\n",
      "\titers: 500, epoch: 3 | loss: 0.1556357\n",
      "\tspeed: 0.0302s/iter; left time: 65.7968s\n",
      "\titers: 600, epoch: 3 | loss: 0.1334959\n",
      "\tspeed: 0.0318s/iter; left time: 66.0478s\n",
      "Epoch: 3 cost time: 20.2076575756073\n",
      "Epoch: 3, Steps: 669 | Train Loss: 0.1777899 Vali Loss: 0.3137172 Test Loss: 0.2442333\n",
      "Validation loss decreased (0.344432 --> 0.313717).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2161897\n",
      "\tspeed: 0.0841s/iter; left time: 160.5332s\n",
      "\titers: 200, epoch: 4 | loss: 0.1258255\n",
      "\tspeed: 0.0306s/iter; left time: 55.3721s\n",
      "\titers: 300, epoch: 4 | loss: 0.2240745\n",
      "\tspeed: 0.0315s/iter; left time: 53.8771s\n",
      "\titers: 400, epoch: 4 | loss: 0.1221924\n",
      "\tspeed: 0.0289s/iter; left time: 46.4255s\n",
      "\titers: 500, epoch: 4 | loss: 0.1536993\n",
      "\tspeed: 0.0295s/iter; left time: 44.4526s\n",
      "\titers: 600, epoch: 4 | loss: 0.1682727\n",
      "\tspeed: 0.0301s/iter; left time: 42.4045s\n",
      "Epoch: 4 cost time: 20.15827775001526\n",
      "Epoch: 4, Steps: 669 | Train Loss: 0.1615465 Vali Loss: 0.3182318 Test Loss: 0.2458278\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1275859\n",
      "\tspeed: 0.0865s/iter; left time: 107.2235s\n",
      "\titers: 200, epoch: 5 | loss: 0.1459723\n",
      "\tspeed: 0.0288s/iter; left time: 32.7485s\n",
      "\titers: 300, epoch: 5 | loss: 0.1253775\n",
      "\tspeed: 0.0291s/iter; left time: 30.1922s\n",
      "\titers: 400, epoch: 5 | loss: 0.1553330\n",
      "\tspeed: 0.0282s/iter; left time: 26.5248s\n",
      "\titers: 500, epoch: 5 | loss: 0.2334034\n",
      "\tspeed: 0.0308s/iter; left time: 25.8070s\n",
      "\titers: 600, epoch: 5 | loss: 0.1953025\n",
      "\tspeed: 0.0302s/iter; left time: 22.3326s\n",
      "Epoch: 5 cost time: 19.784204483032227\n",
      "Epoch: 5, Steps: 669 | Train Loss: 0.1527169 Vali Loss: 0.3183437 Test Loss: 0.2484394\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1459051\n",
      "\tspeed: 0.0823s/iter; left time: 46.9220s\n",
      "\titers: 200, epoch: 6 | loss: 0.0881931\n",
      "\tspeed: 0.0301s/iter; left time: 14.1525s\n",
      "\titers: 300, epoch: 6 | loss: 0.1513776\n",
      "\tspeed: 0.0306s/iter; left time: 11.3291s\n",
      "\titers: 400, epoch: 6 | loss: 0.1046793\n",
      "\tspeed: 0.0301s/iter; left time: 8.1302s\n",
      "\titers: 500, epoch: 6 | loss: 0.1748990\n",
      "\tspeed: 0.0289s/iter; left time: 4.9114s\n",
      "\titers: 600, epoch: 6 | loss: 0.1783435\n",
      "\tspeed: 0.0295s/iter; left time: 2.0616s\n",
      "Epoch: 6 cost time: 19.856738328933716\n",
      "Epoch: 6, Steps: 669 | Train Loss: 0.1473295 Vali Loss: 0.3328100 Test Loss: 0.2570680\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "Test cost time: 2.0554s\n",
      "test shape: (177, 32, 6, 1) (177, 32, 6, 1)\n",
      "test shape: (5664, 6, 1) (5664, 6, 1)\n",
      "mse:0.24445855617523193, mae:0.32256603240966797\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1673.997314453125\n",
      "MAE:  26.692752838134766\n",
      "RMSE: 40.914512634277344\n",
      "MAPE: 0.30658742785453796\n",
      "MSPE: 0.408983051776886\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24419\n",
      "[DEBUG] Original dataset length: 24419\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21417\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3375\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "\titers: 100, epoch: 1 | loss: 0.1766875\n",
      "\tspeed: 0.0296s/iter; left time: 115.8071s\n",
      "\titers: 200, epoch: 1 | loss: 0.2898481\n",
      "\tspeed: 0.0293s/iter; left time: 111.7454s\n",
      "\titers: 300, epoch: 1 | loss: 0.1890761\n",
      "\tspeed: 0.0292s/iter; left time: 108.5209s\n",
      "\titers: 400, epoch: 1 | loss: 0.3579829\n",
      "\tspeed: 0.0317s/iter; left time: 114.5493s\n",
      "\titers: 500, epoch: 1 | loss: 0.2242780\n",
      "\tspeed: 0.0292s/iter; left time: 102.7072s\n",
      "\titers: 600, epoch: 1 | loss: 0.1969734\n",
      "\tspeed: 0.0295s/iter; left time: 100.7753s\n",
      "Epoch: 1 cost time: 19.8271963596344\n",
      "Epoch: 1, Steps: 669 | Train Loss: 0.2792591 Vali Loss: 0.3477232 Test Loss: 0.2717884\n",
      "Validation loss decreased (inf --> 0.347723).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2274358\n",
      "\tspeed: 0.0821s/iter; left time: 266.4467s\n",
      "\titers: 200, epoch: 2 | loss: 0.1619924\n",
      "\tspeed: 0.0290s/iter; left time: 91.3549s\n",
      "\titers: 300, epoch: 2 | loss: 0.2213582\n",
      "\tspeed: 0.0286s/iter; left time: 87.1551s\n",
      "\titers: 400, epoch: 2 | loss: 0.1845807\n",
      "\tspeed: 0.0295s/iter; left time: 86.8071s\n",
      "\titers: 500, epoch: 2 | loss: 0.1090104\n",
      "\tspeed: 0.0301s/iter; left time: 85.7097s\n",
      "\titers: 600, epoch: 2 | loss: 0.1955018\n",
      "\tspeed: 0.0308s/iter; left time: 84.6219s\n",
      "Epoch: 2 cost time: 19.763458967208862\n",
      "Epoch: 2, Steps: 669 | Train Loss: 0.2061150 Vali Loss: 0.3415181 Test Loss: 0.2717795\n",
      "Validation loss decreased (0.347723 --> 0.341518).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1305665\n",
      "\tspeed: 0.0827s/iter; left time: 213.1702s\n",
      "\titers: 200, epoch: 3 | loss: 0.3152400\n",
      "\tspeed: 0.0293s/iter; left time: 72.5801s\n",
      "\titers: 300, epoch: 3 | loss: 0.1867478\n",
      "\tspeed: 0.0298s/iter; left time: 70.7890s\n",
      "\titers: 400, epoch: 3 | loss: 0.1817921\n",
      "\tspeed: 0.0313s/iter; left time: 71.3483s\n",
      "\titers: 500, epoch: 3 | loss: 0.1659057\n",
      "\tspeed: 0.0291s/iter; left time: 63.4420s\n",
      "\titers: 600, epoch: 3 | loss: 0.1748783\n",
      "\tspeed: 0.0290s/iter; left time: 60.1359s\n",
      "Epoch: 3 cost time: 19.871044874191284\n",
      "Epoch: 3, Steps: 669 | Train Loss: 0.1777980 Vali Loss: 0.3171933 Test Loss: 0.2709894\n",
      "Validation loss decreased (0.341518 --> 0.317193).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1415166\n",
      "\tspeed: 0.0852s/iter; left time: 162.6109s\n",
      "\titers: 200, epoch: 4 | loss: 0.3948245\n",
      "\tspeed: 0.0297s/iter; left time: 53.6173s\n",
      "\titers: 300, epoch: 4 | loss: 0.1120557\n",
      "\tspeed: 0.0291s/iter; left time: 49.6209s\n",
      "\titers: 400, epoch: 4 | loss: 0.0839110\n",
      "\tspeed: 0.0294s/iter; left time: 47.2753s\n",
      "\titers: 500, epoch: 4 | loss: 0.1490628\n",
      "\tspeed: 0.0294s/iter; left time: 44.3397s\n",
      "\titers: 600, epoch: 4 | loss: 0.1540286\n",
      "\tspeed: 0.0306s/iter; left time: 43.1461s\n",
      "Epoch: 4 cost time: 19.867923259735107\n",
      "Epoch: 4, Steps: 669 | Train Loss: 0.1637007 Vali Loss: 0.3157906 Test Loss: 0.2489892\n",
      "Validation loss decreased (0.317193 --> 0.315791).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1293163\n",
      "\tspeed: 0.0821s/iter; left time: 101.7446s\n",
      "\titers: 200, epoch: 5 | loss: 0.1053158\n",
      "\tspeed: 0.0295s/iter; left time: 33.5606s\n",
      "\titers: 300, epoch: 5 | loss: 0.1356285\n",
      "\tspeed: 0.0314s/iter; left time: 32.6462s\n",
      "\titers: 400, epoch: 5 | loss: 0.1257097\n",
      "\tspeed: 0.0291s/iter; left time: 27.3035s\n",
      "\titers: 500, epoch: 5 | loss: 0.1213887\n",
      "\tspeed: 0.0299s/iter; left time: 25.0962s\n",
      "\titers: 600, epoch: 5 | loss: 0.1021550\n",
      "\tspeed: 0.0302s/iter; left time: 22.2878s\n",
      "Epoch: 5 cost time: 19.879157304763794\n",
      "Epoch: 5, Steps: 669 | Train Loss: 0.1534192 Vali Loss: 0.3290899 Test Loss: 0.2595619\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1696480\n",
      "\tspeed: 0.0841s/iter; left time: 47.9189s\n",
      "\titers: 200, epoch: 6 | loss: 0.1827508\n",
      "\tspeed: 0.0296s/iter; left time: 13.9113s\n",
      "\titers: 300, epoch: 6 | loss: 0.1492134\n",
      "\tspeed: 0.0303s/iter; left time: 11.2069s\n",
      "\titers: 400, epoch: 6 | loss: 0.1473132\n",
      "\tspeed: 0.0307s/iter; left time: 8.2769s\n",
      "\titers: 500, epoch: 6 | loss: 0.1199862\n",
      "\tspeed: 0.0314s/iter; left time: 5.3412s\n",
      "\titers: 600, epoch: 6 | loss: 0.1447994\n",
      "\tspeed: 0.0302s/iter; left time: 2.1168s\n",
      "Epoch: 6 cost time: 20.330076694488525\n",
      "Epoch: 6, Steps: 669 | Train Loss: 0.1479750 Vali Loss: 0.3305779 Test Loss: 0.2603847\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "Test cost time: 2.0830s\n",
      "test shape: (177, 32, 6, 1) (177, 32, 6, 1)\n",
      "test shape: (5664, 6, 1) (5664, 6, 1)\n",
      "mse:0.24830690026283264, mae:0.32285362482070923\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1700.35009765625\n",
      "MAE:  26.716552734375\n",
      "RMSE: 41.23530197143555\n",
      "MAPE: 0.32526084780693054\n",
      "MSPE: 0.5185482501983643\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24419\n",
      "[DEBUG] Original dataset length: 24419\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21417\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3375\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "\titers: 100, epoch: 1 | loss: 0.3129759\n",
      "\tspeed: 0.0308s/iter; left time: 120.5281s\n",
      "\titers: 200, epoch: 1 | loss: 0.3183265\n",
      "\tspeed: 0.0314s/iter; left time: 119.8452s\n",
      "\titers: 300, epoch: 1 | loss: 0.2155317\n",
      "\tspeed: 0.0302s/iter; left time: 112.0263s\n",
      "\titers: 400, epoch: 1 | loss: 0.1623970\n",
      "\tspeed: 0.0290s/iter; left time: 104.8507s\n",
      "\titers: 500, epoch: 1 | loss: 0.3066226\n",
      "\tspeed: 0.0292s/iter; left time: 102.7804s\n",
      "\titers: 600, epoch: 1 | loss: 0.1395139\n",
      "\tspeed: 0.0309s/iter; left time: 105.4476s\n",
      "Epoch: 1 cost time: 20.215270280838013\n",
      "Epoch: 1, Steps: 669 | Train Loss: 0.2814849 Vali Loss: 0.3367173 Test Loss: 0.2795452\n",
      "Validation loss decreased (inf --> 0.336717).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4737352\n",
      "\tspeed: 0.0831s/iter; left time: 269.7210s\n",
      "\titers: 200, epoch: 2 | loss: 0.1848485\n",
      "\tspeed: 0.0300s/iter; left time: 94.3635s\n",
      "\titers: 300, epoch: 2 | loss: 0.1400216\n",
      "\tspeed: 0.0304s/iter; left time: 92.5156s\n",
      "\titers: 400, epoch: 2 | loss: 0.3328413\n",
      "\tspeed: 0.0301s/iter; left time: 88.6974s\n",
      "\titers: 500, epoch: 2 | loss: 0.2249845\n",
      "\tspeed: 0.0291s/iter; left time: 82.7807s\n",
      "\titers: 600, epoch: 2 | loss: 0.2149262\n",
      "\tspeed: 0.0286s/iter; left time: 78.5552s\n",
      "Epoch: 2 cost time: 19.750216960906982\n",
      "Epoch: 2, Steps: 669 | Train Loss: 0.2089880 Vali Loss: 0.3343337 Test Loss: 0.2789277\n",
      "Validation loss decreased (0.336717 --> 0.334334).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2431273\n",
      "\tspeed: 0.0860s/iter; left time: 221.6141s\n",
      "\titers: 200, epoch: 3 | loss: 0.1977098\n",
      "\tspeed: 0.0292s/iter; left time: 72.3509s\n",
      "\titers: 300, epoch: 3 | loss: 0.1726256\n",
      "\tspeed: 0.0285s/iter; left time: 67.8065s\n",
      "\titers: 400, epoch: 3 | loss: 0.1581546\n",
      "\tspeed: 0.0287s/iter; left time: 65.2416s\n",
      "\titers: 500, epoch: 3 | loss: 0.2978215\n",
      "\tspeed: 0.0290s/iter; left time: 63.1750s\n",
      "\titers: 600, epoch: 3 | loss: 0.2591465\n",
      "\tspeed: 0.0310s/iter; left time: 64.3723s\n",
      "Epoch: 3 cost time: 19.970731496810913\n",
      "Epoch: 3, Steps: 669 | Train Loss: 0.1785396 Vali Loss: 0.3185647 Test Loss: 0.2581359\n",
      "Validation loss decreased (0.334334 --> 0.318565).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1771811\n",
      "\tspeed: 0.0844s/iter; left time: 161.1179s\n",
      "\titers: 200, epoch: 4 | loss: 0.1134176\n",
      "\tspeed: 0.0289s/iter; left time: 52.1938s\n",
      "\titers: 300, epoch: 4 | loss: 0.2656380\n",
      "\tspeed: 0.0306s/iter; left time: 52.1833s\n",
      "\titers: 400, epoch: 4 | loss: 0.1405503\n",
      "\tspeed: 0.0288s/iter; left time: 46.3140s\n",
      "\titers: 500, epoch: 4 | loss: 0.2711481\n",
      "\tspeed: 0.0289s/iter; left time: 43.5685s\n",
      "\titers: 600, epoch: 4 | loss: 0.1933218\n",
      "\tspeed: 0.0296s/iter; left time: 41.6899s\n",
      "Epoch: 4 cost time: 19.49726676940918\n",
      "Epoch: 4, Steps: 669 | Train Loss: 0.1619136 Vali Loss: 0.3220675 Test Loss: 0.2595217\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1651717\n",
      "\tspeed: 0.0820s/iter; left time: 101.5486s\n",
      "\titers: 200, epoch: 5 | loss: 0.1040614\n",
      "\tspeed: 0.0289s/iter; left time: 32.9685s\n",
      "\titers: 300, epoch: 5 | loss: 0.1625568\n",
      "\tspeed: 0.0289s/iter; left time: 29.9839s\n",
      "\titers: 400, epoch: 5 | loss: 0.1254661\n",
      "\tspeed: 0.0310s/iter; left time: 29.0693s\n",
      "\titers: 500, epoch: 5 | loss: 0.1224186\n",
      "\tspeed: 0.0307s/iter; left time: 25.7364s\n",
      "\titers: 600, epoch: 5 | loss: 0.1105497\n",
      "\tspeed: 0.0318s/iter; left time: 23.4847s\n",
      "Epoch: 5 cost time: 20.129689693450928\n",
      "Epoch: 5, Steps: 669 | Train Loss: 0.1524313 Vali Loss: 0.3248854 Test Loss: 0.2572644\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1269851\n",
      "\tspeed: 0.0839s/iter; left time: 47.8024s\n",
      "\titers: 200, epoch: 6 | loss: 0.2270852\n",
      "\tspeed: 0.0292s/iter; left time: 13.7311s\n",
      "\titers: 300, epoch: 6 | loss: 0.1456115\n",
      "\tspeed: 0.0309s/iter; left time: 11.4254s\n",
      "\titers: 400, epoch: 6 | loss: 0.1440899\n",
      "\tspeed: 0.0291s/iter; left time: 7.8500s\n",
      "\titers: 500, epoch: 6 | loss: 0.3186296\n",
      "\tspeed: 0.0294s/iter; left time: 4.9965s\n",
      "\titers: 600, epoch: 6 | loss: 0.1303986\n",
      "\tspeed: 0.0287s/iter; left time: 2.0102s\n",
      "Epoch: 6 cost time: 19.639769315719604\n",
      "Epoch: 6, Steps: 669 | Train Loss: 0.1476486 Vali Loss: 0.3225944 Test Loss: 0.2544409\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "Test cost time: 1.9958s\n",
      "test shape: (177, 32, 6, 1) (177, 32, 6, 1)\n",
      "test shape: (5664, 6, 1) (5664, 6, 1)\n",
      "mse:0.25720837712287903, mae:0.32841095328330994\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1761.3050537109375\n",
      "MAE:  27.176427841186523\n",
      "RMSE: 41.96790313720703\n",
      "MAPE: 0.31747156381607056\n",
      "MSPE: 0.4644535481929779\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24419\n",
      "[DEBUG] Original dataset length: 24419\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21417\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3375\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "\titers: 100, epoch: 1 | loss: 0.3175164\n",
      "\tspeed: 0.0283s/iter; left time: 110.6791s\n",
      "\titers: 200, epoch: 1 | loss: 0.2460282\n",
      "\tspeed: 0.0293s/iter; left time: 111.7100s\n",
      "\titers: 300, epoch: 1 | loss: 0.2169060\n",
      "\tspeed: 0.0290s/iter; left time: 107.6451s\n",
      "\titers: 400, epoch: 1 | loss: 0.2816267\n",
      "\tspeed: 0.0316s/iter; left time: 114.2832s\n",
      "\titers: 500, epoch: 1 | loss: 0.2790151\n",
      "\tspeed: 0.0308s/iter; left time: 108.2420s\n",
      "\titers: 600, epoch: 1 | loss: 0.4160570\n",
      "\tspeed: 0.0294s/iter; left time: 100.3294s\n",
      "Epoch: 1 cost time: 19.934784650802612\n",
      "Epoch: 1, Steps: 669 | Train Loss: 0.2755758 Vali Loss: 0.3420117 Test Loss: 0.2813919\n",
      "Validation loss decreased (inf --> 0.342012).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1903886\n",
      "\tspeed: 0.0856s/iter; left time: 278.0188s\n",
      "\titers: 200, epoch: 2 | loss: 0.2268245\n",
      "\tspeed: 0.0305s/iter; left time: 96.0655s\n",
      "\titers: 300, epoch: 2 | loss: 0.2251563\n",
      "\tspeed: 0.0294s/iter; left time: 89.6140s\n",
      "\titers: 400, epoch: 2 | loss: 0.2041740\n",
      "\tspeed: 0.0286s/iter; left time: 84.1513s\n",
      "\titers: 500, epoch: 2 | loss: 0.1849482\n",
      "\tspeed: 0.0298s/iter; left time: 84.7326s\n",
      "\titers: 600, epoch: 2 | loss: 0.1521134\n",
      "\tspeed: 0.0298s/iter; left time: 81.9549s\n",
      "Epoch: 2 cost time: 19.99004364013672\n",
      "Epoch: 2, Steps: 669 | Train Loss: 0.2056404 Vali Loss: 0.3295598 Test Loss: 0.2639320\n",
      "Validation loss decreased (0.342012 --> 0.329560).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1781307\n",
      "\tspeed: 0.0838s/iter; left time: 216.0203s\n",
      "\titers: 200, epoch: 3 | loss: 0.2166627\n",
      "\tspeed: 0.0288s/iter; left time: 71.4197s\n",
      "\titers: 300, epoch: 3 | loss: 0.1839844\n",
      "\tspeed: 0.0293s/iter; left time: 69.6889s\n",
      "\titers: 400, epoch: 3 | loss: 0.2134436\n",
      "\tspeed: 0.0304s/iter; left time: 69.3256s\n",
      "\titers: 500, epoch: 3 | loss: 0.1650638\n",
      "\tspeed: 0.0286s/iter; left time: 62.3048s\n",
      "\titers: 600, epoch: 3 | loss: 0.1389435\n",
      "\tspeed: 0.0285s/iter; left time: 59.2112s\n",
      "Epoch: 3 cost time: 19.468640327453613\n",
      "Epoch: 3, Steps: 669 | Train Loss: 0.1768164 Vali Loss: 0.3290736 Test Loss: 0.2496651\n",
      "Validation loss decreased (0.329560 --> 0.329074).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1700998\n",
      "\tspeed: 0.0847s/iter; left time: 161.5441s\n",
      "\titers: 200, epoch: 4 | loss: 0.1883674\n",
      "\tspeed: 0.0288s/iter; left time: 52.0590s\n",
      "\titers: 300, epoch: 4 | loss: 0.1378731\n",
      "\tspeed: 0.0294s/iter; left time: 50.2651s\n",
      "\titers: 400, epoch: 4 | loss: 0.2412249\n",
      "\tspeed: 0.0300s/iter; left time: 48.2076s\n",
      "\titers: 500, epoch: 4 | loss: 0.1179490\n",
      "\tspeed: 0.0294s/iter; left time: 44.2828s\n",
      "\titers: 600, epoch: 4 | loss: 0.1686318\n",
      "\tspeed: 0.0311s/iter; left time: 43.7782s\n",
      "Epoch: 4 cost time: 19.992467641830444\n",
      "Epoch: 4, Steps: 669 | Train Loss: 0.1613031 Vali Loss: 0.3274207 Test Loss: 0.2450488\n",
      "Validation loss decreased (0.329074 --> 0.327421).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1355752\n",
      "\tspeed: 0.0830s/iter; left time: 102.8797s\n",
      "\titers: 200, epoch: 5 | loss: 0.1340965\n",
      "\tspeed: 0.0292s/iter; left time: 33.2821s\n",
      "\titers: 300, epoch: 5 | loss: 0.1651927\n",
      "\tspeed: 0.0318s/iter; left time: 33.0710s\n",
      "\titers: 400, epoch: 5 | loss: 0.1535073\n",
      "\tspeed: 0.0298s/iter; left time: 27.9353s\n",
      "\titers: 500, epoch: 5 | loss: 0.1281655\n",
      "\tspeed: 0.0286s/iter; left time: 23.9570s\n",
      "\titers: 600, epoch: 5 | loss: 0.1093214\n",
      "\tspeed: 0.0289s/iter; left time: 21.3897s\n",
      "Epoch: 5 cost time: 19.603896617889404\n",
      "Epoch: 5, Steps: 669 | Train Loss: 0.1513299 Vali Loss: 0.3360975 Test Loss: 0.2464703\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1156439\n",
      "\tspeed: 0.0825s/iter; left time: 47.0011s\n",
      "\titers: 200, epoch: 6 | loss: 0.1227821\n",
      "\tspeed: 0.0280s/iter; left time: 13.1676s\n",
      "\titers: 300, epoch: 6 | loss: 0.1295363\n",
      "\tspeed: 0.0298s/iter; left time: 11.0418s\n",
      "\titers: 400, epoch: 6 | loss: 0.1316656\n",
      "\tspeed: 0.0369s/iter; left time: 9.9735s\n",
      "\titers: 500, epoch: 6 | loss: 0.1174205\n",
      "\tspeed: 0.0324s/iter; left time: 5.5160s\n",
      "\titers: 600, epoch: 6 | loss: 0.1590780\n",
      "\tspeed: 0.0300s/iter; left time: 2.1007s\n",
      "Epoch: 6 cost time: 20.793537139892578\n",
      "Epoch: 6, Steps: 669 | Train Loss: 0.1461874 Vali Loss: 0.3450511 Test Loss: 0.2517073\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "Test cost time: 1.9984s\n",
      "test shape: (177, 32, 6, 1) (177, 32, 6, 1)\n",
      "test shape: (5664, 6, 1) (5664, 6, 1)\n",
      "mse:0.24388404190540314, mae:0.3303932547569275\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1670.0631103515625\n",
      "MAE:  27.34046745300293\n",
      "RMSE: 40.86640548706055\n",
      "MAPE: 0.34752771258354187\n",
      "MSPE: 0.5988611578941345\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24419\n",
      "[DEBUG] Original dataset length: 24419\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21417\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3375\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "\titers: 100, epoch: 1 | loss: 0.2483055\n",
      "\tspeed: 0.0313s/iter; left time: 122.4440s\n",
      "\titers: 200, epoch: 1 | loss: 0.2184395\n",
      "\tspeed: 0.0291s/iter; left time: 111.1585s\n",
      "\titers: 300, epoch: 1 | loss: 0.3362479\n",
      "\tspeed: 0.0301s/iter; left time: 111.7839s\n",
      "\titers: 400, epoch: 1 | loss: 0.1719485\n",
      "\tspeed: 0.0299s/iter; left time: 108.0364s\n",
      "\titers: 500, epoch: 1 | loss: 0.2879986\n",
      "\tspeed: 0.0292s/iter; left time: 102.7952s\n",
      "\titers: 600, epoch: 1 | loss: 0.1799295\n",
      "\tspeed: 0.0310s/iter; left time: 105.9617s\n",
      "Epoch: 1 cost time: 20.065123081207275\n",
      "Epoch: 1, Steps: 669 | Train Loss: 0.2779948 Vali Loss: 0.3615663 Test Loss: 0.2974364\n",
      "Validation loss decreased (inf --> 0.361566).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2083639\n",
      "\tspeed: 0.0818s/iter; left time: 265.3878s\n",
      "\titers: 200, epoch: 2 | loss: 0.2779917\n",
      "\tspeed: 0.0293s/iter; left time: 92.2840s\n",
      "\titers: 300, epoch: 2 | loss: 0.2283624\n",
      "\tspeed: 0.0306s/iter; left time: 93.0614s\n",
      "\titers: 400, epoch: 2 | loss: 0.2376982\n",
      "\tspeed: 0.0305s/iter; left time: 89.8651s\n",
      "\titers: 500, epoch: 2 | loss: 0.1473158\n",
      "\tspeed: 0.0292s/iter; left time: 83.1350s\n",
      "\titers: 600, epoch: 2 | loss: 0.1933712\n",
      "\tspeed: 0.0297s/iter; left time: 81.6460s\n",
      "Epoch: 2 cost time: 19.80774474143982\n",
      "Epoch: 2, Steps: 669 | Train Loss: 0.2039512 Vali Loss: 0.3285629 Test Loss: 0.2609548\n",
      "Validation loss decreased (0.361566 --> 0.328563).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1916445\n",
      "\tspeed: 0.0854s/iter; left time: 220.1731s\n",
      "\titers: 200, epoch: 3 | loss: 0.1203380\n",
      "\tspeed: 0.0291s/iter; left time: 72.0709s\n",
      "\titers: 300, epoch: 3 | loss: 0.1825899\n",
      "\tspeed: 0.0311s/iter; left time: 74.0374s\n",
      "\titers: 400, epoch: 3 | loss: 0.1178923\n",
      "\tspeed: 0.0314s/iter; left time: 71.6047s\n",
      "\titers: 500, epoch: 3 | loss: 0.1693854\n",
      "\tspeed: 0.0302s/iter; left time: 65.7596s\n",
      "\titers: 600, epoch: 3 | loss: 0.1453839\n",
      "\tspeed: 0.0312s/iter; left time: 64.7248s\n",
      "Epoch: 3 cost time: 20.540021419525146\n",
      "Epoch: 3, Steps: 669 | Train Loss: 0.1752684 Vali Loss: 0.3160602 Test Loss: 0.2388015\n",
      "Validation loss decreased (0.328563 --> 0.316060).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1450907\n",
      "\tspeed: 0.0863s/iter; left time: 164.7084s\n",
      "\titers: 200, epoch: 4 | loss: 0.1507808\n",
      "\tspeed: 0.0305s/iter; left time: 55.1030s\n",
      "\titers: 300, epoch: 4 | loss: 0.1215773\n",
      "\tspeed: 0.0314s/iter; left time: 53.7132s\n",
      "\titers: 400, epoch: 4 | loss: 0.1039639\n",
      "\tspeed: 0.0296s/iter; left time: 47.6605s\n",
      "\titers: 500, epoch: 4 | loss: 0.1687682\n",
      "\tspeed: 0.0294s/iter; left time: 44.3306s\n",
      "\titers: 600, epoch: 4 | loss: 0.1373677\n",
      "\tspeed: 0.0299s/iter; left time: 42.0558s\n",
      "Epoch: 4 cost time: 20.181318044662476\n",
      "Epoch: 4, Steps: 669 | Train Loss: 0.1609861 Vali Loss: 0.3338525 Test Loss: 0.2516915\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1154382\n",
      "\tspeed: 0.0852s/iter; left time: 105.5120s\n",
      "\titers: 200, epoch: 5 | loss: 0.0716343\n",
      "\tspeed: 0.0289s/iter; left time: 32.8892s\n",
      "\titers: 300, epoch: 5 | loss: 0.1249299\n",
      "\tspeed: 0.0300s/iter; left time: 31.1317s\n",
      "\titers: 400, epoch: 5 | loss: 0.1378342\n",
      "\tspeed: 0.0285s/iter; left time: 26.7167s\n",
      "\titers: 500, epoch: 5 | loss: 0.1228136\n",
      "\tspeed: 0.0317s/iter; left time: 26.5867s\n",
      "\titers: 600, epoch: 5 | loss: 0.1019103\n",
      "\tspeed: 0.0298s/iter; left time: 22.0029s\n",
      "Epoch: 5 cost time: 19.90030026435852\n",
      "Epoch: 5, Steps: 669 | Train Loss: 0.1513874 Vali Loss: 0.3195185 Test Loss: 0.2450003\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1355816\n",
      "\tspeed: 0.0850s/iter; left time: 48.4327s\n",
      "\titers: 200, epoch: 6 | loss: 0.0998080\n",
      "\tspeed: 0.0322s/iter; left time: 15.1303s\n",
      "\titers: 300, epoch: 6 | loss: 0.2422763\n",
      "\tspeed: 0.0296s/iter; left time: 10.9567s\n",
      "\titers: 400, epoch: 6 | loss: 0.1175375\n",
      "\tspeed: 0.0307s/iter; left time: 8.2803s\n",
      "\titers: 500, epoch: 6 | loss: 0.1013665\n",
      "\tspeed: 0.0285s/iter; left time: 4.8454s\n",
      "\titers: 600, epoch: 6 | loss: 0.1016338\n",
      "\tspeed: 0.0279s/iter; left time: 1.9563s\n",
      "Epoch: 6 cost time: 20.197235107421875\n",
      "Epoch: 6, Steps: 669 | Train Loss: 0.1461930 Vali Loss: 0.3280589 Test Loss: 0.2447528\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "Test cost time: 2.0572s\n",
      "test shape: (177, 32, 6, 1) (177, 32, 6, 1)\n",
      "test shape: (5664, 6, 1) (5664, 6, 1)\n",
      "mse:0.23826181888580322, mae:0.32225674390792847\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1631.5635986328125\n",
      "MAE:  26.667160034179688\n",
      "RMSE: 40.392616271972656\n",
      "MAPE: 0.3717328906059265\n",
      "MSPE: 0.74078768491745\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24419\n",
      "[DEBUG] Original dataset length: 24419\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21417\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3375\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "\titers: 100, epoch: 1 | loss: 0.3367557\n",
      "\tspeed: 0.0292s/iter; left time: 114.3947s\n",
      "\titers: 200, epoch: 1 | loss: 0.3076052\n",
      "\tspeed: 0.0286s/iter; left time: 109.2354s\n",
      "\titers: 300, epoch: 1 | loss: 0.2676283\n",
      "\tspeed: 0.0304s/iter; left time: 113.0683s\n",
      "\titers: 400, epoch: 1 | loss: 0.2702767\n",
      "\tspeed: 0.0298s/iter; left time: 107.7858s\n",
      "\titers: 500, epoch: 1 | loss: 0.1744750\n",
      "\tspeed: 0.0297s/iter; left time: 104.3365s\n",
      "\titers: 600, epoch: 1 | loss: 0.2288814\n",
      "\tspeed: 0.0296s/iter; left time: 101.1642s\n",
      "Epoch: 1 cost time: 19.817902326583862\n",
      "Epoch: 1, Steps: 669 | Train Loss: 0.2823472 Vali Loss: 0.3467079 Test Loss: 0.2705573\n",
      "Validation loss decreased (inf --> 0.346708).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1400348\n",
      "\tspeed: 0.0854s/iter; left time: 277.1835s\n",
      "\titers: 200, epoch: 2 | loss: 0.1833047\n",
      "\tspeed: 0.0297s/iter; left time: 93.4298s\n",
      "\titers: 300, epoch: 2 | loss: 0.1757093\n",
      "\tspeed: 0.0285s/iter; left time: 86.8992s\n",
      "\titers: 400, epoch: 2 | loss: 0.2631150\n",
      "\tspeed: 0.0296s/iter; left time: 87.1818s\n",
      "\titers: 500, epoch: 2 | loss: 0.1416335\n",
      "\tspeed: 0.0308s/iter; left time: 87.6277s\n",
      "\titers: 600, epoch: 2 | loss: 0.1230639\n",
      "\tspeed: 0.0303s/iter; left time: 83.2218s\n",
      "Epoch: 2 cost time: 20.069616317749023\n",
      "Epoch: 2, Steps: 669 | Train Loss: 0.2044819 Vali Loss: 0.3232858 Test Loss: 0.2592351\n",
      "Validation loss decreased (0.346708 --> 0.323286).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1787371\n",
      "\tspeed: 0.0852s/iter; left time: 219.6384s\n",
      "\titers: 200, epoch: 3 | loss: 0.2500333\n",
      "\tspeed: 0.0303s/iter; left time: 74.9965s\n",
      "\titers: 300, epoch: 3 | loss: 0.1426336\n",
      "\tspeed: 0.0319s/iter; left time: 75.8018s\n",
      "\titers: 400, epoch: 3 | loss: 0.1429830\n",
      "\tspeed: 0.0292s/iter; left time: 66.3768s\n",
      "\titers: 500, epoch: 3 | loss: 0.1613368\n",
      "\tspeed: 0.0287s/iter; left time: 62.4292s\n",
      "\titers: 600, epoch: 3 | loss: 0.1646766\n",
      "\tspeed: 0.0288s/iter; left time: 59.7865s\n",
      "Epoch: 3 cost time: 19.93454122543335\n",
      "Epoch: 3, Steps: 669 | Train Loss: 0.1775021 Vali Loss: 0.3295041 Test Loss: 0.2579264\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1773598\n",
      "\tspeed: 0.0828s/iter; left time: 157.9148s\n",
      "\titers: 200, epoch: 4 | loss: 0.2588739\n",
      "\tspeed: 0.0294s/iter; left time: 53.1534s\n",
      "\titers: 300, epoch: 4 | loss: 0.1399405\n",
      "\tspeed: 0.0290s/iter; left time: 49.4664s\n",
      "\titers: 400, epoch: 4 | loss: 0.2040240\n",
      "\tspeed: 0.0291s/iter; left time: 46.7215s\n",
      "\titers: 500, epoch: 4 | loss: 0.1220358\n",
      "\tspeed: 0.0319s/iter; left time: 48.0999s\n",
      "\titers: 600, epoch: 4 | loss: 0.1222661\n",
      "\tspeed: 0.0311s/iter; left time: 43.7680s\n",
      "Epoch: 4 cost time: 20.022085189819336\n",
      "Epoch: 4, Steps: 669 | Train Loss: 0.1610487 Vali Loss: 0.3280000 Test Loss: 0.2524072\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1046434\n",
      "\tspeed: 0.0863s/iter; left time: 106.9123s\n",
      "\titers: 200, epoch: 5 | loss: 0.2330143\n",
      "\tspeed: 0.0321s/iter; left time: 36.6135s\n",
      "\titers: 300, epoch: 5 | loss: 0.1346420\n",
      "\tspeed: 0.0295s/iter; left time: 30.6341s\n",
      "\titers: 400, epoch: 5 | loss: 0.1001600\n",
      "\tspeed: 0.0287s/iter; left time: 26.9172s\n",
      "\titers: 500, epoch: 5 | loss: 0.0960345\n",
      "\tspeed: 0.0293s/iter; left time: 24.5648s\n",
      "\titers: 600, epoch: 5 | loss: 0.1024988\n",
      "\tspeed: 0.0293s/iter; left time: 21.6387s\n",
      "Epoch: 5 cost time: 20.298980236053467\n",
      "Epoch: 5, Steps: 669 | Train Loss: 0.1519645 Vali Loss: 0.3319539 Test Loss: 0.2553366\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "Test cost time: 2.0006s\n",
      "test shape: (177, 32, 6, 1) (177, 32, 6, 1)\n",
      "test shape: (5664, 6, 1) (5664, 6, 1)\n",
      "mse:0.25937169790267944, mae:0.3545036315917969\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1776.118896484375\n",
      "MAE:  29.335630416870117\n",
      "RMSE: 42.14402389526367\n",
      "MAPE: 0.4527857005596161\n",
      "MSPE: 1.2274961471557617\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24419\n",
      "[DEBUG] Original dataset length: 24419\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21417\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3375\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "\titers: 100, epoch: 1 | loss: 0.2770473\n",
      "\tspeed: 0.0291s/iter; left time: 113.7887s\n",
      "\titers: 200, epoch: 1 | loss: 0.2683533\n",
      "\tspeed: 0.0288s/iter; left time: 109.7170s\n",
      "\titers: 300, epoch: 1 | loss: 0.2365727\n",
      "\tspeed: 0.0304s/iter; left time: 112.8700s\n",
      "\titers: 400, epoch: 1 | loss: 0.2466895\n",
      "\tspeed: 0.0297s/iter; left time: 107.4453s\n",
      "\titers: 500, epoch: 1 | loss: 0.2726954\n",
      "\tspeed: 0.0291s/iter; left time: 102.4513s\n",
      "\titers: 600, epoch: 1 | loss: 0.2015069\n",
      "\tspeed: 0.0289s/iter; left time: 98.8126s\n",
      "Epoch: 1 cost time: 19.6478111743927\n",
      "Epoch: 1, Steps: 669 | Train Loss: 0.2846432 Vali Loss: 0.3199452 Test Loss: 0.2698288\n",
      "Validation loss decreased (inf --> 0.319945).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1698016\n",
      "\tspeed: 0.0849s/iter; left time: 275.4551s\n",
      "\titers: 200, epoch: 2 | loss: 0.2122671\n",
      "\tspeed: 0.0293s/iter; left time: 92.0884s\n",
      "\titers: 300, epoch: 2 | loss: 0.1559289\n",
      "\tspeed: 0.0290s/iter; left time: 88.3594s\n",
      "\titers: 400, epoch: 2 | loss: 0.2845930\n",
      "\tspeed: 0.0300s/iter; left time: 88.4086s\n",
      "\titers: 500, epoch: 2 | loss: 0.1610010\n",
      "\tspeed: 0.0293s/iter; left time: 83.3117s\n",
      "\titers: 600, epoch: 2 | loss: 0.1855573\n",
      "\tspeed: 0.0313s/iter; left time: 85.9682s\n",
      "Epoch: 2 cost time: 19.96553349494934\n",
      "Epoch: 2, Steps: 669 | Train Loss: 0.2074896 Vali Loss: 0.3268122 Test Loss: 0.2708579\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1441421\n",
      "\tspeed: 0.0823s/iter; left time: 212.1504s\n",
      "\titers: 200, epoch: 3 | loss: 0.2001697\n",
      "\tspeed: 0.0295s/iter; left time: 73.1609s\n",
      "\titers: 300, epoch: 3 | loss: 0.1969723\n",
      "\tspeed: 0.0314s/iter; left time: 74.5248s\n",
      "\titers: 400, epoch: 3 | loss: 0.1118765\n",
      "\tspeed: 0.0299s/iter; left time: 68.1285s\n",
      "\titers: 500, epoch: 3 | loss: 0.1576896\n",
      "\tspeed: 0.0288s/iter; left time: 62.6218s\n",
      "\titers: 600, epoch: 3 | loss: 0.2310714\n",
      "\tspeed: 0.0294s/iter; left time: 61.1587s\n",
      "Epoch: 3 cost time: 19.851097583770752\n",
      "Epoch: 3, Steps: 669 | Train Loss: 0.1773895 Vali Loss: 0.3194575 Test Loss: 0.2566895\n",
      "Validation loss decreased (0.319945 --> 0.319458).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1203125\n",
      "\tspeed: 0.0856s/iter; left time: 163.3930s\n",
      "\titers: 200, epoch: 4 | loss: 0.1252383\n",
      "\tspeed: 0.0283s/iter; left time: 51.2524s\n",
      "\titers: 300, epoch: 4 | loss: 0.1066315\n",
      "\tspeed: 0.0295s/iter; left time: 50.4020s\n",
      "\titers: 400, epoch: 4 | loss: 0.1966377\n",
      "\tspeed: 0.0294s/iter; left time: 47.2484s\n",
      "\titers: 500, epoch: 4 | loss: 0.1710977\n",
      "\tspeed: 0.0317s/iter; left time: 47.8118s\n",
      "\titers: 600, epoch: 4 | loss: 0.1970648\n",
      "\tspeed: 0.0293s/iter; left time: 41.2086s\n",
      "Epoch: 4 cost time: 19.88554835319519\n",
      "Epoch: 4, Steps: 669 | Train Loss: 0.1612354 Vali Loss: 0.3096708 Test Loss: 0.2454018\n",
      "Validation loss decreased (0.319458 --> 0.309671).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1283020\n",
      "\tspeed: 0.0844s/iter; left time: 104.5558s\n",
      "\titers: 200, epoch: 5 | loss: 0.1412129\n",
      "\tspeed: 0.0310s/iter; left time: 35.2581s\n",
      "\titers: 300, epoch: 5 | loss: 0.1555951\n",
      "\tspeed: 0.0299s/iter; left time: 31.0430s\n",
      "\titers: 400, epoch: 5 | loss: 0.1349823\n",
      "\tspeed: 0.0295s/iter; left time: 27.7365s\n",
      "\titers: 500, epoch: 5 | loss: 0.1046769\n",
      "\tspeed: 0.0291s/iter; left time: 24.4165s\n",
      "\titers: 600, epoch: 5 | loss: 0.1589835\n",
      "\tspeed: 0.0315s/iter; left time: 23.2871s\n",
      "Epoch: 5 cost time: 20.322624921798706\n",
      "Epoch: 5, Steps: 669 | Train Loss: 0.1516978 Vali Loss: 0.3099232 Test Loss: 0.2520621\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1383567\n",
      "\tspeed: 0.0854s/iter; left time: 48.6874s\n",
      "\titers: 200, epoch: 6 | loss: 0.0915017\n",
      "\tspeed: 0.0295s/iter; left time: 13.8779s\n",
      "\titers: 300, epoch: 6 | loss: 0.1030756\n",
      "\tspeed: 0.0306s/iter; left time: 11.3066s\n",
      "\titers: 400, epoch: 6 | loss: 0.1057058\n",
      "\tspeed: 0.0320s/iter; left time: 8.6470s\n",
      "\titers: 500, epoch: 6 | loss: 0.0999303\n",
      "\tspeed: 0.0299s/iter; left time: 5.0899s\n",
      "\titers: 600, epoch: 6 | loss: 0.1170566\n",
      "\tspeed: 0.0292s/iter; left time: 2.0470s\n",
      "Epoch: 6 cost time: 20.075517654418945\n",
      "Epoch: 6, Steps: 669 | Train Loss: 0.1472113 Vali Loss: 0.3210864 Test Loss: 0.2535749\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "Test cost time: 2.0226s\n",
      "test shape: (177, 32, 6, 1) (177, 32, 6, 1)\n",
      "test shape: (5664, 6, 1) (5664, 6, 1)\n",
      "mse:0.24447588622570038, mae:0.3284424841403961\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1674.115966796875\n",
      "MAE:  27.179035186767578\n",
      "RMSE: 40.91596221923828\n",
      "MAPE: 0.3561098277568817\n",
      "MSPE: 0.6358398795127869\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24419\n",
      "[DEBUG] Original dataset length: 24419\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21417\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3375\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "\titers: 100, epoch: 1 | loss: 0.3639414\n",
      "\tspeed: 0.0308s/iter; left time: 120.6017s\n",
      "\titers: 200, epoch: 1 | loss: 0.2070030\n",
      "\tspeed: 0.0288s/iter; left time: 109.9089s\n",
      "\titers: 300, epoch: 1 | loss: 0.1245842\n",
      "\tspeed: 0.0283s/iter; left time: 105.0894s\n",
      "\titers: 400, epoch: 1 | loss: 0.1947647\n",
      "\tspeed: 0.0285s/iter; left time: 103.1036s\n",
      "\titers: 500, epoch: 1 | loss: 0.1726383\n",
      "\tspeed: 0.0293s/iter; left time: 103.1607s\n",
      "\titers: 600, epoch: 1 | loss: 0.2076362\n",
      "\tspeed: 0.0309s/iter; left time: 105.4404s\n",
      "Epoch: 1 cost time: 19.665568828582764\n",
      "Epoch: 1, Steps: 669 | Train Loss: 0.2783534 Vali Loss: 0.3281251 Test Loss: 0.2691971\n",
      "Validation loss decreased (inf --> 0.328125).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2794638\n",
      "\tspeed: 0.0819s/iter; left time: 265.7673s\n",
      "\titers: 200, epoch: 2 | loss: 0.2165719\n",
      "\tspeed: 0.0295s/iter; left time: 92.6726s\n",
      "\titers: 300, epoch: 2 | loss: 0.1837499\n",
      "\tspeed: 0.0310s/iter; left time: 94.4319s\n",
      "\titers: 400, epoch: 2 | loss: 0.2363719\n",
      "\tspeed: 0.0301s/iter; left time: 88.5725s\n",
      "\titers: 500, epoch: 2 | loss: 0.1931095\n",
      "\tspeed: 0.0291s/iter; left time: 82.7111s\n",
      "\titers: 600, epoch: 2 | loss: 0.2333914\n",
      "\tspeed: 0.0292s/iter; left time: 80.0937s\n",
      "Epoch: 2 cost time: 19.759725093841553\n",
      "Epoch: 2, Steps: 669 | Train Loss: 0.2050948 Vali Loss: 0.3211983 Test Loss: 0.2610125\n",
      "Validation loss decreased (0.328125 --> 0.321198).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2924267\n",
      "\tspeed: 0.0841s/iter; left time: 216.7532s\n",
      "\titers: 200, epoch: 3 | loss: 0.1432790\n",
      "\tspeed: 0.0289s/iter; left time: 71.5195s\n",
      "\titers: 300, epoch: 3 | loss: 0.2009752\n",
      "\tspeed: 0.0290s/iter; left time: 68.9937s\n",
      "\titers: 400, epoch: 3 | loss: 0.1790746\n",
      "\tspeed: 0.0291s/iter; left time: 66.2201s\n",
      "\titers: 500, epoch: 3 | loss: 0.2408326\n",
      "\tspeed: 0.0304s/iter; left time: 66.2026s\n",
      "\titers: 600, epoch: 3 | loss: 0.1165665\n",
      "\tspeed: 0.0319s/iter; left time: 66.2177s\n",
      "Epoch: 3 cost time: 19.810590744018555\n",
      "Epoch: 3, Steps: 669 | Train Loss: 0.1753943 Vali Loss: 0.3261100 Test Loss: 0.2576358\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1178407\n",
      "\tspeed: 0.0827s/iter; left time: 157.7891s\n",
      "\titers: 200, epoch: 4 | loss: 0.1156313\n",
      "\tspeed: 0.0287s/iter; left time: 51.8779s\n",
      "\titers: 300, epoch: 4 | loss: 0.1119328\n",
      "\tspeed: 0.0316s/iter; left time: 53.9114s\n",
      "\titers: 400, epoch: 4 | loss: 0.1618928\n",
      "\tspeed: 0.0291s/iter; left time: 46.8416s\n",
      "\titers: 500, epoch: 4 | loss: 0.1220269\n",
      "\tspeed: 0.0298s/iter; left time: 44.9468s\n",
      "\titers: 600, epoch: 4 | loss: 0.1634695\n",
      "\tspeed: 0.0288s/iter; left time: 40.5699s\n",
      "Epoch: 4 cost time: 19.781186819076538\n",
      "Epoch: 4, Steps: 669 | Train Loss: 0.1605350 Vali Loss: 0.3262684 Test Loss: 0.2606266\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1679568\n",
      "\tspeed: 0.0828s/iter; left time: 102.6316s\n",
      "\titers: 200, epoch: 5 | loss: 0.1361800\n",
      "\tspeed: 0.0294s/iter; left time: 33.5345s\n",
      "\titers: 300, epoch: 5 | loss: 0.2512585\n",
      "\tspeed: 0.0288s/iter; left time: 29.9682s\n",
      "\titers: 400, epoch: 5 | loss: 0.1703084\n",
      "\tspeed: 0.0293s/iter; left time: 27.4665s\n",
      "\titers: 500, epoch: 5 | loss: 0.1169138\n",
      "\tspeed: 0.0310s/iter; left time: 26.0233s\n",
      "\titers: 600, epoch: 5 | loss: 0.1177534\n",
      "\tspeed: 0.0305s/iter; left time: 22.5265s\n",
      "Epoch: 5 cost time: 19.822612285614014\n",
      "Epoch: 5, Steps: 669 | Train Loss: 0.1519584 Vali Loss: 0.3284130 Test Loss: 0.2512243\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "Test cost time: 2.0611s\n",
      "test shape: (177, 32, 6, 1) (177, 32, 6, 1)\n",
      "test shape: (5664, 6, 1) (5664, 6, 1)\n",
      "mse:0.26095011830329895, mae:0.3362491726875305\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl120_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1786.927734375\n",
      "MAE:  27.82505226135254\n",
      "RMSE: 42.27206802368164\n",
      "MAPE: 0.35854241251945496\n",
      "MSPE: 0.6627781391143799\n",
      ">>>>>>>Running time saved<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Running seq_len=144\n",
      "Args in experiment:\n",
      "Namespace(model='informer', data='traffic_full', root_path='../', data_path='traffic_full.csv', features='S', target='flow', freq='h', checkpoints='./checkpoints/', seq_len=144, label_len=24, pred_len=6, enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=2, d_layers=1, s_layers=[3, 2, 1], d_ff=2048, factor=5, padding=0, distil=True, dropout=0.05, attn='prob', embed='timeF', activation='gelu', output_attention=False, do_predict=False, mix=True, cols=None, num_workers=0, itr=10, train_epochs=6, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, inverse=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', detail_freq='h')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24395\n",
      "[DEBUG] Original dataset length: 24395\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21009\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3351\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "\titers: 100, epoch: 1 | loss: 0.5773597\n",
      "\tspeed: 0.0465s/iter; left time: 178.3220s\n",
      "\titers: 200, epoch: 1 | loss: 0.2248472\n",
      "\tspeed: 0.0318s/iter; left time: 118.8166s\n",
      "\titers: 300, epoch: 1 | loss: 0.2949802\n",
      "\tspeed: 0.0326s/iter; left time: 118.7469s\n",
      "\titers: 400, epoch: 1 | loss: 0.2345624\n",
      "\tspeed: 0.0329s/iter; left time: 116.2416s\n",
      "\titers: 500, epoch: 1 | loss: 0.1736841\n",
      "\tspeed: 0.0333s/iter; left time: 114.3790s\n",
      "\titers: 600, epoch: 1 | loss: 0.1810509\n",
      "\tspeed: 0.0315s/iter; left time: 105.1391s\n",
      "Epoch: 1 cost time: 21.76258111000061\n",
      "Epoch: 1, Steps: 656 | Train Loss: 0.2915067 Vali Loss: 0.3236095 Test Loss: 0.2708859\n",
      "Validation loss decreased (inf --> 0.323610).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2659350\n",
      "\tspeed: 0.0869s/iter; left time: 276.5308s\n",
      "\titers: 200, epoch: 2 | loss: 0.2451571\n",
      "\tspeed: 0.0335s/iter; left time: 103.1786s\n",
      "\titers: 300, epoch: 2 | loss: 0.2036144\n",
      "\tspeed: 0.0324s/iter; left time: 96.5466s\n",
      "\titers: 400, epoch: 2 | loss: 0.2439407\n",
      "\tspeed: 0.0318s/iter; left time: 91.5526s\n",
      "\titers: 500, epoch: 2 | loss: 0.1507605\n",
      "\tspeed: 0.0328s/iter; left time: 91.1267s\n",
      "\titers: 600, epoch: 2 | loss: 0.1592151\n",
      "\tspeed: 0.0340s/iter; left time: 91.1180s\n",
      "Epoch: 2 cost time: 21.53081464767456\n",
      "Epoch: 2, Steps: 656 | Train Loss: 0.2042075 Vali Loss: 0.3095017 Test Loss: 0.2474790\n",
      "Validation loss decreased (0.323610 --> 0.309502).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2643145\n",
      "\tspeed: 0.0864s/iter; left time: 218.2259s\n",
      "\titers: 200, epoch: 3 | loss: 0.1391766\n",
      "\tspeed: 0.0321s/iter; left time: 77.7369s\n",
      "\titers: 300, epoch: 3 | loss: 0.2408876\n",
      "\tspeed: 0.0336s/iter; left time: 78.2249s\n",
      "\titers: 400, epoch: 3 | loss: 0.1058808\n",
      "\tspeed: 0.0325s/iter; left time: 72.2084s\n",
      "\titers: 500, epoch: 3 | loss: 0.1230905\n",
      "\tspeed: 0.0332s/iter; left time: 70.5224s\n",
      "\titers: 600, epoch: 3 | loss: 0.1376670\n",
      "\tspeed: 0.0324s/iter; left time: 65.5260s\n",
      "Epoch: 3 cost time: 21.37095355987549\n",
      "Epoch: 3, Steps: 656 | Train Loss: 0.1774441 Vali Loss: 0.3243236 Test Loss: 0.2582257\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2078511\n",
      "\tspeed: 0.0866s/iter; left time: 161.9470s\n",
      "\titers: 200, epoch: 4 | loss: 0.1513474\n",
      "\tspeed: 0.0323s/iter; left time: 57.1375s\n",
      "\titers: 300, epoch: 4 | loss: 0.1232958\n",
      "\tspeed: 0.0320s/iter; left time: 53.4611s\n",
      "\titers: 400, epoch: 4 | loss: 0.1249274\n",
      "\tspeed: 0.0332s/iter; left time: 52.1365s\n",
      "\titers: 500, epoch: 4 | loss: 0.1749458\n",
      "\tspeed: 0.0326s/iter; left time: 47.8447s\n",
      "\titers: 600, epoch: 4 | loss: 0.1450439\n",
      "\tspeed: 0.0322s/iter; left time: 44.1167s\n",
      "Epoch: 4 cost time: 21.200046062469482\n",
      "Epoch: 4, Steps: 656 | Train Loss: 0.1620556 Vali Loss: 0.3248985 Test Loss: 0.2599406\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2129422\n",
      "\tspeed: 0.0863s/iter; left time: 104.6535s\n",
      "\titers: 200, epoch: 5 | loss: 0.1326293\n",
      "\tspeed: 0.0330s/iter; left time: 36.7493s\n",
      "\titers: 300, epoch: 5 | loss: 0.0759179\n",
      "\tspeed: 0.0319s/iter; left time: 32.3395s\n",
      "\titers: 400, epoch: 5 | loss: 0.3566663\n",
      "\tspeed: 0.0314s/iter; left time: 28.6617s\n",
      "\titers: 500, epoch: 5 | loss: 0.1266163\n",
      "\tspeed: 0.0315s/iter; left time: 25.5798s\n",
      "\titers: 600, epoch: 5 | loss: 0.1562040\n",
      "\tspeed: 0.0357s/iter; left time: 25.4402s\n",
      "Epoch: 5 cost time: 21.4954891204834\n",
      "Epoch: 5, Steps: 656 | Train Loss: 0.1532734 Vali Loss: 0.3192654 Test Loss: 0.2553161\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "Test cost time: 2.1736s\n",
      "test shape: (171, 32, 6, 1) (171, 32, 6, 1)\n",
      "test shape: (5472, 6, 1) (5472, 6, 1)\n",
      "mse:0.2473912537097931, mae:0.3308350145816803\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1694.079833984375\n",
      "MAE:  27.377023696899414\n",
      "RMSE: 41.159202575683594\n",
      "MAPE: 0.36822906136512756\n",
      "MSPE: 0.7107917070388794\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24395\n",
      "[DEBUG] Original dataset length: 24395\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21009\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3351\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "\titers: 100, epoch: 1 | loss: 0.5202874\n",
      "\tspeed: 0.0324s/iter; left time: 124.3661s\n",
      "\titers: 200, epoch: 1 | loss: 0.2529262\n",
      "\tspeed: 0.0339s/iter; left time: 126.7821s\n",
      "\titers: 300, epoch: 1 | loss: 0.2244729\n",
      "\tspeed: 0.0326s/iter; left time: 118.4798s\n",
      "\titers: 400, epoch: 1 | loss: 0.1588057\n",
      "\tspeed: 0.0325s/iter; left time: 114.7997s\n",
      "\titers: 500, epoch: 1 | loss: 0.3115514\n",
      "\tspeed: 0.0319s/iter; left time: 109.6195s\n",
      "\titers: 600, epoch: 1 | loss: 0.1302193\n",
      "\tspeed: 0.0323s/iter; left time: 107.7499s\n",
      "Epoch: 1 cost time: 21.484659433364868\n",
      "Epoch: 1, Steps: 656 | Train Loss: 0.2923461 Vali Loss: 0.4264196 Test Loss: 0.3506412\n",
      "Validation loss decreased (inf --> 0.426420).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3181400\n",
      "\tspeed: 0.0876s/iter; left time: 278.7413s\n",
      "\titers: 200, epoch: 2 | loss: 0.2591125\n",
      "\tspeed: 0.0318s/iter; left time: 97.9560s\n",
      "\titers: 300, epoch: 2 | loss: 0.2657251\n",
      "\tspeed: 0.0318s/iter; left time: 94.8941s\n",
      "\titers: 400, epoch: 2 | loss: 0.1652795\n",
      "\tspeed: 0.0335s/iter; left time: 96.4786s\n",
      "\titers: 500, epoch: 2 | loss: 0.1891092\n",
      "\tspeed: 0.0316s/iter; left time: 87.9266s\n",
      "\titers: 600, epoch: 2 | loss: 0.2087853\n",
      "\tspeed: 0.0329s/iter; left time: 88.2012s\n",
      "Epoch: 2 cost time: 21.171385288238525\n",
      "Epoch: 2, Steps: 656 | Train Loss: 0.2065615 Vali Loss: 0.3105869 Test Loss: 0.2583423\n",
      "Validation loss decreased (0.426420 --> 0.310587).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1392770\n",
      "\tspeed: 0.0864s/iter; left time: 218.1888s\n",
      "\titers: 200, epoch: 3 | loss: 0.1337592\n",
      "\tspeed: 0.0318s/iter; left time: 77.0363s\n",
      "\titers: 300, epoch: 3 | loss: 0.4520859\n",
      "\tspeed: 0.0318s/iter; left time: 73.8375s\n",
      "\titers: 400, epoch: 3 | loss: 0.1435578\n",
      "\tspeed: 0.0332s/iter; left time: 73.8141s\n",
      "\titers: 500, epoch: 3 | loss: 0.1335852\n",
      "\tspeed: 0.0352s/iter; left time: 74.8253s\n",
      "\titers: 600, epoch: 3 | loss: 0.1757742\n",
      "\tspeed: 0.0318s/iter; left time: 64.3551s\n",
      "Epoch: 3 cost time: 21.321564197540283\n",
      "Epoch: 3, Steps: 656 | Train Loss: 0.1778551 Vali Loss: 0.3079953 Test Loss: 0.2421847\n",
      "Validation loss decreased (0.310587 --> 0.307995).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2146083\n",
      "\tspeed: 0.0861s/iter; left time: 160.8612s\n",
      "\titers: 200, epoch: 4 | loss: 0.1350423\n",
      "\tspeed: 0.0335s/iter; left time: 59.1841s\n",
      "\titers: 300, epoch: 4 | loss: 0.0978987\n",
      "\tspeed: 0.0332s/iter; left time: 55.3387s\n",
      "\titers: 400, epoch: 4 | loss: 0.1562371\n",
      "\tspeed: 0.0329s/iter; left time: 51.5490s\n",
      "\titers: 500, epoch: 4 | loss: 0.1897022\n",
      "\tspeed: 0.0314s/iter; left time: 46.1330s\n",
      "\titers: 600, epoch: 4 | loss: 0.1793880\n",
      "\tspeed: 0.0317s/iter; left time: 43.3534s\n",
      "Epoch: 4 cost time: 21.4914813041687\n",
      "Epoch: 4, Steps: 656 | Train Loss: 0.1617256 Vali Loss: 0.3184051 Test Loss: 0.2511179\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1367395\n",
      "\tspeed: 0.0879s/iter; left time: 106.5893s\n",
      "\titers: 200, epoch: 5 | loss: 0.1646073\n",
      "\tspeed: 0.0314s/iter; left time: 34.9985s\n",
      "\titers: 300, epoch: 5 | loss: 0.1639174\n",
      "\tspeed: 0.0321s/iter; left time: 32.4968s\n",
      "\titers: 400, epoch: 5 | loss: 0.0973565\n",
      "\tspeed: 0.0338s/iter; left time: 30.8219s\n",
      "\titers: 500, epoch: 5 | loss: 0.1265430\n",
      "\tspeed: 0.0329s/iter; left time: 26.7787s\n",
      "\titers: 600, epoch: 5 | loss: 0.1102843\n",
      "\tspeed: 0.0329s/iter; left time: 23.4611s\n",
      "Epoch: 5 cost time: 21.295121908187866\n",
      "Epoch: 5, Steps: 656 | Train Loss: 0.1525152 Vali Loss: 0.3226796 Test Loss: 0.2548923\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1711726\n",
      "\tspeed: 0.0878s/iter; left time: 48.9274s\n",
      "\titers: 200, epoch: 6 | loss: 0.1758771\n",
      "\tspeed: 0.0322s/iter; left time: 14.7212s\n",
      "\titers: 300, epoch: 6 | loss: 0.1159998\n",
      "\tspeed: 0.0325s/iter; left time: 11.6104s\n",
      "\titers: 400, epoch: 6 | loss: 0.1226210\n",
      "\tspeed: 0.0320s/iter; left time: 8.2215s\n",
      "\titers: 500, epoch: 6 | loss: 0.1432070\n",
      "\tspeed: 0.0339s/iter; left time: 5.3188s\n",
      "\titers: 600, epoch: 6 | loss: 0.1445169\n",
      "\tspeed: 0.0330s/iter; left time: 1.8818s\n",
      "Epoch: 6 cost time: 21.570029735565186\n",
      "Epoch: 6, Steps: 656 | Train Loss: 0.1476675 Vali Loss: 0.3178961 Test Loss: 0.2505395\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "Test cost time: 2.0037s\n",
      "test shape: (171, 32, 6, 1) (171, 32, 6, 1)\n",
      "test shape: (5472, 6, 1) (5472, 6, 1)\n",
      "mse:0.24241036176681519, mae:0.33062732219696045\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1659.9716796875\n",
      "MAE:  27.359840393066406\n",
      "RMSE: 40.74274826049805\n",
      "MAPE: 0.3918161988258362\n",
      "MSPE: 0.7807728052139282\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24395\n",
      "[DEBUG] Original dataset length: 24395\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21009\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3351\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "\titers: 100, epoch: 1 | loss: 0.2570846\n",
      "\tspeed: 0.0318s/iter; left time: 122.0381s\n",
      "\titers: 200, epoch: 1 | loss: 0.2482557\n",
      "\tspeed: 0.0314s/iter; left time: 117.4840s\n",
      "\titers: 300, epoch: 1 | loss: 0.2382472\n",
      "\tspeed: 0.0317s/iter; left time: 115.2959s\n",
      "\titers: 400, epoch: 1 | loss: 0.2037688\n",
      "\tspeed: 0.0321s/iter; left time: 113.6396s\n",
      "\titers: 500, epoch: 1 | loss: 0.1977069\n",
      "\tspeed: 0.0324s/iter; left time: 111.2736s\n",
      "\titers: 600, epoch: 1 | loss: 0.3040150\n",
      "\tspeed: 0.0343s/iter; left time: 114.5561s\n",
      "Epoch: 1 cost time: 21.187795162200928\n",
      "Epoch: 1, Steps: 656 | Train Loss: 0.2807286 Vali Loss: 0.3194149 Test Loss: 0.2605503\n",
      "Validation loss decreased (inf --> 0.319415).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1922045\n",
      "\tspeed: 0.0865s/iter; left time: 275.3067s\n",
      "\titers: 200, epoch: 2 | loss: 0.1726666\n",
      "\tspeed: 0.0343s/iter; left time: 105.7283s\n",
      "\titers: 300, epoch: 2 | loss: 0.3991269\n",
      "\tspeed: 0.0335s/iter; left time: 99.9879s\n",
      "\titers: 400, epoch: 2 | loss: 0.1488326\n",
      "\tspeed: 0.0326s/iter; left time: 93.8858s\n",
      "\titers: 500, epoch: 2 | loss: 0.1927002\n",
      "\tspeed: 0.0319s/iter; left time: 88.7195s\n",
      "\titers: 600, epoch: 2 | loss: 0.1453212\n",
      "\tspeed: 0.0318s/iter; left time: 85.3190s\n",
      "Epoch: 2 cost time: 21.465625047683716\n",
      "Epoch: 2, Steps: 656 | Train Loss: 0.2069821 Vali Loss: 0.3068630 Test Loss: 0.2439928\n",
      "Validation loss decreased (0.319415 --> 0.306863).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2578698\n",
      "\tspeed: 0.0876s/iter; left time: 221.0686s\n",
      "\titers: 200, epoch: 3 | loss: 0.1612262\n",
      "\tspeed: 0.0308s/iter; left time: 74.6148s\n",
      "\titers: 300, epoch: 3 | loss: 0.2674793\n",
      "\tspeed: 0.0325s/iter; left time: 75.5342s\n",
      "\titers: 400, epoch: 3 | loss: 0.1527422\n",
      "\tspeed: 0.0324s/iter; left time: 72.1909s\n",
      "\titers: 500, epoch: 3 | loss: 0.2474272\n",
      "\tspeed: 0.0340s/iter; left time: 72.2769s\n",
      "\titers: 600, epoch: 3 | loss: 0.1507257\n",
      "\tspeed: 0.0320s/iter; left time: 64.7327s\n",
      "Epoch: 3 cost time: 21.202395915985107\n",
      "Epoch: 3, Steps: 656 | Train Loss: 0.1769989 Vali Loss: 0.3079812 Test Loss: 0.2464832\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1338294\n",
      "\tspeed: 0.0872s/iter; left time: 162.8917s\n",
      "\titers: 200, epoch: 4 | loss: 0.1632125\n",
      "\tspeed: 0.0331s/iter; left time: 58.5865s\n",
      "\titers: 300, epoch: 4 | loss: 0.1377309\n",
      "\tspeed: 0.0324s/iter; left time: 53.9972s\n",
      "\titers: 400, epoch: 4 | loss: 0.1996593\n",
      "\tspeed: 0.0324s/iter; left time: 50.8837s\n",
      "\titers: 500, epoch: 4 | loss: 0.1181102\n",
      "\tspeed: 0.0330s/iter; left time: 48.5066s\n",
      "\titers: 600, epoch: 4 | loss: 0.1517173\n",
      "\tspeed: 0.0336s/iter; left time: 45.9624s\n",
      "Epoch: 4 cost time: 21.61107325553894\n",
      "Epoch: 4, Steps: 656 | Train Loss: 0.1614704 Vali Loss: 0.3073667 Test Loss: 0.2438443\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1883718\n",
      "\tspeed: 0.0858s/iter; left time: 104.1057s\n",
      "\titers: 200, epoch: 5 | loss: 0.1666218\n",
      "\tspeed: 0.0326s/iter; left time: 36.2451s\n",
      "\titers: 300, epoch: 5 | loss: 0.1837917\n",
      "\tspeed: 0.0341s/iter; left time: 34.5119s\n",
      "\titers: 400, epoch: 5 | loss: 0.1438666\n",
      "\tspeed: 0.0318s/iter; left time: 29.0283s\n",
      "\titers: 500, epoch: 5 | loss: 0.2279110\n",
      "\tspeed: 0.0320s/iter; left time: 25.9965s\n",
      "\titers: 600, epoch: 5 | loss: 0.0954488\n",
      "\tspeed: 0.0321s/iter; left time: 22.8568s\n",
      "Epoch: 5 cost time: 21.256062984466553\n",
      "Epoch: 5, Steps: 656 | Train Loss: 0.1528043 Vali Loss: 0.3160452 Test Loss: 0.2406316\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "Test cost time: 2.1622s\n",
      "test shape: (171, 32, 6, 1) (171, 32, 6, 1)\n",
      "test shape: (5472, 6, 1) (5472, 6, 1)\n",
      "mse:0.24379949271678925, mae:0.3338160812854767\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1669.4842529296875\n",
      "MAE:  27.623708724975586\n",
      "RMSE: 40.85932159423828\n",
      "MAPE: 0.37733444571495056\n",
      "MSPE: 0.7389913201332092\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24395\n",
      "[DEBUG] Original dataset length: 24395\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21009\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3351\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "\titers: 100, epoch: 1 | loss: 0.2182837\n",
      "\tspeed: 0.0318s/iter; left time: 121.9593s\n",
      "\titers: 200, epoch: 1 | loss: 0.1751437\n",
      "\tspeed: 0.0312s/iter; left time: 116.6317s\n",
      "\titers: 300, epoch: 1 | loss: 0.1735273\n",
      "\tspeed: 0.0318s/iter; left time: 115.7865s\n",
      "\titers: 400, epoch: 1 | loss: 0.2533305\n",
      "\tspeed: 0.0336s/iter; left time: 118.7304s\n",
      "\titers: 500, epoch: 1 | loss: 0.1751117\n",
      "\tspeed: 0.0315s/iter; left time: 108.2567s\n",
      "\titers: 600, epoch: 1 | loss: 0.2409586\n",
      "\tspeed: 0.0325s/iter; left time: 108.4694s\n",
      "Epoch: 1 cost time: 21.008002519607544\n",
      "Epoch: 1, Steps: 656 | Train Loss: 0.2820610 Vali Loss: 0.3405585 Test Loss: 0.2846715\n",
      "Validation loss decreased (inf --> 0.340558).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1877191\n",
      "\tspeed: 0.0877s/iter; left time: 278.9498s\n",
      "\titers: 200, epoch: 2 | loss: 0.1619586\n",
      "\tspeed: 0.0309s/iter; left time: 95.3495s\n",
      "\titers: 300, epoch: 2 | loss: 0.1549713\n",
      "\tspeed: 0.0307s/iter; left time: 91.4737s\n",
      "\titers: 400, epoch: 2 | loss: 0.1674839\n",
      "\tspeed: 0.0320s/iter; left time: 92.1423s\n",
      "\titers: 500, epoch: 2 | loss: 0.2822004\n",
      "\tspeed: 0.0324s/iter; left time: 90.1362s\n",
      "\titers: 600, epoch: 2 | loss: 0.2392451\n",
      "\tspeed: 0.0327s/iter; left time: 87.5420s\n",
      "Epoch: 2 cost time: 20.98350691795349\n",
      "Epoch: 2, Steps: 656 | Train Loss: 0.2065895 Vali Loss: 0.3001632 Test Loss: 0.2552680\n",
      "Validation loss decreased (0.340558 --> 0.300163).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1109193\n",
      "\tspeed: 0.0861s/iter; left time: 217.2796s\n",
      "\titers: 200, epoch: 3 | loss: 0.1828853\n",
      "\tspeed: 0.0324s/iter; left time: 78.6679s\n",
      "\titers: 300, epoch: 3 | loss: 0.1843476\n",
      "\tspeed: 0.0321s/iter; left time: 74.5961s\n",
      "\titers: 400, epoch: 3 | loss: 0.1464380\n",
      "\tspeed: 0.0321s/iter; left time: 71.4378s\n",
      "\titers: 500, epoch: 3 | loss: 0.2522005\n",
      "\tspeed: 0.0327s/iter; left time: 69.4140s\n",
      "\titers: 600, epoch: 3 | loss: 0.2003523\n",
      "\tspeed: 0.0323s/iter; left time: 65.3467s\n",
      "Epoch: 3 cost time: 21.26072406768799\n",
      "Epoch: 3, Steps: 656 | Train Loss: 0.1772387 Vali Loss: 0.3090435 Test Loss: 0.2568916\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1443746\n",
      "\tspeed: 0.0874s/iter; left time: 163.2667s\n",
      "\titers: 200, epoch: 4 | loss: 0.1165230\n",
      "\tspeed: 0.0316s/iter; left time: 55.8267s\n",
      "\titers: 300, epoch: 4 | loss: 0.1668504\n",
      "\tspeed: 0.0331s/iter; left time: 55.1660s\n",
      "\titers: 400, epoch: 4 | loss: 0.1844789\n",
      "\tspeed: 0.0334s/iter; left time: 52.4827s\n",
      "\titers: 500, epoch: 4 | loss: 0.1157616\n",
      "\tspeed: 0.0316s/iter; left time: 46.4300s\n",
      "\titers: 600, epoch: 4 | loss: 0.1308580\n",
      "\tspeed: 0.0335s/iter; left time: 45.8964s\n",
      "Epoch: 4 cost time: 21.356777667999268\n",
      "Epoch: 4, Steps: 656 | Train Loss: 0.1618986 Vali Loss: 0.3000285 Test Loss: 0.2469149\n",
      "Validation loss decreased (0.300163 --> 0.300029).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1526116\n",
      "\tspeed: 0.0875s/iter; left time: 106.1548s\n",
      "\titers: 200, epoch: 5 | loss: 0.1466545\n",
      "\tspeed: 0.0315s/iter; left time: 35.1096s\n",
      "\titers: 300, epoch: 5 | loss: 0.1603190\n",
      "\tspeed: 0.0313s/iter; left time: 31.7307s\n",
      "\titers: 400, epoch: 5 | loss: 0.1283255\n",
      "\tspeed: 0.0312s/iter; left time: 28.4840s\n",
      "\titers: 500, epoch: 5 | loss: 0.1349591\n",
      "\tspeed: 0.0322s/iter; left time: 26.2175s\n",
      "\titers: 600, epoch: 5 | loss: 0.1036943\n",
      "\tspeed: 0.0326s/iter; left time: 23.2755s\n",
      "Epoch: 5 cost time: 21.012609004974365\n",
      "Epoch: 5, Steps: 656 | Train Loss: 0.1530596 Vali Loss: 0.3067658 Test Loss: 0.2490044\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1770464\n",
      "\tspeed: 0.0849s/iter; left time: 47.2633s\n",
      "\titers: 200, epoch: 6 | loss: 0.1553153\n",
      "\tspeed: 0.0324s/iter; left time: 14.7875s\n",
      "\titers: 300, epoch: 6 | loss: 0.1164552\n",
      "\tspeed: 0.0331s/iter; left time: 11.8270s\n",
      "\titers: 400, epoch: 6 | loss: 0.1063500\n",
      "\tspeed: 0.0330s/iter; left time: 8.4934s\n",
      "\titers: 500, epoch: 6 | loss: 0.2270106\n",
      "\tspeed: 0.0326s/iter; left time: 5.1208s\n",
      "\titers: 600, epoch: 6 | loss: 0.1174443\n",
      "\tspeed: 0.0340s/iter; left time: 1.9385s\n",
      "Epoch: 6 cost time: 21.65643620491028\n",
      "Epoch: 6, Steps: 656 | Train Loss: 0.1482696 Vali Loss: 0.3106974 Test Loss: 0.2501840\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "Test cost time: 2.2442s\n",
      "test shape: (171, 32, 6, 1) (171, 32, 6, 1)\n",
      "test shape: (5472, 6, 1) (5472, 6, 1)\n",
      "mse:0.2472953498363495, mae:0.3334175646305084\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1693.4228515625\n",
      "MAE:  27.590730667114258\n",
      "RMSE: 41.15121841430664\n",
      "MAPE: 0.38321784138679504\n",
      "MSPE: 0.8108810782432556\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24395\n",
      "[DEBUG] Original dataset length: 24395\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21009\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3351\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "\titers: 100, epoch: 1 | loss: 0.4533430\n",
      "\tspeed: 0.0339s/iter; left time: 129.9147s\n",
      "\titers: 200, epoch: 1 | loss: 0.3357265\n",
      "\tspeed: 0.0327s/iter; left time: 122.0980s\n",
      "\titers: 300, epoch: 1 | loss: 0.1681057\n",
      "\tspeed: 0.0339s/iter; left time: 123.3772s\n",
      "\titers: 400, epoch: 1 | loss: 0.2521320\n",
      "\tspeed: 0.0337s/iter; left time: 119.2107s\n",
      "\titers: 500, epoch: 1 | loss: 0.1625538\n",
      "\tspeed: 0.0333s/iter; left time: 114.3460s\n",
      "\titers: 600, epoch: 1 | loss: 0.2709439\n",
      "\tspeed: 0.0318s/iter; left time: 106.1021s\n",
      "Epoch: 1 cost time: 21.707306146621704\n",
      "Epoch: 1, Steps: 656 | Train Loss: 0.2817353 Vali Loss: 0.3176092 Test Loss: 0.2668105\n",
      "Validation loss decreased (inf --> 0.317609).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2976071\n",
      "\tspeed: 0.0859s/iter; left time: 273.1232s\n",
      "\titers: 200, epoch: 2 | loss: 0.2504873\n",
      "\tspeed: 0.0316s/iter; left time: 97.3562s\n",
      "\titers: 300, epoch: 2 | loss: 0.2155575\n",
      "\tspeed: 0.0317s/iter; left time: 94.5230s\n",
      "\titers: 400, epoch: 2 | loss: 0.1412204\n",
      "\tspeed: 0.0320s/iter; left time: 92.1142s\n",
      "\titers: 500, epoch: 2 | loss: 0.1337893\n",
      "\tspeed: 0.0330s/iter; left time: 91.7693s\n",
      "\titers: 600, epoch: 2 | loss: 0.1330557\n",
      "\tspeed: 0.0327s/iter; left time: 87.7260s\n",
      "Epoch: 2 cost time: 21.21277379989624\n",
      "Epoch: 2, Steps: 656 | Train Loss: 0.2054136 Vali Loss: 0.3248751 Test Loss: 0.2711644\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1273565\n",
      "\tspeed: 0.0883s/iter; left time: 222.9173s\n",
      "\titers: 200, epoch: 3 | loss: 0.2009385\n",
      "\tspeed: 0.0336s/iter; left time: 81.3661s\n",
      "\titers: 300, epoch: 3 | loss: 0.2076006\n",
      "\tspeed: 0.0324s/iter; left time: 75.3022s\n",
      "\titers: 400, epoch: 3 | loss: 0.1313150\n",
      "\tspeed: 0.0316s/iter; left time: 70.2281s\n",
      "\titers: 500, epoch: 3 | loss: 0.2022340\n",
      "\tspeed: 0.0316s/iter; left time: 67.1038s\n",
      "\titers: 600, epoch: 3 | loss: 0.1879010\n",
      "\tspeed: 0.0338s/iter; left time: 68.4052s\n",
      "Epoch: 3 cost time: 21.481112957000732\n",
      "Epoch: 3, Steps: 656 | Train Loss: 0.1761408 Vali Loss: 0.3088647 Test Loss: 0.2495510\n",
      "Validation loss decreased (0.317609 --> 0.308865).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1385113\n",
      "\tspeed: 0.0869s/iter; left time: 162.3302s\n",
      "\titers: 200, epoch: 4 | loss: 0.1955617\n",
      "\tspeed: 0.0319s/iter; left time: 56.4111s\n",
      "\titers: 300, epoch: 4 | loss: 0.1958989\n",
      "\tspeed: 0.0344s/iter; left time: 57.3378s\n",
      "\titers: 400, epoch: 4 | loss: 0.1205724\n",
      "\tspeed: 0.0319s/iter; left time: 50.1105s\n",
      "\titers: 500, epoch: 4 | loss: 0.1366789\n",
      "\tspeed: 0.0314s/iter; left time: 46.0853s\n",
      "\titers: 600, epoch: 4 | loss: 0.1859898\n",
      "\tspeed: 0.0319s/iter; left time: 43.6210s\n",
      "Epoch: 4 cost time: 21.092772960662842\n",
      "Epoch: 4, Steps: 656 | Train Loss: 0.1610313 Vali Loss: 0.3132033 Test Loss: 0.2536923\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1505619\n",
      "\tspeed: 0.0856s/iter; left time: 103.8086s\n",
      "\titers: 200, epoch: 5 | loss: 0.1145787\n",
      "\tspeed: 0.0319s/iter; left time: 35.5396s\n",
      "\titers: 300, epoch: 5 | loss: 0.1305927\n",
      "\tspeed: 0.0330s/iter; left time: 33.4456s\n",
      "\titers: 400, epoch: 5 | loss: 0.1405850\n",
      "\tspeed: 0.0322s/iter; left time: 29.3776s\n",
      "\titers: 500, epoch: 5 | loss: 0.3225027\n",
      "\tspeed: 0.0333s/iter; left time: 27.0687s\n",
      "\titers: 600, epoch: 5 | loss: 0.0998598\n",
      "\tspeed: 0.0313s/iter; left time: 22.3267s\n",
      "Epoch: 5 cost time: 21.119280338287354\n",
      "Epoch: 5, Steps: 656 | Train Loss: 0.1519307 Vali Loss: 0.3078241 Test Loss: 0.2506665\n",
      "Validation loss decreased (0.308865 --> 0.307824).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1198894\n",
      "\tspeed: 0.0855s/iter; left time: 47.6246s\n",
      "\titers: 200, epoch: 6 | loss: 0.1307646\n",
      "\tspeed: 0.0332s/iter; left time: 15.1903s\n",
      "\titers: 300, epoch: 6 | loss: 0.0832964\n",
      "\tspeed: 0.0314s/iter; left time: 11.2175s\n",
      "\titers: 400, epoch: 6 | loss: 0.1459436\n",
      "\tspeed: 0.0323s/iter; left time: 8.3064s\n",
      "\titers: 500, epoch: 6 | loss: 0.1478643\n",
      "\tspeed: 0.0325s/iter; left time: 5.0985s\n",
      "\titers: 600, epoch: 6 | loss: 0.1780171\n",
      "\tspeed: 0.0323s/iter; left time: 1.8431s\n",
      "Epoch: 6 cost time: 21.25728178024292\n",
      "Epoch: 6, Steps: 656 | Train Loss: 0.1469934 Vali Loss: 0.3195954 Test Loss: 0.2549908\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "Test cost time: 2.0659s\n",
      "test shape: (171, 32, 6, 1) (171, 32, 6, 1)\n",
      "test shape: (5472, 6, 1) (5472, 6, 1)\n",
      "mse:0.25094932317733765, mae:0.32892411947250366\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1718.4444580078125\n",
      "MAE:  27.218891143798828\n",
      "RMSE: 41.454124450683594\n",
      "MAPE: 0.3496236503124237\n",
      "MSPE: 0.6073595881462097\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24395\n",
      "[DEBUG] Original dataset length: 24395\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 21009\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3351\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "\titers: 100, epoch: 1 | loss: 0.4559557\n",
      "\tspeed: 0.0312s/iter; left time: 119.5465s\n",
      "\titers: 200, epoch: 1 | loss: 0.2925802\n",
      "\tspeed: 0.0321s/iter; left time: 119.8616s\n",
      "\titers: 300, epoch: 1 | loss: 0.2696863\n",
      "\tspeed: 0.0324s/iter; left time: 117.8434s\n",
      "\titers: 400, epoch: 1 | loss: 0.1977392\n",
      "\tspeed: 0.0313s/iter; left time: 110.8022s\n",
      "\titers: 500, epoch: 1 | loss: 0.2495583\n",
      "\tspeed: 0.0319s/iter; left time: 109.7295s\n",
      "\titers: 600, epoch: 1 | loss: 0.1558201\n",
      "\tspeed: 0.0324s/iter; left time: 108.1049s\n",
      "Epoch: 1 cost time: 20.98933696746826\n",
      "Epoch: 1, Steps: 656 | Train Loss: 0.2984924 Vali Loss: 0.3201454 Test Loss: 0.2702071\n",
      "Validation loss decreased (inf --> 0.320145).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2664364\n",
      "\tspeed: 0.0873s/iter; left time: 277.5507s\n",
      "\titers: 200, epoch: 2 | loss: 0.1827358\n",
      "\tspeed: 0.0318s/iter; left time: 98.0641s\n",
      "\titers: 300, epoch: 2 | loss: 0.2797287\n",
      "\tspeed: 0.0312s/iter; left time: 92.9708s\n",
      "\titers: 400, epoch: 2 | loss: 0.1162731\n",
      "\tspeed: 0.0337s/iter; left time: 97.1356s\n",
      "\titers: 500, epoch: 2 | loss: 0.2254053\n",
      "\tspeed: 0.0321s/iter; left time: 89.1720s\n",
      "\titers: 600, epoch: 2 | loss: 0.1095070\n",
      "\tspeed: 0.0316s/iter; left time: 84.6769s\n",
      "Epoch: 2 cost time: 21.083333492279053\n",
      "Epoch: 2, Steps: 656 | Train Loss: 0.2115741 Vali Loss: 0.3087421 Test Loss: 0.2607134\n",
      "Validation loss decreased (0.320145 --> 0.308742).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1613717\n",
      "\tspeed: 0.0877s/iter; left time: 221.4574s\n",
      "\titers: 200, epoch: 3 | loss: 0.1867044\n",
      "\tspeed: 0.0316s/iter; left time: 76.7480s\n",
      "\titers: 300, epoch: 3 | loss: 0.2047146\n",
      "\tspeed: 0.0321s/iter; left time: 74.6884s\n",
      "\titers: 400, epoch: 3 | loss: 0.1981609\n",
      "\tspeed: 0.0311s/iter; left time: 69.2775s\n",
      "\titers: 500, epoch: 3 | loss: 0.1202245\n",
      "\tspeed: 0.0314s/iter; left time: 66.7129s\n",
      "\titers: 600, epoch: 3 | loss: 0.1331491\n",
      "\tspeed: 0.0329s/iter; left time: 66.5964s\n",
      "Epoch: 3 cost time: 21.0702645778656\n",
      "Epoch: 3, Steps: 656 | Train Loss: 0.1808753 Vali Loss: 0.3162298 Test Loss: 0.2564309\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2150653\n",
      "\tspeed: 0.0837s/iter; left time: 156.4092s\n",
      "\titers: 200, epoch: 4 | loss: 0.4382178\n",
      "\tspeed: 0.0329s/iter; left time: 58.1467s\n",
      "\titers: 300, epoch: 4 | loss: 0.2860485\n",
      "\tspeed: 0.0345s/iter; left time: 57.5681s\n",
      "\titers: 400, epoch: 4 | loss: 0.2482043\n",
      "\tspeed: 0.0318s/iter; left time: 49.8857s\n",
      "\titers: 500, epoch: 4 | loss: 0.1666696\n",
      "\tspeed: 0.0322s/iter; left time: 47.2287s\n",
      "\titers: 600, epoch: 4 | loss: 0.1999657\n",
      "\tspeed: 0.0313s/iter; left time: 42.7883s\n",
      "Epoch: 4 cost time: 21.194647789001465\n",
      "Epoch: 4, Steps: 656 | Train Loss: 0.1641344 Vali Loss: 0.3106291 Test Loss: 0.2564653\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1213623\n",
      "\tspeed: 0.0867s/iter; left time: 105.1506s\n",
      "\titers: 200, epoch: 5 | loss: 0.1791154\n",
      "\tspeed: 0.0314s/iter; left time: 34.9909s\n",
      "\titers: 300, epoch: 5 | loss: 0.2896864\n",
      "\tspeed: 0.0315s/iter; left time: 31.9059s\n",
      "\titers: 400, epoch: 5 | loss: 0.1097997\n",
      "\tspeed: 0.0320s/iter; left time: 29.1811s\n",
      "\titers: 500, epoch: 5 | loss: 0.1229164\n",
      "\tspeed: 0.0309s/iter; left time: 25.1079s\n",
      "\titers: 600, epoch: 5 | loss: 0.1665802\n",
      "\tspeed: 0.0304s/iter; left time: 21.6919s\n",
      "Epoch: 5 cost time: 20.56212544441223\n",
      "Epoch: 5, Steps: 656 | Train Loss: 0.1548992 Vali Loss: 0.3199593 Test Loss: 0.2593756\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl144_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\titers: 200, epoch: 2 | loss: 0.1532303\n",
      "\tspeed: 0.0437s/iter; left time: 126.2771s\n",
      "\titers: 300, epoch: 2 | loss: 0.1194427\n",
      "\tspeed: 0.0421s/iter; left time: 117.3745s\n",
      "\titers: 400, epoch: 2 | loss: 0.1741949\n",
      "\tspeed: 0.0420s/iter; left time: 113.1091s\n",
      "\titers: 500, epoch: 2 | loss: 0.2344944\n",
      "\tspeed: 0.0424s/iter; left time: 109.8542s\n",
      "\titers: 600, epoch: 2 | loss: 0.2087820\n",
      "\tspeed: 0.0433s/iter; left time: 107.9172s\n",
      "Epoch: 2 cost time: 26.315322875976562\n",
      "Epoch: 2, Steps: 618 | Train Loss: 0.2002093 Vali Loss: 0.3317700 Test Loss: 0.2666194\n",
      "Validation loss decreased (0.349521 --> 0.331770).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1226939\n",
      "\tspeed: 0.0955s/iter; left time: 226.5762s\n",
      "\titers: 200, epoch: 3 | loss: 0.1673248\n",
      "\tspeed: 0.0435s/iter; left time: 98.8637s\n",
      "\titers: 300, epoch: 3 | loss: 0.1549045\n",
      "\tspeed: 0.0422s/iter; left time: 91.8031s\n",
      "\titers: 400, epoch: 3 | loss: 0.1939242\n",
      "\tspeed: 0.0417s/iter; left time: 86.5266s\n",
      "\titers: 500, epoch: 3 | loss: 0.1751583\n",
      "\tspeed: 0.0428s/iter; left time: 84.3885s\n",
      "\titers: 600, epoch: 3 | loss: 0.1781137\n",
      "\tspeed: 0.0424s/iter; left time: 79.4407s\n",
      "Epoch: 3 cost time: 26.27789568901062\n",
      "Epoch: 3, Steps: 618 | Train Loss: 0.1735032 Vali Loss: 0.3154289 Test Loss: 0.2426457\n",
      "Validation loss decreased (0.331770 --> 0.315429).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2534605\n",
      "\tspeed: 0.0956s/iter; left time: 167.8433s\n",
      "\titers: 200, epoch: 4 | loss: 0.1163494\n",
      "\tspeed: 0.0429s/iter; left time: 70.9199s\n",
      "\titers: 300, epoch: 4 | loss: 0.1868854\n",
      "\tspeed: 0.0416s/iter; left time: 64.7039s\n",
      "\titers: 400, epoch: 4 | loss: 0.1310972\n",
      "\tspeed: 0.0414s/iter; left time: 60.1999s\n",
      "\titers: 500, epoch: 4 | loss: 0.1387785\n",
      "\tspeed: 0.0427s/iter; left time: 57.8747s\n",
      "\titers: 600, epoch: 4 | loss: 0.0808690\n",
      "\tspeed: 0.0424s/iter; left time: 53.2694s\n",
      "Epoch: 4 cost time: 26.12479043006897\n",
      "Epoch: 4, Steps: 618 | Train Loss: 0.1586814 Vali Loss: 0.3029079 Test Loss: 0.2410731\n",
      "Validation loss decreased (0.315429 --> 0.302908).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 200, epoch: 5 | loss: 0.0849414\n",
      "\tspeed: 0.0432s/iter; left time: 44.7634s\n",
      "\titers: 300, epoch: 5 | loss: 0.1287156\n",
      "\tspeed: 0.0416s/iter; left time: 39.0016s\n",
      "\titers: 400, epoch: 5 | loss: 0.1166004\n",
      "\tspeed: 0.0418s/iter; left time: 34.9675s\n",
      "\titers: 500, epoch: 5 | loss: 0.0874473\n",
      "\tspeed: 0.0428s/iter; left time: 31.5130s\n",
      "\titers: 600, epoch: 5 | loss: 0.1388423\n",
      "\tspeed: 0.0422s/iter; left time: 26.8969s\n",
      "Epoch: 5 cost time: 26.13906168937683\n",
      "Epoch: 5, Steps: 618 | Train Loss: 0.1491766 Vali Loss: 0.3102446 Test Loss: 0.2453862\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1230433\n",
      "\tspeed: 0.0937s/iter; left time: 48.6393s\n",
      "\titers: 200, epoch: 6 | loss: 0.1286636\n",
      "\tspeed: 0.0422s/iter; left time: 17.6840s\n",
      "\titers: 300, epoch: 6 | loss: 0.1279359\n",
      "\tspeed: 0.0415s/iter; left time: 13.2457s\n",
      "\titers: 400, epoch: 6 | loss: 0.1358311\n",
      "\tspeed: 0.0423s/iter; left time: 9.2545s\n",
      "\titers: 500, epoch: 6 | loss: 0.1060025\n",
      "\tspeed: 0.0423s/iter; left time: 5.0370s\n",
      "\titers: 600, epoch: 6 | loss: 0.1155184\n",
      "\tspeed: 0.0417s/iter; left time: 0.7914s\n",
      "Epoch: 6 cost time: 25.971617698669434\n",
      "Epoch: 6, Steps: 618 | Train Loss: 0.1439702 Vali Loss: 0.3155705 Test Loss: 0.2457050\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl216_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4994\n",
      "Test cost time: 2.6807s\n",
      "test shape: (156, 32, 6, 1) (156, 32, 6, 1)\n",
      "test shape: (4992, 6, 1) (4992, 6, 1)\n",
      "mse:0.24078059196472168, mae:0.33161690831184387\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl216_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1648.811279296875\n",
      "MAE:  27.441726684570312\n",
      "RMSE: 40.60555648803711\n",
      "MAPE: 0.3915203809738159\n",
      "MSPE: 0.7362817525863647\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl216_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24323\n",
      "[DEBUG] Original dataset length: 24323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19785\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3279\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4994\n",
      "\titers: 100, epoch: 1 | loss: 0.2582921\n",
      "\tspeed: 0.0451s/iter; left time: 162.8793s\n",
      "\titers: 200, epoch: 1 | loss: 0.2142357\n",
      "\tspeed: 0.0421s/iter; left time: 147.5947s\n",
      "\titers: 300, epoch: 1 | loss: 0.2157873\n",
      "\tspeed: 0.0417s/iter; left time: 142.2499s\n",
      "\titers: 400, epoch: 1 | loss: 0.2203617\n",
      "\tspeed: 0.0421s/iter; left time: 139.1723s\n",
      "\titers: 500, epoch: 1 | loss: 0.3249401\n",
      "\tspeed: 0.0428s/iter; left time: 137.4800s\n",
      "\titers: 600, epoch: 1 | loss: 0.2049375\n",
      "\tspeed: 0.0416s/iter; left time: 129.3381s\n",
      "Epoch: 1 cost time: 26.302100658416748\n",
      "Epoch: 1, Steps: 618 | Train Loss: 0.2764520 Vali Loss: 0.3281155 Test Loss: 0.2700931\n",
      "Validation loss decreased (inf --> 0.328115).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4484720\n",
      "\tspeed: 0.0967s/iter; left time: 289.3618s\n",
      "\titers: 200, epoch: 2 | loss: 0.1137520\n",
      "\tspeed: 0.0419s/iter; left time: 121.0426s\n",
      "\titers: 300, epoch: 2 | loss: 0.1501827\n",
      "\tspeed: 0.0419s/iter; left time: 116.9573s\n",
      "\titers: 400, epoch: 2 | loss: 0.1383560\n",
      "\tspeed: 0.0425s/iter; left time: 114.4616s\n",
      "\titers: 500, epoch: 2 | loss: 0.2124247\n",
      "\tspeed: 0.0433s/iter; left time: 112.0890s\n",
      "\titers: 600, epoch: 2 | loss: 0.1524644\n",
      "\tspeed: 0.0421s/iter; left time: 104.7650s\n",
      "Epoch: 2 cost time: 26.13294219970703\n",
      "Epoch: 2, Steps: 618 | Train Loss: 0.1988230 Vali Loss: 0.3237361 Test Loss: 0.2629321\n",
      "Validation loss decreased (0.328115 --> 0.323736).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2649992\n",
      "\tspeed: 0.0946s/iter; left time: 224.4185s\n",
      "\titers: 200, epoch: 3 | loss: 0.1216606\n",
      "\tspeed: 0.0418s/iter; left time: 94.9054s\n",
      "\titers: 300, epoch: 3 | loss: 0.1789708\n",
      "\tspeed: 0.0420s/iter; left time: 91.2766s\n",
      "\titers: 400, epoch: 3 | loss: 0.1617068\n",
      "\tspeed: 0.0421s/iter; left time: 87.2330s\n",
      "\titers: 500, epoch: 3 | loss: 0.2519102\n",
      "\tspeed: 0.0431s/iter; left time: 85.0005s\n",
      "\titers: 600, epoch: 3 | loss: 0.1340184\n",
      "\tspeed: 0.0412s/iter; left time: 77.0970s\n",
      "Epoch: 3 cost time: 25.978017568588257\n",
      "Epoch: 3, Steps: 618 | Train Loss: 0.1711658 Vali Loss: 0.3152286 Test Loss: 0.2511558\n",
      "Validation loss decreased (0.323736 --> 0.315229).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1620352\n",
      "\tspeed: 0.0950s/iter; left time: 166.6920s\n",
      "\titers: 200, epoch: 4 | loss: 0.2392211\n",
      "\tspeed: 0.0418s/iter; left time: 69.1029s\n",
      "\titers: 300, epoch: 4 | loss: 0.2237509\n",
      "\tspeed: 0.0415s/iter; left time: 64.4813s\n",
      "\titers: 400, epoch: 4 | loss: 0.1197724\n",
      "\tspeed: 0.0423s/iter; left time: 61.5908s\n",
      "\titers: 500, epoch: 4 | loss: 0.2800475\n",
      "\tspeed: 0.0429s/iter; left time: 58.1166s\n",
      "\titers: 600, epoch: 4 | loss: 0.1265808\n",
      "\tspeed: 0.0414s/iter; left time: 51.9062s\n",
      "Epoch: 4 cost time: 25.92534112930298\n",
      "Epoch: 4, Steps: 618 | Train Loss: 0.1556970 Vali Loss: 0.3280012 Test Loss: 0.2467037\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1175876\n",
      "\tspeed: 0.0950s/iter; left time: 108.0636s\n",
      "\titers: 200, epoch: 5 | loss: 0.1346732\n",
      "\tspeed: 0.0421s/iter; left time: 43.6784s\n",
      "\titers: 300, epoch: 5 | loss: 0.1420895\n",
      "\tspeed: 0.0422s/iter; left time: 39.4998s\n",
      "\titers: 400, epoch: 5 | loss: 0.1223109\n",
      "\tspeed: 0.0420s/iter; left time: 35.1153s\n",
      "\titers: 500, epoch: 5 | loss: 0.0999613\n",
      "\tspeed: 0.0431s/iter; left time: 31.7287s\n",
      "\titers: 600, epoch: 5 | loss: 0.1041320\n",
      "\tspeed: 0.0423s/iter; left time: 26.9418s\n",
      "Epoch: 5 cost time: 26.20616364479065\n",
      "Epoch: 5, Steps: 618 | Train Loss: 0.1463247 Vali Loss: 0.3219205 Test Loss: 0.2489407\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1087956\n",
      "\tspeed: 0.0948s/iter; left time: 49.2257s\n",
      "\titers: 200, epoch: 6 | loss: 0.0775446\n",
      "\tspeed: 0.0420s/iter; left time: 17.6063s\n",
      "\titers: 300, epoch: 6 | loss: 0.1248596\n",
      "\tspeed: 0.0416s/iter; left time: 13.2851s\n",
      "\titers: 400, epoch: 6 | loss: 0.1436497\n",
      "\tspeed: 0.0418s/iter; left time: 9.1506s\n",
      "\titers: 500, epoch: 6 | loss: 0.1456562\n",
      "\tspeed: 0.0427s/iter; left time: 5.0775s\n",
      "\titers: 600, epoch: 6 | loss: 0.1503458\n",
      "\tspeed: 0.0423s/iter; left time: 0.8039s\n",
      "Epoch: 6 cost time: 26.18534016609192\n",
      "Epoch: 6, Steps: 618 | Train Loss: 0.1413288 Vali Loss: 0.3296981 Test Loss: 0.2491597\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl216_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4994\n",
      "Test cost time: 2.6836s\n",
      "test shape: (156, 32, 6, 1) (156, 32, 6, 1)\n",
      "test shape: (4992, 6, 1) (4992, 6, 1)\n",
      "mse:0.2527669668197632, mae:0.3346236050128937\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl216_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1730.8916015625\n",
      "MAE:  27.690536499023438\n",
      "RMSE: 41.60398483276367\n",
      "MAPE: 0.3959085941314697\n",
      "MSPE: 0.8075483441352844\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl216_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24323\n",
      "[DEBUG] Original dataset length: 24323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19785\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3279\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4994\n",
      "\titers: 100, epoch: 1 | loss: 0.3663201\n",
      "\tspeed: 0.0428s/iter; left time: 154.4336s\n",
      "\titers: 200, epoch: 1 | loss: 0.2607256\n",
      "\tspeed: 0.0421s/iter; left time: 147.6534s\n",
      "\titers: 300, epoch: 1 | loss: 0.1887660\n",
      "\tspeed: 0.0417s/iter; left time: 141.9904s\n",
      "\titers: 400, epoch: 1 | loss: 0.2481453\n",
      "\tspeed: 0.0433s/iter; left time: 143.2311s\n",
      "\titers: 500, epoch: 1 | loss: 0.2478992\n",
      "\tspeed: 0.0419s/iter; left time: 134.3465s\n",
      "\titers: 600, epoch: 1 | loss: 0.1865162\n",
      "\tspeed: 0.0424s/iter; left time: 131.7584s\n",
      "Epoch: 1 cost time: 26.200383186340332\n",
      "Epoch: 1, Steps: 618 | Train Loss: 0.2814964 Vali Loss: 0.3173611 Test Loss: 0.2574653\n",
      "Validation loss decreased (inf --> 0.317361).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3215540\n",
      "\tspeed: 0.0970s/iter; left time: 289.9786s\n",
      "\titers: 200, epoch: 2 | loss: 0.2299848\n",
      "\tspeed: 0.0427s/iter; left time: 123.3914s\n",
      "\titers: 300, epoch: 2 | loss: 0.2129880\n",
      "\tspeed: 0.0427s/iter; left time: 119.0485s\n",
      "\titers: 400, epoch: 2 | loss: 0.1368433\n",
      "\tspeed: 0.0442s/iter; left time: 118.9587s\n",
      "\titers: 500, epoch: 2 | loss: 0.1495978\n",
      "\tspeed: 0.0426s/iter; left time: 110.2804s\n",
      "\titers: 600, epoch: 2 | loss: 0.1436598\n",
      "\tspeed: 0.0427s/iter; left time: 106.3411s\n",
      "Epoch: 2 cost time: 26.53640651702881\n",
      "Epoch: 2, Steps: 618 | Train Loss: 0.2004114 Vali Loss: 0.3145812 Test Loss: 0.2562110\n",
      "Validation loss decreased (0.317361 --> 0.314581).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1717549\n",
      "\tspeed: 0.0974s/iter; left time: 231.2133s\n",
      "\titers: 200, epoch: 3 | loss: 0.1024798\n",
      "\tspeed: 0.0430s/iter; left time: 97.6568s\n",
      "\titers: 300, epoch: 3 | loss: 0.2018980\n",
      "\tspeed: 0.0431s/iter; left time: 93.6019s\n",
      "\titers: 400, epoch: 3 | loss: 0.1490218\n",
      "\tspeed: 0.0443s/iter; left time: 91.9208s\n",
      "\titers: 500, epoch: 3 | loss: 0.1148567\n",
      "\tspeed: 0.0430s/iter; left time: 84.7820s\n",
      "\titers: 600, epoch: 3 | loss: 0.1667985\n",
      "\tspeed: 0.0423s/iter; left time: 79.3211s\n",
      "Epoch: 3 cost time: 26.672253847122192\n",
      "Epoch: 3, Steps: 618 | Train Loss: 0.1719259 Vali Loss: 0.3079414 Test Loss: 0.2418546\n",
      "Validation loss decreased (0.314581 --> 0.307941).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1700431\n",
      "\tspeed: 0.0965s/iter; left time: 169.3316s\n",
      "\titers: 200, epoch: 4 | loss: 0.1768593\n",
      "\tspeed: 0.0429s/iter; left time: 70.9699s\n",
      "\titers: 300, epoch: 4 | loss: 0.2237493\n",
      "\tspeed: 0.0423s/iter; left time: 65.8503s\n",
      "\titers: 400, epoch: 4 | loss: 0.0976973\n",
      "\tspeed: 0.0437s/iter; left time: 63.5642s\n",
      "\titers: 500, epoch: 4 | loss: 0.1349014\n",
      "\tspeed: 0.0438s/iter; left time: 59.3496s\n",
      "\titers: 600, epoch: 4 | loss: 0.1642562\n",
      "\tspeed: 0.0434s/iter; left time: 54.4406s\n",
      "Epoch: 4 cost time: 26.598915815353394\n",
      "Epoch: 4, Steps: 618 | Train Loss: 0.1567625 Vali Loss: 0.3138925 Test Loss: 0.2492318\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1343656\n",
      "\tspeed: 0.0952s/iter; left time: 108.2618s\n",
      "\titers: 200, epoch: 5 | loss: 0.1559961\n",
      "\tspeed: 0.0430s/iter; left time: 44.6225s\n",
      "\titers: 300, epoch: 5 | loss: 0.1233110\n",
      "\tspeed: 0.0428s/iter; left time: 40.1123s\n",
      "\titers: 400, epoch: 5 | loss: 0.1776212\n",
      "\tspeed: 0.0438s/iter; left time: 36.6419s\n",
      "\titers: 500, epoch: 5 | loss: 0.1519401\n",
      "\tspeed: 0.0419s/iter; left time: 30.8620s\n",
      "\titers: 600, epoch: 5 | loss: 0.1732384\n",
      "\tspeed: 0.0429s/iter; left time: 27.3108s\n",
      "Epoch: 5 cost time: 26.45865821838379\n",
      "Epoch: 5, Steps: 618 | Train Loss: 0.1471789 Vali Loss: 0.3088903 Test Loss: 0.2510030\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2094733\n",
      "\tspeed: 0.0957s/iter; left time: 49.6894s\n",
      "\titers: 200, epoch: 6 | loss: 0.1189274\n",
      "\tspeed: 0.0424s/iter; left time: 17.7578s\n",
      "\titers: 300, epoch: 6 | loss: 0.1680369\n",
      "\tspeed: 0.0424s/iter; left time: 13.5268s\n",
      "\titers: 400, epoch: 6 | loss: 0.0696787\n",
      "\tspeed: 0.0433s/iter; left time: 9.4855s\n",
      "\titers: 500, epoch: 6 | loss: 0.1559110\n",
      "\tspeed: 0.0421s/iter; left time: 5.0054s\n",
      "\titers: 600, epoch: 6 | loss: 0.1555460\n",
      "\tspeed: 0.0425s/iter; left time: 0.8081s\n",
      "Epoch: 6 cost time: 26.276623487472534\n",
      "Epoch: 6, Steps: 618 | Train Loss: 0.1419787 Vali Loss: 0.3119181 Test Loss: 0.2509308\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl216_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4994\n",
      "Test cost time: 2.7332s\n",
      "test shape: (156, 32, 6, 1) (156, 32, 6, 1)\n",
      "test shape: (4992, 6, 1) (4992, 6, 1)\n",
      "mse:0.24249933660030365, mae:0.3270329535007477\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl216_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1660.5809326171875\n",
      "MAE:  27.06239891052246\n",
      "RMSE: 40.75022506713867\n",
      "MAPE: 0.38842013478279114\n",
      "MSPE: 0.7867160439491272\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl216_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24323\n",
      "[DEBUG] Original dataset length: 24323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19785\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3279\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4994\n",
      "\titers: 100, epoch: 1 | loss: 0.2032532\n",
      "\tspeed: 0.0450s/iter; left time: 162.5694s\n",
      "\titers: 200, epoch: 1 | loss: 0.1563274\n",
      "\tspeed: 0.0423s/iter; left time: 148.5683s\n",
      "\titers: 300, epoch: 1 | loss: 0.2232013\n",
      "\tspeed: 0.0436s/iter; left time: 148.6863s\n",
      "\titers: 400, epoch: 1 | loss: 0.2476838\n",
      "\tspeed: 0.0429s/iter; left time: 141.8675s\n",
      "\titers: 500, epoch: 1 | loss: 0.2196051\n",
      "\tspeed: 0.0425s/iter; left time: 136.3004s\n",
      "\titers: 600, epoch: 1 | loss: 0.1190104\n",
      "\tspeed: 0.0431s/iter; left time: 134.0178s\n",
      "Epoch: 1 cost time: 26.75853967666626\n",
      "Epoch: 1, Steps: 618 | Train Loss: 0.2769553 Vali Loss: 0.3341312 Test Loss: 0.2757868\n",
      "Validation loss decreased (inf --> 0.334131).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1786525\n",
      "\tspeed: 0.0983s/iter; left time: 294.0344s\n",
      "\titers: 200, epoch: 2 | loss: 0.1971705\n",
      "\tspeed: 0.0432s/iter; left time: 124.7719s\n",
      "\titers: 300, epoch: 2 | loss: 0.2869054\n",
      "\tspeed: 0.0433s/iter; left time: 120.8248s\n",
      "\titers: 400, epoch: 2 | loss: 0.2147620\n",
      "\tspeed: 0.0432s/iter; left time: 116.2839s\n",
      "\titers: 500, epoch: 2 | loss: 0.1511822\n",
      "\tspeed: 0.0432s/iter; left time: 111.9206s\n",
      "\titers: 600, epoch: 2 | loss: 0.2114589\n",
      "\tspeed: 0.0445s/iter; left time: 110.7365s\n",
      "Epoch: 2 cost time: 26.93069314956665\n",
      "Epoch: 2, Steps: 618 | Train Loss: 0.1954781 Vali Loss: 0.3158267 Test Loss: 0.2525209\n",
      "Validation loss decreased (0.334131 --> 0.315827).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1257085\n",
      "\tspeed: 0.0984s/iter; left time: 233.4402s\n",
      "\titers: 200, epoch: 3 | loss: 0.1782224\n",
      "\tspeed: 0.0446s/iter; left time: 101.3000s\n",
      "\titers: 300, epoch: 3 | loss: 0.1250286\n",
      "\tspeed: 0.0430s/iter; left time: 93.4854s\n",
      "\titers: 400, epoch: 3 | loss: 0.2739024\n",
      "\tspeed: 0.0432s/iter; left time: 89.4776s\n",
      "\titers: 500, epoch: 3 | loss: 0.1310438\n",
      "\tspeed: 0.0421s/iter; left time: 83.1595s\n",
      "\titers: 600, epoch: 3 | loss: 0.2279646\n",
      "\tspeed: 0.0479s/iter; left time: 89.7251s\n",
      "Epoch: 3 cost time: 27.228859186172485\n",
      "Epoch: 3, Steps: 618 | Train Loss: 0.1712560 Vali Loss: 0.3140414 Test Loss: 0.2479146\n",
      "Validation loss decreased (0.315827 --> 0.314041).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1319314\n",
      "\tspeed: 0.0984s/iter; left time: 172.6591s\n",
      "\titers: 200, epoch: 4 | loss: 0.1478963\n",
      "\tspeed: 0.0435s/iter; left time: 72.0454s\n",
      "\titers: 300, epoch: 4 | loss: 0.1752971\n",
      "\tspeed: 0.0419s/iter; left time: 65.0968s\n",
      "\titers: 400, epoch: 4 | loss: 0.1838036\n",
      "\tspeed: 0.0425s/iter; left time: 61.7918s\n",
      "\titers: 500, epoch: 4 | loss: 0.1232213\n",
      "\tspeed: 0.0422s/iter; left time: 57.1985s\n",
      "\titers: 600, epoch: 4 | loss: 0.3609026\n",
      "\tspeed: 0.0426s/iter; left time: 53.4668s\n",
      "Epoch: 4 cost time: 26.35153102874756\n",
      "Epoch: 4, Steps: 618 | Train Loss: 0.1557990 Vali Loss: 0.3134092 Test Loss: 0.2523001\n",
      "Validation loss decreased (0.314041 --> 0.313409).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1199196\n",
      "\tspeed: 0.0936s/iter; left time: 106.4205s\n",
      "\titers: 200, epoch: 5 | loss: 0.1493078\n",
      "\tspeed: 0.0426s/iter; left time: 44.2052s\n",
      "\titers: 300, epoch: 5 | loss: 0.1602696\n",
      "\tspeed: 0.0420s/iter; left time: 39.3506s\n",
      "\titers: 400, epoch: 5 | loss: 0.1826160\n",
      "\tspeed: 0.0414s/iter; left time: 34.6846s\n",
      "\titers: 500, epoch: 5 | loss: 0.1088535\n",
      "\tspeed: 0.0420s/iter; left time: 30.9399s\n",
      "\titers: 600, epoch: 5 | loss: 0.0920276\n",
      "\tspeed: 0.0437s/iter; left time: 27.8388s\n",
      "Epoch: 5 cost time: 26.047558307647705\n",
      "Epoch: 5, Steps: 618 | Train Loss: 0.1471018 Vali Loss: 0.3149575 Test Loss: 0.2584056\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0988151\n",
      "\tspeed: 0.0934s/iter; left time: 48.4630s\n",
      "\titers: 200, epoch: 6 | loss: 0.1204196\n",
      "\tspeed: 0.0430s/iter; left time: 18.0222s\n",
      "\titers: 300, epoch: 6 | loss: 0.1423402\n",
      "\tspeed: 0.0414s/iter; left time: 13.2097s\n",
      "\titers: 400, epoch: 6 | loss: 0.1468095\n",
      "\tspeed: 0.0413s/iter; left time: 9.0352s\n",
      "\titers: 500, epoch: 6 | loss: 0.2755381\n",
      "\tspeed: 0.0425s/iter; left time: 5.0620s\n",
      "\titers: 600, epoch: 6 | loss: 0.1499323\n",
      "\tspeed: 0.0418s/iter; left time: 0.7937s\n",
      "Epoch: 6 cost time: 25.98641014099121\n",
      "Epoch: 6, Steps: 618 | Train Loss: 0.1419851 Vali Loss: 0.3068340 Test Loss: 0.2524299\n",
      "Validation loss decreased (0.313409 --> 0.306834).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl216_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4994\n",
      "Test cost time: 2.6633s\n",
      "test shape: (156, 32, 6, 1) (156, 32, 6, 1)\n",
      "test shape: (4992, 6, 1) (4992, 6, 1)\n",
      "mse:0.2544175386428833, mae:0.3253953158855438\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl216_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1742.194091796875\n",
      "MAE:  26.926881790161133\n",
      "RMSE: 41.73959732055664\n",
      "MAPE: 0.344081848859787\n",
      "MSPE: 0.5385942459106445\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl216_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24323\n",
      "[DEBUG] Original dataset length: 24323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19785\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3279\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4994\n",
      "\titers: 100, epoch: 1 | loss: 0.4121531\n",
      "\tspeed: 0.0421s/iter; left time: 152.1127s\n",
      "\titers: 200, epoch: 1 | loss: 0.2414803\n",
      "\tspeed: 0.0417s/iter; left time: 146.3045s\n",
      "\titers: 300, epoch: 1 | loss: 0.2232457\n",
      "\tspeed: 0.0414s/iter; left time: 140.9967s\n",
      "\titers: 400, epoch: 1 | loss: 0.2618462\n",
      "\tspeed: 0.0414s/iter; left time: 136.9763s\n",
      "\titers: 500, epoch: 1 | loss: 0.2106108\n",
      "\tspeed: 0.0430s/iter; left time: 137.8668s\n",
      "\titers: 600, epoch: 1 | loss: 0.2415765\n",
      "\tspeed: 0.0420s/iter; left time: 130.5408s\n",
      "Epoch: 1 cost time: 25.92520236968994\n",
      "Epoch: 1, Steps: 618 | Train Loss: 0.2960583 Vali Loss: 0.3377845 Test Loss: 0.2846154\n",
      "Validation loss decreased (inf --> 0.337784).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1967784\n",
      "\tspeed: 0.0942s/iter; left time: 281.6610s\n",
      "\titers: 200, epoch: 2 | loss: 0.2142658\n",
      "\tspeed: 0.0414s/iter; left time: 119.6016s\n",
      "\titers: 300, epoch: 2 | loss: 0.1820853\n",
      "\tspeed: 0.0417s/iter; left time: 116.4305s\n",
      "\titers: 400, epoch: 2 | loss: 0.2328463\n",
      "\tspeed: 0.0415s/iter; left time: 111.6662s\n",
      "\titers: 500, epoch: 2 | loss: 0.4991306\n",
      "\tspeed: 0.0422s/iter; left time: 109.4036s\n",
      "\titers: 600, epoch: 2 | loss: 0.2701077\n",
      "\tspeed: 0.0416s/iter; left time: 103.5228s\n",
      "Epoch: 2 cost time: 25.725220203399658\n",
      "Epoch: 2, Steps: 618 | Train Loss: 0.2012755 Vali Loss: 0.3333133 Test Loss: 0.2670879\n",
      "Validation loss decreased (0.337784 --> 0.333313).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1551149\n",
      "\tspeed: 0.0949s/iter; left time: 225.0969s\n",
      "\titers: 200, epoch: 3 | loss: 0.1445478\n",
      "\tspeed: 0.0422s/iter; left time: 95.8995s\n",
      "\titers: 300, epoch: 3 | loss: 0.1368873\n",
      "\tspeed: 0.0415s/iter; left time: 90.1391s\n",
      "\titers: 400, epoch: 3 | loss: 0.1274137\n",
      "\tspeed: 0.0412s/iter; left time: 85.4666s\n",
      "\titers: 500, epoch: 3 | loss: 0.1286819\n",
      "\tspeed: 0.0428s/iter; left time: 84.4615s\n",
      "\titers: 600, epoch: 3 | loss: 0.0996899\n",
      "\tspeed: 0.0411s/iter; left time: 77.0488s\n",
      "Epoch: 3 cost time: 25.874960899353027\n",
      "Epoch: 3, Steps: 618 | Train Loss: 0.1729698 Vali Loss: 0.3082447 Test Loss: 0.2411761\n",
      "Validation loss decreased (0.333313 --> 0.308245).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1615661\n",
      "\tspeed: 0.0951s/iter; left time: 166.9414s\n",
      "\titers: 200, epoch: 4 | loss: 0.1111029\n",
      "\tspeed: 0.0425s/iter; left time: 70.2956s\n",
      "\titers: 300, epoch: 4 | loss: 0.0956634\n",
      "\tspeed: 0.0414s/iter; left time: 64.4114s\n",
      "\titers: 400, epoch: 4 | loss: 0.2307972\n",
      "\tspeed: 0.0417s/iter; left time: 60.6332s\n",
      "\titers: 500, epoch: 4 | loss: 0.1342136\n",
      "\tspeed: 0.0427s/iter; left time: 57.8943s\n",
      "\titers: 600, epoch: 4 | loss: 0.2959890\n",
      "\tspeed: 0.0425s/iter; left time: 53.3272s\n",
      "Epoch: 4 cost time: 26.101926565170288\n",
      "Epoch: 4, Steps: 618 | Train Loss: 0.1575196 Vali Loss: 0.3145727 Test Loss: 0.2482154\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1563228\n",
      "\tspeed: 0.0947s/iter; left time: 107.6481s\n",
      "\titers: 200, epoch: 5 | loss: 0.1583908\n",
      "\tspeed: 0.0420s/iter; left time: 43.5978s\n",
      "\titers: 300, epoch: 5 | loss: 0.1178816\n",
      "\tspeed: 0.0418s/iter; left time: 39.1659s\n",
      "\titers: 400, epoch: 5 | loss: 0.1281954\n",
      "\tspeed: 0.0417s/iter; left time: 34.8784s\n",
      "\titers: 500, epoch: 5 | loss: 0.1068196\n",
      "\tspeed: 0.0426s/iter; left time: 31.3633s\n",
      "\titers: 600, epoch: 5 | loss: 0.1602941\n",
      "\tspeed: 0.0412s/iter; left time: 26.2695s\n",
      "Epoch: 5 cost time: 25.89297652244568\n",
      "Epoch: 5, Steps: 618 | Train Loss: 0.1482549 Vali Loss: 0.3200294 Test Loss: 0.2549565\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2097220\n",
      "\tspeed: 0.0937s/iter; left time: 48.6064s\n",
      "\titers: 200, epoch: 6 | loss: 0.0853412\n",
      "\tspeed: 0.0429s/iter; left time: 17.9544s\n",
      "\titers: 300, epoch: 6 | loss: 0.1417271\n",
      "\tspeed: 0.0422s/iter; left time: 13.4533s\n",
      "\titers: 400, epoch: 6 | loss: 0.1316091\n",
      "\tspeed: 0.0415s/iter; left time: 9.0873s\n",
      "\titers: 500, epoch: 6 | loss: 0.1413137\n",
      "\tspeed: 0.0427s/iter; left time: 5.0833s\n",
      "\titers: 600, epoch: 6 | loss: 0.1131534\n",
      "\tspeed: 0.0420s/iter; left time: 0.7977s\n",
      "Epoch: 6 cost time: 26.076175689697266\n",
      "Epoch: 6, Steps: 618 | Train Loss: 0.1432047 Vali Loss: 0.3301705 Test Loss: 0.2569723\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl216_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4994\n",
      "Test cost time: 2.6871s\n",
      "test shape: (156, 32, 6, 1) (156, 32, 6, 1)\n",
      "test shape: (4992, 6, 1) (4992, 6, 1)\n",
      "mse:0.24254441261291504, mae:0.3337668478488922\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl216_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1660.8896484375\n",
      "MAE:  27.61963653564453\n",
      "RMSE: 40.75401306152344\n",
      "MAPE: 0.421096533536911\n",
      "MSPE: 0.8992426991462708\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl216_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24323\n",
      "[DEBUG] Original dataset length: 24323\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19785\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3279\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4994\n",
      "\titers: 100, epoch: 1 | loss: 0.2675985\n",
      "\tspeed: 0.0495s/iter; left time: 178.5448s\n",
      "\titers: 200, epoch: 1 | loss: 0.2659911\n",
      "\tspeed: 0.0413s/iter; left time: 145.0514s\n",
      "\titers: 300, epoch: 1 | loss: 0.2630031\n",
      "\tspeed: 0.0412s/iter; left time: 140.4849s\n",
      "\titers: 400, epoch: 1 | loss: 0.1671163\n",
      "\tspeed: 0.0429s/iter; left time: 141.9724s\n",
      "\titers: 500, epoch: 1 | loss: 0.1804161\n",
      "\tspeed: 0.0425s/iter; left time: 136.2645s\n",
      "\titers: 600, epoch: 1 | loss: 0.2369458\n",
      "\tspeed: 0.0420s/iter; left time: 130.6081s\n",
      "Epoch: 1 cost time: 26.729716300964355\n",
      "Epoch: 1, Steps: 618 | Train Loss: 0.2941173 Vali Loss: 0.3402280 Test Loss: 0.2910387\n",
      "Validation loss decreased (inf --> 0.340228).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1987396\n",
      "\tspeed: 0.0973s/iter; left time: 290.9307s\n",
      "\titers: 200, epoch: 2 | loss: 0.2926353\n",
      "\tspeed: 0.0414s/iter; left time: 119.7629s\n",
      "\titers: 300, epoch: 2 | loss: 0.1864560\n",
      "\tspeed: 0.0412s/iter; left time: 115.0843s\n",
      "\titers: 400, epoch: 2 | loss: 0.1905792\n",
      "\tspeed: 0.0422s/iter; left time: 113.6864s\n",
      "\titers: 500, epoch: 2 | loss: 0.3763025\n",
      "\tspeed: 0.0425s/iter; left time: 110.1528s\n",
      "\titers: 600, epoch: 2 | loss: 0.1395880\n",
      "\tspeed: 0.0422s/iter; left time: 105.1735s\n",
      "Epoch: 2 cost time: 25.979896783828735\n",
      "Epoch: 2, Steps: 618 | Train Loss: 0.2025699 Vali Loss: 0.3245832 Test Loss: 0.2729788\n",
      "Validation loss decreased (0.340228 --> 0.324583).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2120875\n",
      "\tspeed: 0.0936s/iter; left time: 222.1688s\n",
      "\titers: 200, epoch: 3 | loss: 0.1325023\n",
      "\tspeed: 0.0416s/iter; left time: 94.4965s\n",
      "\titers: 300, epoch: 3 | loss: 0.1422473\n",
      "\tspeed: 0.0412s/iter; left time: 89.6357s\n",
      "\titers: 400, epoch: 3 | loss: 0.1364473\n",
      "\tspeed: 0.0419s/iter; left time: 86.9447s\n",
      "\titers: 500, epoch: 3 | loss: 0.1337636\n",
      "\tspeed: 0.0425s/iter; left time: 83.7929s\n",
      "\titers: 600, epoch: 3 | loss: 0.1595610\n",
      "\tspeed: 0.0424s/iter; left time: 79.3511s\n",
      "Epoch: 3 cost time: 25.852632522583008\n",
      "Epoch: 3, Steps: 618 | Train Loss: 0.1723179 Vali Loss: 0.3104116 Test Loss: 0.2505572\n",
      "Validation loss decreased (0.324583 --> 0.310412).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1719283\n",
      "\tspeed: 0.0955s/iter; left time: 167.6883s\n",
      "\titers: 200, epoch: 4 | loss: 0.1514657\n",
      "\tspeed: 0.0419s/iter; left time: 69.3207s\n",
      "\titers: 300, epoch: 4 | loss: 0.1412131\n",
      "\tspeed: 0.0414s/iter; left time: 64.3909s\n",
      "\titers: 400, epoch: 4 | loss: 0.1493793\n",
      "\tspeed: 0.0420s/iter; left time: 61.0640s\n",
      "\titers: 500, epoch: 4 | loss: 0.2003113\n",
      "\tspeed: 0.0422s/iter; left time: 57.1478s\n",
      "\titers: 600, epoch: 4 | loss: 0.1438348\n",
      "\tspeed: 0.0428s/iter; left time: 53.6775s\n",
      "Epoch: 4 cost time: 26.01955533027649\n",
      "Epoch: 4, Steps: 618 | Train Loss: 0.1562042 Vali Loss: 0.3063864 Test Loss: 0.2485543\n",
      "Validation loss decreased (0.310412 --> 0.306386).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1641852\n",
      "\tspeed: 0.0959s/iter; left time: 109.0284s\n",
      "\titers: 200, epoch: 5 | loss: 0.1286202\n",
      "\tspeed: 0.0416s/iter; left time: 43.0909s\n",
      "\titers: 300, epoch: 5 | loss: 0.1829571\n",
      "\tspeed: 0.0414s/iter; left time: 38.7885s\n",
      "\titers: 400, epoch: 5 | loss: 0.1691171\n",
      "\tspeed: 0.0421s/iter; left time: 35.1989s\n",
      "\titers: 500, epoch: 5 | loss: 0.1600448\n",
      "\tspeed: 0.0419s/iter; left time: 30.9171s\n",
      "\titers: 600, epoch: 5 | loss: 0.1593293\n",
      "\tspeed: 0.0417s/iter; left time: 26.5687s\n",
      "Epoch: 5 cost time: 25.9362690448761\n",
      "Epoch: 5, Steps: 618 | Train Loss: 0.1465654 Vali Loss: 0.3162679 Test Loss: 0.2543659\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1409432\n",
      "\tspeed: 0.0941s/iter; left time: 48.8203s\n",
      "\titers: 200, epoch: 6 | loss: 0.0957621\n",
      "\tspeed: 0.0420s/iter; left time: 17.5931s\n",
      "\titers: 300, epoch: 6 | loss: 0.1667231\n",
      "\tspeed: 0.0416s/iter; left time: 13.2666s\n",
      "\titers: 400, epoch: 6 | loss: 0.1415000\n",
      "\tspeed: 0.0417s/iter; left time: 9.1345s\n",
      "\titers: 500, epoch: 6 | loss: 0.1890998\n",
      "\tspeed: 0.0420s/iter; left time: 4.9987s\n",
      "\titers: 600, epoch: 6 | loss: 0.1198669\n",
      "\tspeed: 0.0425s/iter; left time: 0.8076s\n",
      "Epoch: 6 cost time: 26.004842281341553\n",
      "Epoch: 6, Steps: 618 | Train Loss: 0.1418650 Vali Loss: 0.3351026 Test Loss: 0.2559977\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl216_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4994\n",
      "Test cost time: 2.6917s\n",
      "test shape: (156, 32, 6, 1) (156, 32, 6, 1)\n",
      "test shape: (4992, 6, 1) (4992, 6, 1)\n",
      "mse:0.24835717678070068, mae:0.3331948220729828\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl216_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1700.6942138671875\n",
      "MAE:  27.57229995727539\n",
      "RMSE: 41.23947525024414\n",
      "MAPE: 0.3635236620903015\n",
      "MSPE: 0.6031321883201599\n",
      ">>>>>>>Running time saved<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Running seq_len=240\n",
      "Args in experiment:\n",
      "Namespace(model='informer', data='traffic_full', root_path='../', data_path='traffic_full.csv', features='S', target='flow', freq='h', checkpoints='./checkpoints/', seq_len=240, label_len=24, pred_len=6, enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=2, d_layers=1, s_layers=[3, 2, 1], d_ff=2048, factor=5, padding=0, distil=True, dropout=0.05, attn='prob', embed='timeF', activation='gelu', output_attention=False, do_predict=False, mix=True, cols=None, num_workers=0, itr=10, train_epochs=6, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, inverse=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', detail_freq='h')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24299\n",
      "[DEBUG] Original dataset length: 24299\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19377\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3255\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "\titers: 100, epoch: 1 | loss: 0.3546871\n",
      "\tspeed: 0.0589s/iter; left time: 207.9175s\n",
      "\titers: 200, epoch: 1 | loss: 0.2993786\n",
      "\tspeed: 0.0444s/iter; left time: 152.4810s\n",
      "\titers: 300, epoch: 1 | loss: 0.2675970\n",
      "\tspeed: 0.0449s/iter; left time: 149.5058s\n",
      "\titers: 400, epoch: 1 | loss: 0.2477891\n",
      "\tspeed: 0.0446s/iter; left time: 144.0266s\n",
      "\titers: 500, epoch: 1 | loss: 0.4545132\n",
      "\tspeed: 0.0443s/iter; left time: 138.8371s\n",
      "\titers: 600, epoch: 1 | loss: 0.2212815\n",
      "\tspeed: 0.0453s/iter; left time: 137.4480s\n",
      "Epoch: 1 cost time: 27.556166172027588\n",
      "Epoch: 1, Steps: 605 | Train Loss: 0.2871743 Vali Loss: 0.3479817 Test Loss: 0.3048871\n",
      "Validation loss decreased (inf --> 0.347982).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1546247\n",
      "\tspeed: 0.0933s/iter; left time: 273.1157s\n",
      "\titers: 200, epoch: 2 | loss: 0.4938394\n",
      "\tspeed: 0.0451s/iter; left time: 127.5372s\n",
      "\titers: 300, epoch: 2 | loss: 0.1789630\n",
      "\tspeed: 0.0447s/iter; left time: 121.7347s\n",
      "\titers: 400, epoch: 2 | loss: 0.2018030\n",
      "\tspeed: 0.0447s/iter; left time: 117.3492s\n",
      "\titers: 500, epoch: 2 | loss: 0.1464297\n",
      "\tspeed: 0.0445s/iter; left time: 112.3590s\n",
      "\titers: 600, epoch: 2 | loss: 0.1904877\n",
      "\tspeed: 0.0452s/iter; left time: 109.5393s\n",
      "Epoch: 2 cost time: 27.06833553314209\n",
      "Epoch: 2, Steps: 605 | Train Loss: 0.2010745 Vali Loss: 0.3595946 Test Loss: 0.2899222\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1282312\n",
      "\tspeed: 0.0925s/iter; left time: 214.7722s\n",
      "\titers: 200, epoch: 3 | loss: 0.1518289\n",
      "\tspeed: 0.0453s/iter; left time: 100.5373s\n",
      "\titers: 300, epoch: 3 | loss: 0.1745663\n",
      "\tspeed: 0.0443s/iter; left time: 93.9239s\n",
      "\titers: 400, epoch: 3 | loss: 0.2905336\n",
      "\tspeed: 0.0441s/iter; left time: 89.1863s\n",
      "\titers: 500, epoch: 3 | loss: 0.1416414\n",
      "\tspeed: 0.0450s/iter; left time: 86.4795s\n",
      "\titers: 600, epoch: 3 | loss: 0.3046931\n",
      "\tspeed: 0.0450s/iter; left time: 81.8683s\n",
      "Epoch: 3 cost time: 27.07199001312256\n",
      "Epoch: 3, Steps: 605 | Train Loss: 0.1694175 Vali Loss: 0.3199262 Test Loss: 0.2568452\n",
      "Validation loss decreased (0.347982 --> 0.319926).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0802445\n",
      "\tspeed: 0.0942s/iter; left time: 161.6598s\n",
      "\titers: 200, epoch: 4 | loss: 0.1307834\n",
      "\tspeed: 0.0457s/iter; left time: 73.8472s\n",
      "\titers: 300, epoch: 4 | loss: 0.2070717\n",
      "\tspeed: 0.0441s/iter; left time: 66.8270s\n",
      "\titers: 400, epoch: 4 | loss: 0.1654413\n",
      "\tspeed: 0.0446s/iter; left time: 63.1137s\n",
      "\titers: 500, epoch: 4 | loss: 0.1137933\n",
      "\tspeed: 0.0457s/iter; left time: 60.1489s\n",
      "\titers: 600, epoch: 4 | loss: 0.1222538\n",
      "\tspeed: 0.0438s/iter; left time: 53.2930s\n",
      "Epoch: 4 cost time: 27.09575605392456\n",
      "Epoch: 4, Steps: 605 | Train Loss: 0.1549409 Vali Loss: 0.3164373 Test Loss: 0.2522540\n",
      "Validation loss decreased (0.319926 --> 0.316437).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2000692\n",
      "\tspeed: 0.0934s/iter; left time: 103.7337s\n",
      "\titers: 200, epoch: 5 | loss: 0.1241776\n",
      "\tspeed: 0.0437s/iter; left time: 44.2195s\n",
      "\titers: 300, epoch: 5 | loss: 0.1543847\n",
      "\tspeed: 0.0443s/iter; left time: 40.3612s\n",
      "\titers: 400, epoch: 5 | loss: 0.0986403\n",
      "\tspeed: 0.0444s/iter; left time: 36.0142s\n",
      "\titers: 500, epoch: 5 | loss: 0.1071101\n",
      "\tspeed: 0.0454s/iter; left time: 32.2642s\n",
      "\titers: 600, epoch: 5 | loss: 0.1854616\n",
      "\tspeed: 0.0445s/iter; left time: 27.1939s\n",
      "Epoch: 5 cost time: 26.85697293281555\n",
      "Epoch: 5, Steps: 605 | Train Loss: 0.1461998 Vali Loss: 0.3233185 Test Loss: 0.2495452\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1583440\n",
      "\tspeed: 0.0935s/iter; left time: 47.3279s\n",
      "\titers: 200, epoch: 6 | loss: 0.1225656\n",
      "\tspeed: 0.0456s/iter; left time: 18.5020s\n",
      "\titers: 300, epoch: 6 | loss: 0.1298719\n",
      "\tspeed: 0.0447s/iter; left time: 13.6651s\n",
      "\titers: 400, epoch: 6 | loss: 0.2102426\n",
      "\tspeed: 0.0444s/iter; left time: 9.1392s\n",
      "\titers: 500, epoch: 6 | loss: 0.0827371\n",
      "\tspeed: 0.0446s/iter; left time: 4.7294s\n",
      "\titers: 600, epoch: 6 | loss: 0.2194119\n",
      "\tspeed: 0.0442s/iter; left time: 0.2650s\n",
      "Epoch: 6 cost time: 27.124669313430786\n",
      "Epoch: 6, Steps: 605 | Train Loss: 0.1414889 Vali Loss: 0.3273892 Test Loss: 0.2552150\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "Test cost time: 2.7801s\n",
      "test shape: (150, 32, 6, 1) (150, 32, 6, 1)\n",
      "test shape: (4800, 6, 1) (4800, 6, 1)\n",
      "mse:0.2512800395488739, mae:0.32814377546310425\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1720.7093505859375\n",
      "MAE:  27.15431785583496\n",
      "RMSE: 41.4814338684082\n",
      "MAPE: 0.3628509044647217\n",
      "MSPE: 0.6306906342506409\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24299\n",
      "[DEBUG] Original dataset length: 24299\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19377\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3255\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "\titers: 100, epoch: 1 | loss: 0.3504760\n",
      "\tspeed: 0.0442s/iter; left time: 156.0641s\n",
      "\titers: 200, epoch: 1 | loss: 0.3145763\n",
      "\tspeed: 0.0440s/iter; left time: 150.9054s\n",
      "\titers: 300, epoch: 1 | loss: 0.2003708\n",
      "\tspeed: 0.0442s/iter; left time: 147.3150s\n",
      "\titers: 400, epoch: 1 | loss: 0.2305922\n",
      "\tspeed: 0.0453s/iter; left time: 146.4796s\n",
      "\titers: 500, epoch: 1 | loss: 0.1543079\n",
      "\tspeed: 0.0453s/iter; left time: 141.7245s\n",
      "\titers: 600, epoch: 1 | loss: 0.2346435\n",
      "\tspeed: 0.0446s/iter; left time: 135.0746s\n",
      "Epoch: 1 cost time: 27.007298231124878\n",
      "Epoch: 1, Steps: 605 | Train Loss: 0.2898870 Vali Loss: 0.3304249 Test Loss: 0.2665307\n",
      "Validation loss decreased (inf --> 0.330425).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1209250\n",
      "\tspeed: 0.0961s/iter; left time: 281.0479s\n",
      "\titers: 200, epoch: 2 | loss: 0.2019567\n",
      "\tspeed: 0.0451s/iter; left time: 127.3339s\n",
      "\titers: 300, epoch: 2 | loss: 0.1537015\n",
      "\tspeed: 0.0459s/iter; left time: 125.2492s\n",
      "\titers: 400, epoch: 2 | loss: 0.2416111\n",
      "\tspeed: 0.0462s/iter; left time: 121.2809s\n",
      "\titers: 500, epoch: 2 | loss: 0.1263018\n",
      "\tspeed: 0.0452s/iter; left time: 114.0888s\n",
      "\titers: 600, epoch: 2 | loss: 0.2908061\n",
      "\tspeed: 0.0451s/iter; left time: 109.5236s\n",
      "Epoch: 2 cost time: 27.493525981903076\n",
      "Epoch: 2, Steps: 605 | Train Loss: 0.1969819 Vali Loss: 0.3213315 Test Loss: 0.2575419\n",
      "Validation loss decreased (0.330425 --> 0.321332).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1477247\n",
      "\tspeed: 0.0959s/iter; left time: 222.5145s\n",
      "\titers: 200, epoch: 3 | loss: 0.1456246\n",
      "\tspeed: 0.0450s/iter; left time: 99.9442s\n",
      "\titers: 300, epoch: 3 | loss: 0.1307080\n",
      "\tspeed: 0.0450s/iter; left time: 95.4184s\n",
      "\titers: 400, epoch: 3 | loss: 0.2041646\n",
      "\tspeed: 0.0450s/iter; left time: 90.9834s\n",
      "\titers: 500, epoch: 3 | loss: 0.1587016\n",
      "\tspeed: 0.0457s/iter; left time: 87.7337s\n",
      "\titers: 600, epoch: 3 | loss: 0.1153596\n",
      "\tspeed: 0.0463s/iter; left time: 84.2305s\n",
      "Epoch: 3 cost time: 27.455731630325317\n",
      "Epoch: 3, Steps: 605 | Train Loss: 0.1695223 Vali Loss: 0.3316666 Test Loss: 0.2576473\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1524941\n",
      "\tspeed: 0.0944s/iter; left time: 161.9324s\n",
      "\titers: 200, epoch: 4 | loss: 0.1457122\n",
      "\tspeed: 0.0453s/iter; left time: 73.2465s\n",
      "\titers: 300, epoch: 4 | loss: 0.1419670\n",
      "\tspeed: 0.0458s/iter; left time: 69.4525s\n",
      "\titers: 400, epoch: 4 | loss: 0.2018518\n",
      "\tspeed: 0.0456s/iter; left time: 64.5538s\n",
      "\titers: 500, epoch: 4 | loss: 0.1779337\n",
      "\tspeed: 0.0458s/iter; left time: 60.2101s\n",
      "\titers: 600, epoch: 4 | loss: 0.1989736\n",
      "\tspeed: 0.0463s/iter; left time: 56.3434s\n",
      "Epoch: 4 cost time: 27.641367197036743\n",
      "Epoch: 4, Steps: 605 | Train Loss: 0.1534309 Vali Loss: 0.3375521 Test Loss: 0.2641195\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1779419\n",
      "\tspeed: 0.0945s/iter; left time: 104.9938s\n",
      "\titers: 200, epoch: 5 | loss: 0.1681830\n",
      "\tspeed: 0.0463s/iter; left time: 46.8137s\n",
      "\titers: 300, epoch: 5 | loss: 0.1905485\n",
      "\tspeed: 0.0446s/iter; left time: 40.6182s\n",
      "\titers: 400, epoch: 5 | loss: 0.1573281\n",
      "\tspeed: 0.0448s/iter; left time: 36.3299s\n",
      "\titers: 500, epoch: 5 | loss: 0.0991551\n",
      "\tspeed: 0.0460s/iter; left time: 32.7123s\n",
      "\titers: 600, epoch: 5 | loss: 0.1500919\n",
      "\tspeed: 0.0442s/iter; left time: 27.0277s\n",
      "Epoch: 5 cost time: 27.350849628448486\n",
      "Epoch: 5, Steps: 605 | Train Loss: 0.1457710 Vali Loss: 0.3332706 Test Loss: 0.2492727\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "Test cost time: 2.7362s\n",
      "test shape: (150, 32, 6, 1) (150, 32, 6, 1)\n",
      "test shape: (4800, 6, 1) (4800, 6, 1)\n",
      "mse:0.25740060210227966, mae:0.34558525681495667\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1762.6217041015625\n",
      "MAE:  28.597625732421875\n",
      "RMSE: 41.98358917236328\n",
      "MAPE: 0.4253406524658203\n",
      "MSPE: 0.9769390225410461\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24299\n",
      "[DEBUG] Original dataset length: 24299\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19377\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3255\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "\titers: 100, epoch: 1 | loss: 0.3845879\n",
      "\tspeed: 0.0451s/iter; left time: 159.1652s\n",
      "\titers: 200, epoch: 1 | loss: 0.2349953\n",
      "\tspeed: 0.0448s/iter; left time: 153.5559s\n",
      "\titers: 300, epoch: 1 | loss: 0.3060913\n",
      "\tspeed: 0.0449s/iter; left time: 149.4989s\n",
      "\titers: 400, epoch: 1 | loss: 0.2179845\n",
      "\tspeed: 0.0452s/iter; left time: 145.9301s\n",
      "\titers: 500, epoch: 1 | loss: 0.1809912\n",
      "\tspeed: 0.0453s/iter; left time: 141.9873s\n",
      "\titers: 600, epoch: 1 | loss: 0.3051285\n",
      "\tspeed: 0.0449s/iter; left time: 136.0383s\n",
      "Epoch: 1 cost time: 27.259770393371582\n",
      "Epoch: 1, Steps: 605 | Train Loss: 0.2708194 Vali Loss: 0.3416645 Test Loss: 0.2784626\n",
      "Validation loss decreased (inf --> 0.341664).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1410696\n",
      "\tspeed: 0.0970s/iter; left time: 283.9418s\n",
      "\titers: 200, epoch: 2 | loss: 0.3050268\n",
      "\tspeed: 0.0446s/iter; left time: 125.9695s\n",
      "\titers: 300, epoch: 2 | loss: 0.2285542\n",
      "\tspeed: 0.0457s/iter; left time: 124.5160s\n",
      "\titers: 400, epoch: 2 | loss: 0.3973157\n",
      "\tspeed: 0.0470s/iter; left time: 123.3842s\n",
      "\titers: 500, epoch: 2 | loss: 0.2232391\n",
      "\tspeed: 0.0464s/iter; left time: 117.1704s\n",
      "\titers: 600, epoch: 2 | loss: 0.1358194\n",
      "\tspeed: 0.0468s/iter; left time: 113.5471s\n",
      "Epoch: 2 cost time: 27.859485864639282\n",
      "Epoch: 2, Steps: 605 | Train Loss: 0.1940281 Vali Loss: 0.3374898 Test Loss: 0.2670369\n",
      "Validation loss decreased (0.341664 --> 0.337490).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1551415\n",
      "\tspeed: 0.0969s/iter; left time: 224.9493s\n",
      "\titers: 200, epoch: 3 | loss: 0.1222430\n",
      "\tspeed: 0.0438s/iter; left time: 97.3795s\n",
      "\titers: 300, epoch: 3 | loss: 0.1699100\n",
      "\tspeed: 0.0447s/iter; left time: 94.8522s\n",
      "\titers: 400, epoch: 3 | loss: 0.1594872\n",
      "\tspeed: 0.0463s/iter; left time: 93.5939s\n",
      "\titers: 500, epoch: 3 | loss: 0.1668733\n",
      "\tspeed: 0.0450s/iter; left time: 86.3901s\n",
      "\titers: 600, epoch: 3 | loss: 0.2047323\n",
      "\tspeed: 0.0455s/iter; left time: 82.8904s\n",
      "Epoch: 3 cost time: 27.303165435791016\n",
      "Epoch: 3, Steps: 605 | Train Loss: 0.1669052 Vali Loss: 0.3344119 Test Loss: 0.2579402\n",
      "Validation loss decreased (0.337490 --> 0.334412).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1127484\n",
      "\tspeed: 0.0963s/iter; left time: 165.1783s\n",
      "\titers: 200, epoch: 4 | loss: 0.1269177\n",
      "\tspeed: 0.0455s/iter; left time: 73.5199s\n",
      "\titers: 300, epoch: 4 | loss: 0.1590138\n",
      "\tspeed: 0.0451s/iter; left time: 68.4002s\n",
      "\titers: 400, epoch: 4 | loss: 0.1151105\n",
      "\tspeed: 0.0449s/iter; left time: 63.5709s\n",
      "\titers: 500, epoch: 4 | loss: 0.1345040\n",
      "\tspeed: 0.0458s/iter; left time: 60.2672s\n",
      "\titers: 600, epoch: 4 | loss: 0.1037954\n",
      "\tspeed: 0.0451s/iter; left time: 54.8154s\n",
      "Epoch: 4 cost time: 27.410629510879517\n",
      "Epoch: 4, Steps: 605 | Train Loss: 0.1530664 Vali Loss: 0.3496295 Test Loss: 0.2683142\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1259331\n",
      "\tspeed: 0.0940s/iter; left time: 104.4690s\n",
      "\titers: 200, epoch: 5 | loss: 0.1619763\n",
      "\tspeed: 0.0450s/iter; left time: 45.4470s\n",
      "\titers: 300, epoch: 5 | loss: 0.1412233\n",
      "\tspeed: 0.0457s/iter; left time: 41.5972s\n",
      "\titers: 400, epoch: 5 | loss: 0.1177775\n",
      "\tspeed: 0.0447s/iter; left time: 36.2123s\n",
      "\titers: 500, epoch: 5 | loss: 0.1820581\n",
      "\tspeed: 0.0449s/iter; left time: 31.9363s\n",
      "\titers: 600, epoch: 5 | loss: 0.1594034\n",
      "\tspeed: 0.0451s/iter; left time: 27.5680s\n",
      "Epoch: 5 cost time: 27.233579635620117\n",
      "Epoch: 5, Steps: 605 | Train Loss: 0.1453740 Vali Loss: 0.3269091 Test Loss: 0.2504836\n",
      "Validation loss decreased (0.334412 --> 0.326909).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0973285\n",
      "\tspeed: 0.0949s/iter; left time: 48.0047s\n",
      "\titers: 200, epoch: 6 | loss: 0.1024074\n",
      "\tspeed: 0.0448s/iter; left time: 18.2030s\n",
      "\titers: 300, epoch: 6 | loss: 0.1143235\n",
      "\tspeed: 0.0453s/iter; left time: 13.8736s\n",
      "\titers: 400, epoch: 6 | loss: 0.1157825\n",
      "\tspeed: 0.0448s/iter; left time: 9.2334s\n",
      "\titers: 500, epoch: 6 | loss: 0.2217886\n",
      "\tspeed: 0.0445s/iter; left time: 4.7128s\n",
      "\titers: 600, epoch: 6 | loss: 0.1226147\n",
      "\tspeed: 0.0461s/iter; left time: 0.2763s\n",
      "Epoch: 6 cost time: 27.291992664337158\n",
      "Epoch: 6, Steps: 605 | Train Loss: 0.1403414 Vali Loss: 0.3298041 Test Loss: 0.2539586\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "Test cost time: 2.7584s\n",
      "test shape: (150, 32, 6, 1) (150, 32, 6, 1)\n",
      "test shape: (4800, 6, 1) (4800, 6, 1)\n",
      "mse:0.25005200505256653, mae:0.32281696796417236\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1712.300048828125\n",
      "MAE:  26.713520050048828\n",
      "RMSE: 41.379947662353516\n",
      "MAPE: 0.3428734540939331\n",
      "MSPE: 0.5319750905036926\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24299\n",
      "[DEBUG] Original dataset length: 24299\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19377\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3255\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "\titers: 100, epoch: 1 | loss: 0.3383255\n",
      "\tspeed: 0.0446s/iter; left time: 157.6084s\n",
      "\titers: 200, epoch: 1 | loss: 0.3753301\n",
      "\tspeed: 0.0462s/iter; left time: 158.5096s\n",
      "\titers: 300, epoch: 1 | loss: 0.2040434\n",
      "\tspeed: 0.0454s/iter; left time: 151.2684s\n",
      "\titers: 400, epoch: 1 | loss: 0.2604682\n",
      "\tspeed: 0.0453s/iter; left time: 146.2717s\n",
      "\titers: 500, epoch: 1 | loss: 0.4085920\n",
      "\tspeed: 0.0458s/iter; left time: 143.5309s\n",
      "\titers: 600, epoch: 1 | loss: 0.2126736\n",
      "\tspeed: 0.0455s/iter; left time: 138.0395s\n",
      "Epoch: 1 cost time: 27.539767742156982\n",
      "Epoch: 1, Steps: 605 | Train Loss: 0.2826215 Vali Loss: 0.3765716 Test Loss: 0.3153481\n",
      "Validation loss decreased (inf --> 0.376572).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1180116\n",
      "\tspeed: 0.0953s/iter; left time: 278.8036s\n",
      "\titers: 200, epoch: 2 | loss: 0.1763289\n",
      "\tspeed: 0.0455s/iter; left time: 128.6773s\n",
      "\titers: 300, epoch: 2 | loss: 0.1975053\n",
      "\tspeed: 0.0451s/iter; left time: 123.0217s\n",
      "\titers: 400, epoch: 2 | loss: 0.2278317\n",
      "\tspeed: 0.0448s/iter; left time: 117.6142s\n",
      "\titers: 500, epoch: 2 | loss: 0.1724010\n",
      "\tspeed: 0.0465s/iter; left time: 117.3488s\n",
      "\titers: 600, epoch: 2 | loss: 0.1713602\n",
      "\tspeed: 0.0451s/iter; left time: 109.3596s\n",
      "Epoch: 2 cost time: 27.501312255859375\n",
      "Epoch: 2, Steps: 605 | Train Loss: 0.1991847 Vali Loss: 0.3226936 Test Loss: 0.2700602\n",
      "Validation loss decreased (0.376572 --> 0.322694).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1747060\n",
      "\tspeed: 0.0954s/iter; left time: 221.4237s\n",
      "\titers: 200, epoch: 3 | loss: 0.1265258\n",
      "\tspeed: 0.0458s/iter; left time: 101.6190s\n",
      "\titers: 300, epoch: 3 | loss: 0.1977976\n",
      "\tspeed: 0.0457s/iter; left time: 96.8463s\n",
      "\titers: 400, epoch: 3 | loss: 0.0966218\n",
      "\tspeed: 0.0453s/iter; left time: 91.5299s\n",
      "\titers: 500, epoch: 3 | loss: 0.2202561\n",
      "\tspeed: 0.0452s/iter; left time: 86.8737s\n",
      "\titers: 600, epoch: 3 | loss: 0.1930201\n",
      "\tspeed: 0.0455s/iter; left time: 82.7995s\n",
      "Epoch: 3 cost time: 27.52275514602661\n",
      "Epoch: 3, Steps: 605 | Train Loss: 0.1711648 Vali Loss: 0.3254500 Test Loss: 0.2656896\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2097965\n",
      "\tspeed: 0.0952s/iter; left time: 163.2843s\n",
      "\titers: 200, epoch: 4 | loss: 0.2298828\n",
      "\tspeed: 0.0454s/iter; left time: 73.2923s\n",
      "\titers: 300, epoch: 4 | loss: 0.2922571\n",
      "\tspeed: 0.0453s/iter; left time: 68.6470s\n",
      "\titers: 400, epoch: 4 | loss: 0.1438338\n",
      "\tspeed: 0.0454s/iter; left time: 64.3361s\n",
      "\titers: 500, epoch: 4 | loss: 0.1462069\n",
      "\tspeed: 0.0451s/iter; left time: 59.3866s\n",
      "\titers: 600, epoch: 4 | loss: 0.1126169\n",
      "\tspeed: 0.0455s/iter; left time: 55.3145s\n",
      "Epoch: 4 cost time: 27.531158208847046\n",
      "Epoch: 4, Steps: 605 | Train Loss: 0.1568941 Vali Loss: 0.3174646 Test Loss: 0.2685977\n",
      "Validation loss decreased (0.322694 --> 0.317465).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1748972\n",
      "\tspeed: 0.0960s/iter; left time: 106.6754s\n",
      "\titers: 200, epoch: 5 | loss: 0.1176947\n",
      "\tspeed: 0.0454s/iter; left time: 45.8571s\n",
      "\titers: 300, epoch: 5 | loss: 0.1257904\n",
      "\tspeed: 0.0465s/iter; left time: 42.3213s\n",
      "\titers: 400, epoch: 5 | loss: 0.0974078\n",
      "\tspeed: 0.0455s/iter; left time: 36.9056s\n",
      "\titers: 500, epoch: 5 | loss: 0.1469759\n",
      "\tspeed: 0.0454s/iter; left time: 32.2471s\n",
      "\titers: 600, epoch: 5 | loss: 0.1203570\n",
      "\tspeed: 0.0452s/iter; left time: 27.6201s\n",
      "Epoch: 5 cost time: 27.543533325195312\n",
      "Epoch: 5, Steps: 605 | Train Loss: 0.1494165 Vali Loss: 0.3216069 Test Loss: 0.2675297\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1936310\n",
      "\tspeed: 0.0946s/iter; left time: 47.8602s\n",
      "\titers: 200, epoch: 6 | loss: 0.1385280\n",
      "\tspeed: 0.0453s/iter; left time: 18.3875s\n",
      "\titers: 300, epoch: 6 | loss: 0.0964164\n",
      "\tspeed: 0.0455s/iter; left time: 13.9173s\n",
      "\titers: 400, epoch: 6 | loss: 0.1216507\n",
      "\tspeed: 0.0448s/iter; left time: 9.2304s\n",
      "\titers: 500, epoch: 6 | loss: 0.1325035\n",
      "\tspeed: 0.0452s/iter; left time: 4.7952s\n",
      "\titers: 600, epoch: 6 | loss: 0.1275657\n",
      "\tspeed: 0.0453s/iter; left time: 0.2720s\n",
      "Epoch: 6 cost time: 27.379326581954956\n",
      "Epoch: 6, Steps: 605 | Train Loss: 0.1440462 Vali Loss: 0.3212618 Test Loss: 0.2644680\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "Test cost time: 2.7647s\n",
      "test shape: (150, 32, 6, 1) (150, 32, 6, 1)\n",
      "test shape: (4800, 6, 1) (4800, 6, 1)\n",
      "mse:0.26985716819763184, mae:0.3460264205932617\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1847.921142578125\n",
      "MAE:  28.634132385253906\n",
      "RMSE: 42.98745346069336\n",
      "MAPE: 0.35033249855041504\n",
      "MSPE: 0.48819345235824585\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24299\n",
      "[DEBUG] Original dataset length: 24299\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19377\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3255\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "\titers: 100, epoch: 1 | loss: 0.2524586\n",
      "\tspeed: 0.0461s/iter; left time: 162.7392s\n",
      "\titers: 200, epoch: 1 | loss: 0.2321238\n",
      "\tspeed: 0.0460s/iter; left time: 157.9127s\n",
      "\titers: 300, epoch: 1 | loss: 0.2113032\n",
      "\tspeed: 0.0451s/iter; left time: 150.0750s\n",
      "\titers: 400, epoch: 1 | loss: 0.2253240\n",
      "\tspeed: 0.0445s/iter; left time: 143.6532s\n",
      "\titers: 500, epoch: 1 | loss: 0.2695982\n",
      "\tspeed: 0.0453s/iter; left time: 141.9101s\n",
      "\titers: 600, epoch: 1 | loss: 0.2429025\n",
      "\tspeed: 0.0450s/iter; left time: 136.4777s\n",
      "Epoch: 1 cost time: 27.449835538864136\n",
      "Epoch: 1, Steps: 605 | Train Loss: 0.2750817 Vali Loss: 0.3294223 Test Loss: 0.2789281\n",
      "Validation loss decreased (inf --> 0.329422).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2049259\n",
      "\tspeed: 0.0950s/iter; left time: 277.9687s\n",
      "\titers: 200, epoch: 2 | loss: 0.1839683\n",
      "\tspeed: 0.0448s/iter; left time: 126.6765s\n",
      "\titers: 300, epoch: 2 | loss: 0.2754406\n",
      "\tspeed: 0.0445s/iter; left time: 121.2049s\n",
      "\titers: 400, epoch: 2 | loss: 0.1806444\n",
      "\tspeed: 0.0448s/iter; left time: 117.5657s\n",
      "\titers: 500, epoch: 2 | loss: 0.2406071\n",
      "\tspeed: 0.0456s/iter; left time: 115.1918s\n",
      "\titers: 600, epoch: 2 | loss: 0.2735046\n",
      "\tspeed: 0.0443s/iter; left time: 107.4708s\n",
      "Epoch: 2 cost time: 27.193928480148315\n",
      "Epoch: 2, Steps: 605 | Train Loss: 0.1980407 Vali Loss: 0.3281589 Test Loss: 0.2701092\n",
      "Validation loss decreased (0.329422 --> 0.328159).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1963482\n",
      "\tspeed: 0.0944s/iter; left time: 219.0537s\n",
      "\titers: 200, epoch: 3 | loss: 0.1298716\n",
      "\tspeed: 0.0458s/iter; left time: 101.7709s\n",
      "\titers: 300, epoch: 3 | loss: 0.1774404\n",
      "\tspeed: 0.0447s/iter; left time: 94.7594s\n",
      "\titers: 400, epoch: 3 | loss: 0.0989035\n",
      "\tspeed: 0.0441s/iter; left time: 89.1703s\n",
      "\titers: 500, epoch: 3 | loss: 0.1494391\n",
      "\tspeed: 0.0460s/iter; left time: 88.4072s\n",
      "\titers: 600, epoch: 3 | loss: 0.1866919\n",
      "\tspeed: 0.0454s/iter; left time: 82.6729s\n",
      "Epoch: 3 cost time: 27.33031988143921\n",
      "Epoch: 3, Steps: 605 | Train Loss: 0.1697416 Vali Loss: 0.3231154 Test Loss: 0.2556813\n",
      "Validation loss decreased (0.328159 --> 0.323115).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0715048\n",
      "\tspeed: 0.0948s/iter; left time: 162.7170s\n",
      "\titers: 200, epoch: 4 | loss: 0.1437663\n",
      "\tspeed: 0.0453s/iter; left time: 73.1800s\n",
      "\titers: 300, epoch: 4 | loss: 0.1235285\n",
      "\tspeed: 0.0450s/iter; left time: 68.2370s\n",
      "\titers: 400, epoch: 4 | loss: 0.1261751\n",
      "\tspeed: 0.0451s/iter; left time: 63.9180s\n",
      "\titers: 500, epoch: 4 | loss: 0.2103669\n",
      "\tspeed: 0.0452s/iter; left time: 59.5281s\n",
      "\titers: 600, epoch: 4 | loss: 0.1871294\n",
      "\tspeed: 0.0443s/iter; left time: 53.8896s\n",
      "Epoch: 4 cost time: 27.259241819381714\n",
      "Epoch: 4, Steps: 605 | Train Loss: 0.1551382 Vali Loss: 0.3349608 Test Loss: 0.2625583\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1097669\n",
      "\tspeed: 0.0938s/iter; left time: 104.2101s\n",
      "\titers: 200, epoch: 5 | loss: 0.1319301\n",
      "\tspeed: 0.0449s/iter; left time: 45.3845s\n",
      "\titers: 300, epoch: 5 | loss: 0.1581110\n",
      "\tspeed: 0.0446s/iter; left time: 40.6339s\n",
      "\titers: 400, epoch: 5 | loss: 0.1233631\n",
      "\tspeed: 0.0453s/iter; left time: 36.7553s\n",
      "\titers: 500, epoch: 5 | loss: 0.0979262\n",
      "\tspeed: 0.0452s/iter; left time: 32.1266s\n",
      "\titers: 600, epoch: 5 | loss: 0.1780928\n",
      "\tspeed: 0.0450s/iter; left time: 27.4802s\n",
      "Epoch: 5 cost time: 27.29565954208374\n",
      "Epoch: 5, Steps: 605 | Train Loss: 0.1469042 Vali Loss: 0.3309154 Test Loss: 0.2557194\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0835098\n",
      "\tspeed: 0.0928s/iter; left time: 46.9599s\n",
      "\titers: 200, epoch: 6 | loss: 0.1220840\n",
      "\tspeed: 0.0448s/iter; left time: 18.1886s\n",
      "\titers: 300, epoch: 6 | loss: 0.1329109\n",
      "\tspeed: 0.0451s/iter; left time: 13.8036s\n",
      "\titers: 400, epoch: 6 | loss: 0.1204978\n",
      "\tspeed: 0.0457s/iter; left time: 9.4100s\n",
      "\titers: 500, epoch: 6 | loss: 0.1085567\n",
      "\tspeed: 0.0453s/iter; left time: 4.8027s\n",
      "\titers: 600, epoch: 6 | loss: 0.2035782\n",
      "\tspeed: 0.0454s/iter; left time: 0.2721s\n",
      "Epoch: 6 cost time: 27.27722978591919\n",
      "Epoch: 6, Steps: 605 | Train Loss: 0.1420984 Vali Loss: 0.3284882 Test Loss: 0.2569660\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "Test cost time: 2.8982s\n",
      "test shape: (150, 32, 6, 1) (150, 32, 6, 1)\n",
      "test shape: (4800, 6, 1) (4800, 6, 1)\n",
      "mse:0.25461506843566895, mae:0.3217587471008301\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1743.5469970703125\n",
      "MAE:  26.625951766967773\n",
      "RMSE: 41.755802154541016\n",
      "MAPE: 0.34330233931541443\n",
      "MSPE: 0.5413418412208557\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24299\n",
      "[DEBUG] Original dataset length: 24299\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19377\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3255\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "\titers: 100, epoch: 1 | loss: 0.2893296\n",
      "\tspeed: 0.0442s/iter; left time: 156.0109s\n",
      "\titers: 200, epoch: 1 | loss: 0.2795418\n",
      "\tspeed: 0.0447s/iter; left time: 153.5194s\n",
      "\titers: 300, epoch: 1 | loss: 0.1843330\n",
      "\tspeed: 0.0455s/iter; left time: 151.4483s\n",
      "\titers: 400, epoch: 1 | loss: 0.2463661\n",
      "\tspeed: 0.0445s/iter; left time: 143.6641s\n",
      "\titers: 500, epoch: 1 | loss: 0.2157255\n",
      "\tspeed: 0.0448s/iter; left time: 140.1220s\n",
      "\titers: 600, epoch: 1 | loss: 0.2640129\n",
      "\tspeed: 0.0453s/iter; left time: 137.4128s\n",
      "Epoch: 1 cost time: 27.147366762161255\n",
      "Epoch: 1, Steps: 605 | Train Loss: 0.2764628 Vali Loss: 0.3310328 Test Loss: 0.2731429\n",
      "Validation loss decreased (inf --> 0.331033).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1891289\n",
      "\tspeed: 0.0959s/iter; left time: 280.7041s\n",
      "\titers: 200, epoch: 2 | loss: 0.1393946\n",
      "\tspeed: 0.0444s/iter; left time: 125.4894s\n",
      "\titers: 300, epoch: 2 | loss: 0.1221945\n",
      "\tspeed: 0.0458s/iter; left time: 124.9823s\n",
      "\titers: 400, epoch: 2 | loss: 0.2820367\n",
      "\tspeed: 0.0450s/iter; left time: 118.2572s\n",
      "\titers: 500, epoch: 2 | loss: 0.2330725\n",
      "\tspeed: 0.0444s/iter; left time: 112.2153s\n",
      "\titers: 600, epoch: 2 | loss: 0.1271834\n",
      "\tspeed: 0.0460s/iter; left time: 111.5336s\n",
      "Epoch: 2 cost time: 27.28860569000244\n",
      "Epoch: 2, Steps: 605 | Train Loss: 0.1923155 Vali Loss: 0.3229811 Test Loss: 0.2607305\n",
      "Validation loss decreased (0.331033 --> 0.322981).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2312613\n",
      "\tspeed: 0.0944s/iter; left time: 219.1410s\n",
      "\titers: 200, epoch: 3 | loss: 0.2346363\n",
      "\tspeed: 0.0455s/iter; left time: 101.0583s\n",
      "\titers: 300, epoch: 3 | loss: 0.1117663\n",
      "\tspeed: 0.0454s/iter; left time: 96.3145s\n",
      "\titers: 400, epoch: 3 | loss: 0.0964210\n",
      "\tspeed: 0.0449s/iter; left time: 90.6970s\n",
      "\titers: 500, epoch: 3 | loss: 0.1263062\n",
      "\tspeed: 0.0446s/iter; left time: 85.7311s\n",
      "\titers: 600, epoch: 3 | loss: 0.1978659\n",
      "\tspeed: 0.0455s/iter; left time: 82.9427s\n",
      "Epoch: 3 cost time: 27.27264165878296\n",
      "Epoch: 3, Steps: 605 | Train Loss: 0.1673639 Vali Loss: 0.3184876 Test Loss: 0.2473771\n",
      "Validation loss decreased (0.322981 --> 0.318488).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1656242\n",
      "\tspeed: 0.0937s/iter; left time: 160.8231s\n",
      "\titers: 200, epoch: 4 | loss: 0.1075492\n",
      "\tspeed: 0.0448s/iter; left time: 72.3310s\n",
      "\titers: 300, epoch: 4 | loss: 0.1335539\n",
      "\tspeed: 0.0455s/iter; left time: 68.9415s\n",
      "\titers: 400, epoch: 4 | loss: 0.1572973\n",
      "\tspeed: 0.0445s/iter; left time: 62.9455s\n",
      "\titers: 500, epoch: 4 | loss: 0.1301105\n",
      "\tspeed: 0.0453s/iter; left time: 59.6352s\n",
      "\titers: 600, epoch: 4 | loss: 0.3017600\n",
      "\tspeed: 0.0456s/iter; left time: 55.4834s\n",
      "Epoch: 4 cost time: 27.230005025863647\n",
      "Epoch: 4, Steps: 605 | Train Loss: 0.1530762 Vali Loss: 0.3093312 Test Loss: 0.2512638\n",
      "Validation loss decreased (0.318488 --> 0.309331).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2052740\n",
      "\tspeed: 0.0943s/iter; left time: 104.8030s\n",
      "\titers: 200, epoch: 5 | loss: 0.1250549\n",
      "\tspeed: 0.0458s/iter; left time: 46.3424s\n",
      "\titers: 300, epoch: 5 | loss: 0.2187440\n",
      "\tspeed: 0.0453s/iter; left time: 41.3072s\n",
      "\titers: 400, epoch: 5 | loss: 0.2073985\n",
      "\tspeed: 0.0454s/iter; left time: 36.7894s\n",
      "\titers: 500, epoch: 5 | loss: 0.2480398\n",
      "\tspeed: 0.0480s/iter; left time: 34.1467s\n",
      "\titers: 600, epoch: 5 | loss: 0.1897676\n",
      "\tspeed: 0.0458s/iter; left time: 27.9945s\n",
      "Epoch: 5 cost time: 27.749210357666016\n",
      "Epoch: 5, Steps: 605 | Train Loss: 0.1447793 Vali Loss: 0.3182001 Test Loss: 0.2547049\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1335582\n",
      "\tspeed: 0.0942s/iter; left time: 47.6779s\n",
      "\titers: 200, epoch: 6 | loss: 0.1262666\n",
      "\tspeed: 0.0461s/iter; left time: 18.7235s\n",
      "\titers: 300, epoch: 6 | loss: 0.1086114\n",
      "\tspeed: 0.0447s/iter; left time: 13.6787s\n",
      "\titers: 400, epoch: 6 | loss: 0.0935013\n",
      "\tspeed: 0.0453s/iter; left time: 9.3253s\n",
      "\titers: 500, epoch: 6 | loss: 0.1508603\n",
      "\tspeed: 0.0450s/iter; left time: 4.7722s\n",
      "\titers: 600, epoch: 6 | loss: 0.1085182\n",
      "\tspeed: 0.0445s/iter; left time: 0.2669s\n",
      "Epoch: 6 cost time: 27.30798029899597\n",
      "Epoch: 6, Steps: 605 | Train Loss: 0.1391254 Vali Loss: 0.3258884 Test Loss: 0.2570670\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "Test cost time: 2.6571s\n",
      "test shape: (150, 32, 6, 1) (150, 32, 6, 1)\n",
      "test shape: (4800, 6, 1) (4800, 6, 1)\n",
      "mse:0.2499544769525528, mae:0.3219849169254303\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1711.6319580078125\n",
      "MAE:  26.64466667175293\n",
      "RMSE: 41.37187576293945\n",
      "MAPE: 0.33616167306900024\n",
      "MSPE: 0.4974191188812256\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24299\n",
      "[DEBUG] Original dataset length: 24299\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19377\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3255\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "\titers: 100, epoch: 1 | loss: 0.3526778\n",
      "\tspeed: 0.0451s/iter; left time: 159.2603s\n",
      "\titers: 200, epoch: 1 | loss: 0.3649695\n",
      "\tspeed: 0.0454s/iter; left time: 155.6670s\n",
      "\titers: 300, epoch: 1 | loss: 0.2235704\n",
      "\tspeed: 0.0455s/iter; left time: 151.4926s\n",
      "\titers: 400, epoch: 1 | loss: 0.2800680\n",
      "\tspeed: 0.0465s/iter; left time: 150.2745s\n",
      "\titers: 500, epoch: 1 | loss: 0.2079461\n",
      "\tspeed: 0.0445s/iter; left time: 139.3114s\n",
      "\titers: 600, epoch: 1 | loss: 0.1799051\n",
      "\tspeed: 0.0454s/iter; left time: 137.4897s\n",
      "Epoch: 1 cost time: 27.480598211288452\n",
      "Epoch: 1, Steps: 605 | Train Loss: 0.2882375 Vali Loss: 0.3370455 Test Loss: 0.2944346\n",
      "Validation loss decreased (inf --> 0.337045).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1882566\n",
      "\tspeed: 0.0957s/iter; left time: 279.9391s\n",
      "\titers: 200, epoch: 2 | loss: 0.1807727\n",
      "\tspeed: 0.0454s/iter; left time: 128.4190s\n",
      "\titers: 300, epoch: 2 | loss: 0.1559089\n",
      "\tspeed: 0.0460s/iter; left time: 125.4772s\n",
      "\titers: 400, epoch: 2 | loss: 0.1354786\n",
      "\tspeed: 0.0451s/iter; left time: 118.4239s\n",
      "\titers: 500, epoch: 2 | loss: 0.1417190\n",
      "\tspeed: 0.0450s/iter; left time: 113.6212s\n",
      "\titers: 600, epoch: 2 | loss: 0.1008510\n",
      "\tspeed: 0.0454s/iter; left time: 110.2585s\n",
      "Epoch: 2 cost time: 27.50469732284546\n",
      "Epoch: 2, Steps: 605 | Train Loss: 0.1961357 Vali Loss: 0.3335454 Test Loss: 0.2677340\n",
      "Validation loss decreased (0.337045 --> 0.333545).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0926799\n",
      "\tspeed: 0.0953s/iter; left time: 221.2744s\n",
      "\titers: 200, epoch: 3 | loss: 0.1145839\n",
      "\tspeed: 0.0453s/iter; left time: 100.6343s\n",
      "\titers: 300, epoch: 3 | loss: 0.2861308\n",
      "\tspeed: 0.0450s/iter; left time: 95.4861s\n",
      "\titers: 400, epoch: 3 | loss: 0.1630567\n",
      "\tspeed: 0.0449s/iter; left time: 90.7831s\n",
      "\titers: 500, epoch: 3 | loss: 0.1155804\n",
      "\tspeed: 0.0447s/iter; left time: 85.8300s\n",
      "\titers: 600, epoch: 3 | loss: 0.2146022\n",
      "\tspeed: 0.0448s/iter; left time: 81.6670s\n",
      "Epoch: 3 cost time: 27.209857940673828\n",
      "Epoch: 3, Steps: 605 | Train Loss: 0.1663221 Vali Loss: 0.3185535 Test Loss: 0.2577396\n",
      "Validation loss decreased (0.333545 --> 0.318554).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1241129\n",
      "\tspeed: 0.0953s/iter; left time: 163.5188s\n",
      "\titers: 200, epoch: 4 | loss: 0.1488439\n",
      "\tspeed: 0.0453s/iter; left time: 73.2315s\n",
      "\titers: 300, epoch: 4 | loss: 0.1689079\n",
      "\tspeed: 0.0452s/iter; left time: 68.5418s\n",
      "\titers: 400, epoch: 4 | loss: 0.1549513\n",
      "\tspeed: 0.0446s/iter; left time: 63.2116s\n",
      "\titers: 500, epoch: 4 | loss: 0.1672726\n",
      "\tspeed: 0.0448s/iter; left time: 58.9897s\n",
      "\titers: 600, epoch: 4 | loss: 0.1725010\n",
      "\tspeed: 0.0448s/iter; left time: 54.5360s\n",
      "Epoch: 4 cost time: 27.226154565811157\n",
      "Epoch: 4, Steps: 605 | Train Loss: 0.1534790 Vali Loss: 0.3191174 Test Loss: 0.2490041\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1467252\n",
      "\tspeed: 0.0937s/iter; left time: 104.0466s\n",
      "\titers: 200, epoch: 5 | loss: 0.1787222\n",
      "\tspeed: 0.0453s/iter; left time: 45.7846s\n",
      "\titers: 300, epoch: 5 | loss: 0.1244202\n",
      "\tspeed: 0.0455s/iter; left time: 41.4229s\n",
      "\titers: 400, epoch: 5 | loss: 0.1162108\n",
      "\tspeed: 0.0444s/iter; left time: 36.0264s\n",
      "\titers: 500, epoch: 5 | loss: 0.1081113\n",
      "\tspeed: 0.0444s/iter; left time: 31.5913s\n",
      "\titers: 600, epoch: 5 | loss: 0.1337187\n",
      "\tspeed: 0.0467s/iter; left time: 28.5481s\n",
      "Epoch: 5 cost time: 27.393564701080322\n",
      "Epoch: 5, Steps: 605 | Train Loss: 0.1452046 Vali Loss: 0.3258006 Test Loss: 0.2540103\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2358718\n",
      "\tspeed: 0.0935s/iter; left time: 47.3020s\n",
      "\titers: 200, epoch: 6 | loss: 0.1373126\n",
      "\tspeed: 0.0451s/iter; left time: 18.3178s\n",
      "\titers: 300, epoch: 6 | loss: 0.1305677\n",
      "\tspeed: 0.0450s/iter; left time: 13.7843s\n",
      "\titers: 400, epoch: 6 | loss: 0.2796135\n",
      "\tspeed: 0.0446s/iter; left time: 9.1837s\n",
      "\titers: 500, epoch: 6 | loss: 0.1584738\n",
      "\tspeed: 0.0445s/iter; left time: 4.7160s\n",
      "\titers: 600, epoch: 6 | loss: 0.1110494\n",
      "\tspeed: 0.0455s/iter; left time: 0.2730s\n",
      "Epoch: 6 cost time: 27.20852541923523\n",
      "Epoch: 6, Steps: 605 | Train Loss: 0.1411290 Vali Loss: 0.3290641 Test Loss: 0.2529857\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "Test cost time: 2.7341s\n",
      "test shape: (150, 32, 6, 1) (150, 32, 6, 1)\n",
      "test shape: (4800, 6, 1) (4800, 6, 1)\n",
      "mse:0.2589043080806732, mae:0.33648204803466797\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1772.9183349609375\n",
      "MAE:  27.844322204589844\n",
      "RMSE: 42.10603713989258\n",
      "MAPE: 0.3970957398414612\n",
      "MSPE: 0.7859569191932678\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24299\n",
      "[DEBUG] Original dataset length: 24299\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19377\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3255\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "\titers: 100, epoch: 1 | loss: 0.3352110\n",
      "\tspeed: 0.0463s/iter; left time: 163.6540s\n",
      "\titers: 200, epoch: 1 | loss: 0.2302520\n",
      "\tspeed: 0.0448s/iter; left time: 153.8578s\n",
      "\titers: 300, epoch: 1 | loss: 0.2613030\n",
      "\tspeed: 0.0447s/iter; left time: 149.0243s\n",
      "\titers: 400, epoch: 1 | loss: 0.3102440\n",
      "\tspeed: 0.0443s/iter; left time: 143.0174s\n",
      "\titers: 500, epoch: 1 | loss: 0.2897158\n",
      "\tspeed: 0.0466s/iter; left time: 145.9141s\n",
      "\titers: 600, epoch: 1 | loss: 0.2651628\n",
      "\tspeed: 0.0453s/iter; left time: 137.1846s\n",
      "Epoch: 1 cost time: 27.455227613449097\n",
      "Epoch: 1, Steps: 605 | Train Loss: 0.2991514 Vali Loss: 0.3307997 Test Loss: 0.2662659\n",
      "Validation loss decreased (inf --> 0.330800).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1691494\n",
      "\tspeed: 0.0947s/iter; left time: 277.1685s\n",
      "\titers: 200, epoch: 2 | loss: 0.1380339\n",
      "\tspeed: 0.0443s/iter; left time: 125.2519s\n",
      "\titers: 300, epoch: 2 | loss: 0.2496153\n",
      "\tspeed: 0.0443s/iter; left time: 120.8768s\n",
      "\titers: 400, epoch: 2 | loss: 0.2829601\n",
      "\tspeed: 0.0446s/iter; left time: 117.0208s\n",
      "\titers: 500, epoch: 2 | loss: 0.1495031\n",
      "\tspeed: 0.0460s/iter; left time: 116.2267s\n",
      "\titers: 600, epoch: 2 | loss: 0.2282383\n",
      "\tspeed: 0.0451s/iter; left time: 109.4593s\n",
      "Epoch: 2 cost time: 27.214818239212036\n",
      "Epoch: 2, Steps: 605 | Train Loss: 0.1983571 Vali Loss: 0.3339989 Test Loss: 0.2701737\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2051028\n",
      "\tspeed: 0.0944s/iter; left time: 219.1710s\n",
      "\titers: 200, epoch: 3 | loss: 0.1960232\n",
      "\tspeed: 0.0444s/iter; left time: 98.5958s\n",
      "\titers: 300, epoch: 3 | loss: 0.2050721\n",
      "\tspeed: 0.0445s/iter; left time: 94.2906s\n",
      "\titers: 400, epoch: 3 | loss: 0.1511521\n",
      "\tspeed: 0.0455s/iter; left time: 92.0132s\n",
      "\titers: 500, epoch: 3 | loss: 0.1740494\n",
      "\tspeed: 0.0456s/iter; left time: 87.6474s\n",
      "\titers: 600, epoch: 3 | loss: 0.1250066\n",
      "\tspeed: 0.0452s/iter; left time: 82.3314s\n",
      "Epoch: 3 cost time: 27.35360074043274\n",
      "Epoch: 3, Steps: 605 | Train Loss: 0.1678025 Vali Loss: 0.3219097 Test Loss: 0.2581487\n",
      "Validation loss decreased (0.330800 --> 0.321910).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0882398\n",
      "\tspeed: 0.0959s/iter; left time: 164.6003s\n",
      "\titers: 200, epoch: 4 | loss: 0.1399671\n",
      "\tspeed: 0.0446s/iter; left time: 72.0908s\n",
      "\titers: 300, epoch: 4 | loss: 0.1197699\n",
      "\tspeed: 0.0444s/iter; left time: 67.3020s\n",
      "\titers: 400, epoch: 4 | loss: 0.2254175\n",
      "\tspeed: 0.0459s/iter; left time: 64.9895s\n",
      "\titers: 500, epoch: 4 | loss: 0.1997654\n",
      "\tspeed: 0.0452s/iter; left time: 59.4847s\n",
      "\titers: 600, epoch: 4 | loss: 0.1798957\n",
      "\tspeed: 0.0446s/iter; left time: 54.2727s\n",
      "Epoch: 4 cost time: 27.234737634658813\n",
      "Epoch: 4, Steps: 605 | Train Loss: 0.1536028 Vali Loss: 0.3268804 Test Loss: 0.2489832\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1484982\n",
      "\tspeed: 0.0944s/iter; left time: 104.8905s\n",
      "\titers: 200, epoch: 5 | loss: 0.1381795\n",
      "\tspeed: 0.0444s/iter; left time: 44.8808s\n",
      "\titers: 300, epoch: 5 | loss: 0.0966402\n",
      "\tspeed: 0.0445s/iter; left time: 40.4961s\n",
      "\titers: 400, epoch: 5 | loss: 0.1652716\n",
      "\tspeed: 0.0454s/iter; left time: 36.8436s\n",
      "\titers: 500, epoch: 5 | loss: 0.1801379\n",
      "\tspeed: 0.0456s/iter; left time: 32.4496s\n",
      "\titers: 600, epoch: 5 | loss: 0.1592477\n",
      "\tspeed: 0.0453s/iter; left time: 27.7012s\n",
      "Epoch: 5 cost time: 27.23875093460083\n",
      "Epoch: 5, Steps: 605 | Train Loss: 0.1440454 Vali Loss: 0.3319702 Test Loss: 0.2532677\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1055245\n",
      "\tspeed: 0.0947s/iter; left time: 47.9229s\n",
      "\titers: 200, epoch: 6 | loss: 0.2452242\n",
      "\tspeed: 0.0451s/iter; left time: 18.3199s\n",
      "\titers: 300, epoch: 6 | loss: 0.1013545\n",
      "\tspeed: 0.0458s/iter; left time: 14.0104s\n",
      "\titers: 400, epoch: 6 | loss: 0.1107864\n",
      "\tspeed: 0.0451s/iter; left time: 9.2993s\n",
      "\titers: 500, epoch: 6 | loss: 0.1687116\n",
      "\tspeed: 0.0443s/iter; left time: 4.6977s\n",
      "\titers: 600, epoch: 6 | loss: 0.1395633\n",
      "\tspeed: 0.0450s/iter; left time: 0.2702s\n",
      "Epoch: 6 cost time: 27.266362190246582\n",
      "Epoch: 6, Steps: 605 | Train Loss: 0.1393348 Vali Loss: 0.3322251 Test Loss: 0.2528682\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "Test cost time: 2.7310s\n",
      "test shape: (150, 32, 6, 1) (150, 32, 6, 1)\n",
      "test shape: (4800, 6, 1) (4800, 6, 1)\n",
      "mse:0.2555217742919922, mae:0.3512125313282013\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1749.755615234375\n",
      "MAE:  29.06328773498535\n",
      "RMSE: 41.830081939697266\n",
      "MAPE: 0.46158909797668457\n",
      "MSPE: 1.0409454107284546\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24299\n",
      "[DEBUG] Original dataset length: 24299\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19377\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3255\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "\titers: 100, epoch: 1 | loss: 0.2444936\n",
      "\tspeed: 0.0445s/iter; left time: 157.1529s\n",
      "\titers: 200, epoch: 1 | loss: 0.2886802\n",
      "\tspeed: 0.0453s/iter; left time: 155.4898s\n",
      "\titers: 300, epoch: 1 | loss: 0.1967928\n",
      "\tspeed: 0.0458s/iter; left time: 152.4098s\n",
      "\titers: 400, epoch: 1 | loss: 0.2048725\n",
      "\tspeed: 0.0446s/iter; left time: 144.0995s\n",
      "\titers: 500, epoch: 1 | loss: 0.2156819\n",
      "\tspeed: 0.0445s/iter; left time: 139.3247s\n",
      "\titers: 600, epoch: 1 | loss: 0.2485496\n",
      "\tspeed: 0.0454s/iter; left time: 137.6087s\n",
      "Epoch: 1 cost time: 27.26579713821411\n",
      "Epoch: 1, Steps: 605 | Train Loss: 0.2895597 Vali Loss: 0.3260750 Test Loss: 0.2666872\n",
      "Validation loss decreased (inf --> 0.326075).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2093935\n",
      "\tspeed: 0.0939s/iter; left time: 274.7414s\n",
      "\titers: 200, epoch: 2 | loss: 0.1343881\n",
      "\tspeed: 0.0454s/iter; left time: 128.3605s\n",
      "\titers: 300, epoch: 2 | loss: 0.2341161\n",
      "\tspeed: 0.0449s/iter; left time: 122.4410s\n",
      "\titers: 400, epoch: 2 | loss: 0.1380127\n",
      "\tspeed: 0.0450s/iter; left time: 118.2604s\n",
      "\titers: 500, epoch: 2 | loss: 0.1793060\n",
      "\tspeed: 0.0441s/iter; left time: 111.4984s\n",
      "\titers: 600, epoch: 2 | loss: 0.2336235\n",
      "\tspeed: 0.0449s/iter; left time: 109.0357s\n",
      "Epoch: 2 cost time: 27.165679931640625\n",
      "Epoch: 2, Steps: 605 | Train Loss: 0.1990543 Vali Loss: 0.3530603 Test Loss: 0.2855779\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2427450\n",
      "\tspeed: 0.0932s/iter; left time: 216.3186s\n",
      "\titers: 200, epoch: 3 | loss: 0.1584239\n",
      "\tspeed: 0.0461s/iter; left time: 102.3639s\n",
      "\titers: 300, epoch: 3 | loss: 0.1769095\n",
      "\tspeed: 0.0444s/iter; left time: 94.2239s\n",
      "\titers: 400, epoch: 3 | loss: 0.1607113\n",
      "\tspeed: 0.0446s/iter; left time: 90.0890s\n",
      "\titers: 500, epoch: 3 | loss: 0.1795007\n",
      "\tspeed: 0.0451s/iter; left time: 86.5468s\n",
      "\titers: 600, epoch: 3 | loss: 0.2487166\n",
      "\tspeed: 0.0448s/iter; left time: 81.6128s\n",
      "Epoch: 3 cost time: 27.222835063934326\n",
      "Epoch: 3, Steps: 605 | Train Loss: 0.1690354 Vali Loss: 0.3260676 Test Loss: 0.2626340\n",
      "Validation loss decreased (0.326075 --> 0.326068).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1430045\n",
      "\tspeed: 0.0946s/iter; left time: 162.2634s\n",
      "\titers: 200, epoch: 4 | loss: 0.1326330\n",
      "\tspeed: 0.0455s/iter; left time: 73.5046s\n",
      "\titers: 300, epoch: 4 | loss: 0.1851278\n",
      "\tspeed: 0.0448s/iter; left time: 67.8514s\n",
      "\titers: 400, epoch: 4 | loss: 0.1940961\n",
      "\tspeed: 0.0448s/iter; left time: 63.4695s\n",
      "\titers: 500, epoch: 4 | loss: 0.1343934\n",
      "\tspeed: 0.0456s/iter; left time: 60.0456s\n",
      "\titers: 600, epoch: 4 | loss: 0.1769715\n",
      "\tspeed: 0.0445s/iter; left time: 54.1147s\n",
      "Epoch: 4 cost time: 27.211086988449097\n",
      "Epoch: 4, Steps: 605 | Train Loss: 0.1559010 Vali Loss: 0.3408225 Test Loss: 0.2702345\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1349442\n",
      "\tspeed: 0.0939s/iter; left time: 104.2830s\n",
      "\titers: 200, epoch: 5 | loss: 0.2137940\n",
      "\tspeed: 0.0444s/iter; left time: 44.9217s\n",
      "\titers: 300, epoch: 5 | loss: 0.1061476\n",
      "\tspeed: 0.0447s/iter; left time: 40.7053s\n",
      "\titers: 400, epoch: 5 | loss: 0.1650436\n",
      "\tspeed: 0.0446s/iter; left time: 36.2023s\n",
      "\titers: 500, epoch: 5 | loss: 0.1374962\n",
      "\tspeed: 0.0458s/iter; left time: 32.5931s\n",
      "\titers: 600, epoch: 5 | loss: 0.1621935\n",
      "\tspeed: 0.0448s/iter; left time: 27.4012s\n",
      "Epoch: 5 cost time: 27.221896171569824\n",
      "Epoch: 5, Steps: 605 | Train Loss: 0.1471475 Vali Loss: 0.3328327 Test Loss: 0.2653012\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1850522\n",
      "\tspeed: 0.0937s/iter; left time: 47.3928s\n",
      "\titers: 200, epoch: 6 | loss: 0.1804969\n",
      "\tspeed: 0.0450s/iter; left time: 18.2670s\n",
      "\titers: 300, epoch: 6 | loss: 0.1209239\n",
      "\tspeed: 0.0448s/iter; left time: 13.6937s\n",
      "\titers: 400, epoch: 6 | loss: 0.0895312\n",
      "\tspeed: 0.0454s/iter; left time: 9.3482s\n",
      "\titers: 500, epoch: 6 | loss: 0.1107160\n",
      "\tspeed: 0.0450s/iter; left time: 4.7692s\n",
      "\titers: 600, epoch: 6 | loss: 0.2105376\n",
      "\tspeed: 0.0448s/iter; left time: 0.2690s\n",
      "Epoch: 6 cost time: 27.247360229492188\n",
      "Epoch: 6, Steps: 605 | Train Loss: 0.1420818 Vali Loss: 0.3310109 Test Loss: 0.2633401\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "Test cost time: 2.6218s\n",
      "test shape: (150, 32, 6, 1) (150, 32, 6, 1)\n",
      "test shape: (4800, 6, 1) (4800, 6, 1)\n",
      "mse:0.2621626555919647, mae:0.3361375033855438\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1795.2308349609375\n",
      "MAE:  27.815811157226562\n",
      "RMSE: 42.37016296386719\n",
      "MAPE: 0.40183261036872864\n",
      "MSPE: 0.8284310698509216\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24299\n",
      "[DEBUG] Original dataset length: 24299\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19377\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3255\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "\titers: 100, epoch: 1 | loss: 0.2743800\n",
      "\tspeed: 0.0437s/iter; left time: 154.1630s\n",
      "\titers: 200, epoch: 1 | loss: 0.1424820\n",
      "\tspeed: 0.0446s/iter; left time: 153.0692s\n",
      "\titers: 300, epoch: 1 | loss: 0.3647891\n",
      "\tspeed: 0.0462s/iter; left time: 153.7462s\n",
      "\titers: 400, epoch: 1 | loss: 0.1929086\n",
      "\tspeed: 0.0454s/iter; left time: 146.6878s\n",
      "\titers: 500, epoch: 1 | loss: 0.2667931\n",
      "\tspeed: 0.0454s/iter; left time: 142.1500s\n",
      "\titers: 600, epoch: 1 | loss: 0.1770555\n",
      "\tspeed: 0.0452s/iter; left time: 137.0530s\n",
      "Epoch: 1 cost time: 27.297075271606445\n",
      "Epoch: 1, Steps: 605 | Train Loss: 0.2925249 Vali Loss: 0.3253384 Test Loss: 0.2848671\n",
      "Validation loss decreased (inf --> 0.325338).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1512059\n",
      "\tspeed: 0.0961s/iter; left time: 281.1647s\n",
      "\titers: 200, epoch: 2 | loss: 0.1910280\n",
      "\tspeed: 0.0452s/iter; left time: 127.6575s\n",
      "\titers: 300, epoch: 2 | loss: 0.1979732\n",
      "\tspeed: 0.0452s/iter; left time: 123.2893s\n",
      "\titers: 400, epoch: 2 | loss: 0.1402903\n",
      "\tspeed: 0.0444s/iter; left time: 116.6661s\n",
      "\titers: 500, epoch: 2 | loss: 0.1396793\n",
      "\tspeed: 0.0448s/iter; left time: 113.0667s\n",
      "\titers: 600, epoch: 2 | loss: 0.1562613\n",
      "\tspeed: 0.0451s/iter; left time: 109.4571s\n",
      "Epoch: 2 cost time: 27.205952167510986\n",
      "Epoch: 2, Steps: 605 | Train Loss: 0.1986309 Vali Loss: 0.3085596 Test Loss: 0.2527148\n",
      "Validation loss decreased (0.325338 --> 0.308560).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1926406\n",
      "\tspeed: 0.0938s/iter; left time: 217.7121s\n",
      "\titers: 200, epoch: 3 | loss: 0.3027870\n",
      "\tspeed: 0.0451s/iter; left time: 100.2403s\n",
      "\titers: 300, epoch: 3 | loss: 0.1193113\n",
      "\tspeed: 0.0453s/iter; left time: 96.1347s\n",
      "\titers: 400, epoch: 3 | loss: 0.1410815\n",
      "\tspeed: 0.0449s/iter; left time: 90.7930s\n",
      "\titers: 500, epoch: 3 | loss: 0.2473280\n",
      "\tspeed: 0.0457s/iter; left time: 87.7805s\n",
      "\titers: 600, epoch: 3 | loss: 0.1431266\n",
      "\tspeed: 0.0461s/iter; left time: 83.9027s\n",
      "Epoch: 3 cost time: 27.414229154586792\n",
      "Epoch: 3, Steps: 605 | Train Loss: 0.1673268 Vali Loss: 0.3275316 Test Loss: 0.2615989\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1633880\n",
      "\tspeed: 0.0933s/iter; left time: 160.0945s\n",
      "\titers: 200, epoch: 4 | loss: 0.2627428\n",
      "\tspeed: 0.0457s/iter; left time: 73.7884s\n",
      "\titers: 300, epoch: 4 | loss: 0.1545046\n",
      "\tspeed: 0.0449s/iter; left time: 68.0840s\n",
      "\titers: 400, epoch: 4 | loss: 0.2204980\n",
      "\tspeed: 0.0452s/iter; left time: 64.0253s\n",
      "\titers: 500, epoch: 4 | loss: 0.1433716\n",
      "\tspeed: 0.0456s/iter; left time: 59.9549s\n",
      "\titers: 600, epoch: 4 | loss: 0.1525218\n",
      "\tspeed: 0.0461s/iter; left time: 56.0313s\n",
      "Epoch: 4 cost time: 27.460906982421875\n",
      "Epoch: 4, Steps: 605 | Train Loss: 0.1543064 Vali Loss: 0.3150260 Test Loss: 0.2576281\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1602184\n",
      "\tspeed: 0.0935s/iter; left time: 103.9130s\n",
      "\titers: 200, epoch: 5 | loss: 0.1344819\n",
      "\tspeed: 0.0456s/iter; left time: 46.1102s\n",
      "\titers: 300, epoch: 5 | loss: 0.1537964\n",
      "\tspeed: 0.0460s/iter; left time: 41.8677s\n",
      "\titers: 400, epoch: 5 | loss: 0.1059979\n",
      "\tspeed: 0.0449s/iter; left time: 36.3907s\n",
      "\titers: 500, epoch: 5 | loss: 0.1824389\n",
      "\tspeed: 0.0460s/iter; left time: 32.7287s\n",
      "\titers: 600, epoch: 5 | loss: 0.1348102\n",
      "\tspeed: 0.0451s/iter; left time: 27.5361s\n",
      "Epoch: 5 cost time: 27.458375453948975\n",
      "Epoch: 5, Steps: 605 | Train Loss: 0.1468033 Vali Loss: 0.3118684 Test Loss: 0.2587134\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "Test cost time: 2.6705s\n",
      "test shape: (150, 32, 6, 1) (150, 32, 6, 1)\n",
      "test shape: (4800, 6, 1) (4800, 6, 1)\n",
      "mse:0.2535964548587799, mae:0.332745224237442\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl240_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1736.5716552734375\n",
      "MAE:  27.53509521484375\n",
      "RMSE: 41.67219161987305\n",
      "MAPE: 0.3717930018901825\n",
      "MSPE: 0.7125029563903809\n",
      ">>>>>>>Running time saved<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Running seq_len=264\n",
      "Args in experiment:\n",
      "Namespace(model='informer', data='traffic_full', root_path='../', data_path='traffic_full.csv', features='S', target='flow', freq='h', checkpoints='./checkpoints/', seq_len=264, label_len=24, pred_len=6, enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=2, d_layers=1, s_layers=[3, 2, 1], d_ff=2048, factor=5, padding=0, distil=True, dropout=0.05, attn='prob', embed='timeF', activation='gelu', output_attention=False, do_predict=False, mix=True, cols=None, num_workers=0, itr=10, train_epochs=6, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, inverse=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', detail_freq='h')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl264_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24275\n",
      "[DEBUG] Original dataset length: 24275\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18969\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3231\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4658\n",
      "\titers: 100, epoch: 1 | loss: 0.4306395\n",
      "\tspeed: 0.0609s/iter; left time: 210.1296s\n",
      "\titers: 200, epoch: 1 | loss: 0.4636232\n",
      "\tspeed: 0.0482s/iter; left time: 161.5904s\n",
      "\titers: 300, epoch: 1 | loss: 0.2210943\n",
      "\tspeed: 0.0484s/iter; left time: 157.4097s\n",
      "\titers: 400, epoch: 1 | loss: 0.1962540\n",
      "\tspeed: 0.0478s/iter; left time: 150.7725s\n",
      "\titers: 500, epoch: 1 | loss: 0.1783828\n",
      "\tspeed: 0.0477s/iter; left time: 145.5300s\n",
      "Epoch: 1 cost time: 29.133559226989746\n",
      "Epoch: 1, Steps: 592 | Train Loss: 0.3062283 Vali Loss: 0.4390837 Test Loss: 0.3591432\n",
      "Validation loss decreased (inf --> 0.439084).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1169467\n",
      "\tspeed: 0.1445s/iter; left time: 413.4559s\n",
      "\titers: 200, epoch: 2 | loss: 0.1278029\n",
      "\tspeed: 0.0484s/iter; left time: 133.6702s\n",
      "\titers: 300, epoch: 2 | loss: 0.1556418\n",
      "\tspeed: 0.0478s/iter; left time: 127.2757s\n",
      "\titers: 400, epoch: 2 | loss: 0.1647757\n",
      "\tspeed: 0.0477s/iter; left time: 122.0400s\n",
      "\titers: 500, epoch: 2 | loss: 0.2149354\n",
      "\tspeed: 0.0483s/iter; left time: 118.8320s\n",
      "Epoch: 2 cost time: 28.52811598777771\n",
      "Epoch: 2, Steps: 592 | Train Loss: 0.2030981 Vali Loss: 0.3488366 Test Loss: 0.2901009\n",
      "Validation loss decreased (0.439084 --> 0.348837).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1143168\n",
      "\tspeed: 0.1452s/iter; left time: 329.4509s\n",
      "\titers: 200, epoch: 3 | loss: 0.1397138\n",
      "\tspeed: 0.0486s/iter; left time: 105.3629s\n",
      "\titers: 300, epoch: 3 | loss: 0.1509393\n",
      "\tspeed: 0.0478s/iter; left time: 98.8304s\n",
      "\titers: 400, epoch: 3 | loss: 0.2028084\n",
      "\tspeed: 0.0481s/iter; left time: 94.7584s\n",
      "\titers: 500, epoch: 3 | loss: 0.1768380\n",
      "\tspeed: 0.0483s/iter; left time: 90.3408s\n",
      "Epoch: 3 cost time: 28.58752417564392\n",
      "Epoch: 3, Steps: 592 | Train Loss: 0.1724957 Vali Loss: 0.3244339 Test Loss: 0.2709692\n",
      "Validation loss decreased (0.348837 --> 0.324434).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1344430\n",
      "\tspeed: 0.1432s/iter; left time: 240.1799s\n",
      "\titers: 200, epoch: 4 | loss: 0.0958128\n",
      "\tspeed: 0.0477s/iter; left time: 75.2085s\n",
      "\titers: 300, epoch: 4 | loss: 0.1067410\n",
      "\tspeed: 0.0480s/iter; left time: 70.8606s\n",
      "\titers: 400, epoch: 4 | loss: 0.0968442\n",
      "\tspeed: 0.0481s/iter; left time: 66.2165s\n",
      "\titers: 500, epoch: 4 | loss: 0.2000872\n",
      "\tspeed: 0.0481s/iter; left time: 61.3613s\n",
      "Epoch: 4 cost time: 28.385226726531982\n",
      "Epoch: 4, Steps: 592 | Train Loss: 0.1564530 Vali Loss: 0.3406805 Test Loss: 0.2663288\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1131562\n",
      "\tspeed: 0.1430s/iter; left time: 155.2003s\n",
      "\titers: 200, epoch: 5 | loss: 0.1340250\n",
      "\tspeed: 0.0476s/iter; left time: 46.8874s\n",
      "\titers: 300, epoch: 5 | loss: 0.1407220\n",
      "\tspeed: 0.0475s/iter; left time: 41.9976s\n",
      "\titers: 400, epoch: 5 | loss: 0.1576377\n",
      "\tspeed: 0.0495s/iter; left time: 38.8800s\n",
      "\titers: 500, epoch: 5 | loss: 0.1002384\n",
      "\tspeed: 0.0485s/iter; left time: 33.2148s\n",
      "Epoch: 5 cost time: 28.558305978775024\n",
      "Epoch: 5, Steps: 592 | Train Loss: 0.1487092 Vali Loss: 0.3307880 Test Loss: 0.2568153\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1225346\n",
      "\tspeed: 0.1425s/iter; left time: 70.2636s\n",
      "\titers: 200, epoch: 6 | loss: 0.2481631\n",
      "\tspeed: 0.0480s/iter; left time: 18.8548s\n",
      "\titers: 300, epoch: 6 | loss: 0.1261239\n",
      "\tspeed: 0.0486s/iter; left time: 14.2464s\n",
      "\titers: 400, epoch: 6 | loss: 0.1303389\n",
      "\tspeed: 0.0477s/iter; left time: 9.2094s\n",
      "\titers: 500, epoch: 6 | loss: 0.0981490\n",
      "\tspeed: 0.0479s/iter; left time: 4.4523s\n",
      "Epoch: 6 cost time: 28.44821786880493\n",
      "Epoch: 6, Steps: 592 | Train Loss: 0.1436069 Vali Loss: 0.3318109 Test Loss: 0.2603302\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl264_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4658\n",
      "Test cost time: 2.9620s\n",
      "test shape: (145, 32, 6, 1) (145, 32, 6, 1)\n",
      "test shape: (4640, 6, 1) (4640, 6, 1)\n",
      "mse:0.26877492666244507, mae:0.3392990231513977\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl264_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1840.5103759765625\n",
      "MAE:  28.07743263244629\n",
      "RMSE: 42.90116882324219\n",
      "MAPE: 0.38646194338798523\n",
      "MSPE: 0.675155520439148\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl264_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24275\n",
      "[DEBUG] Original dataset length: 24275\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18969\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3231\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4658\n",
      "\titers: 100, epoch: 1 | loss: 0.2474291\n",
      "\tspeed: 0.0477s/iter; left time: 164.6356s\n",
      "\titers: 200, epoch: 1 | loss: 0.3324211\n",
      "\tspeed: 0.0483s/iter; left time: 161.9056s\n",
      "\titers: 300, epoch: 1 | loss: 0.2283477\n",
      "\tspeed: 0.0478s/iter; left time: 155.3638s\n",
      "\titers: 400, epoch: 1 | loss: 0.2562098\n",
      "\tspeed: 0.0481s/iter; left time: 151.7547s\n",
      "\titers: 500, epoch: 1 | loss: 0.1543906\n",
      "\tspeed: 0.0488s/iter; left time: 148.9258s\n",
      "Epoch: 1 cost time: 28.48798131942749\n",
      "Epoch: 1, Steps: 592 | Train Loss: 0.2919944 Vali Loss: 0.3298880 Test Loss: 0.2818691\n",
      "Validation loss decreased (inf --> 0.329888).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2792772\n",
      "\tspeed: 0.1439s/iter; left time: 411.6612s\n",
      "\titers: 200, epoch: 2 | loss: 0.2789509\n",
      "\tspeed: 0.0477s/iter; left time: 131.6815s\n",
      "\titers: 300, epoch: 2 | loss: 0.2257012\n",
      "\tspeed: 0.0486s/iter; left time: 129.4133s\n",
      "\titers: 400, epoch: 2 | loss: 0.1908844\n",
      "\tspeed: 0.0492s/iter; left time: 126.0750s\n",
      "\titers: 500, epoch: 2 | loss: 0.1577266\n",
      "\tspeed: 0.0481s/iter; left time: 118.4340s\n",
      "Epoch: 2 cost time: 28.63974690437317\n",
      "Epoch: 2, Steps: 592 | Train Loss: 0.1991852 Vali Loss: 0.3315318 Test Loss: 0.2701449\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1629312\n",
      "\tspeed: 0.1430s/iter; left time: 324.5534s\n",
      "\titers: 200, epoch: 3 | loss: 0.2728530\n",
      "\tspeed: 0.0482s/iter; left time: 104.4561s\n",
      "\titers: 300, epoch: 3 | loss: 0.1203406\n",
      "\tspeed: 0.0479s/iter; left time: 99.1946s\n",
      "\titers: 400, epoch: 3 | loss: 0.2452630\n",
      "\tspeed: 0.0487s/iter; left time: 95.7936s\n",
      "\titers: 500, epoch: 3 | loss: 0.1691050\n",
      "\tspeed: 0.0482s/iter; left time: 90.0934s\n",
      "Epoch: 3 cost time: 28.49030351638794\n",
      "Epoch: 3, Steps: 592 | Train Loss: 0.1690470 Vali Loss: 0.3366002 Test Loss: 0.2785046\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2173315\n",
      "\tspeed: 0.1430s/iter; left time: 239.8463s\n",
      "\titers: 200, epoch: 4 | loss: 0.2009811\n",
      "\tspeed: 0.0482s/iter; left time: 75.9432s\n",
      "\titers: 300, epoch: 4 | loss: 0.1406435\n",
      "\tspeed: 0.0483s/iter; left time: 71.3402s\n",
      "\titers: 400, epoch: 4 | loss: 0.1045710\n",
      "\tspeed: 0.0480s/iter; left time: 66.1294s\n",
      "\titers: 500, epoch: 4 | loss: 0.1522595\n",
      "\tspeed: 0.0479s/iter; left time: 61.1509s\n",
      "Epoch: 4 cost time: 28.593512058258057\n",
      "Epoch: 4, Steps: 592 | Train Loss: 0.1537635 Vali Loss: 0.3370950 Test Loss: 0.2722970\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl264_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4658\n",
      "Test cost time: 2.9409s\n",
      "test shape: (145, 32, 6, 1) (145, 32, 6, 1)\n",
      "test shape: (4640, 6, 1) (4640, 6, 1)\n",
      "mse:0.2813633680343628, mae:0.35438263416290283\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl264_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1926.7132568359375\n",
      "MAE:  29.32561683654785\n",
      "RMSE: 43.89434051513672\n",
      "MAPE: 0.4326225221157074\n",
      "MSPE: 1.019912600517273\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl264_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24275\n",
      "[DEBUG] Original dataset length: 24275\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18969\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3231\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4658\n",
      "\titers: 100, epoch: 1 | loss: 0.2145619\n",
      "\tspeed: 0.0482s/iter; left time: 166.3952s\n",
      "\titers: 200, epoch: 1 | loss: 0.3094923\n",
      "\tspeed: 0.0488s/iter; left time: 163.5041s\n",
      "\titers: 300, epoch: 1 | loss: 0.1631017\n",
      "\tspeed: 0.0479s/iter; left time: 155.7971s\n",
      "\titers: 400, epoch: 1 | loss: 0.2345069\n",
      "\tspeed: 0.0481s/iter; left time: 151.5309s\n",
      "\titers: 500, epoch: 1 | loss: 0.2423766\n",
      "\tspeed: 0.0487s/iter; left time: 148.7798s\n",
      "Epoch: 1 cost time: 28.625557899475098\n",
      "Epoch: 1, Steps: 592 | Train Loss: 0.2924370 Vali Loss: 0.3458367 Test Loss: 0.2866786\n",
      "Validation loss decreased (inf --> 0.345837).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1610012\n",
      "\tspeed: 0.1437s/iter; left time: 411.1440s\n",
      "\titers: 200, epoch: 2 | loss: 0.1938104\n",
      "\tspeed: 0.0479s/iter; left time: 132.3586s\n",
      "\titers: 300, epoch: 2 | loss: 0.2936522\n",
      "\tspeed: 0.0477s/iter; left time: 126.8222s\n",
      "\titers: 400, epoch: 2 | loss: 0.1695487\n",
      "\tspeed: 0.0489s/iter; left time: 125.2886s\n",
      "\titers: 500, epoch: 2 | loss: 0.1510869\n",
      "\tspeed: 0.0482s/iter; left time: 118.5056s\n",
      "Epoch: 2 cost time: 28.524946689605713\n",
      "Epoch: 2, Steps: 592 | Train Loss: 0.1968359 Vali Loss: 0.3268798 Test Loss: 0.2703419\n",
      "Validation loss decreased (0.345837 --> 0.326880).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1793593\n",
      "\tspeed: 0.1443s/iter; left time: 327.4471s\n",
      "\titers: 200, epoch: 3 | loss: 0.2308128\n",
      "\tspeed: 0.0480s/iter; left time: 104.0972s\n",
      "\titers: 300, epoch: 3 | loss: 0.2420843\n",
      "\tspeed: 0.0491s/iter; left time: 101.6100s\n",
      "\titers: 400, epoch: 3 | loss: 0.1239342\n",
      "\tspeed: 0.0482s/iter; left time: 94.9336s\n",
      "\titers: 500, epoch: 3 | loss: 0.2173450\n",
      "\tspeed: 0.0480s/iter; left time: 89.7362s\n",
      "Epoch: 3 cost time: 28.62250566482544\n",
      "Epoch: 3, Steps: 592 | Train Loss: 0.1699812 Vali Loss: 0.3445376 Test Loss: 0.2784289\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1135305\n",
      "\tspeed: 0.1444s/iter; left time: 242.1704s\n",
      "\titers: 200, epoch: 4 | loss: 0.1097157\n",
      "\tspeed: 0.0486s/iter; left time: 76.6884s\n",
      "\titers: 300, epoch: 4 | loss: 0.1038989\n",
      "\tspeed: 0.0488s/iter; left time: 72.1435s\n",
      "\titers: 400, epoch: 4 | loss: 0.1769044\n",
      "\tspeed: 0.0482s/iter; left time: 66.3320s\n",
      "\titers: 500, epoch: 4 | loss: 0.1872030\n",
      "\tspeed: 0.0480s/iter; left time: 61.2699s\n",
      "Epoch: 4 cost time: 28.66681957244873\n",
      "Epoch: 4, Steps: 592 | Train Loss: 0.1539646 Vali Loss: 0.3289609 Test Loss: 0.2654064\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1629908\n",
      "\tspeed: 0.1437s/iter; left time: 155.8994s\n",
      "\titers: 200, epoch: 5 | loss: 0.2027259\n",
      "\tspeed: 0.0488s/iter; left time: 48.0658s\n",
      "\titers: 300, epoch: 5 | loss: 0.1268513\n",
      "\tspeed: 0.0483s/iter; left time: 42.7137s\n",
      "\titers: 400, epoch: 5 | loss: 0.1183283\n",
      "\tspeed: 0.0479s/iter; left time: 37.5734s\n",
      "\titers: 500, epoch: 5 | loss: 0.2195450\n",
      "\tspeed: 0.0482s/iter; left time: 33.0260s\n",
      "Epoch: 5 cost time: 28.48624610900879\n",
      "Epoch: 5, Steps: 592 | Train Loss: 0.1453150 Vali Loss: 0.3483689 Test Loss: 0.2770323\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl264_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4658\n",
      "Test cost time: 2.9699s\n",
      "test shape: (145, 32, 6, 1) (145, 32, 6, 1)\n",
      "test shape: (4640, 6, 1) (4640, 6, 1)\n",
      "mse:0.2698992192745209, mae:0.3445226848125458\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl264_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1848.209228515625\n",
      "MAE:  28.50969886779785\n",
      "RMSE: 42.99080276489258\n",
      "MAPE: 0.3558867275714874\n",
      "MSPE: 0.5540375709533691\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl264_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24275\n",
      "[DEBUG] Original dataset length: 24275\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18969\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3231\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4658\n",
      "\titers: 100, epoch: 1 | loss: 0.5122076\n",
      "\tspeed: 0.0479s/iter; left time: 165.5436s\n",
      "\titers: 200, epoch: 1 | loss: 0.3492249\n",
      "\tspeed: 0.0477s/iter; left time: 159.9224s\n",
      "\titers: 300, epoch: 1 | loss: 0.2759461\n",
      "\tspeed: 0.0478s/iter; left time: 155.6430s\n",
      "\titers: 400, epoch: 1 | loss: 0.1861750\n",
      "\tspeed: 0.0484s/iter; left time: 152.5923s\n",
      "\titers: 500, epoch: 1 | loss: 0.1903228\n",
      "\tspeed: 0.0478s/iter; left time: 146.0831s\n",
      "Epoch: 1 cost time: 28.372456312179565\n",
      "Epoch: 1, Steps: 592 | Train Loss: 0.2950817 Vali Loss: 0.3511243 Test Loss: 0.3076308\n",
      "Validation loss decreased (inf --> 0.351124).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3360974\n",
      "\tspeed: 0.1435s/iter; left time: 410.5263s\n",
      "\titers: 200, epoch: 2 | loss: 0.2317083\n",
      "\tspeed: 0.0477s/iter; left time: 131.7959s\n",
      "\titers: 300, epoch: 2 | loss: 0.1734289\n",
      "\tspeed: 0.0489s/iter; left time: 130.0278s\n",
      "\titers: 400, epoch: 2 | loss: 0.1511795\n",
      "\tspeed: 0.0479s/iter; left time: 122.6350s\n",
      "\titers: 500, epoch: 2 | loss: 0.2030900\n",
      "\tspeed: 0.0480s/iter; left time: 118.1485s\n",
      "Epoch: 2 cost time: 28.522156238555908\n",
      "Epoch: 2, Steps: 592 | Train Loss: 0.2032895 Vali Loss: 0.3307184 Test Loss: 0.2734164\n",
      "Validation loss decreased (0.351124 --> 0.330718).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1447168\n",
      "\tspeed: 0.1438s/iter; left time: 326.3711s\n",
      "\titers: 200, epoch: 3 | loss: 0.2481168\n",
      "\tspeed: 0.0487s/iter; left time: 105.7279s\n",
      "\titers: 300, epoch: 3 | loss: 0.1794223\n",
      "\tspeed: 0.0482s/iter; left time: 99.6722s\n",
      "\titers: 400, epoch: 3 | loss: 0.2239337\n",
      "\tspeed: 0.0493s/iter; left time: 97.1577s\n",
      "\titers: 500, epoch: 3 | loss: 0.1638076\n",
      "\tspeed: 0.0507s/iter; left time: 94.6972s\n",
      "Epoch: 3 cost time: 29.278634786605835\n",
      "Epoch: 3, Steps: 592 | Train Loss: 0.1709232 Vali Loss: 0.3242403 Test Loss: 0.2630625\n",
      "Validation loss decreased (0.330718 --> 0.324240).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0847816\n",
      "\tspeed: 0.1492s/iter; left time: 250.2154s\n",
      "\titers: 200, epoch: 4 | loss: 0.1426499\n",
      "\tspeed: 0.0488s/iter; left time: 76.9445s\n",
      "\titers: 300, epoch: 4 | loss: 0.1962283\n",
      "\tspeed: 0.0479s/iter; left time: 70.7093s\n",
      "\titers: 400, epoch: 4 | loss: 0.1166040\n",
      "\tspeed: 0.0484s/iter; left time: 66.7116s\n",
      "\titers: 500, epoch: 4 | loss: 0.1505607\n",
      "\tspeed: 0.0487s/iter; left time: 62.1282s\n",
      "Epoch: 4 cost time: 28.6310715675354\n",
      "Epoch: 4, Steps: 592 | Train Loss: 0.1592019 Vali Loss: 0.3319196 Test Loss: 0.2582124\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1135953\n",
      "\tspeed: 0.1423s/iter; left time: 154.3566s\n",
      "\titers: 200, epoch: 5 | loss: 0.1225982\n",
      "\tspeed: 0.0476s/iter; left time: 46.8580s\n",
      "\titers: 300, epoch: 5 | loss: 0.1198607\n",
      "\tspeed: 0.0481s/iter; left time: 42.5591s\n",
      "\titers: 400, epoch: 5 | loss: 0.1328245\n",
      "\tspeed: 0.0491s/iter; left time: 38.5400s\n",
      "\titers: 500, epoch: 5 | loss: 0.0953709\n",
      "\tspeed: 0.0478s/iter; left time: 32.7359s\n",
      "Epoch: 5 cost time: 28.540502548217773\n",
      "Epoch: 5, Steps: 592 | Train Loss: 0.1491875 Vali Loss: 0.3290828 Test Loss: 0.2572420\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1186251\n",
      "\tspeed: 0.1431s/iter; left time: 70.5261s\n",
      "\titers: 200, epoch: 6 | loss: 0.1407453\n",
      "\tspeed: 0.0480s/iter; left time: 18.8453s\n",
      "\titers: 300, epoch: 6 | loss: 0.1180855\n",
      "\tspeed: 0.0479s/iter; left time: 14.0395s\n",
      "\titers: 400, epoch: 6 | loss: 0.1590672\n",
      "\tspeed: 0.0482s/iter; left time: 9.3122s\n",
      "\titers: 500, epoch: 6 | loss: 0.2340609\n",
      "\tspeed: 0.0477s/iter; left time: 4.4378s\n",
      "Epoch: 6 cost time: 28.406505823135376\n",
      "Epoch: 6, Steps: 592 | Train Loss: 0.1448816 Vali Loss: 0.3358484 Test Loss: 0.2620377\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl264_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4658\n",
      "Test cost time: 2.9474s\n",
      "test shape: (145, 32, 6, 1) (145, 32, 6, 1)\n",
      "test shape: (4640, 6, 1) (4640, 6, 1)\n",
      "mse:0.2630928158760071, mae:0.32859447598457336\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl264_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1801.6005859375\n",
      "MAE:  27.191614151000977\n",
      "RMSE: 42.44526672363281\n",
      "MAPE: 0.3155776858329773\n",
      "MSPE: 0.3991551399230957\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl264_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24275\n",
      "[DEBUG] Original dataset length: 24275\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18969\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3231\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4658\n",
      "\titers: 100, epoch: 1 | loss: 0.2398197\n",
      "\tspeed: 0.0502s/iter; left time: 173.3017s\n",
      "\titers: 200, epoch: 1 | loss: 0.3099236\n",
      "\tspeed: 0.0490s/iter; left time: 164.3662s\n",
      "\titers: 300, epoch: 1 | loss: 0.2005686\n",
      "\tspeed: 0.0481s/iter; left time: 156.3287s\n",
      "\titers: 400, epoch: 1 | loss: 0.2934469\n",
      "\tspeed: 0.0479s/iter; left time: 151.0779s\n",
      "\titers: 500, epoch: 1 | loss: 0.2194093\n",
      "\tspeed: 0.0485s/iter; left time: 148.0813s\n",
      "Epoch: 1 cost time: 28.805402994155884\n",
      "Epoch: 1, Steps: 592 | Train Loss: 0.3087089 Vali Loss: 0.3339134 Test Loss: 0.2776230\n",
      "Validation loss decreased (inf --> 0.333913).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2780959\n",
      "\tspeed: 0.1434s/iter; left time: 410.2715s\n",
      "\titers: 200, epoch: 2 | loss: 0.1712196\n",
      "\tspeed: 0.0478s/iter; left time: 131.9904s\n",
      "\titers: 300, epoch: 2 | loss: 0.1787416\n",
      "\tspeed: 0.0475s/iter; left time: 126.5211s\n",
      "\titers: 400, epoch: 2 | loss: 0.2892125\n",
      "\tspeed: 0.0484s/iter; left time: 124.0532s\n",
      "\titers: 500, epoch: 2 | loss: 0.2073604\n",
      "\tspeed: 0.0485s/iter; left time: 119.4079s\n",
      "Epoch: 2 cost time: 28.494032621383667\n",
      "Epoch: 2, Steps: 592 | Train Loss: 0.2099880 Vali Loss: 0.3224824 Test Loss: 0.2656411\n",
      "Validation loss decreased (0.333913 --> 0.322482).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1380003\n",
      "\tspeed: 0.1436s/iter; left time: 325.9402s\n",
      "\titers: 200, epoch: 3 | loss: 0.1259315\n",
      "\tspeed: 0.0483s/iter; left time: 104.7575s\n",
      "\titers: 300, epoch: 3 | loss: 0.1109736\n",
      "\tspeed: 0.0479s/iter; left time: 99.1827s\n",
      "\titers: 400, epoch: 3 | loss: 0.2610424\n",
      "\tspeed: 0.0490s/iter; left time: 96.5304s\n",
      "\titers: 500, epoch: 3 | loss: 0.1504841\n",
      "\tspeed: 0.0479s/iter; left time: 89.5154s\n",
      "Epoch: 3 cost time: 28.609373807907104\n",
      "Epoch: 3, Steps: 592 | Train Loss: 0.1759042 Vali Loss: 0.3648201 Test Loss: 0.2963727\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1359264\n",
      "\tspeed: 0.1433s/iter; left time: 240.2984s\n",
      "\titers: 200, epoch: 4 | loss: 0.1178913\n",
      "\tspeed: 0.0479s/iter; left time: 75.5913s\n",
      "\titers: 300, epoch: 4 | loss: 0.1387924\n",
      "\tspeed: 0.0487s/iter; left time: 71.9966s\n",
      "\titers: 400, epoch: 4 | loss: 0.1434556\n",
      "\tspeed: 0.0484s/iter; left time: 66.5814s\n",
      "\titers: 500, epoch: 4 | loss: 0.2455255\n",
      "\tspeed: 0.0481s/iter; left time: 61.4006s\n",
      "Epoch: 4 cost time: 28.759352922439575\n",
      "Epoch: 4, Steps: 592 | Train Loss: 0.1595188 Vali Loss: 0.3287992 Test Loss: 0.2625940\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2438694\n",
      "\tspeed: 0.1449s/iter; left time: 157.1633s\n",
      "\titers: 200, epoch: 5 | loss: 0.0912696\n",
      "\tspeed: 0.0483s/iter; left time: 47.5309s\n",
      "\titers: 300, epoch: 5 | loss: 0.0829406\n",
      "\tspeed: 0.0482s/iter; left time: 42.6918s\n",
      "\titers: 400, epoch: 5 | loss: 0.2727914\n",
      "\tspeed: 0.0481s/iter; left time: 37.7533s\n",
      "\titers: 500, epoch: 5 | loss: 0.1229763\n",
      "\tspeed: 0.0481s/iter; left time: 32.9557s\n",
      "Epoch: 5 cost time: 28.52943444252014\n",
      "Epoch: 5, Steps: 592 | Train Loss: 0.1501977 Vali Loss: 0.3370742 Test Loss: 0.2627393\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl264_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4658\n",
      "Test cost time: 2.9445s\n",
      "test shape: (145, 32, 6, 1) (145, 32, 6, 1)\n",
      "test shape: (4640, 6, 1) (4640, 6, 1)\n",
      "mse:0.26690393686294556, mae:0.33992505073547363\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl264_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1827.697998046875\n",
      "MAE:  28.129234313964844\n",
      "RMSE: 42.751583099365234\n",
      "MAPE: 0.35695478320121765\n",
      "MSPE: 0.575295627117157\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl264_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24275\n",
      "[DEBUG] Original dataset length: 24275\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18969\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3231\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4658\n",
      "\titers: 100, epoch: 1 | loss: 0.2972556\n",
      "\tspeed: 0.0482s/iter; left time: 166.5009s\n",
      "\titers: 200, epoch: 1 | loss: 0.4008135\n",
      "\tspeed: 0.0475s/iter; left time: 159.3212s\n",
      "\titers: 300, epoch: 1 | loss: 0.2568896\n",
      "\tspeed: 0.0476s/iter; left time: 154.9801s\n",
      "\titers: 400, epoch: 1 | loss: 0.2382307\n",
      "\tspeed: 0.0490s/iter; left time: 154.4788s\n",
      "\titers: 500, epoch: 1 | loss: 0.3151295\n",
      "\tspeed: 0.0483s/iter; left time: 147.4016s\n",
      "Epoch: 1 cost time: 28.52566432952881\n",
      "Epoch: 1, Steps: 592 | Train Loss: 0.2814492 Vali Loss: 0.3297268 Test Loss: 0.2708221\n",
      "Validation loss decreased (inf --> 0.329727).  Saving model ...\n",
      "Updating learning rate to 0.0001\n"
     ]
    }
   ],
   "source": [
    "for seq_len in seq_lens:\n",
    "    print(f\"Running seq_len={seq_len}\")\n",
    "    !python -u main_informer.py --model informer --data traffic_full --root_path ../ --features S --seq_len {seq_len} --label_len 24 --pred_len 6 --e_layers 2 --d_layers 1 --attn prob --des 'Exp' --itr 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b6691ac-0a81-4ead-a255-8904e5bafeb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17.32990809,  1.68137169])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load(\"./results/running_time_24.npy\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1a4d2e-92ac-41f1-bb1f-31c42347b0f7",
   "metadata": {},
   "source": [
    "## Calculate the metrics of each step and each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51ae6507-049c-48f1-afe2-9636d77bb319",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Helper: extract seq_len and run number from directory name\n",
    "# Example:\n",
    "# informer_traffic_full_ftS_sl24_ll24_pl6_dm512_..._Exp_3\n",
    "# seq_len = 24, run_num = 3\n",
    "# ---------------------------------------------------------\n",
    "def extract_info(dirname):\n",
    "    seq_match = re.search(r\"sl(\\d+)\", dirname)\n",
    "    run_match = re.search(r\"Exp_(\\d+)\", dirname)\n",
    "\n",
    "    seq_len = int(seq_match.group(1)) if seq_match else None\n",
    "    run_num = int(run_match.group(1)) + 1 if run_match else None  # Exp_0 → run 1\n",
    "\n",
    "    return seq_len, run_num\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Compute metrics for each of 6 prediction steps\n",
    "# pred, true shape: (N, 6, 1)\n",
    "# ---------------------------------------------------------\n",
    "def compute_step_metrics(pred, true):\n",
    "    steps = pred.shape[1]\n",
    "    rows = []\n",
    "\n",
    "    for step in range(steps):\n",
    "        p = pred[:, step, 0]\n",
    "        g = true[:, step, 0]\n",
    "\n",
    "        mae = mean_absolute_error(g, p)\n",
    "        rmse = root_mean_squared_error(g, p)\n",
    "        mape = mean_absolute_percentage_error(g, p) * 100  # convert to percentage\n",
    "        rows.append((step + 1, mae, rmse, mape))\n",
    "        \n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "242c9ab5-6767-4be6-8edf-4ef54f8594b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping missing: .ipynb_checkpoints\n"
     ]
    }
   ],
   "source": [
    "all_rows = []\n",
    "\n",
    "# your result directories (you can replace this with auto-search)\n",
    "result_dirs = sorted([\n",
    "    d for d in os.listdir(\"results\")\n",
    "    if os.path.isdir(os.path.join(\"results\", d))\n",
    "])\n",
    "\n",
    "for d in result_dirs:\n",
    "    seq_len, run_num = extract_info(d)\n",
    "\n",
    "    pred_path = os.path.join(\"results\", d, \"pred_inverse.npy\")\n",
    "    true_path = os.path.join(\"results\", d, \"true_inverse.npy\")\n",
    "\n",
    "    if not (os.path.exists(pred_path) and os.path.exists(true_path)):\n",
    "        print(f\"Skipping missing: {d}\")\n",
    "        continue\n",
    "\n",
    "    pred = np.load(pred_path)\n",
    "    true = np.load(true_path)\n",
    "\n",
    "    metrics = compute_step_metrics(pred, true)\n",
    "\n",
    "    for step, mae, rmse, mape in metrics:\n",
    "        all_rows.append({\n",
    "            \"input_len\": seq_len,\n",
    "            \"run_num\": run_num,\n",
    "            \"pre_step\": step,\n",
    "            \"MAE_test\": mae,\n",
    "            \"RMSE_test\": rmse,\n",
    "            \"MAPE (%)_test\": mape\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(all_rows)\n",
    "df = df.sort_values(by=[\"input_len\", \"run_num\", \"pre_step\"]).reset_index(drop=True)\n",
    "#df.to_csv('../all_metrics_informer_entire_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "151ef470-abfe-4360-8a2c-334c5bedd5a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_len</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>26.827424</td>\n",
       "      <td>40.091506</td>\n",
       "      <td>33.976340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>27.086889</td>\n",
       "      <td>40.371117</td>\n",
       "      <td>35.322956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>27.484757</td>\n",
       "      <td>40.414853</td>\n",
       "      <td>37.142969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96</td>\n",
       "      <td>27.565523</td>\n",
       "      <td>41.038521</td>\n",
       "      <td>35.855909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>27.364081</td>\n",
       "      <td>41.213944</td>\n",
       "      <td>35.366292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>144</td>\n",
       "      <td>27.528013</td>\n",
       "      <td>41.292334</td>\n",
       "      <td>35.943623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>168</td>\n",
       "      <td>27.900328</td>\n",
       "      <td>41.459094</td>\n",
       "      <td>37.013240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>192</td>\n",
       "      <td>27.311530</td>\n",
       "      <td>41.252090</td>\n",
       "      <td>34.981317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>216</td>\n",
       "      <td>27.348362</td>\n",
       "      <td>40.972219</td>\n",
       "      <td>37.868599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>240</td>\n",
       "      <td>27.662873</td>\n",
       "      <td>41.741723</td>\n",
       "      <td>37.931720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>264</td>\n",
       "      <td>27.909886</td>\n",
       "      <td>42.613484</td>\n",
       "      <td>36.033699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>288</td>\n",
       "      <td>28.428512</td>\n",
       "      <td>42.839811</td>\n",
       "      <td>38.538594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>312</td>\n",
       "      <td>27.657373</td>\n",
       "      <td>42.875749</td>\n",
       "      <td>34.077934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>336</td>\n",
       "      <td>28.042166</td>\n",
       "      <td>42.898795</td>\n",
       "      <td>35.931267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>360</td>\n",
       "      <td>28.378985</td>\n",
       "      <td>43.788344</td>\n",
       "      <td>34.976826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>384</td>\n",
       "      <td>28.860072</td>\n",
       "      <td>44.196937</td>\n",
       "      <td>36.085584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>408</td>\n",
       "      <td>29.124343</td>\n",
       "      <td>44.124789</td>\n",
       "      <td>38.010948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>432</td>\n",
       "      <td>28.937098</td>\n",
       "      <td>44.651621</td>\n",
       "      <td>36.279675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>456</td>\n",
       "      <td>29.117829</td>\n",
       "      <td>44.748922</td>\n",
       "      <td>37.068310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>480</td>\n",
       "      <td>29.624438</td>\n",
       "      <td>46.003536</td>\n",
       "      <td>36.347774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>504</td>\n",
       "      <td>29.368494</td>\n",
       "      <td>46.124282</td>\n",
       "      <td>36.350152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    input_len   MAE_test  RMSE_test  MAPE (%)_test\n",
       "0          24  26.827424  40.091506      33.976340\n",
       "1          48  27.086889  40.371117      35.322956\n",
       "2          72  27.484757  40.414853      37.142969\n",
       "3          96  27.565523  41.038521      35.855909\n",
       "4         120  27.364081  41.213944      35.366292\n",
       "5         144  27.528013  41.292334      35.943623\n",
       "6         168  27.900328  41.459094      37.013240\n",
       "7         192  27.311530  41.252090      34.981317\n",
       "8         216  27.348362  40.972219      37.868599\n",
       "9         240  27.662873  41.741723      37.931720\n",
       "10        264  27.909886  42.613484      36.033699\n",
       "11        288  28.428512  42.839811      38.538594\n",
       "12        312  27.657373  42.875749      34.077934\n",
       "13        336  28.042166  42.898795      35.931267\n",
       "14        360  28.378985  43.788344      34.976826\n",
       "15        384  28.860072  44.196937      36.085584\n",
       "16        408  29.124343  44.124789      38.010948\n",
       "17        432  28.937098  44.651621      36.279675\n",
       "18        456  29.117829  44.748922      37.068310\n",
       "19        480  29.624438  46.003536      36.347774\n",
       "20        504  29.368494  46.124282      36.350152"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_seq = df.groupby(\"input_len\")[[\"MAE_test\", \"RMSE_test\", \"MAPE (%)_test\"]].mean().reset_index()\n",
    "#avg_by_seq.to_csv('../metrics_informer_entire_data.csv', index=False)\n",
    "avg_by_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b194aac0-3818-4daf-8c74-6f7cdb1b488a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] Missing metrics_inverse.npy in results/.ipynb_checkpoints\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_len</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>26.827423</td>\n",
       "      <td>40.248596</td>\n",
       "      <td>33.976345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>27.086889</td>\n",
       "      <td>40.532936</td>\n",
       "      <td>35.322960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>27.484756</td>\n",
       "      <td>40.567635</td>\n",
       "      <td>37.142967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96</td>\n",
       "      <td>27.565521</td>\n",
       "      <td>41.195618</td>\n",
       "      <td>35.855907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>27.364080</td>\n",
       "      <td>41.375389</td>\n",
       "      <td>35.366291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>144</td>\n",
       "      <td>27.528015</td>\n",
       "      <td>41.451664</td>\n",
       "      <td>35.943626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>168</td>\n",
       "      <td>27.900330</td>\n",
       "      <td>41.608902</td>\n",
       "      <td>37.013237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>192</td>\n",
       "      <td>27.311533</td>\n",
       "      <td>41.407749</td>\n",
       "      <td>34.981316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>216</td>\n",
       "      <td>27.348362</td>\n",
       "      <td>41.117546</td>\n",
       "      <td>37.868603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>240</td>\n",
       "      <td>27.662872</td>\n",
       "      <td>41.893860</td>\n",
       "      <td>37.931721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>264</td>\n",
       "      <td>27.909887</td>\n",
       "      <td>42.781487</td>\n",
       "      <td>36.033703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>288</td>\n",
       "      <td>28.428513</td>\n",
       "      <td>43.016197</td>\n",
       "      <td>38.538597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>312</td>\n",
       "      <td>27.657373</td>\n",
       "      <td>43.059753</td>\n",
       "      <td>34.077934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>336</td>\n",
       "      <td>28.042166</td>\n",
       "      <td>43.075539</td>\n",
       "      <td>35.931267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>360</td>\n",
       "      <td>28.378986</td>\n",
       "      <td>43.971962</td>\n",
       "      <td>34.976826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>384</td>\n",
       "      <td>28.860071</td>\n",
       "      <td>44.398430</td>\n",
       "      <td>36.085587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>408</td>\n",
       "      <td>29.124344</td>\n",
       "      <td>44.320198</td>\n",
       "      <td>38.010944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>432</td>\n",
       "      <td>28.937099</td>\n",
       "      <td>44.846455</td>\n",
       "      <td>36.279671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>456</td>\n",
       "      <td>29.117828</td>\n",
       "      <td>44.940174</td>\n",
       "      <td>37.068310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>480</td>\n",
       "      <td>29.624439</td>\n",
       "      <td>46.211472</td>\n",
       "      <td>36.347771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>504</td>\n",
       "      <td>29.368494</td>\n",
       "      <td>46.341087</td>\n",
       "      <td>36.350151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    input_len   MAE_test  RMSE_test  MAPE (%)_test\n",
       "0          24  26.827423  40.248596      33.976345\n",
       "1          48  27.086889  40.532936      35.322960\n",
       "2          72  27.484756  40.567635      37.142967\n",
       "3          96  27.565521  41.195618      35.855907\n",
       "4         120  27.364080  41.375389      35.366291\n",
       "5         144  27.528015  41.451664      35.943626\n",
       "6         168  27.900330  41.608902      37.013237\n",
       "7         192  27.311533  41.407749      34.981316\n",
       "8         216  27.348362  41.117546      37.868603\n",
       "9         240  27.662872  41.893860      37.931721\n",
       "10        264  27.909887  42.781487      36.033703\n",
       "11        288  28.428513  43.016197      38.538597\n",
       "12        312  27.657373  43.059753      34.077934\n",
       "13        336  28.042166  43.075539      35.931267\n",
       "14        360  28.378986  43.971962      34.976826\n",
       "15        384  28.860071  44.398430      36.085587\n",
       "16        408  29.124344  44.320198      38.010944\n",
       "17        432  28.937099  44.846455      36.279671\n",
       "18        456  29.117828  44.940174      37.068310\n",
       "19        480  29.624439  46.211472      36.347771\n",
       "20        504  29.368494  46.341087      36.350151"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect all result directories\n",
    "result_dirs = sorted([\n",
    "    d for d in os.listdir(\"results\")\n",
    "    if os.path.isdir(os.path.join(\"results\", d))\n",
    "])\n",
    "\n",
    "# Dictionary to store metrics per seq_len\n",
    "metrics_dict = {}\n",
    "\n",
    "for d in result_dirs:\n",
    "    folder_path = os.path.join(\"results\", d)\n",
    "    \n",
    "    metrics_path = os.path.join(folder_path, \"metrics_inverse.npy\")\n",
    "    if not os.path.exists(metrics_path):\n",
    "        print(f\"[WARNING] Missing metrics_inverse.npy in {folder_path}\")\n",
    "        continue\n",
    "    \n",
    "    metrics = np.load(metrics_path)  # [MAE, MSE, RMSE, MAPE, MSPE]\n",
    "    \n",
    "    # Extract seq_len from folder name (assuming folder name contains 'sl<seq_len>_run<run_num>')\n",
    "    seq_len = int([s for s in d.split(\"_\") if s.startswith(\"sl\")][0][2:])\n",
    "    \n",
    "    if seq_len not in metrics_dict:\n",
    "        metrics_dict[seq_len] = {\"MAE\": [], \"RMSE\": [], \"MAPE\": []}\n",
    "    \n",
    "    metrics_dict[seq_len][\"MAE\"].append(metrics[0])\n",
    "    metrics_dict[seq_len][\"RMSE\"].append(metrics[2])\n",
    "    metrics_dict[seq_len][\"MAPE\"].append(metrics[3])\n",
    "\n",
    "# Calculate mean over all runs per seq_len\n",
    "rows = []\n",
    "for seq_len, vals in metrics_dict.items():\n",
    "    rows.append({\n",
    "        \"input_len\": seq_len,\n",
    "        \"MAE_test\": np.mean(vals[\"MAE\"]),\n",
    "        \"RMSE_test\": np.mean(vals[\"RMSE\"]),\n",
    "        \"MAPE (%)_test\": np.mean(vals[\"MAPE\"]) *100\n",
    "    })\n",
    "\n",
    "df_inverse_avg = pd.DataFrame(rows).sort_values(\"input_len\").reset_index(drop=True)\n",
    "df_inverse_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2571b057-b72b-4a49-b779-a68eb3a3466c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_seq.equals(df_inverse_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ceab08c1-73bd-47ef-a8a2-9ea741bfe525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAE_test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RMSE_test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>self</th>\n",
       "      <th>other</th>\n",
       "      <th>self</th>\n",
       "      <th>other</th>\n",
       "      <th>self</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.827424</td>\n",
       "      <td>26.827423</td>\n",
       "      <td>40.091506</td>\n",
       "      <td>40.248596</td>\n",
       "      <td>33.976340</td>\n",
       "      <td>33.976345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.086889</td>\n",
       "      <td>27.086889</td>\n",
       "      <td>40.371117</td>\n",
       "      <td>40.532936</td>\n",
       "      <td>35.322956</td>\n",
       "      <td>35.322960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.484757</td>\n",
       "      <td>27.484756</td>\n",
       "      <td>40.414853</td>\n",
       "      <td>40.567635</td>\n",
       "      <td>37.142969</td>\n",
       "      <td>37.142967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.565523</td>\n",
       "      <td>27.565521</td>\n",
       "      <td>41.038521</td>\n",
       "      <td>41.195618</td>\n",
       "      <td>35.855909</td>\n",
       "      <td>35.855907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.364081</td>\n",
       "      <td>27.364080</td>\n",
       "      <td>41.213944</td>\n",
       "      <td>41.375389</td>\n",
       "      <td>35.366292</td>\n",
       "      <td>35.366291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27.528013</td>\n",
       "      <td>27.528015</td>\n",
       "      <td>41.292334</td>\n",
       "      <td>41.451664</td>\n",
       "      <td>35.943623</td>\n",
       "      <td>35.943626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27.900328</td>\n",
       "      <td>27.900330</td>\n",
       "      <td>41.459094</td>\n",
       "      <td>41.608902</td>\n",
       "      <td>37.013240</td>\n",
       "      <td>37.013237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>27.311530</td>\n",
       "      <td>27.311533</td>\n",
       "      <td>41.252090</td>\n",
       "      <td>41.407749</td>\n",
       "      <td>34.981317</td>\n",
       "      <td>34.981316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27.348362</td>\n",
       "      <td>27.348362</td>\n",
       "      <td>40.972219</td>\n",
       "      <td>41.117546</td>\n",
       "      <td>37.868599</td>\n",
       "      <td>37.868603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>27.662873</td>\n",
       "      <td>27.662872</td>\n",
       "      <td>41.741723</td>\n",
       "      <td>41.893860</td>\n",
       "      <td>37.931720</td>\n",
       "      <td>37.931721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>27.909886</td>\n",
       "      <td>27.909887</td>\n",
       "      <td>42.613484</td>\n",
       "      <td>42.781487</td>\n",
       "      <td>36.033699</td>\n",
       "      <td>36.033703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>28.428512</td>\n",
       "      <td>28.428513</td>\n",
       "      <td>42.839811</td>\n",
       "      <td>43.016197</td>\n",
       "      <td>38.538594</td>\n",
       "      <td>38.538597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>27.657373</td>\n",
       "      <td>27.657373</td>\n",
       "      <td>42.875749</td>\n",
       "      <td>43.059753</td>\n",
       "      <td>34.077934</td>\n",
       "      <td>34.077934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>28.042166</td>\n",
       "      <td>28.042166</td>\n",
       "      <td>42.898795</td>\n",
       "      <td>43.075539</td>\n",
       "      <td>35.931267</td>\n",
       "      <td>35.931267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>28.378985</td>\n",
       "      <td>28.378986</td>\n",
       "      <td>43.788344</td>\n",
       "      <td>43.971962</td>\n",
       "      <td>34.976826</td>\n",
       "      <td>34.976826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>28.860072</td>\n",
       "      <td>28.860071</td>\n",
       "      <td>44.196937</td>\n",
       "      <td>44.398430</td>\n",
       "      <td>36.085584</td>\n",
       "      <td>36.085587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>29.124343</td>\n",
       "      <td>29.124344</td>\n",
       "      <td>44.124789</td>\n",
       "      <td>44.320198</td>\n",
       "      <td>38.010948</td>\n",
       "      <td>38.010944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>28.937098</td>\n",
       "      <td>28.937099</td>\n",
       "      <td>44.651621</td>\n",
       "      <td>44.846455</td>\n",
       "      <td>36.279675</td>\n",
       "      <td>36.279671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>29.117829</td>\n",
       "      <td>29.117828</td>\n",
       "      <td>44.748922</td>\n",
       "      <td>44.940174</td>\n",
       "      <td>37.068310</td>\n",
       "      <td>37.068310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>29.624438</td>\n",
       "      <td>29.624439</td>\n",
       "      <td>46.003536</td>\n",
       "      <td>46.211472</td>\n",
       "      <td>36.347774</td>\n",
       "      <td>36.347771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>29.368494</td>\n",
       "      <td>29.368494</td>\n",
       "      <td>46.124282</td>\n",
       "      <td>46.341087</td>\n",
       "      <td>36.350152</td>\n",
       "      <td>36.350151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAE_test             RMSE_test            MAPE (%)_test           \n",
       "         self      other       self      other          self      other\n",
       "0   26.827424  26.827423  40.091506  40.248596     33.976340  33.976345\n",
       "1   27.086889  27.086889  40.371117  40.532936     35.322956  35.322960\n",
       "2   27.484757  27.484756  40.414853  40.567635     37.142969  37.142967\n",
       "3   27.565523  27.565521  41.038521  41.195618     35.855909  35.855907\n",
       "4   27.364081  27.364080  41.213944  41.375389     35.366292  35.366291\n",
       "5   27.528013  27.528015  41.292334  41.451664     35.943623  35.943626\n",
       "6   27.900328  27.900330  41.459094  41.608902     37.013240  37.013237\n",
       "7   27.311530  27.311533  41.252090  41.407749     34.981317  34.981316\n",
       "8   27.348362  27.348362  40.972219  41.117546     37.868599  37.868603\n",
       "9   27.662873  27.662872  41.741723  41.893860     37.931720  37.931721\n",
       "10  27.909886  27.909887  42.613484  42.781487     36.033699  36.033703\n",
       "11  28.428512  28.428513  42.839811  43.016197     38.538594  38.538597\n",
       "12  27.657373  27.657373  42.875749  43.059753     34.077934  34.077934\n",
       "13  28.042166  28.042166  42.898795  43.075539     35.931267  35.931267\n",
       "14  28.378985  28.378986  43.788344  43.971962     34.976826  34.976826\n",
       "15  28.860072  28.860071  44.196937  44.398430     36.085584  36.085587\n",
       "16  29.124343  29.124344  44.124789  44.320198     38.010948  38.010944\n",
       "17  28.937098  28.937099  44.651621  44.846455     36.279675  36.279671\n",
       "18  29.117829  29.117828  44.748922  44.940174     37.068310  37.068310\n",
       "19  29.624438  29.624439  46.003536  46.211472     36.347774  36.347771\n",
       "20  29.368494  29.368494  46.124282  46.341087     36.350152  36.350151"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_seq.compare(df_inverse_avg)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7620b5f-c4b8-436b-8c89-6ee474c5d53b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "transformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
