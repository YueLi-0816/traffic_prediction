{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67f7f33-1987-4932-9803-883ede914b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/zhouhaoyi/Informer2020.git\n",
    "#!git clone https://github.com/zhouhaoyi/ETDataset.git\n",
    "# modify the code based on my dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e4301a-419a-40b0-98e8-eea762441e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !{sys.executable} -m pip install matplotlib\n",
    "# !{sys.executable} -m pip install pandas\n",
    "# !{sys.executable} -m pip install scikit_learn\n",
    "# !{sys.executable} -m pip install torch\n",
    "# !{sys.executable} -m pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb6cc0a2-7f97-4bc2-b439-c7b775a9cd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60a07922-9f8e-44bb-825a-b576a86a90e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not 'Informer2020' in sys.path:\n",
    "    sys.path += ['Informer2020']\n",
    "\n",
    "from data.data_loader import Dataset_Custom\n",
    "from utils.metrics import metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd148590-d5a3-4a2b-afa4-77b77d84a671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cu128\n",
      "12.8\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6373961a-d2b9-4fbb-96a5-9ad2c3fbdc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 1\n",
      "GPU 0: NVIDIA A30\n"
     ]
    }
   ],
   "source": [
    "num_gpus = torch.cuda.device_count()\n",
    "print(\"Number of GPUs available:\", num_gpus)\n",
    "\n",
    "for i in range(num_gpus):\n",
    "    gpu_name = torch.cuda.get_device_name(i)\n",
    "    print(f\"GPU {i}: {gpu_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd1c08a-8be5-4e5c-a69c-b838fc3803d5",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d5eb9c8-e5e9-43e4-b287-564297d0b25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = pd.read_csv('../GD030A_S.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e02c837f-f057-48fc-ad77-aa5d7c99d36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the recover_timestamp function\n",
    "def recover_timestamp(data):\n",
    "    # Combine 'date' and 'time' to form a datetime column\n",
    "    data['datetime'] = pd.to_datetime(data['date'] + ' ' + data['time'].astype(str) + ':00', format='%Y-%m-%d %H:%M')\n",
    "\n",
    "    # Set 'datetime' as index\n",
    "    data = data.set_index('datetime')\n",
    "\n",
    "    # Create a complete range of timestamps with hourly frequency\n",
    "    full_time_range = pd.date_range(start=data.index.min(), end=data.index.max(), freq='H')\n",
    "\n",
    "    # Reindex the data to include all timestamps, filling missing rows with NaN\n",
    "    data_full = data.reindex(full_time_range)\n",
    "\n",
    "    return data_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fb2e9e-0912-4c8a-8ccd-bca7f1fc91d9",
   "metadata": {},
   "source": [
    "Custom data (xxx.csv) has to include at least 2 features: date(format: YYYY-MM-DD hh:mm:ss) and target feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fa5669-e577-40ea-9c59-6e998abacda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_full = recover_timestamp(my_data)\n",
    "traffic_full.drop(['date', 'time'], axis=1, inplace=True)\n",
    "traffic_full = traffic_full.reset_index(names='date')\n",
    "traffic_full['date'] = traffic_full['date'].astype(str)\n",
    "traffic_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e64353-3a50-4922-b0ae-81f1f592c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#traffic_full.to_csv('traffic_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04616932-2190-4b35-bceb-1bf11fa3e582",
   "metadata": {},
   "source": [
    "## Run training directly using bash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fc824e-bfd2-4f1e-ad4a-061367f8f9fa",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Next step: to record training time and inference time into log file</span>\n",
    "#### <span style=\"color:red\">write loop for the shell commands and inverse_results</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6890335e-1970-46ea-a2f0-9f3a9fb4938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure the shell commands below using the current Python environment\n",
    "os.environ[\"PATH\"] = f\"{sys.prefix}/bin:\" + os.environ[\"PATH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adf9133b-3e63-4228-8340-98bc089bf852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/transformer/Informer2020\n"
     ]
    }
   ],
   "source": [
    "cd Informer2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05ce82bd-438d-4fec-b166-87b2984ae0f9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(model='informer', data='traffic_full', root_path='../', data_path='traffic_full.csv', features='S', target='flow', freq='h', checkpoints='./checkpoints/', seq_len=24, label_len=24, pred_len=6, enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=2, d_layers=1, s_layers=[3, 2, 1], d_ff=2048, factor=5, padding=0, distil=True, dropout=0.05, attn='prob', embed='timeF', activation='gelu', output_attention=False, do_predict=False, mix=True, cols=None, num_workers=0, itr=2, train_epochs=6, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, inverse=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', detail_freq='h')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24515\n",
      "[DEBUG] Original dataset length: 24515\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 23049\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3471\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.2884856\n",
      "\tspeed: 0.0389s/iter; left time: 164.1249s\n",
      "\titers: 200, epoch: 1 | loss: 0.1755385\n",
      "\tspeed: 0.0250s/iter; left time: 102.8551s\n",
      "\titers: 300, epoch: 1 | loss: 0.2491599\n",
      "\tspeed: 0.0255s/iter; left time: 102.4994s\n",
      "\titers: 400, epoch: 1 | loss: 0.1548343\n",
      "\tspeed: 0.0258s/iter; left time: 101.1825s\n",
      "\titers: 500, epoch: 1 | loss: 0.1927182\n",
      "\tspeed: 0.0261s/iter; left time: 99.7301s\n",
      "\titers: 600, epoch: 1 | loss: 0.2821480\n",
      "\tspeed: 0.0253s/iter; left time: 93.9932s\n",
      "\titers: 700, epoch: 1 | loss: 0.3499653\n",
      "\tspeed: 0.0251s/iter; left time: 90.8236s\n",
      "Epoch: 1 cost time: 18.72835946083069\n",
      "Epoch: 1, Steps: 720 | Train Loss: 0.2695103 Vali Loss: 0.3603471 Test Loss: 0.2811839\n",
      "Validation loss decreased (inf --> 0.360347).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2456741\n",
      "\tspeed: 0.0590s/iter; left time: 206.7018s\n",
      "\titers: 200, epoch: 2 | loss: 0.2801323\n",
      "\tspeed: 0.0252s/iter; left time: 85.7032s\n",
      "\titers: 300, epoch: 2 | loss: 0.1969853\n",
      "\tspeed: 0.0261s/iter; left time: 86.3181s\n",
      "\titers: 400, epoch: 2 | loss: 0.2009655\n",
      "\tspeed: 0.0260s/iter; left time: 83.3389s\n",
      "\titers: 500, epoch: 2 | loss: 0.4421855\n",
      "\tspeed: 0.0240s/iter; left time: 74.2701s\n",
      "\titers: 600, epoch: 2 | loss: 0.1194793\n",
      "\tspeed: 0.0259s/iter; left time: 77.8279s\n",
      "\titers: 700, epoch: 2 | loss: 0.2365058\n",
      "\tspeed: 0.0255s/iter; left time: 73.9276s\n",
      "Epoch: 2 cost time: 18.42206072807312\n",
      "Epoch: 2, Steps: 720 | Train Loss: 0.2146434 Vali Loss: 0.3402226 Test Loss: 0.2565342\n",
      "Validation loss decreased (0.360347 --> 0.340223).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.4797178\n",
      "\tspeed: 0.0624s/iter; left time: 173.5233s\n",
      "\titers: 200, epoch: 3 | loss: 0.1335445\n",
      "\tspeed: 0.0253s/iter; left time: 67.9562s\n",
      "\titers: 300, epoch: 3 | loss: 0.1152782\n",
      "\tspeed: 0.0249s/iter; left time: 64.3421s\n",
      "\titers: 400, epoch: 3 | loss: 0.2305284\n",
      "\tspeed: 0.0260s/iter; left time: 64.5756s\n",
      "\titers: 500, epoch: 3 | loss: 0.2041782\n",
      "\tspeed: 0.0247s/iter; left time: 58.8928s\n",
      "\titers: 600, epoch: 3 | loss: 0.1779307\n",
      "\tspeed: 0.0249s/iter; left time: 56.7548s\n",
      "\titers: 700, epoch: 3 | loss: 0.1267211\n",
      "\tspeed: 0.0239s/iter; left time: 52.1120s\n",
      "Epoch: 3 cost time: 18.05015277862549\n",
      "Epoch: 3, Steps: 720 | Train Loss: 0.1885232 Vali Loss: 0.3098178 Test Loss: 0.2396975\n",
      "Validation loss decreased (0.340223 --> 0.309818).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1258162\n",
      "\tspeed: 0.0581s/iter; left time: 119.7154s\n",
      "\titers: 200, epoch: 4 | loss: 0.1399446\n",
      "\tspeed: 0.0252s/iter; left time: 49.4901s\n",
      "\titers: 300, epoch: 4 | loss: 0.0888401\n",
      "\tspeed: 0.0238s/iter; left time: 44.2891s\n",
      "\titers: 400, epoch: 4 | loss: 0.1606357\n",
      "\tspeed: 0.0237s/iter; left time: 41.6857s\n",
      "\titers: 500, epoch: 4 | loss: 0.1240849\n",
      "\tspeed: 0.0237s/iter; left time: 39.3092s\n",
      "\titers: 600, epoch: 4 | loss: 0.1416617\n",
      "\tspeed: 0.0248s/iter; left time: 38.7105s\n",
      "\titers: 700, epoch: 4 | loss: 0.1955214\n",
      "\tspeed: 0.0249s/iter; left time: 36.3906s\n",
      "Epoch: 4 cost time: 17.74261212348938\n",
      "Epoch: 4, Steps: 720 | Train Loss: 0.1739871 Vali Loss: 0.3047057 Test Loss: 0.2477681\n",
      "Validation loss decreased (0.309818 --> 0.304706).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1730151\n",
      "\tspeed: 0.0580s/iter; left time: 77.7717s\n",
      "\titers: 200, epoch: 5 | loss: 0.1409285\n",
      "\tspeed: 0.0235s/iter; left time: 29.1633s\n",
      "\titers: 300, epoch: 5 | loss: 0.1821510\n",
      "\tspeed: 0.0245s/iter; left time: 27.9634s\n",
      "\titers: 400, epoch: 5 | loss: 0.1468031\n",
      "\tspeed: 0.0237s/iter; left time: 24.6530s\n",
      "\titers: 500, epoch: 5 | loss: 0.1401295\n",
      "\tspeed: 0.0244s/iter; left time: 22.9869s\n",
      "\titers: 600, epoch: 5 | loss: 0.1535597\n",
      "\tspeed: 0.0258s/iter; left time: 21.6600s\n",
      "\titers: 700, epoch: 5 | loss: 0.1502461\n",
      "\tspeed: 0.0254s/iter; left time: 18.8326s\n",
      "Epoch: 5 cost time: 17.608397483825684\n",
      "Epoch: 5, Steps: 720 | Train Loss: 0.1653882 Vali Loss: 0.3087140 Test Loss: 0.2429592\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1888726\n",
      "\tspeed: 0.0541s/iter; left time: 33.5959s\n",
      "\titers: 200, epoch: 6 | loss: 0.1194530\n",
      "\tspeed: 0.0226s/iter; left time: 11.7856s\n",
      "\titers: 300, epoch: 6 | loss: 0.1487306\n",
      "\tspeed: 0.0246s/iter; left time: 10.3380s\n",
      "\titers: 400, epoch: 6 | loss: 0.1233295\n",
      "\tspeed: 0.0241s/iter; left time: 7.7384s\n",
      "\titers: 500, epoch: 6 | loss: 0.1144146\n",
      "\tspeed: 0.0239s/iter; left time: 5.2754s\n",
      "\titers: 600, epoch: 6 | loss: 0.2017381\n",
      "\tspeed: 0.0230s/iter; left time: 2.7848s\n",
      "\titers: 700, epoch: 6 | loss: 0.1629123\n",
      "\tspeed: 0.0239s/iter; left time: 0.5019s\n",
      "Epoch: 6 cost time: 16.962669849395752\n",
      "Epoch: 6, Steps: 720 | Train Loss: 0.1600093 Vali Loss: 0.3045644 Test Loss: 0.2451722\n",
      "Validation loss decreased (0.304706 --> 0.304564).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "Test cost time: 1.7177s\n",
      "test shape: (198, 32, 6, 1) (198, 32, 6, 1)\n",
      "test shape: (6336, 6, 1) (6336, 6, 1)\n",
      "mse:0.24473923444747925, mae:0.32641857862472534\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24515\n",
      "[DEBUG] Original dataset length: 24515\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 23049\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3471\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.2383045\n",
      "\tspeed: 0.0247s/iter; left time: 104.3716s\n",
      "\titers: 200, epoch: 1 | loss: 0.3476331\n",
      "\tspeed: 0.0238s/iter; left time: 97.9862s\n",
      "\titers: 300, epoch: 1 | loss: 0.2229072\n",
      "\tspeed: 0.0227s/iter; left time: 91.2092s\n",
      "\titers: 400, epoch: 1 | loss: 0.1415018\n",
      "\tspeed: 0.0226s/iter; left time: 88.6547s\n",
      "\titers: 500, epoch: 1 | loss: 0.2908813\n",
      "\tspeed: 0.0228s/iter; left time: 87.0396s\n",
      "\titers: 600, epoch: 1 | loss: 0.1135073\n",
      "\tspeed: 0.0234s/iter; left time: 87.0229s\n",
      "\titers: 700, epoch: 1 | loss: 0.1381817\n",
      "\tspeed: 0.0258s/iter; left time: 93.5293s\n",
      "Epoch: 1 cost time: 17.0408935546875\n",
      "Epoch: 1, Steps: 720 | Train Loss: 0.2764978 Vali Loss: 0.3478245 Test Loss: 0.2677115\n",
      "Validation loss decreased (inf --> 0.347825).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3257343\n",
      "\tspeed: 0.0532s/iter; left time: 186.2488s\n",
      "\titers: 200, epoch: 2 | loss: 0.1264900\n",
      "\tspeed: 0.0226s/iter; left time: 76.8999s\n",
      "\titers: 300, epoch: 2 | loss: 0.1564410\n",
      "\tspeed: 0.0219s/iter; left time: 72.4140s\n",
      "\titers: 400, epoch: 2 | loss: 0.2772850\n",
      "\tspeed: 0.0236s/iter; left time: 75.4724s\n",
      "\titers: 500, epoch: 2 | loss: 0.1677941\n",
      "\tspeed: 0.0257s/iter; left time: 79.7119s\n",
      "\titers: 600, epoch: 2 | loss: 0.2014831\n",
      "\tspeed: 0.0240s/iter; left time: 71.9719s\n",
      "\titers: 700, epoch: 2 | loss: 0.2590762\n",
      "\tspeed: 0.0253s/iter; left time: 73.4837s\n",
      "Epoch: 2 cost time: 17.05608105659485\n",
      "Epoch: 2, Steps: 720 | Train Loss: 0.2142572 Vali Loss: 0.3231415 Test Loss: 0.2532450\n",
      "Validation loss decreased (0.347825 --> 0.323141).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1129300\n",
      "\tspeed: 0.0554s/iter; left time: 153.9671s\n",
      "\titers: 200, epoch: 3 | loss: 0.1357491\n",
      "\tspeed: 0.0225s/iter; left time: 60.3922s\n",
      "\titers: 300, epoch: 3 | loss: 0.1898774\n",
      "\tspeed: 0.0252s/iter; left time: 65.1511s\n",
      "\titers: 400, epoch: 3 | loss: 0.1172767\n",
      "\tspeed: 0.0233s/iter; left time: 57.8644s\n",
      "\titers: 500, epoch: 3 | loss: 0.2724464\n",
      "\tspeed: 0.0224s/iter; left time: 53.2685s\n",
      "\titers: 600, epoch: 3 | loss: 0.2127222\n",
      "\tspeed: 0.0226s/iter; left time: 51.5278s\n",
      "\titers: 700, epoch: 3 | loss: 0.1095532\n",
      "\tspeed: 0.0233s/iter; left time: 50.8594s\n",
      "Epoch: 3 cost time: 16.789766311645508\n",
      "Epoch: 3, Steps: 720 | Train Loss: 0.1888948 Vali Loss: 0.3226480 Test Loss: 0.2488918\n",
      "Validation loss decreased (0.323141 --> 0.322648).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1388624\n",
      "\tspeed: 0.0538s/iter; left time: 110.9348s\n",
      "\titers: 200, epoch: 4 | loss: 0.2342280\n",
      "\tspeed: 0.0216s/iter; left time: 42.4439s\n",
      "\titers: 300, epoch: 4 | loss: 0.1489168\n",
      "\tspeed: 0.0219s/iter; left time: 40.7309s\n",
      "\titers: 400, epoch: 4 | loss: 0.1567622\n",
      "\tspeed: 0.0218s/iter; left time: 38.3849s\n",
      "\titers: 500, epoch: 4 | loss: 0.3663613\n",
      "\tspeed: 0.0222s/iter; left time: 36.8546s\n",
      "\titers: 600, epoch: 4 | loss: 0.2098427\n",
      "\tspeed: 0.0219s/iter; left time: 34.2009s\n",
      "\titers: 700, epoch: 4 | loss: 0.2006030\n",
      "\tspeed: 0.0238s/iter; left time: 34.8296s\n",
      "Epoch: 4 cost time: 16.15394902229309\n",
      "Epoch: 4, Steps: 720 | Train Loss: 0.1747139 Vali Loss: 0.3157785 Test Loss: 0.2441619\n",
      "Validation loss decreased (0.322648 --> 0.315779).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0997090\n",
      "\tspeed: 0.0561s/iter; left time: 75.2695s\n",
      "\titers: 200, epoch: 5 | loss: 0.1880583\n",
      "\tspeed: 0.0224s/iter; left time: 27.7518s\n",
      "\titers: 300, epoch: 5 | loss: 0.1553649\n",
      "\tspeed: 0.0226s/iter; left time: 25.8308s\n",
      "\titers: 400, epoch: 5 | loss: 0.1014133\n",
      "\tspeed: 0.0220s/iter; left time: 22.9212s\n",
      "\titers: 500, epoch: 5 | loss: 0.1883248\n",
      "\tspeed: 0.0244s/iter; left time: 22.9148s\n",
      "\titers: 600, epoch: 5 | loss: 0.1209955\n",
      "\tspeed: 0.0250s/iter; left time: 21.0232s\n",
      "\titers: 700, epoch: 5 | loss: 0.1051992\n",
      "\tspeed: 0.0235s/iter; left time: 17.4223s\n",
      "Epoch: 5 cost time: 16.80430030822754\n",
      "Epoch: 5, Steps: 720 | Train Loss: 0.1656383 Vali Loss: 0.3096630 Test Loss: 0.2424901\n",
      "Validation loss decreased (0.315779 --> 0.309663).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2129475\n",
      "\tspeed: 0.0544s/iter; left time: 33.8002s\n",
      "\titers: 200, epoch: 6 | loss: 0.2765687\n",
      "\tspeed: 0.0219s/iter; left time: 11.3912s\n",
      "\titers: 300, epoch: 6 | loss: 0.1300359\n",
      "\tspeed: 0.0231s/iter; left time: 9.7316s\n",
      "\titers: 400, epoch: 6 | loss: 0.1653813\n",
      "\tspeed: 0.0249s/iter; left time: 7.9797s\n",
      "\titers: 500, epoch: 6 | loss: 0.1376665\n",
      "\tspeed: 0.0230s/iter; left time: 5.0837s\n",
      "\titers: 600, epoch: 6 | loss: 0.1715132\n",
      "\tspeed: 0.0244s/iter; left time: 2.9478s\n",
      "\titers: 700, epoch: 6 | loss: 0.1763989\n",
      "\tspeed: 0.0220s/iter; left time: 0.4613s\n",
      "Epoch: 6 cost time: 16.599682331085205\n",
      "Epoch: 6, Steps: 720 | Train Loss: 0.1619694 Vali Loss: 0.3139386 Test Loss: 0.2421657\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "Test cost time: 1.6450s\n",
      "test shape: (198, 32, 6, 1) (198, 32, 6, 1)\n",
      "test shape: (6336, 6, 1) (6336, 6, 1)\n",
      "mse:0.24241915345191956, mae:0.326669305562973\n"
     ]
    }
   ],
   "source": [
    "!python -u main_informer.py --model informer --data traffic_full --root_path ../ --features S --seq_len 24 --label_len 24 --pred_len 6 --e_layers 2 --d_layers 1 --attn prob --des 'Exp' --itr 2 #--inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "297f6900-cd2b-4569-8ef9-4b2e4dd2b144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24, 48, 72, 96, 120, 144, 168, 192, 216, 240, 264, 288, 312, 336, 360, 384, 408, 432, 456, 480, 504]\n"
     ]
    }
   ],
   "source": [
    "seq_lens = [24 * i for i in range(1, 22)]\n",
    "print(seq_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97623185-1858-4ecd-99d3-bb9f6ff19c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running seq_len=24\n",
      "Args in experiment:\n",
      "Namespace(model='informer', data='traffic_full', root_path='../', data_path='traffic_full.csv', features='S', target='flow', freq='h', checkpoints='./checkpoints/', seq_len=24, label_len=24, pred_len=6, enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=2, d_layers=1, s_layers=[3, 2, 1], d_ff=2048, factor=5, padding=0, distil=True, dropout=0.05, attn='prob', embed='timeF', activation='gelu', output_attention=False, do_predict=False, mix=True, cols=None, num_workers=0, itr=10, train_epochs=6, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, inverse=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', detail_freq='h')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24515\n",
      "[DEBUG] Original dataset length: 24515\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 23049\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3471\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.5307340\n",
      "\tspeed: 0.0371s/iter; left time: 156.6516s\n",
      "\titers: 200, epoch: 1 | loss: 0.4023372\n",
      "\tspeed: 0.0227s/iter; left time: 93.3734s\n",
      "\titers: 300, epoch: 1 | loss: 0.3258615\n",
      "\tspeed: 0.0253s/iter; left time: 101.5862s\n",
      "\titers: 400, epoch: 1 | loss: 0.2069519\n",
      "\tspeed: 0.0249s/iter; left time: 97.4393s\n",
      "\titers: 500, epoch: 1 | loss: 0.2388484\n",
      "\tspeed: 0.0226s/iter; left time: 86.4546s\n",
      "\titers: 600, epoch: 1 | loss: 0.1579532\n",
      "\tspeed: 0.0221s/iter; left time: 82.1602s\n"
     ]
    }
   ],
   "source": [
    "for seq_len in seq_lens:\n",
    "    print(f\"Running seq_len={seq_len}\")\n",
    "    !python -u main_informer.py --model informer --data traffic_full --root_path ../ --features S --seq_len {seq_len} --label_len 24 --pred_len 6 --e_layers 2 --d_layers 1 --attn prob --des 'Exp' --itr 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b6691ac-0a81-4ead-a255-8904e5bafeb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17.32990809,  1.68137169])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load(\"./results/running_time_24.npy\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783e5d81-4226-4458-b558-06049f1da0f6",
   "metadata": {},
   "source": [
    "## Get the prediction results and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc6047d2-d947-4693-9a79-df6718d97852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_results(setting, args):\n",
    "    \"\"\"\n",
    "    Convert saved scaled predictions (pred.npy, true.npy) back to original scale.\n",
    "    \"\"\"\n",
    "    # Load stored pred & true\n",
    "    result_path = f'./results/{setting}/'\n",
    "    preds = np.load(result_path + 'pred.npy')\n",
    "    trues = np.load(result_path + 'true.npy')\n",
    "\n",
    "    # Rebuild the dataset to recover the SCALER\n",
    "    # We rebuild Dataset_Custom ONLY to access its scaler;\n",
    "    dataset = Dataset_Custom(\n",
    "        root_path=args.root_path,\n",
    "        data_path=args.data_path,\n",
    "        flag='train',                    # scaler is fit on TRAIN SPLIT\n",
    "        size=[args.seq_len, args.label_len, args.pred_len],\n",
    "        features=args.features,\n",
    "        target=args.target,\n",
    "        scale=True,\n",
    "        inverse=False,\n",
    "        timeenc=0,\n",
    "        freq=args.freq,\n",
    "        cols=args.cols\n",
    "    )\n",
    "\n",
    "    scaler = dataset.scaler  # this is the original scaler used during training\n",
    "\n",
    "    # Apply inverse scaling: reshape → inverse → reshape back\n",
    "    def _inverse(x):\n",
    "        orig_shape = x.shape\n",
    "        x2 = x.reshape(-1, orig_shape[-1])    # 2D for StandardScaler\n",
    "        x2 = scaler.inverse_transform(x2)\n",
    "        return x2.reshape(orig_shape)\n",
    "\n",
    "    preds_inv = _inverse(preds)\n",
    "    trues_inv = _inverse(trues)\n",
    "\n",
    "    # Calculate metrics on ORIGINAL scale\n",
    "    mae, mse, rmse, mape, mspe = metric(preds_inv, trues_inv)\n",
    "\n",
    "    # Save inverse results\n",
    "    np.save(result_path + 'pred_inverse.npy', preds_inv)\n",
    "    np.save(result_path + 'true_inverse.npy', trues_inv)\n",
    "    np.save(result_path + 'metrics_inverse.npy', np.array([mae, mse, rmse, mape, mspe]))\n",
    "\n",
    "    print(\"✓ Inverse transformation complete\")\n",
    "    print(\"=== Inverse Scale Metrics ===\")\n",
    "    print(f\"MSE:  {mse}\")\n",
    "    print(f\"MAE:  {mae}\")\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    print(f\"MAPE: {mape}\")\n",
    "    print(f\"MSPE: {mspe}\")\n",
    "\n",
    "    return preds_inv, trues_inv, (mae, mse, rmse, mape, mspe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86ac2778-aac2-4a8a-9b14-6996539e0849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1621.3642578125\n",
      "MAE:  27.05768585205078\n",
      "RMSE: 40.26616668701172\n",
      "MAPE: 0.3291575014591217\n",
      "MSPE: 0.49489617347717285\n"
     ]
    }
   ],
   "source": [
    "# Recreate args from the experiment\n",
    "args = Namespace(\n",
    "    root_path=\"../\",\n",
    "    data_path=\"traffic_full.csv\",\n",
    "    seq_len=24,\n",
    "    label_len=24,\n",
    "    pred_len=6,\n",
    "    features=\"S\",\n",
    "    target=\"flow\",\n",
    "    freq='h',\n",
    "    cols=None\n",
    ")\n",
    "\n",
    "setting = \"informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0\"\n",
    "\n",
    "preds_inv, trues_inv, metrics_inv = inverse_results(setting, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b9a808-f64c-43f8-b7da-2d46bae22c53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "transformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
