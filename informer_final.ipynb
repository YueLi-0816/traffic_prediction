{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67f7f33-1987-4932-9803-883ede914b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/zhouhaoyi/Informer2020.git\n",
    "#!git clone https://github.com/zhouhaoyi/ETDataset.git\n",
    "# modify the code based on my dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e4301a-419a-40b0-98e8-eea762441e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !{sys.executable} -m pip install matplotlib\n",
    "# !{sys.executable} -m pip install pandas\n",
    "# !{sys.executable} -m pip install scikit_learn\n",
    "# !{sys.executable} -m pip install torch\n",
    "# !{sys.executable} -m pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb6cc0a2-7f97-4bc2-b439-c7b775a9cd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from argparse import Namespace\n",
    "\n",
    "from data.data_loader import Dataset_Custom\n",
    "from utils.metrics import metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd148590-d5a3-4a2b-afa4-77b77d84a671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cu128\n",
      "12.8\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6373961a-d2b9-4fbb-96a5-9ad2c3fbdc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 1\n",
      "GPU 0: NVIDIA A30\n"
     ]
    }
   ],
   "source": [
    "num_gpus = torch.cuda.device_count()\n",
    "print(\"Number of GPUs available:\", num_gpus)\n",
    "\n",
    "for i in range(num_gpus):\n",
    "    gpu_name = torch.cuda.get_device_name(i)\n",
    "    print(f\"GPU {i}: {gpu_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd1c08a-8be5-4e5c-a69c-b838fc3803d5",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d5eb9c8-e5e9-43e4-b287-564297d0b25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = pd.read_csv('../GD030A_S.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e02c837f-f057-48fc-ad77-aa5d7c99d36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the recover_timestamp function\n",
    "def recover_timestamp(data):\n",
    "    # Combine 'date' and 'time' to form a datetime column\n",
    "    data['datetime'] = pd.to_datetime(data['date'] + ' ' + data['time'].astype(str) + ':00', format='%Y-%m-%d %H:%M')\n",
    "\n",
    "    # Set 'datetime' as index\n",
    "    data = data.set_index('datetime')\n",
    "\n",
    "    # Create a complete range of timestamps with hourly frequency\n",
    "    full_time_range = pd.date_range(start=data.index.min(), end=data.index.max(), freq='H')\n",
    "\n",
    "    # Reindex the data to include all timestamps, filling missing rows with NaN\n",
    "    data_full = data.reindex(full_time_range)\n",
    "\n",
    "    return data_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fb2e9e-0912-4c8a-8ccd-bca7f1fc91d9",
   "metadata": {},
   "source": [
    "Custom data (xxx.csv) has to include at least 2 features: date(format: YYYY-MM-DD hh:mm:ss) and target feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fa5669-e577-40ea-9c59-6e998abacda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_full = recover_timestamp(my_data)\n",
    "traffic_full.drop(['date', 'time'], axis=1, inplace=True)\n",
    "traffic_full = traffic_full.reset_index(names='date')\n",
    "traffic_full['date'] = traffic_full['date'].astype(str)\n",
    "traffic_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e64353-3a50-4922-b0ae-81f1f592c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#traffic_full.to_csv('traffic_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04616932-2190-4b35-bceb-1bf11fa3e582",
   "metadata": {},
   "source": [
    "## Run training directly using bash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fc824e-bfd2-4f1e-ad4a-061367f8f9fa",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Next step: to record training time and inference time into log file</span>\n",
    "#### <span style=\"color:red\">write loop for the shell commands and inverse_results</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6890335e-1970-46ea-a2f0-9f3a9fb4938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure the shell commands below using the current Python environment\n",
    "os.environ[\"PATH\"] = f\"{sys.prefix}/bin:\" + os.environ[\"PATH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adf9133b-3e63-4228-8340-98bc089bf852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/transformer/Informer2020\n"
     ]
    }
   ],
   "source": [
    "cd Informer2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "05ce82bd-438d-4fec-b166-87b2984ae0f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(model='informer', data='traffic_full', root_path='../', data_path='traffic_full.csv', features='S', target='flow', freq='h', checkpoints='./checkpoints/', seq_len=24, label_len=24, pred_len=6, enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=2, d_layers=1, s_layers=[3, 2, 1], d_ff=2048, factor=5, padding=0, distil=True, dropout=0.05, attn='prob', embed='timeF', activation='gelu', output_attention=False, do_predict=False, mix=True, cols=None, num_workers=0, itr=10, train_epochs=6, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, inverse=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', detail_freq='h')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24515\n",
      "[DEBUG] Original dataset length: 24515\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 23049\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3471\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.2461961\n",
      "\tspeed: 0.0404s/iter; left time: 170.6204s\n",
      "\titers: 200, epoch: 1 | loss: 0.3187841\n",
      "\tspeed: 0.0258s/iter; left time: 106.4660s\n",
      "\titers: 300, epoch: 1 | loss: 0.2757672\n",
      "\tspeed: 0.0269s/iter; left time: 108.1238s\n",
      "\titers: 400, epoch: 1 | loss: 0.3401806\n",
      "\tspeed: 0.0253s/iter; left time: 99.0496s\n",
      "\titers: 500, epoch: 1 | loss: 0.1997587\n",
      "\tspeed: 0.0261s/iter; left time: 99.6827s\n",
      "\titers: 600, epoch: 1 | loss: 0.1148522\n",
      "\tspeed: 0.0239s/iter; left time: 88.9512s\n",
      "\titers: 700, epoch: 1 | loss: 0.2335235\n",
      "\tspeed: 0.0243s/iter; left time: 87.8441s\n",
      "Epoch: 1 cost time: 18.991898775100708\n",
      "Epoch: 1, Steps: 720 | Train Loss: 0.2689325 Vali Loss: 0.3262943 Test Loss: 0.2529909\n",
      "Validation loss decreased (inf --> 0.326294).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2495385\n",
      "\tspeed: 0.0580s/iter; left time: 202.9450s\n",
      "\titers: 200, epoch: 2 | loss: 0.1750263\n",
      "\tspeed: 0.0230s/iter; left time: 78.0580s\n",
      "\titers: 300, epoch: 2 | loss: 0.2015916\n",
      "\tspeed: 0.0231s/iter; left time: 76.4130s\n",
      "\titers: 400, epoch: 2 | loss: 0.1869667\n",
      "\tspeed: 0.0233s/iter; left time: 74.6521s\n",
      "\titers: 500, epoch: 2 | loss: 0.1973119\n",
      "\tspeed: 0.0237s/iter; left time: 73.5985s\n",
      "\titers: 600, epoch: 2 | loss: 0.1794440\n",
      "\tspeed: 0.0260s/iter; left time: 77.9904s\n",
      "\titers: 700, epoch: 2 | loss: 0.1499409\n",
      "\tspeed: 0.0234s/iter; left time: 67.9900s\n",
      "Epoch: 2 cost time: 17.12300682067871\n",
      "Epoch: 2, Steps: 720 | Train Loss: 0.2117988 Vali Loss: 0.3339267 Test Loss: 0.2595414\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1406861\n",
      "\tspeed: 0.0556s/iter; left time: 154.6434s\n",
      "\titers: 200, epoch: 3 | loss: 0.1013163\n",
      "\tspeed: 0.0234s/iter; left time: 62.8248s\n",
      "\titers: 300, epoch: 3 | loss: 0.1612110\n",
      "\tspeed: 0.0243s/iter; left time: 62.7508s\n",
      "\titers: 400, epoch: 3 | loss: 0.2806622\n",
      "\tspeed: 0.0260s/iter; left time: 64.5402s\n",
      "\titers: 500, epoch: 3 | loss: 0.2239845\n",
      "\tspeed: 0.0231s/iter; left time: 55.0609s\n",
      "\titers: 600, epoch: 3 | loss: 0.1610321\n",
      "\tspeed: 0.0226s/iter; left time: 51.6209s\n",
      "\titers: 700, epoch: 3 | loss: 0.1887989\n",
      "\tspeed: 0.0231s/iter; left time: 50.3954s\n",
      "Epoch: 3 cost time: 17.096539974212646\n",
      "Epoch: 3, Steps: 720 | Train Loss: 0.1870694 Vali Loss: 0.3136574 Test Loss: 0.2438341\n",
      "Validation loss decreased (0.326294 --> 0.313657).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1926181\n",
      "\tspeed: 0.0565s/iter; left time: 116.4594s\n",
      "\titers: 200, epoch: 4 | loss: 0.2240309\n",
      "\tspeed: 0.0252s/iter; left time: 49.4643s\n",
      "\titers: 300, epoch: 4 | loss: 0.2815523\n",
      "\tspeed: 0.0230s/iter; left time: 42.7316s\n",
      "\titers: 400, epoch: 4 | loss: 0.1539363\n",
      "\tspeed: 0.0253s/iter; left time: 44.6379s\n",
      "\titers: 500, epoch: 4 | loss: 0.1906467\n",
      "\tspeed: 0.0271s/iter; left time: 45.0387s\n",
      "\titers: 600, epoch: 4 | loss: 0.1796353\n",
      "\tspeed: 0.0253s/iter; left time: 39.4781s\n",
      "\titers: 700, epoch: 4 | loss: 0.1505798\n",
      "\tspeed: 0.0258s/iter; left time: 37.7542s\n",
      "Epoch: 4 cost time: 18.185858011245728\n",
      "Epoch: 4, Steps: 720 | Train Loss: 0.1746662 Vali Loss: 0.2984910 Test Loss: 0.2332055\n",
      "Validation loss decreased (0.313657 --> 0.298491).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0928512\n",
      "\tspeed: 0.0603s/iter; left time: 80.8683s\n",
      "\titers: 200, epoch: 5 | loss: 0.2891281\n",
      "\tspeed: 0.0246s/iter; left time: 30.5357s\n",
      "\titers: 300, epoch: 5 | loss: 0.1050647\n",
      "\tspeed: 0.0240s/iter; left time: 27.3980s\n",
      "\titers: 400, epoch: 5 | loss: 0.2186125\n",
      "\tspeed: 0.0254s/iter; left time: 26.4738s\n",
      "\titers: 500, epoch: 5 | loss: 0.1631941\n",
      "\tspeed: 0.0248s/iter; left time: 23.3702s\n",
      "\titers: 600, epoch: 5 | loss: 0.1396428\n",
      "\tspeed: 0.0273s/iter; left time: 22.9778s\n",
      "\titers: 700, epoch: 5 | loss: 0.1259748\n",
      "\tspeed: 0.0254s/iter; left time: 18.7955s\n",
      "Epoch: 5 cost time: 18.238206148147583\n",
      "Epoch: 5, Steps: 720 | Train Loss: 0.1660451 Vali Loss: 0.3083878 Test Loss: 0.2399340\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2430225\n",
      "\tspeed: 0.0575s/iter; left time: 35.7026s\n",
      "\titers: 200, epoch: 6 | loss: 0.1353772\n",
      "\tspeed: 0.0248s/iter; left time: 12.9291s\n",
      "\titers: 300, epoch: 6 | loss: 0.1892256\n",
      "\tspeed: 0.0264s/iter; left time: 11.1115s\n",
      "\titers: 400, epoch: 6 | loss: 0.1394514\n",
      "\tspeed: 0.0260s/iter; left time: 8.3587s\n",
      "\titers: 500, epoch: 6 | loss: 0.1191602\n",
      "\tspeed: 0.0253s/iter; left time: 5.5989s\n",
      "\titers: 600, epoch: 6 | loss: 0.1375968\n",
      "\tspeed: 0.0258s/iter; left time: 3.1210s\n",
      "\titers: 700, epoch: 6 | loss: 0.1726525\n",
      "\tspeed: 0.0251s/iter; left time: 0.5270s\n",
      "Epoch: 6 cost time: 18.311731338500977\n",
      "Epoch: 6, Steps: 720 | Train Loss: 0.1605114 Vali Loss: 0.3071868 Test Loss: 0.2402137\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "test shape: (198, 32, 6, 1) (198, 32, 6, 1)\n",
      "test shape: (6336, 6, 1) (6336, 6, 1)\n",
      "mse:0.2337842732667923, mae:0.3248986601829529\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24515\n",
      "[DEBUG] Original dataset length: 24515\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 23049\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3471\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.2036320\n",
      "\tspeed: 0.0256s/iter; left time: 108.0156s\n",
      "\titers: 200, epoch: 1 | loss: 0.3146660\n",
      "\tspeed: 0.0251s/iter; left time: 103.3249s\n",
      "\titers: 300, epoch: 1 | loss: 0.2550530\n",
      "\tspeed: 0.0264s/iter; left time: 106.0757s\n",
      "\titers: 400, epoch: 1 | loss: 0.1856869\n",
      "\tspeed: 0.0257s/iter; left time: 100.6371s\n",
      "\titers: 500, epoch: 1 | loss: 0.1810939\n",
      "\tspeed: 0.0258s/iter; left time: 98.4552s\n",
      "\titers: 600, epoch: 1 | loss: 0.2378026\n",
      "\tspeed: 0.0273s/iter; left time: 101.4530s\n",
      "\titers: 700, epoch: 1 | loss: 0.2646679\n",
      "\tspeed: 0.0255s/iter; left time: 92.3654s\n",
      "Epoch: 1 cost time: 18.658892393112183\n",
      "Epoch: 1, Steps: 720 | Train Loss: 0.2734891 Vali Loss: 0.3194855 Test Loss: 0.2622627\n",
      "Validation loss decreased (inf --> 0.319486).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1829867\n",
      "\tspeed: 0.0589s/iter; left time: 206.2911s\n",
      "\titers: 200, epoch: 2 | loss: 0.1666643\n",
      "\tspeed: 0.0250s/iter; left time: 84.9099s\n",
      "\titers: 300, epoch: 2 | loss: 0.2160951\n",
      "\tspeed: 0.0266s/iter; left time: 87.8086s\n",
      "\titers: 400, epoch: 2 | loss: 0.2637603\n",
      "\tspeed: 0.0266s/iter; left time: 84.9902s\n",
      "\titers: 500, epoch: 2 | loss: 0.2629114\n",
      "\tspeed: 0.0252s/iter; left time: 78.1516s\n",
      "\titers: 600, epoch: 2 | loss: 0.1157182\n",
      "\tspeed: 0.0234s/iter; left time: 70.0872s\n",
      "\titers: 700, epoch: 2 | loss: 0.2766960\n",
      "\tspeed: 0.0240s/iter; left time: 69.6085s\n",
      "Epoch: 2 cost time: 18.075051307678223\n",
      "Epoch: 2, Steps: 720 | Train Loss: 0.2128726 Vali Loss: 0.3317186 Test Loss: 0.2592762\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1437949\n",
      "\tspeed: 0.0550s/iter; left time: 152.8269s\n",
      "\titers: 200, epoch: 3 | loss: 0.1244939\n",
      "\tspeed: 0.0255s/iter; left time: 68.3485s\n",
      "\titers: 300, epoch: 3 | loss: 0.2525215\n",
      "\tspeed: 0.0253s/iter; left time: 65.2331s\n",
      "\titers: 400, epoch: 3 | loss: 0.1359438\n",
      "\tspeed: 0.0234s/iter; left time: 57.9857s\n",
      "\titers: 500, epoch: 3 | loss: 0.3638684\n",
      "\tspeed: 0.0231s/iter; left time: 55.0933s\n",
      "\titers: 600, epoch: 3 | loss: 0.1723816\n",
      "\tspeed: 0.0234s/iter; left time: 53.2958s\n",
      "\titers: 700, epoch: 3 | loss: 0.2060484\n",
      "\tspeed: 0.0225s/iter; left time: 49.1210s\n",
      "Epoch: 3 cost time: 17.188689470291138\n",
      "Epoch: 3, Steps: 720 | Train Loss: 0.1873741 Vali Loss: 0.3102671 Test Loss: 0.2367323\n",
      "Validation loss decreased (0.319486 --> 0.310267).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1291080\n",
      "\tspeed: 0.0569s/iter; left time: 117.3427s\n",
      "\titers: 200, epoch: 4 | loss: 0.1263461\n",
      "\tspeed: 0.0232s/iter; left time: 45.4214s\n",
      "\titers: 300, epoch: 4 | loss: 0.1979509\n",
      "\tspeed: 0.0240s/iter; left time: 44.6615s\n",
      "\titers: 400, epoch: 4 | loss: 0.1256353\n",
      "\tspeed: 0.0240s/iter; left time: 42.1945s\n",
      "\titers: 500, epoch: 4 | loss: 0.1401203\n",
      "\tspeed: 0.0230s/iter; left time: 38.1713s\n",
      "\titers: 600, epoch: 4 | loss: 0.2421241\n",
      "\tspeed: 0.0261s/iter; left time: 40.7500s\n",
      "\titers: 700, epoch: 4 | loss: 0.1269317\n",
      "\tspeed: 0.0227s/iter; left time: 33.2025s\n",
      "Epoch: 4 cost time: 17.052862882614136\n",
      "Epoch: 4, Steps: 720 | Train Loss: 0.1731344 Vali Loss: 0.3032746 Test Loss: 0.2337237\n",
      "Validation loss decreased (0.310267 --> 0.303275).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1260121\n",
      "\tspeed: 0.0561s/iter; left time: 75.2351s\n",
      "\titers: 200, epoch: 5 | loss: 0.1501535\n",
      "\tspeed: 0.0249s/iter; left time: 30.9347s\n",
      "\titers: 300, epoch: 5 | loss: 0.1685686\n",
      "\tspeed: 0.0231s/iter; left time: 26.3712s\n",
      "\titers: 400, epoch: 5 | loss: 0.0989643\n",
      "\tspeed: 0.0256s/iter; left time: 26.5983s\n",
      "\titers: 500, epoch: 5 | loss: 0.1721183\n",
      "\tspeed: 0.0239s/iter; left time: 22.4603s\n",
      "\titers: 600, epoch: 5 | loss: 0.1374362\n",
      "\tspeed: 0.0251s/iter; left time: 21.0819s\n",
      "\titers: 700, epoch: 5 | loss: 0.1607908\n",
      "\tspeed: 0.0241s/iter; left time: 17.8502s\n",
      "Epoch: 5 cost time: 17.39133596420288\n",
      "Epoch: 5, Steps: 720 | Train Loss: 0.1662240 Vali Loss: 0.3144930 Test Loss: 0.2389600\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1854931\n",
      "\tspeed: 0.0535s/iter; left time: 33.2011s\n",
      "\titers: 200, epoch: 6 | loss: 0.1217520\n",
      "\tspeed: 0.0265s/iter; left time: 13.7909s\n",
      "\titers: 300, epoch: 6 | loss: 0.1428512\n",
      "\tspeed: 0.0237s/iter; left time: 9.9984s\n",
      "\titers: 400, epoch: 6 | loss: 0.0898876\n",
      "\tspeed: 0.0239s/iter; left time: 7.6699s\n",
      "\titers: 500, epoch: 6 | loss: 0.2179535\n",
      "\tspeed: 0.0270s/iter; left time: 5.9588s\n",
      "\titers: 600, epoch: 6 | loss: 0.1251249\n",
      "\tspeed: 0.0257s/iter; left time: 3.1093s\n",
      "\titers: 700, epoch: 6 | loss: 0.1522777\n",
      "\tspeed: 0.0263s/iter; left time: 0.5526s\n",
      "Epoch: 6 cost time: 18.08401584625244\n",
      "Epoch: 6, Steps: 720 | Train Loss: 0.1615646 Vali Loss: 0.3107929 Test Loss: 0.2379517\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "test shape: (198, 32, 6, 1) (198, 32, 6, 1)\n",
      "test shape: (6336, 6, 1) (6336, 6, 1)\n",
      "mse:0.23265303671360016, mae:0.32040151953697205\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24515\n",
      "[DEBUG] Original dataset length: 24515\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 23049\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3471\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.3208058\n",
      "\tspeed: 0.0311s/iter; left time: 131.1000s\n",
      "\titers: 200, epoch: 1 | loss: 0.3205681\n",
      "\tspeed: 0.0275s/iter; left time: 113.2411s\n",
      "\titers: 300, epoch: 1 | loss: 0.2218240\n",
      "\tspeed: 0.0273s/iter; left time: 109.6987s\n",
      "\titers: 400, epoch: 1 | loss: 0.2906373\n",
      "\tspeed: 0.0265s/iter; left time: 103.8423s\n",
      "\titers: 500, epoch: 1 | loss: 0.3060283\n",
      "\tspeed: 0.0258s/iter; left time: 98.4945s\n",
      "\titers: 600, epoch: 1 | loss: 0.1890380\n",
      "\tspeed: 0.0250s/iter; left time: 92.8884s\n",
      "\titers: 700, epoch: 1 | loss: 0.2866476\n",
      "\tspeed: 0.0248s/iter; left time: 89.7057s\n",
      "Epoch: 1 cost time: 19.30843448638916\n",
      "Epoch: 1, Steps: 720 | Train Loss: 0.2762591 Vali Loss: 0.3479816 Test Loss: 0.2630011\n",
      "Validation loss decreased (inf --> 0.347982).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2232919\n",
      "\tspeed: 0.0695s/iter; left time: 243.2548s\n",
      "\titers: 200, epoch: 2 | loss: 0.2007952\n",
      "\tspeed: 0.0316s/iter; left time: 107.4432s\n",
      "\titers: 300, epoch: 2 | loss: 0.4214668\n",
      "\tspeed: 0.0264s/iter; left time: 87.0903s\n",
      "\titers: 400, epoch: 2 | loss: 0.2164929\n",
      "\tspeed: 0.0280s/iter; left time: 89.6463s\n",
      "\titers: 500, epoch: 2 | loss: 0.1115161\n",
      "\tspeed: 0.0259s/iter; left time: 80.2796s\n",
      "\titers: 600, epoch: 2 | loss: 0.2087329\n",
      "\tspeed: 0.0281s/iter; left time: 84.3463s\n",
      "\titers: 700, epoch: 2 | loss: 0.2123361\n",
      "\tspeed: 0.0294s/iter; left time: 85.4160s\n",
      "Epoch: 2 cost time: 20.518657445907593\n",
      "Epoch: 2, Steps: 720 | Train Loss: 0.2165005 Vali Loss: 0.3120045 Test Loss: 0.2469082\n",
      "Validation loss decreased (0.347982 --> 0.312005).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2322105\n",
      "\tspeed: 0.0590s/iter; left time: 164.2069s\n",
      "\titers: 200, epoch: 3 | loss: 0.2197853\n",
      "\tspeed: 0.0238s/iter; left time: 63.6893s\n",
      "\titers: 300, epoch: 3 | loss: 0.1465915\n",
      "\tspeed: 0.0244s/iter; left time: 63.0297s\n",
      "\titers: 400, epoch: 3 | loss: 0.1720169\n",
      "\tspeed: 0.0240s/iter; left time: 59.6242s\n",
      "\titers: 500, epoch: 3 | loss: 0.1568511\n",
      "\tspeed: 0.0260s/iter; left time: 61.8300s\n",
      "\titers: 600, epoch: 3 | loss: 0.2650694\n",
      "\tspeed: 0.0235s/iter; left time: 53.6659s\n",
      "\titers: 700, epoch: 3 | loss: 0.1911796\n",
      "\tspeed: 0.0241s/iter; left time: 52.5699s\n",
      "Epoch: 3 cost time: 17.41433334350586\n",
      "Epoch: 3, Steps: 720 | Train Loss: 0.1899990 Vali Loss: 0.3100899 Test Loss: 0.2405716\n",
      "Validation loss decreased (0.312005 --> 0.310090).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1633185\n",
      "\tspeed: 0.0553s/iter; left time: 113.8896s\n",
      "\titers: 200, epoch: 4 | loss: 0.1150096\n",
      "\tspeed: 0.0227s/iter; left time: 44.6050s\n",
      "\titers: 300, epoch: 4 | loss: 0.2462060\n",
      "\tspeed: 0.0266s/iter; left time: 49.4730s\n",
      "\titers: 400, epoch: 4 | loss: 0.1506547\n",
      "\tspeed: 0.0242s/iter; left time: 42.6386s\n",
      "\titers: 500, epoch: 4 | loss: 0.1642515\n",
      "\tspeed: 0.0238s/iter; left time: 39.5990s\n",
      "\titers: 600, epoch: 4 | loss: 0.1605204\n",
      "\tspeed: 0.0227s/iter; left time: 35.4927s\n",
      "\titers: 700, epoch: 4 | loss: 0.2362583\n",
      "\tspeed: 0.0246s/iter; left time: 35.9751s\n",
      "Epoch: 4 cost time: 17.279119968414307\n",
      "Epoch: 4, Steps: 720 | Train Loss: 0.1757139 Vali Loss: 0.3001357 Test Loss: 0.2364456\n",
      "Validation loss decreased (0.310090 --> 0.300136).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1679163\n",
      "\tspeed: 0.0587s/iter; left time: 78.6839s\n",
      "\titers: 200, epoch: 5 | loss: 0.1145155\n",
      "\tspeed: 0.0237s/iter; left time: 29.3736s\n",
      "\titers: 300, epoch: 5 | loss: 0.2089812\n",
      "\tspeed: 0.0234s/iter; left time: 26.7169s\n",
      "\titers: 400, epoch: 5 | loss: 0.1079248\n",
      "\tspeed: 0.0229s/iter; left time: 23.8232s\n",
      "\titers: 500, epoch: 5 | loss: 0.1084166\n",
      "\tspeed: 0.0235s/iter; left time: 22.1464s\n",
      "\titers: 600, epoch: 5 | loss: 0.1518535\n",
      "\tspeed: 0.0234s/iter; left time: 19.6975s\n",
      "\titers: 700, epoch: 5 | loss: 0.2435581\n",
      "\tspeed: 0.0255s/iter; left time: 18.8685s\n",
      "Epoch: 5 cost time: 17.313013076782227\n",
      "Epoch: 5, Steps: 720 | Train Loss: 0.1678561 Vali Loss: 0.3053715 Test Loss: 0.2376169\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1465326\n",
      "\tspeed: 0.0550s/iter; left time: 34.1541s\n",
      "\titers: 200, epoch: 6 | loss: 0.1072532\n",
      "\tspeed: 0.0232s/iter; left time: 12.0921s\n",
      "\titers: 300, epoch: 6 | loss: 0.1336820\n",
      "\tspeed: 0.0233s/iter; left time: 9.8057s\n",
      "\titers: 400, epoch: 6 | loss: 0.1564688\n",
      "\tspeed: 0.0224s/iter; left time: 7.1912s\n",
      "\titers: 500, epoch: 6 | loss: 0.1207554\n",
      "\tspeed: 0.0257s/iter; left time: 5.6887s\n",
      "\titers: 600, epoch: 6 | loss: 0.1323140\n",
      "\tspeed: 0.0239s/iter; left time: 2.8978s\n",
      "\titers: 700, epoch: 6 | loss: 0.2394179\n",
      "\tspeed: 0.0233s/iter; left time: 0.4883s\n",
      "Epoch: 6 cost time: 17.03184986114502\n",
      "Epoch: 6, Steps: 720 | Train Loss: 0.1631672 Vali Loss: 0.3066655 Test Loss: 0.2421453\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "test shape: (198, 32, 6, 1) (198, 32, 6, 1)\n",
      "test shape: (6336, 6, 1) (6336, 6, 1)\n",
      "mse:0.23638813197612762, mae:0.32513144612312317\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24515\n",
      "[DEBUG] Original dataset length: 24515\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 23049\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3471\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.3071163\n",
      "\tspeed: 0.0241s/iter; left time: 101.7693s\n",
      "\titers: 200, epoch: 1 | loss: 0.5034093\n",
      "\tspeed: 0.0250s/iter; left time: 103.0428s\n",
      "\titers: 300, epoch: 1 | loss: 0.2262011\n",
      "\tspeed: 0.0240s/iter; left time: 96.3680s\n",
      "\titers: 400, epoch: 1 | loss: 0.1547288\n",
      "\tspeed: 0.0227s/iter; left time: 89.0232s\n",
      "\titers: 500, epoch: 1 | loss: 0.1631647\n",
      "\tspeed: 0.0239s/iter; left time: 91.4337s\n",
      "\titers: 600, epoch: 1 | loss: 0.2617444\n",
      "\tspeed: 0.0233s/iter; left time: 86.7008s\n",
      "\titers: 700, epoch: 1 | loss: 0.1376766\n",
      "\tspeed: 0.0236s/iter; left time: 85.5373s\n",
      "Epoch: 1 cost time: 17.21261477470398\n",
      "Epoch: 1, Steps: 720 | Train Loss: 0.2737829 Vali Loss: 0.3564964 Test Loss: 0.2835495\n",
      "Validation loss decreased (inf --> 0.356496).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3507326\n",
      "\tspeed: 0.0605s/iter; left time: 211.9484s\n",
      "\titers: 200, epoch: 2 | loss: 0.1652292\n",
      "\tspeed: 0.0217s/iter; left time: 73.8141s\n",
      "\titers: 300, epoch: 2 | loss: 0.1940800\n",
      "\tspeed: 0.0230s/iter; left time: 75.8832s\n",
      "\titers: 400, epoch: 2 | loss: 0.2061865\n",
      "\tspeed: 0.0227s/iter; left time: 72.7480s\n",
      "\titers: 500, epoch: 2 | loss: 0.2085552\n",
      "\tspeed: 0.0223s/iter; left time: 69.1431s\n",
      "\titers: 600, epoch: 2 | loss: 0.2442675\n",
      "\tspeed: 0.0242s/iter; left time: 72.5747s\n",
      "\titers: 700, epoch: 2 | loss: 0.2929775\n",
      "\tspeed: 0.0262s/iter; left time: 75.9539s\n",
      "Epoch: 2 cost time: 16.97954535484314\n",
      "Epoch: 2, Steps: 720 | Train Loss: 0.2121187 Vali Loss: 0.3398027 Test Loss: 0.2596527\n",
      "Validation loss decreased (0.356496 --> 0.339803).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2307704\n",
      "\tspeed: 0.0559s/iter; left time: 155.4623s\n",
      "\titers: 200, epoch: 3 | loss: 0.1934203\n",
      "\tspeed: 0.0232s/iter; left time: 62.2721s\n",
      "\titers: 300, epoch: 3 | loss: 0.2000226\n",
      "\tspeed: 0.0223s/iter; left time: 57.4332s\n",
      "\titers: 400, epoch: 3 | loss: 0.1387626\n",
      "\tspeed: 0.0231s/iter; left time: 57.4318s\n",
      "\titers: 500, epoch: 3 | loss: 0.1187599\n",
      "\tspeed: 0.0258s/iter; left time: 61.4191s\n",
      "\titers: 600, epoch: 3 | loss: 0.1866774\n",
      "\tspeed: 0.0246s/iter; left time: 56.0286s\n",
      "\titers: 700, epoch: 3 | loss: 0.1440395\n",
      "\tspeed: 0.0229s/iter; left time: 49.9372s\n",
      "Epoch: 3 cost time: 17.01282048225403\n",
      "Epoch: 3, Steps: 720 | Train Loss: 0.1874337 Vali Loss: 0.3090793 Test Loss: 0.2405153\n",
      "Validation loss decreased (0.339803 --> 0.309079).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2458078\n",
      "\tspeed: 0.0558s/iter; left time: 115.0507s\n",
      "\titers: 200, epoch: 4 | loss: 0.1530426\n",
      "\tspeed: 0.0236s/iter; left time: 46.3136s\n",
      "\titers: 300, epoch: 4 | loss: 0.3230697\n",
      "\tspeed: 0.0252s/iter; left time: 46.8283s\n",
      "\titers: 400, epoch: 4 | loss: 0.1044162\n",
      "\tspeed: 0.0243s/iter; left time: 42.8802s\n",
      "\titers: 500, epoch: 4 | loss: 0.1845640\n",
      "\tspeed: 0.0247s/iter; left time: 41.0033s\n",
      "\titers: 600, epoch: 4 | loss: 0.1818872\n",
      "\tspeed: 0.0240s/iter; left time: 37.4667s\n",
      "\titers: 700, epoch: 4 | loss: 0.1374330\n",
      "\tspeed: 0.0227s/iter; left time: 33.1377s\n",
      "Epoch: 4 cost time: 17.158348560333252\n",
      "Epoch: 4, Steps: 720 | Train Loss: 0.1746711 Vali Loss: 0.3117971 Test Loss: 0.2453005\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1922099\n",
      "\tspeed: 0.0565s/iter; left time: 75.7522s\n",
      "\titers: 200, epoch: 5 | loss: 0.1274997\n",
      "\tspeed: 0.0226s/iter; left time: 27.9909s\n",
      "\titers: 300, epoch: 5 | loss: 0.1125627\n",
      "\tspeed: 0.0233s/iter; left time: 26.6233s\n",
      "\titers: 400, epoch: 5 | loss: 0.2757673\n",
      "\tspeed: 0.0238s/iter; left time: 24.8218s\n",
      "\titers: 500, epoch: 5 | loss: 0.1284174\n",
      "\tspeed: 0.0256s/iter; left time: 24.0689s\n",
      "\titers: 600, epoch: 5 | loss: 0.1706811\n",
      "\tspeed: 0.0239s/iter; left time: 20.0968s\n",
      "\titers: 700, epoch: 5 | loss: 0.3813860\n",
      "\tspeed: 0.0238s/iter; left time: 17.6339s\n",
      "Epoch: 5 cost time: 17.319249153137207\n",
      "Epoch: 5, Steps: 720 | Train Loss: 0.1658485 Vali Loss: 0.3105138 Test Loss: 0.2417516\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1439434\n",
      "\tspeed: 0.0560s/iter; left time: 34.7929s\n",
      "\titers: 200, epoch: 6 | loss: 0.2216351\n",
      "\tspeed: 0.0223s/iter; left time: 11.5939s\n",
      "\titers: 300, epoch: 6 | loss: 0.1249258\n",
      "\tspeed: 0.0225s/iter; left time: 9.4583s\n",
      "\titers: 400, epoch: 6 | loss: 0.1557927\n",
      "\tspeed: 0.0227s/iter; left time: 7.2989s\n",
      "\titers: 500, epoch: 6 | loss: 0.1227410\n",
      "\tspeed: 0.0259s/iter; left time: 5.7170s\n",
      "\titers: 600, epoch: 6 | loss: 0.1737669\n",
      "\tspeed: 0.0244s/iter; left time: 2.9546s\n",
      "\titers: 700, epoch: 6 | loss: 0.1617851\n",
      "\tspeed: 0.0238s/iter; left time: 0.5004s\n",
      "Epoch: 6 cost time: 17.04420828819275\n",
      "Epoch: 6, Steps: 720 | Train Loss: 0.1607355 Vali Loss: 0.3084455 Test Loss: 0.2419737\n",
      "Validation loss decreased (0.309079 --> 0.308446).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "test shape: (198, 32, 6, 1) (198, 32, 6, 1)\n",
      "test shape: (6336, 6, 1) (6336, 6, 1)\n",
      "mse:0.2419135868549347, mae:0.3260083496570587\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24515\n",
      "[DEBUG] Original dataset length: 24515\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 23049\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3471\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.2059748\n",
      "\tspeed: 0.0236s/iter; left time: 99.7303s\n",
      "\titers: 200, epoch: 1 | loss: 0.1954982\n",
      "\tspeed: 0.0265s/iter; left time: 109.1824s\n",
      "\titers: 300, epoch: 1 | loss: 0.1743408\n",
      "\tspeed: 0.0247s/iter; left time: 99.1805s\n",
      "\titers: 400, epoch: 1 | loss: 0.2103713\n",
      "\tspeed: 0.0260s/iter; left time: 101.7788s\n",
      "\titers: 500, epoch: 1 | loss: 0.1245905\n",
      "\tspeed: 0.0228s/iter; left time: 87.1822s\n",
      "\titers: 600, epoch: 1 | loss: 0.2061691\n",
      "\tspeed: 0.0233s/iter; left time: 86.7309s\n",
      "\titers: 700, epoch: 1 | loss: 0.2565571\n",
      "\tspeed: 0.0243s/iter; left time: 88.1670s\n",
      "Epoch: 1 cost time: 17.616339445114136\n",
      "Epoch: 1, Steps: 720 | Train Loss: 0.2724949 Vali Loss: 0.3394293 Test Loss: 0.2676842\n",
      "Validation loss decreased (inf --> 0.339429).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3026431\n",
      "\tspeed: 0.0573s/iter; left time: 200.5760s\n",
      "\titers: 200, epoch: 2 | loss: 0.3262357\n",
      "\tspeed: 0.0219s/iter; left time: 74.3589s\n",
      "\titers: 300, epoch: 2 | loss: 0.2290073\n",
      "\tspeed: 0.0240s/iter; left time: 79.2607s\n",
      "\titers: 400, epoch: 2 | loss: 0.2025202\n",
      "\tspeed: 0.0235s/iter; left time: 75.1396s\n",
      "\titers: 500, epoch: 2 | loss: 0.2265947\n",
      "\tspeed: 0.0238s/iter; left time: 73.9208s\n",
      "\titers: 600, epoch: 2 | loss: 0.1889639\n",
      "\tspeed: 0.0237s/iter; left time: 71.0971s\n",
      "\titers: 700, epoch: 2 | loss: 0.1530723\n",
      "\tspeed: 0.0193s/iter; left time: 55.9506s\n",
      "Epoch: 2 cost time: 16.349448204040527\n",
      "Epoch: 2, Steps: 720 | Train Loss: 0.2146220 Vali Loss: 0.3249223 Test Loss: 0.2468786\n",
      "Validation loss decreased (0.339429 --> 0.324922).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1703833\n",
      "\tspeed: 0.0494s/iter; left time: 137.4422s\n",
      "\titers: 200, epoch: 3 | loss: 0.1572222\n",
      "\tspeed: 0.0258s/iter; left time: 69.1459s\n",
      "\titers: 300, epoch: 3 | loss: 0.1398219\n",
      "\tspeed: 0.0236s/iter; left time: 60.9976s\n",
      "\titers: 400, epoch: 3 | loss: 0.2299796\n",
      "\tspeed: 0.0245s/iter; left time: 60.7495s\n",
      "\titers: 500, epoch: 3 | loss: 0.2061773\n",
      "\tspeed: 0.0269s/iter; left time: 64.0489s\n",
      "\titers: 600, epoch: 3 | loss: 0.1656913\n",
      "\tspeed: 0.0245s/iter; left time: 55.8462s\n",
      "\titers: 700, epoch: 3 | loss: 0.1193287\n",
      "\tspeed: 0.0238s/iter; left time: 51.9485s\n",
      "Epoch: 3 cost time: 17.795034885406494\n",
      "Epoch: 3, Steps: 720 | Train Loss: 0.1880121 Vali Loss: 0.3181376 Test Loss: 0.2367450\n",
      "Validation loss decreased (0.324922 --> 0.318138).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1792495\n",
      "\tspeed: 0.0576s/iter; left time: 118.7518s\n",
      "\titers: 200, epoch: 4 | loss: 0.2177718\n",
      "\tspeed: 0.0235s/iter; left time: 45.9986s\n",
      "\titers: 300, epoch: 4 | loss: 0.1330509\n",
      "\tspeed: 0.0250s/iter; left time: 46.5415s\n",
      "\titers: 400, epoch: 4 | loss: 0.1563051\n",
      "\tspeed: 0.0227s/iter; left time: 39.9553s\n",
      "\titers: 500, epoch: 4 | loss: 0.1360454\n",
      "\tspeed: 0.0247s/iter; left time: 40.9492s\n",
      "\titers: 600, epoch: 4 | loss: 0.1376553\n",
      "\tspeed: 0.0235s/iter; left time: 36.7500s\n",
      "\titers: 700, epoch: 4 | loss: 0.1548767\n",
      "\tspeed: 0.0231s/iter; left time: 33.6840s\n",
      "Epoch: 4 cost time: 17.12531328201294\n",
      "Epoch: 4, Steps: 720 | Train Loss: 0.1736155 Vali Loss: 0.3210207 Test Loss: 0.2447865\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0808484\n",
      "\tspeed: 0.0535s/iter; left time: 71.7484s\n",
      "\titers: 200, epoch: 5 | loss: 0.1111788\n",
      "\tspeed: 0.0231s/iter; left time: 28.6831s\n",
      "\titers: 300, epoch: 5 | loss: 0.1852109\n",
      "\tspeed: 0.0236s/iter; left time: 26.8956s\n",
      "\titers: 400, epoch: 5 | loss: 0.1812759\n",
      "\tspeed: 0.0230s/iter; left time: 23.9880s\n",
      "\titers: 500, epoch: 5 | loss: 0.1148832\n",
      "\tspeed: 0.0228s/iter; left time: 21.4908s\n",
      "\titers: 600, epoch: 5 | loss: 0.3038372\n",
      "\tspeed: 0.0222s/iter; left time: 18.6713s\n",
      "\titers: 700, epoch: 5 | loss: 0.1060187\n",
      "\tspeed: 0.0232s/iter; left time: 17.2271s\n",
      "Epoch: 5 cost time: 16.617177724838257\n",
      "Epoch: 5, Steps: 720 | Train Loss: 0.1655815 Vali Loss: 0.3115149 Test Loss: 0.2394357\n",
      "Validation loss decreased (0.318138 --> 0.311515).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1280948\n",
      "\tspeed: 0.0577s/iter; left time: 35.8241s\n",
      "\titers: 200, epoch: 6 | loss: 0.1076520\n",
      "\tspeed: 0.0249s/iter; left time: 12.9696s\n",
      "\titers: 300, epoch: 6 | loss: 0.1413499\n",
      "\tspeed: 0.0229s/iter; left time: 9.6564s\n",
      "\titers: 400, epoch: 6 | loss: 0.1565866\n",
      "\tspeed: 0.0241s/iter; left time: 7.7317s\n",
      "\titers: 500, epoch: 6 | loss: 0.2270945\n",
      "\tspeed: 0.0244s/iter; left time: 5.3845s\n",
      "\titers: 600, epoch: 6 | loss: 0.1616884\n",
      "\tspeed: 0.0261s/iter; left time: 3.1587s\n",
      "\titers: 700, epoch: 6 | loss: 0.1429339\n",
      "\tspeed: 0.0233s/iter; left time: 0.4903s\n",
      "Epoch: 6 cost time: 17.40360426902771\n",
      "Epoch: 6, Steps: 720 | Train Loss: 0.1609860 Vali Loss: 0.3103566 Test Loss: 0.2375504\n",
      "Validation loss decreased (0.311515 --> 0.310357).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "test shape: (198, 32, 6, 1) (198, 32, 6, 1)\n",
      "test shape: (6336, 6, 1) (6336, 6, 1)\n",
      "mse:0.23780035972595215, mae:0.32267990708351135\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24515\n",
      "[DEBUG] Original dataset length: 24515\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 23049\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3471\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.4578329\n",
      "\tspeed: 0.0247s/iter; left time: 104.1329s\n",
      "\titers: 200, epoch: 1 | loss: 0.2111351\n",
      "\tspeed: 0.0245s/iter; left time: 100.9016s\n",
      "\titers: 300, epoch: 1 | loss: 0.3981436\n",
      "\tspeed: 0.0253s/iter; left time: 101.6326s\n",
      "\titers: 400, epoch: 1 | loss: 0.3082929\n",
      "\tspeed: 0.0238s/iter; left time: 93.4122s\n",
      "\titers: 500, epoch: 1 | loss: 0.2361353\n",
      "\tspeed: 0.0249s/iter; left time: 94.9868s\n",
      "\titers: 600, epoch: 1 | loss: 0.2644592\n",
      "\tspeed: 0.0233s/iter; left time: 86.6469s\n",
      "\titers: 700, epoch: 1 | loss: 0.1289656\n",
      "\tspeed: 0.0237s/iter; left time: 85.9159s\n",
      "Epoch: 1 cost time: 17.5069100856781\n",
      "Epoch: 1, Steps: 720 | Train Loss: 0.2705053 Vali Loss: 0.3204713 Test Loss: 0.2605867\n",
      "Validation loss decreased (inf --> 0.320471).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2325593\n",
      "\tspeed: 0.0573s/iter; left time: 200.5357s\n",
      "\titers: 200, epoch: 2 | loss: 0.1463608\n",
      "\tspeed: 0.0230s/iter; left time: 78.2571s\n",
      "\titers: 300, epoch: 2 | loss: 0.3331362\n",
      "\tspeed: 0.0228s/iter; left time: 75.3575s\n",
      "\titers: 400, epoch: 2 | loss: 0.1492515\n",
      "\tspeed: 0.0229s/iter; left time: 73.3935s\n",
      "\titers: 500, epoch: 2 | loss: 0.1766475\n",
      "\tspeed: 0.0228s/iter; left time: 70.7394s\n",
      "\titers: 600, epoch: 2 | loss: 0.1903193\n",
      "\tspeed: 0.0241s/iter; left time: 72.4445s\n",
      "\titers: 700, epoch: 2 | loss: 0.2207110\n",
      "\tspeed: 0.0262s/iter; left time: 76.1176s\n",
      "Epoch: 2 cost time: 17.223204851150513\n",
      "Epoch: 2, Steps: 720 | Train Loss: 0.2136158 Vali Loss: 0.3312358 Test Loss: 0.2584375\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1990218\n",
      "\tspeed: 0.0553s/iter; left time: 153.8132s\n",
      "\titers: 200, epoch: 3 | loss: 0.2775555\n",
      "\tspeed: 0.0243s/iter; left time: 65.1647s\n",
      "\titers: 300, epoch: 3 | loss: 0.2443474\n",
      "\tspeed: 0.0237s/iter; left time: 61.2735s\n",
      "\titers: 400, epoch: 3 | loss: 0.2300918\n",
      "\tspeed: 0.0244s/iter; left time: 60.5640s\n",
      "\titers: 500, epoch: 3 | loss: 0.0932035\n",
      "\tspeed: 0.0261s/iter; left time: 62.0662s\n",
      "\titers: 600, epoch: 3 | loss: 0.1481326\n",
      "\tspeed: 0.0238s/iter; left time: 54.3842s\n",
      "\titers: 700, epoch: 3 | loss: 0.1986964\n",
      "\tspeed: 0.0232s/iter; left time: 50.6872s\n",
      "Epoch: 3 cost time: 17.393672227859497\n",
      "Epoch: 3, Steps: 720 | Train Loss: 0.1860283 Vali Loss: 0.3183285 Test Loss: 0.2354692\n",
      "Validation loss decreased (0.320471 --> 0.318328).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1637353\n",
      "\tspeed: 0.0548s/iter; left time: 112.8612s\n",
      "\titers: 200, epoch: 4 | loss: 0.2963576\n",
      "\tspeed: 0.0232s/iter; left time: 45.4942s\n",
      "\titers: 300, epoch: 4 | loss: 0.2007066\n",
      "\tspeed: 0.0254s/iter; left time: 47.2511s\n",
      "\titers: 400, epoch: 4 | loss: 0.3307243\n",
      "\tspeed: 0.0235s/iter; left time: 41.3901s\n",
      "\titers: 500, epoch: 4 | loss: 0.1557188\n",
      "\tspeed: 0.0229s/iter; left time: 38.0987s\n",
      "\titers: 600, epoch: 4 | loss: 0.1112495\n",
      "\tspeed: 0.0224s/iter; left time: 35.0020s\n",
      "\titers: 700, epoch: 4 | loss: 0.1146738\n",
      "\tspeed: 0.0236s/iter; left time: 34.4462s\n",
      "Epoch: 4 cost time: 16.856013536453247\n",
      "Epoch: 4, Steps: 720 | Train Loss: 0.1725744 Vali Loss: 0.3008887 Test Loss: 0.2292674\n",
      "Validation loss decreased (0.318328 --> 0.300889).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1070238\n",
      "\tspeed: 0.0583s/iter; left time: 78.1924s\n",
      "\titers: 200, epoch: 5 | loss: 0.2752652\n",
      "\tspeed: 0.0227s/iter; left time: 28.2262s\n",
      "\titers: 300, epoch: 5 | loss: 0.1472278\n",
      "\tspeed: 0.0240s/iter; left time: 27.4338s\n",
      "\titers: 400, epoch: 5 | loss: 0.1674641\n",
      "\tspeed: 0.0235s/iter; left time: 24.4869s\n",
      "\titers: 500, epoch: 5 | loss: 0.1361873\n",
      "\tspeed: 0.0237s/iter; left time: 22.3405s\n",
      "\titers: 600, epoch: 5 | loss: 0.0890934\n",
      "\tspeed: 0.0236s/iter; left time: 19.8889s\n",
      "\titers: 700, epoch: 5 | loss: 0.1745538\n",
      "\tspeed: 0.0253s/iter; left time: 18.7719s\n",
      "Epoch: 5 cost time: 17.37479066848755\n",
      "Epoch: 5, Steps: 720 | Train Loss: 0.1632742 Vali Loss: 0.3172847 Test Loss: 0.2381064\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2128024\n",
      "\tspeed: 0.0548s/iter; left time: 34.0577s\n",
      "\titers: 200, epoch: 6 | loss: 0.1543780\n",
      "\tspeed: 0.0226s/iter; left time: 11.7833s\n",
      "\titers: 300, epoch: 6 | loss: 0.1338018\n",
      "\tspeed: 0.0228s/iter; left time: 9.6041s\n",
      "\titers: 400, epoch: 6 | loss: 0.1422574\n",
      "\tspeed: 0.0235s/iter; left time: 7.5335s\n",
      "\titers: 500, epoch: 6 | loss: 0.1185143\n",
      "\tspeed: 0.0274s/iter; left time: 6.0450s\n",
      "\titers: 600, epoch: 6 | loss: 0.1558020\n",
      "\tspeed: 0.0237s/iter; left time: 2.8653s\n",
      "\titers: 700, epoch: 6 | loss: 0.0899440\n",
      "\tspeed: 0.0235s/iter; left time: 0.4926s\n",
      "Epoch: 6 cost time: 17.198524475097656\n",
      "Epoch: 6, Steps: 720 | Train Loss: 0.1587123 Vali Loss: 0.3120169 Test Loss: 0.2358523\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "test shape: (198, 32, 6, 1) (198, 32, 6, 1)\n",
      "test shape: (6336, 6, 1) (6336, 6, 1)\n",
      "mse:0.23026296496391296, mae:0.32375892996788025\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24515\n",
      "[DEBUG] Original dataset length: 24515\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 23049\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3471\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.1291784\n",
      "\tspeed: 0.0238s/iter; left time: 100.6289s\n",
      "\titers: 200, epoch: 1 | loss: 0.1993904\n",
      "\tspeed: 0.0239s/iter; left time: 98.4481s\n",
      "\titers: 300, epoch: 1 | loss: 0.1938093\n",
      "\tspeed: 0.0225s/iter; left time: 90.2772s\n",
      "\titers: 400, epoch: 1 | loss: 0.3596997\n",
      "\tspeed: 0.0229s/iter; left time: 89.7972s\n",
      "\titers: 500, epoch: 1 | loss: 0.2266309\n",
      "\tspeed: 0.0248s/iter; left time: 94.7418s\n",
      "\titers: 600, epoch: 1 | loss: 0.2143608\n",
      "\tspeed: 0.0234s/iter; left time: 87.0842s\n",
      "\titers: 700, epoch: 1 | loss: 0.1972956\n",
      "\tspeed: 0.0260s/iter; left time: 94.1241s\n",
      "Epoch: 1 cost time: 17.26334524154663\n",
      "Epoch: 1, Steps: 720 | Train Loss: 0.2678564 Vali Loss: 0.3302181 Test Loss: 0.2511712\n",
      "Validation loss decreased (inf --> 0.330218).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1798728\n",
      "\tspeed: 0.0574s/iter; left time: 201.0889s\n",
      "\titers: 200, epoch: 2 | loss: 0.2697204\n",
      "\tspeed: 0.0240s/iter; left time: 81.5584s\n",
      "\titers: 300, epoch: 2 | loss: 0.1721526\n",
      "\tspeed: 0.0246s/iter; left time: 81.1629s\n",
      "\titers: 400, epoch: 2 | loss: 0.1880388\n",
      "\tspeed: 0.0255s/iter; left time: 81.5538s\n",
      "\titers: 500, epoch: 2 | loss: 0.3180417\n",
      "\tspeed: 0.0256s/iter; left time: 79.3137s\n",
      "\titers: 600, epoch: 2 | loss: 0.1789899\n",
      "\tspeed: 0.0252s/iter; left time: 75.5536s\n",
      "\titers: 700, epoch: 2 | loss: 0.2360747\n",
      "\tspeed: 0.0252s/iter; left time: 73.0153s\n",
      "Epoch: 2 cost time: 17.840253353118896\n",
      "Epoch: 2, Steps: 720 | Train Loss: 0.2155934 Vali Loss: 0.3066089 Test Loss: 0.2385401\n",
      "Validation loss decreased (0.330218 --> 0.306609).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2037715\n",
      "\tspeed: 0.0556s/iter; left time: 154.5387s\n",
      "\titers: 200, epoch: 3 | loss: 0.1709490\n",
      "\tspeed: 0.0253s/iter; left time: 67.8669s\n",
      "\titers: 300, epoch: 3 | loss: 0.1567327\n",
      "\tspeed: 0.0242s/iter; left time: 62.5863s\n",
      "\titers: 400, epoch: 3 | loss: 0.1781443\n",
      "\tspeed: 0.0252s/iter; left time: 62.5880s\n",
      "\titers: 500, epoch: 3 | loss: 0.1352906\n",
      "\tspeed: 0.0236s/iter; left time: 56.2733s\n",
      "\titers: 600, epoch: 3 | loss: 0.1724356\n",
      "\tspeed: 0.0251s/iter; left time: 57.1897s\n",
      "\titers: 700, epoch: 3 | loss: 0.1692714\n",
      "\tspeed: 0.0241s/iter; left time: 52.5271s\n",
      "Epoch: 3 cost time: 17.735650777816772\n",
      "Epoch: 3, Steps: 720 | Train Loss: 0.1882410 Vali Loss: 0.3229503 Test Loss: 0.2514442\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1584921\n",
      "\tspeed: 0.0547s/iter; left time: 112.8197s\n",
      "\titers: 200, epoch: 4 | loss: 0.1835104\n",
      "\tspeed: 0.0253s/iter; left time: 49.5225s\n",
      "\titers: 300, epoch: 4 | loss: 0.1619648\n",
      "\tspeed: 0.0254s/iter; left time: 47.3358s\n",
      "\titers: 400, epoch: 4 | loss: 0.2669598\n",
      "\tspeed: 0.0236s/iter; left time: 41.5124s\n",
      "\titers: 500, epoch: 4 | loss: 0.2020481\n",
      "\tspeed: 0.0234s/iter; left time: 38.8467s\n",
      "\titers: 600, epoch: 4 | loss: 0.2620074\n",
      "\tspeed: 0.0250s/iter; left time: 38.9676s\n",
      "\titers: 700, epoch: 4 | loss: 0.2026610\n",
      "\tspeed: 0.0231s/iter; left time: 33.7451s\n",
      "Epoch: 4 cost time: 17.362301349639893\n",
      "Epoch: 4, Steps: 720 | Train Loss: 0.1755995 Vali Loss: 0.3092225 Test Loss: 0.2407152\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1445642\n",
      "\tspeed: 0.0572s/iter; left time: 76.7030s\n",
      "\titers: 200, epoch: 5 | loss: 0.1165990\n",
      "\tspeed: 0.0210s/iter; left time: 26.0919s\n",
      "\titers: 300, epoch: 5 | loss: 0.1113235\n",
      "\tspeed: 0.0200s/iter; left time: 22.8530s\n",
      "\titers: 400, epoch: 5 | loss: 0.0993430\n",
      "\tspeed: 0.0210s/iter; left time: 21.8958s\n",
      "\titers: 500, epoch: 5 | loss: 0.1402998\n",
      "\tspeed: 0.0226s/iter; left time: 21.2726s\n",
      "\titers: 600, epoch: 5 | loss: 0.1048911\n",
      "\tspeed: 0.0224s/iter; left time: 18.8082s\n",
      "\titers: 700, epoch: 5 | loss: 0.1757006\n",
      "\tspeed: 0.0244s/iter; left time: 18.0895s\n",
      "Epoch: 5 cost time: 16.248567581176758\n",
      "Epoch: 5, Steps: 720 | Train Loss: 0.1670456 Vali Loss: 0.3120823 Test Loss: 0.2443690\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "test shape: (198, 32, 6, 1) (198, 32, 6, 1)\n",
      "test shape: (6336, 6, 1) (6336, 6, 1)\n",
      "mse:0.238310769200325, mae:0.330943763256073\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24515\n",
      "[DEBUG] Original dataset length: 24515\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 23049\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3471\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.2683886\n",
      "\tspeed: 0.0241s/iter; left time: 101.8477s\n",
      "\titers: 200, epoch: 1 | loss: 0.2588840\n",
      "\tspeed: 0.0235s/iter; left time: 96.9690s\n",
      "\titers: 300, epoch: 1 | loss: 0.3770875\n",
      "\tspeed: 0.0233s/iter; left time: 93.5516s\n",
      "\titers: 400, epoch: 1 | loss: 0.2448425\n",
      "\tspeed: 0.0240s/iter; left time: 94.1979s\n",
      "\titers: 500, epoch: 1 | loss: 0.2418103\n",
      "\tspeed: 0.0238s/iter; left time: 90.8827s\n",
      "\titers: 600, epoch: 1 | loss: 0.1492700\n",
      "\tspeed: 0.0244s/iter; left time: 90.6963s\n",
      "\titers: 700, epoch: 1 | loss: 0.2300760\n",
      "\tspeed: 0.0237s/iter; left time: 85.8418s\n",
      "Epoch: 1 cost time: 17.126222133636475\n",
      "Epoch: 1, Steps: 720 | Train Loss: 0.2741571 Vali Loss: 0.3267933 Test Loss: 0.2578641\n",
      "Validation loss decreased (inf --> 0.326793).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1890037\n",
      "\tspeed: 0.0554s/iter; left time: 194.0317s\n",
      "\titers: 200, epoch: 2 | loss: 0.1934032\n",
      "\tspeed: 0.0244s/iter; left time: 83.0149s\n",
      "\titers: 300, epoch: 2 | loss: 0.2694264\n",
      "\tspeed: 0.0266s/iter; left time: 87.8133s\n",
      "\titers: 400, epoch: 2 | loss: 0.3587272\n",
      "\tspeed: 0.0236s/iter; left time: 75.6114s\n",
      "\titers: 500, epoch: 2 | loss: 0.1936233\n",
      "\tspeed: 0.0239s/iter; left time: 74.0570s\n",
      "\titers: 600, epoch: 2 | loss: 0.3040264\n",
      "\tspeed: 0.0231s/iter; left time: 69.4341s\n",
      "\titers: 700, epoch: 2 | loss: 0.1201348\n",
      "\tspeed: 0.0239s/iter; left time: 69.4457s\n",
      "Epoch: 2 cost time: 17.388708353042603\n",
      "Epoch: 2, Steps: 720 | Train Loss: 0.2141066 Vali Loss: 0.3217953 Test Loss: 0.2517246\n",
      "Validation loss decreased (0.326793 --> 0.321795).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1783958\n",
      "\tspeed: 0.0575s/iter; left time: 159.9603s\n",
      "\titers: 200, epoch: 3 | loss: 0.1608051\n",
      "\tspeed: 0.0234s/iter; left time: 62.7736s\n",
      "\titers: 300, epoch: 3 | loss: 0.2279705\n",
      "\tspeed: 0.0234s/iter; left time: 60.4940s\n",
      "\titers: 400, epoch: 3 | loss: 0.2123446\n",
      "\tspeed: 0.0231s/iter; left time: 57.2786s\n",
      "\titers: 500, epoch: 3 | loss: 0.1771843\n",
      "\tspeed: 0.0240s/iter; left time: 57.1405s\n",
      "\titers: 600, epoch: 3 | loss: 0.1599601\n",
      "\tspeed: 0.0234s/iter; left time: 53.3071s\n",
      "\titers: 700, epoch: 3 | loss: 0.1236720\n",
      "\tspeed: 0.0263s/iter; left time: 57.3947s\n",
      "Epoch: 3 cost time: 17.448195457458496\n",
      "Epoch: 3, Steps: 720 | Train Loss: 0.1890722 Vali Loss: 0.3175762 Test Loss: 0.2476548\n",
      "Validation loss decreased (0.321795 --> 0.317576).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1743361\n",
      "\tspeed: 0.0599s/iter; left time: 123.4311s\n",
      "\titers: 200, epoch: 4 | loss: 0.1292496\n",
      "\tspeed: 0.0308s/iter; left time: 60.4343s\n",
      "\titers: 300, epoch: 4 | loss: 0.3106639\n",
      "\tspeed: 0.0258s/iter; left time: 48.0420s\n",
      "\titers: 400, epoch: 4 | loss: 0.1927088\n",
      "\tspeed: 0.0263s/iter; left time: 46.2867s\n",
      "\titers: 500, epoch: 4 | loss: 0.1483428\n",
      "\tspeed: 0.0251s/iter; left time: 41.7268s\n",
      "\titers: 600, epoch: 4 | loss: 0.3768055\n",
      "\tspeed: 0.0237s/iter; left time: 37.0721s\n",
      "\titers: 700, epoch: 4 | loss: 0.1375931\n",
      "\tspeed: 0.0240s/iter; left time: 35.0944s\n",
      "Epoch: 4 cost time: 18.74407172203064\n",
      "Epoch: 4, Steps: 720 | Train Loss: 0.1747900 Vali Loss: 0.3096836 Test Loss: 0.2405023\n",
      "Validation loss decreased (0.317576 --> 0.309684).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1735885\n",
      "\tspeed: 0.0545s/iter; left time: 73.0309s\n",
      "\titers: 200, epoch: 5 | loss: 0.1379042\n",
      "\tspeed: 0.0258s/iter; left time: 32.0071s\n",
      "\titers: 300, epoch: 5 | loss: 0.1420513\n",
      "\tspeed: 0.0236s/iter; left time: 26.9708s\n",
      "\titers: 400, epoch: 5 | loss: 0.1683416\n",
      "\tspeed: 0.0201s/iter; left time: 20.9225s\n",
      "\titers: 500, epoch: 5 | loss: 0.1237093\n",
      "\tspeed: 0.0228s/iter; left time: 21.4315s\n",
      "\titers: 600, epoch: 5 | loss: 0.2550951\n",
      "\tspeed: 0.0230s/iter; left time: 19.3697s\n",
      "\titers: 700, epoch: 5 | loss: 0.2528846\n",
      "\tspeed: 0.0223s/iter; left time: 16.5543s\n",
      "Epoch: 5 cost time: 16.600220203399658\n",
      "Epoch: 5, Steps: 720 | Train Loss: 0.1665494 Vali Loss: 0.3024839 Test Loss: 0.2386574\n",
      "Validation loss decreased (0.309684 --> 0.302484).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1913895\n",
      "\tspeed: 0.0587s/iter; left time: 36.4693s\n",
      "\titers: 200, epoch: 6 | loss: 0.2065820\n",
      "\tspeed: 0.0235s/iter; left time: 12.2632s\n",
      "\titers: 300, epoch: 6 | loss: 0.2183142\n",
      "\tspeed: 0.0238s/iter; left time: 10.0247s\n",
      "\titers: 400, epoch: 6 | loss: 0.1140192\n",
      "\tspeed: 0.0235s/iter; left time: 7.5433s\n",
      "\titers: 500, epoch: 6 | loss: 0.1808618\n",
      "\tspeed: 0.0225s/iter; left time: 4.9766s\n",
      "\titers: 600, epoch: 6 | loss: 0.1223793\n",
      "\tspeed: 0.0244s/iter; left time: 2.9486s\n",
      "\titers: 700, epoch: 6 | loss: 0.1453043\n",
      "\tspeed: 0.0253s/iter; left time: 0.5309s\n",
      "Epoch: 6 cost time: 17.289628982543945\n",
      "Epoch: 6, Steps: 720 | Train Loss: 0.1612875 Vali Loss: 0.3047495 Test Loss: 0.2417872\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "test shape: (198, 32, 6, 1) (198, 32, 6, 1)\n",
      "test shape: (6336, 6, 1) (6336, 6, 1)\n",
      "mse:0.23814715445041656, mae:0.32021334767341614\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24515\n",
      "[DEBUG] Original dataset length: 24515\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 23049\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3471\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.2685397\n",
      "\tspeed: 0.0229s/iter; left time: 96.6283s\n",
      "\titers: 200, epoch: 1 | loss: 0.2427007\n",
      "\tspeed: 0.0234s/iter; left time: 96.2481s\n",
      "\titers: 300, epoch: 1 | loss: 0.1777392\n",
      "\tspeed: 0.0229s/iter; left time: 91.9729s\n",
      "\titers: 400, epoch: 1 | loss: 0.2178479\n",
      "\tspeed: 0.0257s/iter; left time: 100.6257s\n",
      "\titers: 500, epoch: 1 | loss: 0.1854644\n",
      "\tspeed: 0.0229s/iter; left time: 87.3561s\n",
      "\titers: 600, epoch: 1 | loss: 0.3584431\n",
      "\tspeed: 0.0232s/iter; left time: 86.2573s\n",
      "\titers: 700, epoch: 1 | loss: 0.1928051\n",
      "\tspeed: 0.0227s/iter; left time: 82.2160s\n",
      "Epoch: 1 cost time: 16.857258081436157\n",
      "Epoch: 1, Steps: 720 | Train Loss: 0.2671343 Vali Loss: 0.4639954 Test Loss: 0.3859298\n",
      "Validation loss decreased (inf --> 0.463995).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1811827\n",
      "\tspeed: 0.0575s/iter; left time: 201.3161s\n",
      "\titers: 200, epoch: 2 | loss: 0.2820339\n",
      "\tspeed: 0.0242s/iter; left time: 82.3705s\n",
      "\titers: 300, epoch: 2 | loss: 0.2784422\n",
      "\tspeed: 0.0256s/iter; left time: 84.4680s\n",
      "\titers: 400, epoch: 2 | loss: 0.3101525\n",
      "\tspeed: 0.0249s/iter; left time: 79.6268s\n",
      "\titers: 500, epoch: 2 | loss: 0.1977684\n",
      "\tspeed: 0.0224s/iter; left time: 69.3729s\n",
      "\titers: 600, epoch: 2 | loss: 0.2624440\n",
      "\tspeed: 0.0217s/iter; left time: 65.0911s\n",
      "\titers: 700, epoch: 2 | loss: 0.2554734\n",
      "\tspeed: 0.0237s/iter; left time: 68.8871s\n",
      "Epoch: 2 cost time: 17.03831720352173\n",
      "Epoch: 2, Steps: 720 | Train Loss: 0.2152804 Vali Loss: 0.3138038 Test Loss: 0.2430142\n",
      "Validation loss decreased (0.463995 --> 0.313804).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2472371\n",
      "\tspeed: 0.0591s/iter; left time: 164.4173s\n",
      "\titers: 200, epoch: 3 | loss: 0.1634597\n",
      "\tspeed: 0.0233s/iter; left time: 62.5044s\n",
      "\titers: 300, epoch: 3 | loss: 0.1243721\n",
      "\tspeed: 0.0237s/iter; left time: 61.1809s\n",
      "\titers: 400, epoch: 3 | loss: 0.2265098\n",
      "\tspeed: 0.0235s/iter; left time: 58.3822s\n",
      "\titers: 500, epoch: 3 | loss: 0.2528743\n",
      "\tspeed: 0.0242s/iter; left time: 57.5746s\n",
      "\titers: 600, epoch: 3 | loss: 0.1198649\n",
      "\tspeed: 0.0233s/iter; left time: 53.1915s\n",
      "\titers: 700, epoch: 3 | loss: 0.2673798\n",
      "\tspeed: 0.0255s/iter; left time: 55.5228s\n",
      "Epoch: 3 cost time: 17.248652935028076\n",
      "Epoch: 3, Steps: 720 | Train Loss: 0.1867603 Vali Loss: 0.3220206 Test Loss: 0.2470238\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1878309\n",
      "\tspeed: 0.0545s/iter; left time: 112.3482s\n",
      "\titers: 200, epoch: 4 | loss: 0.1064389\n",
      "\tspeed: 0.0236s/iter; left time: 46.2558s\n",
      "\titers: 300, epoch: 4 | loss: 0.1343601\n",
      "\tspeed: 0.0256s/iter; left time: 47.7331s\n",
      "\titers: 400, epoch: 4 | loss: 0.1291682\n",
      "\tspeed: 0.0231s/iter; left time: 40.7660s\n",
      "\titers: 500, epoch: 4 | loss: 0.0980174\n",
      "\tspeed: 0.0244s/iter; left time: 40.4467s\n",
      "\titers: 600, epoch: 4 | loss: 0.1132647\n",
      "\tspeed: 0.0231s/iter; left time: 36.0624s\n",
      "\titers: 700, epoch: 4 | loss: 0.2431865\n",
      "\tspeed: 0.0226s/iter; left time: 33.0479s\n",
      "Epoch: 4 cost time: 17.13474464416504\n",
      "Epoch: 4, Steps: 720 | Train Loss: 0.1735157 Vali Loss: 0.3098180 Test Loss: 0.2353800\n",
      "Validation loss decreased (0.313804 --> 0.309818).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1102509\n",
      "\tspeed: 0.0564s/iter; left time: 75.6529s\n",
      "\titers: 200, epoch: 5 | loss: 0.2363766\n",
      "\tspeed: 0.0237s/iter; left time: 29.3715s\n",
      "\titers: 300, epoch: 5 | loss: 0.1769781\n",
      "\tspeed: 0.0239s/iter; left time: 27.2557s\n",
      "\titers: 400, epoch: 5 | loss: 0.1312560\n",
      "\tspeed: 0.0249s/iter; left time: 25.9549s\n",
      "\titers: 500, epoch: 5 | loss: 0.0942353\n",
      "\tspeed: 0.0234s/iter; left time: 22.0355s\n",
      "\titers: 600, epoch: 5 | loss: 0.1409826\n",
      "\tspeed: 0.0227s/iter; left time: 19.0780s\n",
      "\titers: 700, epoch: 5 | loss: 0.1492831\n",
      "\tspeed: 0.0225s/iter; left time: 16.6766s\n",
      "Epoch: 5 cost time: 16.86708402633667\n",
      "Epoch: 5, Steps: 720 | Train Loss: 0.1650715 Vali Loss: 0.3183907 Test Loss: 0.2407538\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1078552\n",
      "\tspeed: 0.0566s/iter; left time: 35.1638s\n",
      "\titers: 200, epoch: 6 | loss: 0.0994551\n",
      "\tspeed: 0.0231s/iter; left time: 12.0330s\n",
      "\titers: 300, epoch: 6 | loss: 0.1310085\n",
      "\tspeed: 0.0233s/iter; left time: 9.8112s\n",
      "\titers: 400, epoch: 6 | loss: 0.1091822\n",
      "\tspeed: 0.0229s/iter; left time: 7.3468s\n",
      "\titers: 500, epoch: 6 | loss: 0.0920690\n",
      "\tspeed: 0.0229s/iter; left time: 5.0542s\n",
      "\titers: 600, epoch: 6 | loss: 0.1492889\n",
      "\tspeed: 0.0223s/iter; left time: 2.6939s\n",
      "\titers: 700, epoch: 6 | loss: 0.1619511\n",
      "\tspeed: 0.0252s/iter; left time: 0.5302s\n",
      "Epoch: 6 cost time: 17.12031364440918\n",
      "Epoch: 6, Steps: 720 | Train Loss: 0.1607007 Vali Loss: 0.3108002 Test Loss: 0.2395890\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "test shape: (198, 32, 6, 1) (198, 32, 6, 1)\n",
      "test shape: (6336, 6, 1) (6336, 6, 1)\n",
      "mse:0.23485557734966278, mae:0.3203998804092407\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 24515\n",
      "[DEBUG] Original dataset length: 24515\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 23049\n",
      "val 3503\n",
      "[DEBUG] Original dataset length: 3503\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 3471\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.2074102\n",
      "\tspeed: 0.0252s/iter; left time: 106.3391s\n",
      "\titers: 200, epoch: 1 | loss: 0.2697378\n",
      "\tspeed: 0.0251s/iter; left time: 103.5805s\n",
      "\titers: 300, epoch: 1 | loss: 0.1507512\n",
      "\tspeed: 0.0239s/iter; left time: 96.2459s\n",
      "\titers: 400, epoch: 1 | loss: 0.2134534\n",
      "\tspeed: 0.0267s/iter; left time: 104.6102s\n",
      "\titers: 500, epoch: 1 | loss: 0.3309615\n",
      "\tspeed: 0.0233s/iter; left time: 89.1246s\n",
      "\titers: 600, epoch: 1 | loss: 0.1689638\n",
      "\tspeed: 0.0246s/iter; left time: 91.6149s\n",
      "\titers: 700, epoch: 1 | loss: 0.2330860\n",
      "\tspeed: 0.0230s/iter; left time: 83.1058s\n",
      "Epoch: 1 cost time: 17.672752618789673\n",
      "Epoch: 1, Steps: 720 | Train Loss: 0.2676648 Vali Loss: 0.3461914 Test Loss: 0.2673318\n",
      "Validation loss decreased (inf --> 0.346191).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1685184\n",
      "\tspeed: 0.0534s/iter; left time: 187.0007s\n",
      "\titers: 200, epoch: 2 | loss: 0.2090652\n",
      "\tspeed: 0.0265s/iter; left time: 90.0868s\n",
      "\titers: 300, epoch: 2 | loss: 0.3066219\n",
      "\tspeed: 0.0224s/iter; left time: 73.9798s\n",
      "\titers: 400, epoch: 2 | loss: 0.2679713\n",
      "\tspeed: 0.0235s/iter; left time: 75.1439s\n",
      "\titers: 500, epoch: 2 | loss: 0.0997327\n",
      "\tspeed: 0.0233s/iter; left time: 72.2926s\n",
      "\titers: 600, epoch: 2 | loss: 0.1763743\n",
      "\tspeed: 0.0238s/iter; left time: 71.3121s\n",
      "\titers: 700, epoch: 2 | loss: 0.1455908\n",
      "\tspeed: 0.0225s/iter; left time: 65.2622s\n",
      "Epoch: 2 cost time: 16.914092540740967\n",
      "Epoch: 2, Steps: 720 | Train Loss: 0.2121029 Vali Loss: 0.3240771 Test Loss: 0.2472197\n",
      "Validation loss decreased (0.346191 --> 0.324077).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1435582\n",
      "\tspeed: 0.0574s/iter; left time: 159.6198s\n",
      "\titers: 200, epoch: 3 | loss: 0.1259545\n",
      "\tspeed: 0.0237s/iter; left time: 63.6189s\n",
      "\titers: 300, epoch: 3 | loss: 0.1348708\n",
      "\tspeed: 0.0231s/iter; left time: 59.6781s\n",
      "\titers: 400, epoch: 3 | loss: 0.1899631\n",
      "\tspeed: 0.0236s/iter; left time: 58.6560s\n",
      "\titers: 500, epoch: 3 | loss: 0.2077998\n",
      "\tspeed: 0.0242s/iter; left time: 57.6477s\n",
      "\titers: 600, epoch: 3 | loss: 0.1664147\n",
      "\tspeed: 0.0244s/iter; left time: 55.5646s\n",
      "\titers: 700, epoch: 3 | loss: 0.2062315\n",
      "\tspeed: 0.0257s/iter; left time: 56.0264s\n",
      "Epoch: 3 cost time: 17.334754705429077\n",
      "Epoch: 3, Steps: 720 | Train Loss: 0.1872627 Vali Loss: 0.3143521 Test Loss: 0.2416429\n",
      "Validation loss decreased (0.324077 --> 0.314352).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1808510\n",
      "\tspeed: 0.0554s/iter; left time: 114.1753s\n",
      "\titers: 200, epoch: 4 | loss: 0.1533660\n",
      "\tspeed: 0.0238s/iter; left time: 46.7246s\n",
      "\titers: 300, epoch: 4 | loss: 0.0869979\n",
      "\tspeed: 0.0242s/iter; left time: 45.0722s\n",
      "\titers: 400, epoch: 4 | loss: 0.2366900\n",
      "\tspeed: 0.0248s/iter; left time: 43.6100s\n",
      "\titers: 500, epoch: 4 | loss: 0.1097011\n",
      "\tspeed: 0.0245s/iter; left time: 40.7729s\n",
      "\titers: 600, epoch: 4 | loss: 0.2135506\n",
      "\tspeed: 0.0230s/iter; left time: 35.8863s\n",
      "\titers: 700, epoch: 4 | loss: 0.1979732\n",
      "\tspeed: 0.0229s/iter; left time: 33.4025s\n",
      "Epoch: 4 cost time: 17.1416757106781\n",
      "Epoch: 4, Steps: 720 | Train Loss: 0.1725615 Vali Loss: 0.3081200 Test Loss: 0.2411018\n",
      "Validation loss decreased (0.314352 --> 0.308120).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1130778\n",
      "\tspeed: 0.0564s/iter; left time: 75.5662s\n",
      "\titers: 200, epoch: 5 | loss: 0.1846815\n",
      "\tspeed: 0.0246s/iter; left time: 30.5525s\n",
      "\titers: 300, epoch: 5 | loss: 0.1739918\n",
      "\tspeed: 0.0245s/iter; left time: 27.9820s\n",
      "\titers: 400, epoch: 5 | loss: 0.0994657\n",
      "\tspeed: 0.0240s/iter; left time: 24.9857s\n",
      "\titers: 500, epoch: 5 | loss: 0.1692343\n",
      "\tspeed: 0.0222s/iter; left time: 20.9176s\n",
      "\titers: 600, epoch: 5 | loss: 0.1572670\n",
      "\tspeed: 0.0236s/iter; left time: 19.8340s\n",
      "\titers: 700, epoch: 5 | loss: 0.1712834\n",
      "\tspeed: 0.0230s/iter; left time: 17.0680s\n",
      "Epoch: 5 cost time: 17.059751987457275\n",
      "Epoch: 5, Steps: 720 | Train Loss: 0.1658952 Vali Loss: 0.3107046 Test Loss: 0.2411914\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1114350\n",
      "\tspeed: 0.0573s/iter; left time: 35.5689s\n",
      "\titers: 200, epoch: 6 | loss: 0.1217583\n",
      "\tspeed: 0.0240s/iter; left time: 12.5150s\n",
      "\titers: 300, epoch: 6 | loss: 0.1336683\n",
      "\tspeed: 0.0229s/iter; left time: 9.6287s\n",
      "\titers: 400, epoch: 6 | loss: 0.1235241\n",
      "\tspeed: 0.0226s/iter; left time: 7.2678s\n",
      "\titers: 500, epoch: 6 | loss: 0.2103501\n",
      "\tspeed: 0.0241s/iter; left time: 5.3298s\n",
      "\titers: 600, epoch: 6 | loss: 0.1707033\n",
      "\tspeed: 0.0248s/iter; left time: 2.9982s\n",
      "\titers: 700, epoch: 6 | loss: 0.1202469\n",
      "\tspeed: 0.0257s/iter; left time: 0.5406s\n",
      "Epoch: 6 cost time: 17.408786296844482\n",
      "Epoch: 6, Steps: 720 | Train Loss: 0.1600319 Vali Loss: 0.3070957 Test Loss: 0.2396249\n",
      "Validation loss decreased (0.308120 --> 0.307096).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "test shape: (198, 32, 6, 1) (198, 32, 6, 1)\n",
      "test shape: (6336, 6, 1) (6336, 6, 1)\n",
      "mse:0.24011148512363434, mae:0.3262006342411041\n"
     ]
    }
   ],
   "source": [
    "!python -u main_informer.py --model informer --data traffic_full --root_path ../ --features S --seq_len 24 --label_len 24 --pred_len 6 --e_layers 2 --d_layers 1 --attn prob --des 'Exp' --itr 10 #--inverse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783e5d81-4226-4458-b558-06049f1da0f6",
   "metadata": {},
   "source": [
    "## Get the prediction results and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc6047d2-d947-4693-9a79-df6718d97852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_results(setting, args):\n",
    "    \"\"\"\n",
    "    Convert saved scaled predictions (pred.npy, true.npy) back to original scale.\n",
    "    \"\"\"\n",
    "    # Load stored pred & true\n",
    "    result_path = f'./results/{setting}/'\n",
    "    preds = np.load(result_path + 'pred.npy')\n",
    "    trues = np.load(result_path + 'true.npy')\n",
    "\n",
    "    # Rebuild the dataset to recover the SCALER\n",
    "    # We rebuild Dataset_Custom ONLY to access its scaler;\n",
    "    dataset = Dataset_Custom(\n",
    "        root_path=args.root_path,\n",
    "        data_path=args.data_path,\n",
    "        flag='train',                    # scaler is fit on TRAIN SPLIT\n",
    "        size=[args.seq_len, args.label_len, args.pred_len],\n",
    "        features=args.features,\n",
    "        target=args.target,\n",
    "        scale=True,\n",
    "        inverse=False,\n",
    "        timeenc=0,\n",
    "        freq=args.freq,\n",
    "        cols=args.cols\n",
    "    )\n",
    "\n",
    "    scaler = dataset.scaler  # this is the original scaler used during training\n",
    "\n",
    "    # Apply inverse scaling: reshape  inverse  reshape back\n",
    "    def _inverse(x):\n",
    "        orig_shape = x.shape\n",
    "        x2 = x.reshape(-1, orig_shape[-1])    # 2D for StandardScaler\n",
    "        x2 = scaler.inverse_transform(x2)\n",
    "        return x2.reshape(orig_shape)\n",
    "\n",
    "    preds_inv = _inverse(preds)\n",
    "    trues_inv = _inverse(trues)\n",
    "\n",
    "    # Calculate metrics on ORIGINAL scale\n",
    "    mae, mse, rmse, mape, mspe = metric(preds_inv, trues_inv)\n",
    "\n",
    "    # Save inverse results\n",
    "    np.save(result_path + 'pred_inverse.npy', preds_inv)\n",
    "    np.save(result_path + 'true_inverse.npy', trues_inv)\n",
    "    np.save(result_path + 'metrics_inverse.npy', np.array([mae, mse, rmse, mape, mspe]))\n",
    "\n",
    "    print(\" Inverse transformation complete\")\n",
    "    print(\"=== Inverse Scale Metrics ===\")\n",
    "    print(f\"MSE:  {mse}\")\n",
    "    print(f\"MAE:  {mae}\")\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    print(f\"MAPE: {mape}\")\n",
    "    print(f\"MSPE: {mspe}\")\n",
    "\n",
    "    return preds_inv, trues_inv, (mae, mse, rmse, mape, mspe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "86ac2778-aac2-4a8a-9b14-6996539e0849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1669.9002685546875\n",
      "MAE:  27.648347854614258\n",
      "RMSE: 40.86441421508789\n",
      "MAPE: 0.3588350713253021\n",
      "MSPE: 0.6333627700805664\n"
     ]
    }
   ],
   "source": [
    "# Recreate args from the experiment\n",
    "args = Namespace(\n",
    "    root_path=\"../\",\n",
    "    data_path=\"traffic_full.csv\",\n",
    "    seq_len=24,\n",
    "    label_len=24,\n",
    "    pred_len=6,\n",
    "    features=\"S\",\n",
    "    target=\"flow\",\n",
    "    freq='h',\n",
    "    cols=None\n",
    ")\n",
    "\n",
    "setting = \"informer_traffic_full_ftS_sl24_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0\"\n",
    "\n",
    "preds_inv, trues_inv, metrics_inv = inverse_results(setting, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b9a808-f64c-43f8-b7da-2d46bae22c53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "transformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
