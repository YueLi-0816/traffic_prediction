{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67f7f33-1987-4932-9803-883ede914b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/zhouhaoyi/Informer2020.git\n",
    "#!git clone https://github.com/zhouhaoyi/ETDataset.git\n",
    "# modify the code based on my dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e4301a-419a-40b0-98e8-eea762441e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !{sys.executable} -m pip install matplotlib\n",
    "# !{sys.executable} -m pip install pandas\n",
    "# !{sys.executable} -m pip install scikit_learn\n",
    "# !{sys.executable} -m pip install torch\n",
    "# !{sys.executable} -m pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb6cc0a2-7f97-4bc2-b439-c7b775a9cd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from argparse import Namespace\n",
    "import re\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    root_mean_squared_error,\n",
    "    mean_absolute_percentage_error\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60a07922-9f8e-44bb-825a-b576a86a90e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not 'Informer2020' in sys.path:\n",
    "    sys.path += ['Informer2020']\n",
    "\n",
    "from data.data_loader import Dataset_Custom\n",
    "from utils.metrics import metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd148590-d5a3-4a2b-afa4-77b77d84a671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cu128\n",
      "12.8\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6373961a-d2b9-4fbb-96a5-9ad2c3fbdc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 1\n",
      "GPU 0: NVIDIA A30\n"
     ]
    }
   ],
   "source": [
    "num_gpus = torch.cuda.device_count()\n",
    "print(\"Number of GPUs available:\", num_gpus)\n",
    "\n",
    "for i in range(num_gpus):\n",
    "    gpu_name = torch.cuda.get_device_name(i)\n",
    "    print(f\"GPU {i}: {gpu_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd1c08a-8be5-4e5c-a69c-b838fc3803d5",
   "metadata": {},
   "source": [
    "## 1. Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d5eb9c8-e5e9-43e4-b287-564297d0b25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = pd.read_csv('../GD030A_S.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e02c837f-f057-48fc-ad77-aa5d7c99d36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the recover_timestamp function\n",
    "def recover_timestamp(data):\n",
    "    # Combine 'date' and 'time' to form a datetime column\n",
    "    data['datetime'] = pd.to_datetime(data['date'] + ' ' + data['time'].astype(str) + ':00', format='%Y-%m-%d %H:%M')\n",
    "\n",
    "    # Set 'datetime' as index\n",
    "    data = data.set_index('datetime')\n",
    "\n",
    "    # Create a complete range of timestamps with hourly frequency\n",
    "    full_time_range = pd.date_range(start=data.index.min(), end=data.index.max(), freq='H')\n",
    "\n",
    "    # Reindex the data to include all timestamps, filling missing rows with NaN\n",
    "    data_full = data.reindex(full_time_range)\n",
    "\n",
    "    return data_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fb2e9e-0912-4c8a-8ccd-bca7f1fc91d9",
   "metadata": {},
   "source": [
    "Custom data (xxx.csv) has to include at least 2 features: date(format: YYYY-MM-DD hh:mm:ss) and target feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fa5669-e577-40ea-9c59-6e998abacda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_full = recover_timestamp(my_data)\n",
    "traffic_full.drop(['date', 'time'], axis=1, inplace=True)\n",
    "traffic_full = traffic_full.reset_index(names='date')\n",
    "traffic_full['date'] = traffic_full['date'].astype(str)\n",
    "traffic_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e64353-3a50-4922-b0ae-81f1f592c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#traffic_full.to_csv('traffic_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d99f3419-cdc6-43b7-8dfd-ba258dc9d745",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# after covid data\n",
    "traffic_full = pd.read_csv('../traffic_full.csv')\n",
    "traffic_full\n",
    "traffic_after_covid = traffic_full.loc[traffic_full[traffic_full['date'] == '2022-06-03 00:00:00'].index[0]:]\n",
    "traffic_after_covid = traffic_after_covid.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2ebd29df-5d60-447f-8794-473986ee8a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#traffic_after_covid.to_csv('../traffic_after_covid.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04616932-2190-4b35-bceb-1bf11fa3e582",
   "metadata": {},
   "source": [
    "## 2. Run training directly using bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6890335e-1970-46ea-a2f0-9f3a9fb4938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure the shell commands below using the current Python environment\n",
    "os.environ[\"PATH\"] = f\"{sys.prefix}/bin:\" + os.environ[\"PATH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adf9133b-3e63-4228-8340-98bc089bf852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yl2672496l/Yue/code/transformer/Informer2020\n"
     ]
    }
   ],
   "source": [
    "cd Informer2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05ce82bd-438d-4fec-b166-87b2984ae0f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test\n",
    "# !python -u main_informer.py --model informer --data traffic_after_covid --root_path ../ --features S --seq_len 24 --label_len 24 --pred_len 6 --e_layers 2 --d_layers 1 --attn prob --des 'Exp' --itr 1 #--inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "297f6900-cd2b-4569-8ef9-4b2e4dd2b144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24, 48, 72, 96, 120, 144, 168, 192, 216, 240, 264, 288, 312, 336, 360, 384, 408, 432, 456, 480, 504]\n"
     ]
    }
   ],
   "source": [
    "seq_lens = [24 * i for i in range(1, 22)]\n",
    "print(seq_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c204d504-9a4c-489b-9c24-c4cfe2d2e711",
   "metadata": {},
   "source": [
    "### Train and test the model with different label_len\n",
    "results1 with lable_len == 24, results with label_len == max(pred_len, seq_len // 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e213ceb9-8419-40a5-aec8-1a7486102607",
   "metadata": {},
   "source": [
    "#### Entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97623185-1858-4ecd-99d3-bb9f6ff19c6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running seq_len=24, label_len=8, pred_len=6\n",
      "Args in experiment:\n",
      "Namespace(model='informer', data='traffic_full', root_path='../', data_path='traffic_full.csv', features='S', target='flow', freq='h', checkpoints='./checkpoints/', seq_len=24, label_len=8, pred_len=6, enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=2, d_layers=1, s_layers=[3, 2, 1], d_ff=2048, factor=5, padding=0, distil=True, dropout=0.05, attn='prob', embed='timeF', activation='gelu', output_attention=False, do_predict=False, mix=True, cols=None, num_workers=0, itr=10, train_epochs=20, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, inverse=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', detail_freq='h')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll8_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 21009\n",
      "[DEBUG] Original dataset length: 21009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19676\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6844\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.4133257\n",
      "\tspeed: 0.0437s/iter; left time: 532.3442s\n",
      "\titers: 200, epoch: 1 | loss: 0.1856654\n",
      "\tspeed: 0.0251s/iter; left time: 303.8327s\n",
      "\titers: 300, epoch: 1 | loss: 0.2909093\n",
      "\tspeed: 0.0256s/iter; left time: 306.5079s\n",
      "\titers: 400, epoch: 1 | loss: 0.3488759\n",
      "\tspeed: 0.0245s/iter; left time: 291.5010s\n",
      "\titers: 500, epoch: 1 | loss: 0.1887966\n",
      "\tspeed: 0.0237s/iter; left time: 278.7711s\n",
      "\titers: 600, epoch: 1 | loss: 0.1687151\n",
      "\tspeed: 0.0249s/iter; left time: 291.1612s\n",
      "Epoch: 1 cost time: 16.13381052017212\n",
      "Epoch: 1, Steps: 614 | Train Loss: 0.2626308 Vali Loss: 0.2057098 Test Loss: 0.2387542\n",
      "Validation loss decreased (inf --> 0.205710).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1565392\n",
      "\tspeed: 0.0674s/iter; left time: 779.3766s\n",
      "\titers: 200, epoch: 2 | loss: 0.1613380\n",
      "\tspeed: 0.0247s/iter; left time: 283.0433s\n",
      "\titers: 300, epoch: 2 | loss: 0.1335036\n",
      "\tspeed: 0.0256s/iter; left time: 291.0171s\n",
      "\titers: 400, epoch: 2 | loss: 0.1422512\n",
      "\tspeed: 0.0240s/iter; left time: 269.8745s\n",
      "\titers: 500, epoch: 2 | loss: 0.1251063\n",
      "\tspeed: 0.0254s/iter; left time: 283.9941s\n",
      "\titers: 600, epoch: 2 | loss: 0.1664351\n",
      "\tspeed: 0.0270s/iter; left time: 298.6592s\n",
      "Epoch: 2 cost time: 15.493425846099854\n",
      "Epoch: 2, Steps: 614 | Train Loss: 0.2123239 Vali Loss: 0.2020299 Test Loss: 0.2321024\n",
      "Validation loss decreased (0.205710 --> 0.202030).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2195964\n",
      "\tspeed: 0.0662s/iter; left time: 725.1198s\n",
      "\titers: 200, epoch: 3 | loss: 0.1993416\n",
      "\tspeed: 0.0246s/iter; left time: 267.1507s\n",
      "\titers: 300, epoch: 3 | loss: 0.1836267\n",
      "\tspeed: 0.0263s/iter; left time: 282.4621s\n",
      "\titers: 400, epoch: 3 | loss: 0.1177053\n",
      "\tspeed: 0.0279s/iter; left time: 297.0099s\n",
      "\titers: 500, epoch: 3 | loss: 0.2036432\n",
      "\tspeed: 0.0254s/iter; left time: 267.5276s\n",
      "\titers: 600, epoch: 3 | loss: 0.2291483\n",
      "\tspeed: 0.0261s/iter; left time: 272.7786s\n",
      "Epoch: 3 cost time: 15.869171857833862\n",
      "Epoch: 3, Steps: 614 | Train Loss: 0.1896033 Vali Loss: 0.1868058 Test Loss: 0.2211771\n",
      "Validation loss decreased (0.202030 --> 0.186806).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2082815\n",
      "\tspeed: 0.0671s/iter; left time: 693.8969s\n",
      "\titers: 200, epoch: 4 | loss: 0.1195185\n",
      "\tspeed: 0.0279s/iter; left time: 285.3258s\n",
      "\titers: 300, epoch: 4 | loss: 0.1165289\n",
      "\tspeed: 0.0273s/iter; left time: 276.5792s\n",
      "\titers: 400, epoch: 4 | loss: 0.1991075\n",
      "\tspeed: 0.0257s/iter; left time: 257.9847s\n",
      "\titers: 500, epoch: 4 | loss: 0.2118007\n",
      "\tspeed: 0.0250s/iter; left time: 248.4927s\n",
      "\titers: 600, epoch: 4 | loss: 0.1544728\n",
      "\tspeed: 0.0248s/iter; left time: 244.2610s\n",
      "Epoch: 4 cost time: 16.03819513320923\n",
      "Epoch: 4, Steps: 614 | Train Loss: 0.1753062 Vali Loss: 0.1924707 Test Loss: 0.2305854\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1645859\n",
      "\tspeed: 0.0686s/iter; left time: 667.4155s\n",
      "\titers: 200, epoch: 5 | loss: 0.1491313\n",
      "\tspeed: 0.0249s/iter; left time: 239.6281s\n",
      "\titers: 300, epoch: 5 | loss: 0.1731682\n",
      "\tspeed: 0.0236s/iter; left time: 224.7183s\n",
      "\titers: 400, epoch: 5 | loss: 0.1643465\n",
      "\tspeed: 0.0236s/iter; left time: 222.8701s\n",
      "\titers: 500, epoch: 5 | loss: 0.1548874\n",
      "\tspeed: 0.0245s/iter; left time: 228.0834s\n",
      "\titers: 600, epoch: 5 | loss: 0.1168296\n",
      "\tspeed: 0.0270s/iter; left time: 249.4485s\n",
      "Epoch: 5 cost time: 15.45114278793335\n",
      "Epoch: 5, Steps: 614 | Train Loss: 0.1675241 Vali Loss: 0.1872406 Test Loss: 0.2194965\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2209327\n",
      "\tspeed: 0.0684s/iter; left time: 623.4388s\n",
      "\titers: 200, epoch: 6 | loss: 0.1159822\n",
      "\tspeed: 0.0267s/iter; left time: 240.8074s\n",
      "\titers: 300, epoch: 6 | loss: 0.1219284\n",
      "\tspeed: 0.0252s/iter; left time: 224.4987s\n",
      "\titers: 400, epoch: 6 | loss: 0.1251982\n",
      "\tspeed: 0.0272s/iter; left time: 239.3154s\n",
      "\titers: 500, epoch: 6 | loss: 0.1620982\n",
      "\tspeed: 0.0260s/iter; left time: 226.1051s\n",
      "\titers: 600, epoch: 6 | loss: 0.1553187\n",
      "\tspeed: 0.0246s/iter; left time: 211.5666s\n",
      "Epoch: 6 cost time: 16.018744945526123\n",
      "Epoch: 6, Steps: 614 | Train Loss: 0.1619009 Vali Loss: 0.1922740 Test Loss: 0.2312598\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl24_ll8_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "Test cost time: 1.7871s\n",
      "test shape: (198, 32, 6, 1) (198, 32, 6, 1)\n",
      "test shape: (6336, 6, 1) (6336, 6, 1)\n",
      "mse:0.2218046933412552, mae:0.31723281741142273\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl24_ll8_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1607.968017578125\n",
      "MAE:  27.010427474975586\n",
      "RMSE: 40.0994758605957\n",
      "MAPE: 0.39085036516189575\n",
      "MSPE: 0.8582001328468323\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll8_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 21009\n",
      "[DEBUG] Original dataset length: 21009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19676\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6844\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.2571123\n",
      "\tspeed: 0.0272s/iter; left time: 331.4268s\n",
      "\titers: 200, epoch: 1 | loss: 0.2491693\n",
      "\tspeed: 0.0262s/iter; left time: 316.4133s\n",
      "\titers: 300, epoch: 1 | loss: 0.1886834\n",
      "\tspeed: 0.0262s/iter; left time: 313.3689s\n",
      "\titers: 400, epoch: 1 | loss: 0.2377904\n",
      "\tspeed: 0.0233s/iter; left time: 277.0280s\n",
      "\titers: 500, epoch: 1 | loss: 0.2261761\n",
      "\tspeed: 0.0255s/iter; left time: 300.2881s\n",
      "\titers: 600, epoch: 1 | loss: 0.3250484\n",
      "\tspeed: 0.0240s/iter; left time: 280.6516s\n",
      "Epoch: 1 cost time: 15.592286825180054\n",
      "Epoch: 1, Steps: 614 | Train Loss: 0.2648811 Vali Loss: 0.2004027 Test Loss: 0.2410383\n",
      "Validation loss decreased (inf --> 0.200403).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1378178\n",
      "\tspeed: 0.0721s/iter; left time: 833.7021s\n",
      "\titers: 200, epoch: 2 | loss: 0.2712934\n",
      "\tspeed: 0.0269s/iter; left time: 308.5559s\n",
      "\titers: 300, epoch: 2 | loss: 0.2128772\n",
      "\tspeed: 0.0262s/iter; left time: 297.6383s\n",
      "\titers: 400, epoch: 2 | loss: 0.1548227\n",
      "\tspeed: 0.0273s/iter; left time: 307.4500s\n",
      "\titers: 500, epoch: 2 | loss: 0.4603472\n",
      "\tspeed: 0.0267s/iter; left time: 298.3106s\n",
      "\titers: 600, epoch: 2 | loss: 0.1918837\n",
      "\tspeed: 0.0266s/iter; left time: 294.6067s\n",
      "Epoch: 2 cost time: 16.47530460357666\n",
      "Epoch: 2, Steps: 614 | Train Loss: 0.2159783 Vali Loss: 0.1961964 Test Loss: 0.2340298\n",
      "Validation loss decreased (0.200403 --> 0.196196).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1876912\n",
      "\tspeed: 0.0664s/iter; left time: 727.3875s\n",
      "\titers: 200, epoch: 3 | loss: 0.1948375\n",
      "\tspeed: 0.0253s/iter; left time: 274.7080s\n",
      "\titers: 300, epoch: 3 | loss: 0.1143677\n",
      "\tspeed: 0.0247s/iter; left time: 265.6789s\n",
      "\titers: 400, epoch: 3 | loss: 0.1951960\n",
      "\tspeed: 0.0270s/iter; left time: 287.8866s\n",
      "\titers: 500, epoch: 3 | loss: 0.2053813\n",
      "\tspeed: 0.0249s/iter; left time: 262.6835s\n",
      "\titers: 600, epoch: 3 | loss: 0.3270227\n",
      "\tspeed: 0.0249s/iter; left time: 260.6547s\n",
      "Epoch: 3 cost time: 15.427273750305176\n",
      "Epoch: 3, Steps: 614 | Train Loss: 0.1891436 Vali Loss: 0.1913346 Test Loss: 0.2211996\n",
      "Validation loss decreased (0.196196 --> 0.191335).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1534028\n",
      "\tspeed: 0.0683s/iter; left time: 706.5791s\n",
      "\titers: 200, epoch: 4 | loss: 0.1377754\n",
      "\tspeed: 0.0296s/iter; left time: 302.8334s\n",
      "\titers: 300, epoch: 4 | loss: 0.1697836\n",
      "\tspeed: 0.0272s/iter; left time: 275.4510s\n",
      "\titers: 400, epoch: 4 | loss: 0.2927917\n",
      "\tspeed: 0.0263s/iter; left time: 264.3206s\n",
      "\titers: 500, epoch: 4 | loss: 0.2097104\n",
      "\tspeed: 0.0256s/iter; left time: 254.9295s\n",
      "\titers: 600, epoch: 4 | loss: 0.1614209\n",
      "\tspeed: 0.0258s/iter; left time: 253.9886s\n",
      "Epoch: 4 cost time: 16.420502424240112\n",
      "Epoch: 4, Steps: 614 | Train Loss: 0.1771217 Vali Loss: 0.1921039 Test Loss: 0.2266454\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1722257\n",
      "\tspeed: 0.0710s/iter; left time: 690.0822s\n",
      "\titers: 200, epoch: 5 | loss: 0.3092841\n",
      "\tspeed: 0.0288s/iter; left time: 277.4649s\n",
      "\titers: 300, epoch: 5 | loss: 0.2838149\n",
      "\tspeed: 0.0279s/iter; left time: 266.1977s\n",
      "\titers: 400, epoch: 5 | loss: 0.1416427\n",
      "\tspeed: 0.0300s/iter; left time: 282.5696s\n",
      "\titers: 500, epoch: 5 | loss: 0.1201018\n",
      "\tspeed: 0.0276s/iter; left time: 257.6619s\n",
      "\titers: 600, epoch: 5 | loss: 0.1403250\n",
      "\tspeed: 0.0282s/iter; left time: 259.7043s\n",
      "Epoch: 5 cost time: 17.387020587921143\n",
      "Epoch: 5, Steps: 614 | Train Loss: 0.1681019 Vali Loss: 0.1873827 Test Loss: 0.2270701\n",
      "Validation loss decreased (0.191335 --> 0.187383).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1200769\n",
      "\tspeed: 0.0707s/iter; left time: 643.7513s\n",
      "\titers: 200, epoch: 6 | loss: 0.1346547\n",
      "\tspeed: 0.0273s/iter; left time: 245.8089s\n",
      "\titers: 300, epoch: 6 | loss: 0.2847334\n",
      "\tspeed: 0.0284s/iter; left time: 252.7324s\n",
      "\titers: 400, epoch: 6 | loss: 0.1317425\n",
      "\tspeed: 0.0267s/iter; left time: 235.0091s\n",
      "\titers: 500, epoch: 6 | loss: 0.2281248\n",
      "\tspeed: 0.0259s/iter; left time: 225.8491s\n",
      "\titers: 600, epoch: 6 | loss: 0.2609388\n",
      "\tspeed: 0.0256s/iter; left time: 220.8492s\n",
      "Epoch: 6 cost time: 16.544724464416504\n",
      "Epoch: 6, Steps: 614 | Train Loss: 0.1632582 Vali Loss: 0.1872005 Test Loss: 0.2233363\n",
      "Validation loss decreased (0.187383 --> 0.187201).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2134308\n",
      "\tspeed: 0.0696s/iter; left time: 591.1640s\n",
      "\titers: 200, epoch: 7 | loss: 0.1437418\n",
      "\tspeed: 0.0272s/iter; left time: 228.7241s\n",
      "\titers: 300, epoch: 7 | loss: 0.1485184\n",
      "\tspeed: 0.0264s/iter; left time: 218.7957s\n",
      "\titers: 400, epoch: 7 | loss: 0.1688062\n",
      "\tspeed: 0.0252s/iter; left time: 206.3331s\n",
      "\titers: 500, epoch: 7 | loss: 0.2686862\n",
      "\tspeed: 0.0253s/iter; left time: 204.7457s\n",
      "\titers: 600, epoch: 7 | loss: 0.2202493\n",
      "\tspeed: 0.0258s/iter; left time: 206.0190s\n",
      "Epoch: 7 cost time: 16.1966233253479\n",
      "Epoch: 7, Steps: 614 | Train Loss: 0.1604101 Vali Loss: 0.1865314 Test Loss: 0.2208482\n",
      "Validation loss decreased (0.187201 --> 0.186531).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2387248\n",
      "\tspeed: 0.0680s/iter; left time: 535.9857s\n",
      "\titers: 200, epoch: 8 | loss: 0.1638281\n",
      "\tspeed: 0.0246s/iter; left time: 191.6415s\n",
      "\titers: 300, epoch: 8 | loss: 0.1669670\n",
      "\tspeed: 0.0243s/iter; left time: 186.4130s\n",
      "\titers: 400, epoch: 8 | loss: 0.2605859\n",
      "\tspeed: 0.0243s/iter; left time: 184.6240s\n",
      "\titers: 500, epoch: 8 | loss: 0.1670422\n",
      "\tspeed: 0.0281s/iter; left time: 210.5682s\n",
      "\titers: 600, epoch: 8 | loss: 0.1198996\n",
      "\tspeed: 0.0270s/iter; left time: 199.0590s\n",
      "Epoch: 8 cost time: 15.627099990844727\n",
      "Epoch: 8, Steps: 614 | Train Loss: 0.1589321 Vali Loss: 0.1879580 Test Loss: 0.2235707\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.3779764\n",
      "\tspeed: 0.0674s/iter; left time: 490.1583s\n",
      "\titers: 200, epoch: 9 | loss: 0.1679209\n",
      "\tspeed: 0.0261s/iter; left time: 187.2369s\n",
      "\titers: 300, epoch: 9 | loss: 0.0993538\n",
      "\tspeed: 0.0266s/iter; left time: 188.0280s\n",
      "\titers: 400, epoch: 9 | loss: 0.1118328\n",
      "\tspeed: 0.0258s/iter; left time: 179.6787s\n",
      "\titers: 500, epoch: 9 | loss: 0.0952456\n",
      "\tspeed: 0.0249s/iter; left time: 171.2481s\n",
      "\titers: 600, epoch: 9 | loss: 0.1722600\n",
      "\tspeed: 0.0241s/iter; left time: 162.8571s\n",
      "Epoch: 9 cost time: 15.70413875579834\n",
      "Epoch: 9, Steps: 614 | Train Loss: 0.1583080 Vali Loss: 0.1856320 Test Loss: 0.2227819\n",
      "Validation loss decreased (0.186531 --> 0.185632).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.1551249\n",
      "\tspeed: 0.0650s/iter; left time: 432.6375s\n",
      "\titers: 200, epoch: 10 | loss: 0.1366638\n",
      "\tspeed: 0.0274s/iter; left time: 179.8115s\n",
      "\titers: 300, epoch: 10 | loss: 0.1971271\n",
      "\tspeed: 0.0249s/iter; left time: 160.5069s\n",
      "\titers: 400, epoch: 10 | loss: 0.2290267\n",
      "\tspeed: 0.0239s/iter; left time: 151.6580s\n",
      "\titers: 500, epoch: 10 | loss: 0.1719171\n",
      "\tspeed: 0.0243s/iter; left time: 151.7701s\n",
      "\titers: 600, epoch: 10 | loss: 0.1231840\n",
      "\tspeed: 0.0250s/iter; left time: 153.6810s\n",
      "Epoch: 10 cost time: 15.281212091445923\n",
      "Epoch: 10, Steps: 614 | Train Loss: 0.1576496 Vali Loss: 0.1865613 Test Loss: 0.2235779\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.2736078\n",
      "\tspeed: 0.0674s/iter; left time: 407.1027s\n",
      "\titers: 200, epoch: 11 | loss: 0.1464270\n",
      "\tspeed: 0.0239s/iter; left time: 141.8067s\n",
      "\titers: 300, epoch: 11 | loss: 0.1918187\n",
      "\tspeed: 0.0238s/iter; left time: 139.2706s\n",
      "\titers: 400, epoch: 11 | loss: 0.1632384\n",
      "\tspeed: 0.0235s/iter; left time: 134.9554s\n",
      "\titers: 500, epoch: 11 | loss: 0.0985140\n",
      "\tspeed: 0.0250s/iter; left time: 141.1212s\n",
      "\titers: 600, epoch: 11 | loss: 0.1503576\n",
      "\tspeed: 0.0270s/iter; left time: 149.8009s\n",
      "Epoch: 11 cost time: 15.327263832092285\n",
      "Epoch: 11, Steps: 614 | Train Loss: 0.1574840 Vali Loss: 0.1865029 Test Loss: 0.2248887\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.1605360\n",
      "\tspeed: 0.0660s/iter; left time: 358.0041s\n",
      "\titers: 200, epoch: 12 | loss: 0.0888118\n",
      "\tspeed: 0.0244s/iter; left time: 130.0495s\n",
      "\titers: 300, epoch: 12 | loss: 0.1278328\n",
      "\tspeed: 0.0253s/iter; left time: 132.2786s\n",
      "\titers: 400, epoch: 12 | loss: 0.1279837\n",
      "\tspeed: 0.0267s/iter; left time: 137.0185s\n",
      "\titers: 500, epoch: 12 | loss: 0.1509568\n",
      "\tspeed: 0.0273s/iter; left time: 137.3871s\n",
      "\titers: 600, epoch: 12 | loss: 0.1714019\n",
      "\tspeed: 0.0255s/iter; left time: 125.7649s\n",
      "Epoch: 12 cost time: 15.787374019622803\n",
      "Epoch: 12, Steps: 614 | Train Loss: 0.1576698 Vali Loss: 0.1857882 Test Loss: 0.2234593\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl24_ll8_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "Test cost time: 1.7238s\n",
      "test shape: (198, 32, 6, 1) (198, 32, 6, 1)\n",
      "test shape: (6336, 6, 1) (6336, 6, 1)\n",
      "mse:0.2225600779056549, mae:0.31434717774391174\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl24_ll8_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1613.4444580078125\n",
      "MAE:  26.764738082885742\n",
      "RMSE: 40.16770553588867\n",
      "MAPE: 0.323626846075058\n",
      "MSPE: 0.48141905665397644\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll8_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 21009\n",
      "[DEBUG] Original dataset length: 21009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19676\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6844\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.2062276\n",
      "\tspeed: 0.0238s/iter; left time: 289.9135s\n",
      "\titers: 200, epoch: 1 | loss: 0.2869042\n",
      "\tspeed: 0.0281s/iter; left time: 339.4490s\n",
      "\titers: 300, epoch: 1 | loss: 0.1579965\n",
      "\tspeed: 0.0253s/iter; left time: 302.7070s\n",
      "\titers: 400, epoch: 1 | loss: 0.2424906\n",
      "\tspeed: 0.0253s/iter; left time: 301.1393s\n",
      "\titers: 500, epoch: 1 | loss: 0.2141443\n",
      "\tspeed: 0.0232s/iter; left time: 273.4786s\n",
      "\titers: 600, epoch: 1 | loss: 0.1642455\n",
      "\tspeed: 0.0270s/iter; left time: 315.8989s\n",
      "Epoch: 1 cost time: 15.690059185028076\n",
      "Epoch: 1, Steps: 614 | Train Loss: 0.2655265 Vali Loss: 0.2268586 Test Loss: 0.2513986\n",
      "Validation loss decreased (inf --> 0.226859).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2700408\n",
      "\tspeed: 0.0695s/iter; left time: 803.8675s\n",
      "\titers: 200, epoch: 2 | loss: 0.1986995\n",
      "\tspeed: 0.0255s/iter; left time: 291.8622s\n",
      "\titers: 300, epoch: 2 | loss: 0.1729828\n",
      "\tspeed: 0.0245s/iter; left time: 278.8350s\n",
      "\titers: 400, epoch: 2 | loss: 0.1954899\n",
      "\tspeed: 0.0250s/iter; left time: 282.2022s\n",
      "\titers: 500, epoch: 2 | loss: 0.1600076\n",
      "\tspeed: 0.0246s/iter; left time: 274.3995s\n",
      "\titers: 600, epoch: 2 | loss: 0.1852180\n",
      "\tspeed: 0.0277s/iter; left time: 306.9753s\n",
      "Epoch: 2 cost time: 15.691111087799072\n",
      "Epoch: 2, Steps: 614 | Train Loss: 0.2143312 Vali Loss: 0.1855303 Test Loss: 0.2186726\n",
      "Validation loss decreased (0.226859 --> 0.185530).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2545639\n",
      "\tspeed: 0.0672s/iter; left time: 736.0882s\n",
      "\titers: 200, epoch: 3 | loss: 0.2217985\n",
      "\tspeed: 0.0239s/iter; left time: 259.4297s\n",
      "\titers: 400, epoch: 3 | loss: 0.1223443\n",
      "\tspeed: 0.0265s/iter; left time: 282.4070s\n",
      "\titers: 500, epoch: 3 | loss: 0.1429065\n",
      "\tspeed: 0.0282s/iter; left time: 297.8587s\n",
      "\titers: 600, epoch: 3 | loss: 0.1888111\n",
      "\tspeed: 0.0251s/iter; left time: 261.8895s\n",
      "Epoch: 3 cost time: 15.914838314056396\n",
      "Epoch: 3, Steps: 614 | Train Loss: 0.1906324 Vali Loss: 0.1918927 Test Loss: 0.2286871\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1310019\n",
      "\tspeed: 0.0651s/iter; left time: 672.7806s\n",
      "\titers: 200, epoch: 4 | loss: 0.1750412\n",
      "\tspeed: 0.0262s/iter; left time: 267.8603s\n",
      "\titers: 300, epoch: 4 | loss: 0.2109769\n",
      "\tspeed: 0.0281s/iter; left time: 285.0927s\n",
      "\titers: 400, epoch: 4 | loss: 0.2814055\n",
      "\tspeed: 0.0261s/iter; left time: 262.1760s\n",
      "\titers: 500, epoch: 4 | loss: 0.1484389\n",
      "\tspeed: 0.0247s/iter; left time: 245.4106s\n",
      "\titers: 600, epoch: 4 | loss: 0.1407476\n",
      "\tspeed: 0.0234s/iter; left time: 230.2569s\n",
      "Epoch: 4 cost time: 15.7530038356781\n",
      "Epoch: 4, Steps: 614 | Train Loss: 0.1765830 Vali Loss: 0.1897880 Test Loss: 0.2240285\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1764286\n",
      "\tspeed: 0.0681s/iter; left time: 662.4007s\n",
      "\titers: 200, epoch: 5 | loss: 0.2278647\n",
      "\tspeed: 0.0263s/iter; left time: 252.6651s\n",
      "\titers: 300, epoch: 5 | loss: 0.1535930\n",
      "\tspeed: 0.0251s/iter; left time: 239.3184s\n",
      "\titers: 400, epoch: 5 | loss: 0.1308173\n",
      "\tspeed: 0.0256s/iter; left time: 240.8119s\n",
      "\titers: 500, epoch: 5 | loss: 0.1918726\n",
      "\tspeed: 0.0243s/iter; left time: 226.9872s\n",
      "\titers: 600, epoch: 5 | loss: 0.1073060\n",
      "\tspeed: 0.0250s/iter; left time: 230.2728s\n",
      "Epoch: 5 cost time: 15.83525824546814\n",
      "Epoch: 5, Steps: 614 | Train Loss: 0.1684174 Vali Loss: 0.1848911 Test Loss: 0.2166680\n",
      "Validation loss decreased (0.185530 --> 0.184891).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0937450\n",
      "\tspeed: 0.0708s/iter; left time: 644.9971s\n",
      "\titers: 200, epoch: 6 | loss: 0.1095935\n",
      "\tspeed: 0.0249s/iter; left time: 224.5831s\n",
      "\titers: 300, epoch: 6 | loss: 0.2138997\n",
      "\tspeed: 0.0248s/iter; left time: 220.7052s\n",
      "\titers: 400, epoch: 6 | loss: 0.1100624\n",
      "\tspeed: 0.0239s/iter; left time: 210.9987s\n",
      "\titers: 500, epoch: 6 | loss: 0.1685993\n",
      "\tspeed: 0.0278s/iter; left time: 242.1940s\n",
      "\titers: 600, epoch: 6 | loss: 0.1554113\n",
      "\tspeed: 0.0255s/iter; left time: 219.7940s\n",
      "Epoch: 6 cost time: 15.687419414520264\n",
      "Epoch: 6, Steps: 614 | Train Loss: 0.1637347 Vali Loss: 0.1872715 Test Loss: 0.2205432\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1194133\n",
      "\tspeed: 0.0639s/iter; left time: 543.3402s\n",
      "\titers: 200, epoch: 7 | loss: 0.1567014\n",
      "\tspeed: 0.0249s/iter; left time: 208.7924s\n",
      "\titers: 300, epoch: 7 | loss: 0.1220924\n",
      "\tspeed: 0.0273s/iter; left time: 226.7295s\n",
      "\titers: 400, epoch: 7 | loss: 0.2237823\n",
      "\tspeed: 0.0257s/iter; left time: 211.0645s\n",
      "\titers: 500, epoch: 7 | loss: 0.1673284\n",
      "\tspeed: 0.0248s/iter; left time: 200.9436s\n",
      "\titers: 600, epoch: 7 | loss: 0.1657819\n",
      "\tspeed: 0.0243s/iter; left time: 194.5657s\n",
      "Epoch: 7 cost time: 15.534085273742676\n",
      "Epoch: 7, Steps: 614 | Train Loss: 0.1606362 Vali Loss: 0.1892847 Test Loss: 0.2221360\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1233507\n",
      "\tspeed: 0.0646s/iter; left time: 509.3042s\n",
      "\titers: 200, epoch: 8 | loss: 0.1813727\n",
      "\tspeed: 0.0270s/iter; left time: 210.1975s\n",
      "\titers: 300, epoch: 8 | loss: 0.2174568\n",
      "\tspeed: 0.0247s/iter; left time: 190.1113s\n",
      "\titers: 400, epoch: 8 | loss: 0.1070361\n",
      "\tspeed: 0.0254s/iter; left time: 192.2943s\n",
      "\titers: 500, epoch: 8 | loss: 0.0976090\n",
      "\tspeed: 0.0246s/iter; left time: 183.7818s\n",
      "\titers: 600, epoch: 8 | loss: 0.1130244\n",
      "\tspeed: 0.0253s/iter; left time: 186.9682s\n",
      "Epoch: 8 cost time: 15.554422378540039\n",
      "Epoch: 8, Steps: 614 | Train Loss: 0.1587920 Vali Loss: 0.1887350 Test Loss: 0.2225601\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl24_ll8_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "Test cost time: 1.8678s\n",
      "test shape: (198, 32, 6, 1) (198, 32, 6, 1)\n",
      "test shape: (6336, 6, 1) (6336, 6, 1)\n",
      "mse:0.21692681312561035, mae:0.3126938045024872\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl24_ll8_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1572.60595703125\n",
      "MAE:  26.62395668029785\n",
      "RMSE: 39.656097412109375\n",
      "MAPE: 0.33870476484298706\n",
      "MSPE: 0.6043322682380676\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll8_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 21009\n",
      "[DEBUG] Original dataset length: 21009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19676\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6844\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.2516367\n",
      "\tspeed: 0.0245s/iter; left time: 298.2234s\n",
      "\titers: 200, epoch: 1 | loss: 0.2611606\n",
      "\tspeed: 0.0244s/iter; left time: 294.7323s\n",
      "\titers: 300, epoch: 1 | loss: 0.1552970\n",
      "\tspeed: 0.0243s/iter; left time: 291.2451s\n",
      "\titers: 400, epoch: 1 | loss: 0.1386488\n",
      "\tspeed: 0.0247s/iter; left time: 293.7298s\n",
      "\titers: 500, epoch: 1 | loss: 0.2984030\n",
      "\tspeed: 0.0264s/iter; left time: 311.0153s\n",
      "\titers: 600, epoch: 1 | loss: 0.1936956\n",
      "\tspeed: 0.0264s/iter; left time: 308.9209s\n",
      "Epoch: 1 cost time: 15.428660154342651\n",
      "Epoch: 1, Steps: 614 | Train Loss: 0.2631658 Vali Loss: 0.2145856 Test Loss: 0.2608010\n",
      "Validation loss decreased (inf --> 0.214586).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2355522\n",
      "\tspeed: 0.0667s/iter; left time: 771.9084s\n",
      "\titers: 200, epoch: 2 | loss: 0.2250823\n",
      "\tspeed: 0.0252s/iter; left time: 288.5987s\n",
      "\titers: 300, epoch: 2 | loss: 0.1690245\n",
      "\tspeed: 0.0266s/iter; left time: 301.8729s\n",
      "\titers: 400, epoch: 2 | loss: 0.2098733\n",
      "\tspeed: 0.0275s/iter; left time: 310.1873s\n",
      "\titers: 500, epoch: 2 | loss: 0.1859565\n",
      "\tspeed: 0.0242s/iter; left time: 270.1612s\n",
      "\titers: 600, epoch: 2 | loss: 0.1944089\n",
      "\tspeed: 0.0248s/iter; left time: 274.0985s\n",
      "Epoch: 2 cost time: 15.744856595993042\n",
      "Epoch: 2, Steps: 614 | Train Loss: 0.2141934 Vali Loss: 0.1929602 Test Loss: 0.2299650\n",
      "Validation loss decreased (0.214586 --> 0.192960).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2109205\n",
      "\tspeed: 0.0668s/iter; left time: 731.4313s\n",
      "\titers: 200, epoch: 3 | loss: 0.1760553\n",
      "\tspeed: 0.0267s/iter; left time: 289.7053s\n",
      "\titers: 300, epoch: 3 | loss: 0.1994634\n",
      "\tspeed: 0.0251s/iter; left time: 269.9374s\n",
      "\titers: 400, epoch: 3 | loss: 0.1420324\n",
      "\tspeed: 0.0252s/iter; left time: 268.2953s\n",
      "\titers: 500, epoch: 3 | loss: 0.2666388\n",
      "\tspeed: 0.0259s/iter; left time: 273.4156s\n",
      "\titers: 600, epoch: 3 | loss: 0.3180492\n",
      "\tspeed: 0.0256s/iter; left time: 267.1825s\n",
      "Epoch: 3 cost time: 15.861984014511108\n",
      "Epoch: 3, Steps: 614 | Train Loss: 0.1903797 Vali Loss: 0.1960581 Test Loss: 0.2247072\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1709648\n",
      "\tspeed: 0.0681s/iter; left time: 704.0804s\n",
      "\titers: 200, epoch: 4 | loss: 0.1328435\n",
      "\tspeed: 0.0241s/iter; left time: 246.7905s\n",
      "\titers: 300, epoch: 4 | loss: 0.1336365\n",
      "\tspeed: 0.0238s/iter; left time: 241.7222s\n",
      "\titers: 400, epoch: 4 | loss: 0.1401362\n",
      "\tspeed: 0.0246s/iter; left time: 246.6450s\n",
      "\titers: 500, epoch: 4 | loss: 0.1279848\n",
      "\tspeed: 0.0249s/iter; left time: 247.9238s\n",
      "\titers: 600, epoch: 4 | loss: 0.2156396\n",
      "\tspeed: 0.0272s/iter; left time: 268.0542s\n",
      "Epoch: 4 cost time: 15.354276895523071\n",
      "Epoch: 4, Steps: 614 | Train Loss: 0.1761398 Vali Loss: 0.1884303 Test Loss: 0.2222970\n",
      "Validation loss decreased (0.192960 --> 0.188430).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1870673\n",
      "\tspeed: 0.0682s/iter; left time: 663.5396s\n",
      "\titers: 200, epoch: 5 | loss: 0.2473489\n",
      "\tspeed: 0.0263s/iter; left time: 252.9359s\n",
      "\titers: 300, epoch: 5 | loss: 0.2037406\n",
      "\tspeed: 0.0254s/iter; left time: 242.1667s\n",
      "\titers: 400, epoch: 5 | loss: 0.1174458\n",
      "\tspeed: 0.0284s/iter; left time: 267.7417s\n",
      "\titers: 500, epoch: 5 | loss: 0.1209288\n",
      "\tspeed: 0.0258s/iter; left time: 240.8879s\n",
      "\titers: 600, epoch: 5 | loss: 0.1200169\n",
      "\tspeed: 0.0233s/iter; left time: 214.6940s\n",
      "Epoch: 5 cost time: 15.85579228401184\n",
      "Epoch: 5, Steps: 614 | Train Loss: 0.1668822 Vali Loss: 0.1853589 Test Loss: 0.2187520\n",
      "Validation loss decreased (0.188430 --> 0.185359).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1707580\n",
      "\tspeed: 0.0653s/iter; left time: 595.0849s\n",
      "\titers: 200, epoch: 6 | loss: 0.1264273\n",
      "\tspeed: 0.0271s/iter; left time: 244.1753s\n",
      "\titers: 300, epoch: 6 | loss: 0.1068708\n",
      "\tspeed: 0.0260s/iter; left time: 231.2488s\n",
      "\titers: 400, epoch: 6 | loss: 0.1637805\n",
      "\tspeed: 0.0249s/iter; left time: 219.2136s\n",
      "\titers: 500, epoch: 6 | loss: 0.2276610\n",
      "\tspeed: 0.0242s/iter; left time: 210.8194s\n",
      "\titers: 600, epoch: 6 | loss: 0.1559264\n",
      "\tspeed: 0.0246s/iter; left time: 211.9559s\n",
      "Epoch: 6 cost time: 15.469279766082764\n",
      "Epoch: 6, Steps: 614 | Train Loss: 0.1621850 Vali Loss: 0.1869150 Test Loss: 0.2195108\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1163133\n",
      "\tspeed: 0.0679s/iter; left time: 576.8106s\n",
      "\titers: 200, epoch: 7 | loss: 0.1921547\n",
      "\tspeed: 0.0277s/iter; left time: 232.2227s\n",
      "\titers: 300, epoch: 7 | loss: 0.1505584\n",
      "\tspeed: 0.0259s/iter; left time: 215.0821s\n",
      "\titers: 400, epoch: 7 | loss: 0.2325868\n",
      "\tspeed: 0.0259s/iter; left time: 212.0988s\n",
      "\titers: 500, epoch: 7 | loss: 0.2420987\n",
      "\tspeed: 0.0254s/iter; left time: 205.5202s\n",
      "\titers: 600, epoch: 7 | loss: 0.1395033\n",
      "\tspeed: 0.0263s/iter; left time: 210.0568s\n",
      "Epoch: 7 cost time: 16.320416927337646\n",
      "Epoch: 7, Steps: 614 | Train Loss: 0.1589222 Vali Loss: 0.1891746 Test Loss: 0.2241019\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1910581\n",
      "\tspeed: 0.0713s/iter; left time: 562.0724s\n",
      "\titers: 200, epoch: 8 | loss: 0.1104638\n",
      "\tspeed: 0.0263s/iter; left time: 204.4302s\n",
      "\titers: 300, epoch: 8 | loss: 0.1340043\n",
      "\tspeed: 0.0255s/iter; left time: 196.0760s\n",
      "\titers: 400, epoch: 8 | loss: 0.1376278\n",
      "\tspeed: 0.0263s/iter; left time: 199.3068s\n",
      "\titers: 500, epoch: 8 | loss: 0.1991960\n",
      "\tspeed: 0.0284s/iter; left time: 212.1536s\n",
      "\titers: 600, epoch: 8 | loss: 0.1536229\n",
      "\tspeed: 0.0266s/iter; left time: 196.1288s\n",
      "Epoch: 8 cost time: 16.428576946258545\n",
      "Epoch: 8, Steps: 614 | Train Loss: 0.1569822 Vali Loss: 0.1860041 Test Loss: 0.2193757\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl24_ll8_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "Test cost time: 1.8685s\n",
      "test shape: (198, 32, 6, 1) (198, 32, 6, 1)\n",
      "test shape: (6336, 6, 1) (6336, 6, 1)\n",
      "mse:0.21898823976516724, mae:0.3121865689754486\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl24_ll8_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1587.55029296875\n",
      "MAE:  26.580772399902344\n",
      "RMSE: 39.84407424926758\n",
      "MAPE: 0.31669002771377563\n",
      "MSPE: 0.4707100987434387\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll8_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 21009\n",
      "[DEBUG] Original dataset length: 21009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19676\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6844\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.3119281\n",
      "\tspeed: 0.0255s/iter; left time: 311.1997s\n",
      "\titers: 200, epoch: 1 | loss: 0.2383535\n",
      "\tspeed: 0.0265s/iter; left time: 320.7266s\n",
      "\titers: 300, epoch: 1 | loss: 0.1878325\n",
      "\tspeed: 0.0281s/iter; left time: 336.8885s\n",
      "\titers: 400, epoch: 1 | loss: 0.2833365\n",
      "\tspeed: 0.0266s/iter; left time: 315.6404s\n",
      "\titers: 500, epoch: 1 | loss: 0.1667814\n",
      "\tspeed: 0.0252s/iter; left time: 296.3554s\n",
      "\titers: 600, epoch: 1 | loss: 0.2169490\n",
      "\tspeed: 0.0265s/iter; left time: 309.8890s\n",
      "Epoch: 1 cost time: 16.187129974365234\n",
      "Epoch: 1, Steps: 614 | Train Loss: 0.2706182 Vali Loss: 0.2016486 Test Loss: 0.2407032\n",
      "Validation loss decreased (inf --> 0.201649).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2455741\n",
      "\tspeed: 0.0705s/iter; left time: 815.2554s\n",
      "\titers: 200, epoch: 2 | loss: 0.2118566\n",
      "\tspeed: 0.0258s/iter; left time: 296.1190s\n",
      "\titers: 300, epoch: 2 | loss: 0.2315002\n",
      "\tspeed: 0.0256s/iter; left time: 290.6530s\n",
      "\titers: 400, epoch: 2 | loss: 0.1921448\n",
      "\tspeed: 0.0248s/iter; left time: 279.6517s\n",
      "\titers: 500, epoch: 2 | loss: 0.2480581\n",
      "\tspeed: 0.0261s/iter; left time: 291.3516s\n",
      "\titers: 600, epoch: 2 | loss: 0.2618323\n",
      "\tspeed: 0.0296s/iter; left time: 327.3427s\n",
      "Epoch: 2 cost time: 16.160731315612793\n",
      "Epoch: 2, Steps: 614 | Train Loss: 0.2163039 Vali Loss: 0.2002754 Test Loss: 0.2398833\n",
      "Validation loss decreased (0.201649 --> 0.200275).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1989969\n",
      "\tspeed: 0.0688s/iter; left time: 753.8376s\n",
      "\titers: 200, epoch: 3 | loss: 0.1913328\n",
      "\tspeed: 0.0269s/iter; left time: 291.5088s\n",
      "\titers: 300, epoch: 3 | loss: 0.1941120\n",
      "\tspeed: 0.0263s/iter; left time: 282.5039s\n",
      "\titers: 400, epoch: 3 | loss: 0.1879757\n",
      "\tspeed: 0.0257s/iter; left time: 273.5304s\n",
      "\titers: 500, epoch: 3 | loss: 0.2540777\n",
      "\tspeed: 0.0240s/iter; left time: 253.5271s\n",
      "\titers: 600, epoch: 3 | loss: 0.2731888\n",
      "\tspeed: 0.0249s/iter; left time: 260.6930s\n",
      "Epoch: 3 cost time: 15.862076044082642\n",
      "Epoch: 3, Steps: 614 | Train Loss: 0.1900115 Vali Loss: 0.1910169 Test Loss: 0.2264932\n",
      "Validation loss decreased (0.200275 --> 0.191017).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1837193\n",
      "\tspeed: 0.0660s/iter; left time: 682.8625s\n",
      "\titers: 200, epoch: 4 | loss: 0.1409781\n",
      "\tspeed: 0.0274s/iter; left time: 280.6825s\n",
      "\titers: 300, epoch: 4 | loss: 0.2276027\n",
      "\tspeed: 0.0281s/iter; left time: 284.4626s\n",
      "\titers: 400, epoch: 4 | loss: 0.1363266\n",
      "\tspeed: 0.0261s/iter; left time: 261.8800s\n",
      "\titers: 500, epoch: 4 | loss: 0.1945328\n",
      "\tspeed: 0.0262s/iter; left time: 260.3342s\n",
      "\titers: 600, epoch: 4 | loss: 0.1604636\n",
      "\tspeed: 0.0239s/iter; left time: 234.9728s\n",
      "Epoch: 4 cost time: 15.99052882194519\n",
      "Epoch: 4, Steps: 614 | Train Loss: 0.1769451 Vali Loss: 0.1844775 Test Loss: 0.2273615\n",
      "Validation loss decreased (0.191017 --> 0.184477).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1498961\n",
      "\tspeed: 0.0696s/iter; left time: 676.7699s\n",
      "\titers: 200, epoch: 5 | loss: 0.2344468\n",
      "\tspeed: 0.0253s/iter; left time: 243.3195s\n",
      "\titers: 300, epoch: 5 | loss: 0.1139854\n",
      "\tspeed: 0.0260s/iter; left time: 247.8359s\n",
      "\titers: 400, epoch: 5 | loss: 0.1094021\n",
      "\tspeed: 0.0259s/iter; left time: 244.0364s\n",
      "\titers: 500, epoch: 5 | loss: 0.1723572\n",
      "\tspeed: 0.0252s/iter; left time: 234.6981s\n",
      "\titers: 600, epoch: 5 | loss: 0.1161228\n",
      "\tspeed: 0.0270s/iter; left time: 249.4238s\n",
      "Epoch: 5 cost time: 16.124410390853882\n",
      "Epoch: 5, Steps: 614 | Train Loss: 0.1674372 Vali Loss: 0.1843522 Test Loss: 0.2233679\n",
      "Validation loss decreased (0.184477 --> 0.184352).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3324977\n",
      "\tspeed: 0.0669s/iter; left time: 609.1808s\n",
      "\titers: 200, epoch: 6 | loss: 0.1316707\n",
      "\tspeed: 0.0275s/iter; left time: 248.2525s\n",
      "\titers: 300, epoch: 6 | loss: 0.3906628\n",
      "\tspeed: 0.0257s/iter; left time: 229.2429s\n",
      "\titers: 400, epoch: 6 | loss: 0.1264421\n",
      "\tspeed: 0.0286s/iter; left time: 251.7010s\n",
      "\titers: 500, epoch: 6 | loss: 0.1535587\n",
      "\tspeed: 0.0284s/iter; left time: 247.1211s\n",
      "\titers: 600, epoch: 6 | loss: 0.1593800\n",
      "\tspeed: 0.0280s/iter; left time: 241.2387s\n",
      "Epoch: 6 cost time: 16.680073261260986\n",
      "Epoch: 6, Steps: 614 | Train Loss: 0.1626502 Vali Loss: 0.1855826 Test Loss: 0.2256759\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1918042\n",
      "\tspeed: 0.0625s/iter; left time: 530.7159s\n",
      "\titers: 200, epoch: 7 | loss: 0.1055894\n",
      "\tspeed: 0.0225s/iter; left time: 189.0901s\n",
      "\titers: 300, epoch: 7 | loss: 0.1730555\n",
      "\tspeed: 0.0288s/iter; left time: 238.5390s\n",
      "\titers: 400, epoch: 7 | loss: 0.0964857\n",
      "\tspeed: 0.0273s/iter; left time: 223.6354s\n",
      "\titers: 500, epoch: 7 | loss: 0.1180330\n",
      "\tspeed: 0.0246s/iter; left time: 199.3467s\n",
      "\titers: 600, epoch: 7 | loss: 0.1226307\n",
      "\tspeed: 0.0257s/iter; left time: 205.4958s\n",
      "Epoch: 7 cost time: 15.508246183395386\n",
      "Epoch: 7, Steps: 614 | Train Loss: 0.1601433 Vali Loss: 0.1833327 Test Loss: 0.2215205\n",
      "Validation loss decreased (0.184352 --> 0.183333).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1670860\n",
      "\tspeed: 0.0688s/iter; left time: 542.6303s\n",
      "\titers: 200, epoch: 8 | loss: 0.1848586\n",
      "\tspeed: 0.0261s/iter; left time: 202.8107s\n",
      "\titers: 300, epoch: 8 | loss: 0.1116317\n",
      "\tspeed: 0.0268s/iter; left time: 205.7289s\n",
      "\titers: 400, epoch: 8 | loss: 0.1968446\n",
      "\tspeed: 0.0255s/iter; left time: 193.5311s\n",
      "\titers: 500, epoch: 8 | loss: 0.2036708\n",
      "\tspeed: 0.0264s/iter; left time: 197.4212s\n",
      "\titers: 600, epoch: 8 | loss: 0.1260844\n",
      "\tspeed: 0.0272s/iter; left time: 200.5142s\n",
      "Epoch: 8 cost time: 16.467503786087036\n",
      "Epoch: 8, Steps: 614 | Train Loss: 0.1593277 Vali Loss: 0.1838704 Test Loss: 0.2244561\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1157991\n",
      "\tspeed: 0.0651s/iter; left time: 473.2191s\n",
      "\titers: 200, epoch: 9 | loss: 0.1454970\n",
      "\tspeed: 0.0258s/iter; left time: 185.0610s\n",
      "\titers: 300, epoch: 9 | loss: 0.1842775\n",
      "\tspeed: 0.0252s/iter; left time: 178.3862s\n",
      "\titers: 400, epoch: 9 | loss: 0.1070050\n",
      "\tspeed: 0.0264s/iter; left time: 184.2617s\n",
      "\titers: 600, epoch: 5 | loss: 0.1765556\n",
      "\tspeed: 0.0266s/iter; left time: 245.7762s\n",
      "Epoch: 5 cost time: 15.152562141418457\n",
      "Epoch: 5, Steps: 614 | Train Loss: 0.1690396 Vali Loss: 0.1877882 Test Loss: 0.2329635\n",
      "Validation loss decreased (0.188694 --> 0.187788).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1601945\n",
      "\tspeed: 0.0659s/iter; left time: 600.4032s\n",
      "\titers: 200, epoch: 6 | loss: 0.1799067\n",
      "\tspeed: 0.0252s/iter; left time: 226.9006s\n",
      "\titers: 300, epoch: 6 | loss: 0.2005033\n",
      "\tspeed: 0.0254s/iter; left time: 226.4418s\n",
      "\titers: 400, epoch: 6 | loss: 0.1960144\n",
      "\tspeed: 0.0273s/iter; left time: 240.3320s\n",
      "\titers: 500, epoch: 6 | loss: 0.2007291\n",
      "\tspeed: 0.0259s/iter; left time: 225.4283s\n",
      "\titers: 600, epoch: 6 | loss: 0.0731233\n",
      "\tspeed: 0.0252s/iter; left time: 217.2767s\n",
      "Epoch: 6 cost time: 15.98439073562622\n",
      "Epoch: 6, Steps: 614 | Train Loss: 0.1633961 Vali Loss: 0.1827368 Test Loss: 0.2260702\n",
      "Validation loss decreased (0.187788 --> 0.182737).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2036872\n",
      "\tspeed: 0.0627s/iter; left time: 532.3382s\n",
      "\titers: 200, epoch: 7 | loss: 0.2433193\n",
      "\tspeed: 0.0262s/iter; left time: 220.3809s\n",
      "\titers: 300, epoch: 7 | loss: 0.1443053\n",
      "\tspeed: 0.0268s/iter; left time: 222.1956s\n",
      "\titers: 400, epoch: 7 | loss: 0.1654003\n",
      "\tspeed: 0.0249s/iter; left time: 204.2237s\n",
      "\titers: 500, epoch: 7 | loss: 0.0990150\n",
      "\tspeed: 0.0244s/iter; left time: 197.6532s\n",
      "\titers: 600, epoch: 7 | loss: 0.2039419\n",
      "\tspeed: 0.0256s/iter; left time: 205.0881s\n",
      "Epoch: 7 cost time: 15.573445320129395\n",
      "Epoch: 7, Steps: 614 | Train Loss: 0.1602712 Vali Loss: 0.1841734 Test Loss: 0.2291280\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2493801\n",
      "\tspeed: 0.0645s/iter; left time: 508.7693s\n",
      "\titers: 200, epoch: 8 | loss: 0.1230657\n",
      "\tspeed: 0.0243s/iter; left time: 189.4946s\n",
      "\titers: 300, epoch: 8 | loss: 0.1469155\n",
      "\tspeed: 0.0247s/iter; left time: 189.8705s\n",
      "\titers: 400, epoch: 8 | loss: 0.1841787\n",
      "\tspeed: 0.0233s/iter; left time: 176.7282s\n",
      "\titers: 500, epoch: 8 | loss: 0.1424392\n",
      "\tspeed: 0.0213s/iter; left time: 159.2915s\n",
      "\titers: 600, epoch: 8 | loss: 0.1661735\n",
      "\tspeed: 0.0251s/iter; left time: 185.4141s\n",
      "Epoch: 8 cost time: 14.963395833969116\n",
      "Epoch: 8, Steps: 614 | Train Loss: 0.1591491 Vali Loss: 0.1857950 Test Loss: 0.2305438\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1301067\n",
      "\tspeed: 0.0662s/iter; left time: 481.1522s\n",
      "\titers: 200, epoch: 9 | loss: 0.1716339\n",
      "\tspeed: 0.0232s/iter; left time: 166.2967s\n",
      "\titers: 300, epoch: 9 | loss: 0.1502950\n",
      "\tspeed: 0.0245s/iter; left time: 173.4947s\n",
      "\titers: 400, epoch: 9 | loss: 0.1111709\n",
      "\tspeed: 0.0249s/iter; left time: 173.6946s\n",
      "\titers: 500, epoch: 9 | loss: 0.1857484\n",
      "\tspeed: 0.0262s/iter; left time: 179.7034s\n",
      "\titers: 600, epoch: 9 | loss: 0.2188265\n",
      "\tspeed: 0.0262s/iter; left time: 177.1896s\n",
      "Epoch: 9 cost time: 15.335707187652588\n",
      "Epoch: 9, Steps: 614 | Train Loss: 0.1587786 Vali Loss: 0.1850731 Test Loss: 0.2295475\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl24_ll8_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "Test cost time: 1.6754s\n",
      "test shape: (198, 32, 6, 1) (198, 32, 6, 1)\n",
      "test shape: (6336, 6, 1) (6336, 6, 1)\n",
      "mse:0.22552233934402466, mae:0.3161657154560089\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl24_ll8_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1634.91943359375\n",
      "MAE:  26.919570922851562\n",
      "RMSE: 40.43413543701172\n",
      "MAPE: 0.3376406729221344\n",
      "MSPE: 0.5398781299591064\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll8_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 21009\n",
      "[DEBUG] Original dataset length: 21009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19676\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6844\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.3660628\n",
      "\tspeed: 0.0194s/iter; left time: 236.7311s\n",
      "\titers: 200, epoch: 1 | loss: 0.2587176\n",
      "\tspeed: 0.0203s/iter; left time: 245.5985s\n",
      "\titers: 300, epoch: 1 | loss: 0.2304932\n",
      "\tspeed: 0.0207s/iter; left time: 248.0903s\n",
      "\titers: 400, epoch: 1 | loss: 0.2102213\n",
      "\tspeed: 0.0264s/iter; left time: 313.3940s\n",
      "\titers: 500, epoch: 1 | loss: 0.1831177\n",
      "\tspeed: 0.0243s/iter; left time: 286.0074s\n",
      "\titers: 600, epoch: 1 | loss: 0.2107707\n",
      "\tspeed: 0.0246s/iter; left time: 287.3853s\n",
      "Epoch: 1 cost time: 13.895790576934814\n",
      "Epoch: 1, Steps: 614 | Train Loss: 0.2647068 Vali Loss: 0.2005518 Test Loss: 0.2412211\n",
      "Validation loss decreased (inf --> 0.200552).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2586606\n",
      "\tspeed: 0.0620s/iter; left time: 716.6862s\n",
      "\titers: 200, epoch: 2 | loss: 0.1333314\n",
      "\tspeed: 0.0269s/iter; left time: 308.6743s\n",
      "\titers: 300, epoch: 2 | loss: 0.2865093\n",
      "\tspeed: 0.0246s/iter; left time: 280.0603s\n",
      "\titers: 400, epoch: 2 | loss: 0.2673582\n",
      "\tspeed: 0.0256s/iter; left time: 288.2264s\n",
      "\titers: 500, epoch: 2 | loss: 0.1803723\n",
      "\tspeed: 0.0246s/iter; left time: 274.2459s\n",
      "\titers: 600, epoch: 2 | loss: 0.2005486\n",
      "\tspeed: 0.0241s/iter; left time: 266.5156s\n",
      "Epoch: 2 cost time: 15.34354567527771\n",
      "Epoch: 2, Steps: 614 | Train Loss: 0.2162317 Vali Loss: 0.1900135 Test Loss: 0.2314024\n",
      "Validation loss decreased (0.200552 --> 0.190014).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1593711\n",
      "\tspeed: 0.0685s/iter; left time: 749.8704s\n",
      "\titers: 200, epoch: 3 | loss: 0.1381918\n",
      "\tspeed: 0.0266s/iter; left time: 288.4972s\n",
      "\titers: 300, epoch: 3 | loss: 0.1079327\n",
      "\tspeed: 0.0260s/iter; left time: 279.8034s\n",
      "\titers: 400, epoch: 3 | loss: 0.1876689\n",
      "\tspeed: 0.0270s/iter; left time: 287.5250s\n",
      "\titers: 500, epoch: 3 | loss: 0.1418788\n",
      "\tspeed: 0.0269s/iter; left time: 283.6454s\n",
      "\titers: 600, epoch: 3 | loss: 0.1731455\n",
      "\tspeed: 0.0273s/iter; left time: 285.4623s\n",
      "Epoch: 3 cost time: 16.483786821365356\n",
      "Epoch: 3, Steps: 614 | Train Loss: 0.1904132 Vali Loss: 0.1907730 Test Loss: 0.2162022\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1006356\n",
      "\tspeed: 0.0645s/iter; left time: 667.2108s\n",
      "\titers: 200, epoch: 4 | loss: 0.1961050\n",
      "\tspeed: 0.0256s/iter; left time: 262.0445s\n",
      "\titers: 300, epoch: 4 | loss: 0.1681392\n",
      "\tspeed: 0.0265s/iter; left time: 268.6580s\n",
      "\titers: 400, epoch: 4 | loss: 0.1791334\n",
      "\tspeed: 0.0286s/iter; left time: 286.8521s\n",
      "\titers: 500, epoch: 4 | loss: 0.1539056\n",
      "\tspeed: 0.0267s/iter; left time: 264.9345s\n",
      "\titers: 600, epoch: 4 | loss: 0.1195805\n",
      "\tspeed: 0.0256s/iter; left time: 251.9219s\n",
      "Epoch: 4 cost time: 16.263506174087524\n",
      "Epoch: 4, Steps: 614 | Train Loss: 0.1769154 Vali Loss: 0.1926960 Test Loss: 0.2264644\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1604749\n",
      "\tspeed: 0.0752s/iter; left time: 731.1873s\n",
      "\titers: 200, epoch: 5 | loss: 0.1289871\n",
      "\tspeed: 0.0280s/iter; left time: 269.6160s\n",
      "\titers: 300, epoch: 5 | loss: 0.1185252\n",
      "\tspeed: 0.0264s/iter; left time: 250.9874s\n",
      "\titers: 400, epoch: 5 | loss: 0.1195163\n",
      "\tspeed: 0.0265s/iter; left time: 250.0192s\n",
      "\titers: 500, epoch: 5 | loss: 0.1678311\n",
      "\tspeed: 0.0231s/iter; left time: 215.2536s\n",
      "\titers: 600, epoch: 5 | loss: 0.2033151\n",
      "\tspeed: 0.0256s/iter; left time: 236.2967s\n",
      "Epoch: 5 cost time: 16.152427196502686\n",
      "Epoch: 5, Steps: 614 | Train Loss: 0.1687588 Vali Loss: 0.1904431 Test Loss: 0.2206272\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl24_ll8_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "Test cost time: 1.7402s\n",
      "test shape: (198, 32, 6, 1) (198, 32, 6, 1)\n",
      "test shape: (6336, 6, 1) (6336, 6, 1)\n",
      "mse:0.23140737414360046, mae:0.31784993410110474\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl24_ll8_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1677.5826416015625\n",
      "MAE:  27.062971115112305\n",
      "RMSE: 40.95830535888672\n",
      "MAPE: 0.31135568022727966\n",
      "MSPE: 0.4739473760128021\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll8_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 21009\n",
      "[DEBUG] Original dataset length: 21009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19676\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6844\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.3566253\n",
      "\tspeed: 0.0261s/iter; left time: 318.3912s\n",
      "\titers: 200, epoch: 1 | loss: 0.2255802\n",
      "\tspeed: 0.0265s/iter; left time: 319.7644s\n",
      "\titers: 300, epoch: 1 | loss: 0.1652644\n",
      "\tspeed: 0.0255s/iter; left time: 304.9445s\n",
      "\titers: 400, epoch: 1 | loss: 0.3144698\n",
      "\tspeed: 0.0249s/iter; left time: 295.9570s\n",
      "\titers: 500, epoch: 1 | loss: 0.2261585\n",
      "\tspeed: 0.0265s/iter; left time: 311.9899s\n",
      "\titers: 600, epoch: 1 | loss: 0.3316150\n",
      "\tspeed: 0.0263s/iter; left time: 306.9924s\n",
      "Epoch: 1 cost time: 15.937752485275269\n",
      "Epoch: 1, Steps: 614 | Train Loss: 0.2651309 Vali Loss: 0.2062967 Test Loss: 0.2440164\n",
      "Validation loss decreased (inf --> 0.206297).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1960259\n",
      "\tspeed: 0.0650s/iter; left time: 751.8450s\n",
      "\titers: 200, epoch: 2 | loss: 0.1250091\n",
      "\tspeed: 0.0251s/iter; left time: 288.3470s\n",
      "\titers: 300, epoch: 2 | loss: 0.1473801\n",
      "\tspeed: 0.0264s/iter; left time: 299.6853s\n",
      "\titers: 400, epoch: 2 | loss: 0.2027521\n",
      "\tspeed: 0.0258s/iter; left time: 291.2489s\n",
      "\titers: 500, epoch: 2 | loss: 0.1634026\n",
      "\tspeed: 0.0244s/iter; left time: 272.3058s\n",
      "\titers: 600, epoch: 2 | loss: 0.1728342\n",
      "\tspeed: 0.0248s/iter; left time: 274.3609s\n",
      "Epoch: 2 cost time: 15.506742238998413\n",
      "Epoch: 2, Steps: 614 | Train Loss: 0.2135360 Vali Loss: 0.1929778 Test Loss: 0.2282092\n",
      "Validation loss decreased (0.206297 --> 0.192978).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1529132\n",
      "\tspeed: 0.0646s/iter; left time: 707.7013s\n",
      "\titers: 200, epoch: 3 | loss: 0.1229184\n",
      "\tspeed: 0.0269s/iter; left time: 291.5464s\n",
      "\titers: 300, epoch: 3 | loss: 0.1800910\n",
      "\tspeed: 0.0250s/iter; left time: 268.6131s\n",
      "\titers: 400, epoch: 3 | loss: 0.3247864\n",
      "\tspeed: 0.0243s/iter; left time: 258.8967s\n",
      "\titers: 500, epoch: 3 | loss: 0.2172552\n",
      "\tspeed: 0.0242s/iter; left time: 255.5896s\n",
      "\titers: 600, epoch: 3 | loss: 0.2366304\n",
      "\tspeed: 0.0248s/iter; left time: 259.1819s\n",
      "Epoch: 3 cost time: 15.43940019607544\n",
      "Epoch: 3, Steps: 614 | Train Loss: 0.1882928 Vali Loss: 0.1845438 Test Loss: 0.2239191\n",
      "Validation loss decreased (0.192978 --> 0.184544).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1637301\n",
      "\tspeed: 0.0676s/iter; left time: 698.6143s\n",
      "\titers: 200, epoch: 4 | loss: 0.1445964\n",
      "\tspeed: 0.0252s/iter; left time: 258.0389s\n",
      "\titers: 300, epoch: 4 | loss: 0.1731500\n",
      "\tspeed: 0.0247s/iter; left time: 250.1477s\n",
      "\titers: 400, epoch: 4 | loss: 0.1115353\n",
      "\tspeed: 0.0249s/iter; left time: 250.1092s\n",
      "\titers: 500, epoch: 4 | loss: 0.2280507\n",
      "\tspeed: 0.0240s/iter; left time: 238.3040s\n",
      "\titers: 600, epoch: 4 | loss: 0.1325795\n",
      "\tspeed: 0.0271s/iter; left time: 266.7577s\n",
      "Epoch: 4 cost time: 15.4204421043396\n",
      "Epoch: 4, Steps: 614 | Train Loss: 0.1741659 Vali Loss: 0.1872687 Test Loss: 0.2254989\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1355910\n",
      "\tspeed: 0.0636s/iter; left time: 618.2101s\n",
      "\titers: 200, epoch: 5 | loss: 0.1985794\n",
      "\tspeed: 0.0249s/iter; left time: 239.2378s\n",
      "\titers: 300, epoch: 5 | loss: 0.1770872\n",
      "\tspeed: 0.0239s/iter; left time: 227.9024s\n",
      "\titers: 400, epoch: 5 | loss: 0.1829996\n",
      "\tspeed: 0.0255s/iter; left time: 240.2305s\n",
      "\titers: 500, epoch: 5 | loss: 0.2241460\n",
      "\tspeed: 0.0269s/iter; left time: 250.8073s\n",
      "\titers: 600, epoch: 5 | loss: 0.1601988\n",
      "\tspeed: 0.0252s/iter; left time: 232.0183s\n",
      "Epoch: 5 cost time: 15.398974418640137\n",
      "Epoch: 5, Steps: 614 | Train Loss: 0.1653811 Vali Loss: 0.1885252 Test Loss: 0.2317077\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1289448\n",
      "\tspeed: 0.0645s/iter; left time: 587.3403s\n",
      "\titers: 200, epoch: 6 | loss: 0.1034040\n",
      "\tspeed: 0.0248s/iter; left time: 223.4224s\n",
      "\titers: 300, epoch: 6 | loss: 0.1394274\n",
      "\tspeed: 0.0272s/iter; left time: 242.3018s\n",
      "\titers: 400, epoch: 6 | loss: 0.1509687\n",
      "\tspeed: 0.0250s/iter; left time: 220.4691s\n",
      "\titers: 500, epoch: 6 | loss: 0.1605830\n",
      "\tspeed: 0.0241s/iter; left time: 209.8896s\n",
      "\titers: 600, epoch: 6 | loss: 0.1146489\n",
      "\tspeed: 0.0249s/iter; left time: 214.5029s\n",
      "Epoch: 6 cost time: 15.483290433883667\n",
      "Epoch: 6, Steps: 614 | Train Loss: 0.1613735 Vali Loss: 0.1863121 Test Loss: 0.2294632\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl24_ll8_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "Test cost time: 1.7111s\n",
      "test shape: (198, 32, 6, 1) (198, 32, 6, 1)\n",
      "test shape: (6336, 6, 1) (6336, 6, 1)\n",
      "mse:0.2239546924829483, mae:0.31815746426582336\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl24_ll8_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1623.554443359375\n",
      "MAE:  27.08915901184082\n",
      "RMSE: 40.29335403442383\n",
      "MAPE: 0.335635244846344\n",
      "MSPE: 0.5717995166778564\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll8_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 21009\n",
      "[DEBUG] Original dataset length: 21009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19676\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6844\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.3155006\n",
      "\tspeed: 0.0282s/iter; left time: 343.6539s\n",
      "\titers: 200, epoch: 1 | loss: 0.4139779\n",
      "\tspeed: 0.0253s/iter; left time: 305.2089s\n",
      "\titers: 300, epoch: 1 | loss: 0.2150141\n",
      "\tspeed: 0.0258s/iter; left time: 308.7126s\n",
      "\titers: 400, epoch: 1 | loss: 0.2645711\n",
      "\tspeed: 0.0245s/iter; left time: 291.4635s\n",
      "\titers: 500, epoch: 1 | loss: 0.1458218\n",
      "\tspeed: 0.0252s/iter; left time: 297.3646s\n",
      "\titers: 600, epoch: 1 | loss: 0.2833006\n",
      "\tspeed: 0.0261s/iter; left time: 304.3550s\n",
      "Epoch: 1 cost time: 15.84396743774414\n",
      "Epoch: 1, Steps: 614 | Train Loss: 0.2609080 Vali Loss: 0.2169402 Test Loss: 0.2447030\n",
      "Validation loss decreased (inf --> 0.216940).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2106729\n",
      "\tspeed: 0.0650s/iter; left time: 752.1345s\n",
      "\titers: 200, epoch: 2 | loss: 0.2188083\n",
      "\tspeed: 0.0254s/iter; left time: 291.3287s\n",
      "\titers: 300, epoch: 2 | loss: 0.1653984\n",
      "\tspeed: 0.0241s/iter; left time: 274.2875s\n",
      "\titers: 400, epoch: 2 | loss: 0.1423862\n",
      "\tspeed: 0.0254s/iter; left time: 286.0871s\n",
      "\titers: 500, epoch: 2 | loss: 0.1202390\n",
      "\tspeed: 0.0271s/iter; left time: 302.9022s\n",
      "\titers: 600, epoch: 2 | loss: 0.1757129\n",
      "\tspeed: 0.0236s/iter; left time: 261.4901s\n",
      "Epoch: 2 cost time: 15.36592960357666\n",
      "Epoch: 2, Steps: 614 | Train Loss: 0.2146774 Vali Loss: 0.1989321 Test Loss: 0.2323367\n",
      "Validation loss decreased (0.216940 --> 0.198932).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1415573\n",
      "\tspeed: 0.0625s/iter; left time: 684.5891s\n",
      "\titers: 200, epoch: 3 | loss: 0.1342495\n",
      "\tspeed: 0.0235s/iter; left time: 254.8178s\n",
      "\titers: 300, epoch: 3 | loss: 0.1604407\n",
      "\tspeed: 0.0260s/iter; left time: 279.8210s\n",
      "\titers: 400, epoch: 3 | loss: 0.2355258\n",
      "\tspeed: 0.0269s/iter; left time: 286.1069s\n",
      "\titers: 500, epoch: 3 | loss: 0.1294559\n",
      "\tspeed: 0.0259s/iter; left time: 273.8214s\n",
      "\titers: 600, epoch: 3 | loss: 0.2875795\n",
      "\tspeed: 0.0241s/iter; left time: 251.7108s\n",
      "Epoch: 3 cost time: 15.36045241355896\n",
      "Epoch: 3, Steps: 614 | Train Loss: 0.1904713 Vali Loss: 0.1955433 Test Loss: 0.2344306\n",
      "Validation loss decreased (0.198932 --> 0.195543).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2254146\n",
      "\tspeed: 0.0656s/iter; left time: 677.7849s\n",
      "\titers: 200, epoch: 4 | loss: 0.3942214\n",
      "\tspeed: 0.0286s/iter; left time: 293.2405s\n",
      "\titers: 300, epoch: 4 | loss: 0.2619787\n",
      "\tspeed: 0.0247s/iter; left time: 249.9573s\n",
      "\titers: 400, epoch: 4 | loss: 0.2109350\n",
      "\tspeed: 0.0234s/iter; left time: 235.4014s\n",
      "\titers: 500, epoch: 4 | loss: 0.2491518\n",
      "\tspeed: 0.0240s/iter; left time: 238.4645s\n",
      "\titers: 600, epoch: 4 | loss: 0.1509469\n",
      "\tspeed: 0.0240s/iter; left time: 236.1801s\n",
      "Epoch: 4 cost time: 15.483191013336182\n",
      "Epoch: 4, Steps: 614 | Train Loss: 0.1771866 Vali Loss: 0.1860521 Test Loss: 0.2209933\n",
      "Validation loss decreased (0.195543 --> 0.186052).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2073564\n",
      "\tspeed: 0.0668s/iter; left time: 649.5377s\n",
      "\titers: 200, epoch: 5 | loss: 0.2164766\n",
      "\tspeed: 0.0252s/iter; left time: 242.3087s\n",
      "\titers: 300, epoch: 5 | loss: 0.2027277\n",
      "\tspeed: 0.0250s/iter; left time: 238.0641s\n",
      "\titers: 400, epoch: 5 | loss: 0.1656175\n",
      "\tspeed: 0.0251s/iter; left time: 236.7985s\n",
      "\titers: 500, epoch: 5 | loss: 0.1640745\n",
      "\tspeed: 0.0246s/iter; left time: 229.0286s\n",
      "\titers: 600, epoch: 5 | loss: 0.1524794\n",
      "\tspeed: 0.0286s/iter; left time: 264.0286s\n",
      "Epoch: 5 cost time: 15.728644847869873\n",
      "Epoch: 5, Steps: 614 | Train Loss: 0.1695493 Vali Loss: 0.1855836 Test Loss: 0.2249072\n",
      "Validation loss decreased (0.186052 --> 0.185584).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1333022\n",
      "\tspeed: 0.0650s/iter; left time: 592.1789s\n",
      "\titers: 200, epoch: 6 | loss: 0.1757488\n",
      "\tspeed: 0.0253s/iter; left time: 228.2557s\n",
      "\titers: 300, epoch: 6 | loss: 0.1266014\n",
      "\tspeed: 0.0243s/iter; left time: 216.6735s\n",
      "\titers: 400, epoch: 6 | loss: 0.1601745\n",
      "\tspeed: 0.0270s/iter; left time: 237.8581s\n",
      "\titers: 500, epoch: 6 | loss: 0.1321122\n",
      "\tspeed: 0.0261s/iter; left time: 227.3412s\n",
      "\titers: 600, epoch: 6 | loss: 0.1259593\n",
      "\tspeed: 0.0248s/iter; left time: 213.9116s\n",
      "Epoch: 6 cost time: 15.625999927520752\n",
      "Epoch: 6, Steps: 614 | Train Loss: 0.1646791 Vali Loss: 0.1830227 Test Loss: 0.2198739\n",
      "Validation loss decreased (0.185584 --> 0.183023).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1205486\n",
      "\tspeed: 0.0643s/iter; left time: 546.5635s\n",
      "\titers: 200, epoch: 7 | loss: 0.1733093\n",
      "\tspeed: 0.0256s/iter; left time: 215.1900s\n",
      "\titers: 300, epoch: 7 | loss: 0.1371631\n",
      "\tspeed: 0.0284s/iter; left time: 235.4151s\n",
      "\titers: 400, epoch: 7 | loss: 0.1844656\n",
      "\tspeed: 0.0274s/iter; left time: 224.2957s\n",
      "\titers: 500, epoch: 7 | loss: 0.2199218\n",
      "\tspeed: 0.0260s/iter; left time: 210.3417s\n",
      "\titers: 600, epoch: 7 | loss: 0.1294857\n",
      "\tspeed: 0.0245s/iter; left time: 195.6626s\n",
      "Epoch: 7 cost time: 16.154793739318848\n",
      "Epoch: 7, Steps: 614 | Train Loss: 0.1619291 Vali Loss: 0.1863628 Test Loss: 0.2241376\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1606221\n",
      "\tspeed: 0.0665s/iter; left time: 523.8301s\n",
      "\titers: 200, epoch: 8 | loss: 0.1676751\n",
      "\tspeed: 0.0262s/iter; left time: 203.5734s\n",
      "\titers: 300, epoch: 8 | loss: 0.1278637\n",
      "\tspeed: 0.0262s/iter; left time: 201.3698s\n",
      "\titers: 400, epoch: 8 | loss: 0.3240260\n",
      "\tspeed: 0.0260s/iter; left time: 197.4595s\n",
      "\titers: 500, epoch: 8 | loss: 0.2336770\n",
      "\tspeed: 0.0250s/iter; left time: 187.1118s\n",
      "\titers: 600, epoch: 8 | loss: 0.1294826\n",
      "\tspeed: 0.0250s/iter; left time: 184.6883s\n",
      "Epoch: 8 cost time: 16.030925035476685\n",
      "Epoch: 8, Steps: 614 | Train Loss: 0.1604309 Vali Loss: 0.1869966 Test Loss: 0.2232061\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1440941\n",
      "\tspeed: 0.0636s/iter; left time: 462.2622s\n",
      "\titers: 200, epoch: 9 | loss: 0.1407869\n",
      "\tspeed: 0.0231s/iter; left time: 165.2935s\n",
      "\titers: 300, epoch: 9 | loss: 0.1040785\n",
      "\tspeed: 0.0242s/iter; left time: 171.2548s\n",
      "\titers: 400, epoch: 9 | loss: 0.1442226\n",
      "\tspeed: 0.0242s/iter; left time: 168.6304s\n",
      "\titers: 500, epoch: 9 | loss: 0.1656305\n",
      "\tspeed: 0.0253s/iter; left time: 173.6531s\n",
      "\titers: 600, epoch: 9 | loss: 0.0842901\n",
      "\tspeed: 0.0266s/iter; left time: 180.2030s\n",
      "Epoch: 9 cost time: 15.099498748779297\n",
      "Epoch: 9, Steps: 614 | Train Loss: 0.1593046 Vali Loss: 0.1855268 Test Loss: 0.2217265\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl24_ll8_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "Test cost time: 1.7588s\n",
      "test shape: (198, 32, 6, 1) (198, 32, 6, 1)\n",
      "test shape: (6336, 6, 1) (6336, 6, 1)\n",
      "mse:0.22040767967700958, mae:0.3135533332824707\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl24_ll8_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1597.8406982421875\n",
      "MAE:  26.697139739990234\n",
      "RMSE: 39.972999572753906\n",
      "MAPE: 0.3363465666770935\n",
      "MSPE: 0.5773400068283081\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl24_ll8_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 21009\n",
      "[DEBUG] Original dataset length: 21009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19676\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6844\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "\titers: 100, epoch: 1 | loss: 0.2240220\n",
      "\tspeed: 0.0257s/iter; left time: 313.2167s\n",
      "\titers: 200, epoch: 1 | loss: 0.1986730\n",
      "\tspeed: 0.0261s/iter; left time: 314.7644s\n",
      "\titers: 300, epoch: 1 | loss: 0.2948971\n",
      "\tspeed: 0.0281s/iter; left time: 336.1238s\n",
      "\titers: 400, epoch: 1 | loss: 0.2490925\n",
      "\tspeed: 0.0244s/iter; left time: 289.4102s\n",
      "\titers: 500, epoch: 1 | loss: 0.1802268\n",
      "\tspeed: 0.0247s/iter; left time: 290.7881s\n",
      "\titers: 600, epoch: 1 | loss: 0.3227193\n",
      "\tspeed: 0.0243s/iter; left time: 283.9984s\n",
      "Epoch: 1 cost time: 15.686613321304321\n",
      "Epoch: 1, Steps: 614 | Train Loss: 0.2647407 Vali Loss: 0.2215206 Test Loss: 0.2582771\n",
      "Validation loss decreased (inf --> 0.221521).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2243596\n",
      "\tspeed: 0.0633s/iter; left time: 732.6721s\n",
      "\titers: 200, epoch: 2 | loss: 0.1735912\n",
      "\tspeed: 0.0260s/iter; left time: 297.9746s\n",
      "\titers: 300, epoch: 2 | loss: 0.2250124\n",
      "\tspeed: 0.0258s/iter; left time: 293.5484s\n",
      "\titers: 400, epoch: 2 | loss: 0.3053123\n",
      "\tspeed: 0.0278s/iter; left time: 313.4450s\n",
      "\titers: 500, epoch: 2 | loss: 0.2638804\n",
      "\tspeed: 0.0260s/iter; left time: 290.6617s\n",
      "\titers: 600, epoch: 2 | loss: 0.1821026\n",
      "\tspeed: 0.0256s/iter; left time: 283.6765s\n",
      "Epoch: 2 cost time: 15.9954993724823\n",
      "Epoch: 2, Steps: 614 | Train Loss: 0.2142525 Vali Loss: 0.2015357 Test Loss: 0.2263049\n",
      "Validation loss decreased (0.221521 --> 0.201536).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2336070\n",
      "\tspeed: 0.0656s/iter; left time: 718.4861s\n",
      "\titers: 200, epoch: 3 | loss: 0.3520754\n",
      "\tspeed: 0.0237s/iter; left time: 257.3203s\n",
      "\titers: 300, epoch: 3 | loss: 0.1140396\n",
      "\tspeed: 0.0257s/iter; left time: 276.0464s\n",
      "\titers: 400, epoch: 3 | loss: 0.2224608\n",
      "\tspeed: 0.0259s/iter; left time: 276.2684s\n",
      "\titers: 500, epoch: 3 | loss: 0.1549388\n",
      "\tspeed: 0.0275s/iter; left time: 290.3794s\n",
      "\titers: 600, epoch: 3 | loss: 0.1722060\n",
      "\tspeed: 0.0256s/iter; left time: 267.6001s\n",
      "Epoch: 3 cost time: 15.697534799575806\n",
      "Epoch: 3, Steps: 614 | Train Loss: 0.1904553 Vali Loss: 0.1904713 Test Loss: 0.2257936\n",
      "Validation loss decreased (0.201536 --> 0.190471).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1634023\n",
      "\tspeed: 0.0637s/iter; left time: 658.4287s\n",
      "\titers: 200, epoch: 4 | loss: 0.3318161\n",
      "\tspeed: 0.0243s/iter; left time: 248.8686s\n",
      "\titers: 300, epoch: 4 | loss: 0.2384575\n",
      "\tspeed: 0.0261s/iter; left time: 264.4590s\n",
      "\titers: 400, epoch: 4 | loss: 0.1854358\n",
      "\tspeed: 0.0266s/iter; left time: 266.8292s\n",
      "\titers: 500, epoch: 4 | loss: 0.1481404\n",
      "\tspeed: 0.0248s/iter; left time: 246.5131s\n",
      "\titers: 600, epoch: 4 | loss: 0.3942479\n",
      "\tspeed: 0.0241s/iter; left time: 237.5734s\n",
      "Epoch: 4 cost time: 15.46385908126831\n",
      "Epoch: 4, Steps: 614 | Train Loss: 0.1772326 Vali Loss: 0.1853785 Test Loss: 0.2244285\n",
      "Validation loss decreased (0.190471 --> 0.185378).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1865869\n",
      "\tspeed: 0.0640s/iter; left time: 622.8760s\n",
      "\titers: 200, epoch: 5 | loss: 0.1719176\n",
      "\tspeed: 0.0261s/iter; left time: 251.3852s\n",
      "\titers: 300, epoch: 5 | loss: 0.1343560\n",
      "\tspeed: 0.0251s/iter; left time: 239.4283s\n",
      "\titers: 400, epoch: 5 | loss: 0.1443311\n",
      "\tspeed: 0.0248s/iter; left time: 233.3440s\n",
      "\titers: 500, epoch: 5 | loss: 0.1522672\n",
      "\tspeed: 0.0240s/iter; left time: 223.8122s\n",
      "\titers: 600, epoch: 5 | loss: 0.1319317\n",
      "\tspeed: 0.0248s/iter; left time: 228.7881s\n",
      "Epoch: 5 cost time: 15.345613241195679\n",
      "Epoch: 5, Steps: 614 | Train Loss: 0.1690075 Vali Loss: 0.1859958 Test Loss: 0.2245257\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1657373\n",
      "\tspeed: 0.0627s/iter; left time: 571.3207s\n",
      "\titers: 200, epoch: 6 | loss: 0.1371373\n",
      "\tspeed: 0.0248s/iter; left time: 223.2698s\n",
      "\titers: 300, epoch: 6 | loss: 0.1963868\n",
      "\tspeed: 0.0246s/iter; left time: 219.4394s\n",
      "\titers: 400, epoch: 6 | loss: 0.1436638\n",
      "\tspeed: 0.0254s/iter; left time: 223.8201s\n",
      "\titers: 500, epoch: 6 | loss: 0.2042499\n",
      "\tspeed: 0.0249s/iter; left time: 216.7464s\n",
      "\titers: 600, epoch: 6 | loss: 0.1497800\n",
      "\tspeed: 0.0246s/iter; left time: 211.7037s\n",
      "Epoch: 6 cost time: 15.412862300872803\n",
      "Epoch: 6, Steps: 614 | Train Loss: 0.1628588 Vali Loss: 0.1867969 Test Loss: 0.2223711\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1660796\n",
      "\tspeed: 0.0644s/iter; left time: 547.3782s\n",
      "\titers: 200, epoch: 7 | loss: 0.1598535\n",
      "\tspeed: 0.0234s/iter; left time: 196.5471s\n",
      "\titers: 300, epoch: 7 | loss: 0.2440025\n",
      "\tspeed: 0.0244s/iter; left time: 202.2175s\n",
      "\titers: 400, epoch: 7 | loss: 0.0938348\n",
      "\tspeed: 0.0256s/iter; left time: 209.5352s\n",
      "\titers: 500, epoch: 7 | loss: 0.0939096\n",
      "\tspeed: 0.0255s/iter; left time: 206.5673s\n",
      "\titers: 600, epoch: 7 | loss: 0.1955187\n",
      "\tspeed: 0.0256s/iter; left time: 204.8989s\n",
      "Epoch: 7 cost time: 15.278728008270264\n",
      "Epoch: 7, Steps: 614 | Train Loss: 0.1598688 Vali Loss: 0.1872943 Test Loss: 0.2222335\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl24_ll8_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6357\n",
      "Test cost time: 1.6301s\n",
      "test shape: (198, 32, 6, 1) (198, 32, 6, 1)\n",
      "test shape: (6336, 6, 1) (6336, 6, 1)\n",
      "mse:0.22457388043403625, mae:0.3138121962547302\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl24_ll8_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1628.04345703125\n",
      "MAE:  26.719181060791016\n",
      "RMSE: 40.349021911621094\n",
      "MAPE: 0.31117022037506104\n",
      "MSPE: 0.4638427197933197\n",
      ">>>>>>>Running time saved<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Running seq_len=48, label_len=16, pred_len=6\n",
      "Args in experiment:\n",
      "Namespace(model='informer', data='traffic_full', root_path='../', data_path='traffic_full.csv', features='S', target='flow', freq='h', checkpoints='./checkpoints/', seq_len=48, label_len=16, pred_len=6, enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=2, d_layers=1, s_layers=[3, 2, 1], d_ff=2048, factor=5, padding=0, distil=True, dropout=0.05, attn='prob', embed='timeF', activation='gelu', output_attention=False, do_predict=False, mix=True, cols=None, num_workers=0, itr=10, train_epochs=20, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, inverse=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', detail_freq='h')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl48_ll16_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20985\n",
      "[DEBUG] Original dataset length: 20985\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19316\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6772\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "\titers: 100, epoch: 1 | loss: 0.2939302\n",
      "\tspeed: 0.0490s/iter; left time: 586.1355s\n",
      "\titers: 200, epoch: 1 | loss: 0.3117375\n",
      "\tspeed: 0.0261s/iter; left time: 309.4862s\n",
      "\titers: 300, epoch: 1 | loss: 0.3359863\n",
      "\tspeed: 0.0272s/iter; left time: 320.1724s\n",
      "\titers: 400, epoch: 1 | loss: 0.2667782\n",
      "\tspeed: 0.0272s/iter; left time: 317.3151s\n",
      "\titers: 500, epoch: 1 | loss: 0.1584296\n",
      "\tspeed: 0.0289s/iter; left time: 334.5097s\n",
      "\titers: 600, epoch: 1 | loss: 0.3099288\n",
      "\tspeed: 0.0278s/iter; left time: 318.2754s\n",
      "Epoch: 1 cost time: 17.798187255859375\n",
      "Epoch: 1, Steps: 603 | Train Loss: 0.2938212 Vali Loss: 0.2213260 Test Loss: 0.2641283\n",
      "Validation loss decreased (inf --> 0.221326).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1642684\n",
      "\tspeed: 0.0686s/iter; left time: 779.3757s\n",
      "\titers: 200, epoch: 2 | loss: 0.2178786\n",
      "\tspeed: 0.0270s/iter; left time: 303.9135s\n",
      "\titers: 300, epoch: 2 | loss: 0.2709255\n",
      "\tspeed: 0.0257s/iter; left time: 287.1683s\n",
      "\titers: 400, epoch: 2 | loss: 0.1975669\n",
      "\tspeed: 0.0296s/iter; left time: 326.8080s\n",
      "\titers: 500, epoch: 2 | loss: 0.1374940\n",
      "\tspeed: 0.0287s/iter; left time: 314.6988s\n",
      "\titers: 600, epoch: 2 | loss: 0.2296504\n",
      "\tspeed: 0.0275s/iter; left time: 298.0737s\n",
      "Epoch: 2 cost time: 16.79501438140869\n",
      "Epoch: 2, Steps: 603 | Train Loss: 0.2168567 Vali Loss: 0.2007542 Test Loss: 0.2457608\n",
      "Validation loss decreased (0.221326 --> 0.200754).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1376173\n",
      "\tspeed: 0.0668s/iter; left time: 718.7996s\n",
      "\titers: 200, epoch: 3 | loss: 0.2244036\n",
      "\tspeed: 0.0295s/iter; left time: 314.3382s\n",
      "\titers: 300, epoch: 3 | loss: 0.1292332\n",
      "\tspeed: 0.0280s/iter; left time: 295.3312s\n",
      "\titers: 400, epoch: 3 | loss: 0.1498229\n",
      "\tspeed: 0.0262s/iter; left time: 273.9527s\n",
      "\titers: 500, epoch: 3 | loss: 0.1913774\n",
      "\tspeed: 0.0273s/iter; left time: 282.9198s\n",
      "\titers: 600, epoch: 3 | loss: 0.1808277\n",
      "\tspeed: 0.0257s/iter; left time: 263.2526s\n",
      "Epoch: 3 cost time: 16.57394552230835\n",
      "Epoch: 3, Steps: 603 | Train Loss: 0.1915974 Vali Loss: 0.1957914 Test Loss: 0.2358707\n",
      "Validation loss decreased (0.200754 --> 0.195791).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1291241\n",
      "\tspeed: 0.0689s/iter; left time: 699.0871s\n",
      "\titers: 200, epoch: 4 | loss: 0.2046197\n",
      "\tspeed: 0.0271s/iter; left time: 271.9996s\n",
      "\titers: 300, epoch: 4 | loss: 0.2563699\n",
      "\tspeed: 0.0266s/iter; left time: 264.2475s\n",
      "\titers: 400, epoch: 4 | loss: 0.1421063\n",
      "\tspeed: 0.0273s/iter; left time: 269.1298s\n",
      "\titers: 500, epoch: 4 | loss: 0.2199307\n",
      "\tspeed: 0.0279s/iter; left time: 272.2962s\n",
      "\titers: 600, epoch: 4 | loss: 0.1906538\n",
      "\tspeed: 0.0279s/iter; left time: 268.9386s\n",
      "Epoch: 4 cost time: 16.532638788223267\n",
      "Epoch: 4, Steps: 603 | Train Loss: 0.1755671 Vali Loss: 0.1946344 Test Loss: 0.2305182\n",
      "Validation loss decreased (0.195791 --> 0.194634).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1744290\n",
      "\tspeed: 0.0661s/iter; left time: 631.6605s\n",
      "\titers: 200, epoch: 5 | loss: 0.1766590\n",
      "\tspeed: 0.0258s/iter; left time: 243.3882s\n",
      "\titers: 300, epoch: 5 | loss: 0.1383552\n",
      "\tspeed: 0.0279s/iter; left time: 260.6854s\n",
      "\titers: 400, epoch: 5 | loss: 0.2161062\n",
      "\tspeed: 0.0286s/iter; left time: 264.3316s\n",
      "\titers: 500, epoch: 5 | loss: 0.1766438\n",
      "\tspeed: 0.0273s/iter; left time: 249.9578s\n",
      "\titers: 600, epoch: 5 | loss: 0.1703339\n",
      "\tspeed: 0.0260s/iter; left time: 235.5859s\n",
      "Epoch: 5 cost time: 16.37102699279785\n",
      "Epoch: 5, Steps: 603 | Train Loss: 0.1666040 Vali Loss: 0.1960858 Test Loss: 0.2318868\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1672039\n",
      "\tspeed: 0.0651s/iter; left time: 582.4488s\n",
      "\titers: 200, epoch: 6 | loss: 0.2061069\n",
      "\tspeed: 0.0301s/iter; left time: 266.0998s\n",
      "\titers: 300, epoch: 6 | loss: 0.1316927\n",
      "\tspeed: 0.0241s/iter; left time: 211.0774s\n",
      "\titers: 400, epoch: 6 | loss: 0.1637528\n",
      "\tspeed: 0.0249s/iter; left time: 214.8651s\n",
      "\titers: 500, epoch: 6 | loss: 0.1332066\n",
      "\tspeed: 0.0261s/iter; left time: 222.6887s\n",
      "\titers: 600, epoch: 6 | loss: 0.1219484\n",
      "\tspeed: 0.0268s/iter; left time: 226.6342s\n",
      "Epoch: 6 cost time: 16.0563542842865\n",
      "Epoch: 6, Steps: 603 | Train Loss: 0.1620933 Vali Loss: 0.1919515 Test Loss: 0.2288339\n",
      "Validation loss decreased (0.194634 --> 0.191951).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1595930\n",
      "\tspeed: 0.0703s/iter; left time: 586.1818s\n",
      "\titers: 200, epoch: 7 | loss: 0.2478271\n",
      "\tspeed: 0.0264s/iter; left time: 217.9683s\n",
      "\titers: 300, epoch: 7 | loss: 0.3015774\n",
      "\tspeed: 0.0265s/iter; left time: 215.8227s\n",
      "\titers: 400, epoch: 7 | loss: 0.1673033\n",
      "\tspeed: 0.0301s/iter; left time: 241.7039s\n",
      "\titers: 500, epoch: 7 | loss: 0.1707987\n",
      "\tspeed: 0.0286s/iter; left time: 227.0514s\n",
      "\titers: 600, epoch: 7 | loss: 0.1666659\n",
      "\tspeed: 0.0289s/iter; left time: 226.5992s\n",
      "Epoch: 7 cost time: 16.960070610046387\n",
      "Epoch: 7, Steps: 603 | Train Loss: 0.1586902 Vali Loss: 0.1925916 Test Loss: 0.2296095\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1909680\n",
      "\tspeed: 0.0663s/iter; left time: 513.5061s\n",
      "\titers: 200, epoch: 8 | loss: 0.1359024\n",
      "\tspeed: 0.0276s/iter; left time: 211.1019s\n",
      "\titers: 300, epoch: 8 | loss: 0.2480237\n",
      "\tspeed: 0.0299s/iter; left time: 225.3065s\n",
      "\titers: 400, epoch: 8 | loss: 0.1143311\n",
      "\tspeed: 0.0274s/iter; left time: 203.5784s\n",
      "\titers: 500, epoch: 8 | loss: 0.1576471\n",
      "\tspeed: 0.0286s/iter; left time: 210.2631s\n",
      "\titers: 600, epoch: 8 | loss: 0.1761259\n",
      "\tspeed: 0.0283s/iter; left time: 205.2052s\n",
      "Epoch: 8 cost time: 17.01610016822815\n",
      "Epoch: 8, Steps: 603 | Train Loss: 0.1565275 Vali Loss: 0.1923343 Test Loss: 0.2290901\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1688540\n",
      "\tspeed: 0.0699s/iter; left time: 498.5225s\n",
      "\titers: 200, epoch: 9 | loss: 0.1207337\n",
      "\tspeed: 0.0268s/iter; left time: 188.9073s\n",
      "\titers: 300, epoch: 9 | loss: 0.1528987\n",
      "\tspeed: 0.0278s/iter; left time: 192.5308s\n",
      "\titers: 400, epoch: 9 | loss: 0.1149938\n",
      "\tspeed: 0.0277s/iter; left time: 189.4419s\n",
      "\titers: 500, epoch: 9 | loss: 0.2001331\n",
      "\tspeed: 0.0276s/iter; left time: 185.7051s\n",
      "\titers: 600, epoch: 9 | loss: 0.1305967\n",
      "\tspeed: 0.0268s/iter; left time: 177.8385s\n",
      "Epoch: 9 cost time: 16.731398820877075\n",
      "Epoch: 9, Steps: 603 | Train Loss: 0.1560289 Vali Loss: 0.1915800 Test Loss: 0.2301921\n",
      "Validation loss decreased (0.191951 --> 0.191580).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.1052354\n",
      "\tspeed: 0.0705s/iter; left time: 460.6723s\n",
      "\titers: 200, epoch: 10 | loss: 0.1462633\n",
      "\tspeed: 0.0274s/iter; left time: 176.3308s\n",
      "\titers: 300, epoch: 10 | loss: 0.1513495\n",
      "\tspeed: 0.0283s/iter; left time: 179.2925s\n",
      "\titers: 400, epoch: 10 | loss: 0.1484309\n",
      "\tspeed: 0.0283s/iter; left time: 176.2411s\n",
      "\titers: 500, epoch: 10 | loss: 0.1071354\n",
      "\tspeed: 0.0302s/iter; left time: 185.2859s\n",
      "\titers: 600, epoch: 10 | loss: 0.2043748\n",
      "\tspeed: 0.0268s/iter; left time: 161.7571s\n",
      "Epoch: 10 cost time: 17.001898765563965\n",
      "Epoch: 10, Steps: 603 | Train Loss: 0.1557607 Vali Loss: 0.1911295 Test Loss: 0.2292791\n",
      "Validation loss decreased (0.191580 --> 0.191129).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.2927870\n",
      "\tspeed: 0.0676s/iter; left time: 401.2208s\n",
      "\titers: 200, epoch: 11 | loss: 0.1407440\n",
      "\tspeed: 0.0294s/iter; left time: 171.6086s\n",
      "\titers: 300, epoch: 11 | loss: 0.1392477\n",
      "\tspeed: 0.0288s/iter; left time: 165.1166s\n",
      "\titers: 400, epoch: 11 | loss: 0.1185789\n",
      "\tspeed: 0.0288s/iter; left time: 162.0026s\n",
      "\titers: 500, epoch: 11 | loss: 0.1593135\n",
      "\tspeed: 0.0280s/iter; left time: 155.0151s\n",
      "\titers: 600, epoch: 11 | loss: 0.2289603\n",
      "\tspeed: 0.0265s/iter; left time: 144.1511s\n",
      "Epoch: 11 cost time: 17.00412654876709\n",
      "Epoch: 11, Steps: 603 | Train Loss: 0.1558640 Vali Loss: 0.1913450 Test Loss: 0.2286719\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.1943651\n",
      "\tspeed: 0.0657s/iter; left time: 349.8112s\n",
      "\titers: 200, epoch: 12 | loss: 0.2142932\n",
      "\tspeed: 0.0265s/iter; left time: 138.5030s\n",
      "\titers: 300, epoch: 12 | loss: 0.0769674\n",
      "\tspeed: 0.0280s/iter; left time: 143.5570s\n",
      "\titers: 400, epoch: 12 | loss: 0.1477056\n",
      "\tspeed: 0.0275s/iter; left time: 138.3475s\n",
      "\titers: 500, epoch: 12 | loss: 0.2097076\n",
      "\tspeed: 0.0286s/iter; left time: 140.7597s\n",
      "\titers: 600, epoch: 12 | loss: 0.2643215\n",
      "\tspeed: 0.0288s/iter; left time: 138.9196s\n",
      "Epoch: 12 cost time: 16.66579818725586\n",
      "Epoch: 12, Steps: 603 | Train Loss: 0.1555590 Vali Loss: 0.1914206 Test Loss: 0.2288481\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      "\titers: 100, epoch: 13 | loss: 0.1124392\n",
      "\tspeed: 0.0665s/iter; left time: 314.0170s\n",
      "\titers: 200, epoch: 13 | loss: 0.2001101\n",
      "\tspeed: 0.0267s/iter; left time: 123.5135s\n",
      "\titers: 300, epoch: 13 | loss: 0.1393477\n",
      "\tspeed: 0.0275s/iter; left time: 124.3606s\n",
      "\titers: 400, epoch: 13 | loss: 0.1000935\n",
      "\tspeed: 0.0284s/iter; left time: 125.7112s\n",
      "\titers: 500, epoch: 13 | loss: 0.1376600\n",
      "\tspeed: 0.0283s/iter; left time: 122.5691s\n",
      "\titers: 600, epoch: 13 | loss: 0.1774143\n",
      "\tspeed: 0.0275s/iter; left time: 116.2682s\n",
      "Epoch: 13 cost time: 16.61994981765747\n",
      "Epoch: 13, Steps: 603 | Train Loss: 0.1554522 Vali Loss: 0.1911324 Test Loss: 0.2289528\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl48_ll16_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "Test cost time: 1.7951s\n",
      "test shape: (192, 32, 6, 1) (192, 32, 6, 1)\n",
      "test shape: (6144, 6, 1) (6144, 6, 1)\n",
      "mse:0.22928258776664734, mae:0.31729137897491455\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl48_ll16_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1662.17919921875\n",
      "MAE:  27.01541519165039\n",
      "RMSE: 40.769832611083984\n",
      "MAPE: 0.3352186977863312\n",
      "MSPE: 0.5014934539794922\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl48_ll16_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20985\n",
      "[DEBUG] Original dataset length: 20985\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19316\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6772\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "\titers: 100, epoch: 1 | loss: 0.2543627\n",
      "\tspeed: 0.0287s/iter; left time: 343.4766s\n",
      "\titers: 200, epoch: 1 | loss: 0.2433741\n",
      "\tspeed: 0.0275s/iter; left time: 326.3054s\n",
      "\titers: 300, epoch: 1 | loss: 0.1819980\n",
      "\tspeed: 0.0275s/iter; left time: 323.3559s\n",
      "\titers: 400, epoch: 1 | loss: 0.2746290\n",
      "\tspeed: 0.0269s/iter; left time: 313.7840s\n",
      "\titers: 500, epoch: 1 | loss: 0.2501484\n",
      "\tspeed: 0.0268s/iter; left time: 309.6215s\n",
      "\titers: 600, epoch: 1 | loss: 0.1328936\n",
      "\tspeed: 0.0287s/iter; left time: 329.3822s\n",
      "Epoch: 1 cost time: 16.714446544647217\n",
      "Epoch: 1, Steps: 603 | Train Loss: 0.2947832 Vali Loss: 0.2238170 Test Loss: 0.2603659\n",
      "Validation loss decreased (inf --> 0.223817).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2139259\n",
      "\tspeed: 0.0686s/iter; left time: 778.8209s\n",
      "\titers: 200, epoch: 2 | loss: 0.1948795\n",
      "\tspeed: 0.0271s/iter; left time: 305.4457s\n",
      "\titers: 300, epoch: 2 | loss: 0.2079220\n",
      "\tspeed: 0.0269s/iter; left time: 300.5781s\n",
      "\titers: 400, epoch: 2 | loss: 0.2007839\n",
      "\tspeed: 0.0293s/iter; left time: 323.9728s\n",
      "\titers: 500, epoch: 2 | loss: 0.1981015\n",
      "\tspeed: 0.0271s/iter; left time: 296.7392s\n",
      "\titers: 600, epoch: 2 | loss: 0.2740822\n",
      "\tspeed: 0.0270s/iter; left time: 293.4788s\n",
      "Epoch: 2 cost time: 16.539384841918945\n",
      "Epoch: 2, Steps: 603 | Train Loss: 0.2194328 Vali Loss: 0.2031089 Test Loss: 0.2423521\n",
      "Validation loss decreased (0.223817 --> 0.203109).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1538066\n",
      "\tspeed: 0.0674s/iter; left time: 725.3788s\n",
      "\titers: 200, epoch: 3 | loss: 0.2545019\n",
      "\tspeed: 0.0292s/iter; left time: 310.9010s\n",
      "\titers: 300, epoch: 3 | loss: 0.3168611\n",
      "\tspeed: 0.0270s/iter; left time: 284.4773s\n",
      "\titers: 400, epoch: 3 | loss: 0.1843410\n",
      "\tspeed: 0.0254s/iter; left time: 265.4501s\n",
      "\titers: 500, epoch: 3 | loss: 0.2405500\n",
      "\tspeed: 0.0261s/iter; left time: 270.3571s\n",
      "\titers: 600, epoch: 3 | loss: 0.1497475\n",
      "\tspeed: 0.0268s/iter; left time: 274.6589s\n",
      "Epoch: 3 cost time: 16.358574628829956\n",
      "Epoch: 3, Steps: 603 | Train Loss: 0.1903487 Vali Loss: 0.2034820 Test Loss: 0.2423428\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1521146\n",
      "\tspeed: 0.0641s/iter; left time: 650.4101s\n",
      "\titers: 200, epoch: 4 | loss: 0.1728579\n",
      "\tspeed: 0.0261s/iter; left time: 262.5203s\n",
      "\titers: 300, epoch: 4 | loss: 0.1391570\n",
      "\tspeed: 0.0268s/iter; left time: 266.4013s\n",
      "\titers: 400, epoch: 4 | loss: 0.1658420\n",
      "\tspeed: 0.0262s/iter; left time: 257.9854s\n",
      "\titers: 500, epoch: 4 | loss: 0.1713867\n",
      "\tspeed: 0.0256s/iter; left time: 249.2059s\n",
      "\titers: 600, epoch: 4 | loss: 0.1753833\n",
      "\tspeed: 0.0286s/iter; left time: 276.3938s\n",
      "Epoch: 4 cost time: 16.117119789123535\n",
      "Epoch: 4, Steps: 603 | Train Loss: 0.1754791 Vali Loss: 0.1960511 Test Loss: 0.2273927\n",
      "Validation loss decreased (0.203109 --> 0.196051).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1611022\n",
      "\tspeed: 0.0649s/iter; left time: 620.1603s\n",
      "\titers: 200, epoch: 5 | loss: 0.1796622\n",
      "\tspeed: 0.0253s/iter; left time: 238.9414s\n",
      "\titers: 300, epoch: 5 | loss: 0.1352907\n",
      "\tspeed: 0.0255s/iter; left time: 238.4660s\n",
      "\titers: 400, epoch: 5 | loss: 0.1216780\n",
      "\tspeed: 0.0294s/iter; left time: 271.5658s\n",
      "\titers: 500, epoch: 5 | loss: 0.1300617\n",
      "\tspeed: 0.0269s/iter; left time: 245.8448s\n",
      "\titers: 600, epoch: 5 | loss: 0.1425456\n",
      "\tspeed: 0.0259s/iter; left time: 234.0687s\n",
      "Epoch: 5 cost time: 15.984268426895142\n",
      "Epoch: 5, Steps: 603 | Train Loss: 0.1666980 Vali Loss: 0.1868573 Test Loss: 0.2209479\n",
      "Validation loss decreased (0.196051 --> 0.186857).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1607468\n",
      "\tspeed: 0.0628s/iter; left time: 562.0938s\n",
      "\titers: 200, epoch: 6 | loss: 0.2076115\n",
      "\tspeed: 0.0262s/iter; left time: 231.4172s\n",
      "\titers: 300, epoch: 6 | loss: 0.1590209\n",
      "\tspeed: 0.0272s/iter; left time: 237.7676s\n",
      "\titers: 400, epoch: 6 | loss: 0.1625776\n",
      "\tspeed: 0.0266s/iter; left time: 229.6315s\n",
      "\titers: 500, epoch: 6 | loss: 0.1618621\n",
      "\tspeed: 0.0265s/iter; left time: 226.3924s\n",
      "\titers: 600, epoch: 6 | loss: 0.1648853\n",
      "\tspeed: 0.0253s/iter; left time: 213.3332s\n",
      "Epoch: 6 cost time: 15.796377420425415\n",
      "Epoch: 6, Steps: 603 | Train Loss: 0.1616754 Vali Loss: 0.1858442 Test Loss: 0.2253785\n",
      "Validation loss decreased (0.186857 --> 0.185844).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1411962\n",
      "\tspeed: 0.0686s/iter; left time: 571.9310s\n",
      "\titers: 200, epoch: 7 | loss: 0.2333084\n",
      "\tspeed: 0.0276s/iter; left time: 227.8840s\n",
      "\titers: 300, epoch: 7 | loss: 0.1559913\n",
      "\tspeed: 0.0260s/iter; left time: 211.7708s\n",
      "\titers: 400, epoch: 7 | loss: 0.1747368\n",
      "\tspeed: 0.0260s/iter; left time: 208.9320s\n",
      "\titers: 500, epoch: 7 | loss: 0.1381931\n",
      "\tspeed: 0.0264s/iter; left time: 209.8364s\n",
      "\titers: 600, epoch: 7 | loss: 0.1676274\n",
      "\tspeed: 0.0273s/iter; left time: 214.3161s\n",
      "Epoch: 7 cost time: 16.364790201187134\n",
      "Epoch: 7, Steps: 603 | Train Loss: 0.1587264 Vali Loss: 0.1901672 Test Loss: 0.2292095\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0693406\n",
      "\tspeed: 0.0663s/iter; left time: 513.3496s\n",
      "\titers: 200, epoch: 8 | loss: 0.2162443\n",
      "\tspeed: 0.0253s/iter; left time: 193.6621s\n",
      "\titers: 300, epoch: 8 | loss: 0.1477260\n",
      "\tspeed: 0.0266s/iter; left time: 200.9354s\n",
      "\titers: 400, epoch: 8 | loss: 0.1977099\n",
      "\tspeed: 0.0210s/iter; left time: 156.0880s\n",
      "\titers: 500, epoch: 8 | loss: 0.1026112\n",
      "\tspeed: 0.0244s/iter; left time: 178.7796s\n",
      "\titers: 600, epoch: 8 | loss: 0.3206742\n",
      "\tspeed: 0.0240s/iter; left time: 173.9185s\n",
      "Epoch: 8 cost time: 14.947379112243652\n",
      "Epoch: 8, Steps: 603 | Train Loss: 0.1572360 Vali Loss: 0.1890794 Test Loss: 0.2269336\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1896844\n",
      "\tspeed: 0.0693s/iter; left time: 494.7364s\n",
      "\titers: 200, epoch: 9 | loss: 0.1624594\n",
      "\tspeed: 0.0278s/iter; left time: 195.5141s\n",
      "\titers: 300, epoch: 9 | loss: 0.1747518\n",
      "\tspeed: 0.0305s/iter; left time: 211.5712s\n",
      "\titers: 400, epoch: 9 | loss: 0.1057512\n",
      "\tspeed: 0.0287s/iter; left time: 196.0831s\n",
      "\titers: 500, epoch: 9 | loss: 0.1489500\n",
      "\tspeed: 0.0278s/iter; left time: 187.5058s\n",
      "\titers: 600, epoch: 9 | loss: 0.1331702\n",
      "\tspeed: 0.0280s/iter; left time: 185.8673s\n",
      "Epoch: 9 cost time: 17.303776264190674\n",
      "Epoch: 9, Steps: 603 | Train Loss: 0.1565453 Vali Loss: 0.1900896 Test Loss: 0.2281260\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl48_ll16_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "Test cost time: 1.9964s\n",
      "test shape: (192, 32, 6, 1) (192, 32, 6, 1)\n",
      "test shape: (6144, 6, 1) (6144, 6, 1)\n",
      "mse:0.22514520585536957, mae:0.31746557354927063\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl48_ll16_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1632.1851806640625\n",
      "MAE:  27.03024673461914\n",
      "RMSE: 40.40031051635742\n",
      "MAPE: 0.3499700427055359\n",
      "MSPE: 0.6239498853683472\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl48_ll16_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20985\n",
      "[DEBUG] Original dataset length: 20985\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19316\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6772\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "\titers: 100, epoch: 1 | loss: 0.2170367\n",
      "\tspeed: 0.0285s/iter; left time: 340.6432s\n",
      "\titers: 200, epoch: 1 | loss: 0.2573588\n",
      "\tspeed: 0.0274s/iter; left time: 325.4867s\n",
      "\titers: 300, epoch: 1 | loss: 0.4902624\n",
      "\tspeed: 0.0300s/iter; left time: 353.1824s\n",
      "\titers: 400, epoch: 1 | loss: 0.2863710\n",
      "\tspeed: 0.0279s/iter; left time: 325.1715s\n",
      "\titers: 500, epoch: 1 | loss: 0.2611087\n",
      "\tspeed: 0.0301s/iter; left time: 347.6095s\n",
      "\titers: 600, epoch: 1 | loss: 0.2239169\n",
      "\tspeed: 0.0288s/iter; left time: 330.4008s\n",
      "Epoch: 1 cost time: 17.381980180740356\n",
      "Epoch: 1, Steps: 603 | Train Loss: 0.2905672 Vali Loss: 0.2068889 Test Loss: 0.2424793\n",
      "Validation loss decreased (inf --> 0.206889).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2346256\n",
      "\tspeed: 0.0707s/iter; left time: 803.4946s\n",
      "\titers: 200, epoch: 2 | loss: 0.1813003\n",
      "\tspeed: 0.0284s/iter; left time: 319.6270s\n",
      "\titers: 300, epoch: 2 | loss: 0.1862070\n",
      "\tspeed: 0.0313s/iter; left time: 349.7059s\n",
      "\titers: 400, epoch: 2 | loss: 0.3104570\n",
      "\tspeed: 0.0292s/iter; left time: 322.8893s\n",
      "\titers: 500, epoch: 2 | loss: 0.1992100\n",
      "\tspeed: 0.0294s/iter; left time: 322.5419s\n",
      "\titers: 600, epoch: 2 | loss: 0.1894250\n",
      "\tspeed: 0.0288s/iter; left time: 313.0493s\n",
      "Epoch: 2 cost time: 17.660674810409546\n",
      "Epoch: 2, Steps: 603 | Train Loss: 0.2160407 Vali Loss: 0.2083438 Test Loss: 0.2360956\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2541291\n",
      "\tspeed: 0.0701s/iter; left time: 753.4755s\n",
      "\titers: 200, epoch: 3 | loss: 0.1734619\n",
      "\tspeed: 0.0281s/iter; left time: 299.0199s\n",
      "\titers: 300, epoch: 3 | loss: 0.2848147\n",
      "\tspeed: 0.0281s/iter; left time: 296.6712s\n",
      "\titers: 400, epoch: 3 | loss: 0.1569394\n",
      "\tspeed: 0.0275s/iter; left time: 287.8323s\n",
      "\titers: 500, epoch: 3 | loss: 0.1999632\n",
      "\tspeed: 0.0281s/iter; left time: 290.9481s\n",
      "\titers: 600, epoch: 3 | loss: 0.2283667\n",
      "\tspeed: 0.0291s/iter; left time: 298.2885s\n",
      "Epoch: 3 cost time: 17.15222954750061\n",
      "Epoch: 3, Steps: 603 | Train Loss: 0.1890092 Vali Loss: 0.1968274 Test Loss: 0.2309197\n",
      "Validation loss decreased (0.206889 --> 0.196827).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2140543\n",
      "\tspeed: 0.0717s/iter; left time: 728.1404s\n",
      "\titers: 200, epoch: 4 | loss: 0.2509425\n",
      "\tspeed: 0.0291s/iter; left time: 292.1267s\n",
      "\titers: 300, epoch: 4 | loss: 0.2862993\n",
      "\tspeed: 0.0297s/iter; left time: 296.0431s\n",
      "\titers: 400, epoch: 4 | loss: 0.2170977\n",
      "\tspeed: 0.0304s/iter; left time: 299.7973s\n",
      "\titers: 500, epoch: 4 | loss: 0.1051365\n",
      "\tspeed: 0.0289s/iter; left time: 281.6485s\n",
      "\titers: 600, epoch: 4 | loss: 0.1443205\n",
      "\tspeed: 0.0277s/iter; left time: 267.2765s\n",
      "Epoch: 4 cost time: 17.58349585533142\n",
      "Epoch: 4, Steps: 603 | Train Loss: 0.1747320 Vali Loss: 0.2008591 Test Loss: 0.2362287\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1417891\n",
      "\tspeed: 0.0718s/iter; left time: 685.4775s\n",
      "\titers: 200, epoch: 5 | loss: 0.1177804\n",
      "\tspeed: 0.0300s/iter; left time: 283.2224s\n",
      "\titers: 300, epoch: 5 | loss: 0.1406430\n",
      "\tspeed: 0.0275s/iter; left time: 256.9204s\n",
      "\titers: 400, epoch: 5 | loss: 0.1605591\n",
      "\tspeed: 0.0275s/iter; left time: 254.1731s\n",
      "\titers: 500, epoch: 5 | loss: 0.2000606\n",
      "\tspeed: 0.0275s/iter; left time: 251.9162s\n",
      "\titers: 600, epoch: 5 | loss: 0.1667029\n",
      "\tspeed: 0.0291s/iter; left time: 263.7538s\n",
      "Epoch: 5 cost time: 17.375403881072998\n",
      "Epoch: 5, Steps: 603 | Train Loss: 0.1656683 Vali Loss: 0.1934685 Test Loss: 0.2307065\n",
      "Validation loss decreased (0.196827 --> 0.193468).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1883641\n",
      "\tspeed: 0.0693s/iter; left time: 619.7225s\n",
      "\titers: 200, epoch: 6 | loss: 0.1077065\n",
      "\tspeed: 0.0282s/iter; left time: 249.3020s\n",
      "\titers: 300, epoch: 6 | loss: 0.1384269\n",
      "\tspeed: 0.0266s/iter; left time: 232.9666s\n",
      "\titers: 400, epoch: 6 | loss: 0.1138649\n",
      "\tspeed: 0.0270s/iter; left time: 233.4562s\n",
      "\titers: 500, epoch: 6 | loss: 0.1394195\n",
      "\tspeed: 0.0267s/iter; left time: 227.9354s\n",
      "\titers: 600, epoch: 6 | loss: 0.1601760\n",
      "\tspeed: 0.0254s/iter; left time: 214.4464s\n",
      "Epoch: 6 cost time: 16.17141890525818\n",
      "Epoch: 6, Steps: 603 | Train Loss: 0.1604214 Vali Loss: 0.1936357 Test Loss: 0.2306637\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1717049\n",
      "\tspeed: 0.0617s/iter; left time: 514.8541s\n",
      "\titers: 200, epoch: 7 | loss: 0.1601764\n",
      "\tspeed: 0.0231s/iter; left time: 190.6838s\n",
      "\titers: 300, epoch: 7 | loss: 0.1960203\n",
      "\tspeed: 0.0284s/iter; left time: 231.2928s\n",
      "\titers: 400, epoch: 7 | loss: 0.1470703\n",
      "\tspeed: 0.0284s/iter; left time: 228.8095s\n",
      "\titers: 500, epoch: 7 | loss: 0.1347188\n",
      "\tspeed: 0.0264s/iter; left time: 209.5181s\n",
      "\titers: 600, epoch: 7 | loss: 0.1797640\n",
      "\tspeed: 0.0262s/iter; left time: 205.4616s\n",
      "Epoch: 7 cost time: 15.729365348815918\n",
      "Epoch: 7, Steps: 603 | Train Loss: 0.1580748 Vali Loss: 0.1899952 Test Loss: 0.2290862\n",
      "Validation loss decreased (0.193468 --> 0.189995).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1534702\n",
      "\tspeed: 0.0669s/iter; left time: 517.7181s\n",
      "\titers: 200, epoch: 8 | loss: 0.1069576\n",
      "\tspeed: 0.0269s/iter; left time: 205.8489s\n",
      "\titers: 300, epoch: 8 | loss: 0.1383871\n",
      "\tspeed: 0.0254s/iter; left time: 191.6556s\n",
      "\titers: 400, epoch: 8 | loss: 0.1013696\n",
      "\tspeed: 0.0254s/iter; left time: 188.6163s\n",
      "\titers: 500, epoch: 8 | loss: 0.2050397\n",
      "\tspeed: 0.0256s/iter; left time: 187.9757s\n",
      "\titers: 600, epoch: 8 | loss: 0.1924064\n",
      "\tspeed: 0.0260s/iter; left time: 188.1822s\n",
      "Epoch: 8 cost time: 15.792234659194946\n",
      "Epoch: 8, Steps: 603 | Train Loss: 0.1563692 Vali Loss: 0.1906227 Test Loss: 0.2291547\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1961080\n",
      "\tspeed: 0.0660s/iter; left time: 470.7044s\n",
      "\titers: 200, epoch: 9 | loss: 0.1206641\n",
      "\tspeed: 0.0260s/iter; left time: 182.7194s\n",
      "\titers: 300, epoch: 9 | loss: 0.1593002\n",
      "\tspeed: 0.0250s/iter; left time: 173.4662s\n",
      "\titers: 400, epoch: 9 | loss: 0.1633428\n",
      "\tspeed: 0.0248s/iter; left time: 169.5931s\n",
      "\titers: 500, epoch: 9 | loss: 0.1828605\n",
      "\tspeed: 0.0276s/iter; left time: 185.9589s\n",
      "\titers: 600, epoch: 9 | loss: 0.1299528\n",
      "\tspeed: 0.0270s/iter; left time: 178.8751s\n",
      "Epoch: 9 cost time: 15.703485250473022\n",
      "Epoch: 9, Steps: 603 | Train Loss: 0.1549088 Vali Loss: 0.1912880 Test Loss: 0.2307224\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.1283370\n",
      "\tspeed: 0.0677s/iter; left time: 442.2020s\n",
      "\titers: 200, epoch: 10 | loss: 0.1352492\n",
      "\tspeed: 0.0266s/iter; left time: 171.3048s\n",
      "\titers: 300, epoch: 10 | loss: 0.1449026\n",
      "\tspeed: 0.0296s/iter; left time: 187.1810s\n",
      "\titers: 400, epoch: 10 | loss: 0.0901620\n",
      "\tspeed: 0.0261s/iter; left time: 162.6180s\n",
      "\titers: 500, epoch: 10 | loss: 0.1871071\n",
      "\tspeed: 0.0273s/iter; left time: 167.2532s\n",
      "\titers: 600, epoch: 10 | loss: 0.2226712\n",
      "\tspeed: 0.0274s/iter; left time: 165.1746s\n",
      "Epoch: 10 cost time: 16.66123056411743\n",
      "Epoch: 10, Steps: 603 | Train Loss: 0.1551235 Vali Loss: 0.1909411 Test Loss: 0.2295979\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl48_ll16_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "Test cost time: 1.9597s\n",
      "test shape: (192, 32, 6, 1) (192, 32, 6, 1)\n",
      "test shape: (6144, 6, 1) (6144, 6, 1)\n",
      "mse:0.2297414094209671, mae:0.3202931582927704\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl48_ll16_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1665.5052490234375\n",
      "MAE:  27.270999908447266\n",
      "RMSE: 40.81060028076172\n",
      "MAPE: 0.34572893381118774\n",
      "MSPE: 0.5306603908538818\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl48_ll16_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20985\n",
      "[DEBUG] Original dataset length: 20985\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19316\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6772\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "\titers: 100, epoch: 1 | loss: 0.3284682\n",
      "\tspeed: 0.0261s/iter; left time: 312.4873s\n",
      "\titers: 200, epoch: 1 | loss: 0.1587449\n",
      "\tspeed: 0.0264s/iter; left time: 313.0933s\n",
      "\titers: 300, epoch: 1 | loss: 0.2814291\n",
      "\tspeed: 0.0262s/iter; left time: 308.0163s\n",
      "\titers: 400, epoch: 1 | loss: 0.4255538\n",
      "\tspeed: 0.0258s/iter; left time: 301.1478s\n",
      "\titers: 500, epoch: 1 | loss: 0.2166971\n",
      "\tspeed: 0.0283s/iter; left time: 327.2550s\n",
      "\titers: 600, epoch: 1 | loss: 0.2090960\n",
      "\tspeed: 0.0298s/iter; left time: 341.7862s\n",
      "Epoch: 1 cost time: 16.37019634246826\n",
      "Epoch: 1, Steps: 603 | Train Loss: 0.2810413 Vali Loss: 0.2087021 Test Loss: 0.2423265\n",
      "Validation loss decreased (inf --> 0.208702).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2268844\n",
      "\tspeed: 0.0699s/iter; left time: 793.7234s\n",
      "\titers: 200, epoch: 2 | loss: 0.3811665\n",
      "\tspeed: 0.0283s/iter; left time: 318.2038s\n",
      "\titers: 300, epoch: 2 | loss: 0.1737124\n",
      "\tspeed: 0.0287s/iter; left time: 320.2434s\n",
      "\titers: 400, epoch: 2 | loss: 0.1548484\n",
      "\tspeed: 0.0289s/iter; left time: 319.1304s\n",
      "\titers: 500, epoch: 2 | loss: 0.1856310\n",
      "\tspeed: 0.0287s/iter; left time: 314.4581s\n",
      "\titers: 600, epoch: 2 | loss: 0.2193203\n",
      "\tspeed: 0.0272s/iter; left time: 295.3300s\n",
      "Epoch: 2 cost time: 17.109589099884033\n",
      "Epoch: 2, Steps: 603 | Train Loss: 0.2153537 Vali Loss: 0.2027488 Test Loss: 0.2393497\n",
      "Validation loss decreased (0.208702 --> 0.202749).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1865275\n",
      "\tspeed: 0.0726s/iter; left time: 780.8148s\n",
      "\titers: 200, epoch: 3 | loss: 0.2543087\n",
      "\tspeed: 0.0290s/iter; left time: 309.1991s\n",
      "\titers: 300, epoch: 3 | loss: 0.1470141\n",
      "\tspeed: 0.0284s/iter; left time: 299.7799s\n",
      "\titers: 400, epoch: 3 | loss: 0.1679255\n",
      "\tspeed: 0.0275s/iter; left time: 287.4722s\n",
      "\titers: 500, epoch: 3 | loss: 0.1794147\n",
      "\tspeed: 0.0272s/iter; left time: 281.9072s\n",
      "\titers: 600, epoch: 3 | loss: 0.1212317\n",
      "\tspeed: 0.0290s/iter; left time: 297.6391s\n",
      "Epoch: 3 cost time: 17.140432834625244\n",
      "Epoch: 3, Steps: 603 | Train Loss: 0.1900780 Vali Loss: 0.2041954 Test Loss: 0.2388286\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1459882\n",
      "\tspeed: 0.0692s/iter; left time: 702.9539s\n",
      "\titers: 200, epoch: 4 | loss: 0.1747943\n",
      "\tspeed: 0.0280s/iter; left time: 281.7369s\n",
      "\titers: 300, epoch: 4 | loss: 0.1438586\n",
      "\tspeed: 0.0274s/iter; left time: 272.6486s\n",
      "\titers: 400, epoch: 4 | loss: 0.1361618\n",
      "\tspeed: 0.0284s/iter; left time: 279.8559s\n",
      "\titers: 500, epoch: 4 | loss: 0.1381204\n",
      "\tspeed: 0.0285s/iter; left time: 277.9822s\n",
      "\titers: 600, epoch: 4 | loss: 0.2341520\n",
      "\tspeed: 0.0273s/iter; left time: 263.5229s\n",
      "Epoch: 4 cost time: 16.801605463027954\n",
      "Epoch: 4, Steps: 603 | Train Loss: 0.1747632 Vali Loss: 0.1972208 Test Loss: 0.2241790\n",
      "Validation loss decreased (0.202749 --> 0.197221).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1329876\n",
      "\tspeed: 0.0702s/iter; left time: 670.7199s\n",
      "\titers: 200, epoch: 5 | loss: 0.1713040\n",
      "\tspeed: 0.0289s/iter; left time: 273.3886s\n",
      "\titers: 300, epoch: 5 | loss: 0.1124405\n",
      "\tspeed: 0.0285s/iter; left time: 266.8980s\n",
      "\titers: 400, epoch: 5 | loss: 0.1146251\n",
      "\tspeed: 0.0291s/iter; left time: 269.2364s\n",
      "\titers: 500, epoch: 5 | loss: 0.0990667\n",
      "\tspeed: 0.0284s/iter; left time: 259.3820s\n",
      "\titers: 600, epoch: 5 | loss: 0.2924059\n",
      "\tspeed: 0.0299s/iter; left time: 270.6018s\n",
      "Epoch: 5 cost time: 17.33142066001892\n",
      "Epoch: 5, Steps: 603 | Train Loss: 0.1661678 Vali Loss: 0.2030730 Test Loss: 0.2347238\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1486400\n",
      "\tspeed: 0.0710s/iter; left time: 634.8934s\n",
      "\titers: 200, epoch: 6 | loss: 0.1438644\n",
      "\tspeed: 0.0283s/iter; left time: 249.9134s\n",
      "\titers: 300, epoch: 6 | loss: 0.1276267\n",
      "\tspeed: 0.0278s/iter; left time: 242.7440s\n",
      "\titers: 400, epoch: 6 | loss: 0.1416415\n",
      "\tspeed: 0.0275s/iter; left time: 237.8289s\n",
      "\titers: 500, epoch: 6 | loss: 0.1963636\n",
      "\tspeed: 0.0293s/iter; left time: 250.7283s\n",
      "\titers: 600, epoch: 6 | loss: 0.1238239\n",
      "\tspeed: 0.0304s/iter; left time: 256.4607s\n",
      "Epoch: 6 cost time: 17.29739737510681\n",
      "Epoch: 6, Steps: 603 | Train Loss: 0.1607919 Vali Loss: 0.1961605 Test Loss: 0.2295641\n",
      "Validation loss decreased (0.197221 --> 0.196160).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1829551\n",
      "\tspeed: 0.0705s/iter; left time: 588.3932s\n",
      "\titers: 200, epoch: 7 | loss: 0.1894157\n",
      "\tspeed: 0.0294s/iter; left time: 242.0938s\n",
      "\titers: 300, epoch: 7 | loss: 0.1894092\n",
      "\tspeed: 0.0310s/iter; left time: 252.4560s\n",
      "\titers: 400, epoch: 7 | loss: 0.1526929\n",
      "\tspeed: 0.0297s/iter; left time: 239.2107s\n",
      "\titers: 500, epoch: 7 | loss: 0.1733302\n",
      "\tspeed: 0.0290s/iter; left time: 230.6792s\n",
      "\titers: 600, epoch: 7 | loss: 0.1184067\n",
      "\tspeed: 0.0287s/iter; left time: 225.0661s\n",
      "Epoch: 7 cost time: 17.78393054008484\n",
      "Epoch: 7, Steps: 603 | Train Loss: 0.1573540 Vali Loss: 0.1956400 Test Loss: 0.2283065\n",
      "Validation loss decreased (0.196160 --> 0.195640).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2771971\n",
      "\tspeed: 0.0732s/iter; left time: 566.8475s\n",
      "\titers: 200, epoch: 8 | loss: 0.0856693\n",
      "\tspeed: 0.0296s/iter; left time: 226.2249s\n",
      "\titers: 300, epoch: 8 | loss: 0.2344263\n",
      "\tspeed: 0.0300s/iter; left time: 226.3840s\n",
      "\titers: 400, epoch: 8 | loss: 0.1823473\n",
      "\tspeed: 0.0303s/iter; left time: 225.0980s\n",
      "\titers: 500, epoch: 8 | loss: 0.1333303\n",
      "\tspeed: 0.0287s/iter; left time: 210.3906s\n",
      "\titers: 600, epoch: 8 | loss: 0.1334911\n",
      "\tspeed: 0.0313s/iter; left time: 226.4167s\n",
      "Epoch: 8 cost time: 18.18904995918274\n",
      "Epoch: 8, Steps: 603 | Train Loss: 0.1561351 Vali Loss: 0.1958021 Test Loss: 0.2303249\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1208598\n",
      "\tspeed: 0.0682s/iter; left time: 486.5894s\n",
      "\titers: 200, epoch: 9 | loss: 0.1467291\n",
      "\tspeed: 0.0278s/iter; left time: 195.8350s\n",
      "\titers: 300, epoch: 9 | loss: 0.1681219\n",
      "\tspeed: 0.0287s/iter; left time: 198.8655s\n",
      "\titers: 400, epoch: 9 | loss: 0.1576761\n",
      "\tspeed: 0.0293s/iter; left time: 200.5841s\n",
      "\titers: 500, epoch: 9 | loss: 0.0957210\n",
      "\tspeed: 0.0299s/iter; left time: 201.1001s\n",
      "\titers: 600, epoch: 9 | loss: 0.1336578\n",
      "\tspeed: 0.0286s/iter; left time: 190.1381s\n",
      "Epoch: 9 cost time: 17.29888081550598\n",
      "Epoch: 9, Steps: 603 | Train Loss: 0.1547285 Vali Loss: 0.1950292 Test Loss: 0.2293489\n",
      "Validation loss decreased (0.195640 --> 0.195029).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.1459129\n",
      "\tspeed: 0.0727s/iter; left time: 475.2664s\n",
      "\titers: 200, epoch: 10 | loss: 0.1755684\n",
      "\tspeed: 0.0288s/iter; left time: 185.1635s\n",
      "\titers: 300, epoch: 10 | loss: 0.1385242\n",
      "\tspeed: 0.0280s/iter; left time: 177.3808s\n",
      "\titers: 400, epoch: 10 | loss: 0.2397767\n",
      "\tspeed: 0.0281s/iter; left time: 175.4171s\n",
      "\titers: 500, epoch: 10 | loss: 0.1824671\n",
      "\tspeed: 0.0286s/iter; left time: 175.6093s\n",
      "\titers: 600, epoch: 10 | loss: 0.1809605\n",
      "\tspeed: 0.0294s/iter; left time: 177.5496s\n",
      "Epoch: 10 cost time: 17.434345483779907\n",
      "Epoch: 10, Steps: 603 | Train Loss: 0.1539010 Vali Loss: 0.1964343 Test Loss: 0.2286001\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.1535030\n",
      "\tspeed: 0.0755s/iter; left time: 447.7095s\n",
      "\titers: 200, epoch: 11 | loss: 0.2370549\n",
      "\tspeed: 0.0280s/iter; left time: 163.0670s\n",
      "\titers: 300, epoch: 11 | loss: 0.1737270\n",
      "\tspeed: 0.0288s/iter; left time: 165.2720s\n",
      "\titers: 400, epoch: 11 | loss: 0.1521853\n",
      "\tspeed: 0.0296s/iter; left time: 166.7364s\n",
      "\titers: 500, epoch: 11 | loss: 0.1873342\n",
      "\tspeed: 0.0292s/iter; left time: 161.5418s\n",
      "\titers: 600, epoch: 11 | loss: 0.1121378\n",
      "\tspeed: 0.0297s/iter; left time: 161.5322s\n",
      "Epoch: 11 cost time: 17.539337396621704\n",
      "Epoch: 11, Steps: 603 | Train Loss: 0.1542074 Vali Loss: 0.1959451 Test Loss: 0.2289633\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.1369844\n",
      "\tspeed: 0.0699s/iter; left time: 372.4828s\n",
      "\titers: 200, epoch: 12 | loss: 0.1258122\n",
      "\tspeed: 0.0279s/iter; left time: 146.1056s\n",
      "\titers: 300, epoch: 12 | loss: 0.1367327\n",
      "\tspeed: 0.0282s/iter; left time: 144.5735s\n",
      "\titers: 400, epoch: 12 | loss: 0.1249043\n",
      "\tspeed: 0.0280s/iter; left time: 140.9630s\n",
      "\titers: 500, epoch: 12 | loss: 0.1937708\n",
      "\tspeed: 0.0265s/iter; left time: 130.5226s\n",
      "\titers: 600, epoch: 12 | loss: 0.1333495\n",
      "\tspeed: 0.0272s/iter; left time: 131.2175s\n",
      "Epoch: 12 cost time: 16.637348651885986\n",
      "Epoch: 12, Steps: 603 | Train Loss: 0.1537876 Vali Loss: 0.1969465 Test Loss: 0.2302064\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl48_ll16_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "Test cost time: 1.8978s\n",
      "test shape: (192, 32, 6, 1) (192, 32, 6, 1)\n",
      "test shape: (6144, 6, 1) (6144, 6, 1)\n",
      "mse:0.2294674962759018, mae:0.317621648311615\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl48_ll16_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1663.5196533203125\n",
      "MAE:  27.043535232543945\n",
      "RMSE: 40.7862663269043\n",
      "MAPE: 0.3391295075416565\n",
      "MSPE: 0.5263391137123108\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl48_ll16_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20985\n",
      "[DEBUG] Original dataset length: 20985\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19316\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6772\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "\titers: 100, epoch: 1 | loss: 0.2328127\n",
      "\tspeed: 0.0276s/iter; left time: 330.2607s\n",
      "\titers: 200, epoch: 1 | loss: 0.2132125\n",
      "\tspeed: 0.0279s/iter; left time: 330.5561s\n",
      "\titers: 300, epoch: 1 | loss: 0.3829045\n",
      "\tspeed: 0.0268s/iter; left time: 314.8705s\n",
      "\titers: 400, epoch: 1 | loss: 0.3302230\n",
      "\tspeed: 0.0261s/iter; left time: 303.9830s\n",
      "\titers: 500, epoch: 1 | loss: 0.1413291\n",
      "\tspeed: 0.0276s/iter; left time: 319.5263s\n",
      "\titers: 600, epoch: 1 | loss: 0.1900223\n",
      "\tspeed: 0.0266s/iter; left time: 304.4665s\n",
      "Epoch: 1 cost time: 16.34771990776062\n",
      "Epoch: 1, Steps: 603 | Train Loss: 0.2817148 Vali Loss: 0.2100675 Test Loss: 0.2403002\n",
      "Validation loss decreased (inf --> 0.210068).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2069723\n",
      "\tspeed: 0.0650s/iter; left time: 738.2842s\n",
      "\titers: 200, epoch: 2 | loss: 0.1995990\n",
      "\tspeed: 0.0254s/iter; left time: 286.0384s\n",
      "\titers: 300, epoch: 2 | loss: 0.2147574\n",
      "\tspeed: 0.0283s/iter; left time: 315.8941s\n",
      "\titers: 400, epoch: 2 | loss: 0.3436388\n",
      "\tspeed: 0.0257s/iter; left time: 284.1186s\n",
      "\titers: 500, epoch: 2 | loss: 0.2187081\n",
      "\tspeed: 0.0255s/iter; left time: 279.1060s\n",
      "\titers: 600, epoch: 2 | loss: 0.2429657\n",
      "\tspeed: 0.0262s/iter; left time: 284.5603s\n",
      "Epoch: 2 cost time: 15.808141708374023\n",
      "Epoch: 2, Steps: 603 | Train Loss: 0.2164585 Vali Loss: 0.2237342 Test Loss: 0.2465826\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3020029\n",
      "\tspeed: 0.0682s/iter; left time: 733.6939s\n",
      "\titers: 200, epoch: 3 | loss: 0.2113567\n",
      "\tspeed: 0.0250s/iter; left time: 265.8809s\n",
      "\titers: 300, epoch: 3 | loss: 0.2031043\n",
      "\tspeed: 0.0265s/iter; left time: 279.8326s\n",
      "\titers: 400, epoch: 3 | loss: 0.2245695\n",
      "\tspeed: 0.0256s/iter; left time: 267.1323s\n",
      "\titers: 500, epoch: 3 | loss: 0.2549727\n",
      "\tspeed: 0.0261s/iter; left time: 270.5169s\n",
      "\titers: 600, epoch: 3 | loss: 0.1505793\n",
      "\tspeed: 0.0265s/iter; left time: 271.8366s\n",
      "Epoch: 3 cost time: 16.05950903892517\n",
      "Epoch: 3, Steps: 603 | Train Loss: 0.1918333 Vali Loss: 0.1989371 Test Loss: 0.2298753\n",
      "Validation loss decreased (0.210068 --> 0.198937).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1830190\n",
      "\tspeed: 0.0637s/iter; left time: 646.9782s\n",
      "\titers: 200, epoch: 4 | loss: 0.2851745\n",
      "\tspeed: 0.0246s/iter; left time: 247.5366s\n",
      "\titers: 300, epoch: 4 | loss: 0.1910095\n",
      "\tspeed: 0.0255s/iter; left time: 253.6570s\n",
      "\titers: 400, epoch: 4 | loss: 0.1890481\n",
      "\tspeed: 0.0254s/iter; left time: 250.3332s\n",
      "\titers: 500, epoch: 4 | loss: 0.1134734\n",
      "\tspeed: 0.0285s/iter; left time: 278.0609s\n",
      "\titers: 600, epoch: 4 | loss: 0.2059347\n",
      "\tspeed: 0.0264s/iter; left time: 255.2093s\n",
      "Epoch: 4 cost time: 15.66923451423645\n",
      "Epoch: 4, Steps: 603 | Train Loss: 0.1775710 Vali Loss: 0.1980352 Test Loss: 0.2288245\n",
      "Validation loss decreased (0.198937 --> 0.198035).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1370901\n",
      "\tspeed: 0.0684s/iter; left time: 653.0960s\n",
      "\titers: 200, epoch: 5 | loss: 0.1648696\n",
      "\tspeed: 0.0265s/iter; left time: 250.0393s\n",
      "\titers: 300, epoch: 5 | loss: 0.1845655\n",
      "\tspeed: 0.0285s/iter; left time: 266.3346s\n",
      "\titers: 400, epoch: 5 | loss: 0.1233573\n",
      "\tspeed: 0.0256s/iter; left time: 236.3653s\n",
      "\titers: 500, epoch: 5 | loss: 0.1293817\n",
      "\tspeed: 0.0257s/iter; left time: 235.2134s\n",
      "\titers: 600, epoch: 5 | loss: 0.1419533\n",
      "\tspeed: 0.0261s/iter; left time: 235.9357s\n",
      "Epoch: 5 cost time: 16.19530940055847\n",
      "Epoch: 5, Steps: 603 | Train Loss: 0.1677418 Vali Loss: 0.1954691 Test Loss: 0.2264681\n",
      "Validation loss decreased (0.198035 --> 0.195469).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1854260\n",
      "\tspeed: 0.0678s/iter; left time: 606.7257s\n",
      "\titers: 200, epoch: 6 | loss: 0.1088598\n",
      "\tspeed: 0.0270s/iter; left time: 238.4807s\n",
      "\titers: 300, epoch: 6 | loss: 0.1427426\n",
      "\tspeed: 0.0247s/iter; left time: 216.3684s\n",
      "\titers: 400, epoch: 6 | loss: 0.1784106\n",
      "\tspeed: 0.0245s/iter; left time: 211.6973s\n",
      "\titers: 500, epoch: 6 | loss: 0.1024697\n",
      "\tspeed: 0.0263s/iter; left time: 224.5276s\n",
      "\titers: 600, epoch: 6 | loss: 0.1615958\n",
      "\tspeed: 0.0251s/iter; left time: 211.8060s\n",
      "Epoch: 6 cost time: 15.606940031051636\n",
      "Epoch: 6, Steps: 603 | Train Loss: 0.1627741 Vali Loss: 0.2001084 Test Loss: 0.2298319\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2149781\n",
      "\tspeed: 0.0656s/iter; left time: 547.0250s\n",
      "\titers: 200, epoch: 7 | loss: 0.1371180\n",
      "\tspeed: 0.0249s/iter; left time: 205.5835s\n",
      "\titers: 300, epoch: 7 | loss: 0.1134347\n",
      "\tspeed: 0.0249s/iter; left time: 203.1452s\n",
      "\titers: 400, epoch: 7 | loss: 0.1561986\n",
      "\tspeed: 0.0251s/iter; left time: 201.9688s\n",
      "\titers: 500, epoch: 7 | loss: 0.2037579\n",
      "\tspeed: 0.0281s/iter; left time: 222.8870s\n",
      "\titers: 600, epoch: 7 | loss: 0.1864639\n",
      "\tspeed: 0.0266s/iter; left time: 208.3569s\n",
      "Epoch: 7 cost time: 15.67402696609497\n",
      "Epoch: 7, Steps: 603 | Train Loss: 0.1597768 Vali Loss: 0.1970958 Test Loss: 0.2282212\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1274405\n",
      "\tspeed: 0.0639s/iter; left time: 494.9486s\n",
      "\titers: 200, epoch: 8 | loss: 0.1507405\n",
      "\tspeed: 0.0261s/iter; left time: 199.3086s\n",
      "\titers: 300, epoch: 8 | loss: 0.1618673\n",
      "\tspeed: 0.0264s/iter; left time: 198.8835s\n",
      "\titers: 400, epoch: 8 | loss: 0.1309366\n",
      "\tspeed: 0.0279s/iter; left time: 207.3117s\n",
      "\titers: 500, epoch: 8 | loss: 0.1741031\n",
      "\tspeed: 0.0255s/iter; left time: 187.3222s\n",
      "\titers: 600, epoch: 8 | loss: 0.1770350\n",
      "\tspeed: 0.0267s/iter; left time: 193.0684s\n",
      "Epoch: 8 cost time: 15.96835732460022\n",
      "Epoch: 8, Steps: 603 | Train Loss: 0.1582625 Vali Loss: 0.1964933 Test Loss: 0.2278654\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl48_ll16_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "Test cost time: 1.6870s\n",
      "test shape: (192, 32, 6, 1) (192, 32, 6, 1)\n",
      "test shape: (6144, 6, 1) (6144, 6, 1)\n",
      "mse:0.22683031857013702, mae:0.31467506289482117\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl48_ll16_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1644.4013671875\n",
      "MAE:  26.792654037475586\n",
      "RMSE: 40.55121994018555\n",
      "MAPE: 0.3180069923400879\n",
      "MSPE: 0.46029260754585266\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl48_ll16_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20985\n",
      "[DEBUG] Original dataset length: 20985\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19316\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6772\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "\titers: 100, epoch: 1 | loss: 0.5437943\n",
      "\tspeed: 0.0327s/iter; left time: 391.0159s\n",
      "\titers: 200, epoch: 1 | loss: 0.2931207\n",
      "\tspeed: 0.0252s/iter; left time: 298.8711s\n",
      "\titers: 300, epoch: 1 | loss: 0.2376736\n",
      "\tspeed: 0.0273s/iter; left time: 321.0533s\n",
      "\titers: 400, epoch: 1 | loss: 0.1605839\n",
      "\tspeed: 0.0275s/iter; left time: 321.1162s\n",
      "\titers: 500, epoch: 1 | loss: 0.2828795\n",
      "\tspeed: 0.0273s/iter; left time: 316.1116s\n",
      "\titers: 600, epoch: 1 | loss: 0.3506489\n",
      "\tspeed: 0.0275s/iter; left time: 315.0215s\n",
      "Epoch: 1 cost time: 16.853429794311523\n",
      "Epoch: 1, Steps: 603 | Train Loss: 0.2816515 Vali Loss: 0.2147288 Test Loss: 0.2497032\n",
      "Validation loss decreased (inf --> 0.214729).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2461274\n",
      "\tspeed: 0.0662s/iter; left time: 752.3701s\n",
      "\titers: 200, epoch: 2 | loss: 0.2117147\n",
      "\tspeed: 0.0264s/iter; left time: 297.3502s\n",
      "\titers: 300, epoch: 2 | loss: 0.2079313\n",
      "\tspeed: 0.0260s/iter; left time: 290.4665s\n",
      "\titers: 400, epoch: 2 | loss: 0.2761552\n",
      "\tspeed: 0.0272s/iter; left time: 300.4193s\n",
      "\titers: 500, epoch: 2 | loss: 0.1959343\n",
      "\tspeed: 0.0300s/iter; left time: 329.1962s\n",
      "\titers: 600, epoch: 2 | loss: 0.2643722\n",
      "\tspeed: 0.0271s/iter; left time: 294.0282s\n",
      "Epoch: 2 cost time: 16.255025148391724\n",
      "Epoch: 2, Steps: 603 | Train Loss: 0.2160084 Vali Loss: 0.2080375 Test Loss: 0.2486805\n",
      "Validation loss decreased (0.214729 --> 0.208037).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2564807\n",
      "\tspeed: 0.0705s/iter; left time: 758.5944s\n",
      "\titers: 200, epoch: 3 | loss: 0.1578646\n",
      "\tspeed: 0.0287s/iter; left time: 305.2866s\n",
      "\titers: 300, epoch: 3 | loss: 0.1633332\n",
      "\tspeed: 0.0296s/iter; left time: 312.1393s\n",
      "\titers: 400, epoch: 3 | loss: 0.1621849\n",
      "\tspeed: 0.0272s/iter; left time: 284.8201s\n",
      "\titers: 500, epoch: 3 | loss: 0.2074834\n",
      "\tspeed: 0.0267s/iter; left time: 276.1130s\n",
      "\titers: 600, epoch: 3 | loss: 0.2341425\n",
      "\tspeed: 0.0273s/iter; left time: 279.4610s\n",
      "Epoch: 3 cost time: 16.89093804359436\n",
      "Epoch: 3, Steps: 603 | Train Loss: 0.1898006 Vali Loss: 0.1950240 Test Loss: 0.2290050\n",
      "Validation loss decreased (0.208037 --> 0.195024).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2104886\n",
      "\tspeed: 0.0689s/iter; left time: 699.5143s\n",
      "\titers: 200, epoch: 4 | loss: 0.1340146\n",
      "\tspeed: 0.0269s/iter; left time: 270.4741s\n",
      "\titers: 300, epoch: 4 | loss: 0.1859878\n",
      "\tspeed: 0.0264s/iter; left time: 262.4104s\n",
      "\titers: 400, epoch: 4 | loss: 0.1920657\n",
      "\tspeed: 0.0268s/iter; left time: 264.1933s\n",
      "\titers: 500, epoch: 4 | loss: 0.0953512\n",
      "\tspeed: 0.0264s/iter; left time: 257.9240s\n",
      "\titers: 600, epoch: 4 | loss: 0.1240716\n",
      "\tspeed: 0.0283s/iter; left time: 273.5224s\n",
      "Epoch: 4 cost time: 16.34471821784973\n",
      "Epoch: 4, Steps: 603 | Train Loss: 0.1742255 Vali Loss: 0.1950662 Test Loss: 0.2320490\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2344697\n",
      "\tspeed: 0.0638s/iter; left time: 609.3539s\n",
      "\titers: 200, epoch: 5 | loss: 0.2272163\n",
      "\tspeed: 0.0274s/iter; left time: 259.3155s\n",
      "\titers: 300, epoch: 5 | loss: 0.2863755\n",
      "\tspeed: 0.0249s/iter; left time: 232.5163s\n",
      "\titers: 400, epoch: 5 | loss: 0.2134490\n",
      "\tspeed: 0.0268s/iter; left time: 247.7929s\n",
      "\titers: 500, epoch: 5 | loss: 0.2882470\n",
      "\tspeed: 0.0258s/iter; left time: 236.4030s\n",
      "\titers: 600, epoch: 5 | loss: 0.1307122\n",
      "\tspeed: 0.0251s/iter; left time: 227.0333s\n",
      "Epoch: 5 cost time: 15.75391411781311\n",
      "Epoch: 5, Steps: 603 | Train Loss: 0.1643912 Vali Loss: 0.1973805 Test Loss: 0.2373659\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1392055\n",
      "\tspeed: 0.0609s/iter; left time: 545.2530s\n",
      "\titers: 200, epoch: 6 | loss: 0.1453845\n",
      "\tspeed: 0.0252s/iter; left time: 222.5369s\n",
      "\titers: 300, epoch: 6 | loss: 0.1295573\n",
      "\tspeed: 0.0294s/iter; left time: 257.3147s\n",
      "\titers: 400, epoch: 6 | loss: 0.1190876\n",
      "\tspeed: 0.0246s/iter; left time: 212.3973s\n",
      "\titers: 500, epoch: 6 | loss: 0.1501007\n",
      "\tspeed: 0.0248s/iter; left time: 212.1527s\n",
      "\titers: 600, epoch: 6 | loss: 0.2361408\n",
      "\tspeed: 0.0242s/iter; left time: 204.0666s\n",
      "Epoch: 6 cost time: 15.371629476547241\n",
      "Epoch: 6, Steps: 603 | Train Loss: 0.1600053 Vali Loss: 0.1937297 Test Loss: 0.2312424\n",
      "Validation loss decreased (0.195024 --> 0.193730).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1152714\n",
      "\tspeed: 0.0662s/iter; left time: 552.6480s\n",
      "\titers: 200, epoch: 7 | loss: 0.1424432\n",
      "\tspeed: 0.0255s/iter; left time: 209.9003s\n",
      "\titers: 300, epoch: 7 | loss: 0.1447405\n",
      "\tspeed: 0.0254s/iter; left time: 206.8103s\n",
      "\titers: 400, epoch: 7 | loss: 0.1543993\n",
      "\tspeed: 0.0249s/iter; left time: 200.5070s\n",
      "\titers: 500, epoch: 7 | loss: 0.1882724\n",
      "\tspeed: 0.0248s/iter; left time: 196.9095s\n",
      "\titers: 600, epoch: 7 | loss: 0.1612893\n",
      "\tspeed: 0.0249s/iter; left time: 195.5045s\n",
      "Epoch: 7 cost time: 15.329096555709839\n",
      "Epoch: 7, Steps: 603 | Train Loss: 0.1573001 Vali Loss: 0.1946975 Test Loss: 0.2345696\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1926030\n",
      "\tspeed: 0.0643s/iter; left time: 497.6695s\n",
      "\titers: 200, epoch: 8 | loss: 0.1554707\n",
      "\tspeed: 0.0246s/iter; left time: 188.0950s\n",
      "\titers: 300, epoch: 8 | loss: 0.1338316\n",
      "\tspeed: 0.0248s/iter; left time: 187.3070s\n",
      "\titers: 400, epoch: 8 | loss: 0.0769871\n",
      "\tspeed: 0.0253s/iter; left time: 188.3888s\n",
      "\titers: 500, epoch: 8 | loss: 0.2159229\n",
      "\tspeed: 0.0265s/iter; left time: 194.8626s\n",
      "\titers: 600, epoch: 8 | loss: 0.1625081\n",
      "\tspeed: 0.0278s/iter; left time: 201.0912s\n",
      "Epoch: 8 cost time: 15.411743402481079\n",
      "Epoch: 8, Steps: 603 | Train Loss: 0.1559087 Vali Loss: 0.1943606 Test Loss: 0.2336714\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1393456\n",
      "\tspeed: 0.0645s/iter; left time: 460.0398s\n",
      "\titers: 200, epoch: 9 | loss: 0.1961429\n",
      "\tspeed: 0.0251s/iter; left time: 176.8908s\n",
      "\titers: 300, epoch: 9 | loss: 0.1214041\n",
      "\tspeed: 0.0261s/iter; left time: 181.3247s\n",
      "\titers: 400, epoch: 9 | loss: 0.1403783\n",
      "\tspeed: 0.0284s/iter; left time: 194.4547s\n",
      "\titers: 500, epoch: 9 | loss: 0.1168329\n",
      "\tspeed: 0.0265s/iter; left time: 178.8065s\n",
      "\titers: 600, epoch: 9 | loss: 0.1965187\n",
      "\tspeed: 0.0258s/iter; left time: 171.0743s\n",
      "Epoch: 9 cost time: 15.904801607131958\n",
      "Epoch: 9, Steps: 603 | Train Loss: 0.1543604 Vali Loss: 0.1952109 Test Loss: 0.2339852\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl48_ll16_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "Test cost time: 1.8084s\n",
      "test shape: (192, 32, 6, 1) (192, 32, 6, 1)\n",
      "test shape: (6144, 6, 1) (6144, 6, 1)\n",
      "mse:0.23150038719177246, mae:0.3192559480667114\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl48_ll16_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1678.2569580078125\n",
      "MAE:  27.18268585205078\n",
      "RMSE: 40.96653366088867\n",
      "MAPE: 0.34252917766571045\n",
      "MSPE: 0.5950589776039124\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl48_ll16_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20985\n",
      "[DEBUG] Original dataset length: 20985\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19316\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6772\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "\titers: 100, epoch: 1 | loss: 0.3488126\n",
      "\tspeed: 0.0293s/iter; left time: 350.4372s\n",
      "\titers: 200, epoch: 1 | loss: 0.4905419\n",
      "\tspeed: 0.0256s/iter; left time: 303.2227s\n",
      "\titers: 300, epoch: 1 | loss: 0.3232560\n",
      "\tspeed: 0.0263s/iter; left time: 309.2728s\n",
      "\titers: 400, epoch: 1 | loss: 0.2390879\n",
      "\tspeed: 0.0264s/iter; left time: 308.2976s\n",
      "\titers: 500, epoch: 1 | loss: 0.2248673\n",
      "\tspeed: 0.0269s/iter; left time: 311.2711s\n",
      "\titers: 600, epoch: 1 | loss: 0.2804433\n",
      "\tspeed: 0.0262s/iter; left time: 299.9202s\n",
      "Epoch: 1 cost time: 16.168545484542847\n",
      "Epoch: 1, Steps: 603 | Train Loss: 0.2856056 Vali Loss: 0.2615054 Test Loss: 0.2778745\n",
      "Validation loss decreased (inf --> 0.261505).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0965987\n",
      "\tspeed: 0.0674s/iter; left time: 765.2143s\n",
      "\titers: 200, epoch: 2 | loss: 0.1538710\n",
      "\tspeed: 0.0246s/iter; left time: 277.2971s\n",
      "\titers: 300, epoch: 2 | loss: 0.1248166\n",
      "\tspeed: 0.0267s/iter; left time: 297.8581s\n",
      "\titers: 400, epoch: 2 | loss: 0.2364887\n",
      "\tspeed: 0.0268s/iter; left time: 296.6900s\n",
      "\titers: 500, epoch: 2 | loss: 0.1385300\n",
      "\tspeed: 0.0288s/iter; left time: 315.4373s\n",
      "\titers: 600, epoch: 2 | loss: 0.2511569\n",
      "\tspeed: 0.0260s/iter; left time: 282.7681s\n",
      "Epoch: 2 cost time: 15.959932088851929\n",
      "Epoch: 2, Steps: 603 | Train Loss: 0.2182769 Vali Loss: 0.2532084 Test Loss: 0.2852076\n",
      "Validation loss decreased (0.261505 --> 0.253208).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1459969\n",
      "\tspeed: 0.0650s/iter; left time: 699.0627s\n",
      "\titers: 200, epoch: 3 | loss: 0.2374634\n",
      "\tspeed: 0.0253s/iter; left time: 269.7982s\n",
      "\titers: 300, epoch: 3 | loss: 0.1277271\n",
      "\tspeed: 0.0272s/iter; left time: 287.6035s\n",
      "\titers: 400, epoch: 3 | loss: 0.3550530\n",
      "\tspeed: 0.0265s/iter; left time: 276.6690s\n",
      "\titers: 500, epoch: 3 | loss: 0.1617770\n",
      "\tspeed: 0.0259s/iter; left time: 268.0634s\n",
      "\titers: 600, epoch: 3 | loss: 0.2066145\n",
      "\tspeed: 0.0263s/iter; left time: 269.2397s\n",
      "Epoch: 3 cost time: 15.825621604919434\n",
      "Epoch: 3, Steps: 603 | Train Loss: 0.1887051 Vali Loss: 0.1903149 Test Loss: 0.2258799\n",
      "Validation loss decreased (0.253208 --> 0.190315).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1523912\n",
      "\tspeed: 0.0664s/iter; left time: 673.8672s\n",
      "\titers: 200, epoch: 4 | loss: 0.1067122\n",
      "\tspeed: 0.0270s/iter; left time: 271.3093s\n",
      "\titers: 300, epoch: 4 | loss: 0.1914317\n",
      "\tspeed: 0.0261s/iter; left time: 259.2629s\n",
      "\titers: 400, epoch: 4 | loss: 0.1565502\n",
      "\tspeed: 0.0253s/iter; left time: 249.2863s\n",
      "\titers: 500, epoch: 4 | loss: 0.1341192\n",
      "\tspeed: 0.0261s/iter; left time: 254.7944s\n",
      "\titers: 600, epoch: 4 | loss: 0.1621944\n",
      "\tspeed: 0.0262s/iter; left time: 253.0186s\n",
      "Epoch: 4 cost time: 15.953272104263306\n",
      "Epoch: 4, Steps: 603 | Train Loss: 0.1744159 Vali Loss: 0.2027708 Test Loss: 0.2353563\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1374114\n",
      "\tspeed: 0.0659s/iter; left time: 629.6181s\n",
      "\titers: 200, epoch: 5 | loss: 0.1426378\n",
      "\tspeed: 0.0257s/iter; left time: 242.9188s\n",
      "\titers: 300, epoch: 5 | loss: 0.1439127\n",
      "\tspeed: 0.0249s/iter; left time: 233.0260s\n",
      "\titers: 400, epoch: 5 | loss: 0.1851505\n",
      "\tspeed: 0.0259s/iter; left time: 239.9510s\n",
      "\titers: 500, epoch: 5 | loss: 0.1258366\n",
      "\tspeed: 0.0267s/iter; left time: 244.6212s\n",
      "\titers: 600, epoch: 5 | loss: 0.1575942\n",
      "\tspeed: 0.0269s/iter; left time: 243.8296s\n",
      "Epoch: 5 cost time: 15.728235483169556\n",
      "Epoch: 5, Steps: 603 | Train Loss: 0.1659511 Vali Loss: 0.1886021 Test Loss: 0.2268650\n",
      "Validation loss decreased (0.190315 --> 0.188602).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1922367\n",
      "\tspeed: 0.0651s/iter; left time: 582.3443s\n",
      "\titers: 200, epoch: 6 | loss: 0.1301221\n",
      "\tspeed: 0.0250s/iter; left time: 220.9909s\n",
      "\titers: 300, epoch: 6 | loss: 0.4173237\n",
      "\tspeed: 0.0257s/iter; left time: 224.8165s\n",
      "\titers: 400, epoch: 6 | loss: 0.2293618\n",
      "\tspeed: 0.0270s/iter; left time: 233.8188s\n",
      "\titers: 500, epoch: 6 | loss: 0.1263633\n",
      "\tspeed: 0.0249s/iter; left time: 212.5543s\n",
      "\titers: 600, epoch: 6 | loss: 0.1286116\n",
      "\tspeed: 0.0243s/iter; left time: 205.5151s\n",
      "Epoch: 6 cost time: 15.42153811454773\n",
      "Epoch: 6, Steps: 603 | Train Loss: 0.1606595 Vali Loss: 0.1884125 Test Loss: 0.2263847\n",
      "Validation loss decreased (0.188602 --> 0.188413).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2124079\n",
      "\tspeed: 0.0621s/iter; left time: 518.4571s\n",
      "\titers: 200, epoch: 7 | loss: 0.1344000\n",
      "\tspeed: 0.0243s/iter; left time: 200.0867s\n",
      "\titers: 300, epoch: 7 | loss: 0.1199357\n",
      "\tspeed: 0.0253s/iter; left time: 206.4032s\n",
      "\titers: 400, epoch: 7 | loss: 0.1804149\n",
      "\tspeed: 0.0260s/iter; left time: 209.4107s\n",
      "\titers: 500, epoch: 7 | loss: 0.1991144\n",
      "\tspeed: 0.0255s/iter; left time: 202.5933s\n",
      "\titers: 600, epoch: 7 | loss: 0.2049947\n",
      "\tspeed: 0.0264s/iter; left time: 207.0160s\n",
      "Epoch: 7 cost time: 15.267613887786865\n",
      "Epoch: 7, Steps: 603 | Train Loss: 0.1577885 Vali Loss: 0.1910528 Test Loss: 0.2323781\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1169738\n",
      "\tspeed: 0.0657s/iter; left time: 508.3670s\n",
      "\titers: 200, epoch: 8 | loss: 0.1594861\n",
      "\tspeed: 0.0235s/iter; left time: 179.3495s\n",
      "\titers: 300, epoch: 8 | loss: 0.1716534\n",
      "\tspeed: 0.0248s/iter; left time: 187.0209s\n",
      "\titers: 400, epoch: 8 | loss: 0.1332356\n",
      "\tspeed: 0.0252s/iter; left time: 187.4472s\n",
      "\titers: 500, epoch: 8 | loss: 0.1109492\n",
      "\tspeed: 0.0252s/iter; left time: 185.0187s\n",
      "\titers: 600, epoch: 8 | loss: 0.1161688\n",
      "\tspeed: 0.0280s/iter; left time: 202.5505s\n",
      "Epoch: 8 cost time: 15.435896396636963\n",
      "Epoch: 8, Steps: 603 | Train Loss: 0.1563833 Vali Loss: 0.1896290 Test Loss: 0.2315870\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1327123\n",
      "\tspeed: 0.0688s/iter; left time: 490.7824s\n",
      "\titers: 200, epoch: 9 | loss: 0.1816252\n",
      "\tspeed: 0.0284s/iter; left time: 200.1950s\n",
      "\titers: 300, epoch: 9 | loss: 0.1633821\n",
      "\tspeed: 0.0274s/iter; left time: 190.0710s\n",
      "\titers: 400, epoch: 9 | loss: 0.1086911\n",
      "\tspeed: 0.0283s/iter; left time: 193.2754s\n",
      "\titers: 500, epoch: 9 | loss: 0.1595957\n",
      "\tspeed: 0.0273s/iter; left time: 183.7451s\n",
      "\titers: 600, epoch: 9 | loss: 0.1415854\n",
      "\tspeed: 0.0255s/iter; left time: 169.5005s\n",
      "Epoch: 9 cost time: 16.539454221725464\n",
      "Epoch: 9, Steps: 603 | Train Loss: 0.1549953 Vali Loss: 0.1910196 Test Loss: 0.2312536\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl48_ll16_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "Test cost time: 1.7227s\n",
      "test shape: (192, 32, 6, 1) (192, 32, 6, 1)\n",
      "test shape: (6144, 6, 1) (6144, 6, 1)\n",
      "mse:0.22670380771160126, mae:0.3166910409927368\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl48_ll16_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1643.484130859375\n",
      "MAE:  26.96430206298828\n",
      "RMSE: 40.53990936279297\n",
      "MAPE: 0.3725399374961853\n",
      "MSPE: 0.7461690902709961\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl48_ll16_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20985\n",
      "[DEBUG] Original dataset length: 20985\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19316\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6772\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "\titers: 100, epoch: 1 | loss: 0.2714900\n",
      "\tspeed: 0.0266s/iter; left time: 317.5823s\n",
      "\titers: 200, epoch: 1 | loss: 0.1877517\n",
      "\tspeed: 0.0269s/iter; left time: 318.7332s\n",
      "\titers: 300, epoch: 1 | loss: 0.3345226\n",
      "\tspeed: 0.0258s/iter; left time: 303.4365s\n",
      "\titers: 400, epoch: 1 | loss: 0.4541894\n",
      "\tspeed: 0.0248s/iter; left time: 289.6833s\n",
      "\titers: 500, epoch: 1 | loss: 0.2338556\n",
      "\tspeed: 0.0265s/iter; left time: 306.2216s\n",
      "\titers: 600, epoch: 1 | loss: 0.2839436\n",
      "\tspeed: 0.0250s/iter; left time: 286.6832s\n",
      "Epoch: 1 cost time: 15.649605751037598\n",
      "Epoch: 1, Steps: 603 | Train Loss: 0.2943538 Vali Loss: 0.2065839 Test Loss: 0.2425820\n",
      "Validation loss decreased (inf --> 0.206584).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1967636\n",
      "\tspeed: 0.0675s/iter; left time: 766.2491s\n",
      "\titers: 200, epoch: 2 | loss: 0.3587331\n",
      "\tspeed: 0.0266s/iter; left time: 299.6024s\n",
      "\titers: 300, epoch: 2 | loss: 0.2021923\n",
      "\tspeed: 0.0252s/iter; left time: 280.8608s\n",
      "\titers: 400, epoch: 2 | loss: 0.1023953\n",
      "\tspeed: 0.0254s/iter; left time: 280.4726s\n",
      "\titers: 500, epoch: 2 | loss: 0.3151286\n",
      "\tspeed: 0.0253s/iter; left time: 276.9309s\n",
      "\titers: 600, epoch: 2 | loss: 0.2428958\n",
      "\tspeed: 0.0278s/iter; left time: 301.6813s\n",
      "Epoch: 2 cost time: 15.722517251968384\n",
      "Epoch: 2, Steps: 603 | Train Loss: 0.2181687 Vali Loss: 0.1958004 Test Loss: 0.2342693\n",
      "Validation loss decreased (0.206584 --> 0.195800).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1664001\n",
      "\tspeed: 0.0663s/iter; left time: 712.9193s\n",
      "\titers: 200, epoch: 3 | loss: 0.1485826\n",
      "\tspeed: 0.0262s/iter; left time: 279.4075s\n",
      "\titers: 300, epoch: 3 | loss: 0.1116938\n",
      "\tspeed: 0.0257s/iter; left time: 270.8672s\n",
      "\titers: 400, epoch: 3 | loss: 0.1937691\n",
      "\tspeed: 0.0289s/iter; left time: 302.4118s\n",
      "\titers: 500, epoch: 3 | loss: 0.2059108\n",
      "\tspeed: 0.0260s/iter; left time: 269.1844s\n",
      "\titers: 600, epoch: 3 | loss: 0.2103401\n",
      "\tspeed: 0.0256s/iter; left time: 262.8222s\n",
      "Epoch: 3 cost time: 16.029783010482788\n",
      "Epoch: 3, Steps: 603 | Train Loss: 0.1893891 Vali Loss: 0.1935041 Test Loss: 0.2286829\n",
      "Validation loss decreased (0.195800 --> 0.193504).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1706025\n",
      "\tspeed: 0.0615s/iter; left time: 623.8648s\n",
      "\titers: 200, epoch: 4 | loss: 0.1834649\n",
      "\tspeed: 0.0272s/iter; left time: 273.1873s\n",
      "\titers: 300, epoch: 4 | loss: 0.1787638\n",
      "\tspeed: 0.0253s/iter; left time: 251.6315s\n",
      "\titers: 400, epoch: 4 | loss: 0.1610934\n",
      "\tspeed: 0.0247s/iter; left time: 243.4043s\n",
      "\titers: 500, epoch: 4 | loss: 0.2407990\n",
      "\tspeed: 0.0252s/iter; left time: 245.5913s\n",
      "\titers: 600, epoch: 4 | loss: 0.1347188\n",
      "\tspeed: 0.0241s/iter; left time: 232.6003s\n",
      "Epoch: 4 cost time: 15.159103155136108\n",
      "Epoch: 4, Steps: 603 | Train Loss: 0.1751081 Vali Loss: 0.1946246 Test Loss: 0.2340476\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1696261\n",
      "\tspeed: 0.0648s/iter; left time: 618.6366s\n",
      "\titers: 200, epoch: 5 | loss: 0.1077438\n",
      "\tspeed: 0.0260s/iter; left time: 245.6194s\n",
      "\titers: 300, epoch: 5 | loss: 0.1104470\n",
      "\tspeed: 0.0251s/iter; left time: 234.9311s\n",
      "\titers: 400, epoch: 5 | loss: 0.1739598\n",
      "\tspeed: 0.0259s/iter; left time: 239.3017s\n",
      "\titers: 500, epoch: 5 | loss: 0.1480238\n",
      "\tspeed: 0.0251s/iter; left time: 229.5653s\n",
      "\titers: 600, epoch: 5 | loss: 0.2616807\n",
      "\tspeed: 0.0270s/iter; left time: 243.9287s\n",
      "Epoch: 5 cost time: 15.781593322753906\n",
      "Epoch: 5, Steps: 603 | Train Loss: 0.1653308 Vali Loss: 0.1937660 Test Loss: 0.2321281\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1192791\n",
      "\tspeed: 0.0643s/iter; left time: 574.8656s\n",
      "\titers: 200, epoch: 6 | loss: 0.2242532\n",
      "\tspeed: 0.0265s/iter; left time: 234.2920s\n",
      "\titers: 300, epoch: 6 | loss: 0.1186117\n",
      "\tspeed: 0.0245s/iter; left time: 214.1366s\n",
      "\titers: 400, epoch: 6 | loss: 0.2240689\n",
      "\tspeed: 0.0252s/iter; left time: 217.7744s\n",
      "\titers: 500, epoch: 6 | loss: 0.2525322\n",
      "\tspeed: 0.0278s/iter; left time: 237.8463s\n",
      "\titers: 600, epoch: 6 | loss: 0.0987420\n",
      "\tspeed: 0.0257s/iter; left time: 217.1824s\n",
      "Epoch: 6 cost time: 15.616832971572876\n",
      "Epoch: 6, Steps: 603 | Train Loss: 0.1603650 Vali Loss: 0.1948939 Test Loss: 0.2346450\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl48_ll16_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "Test cost time: 1.8072s\n",
      "test shape: (192, 32, 6, 1) (192, 32, 6, 1)\n",
      "test shape: (6144, 6, 1) (6144, 6, 1)\n",
      "mse:0.22881677746772766, mae:0.3242523968219757\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl48_ll16_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1658.8021240234375\n",
      "MAE:  27.608102798461914\n",
      "RMSE: 40.7283935546875\n",
      "MAPE: 0.3500930368900299\n",
      "MSPE: 0.5491622686386108\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl48_ll16_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20985\n",
      "[DEBUG] Original dataset length: 20985\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19316\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6772\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "\titers: 100, epoch: 1 | loss: 0.2815771\n",
      "\tspeed: 0.0267s/iter; left time: 319.6729s\n",
      "\titers: 200, epoch: 1 | loss: 0.2178006\n",
      "\tspeed: 0.0297s/iter; left time: 351.9637s\n",
      "\titers: 300, epoch: 1 | loss: 0.2398570\n",
      "\tspeed: 0.0255s/iter; left time: 299.5480s\n",
      "\titers: 400, epoch: 1 | loss: 0.1663284\n",
      "\tspeed: 0.0249s/iter; left time: 290.4856s\n",
      "\titers: 500, epoch: 1 | loss: 0.2837053\n",
      "\tspeed: 0.0262s/iter; left time: 302.4894s\n",
      "\titers: 600, epoch: 1 | loss: 0.2247802\n",
      "\tspeed: 0.0258s/iter; left time: 295.2148s\n",
      "Epoch: 1 cost time: 15.955634832382202\n",
      "Epoch: 1, Steps: 603 | Train Loss: 0.2897576 Vali Loss: 0.2170232 Test Loss: 0.2521020\n",
      "Validation loss decreased (inf --> 0.217023).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1902096\n",
      "\tspeed: 0.0673s/iter; left time: 764.9284s\n",
      "\titers: 200, epoch: 2 | loss: 0.1427276\n",
      "\tspeed: 0.0258s/iter; left time: 290.2327s\n",
      "\titers: 300, epoch: 2 | loss: 0.1793497\n",
      "\tspeed: 0.0255s/iter; left time: 284.6048s\n",
      "\titers: 400, epoch: 2 | loss: 0.2211128\n",
      "\tspeed: 0.0252s/iter; left time: 279.1933s\n",
      "\titers: 500, epoch: 2 | loss: 0.2449191\n",
      "\tspeed: 0.0249s/iter; left time: 272.5246s\n",
      "\titers: 600, epoch: 2 | loss: 0.2217624\n",
      "\tspeed: 0.0277s/iter; left time: 301.0323s\n",
      "Epoch: 2 cost time: 15.899510622024536\n",
      "Epoch: 2, Steps: 603 | Train Loss: 0.2203423 Vali Loss: 0.1983291 Test Loss: 0.2364548\n",
      "Validation loss decreased (0.217023 --> 0.198329).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2221140\n",
      "\tspeed: 0.0689s/iter; left time: 741.0626s\n",
      "\titers: 200, epoch: 3 | loss: 0.1886396\n",
      "\tspeed: 0.0256s/iter; left time: 272.9379s\n",
      "\titers: 300, epoch: 3 | loss: 0.1628357\n",
      "\tspeed: 0.0247s/iter; left time: 260.3908s\n",
      "\titers: 400, epoch: 3 | loss: 0.1756297\n",
      "\tspeed: 0.0283s/iter; left time: 295.6708s\n",
      "\titers: 500, epoch: 3 | loss: 0.1903691\n",
      "\tspeed: 0.0271s/iter; left time: 280.5439s\n",
      "\titers: 600, epoch: 3 | loss: 0.1347038\n",
      "\tspeed: 0.0250s/iter; left time: 256.4547s\n",
      "Epoch: 3 cost time: 15.913084268569946\n",
      "Epoch: 3, Steps: 603 | Train Loss: 0.1890062 Vali Loss: 0.2014631 Test Loss: 0.2343263\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2333156\n",
      "\tspeed: 0.0634s/iter; left time: 643.6441s\n",
      "\titers: 200, epoch: 4 | loss: 0.1620288\n",
      "\tspeed: 0.0271s/iter; left time: 272.7168s\n",
      "\titers: 300, epoch: 4 | loss: 0.2346143\n",
      "\tspeed: 0.0295s/iter; left time: 293.9277s\n",
      "\titers: 400, epoch: 4 | loss: 0.0974097\n",
      "\tspeed: 0.0253s/iter; left time: 249.6823s\n",
      "\titers: 500, epoch: 4 | loss: 0.2224316\n",
      "\tspeed: 0.0252s/iter; left time: 245.7589s\n",
      "\titers: 600, epoch: 4 | loss: 0.1232098\n",
      "\tspeed: 0.0254s/iter; left time: 245.3078s\n",
      "Epoch: 4 cost time: 15.950064897537231\n",
      "Epoch: 4, Steps: 603 | Train Loss: 0.1753203 Vali Loss: 0.1914144 Test Loss: 0.2281985\n",
      "Validation loss decreased (0.198329 --> 0.191414).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1527764\n",
      "\tspeed: 0.0651s/iter; left time: 621.2091s\n",
      "\titers: 200, epoch: 5 | loss: 0.2095914\n",
      "\tspeed: 0.0265s/iter; left time: 250.0174s\n",
      "\titers: 300, epoch: 5 | loss: 0.1625112\n",
      "\tspeed: 0.0257s/iter; left time: 240.0646s\n",
      "\titers: 400, epoch: 5 | loss: 0.2127070\n",
      "\tspeed: 0.0255s/iter; left time: 236.3040s\n",
      "\titers: 500, epoch: 5 | loss: 0.1552371\n",
      "\tspeed: 0.0249s/iter; left time: 227.6693s\n",
      "\titers: 600, epoch: 5 | loss: 0.1177787\n",
      "\tspeed: 0.0249s/iter; left time: 224.8977s\n",
      "Epoch: 5 cost time: 15.712251424789429\n",
      "Epoch: 5, Steps: 603 | Train Loss: 0.1660427 Vali Loss: 0.1906596 Test Loss: 0.2276343\n",
      "Validation loss decreased (0.191414 --> 0.190660).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1537815\n",
      "\tspeed: 0.0665s/iter; left time: 594.4652s\n",
      "\titers: 200, epoch: 6 | loss: 0.1175478\n",
      "\tspeed: 0.0277s/iter; left time: 245.3539s\n",
      "\titers: 300, epoch: 6 | loss: 0.1089337\n",
      "\tspeed: 0.0277s/iter; left time: 242.2775s\n",
      "\titers: 400, epoch: 6 | loss: 0.1759370\n",
      "\tspeed: 0.0341s/iter; left time: 294.8363s\n",
      "\titers: 500, epoch: 6 | loss: 0.0931003\n",
      "\tspeed: 0.0328s/iter; left time: 280.4673s\n",
      "\titers: 600, epoch: 6 | loss: 0.1969815\n",
      "\tspeed: 0.0273s/iter; left time: 230.5233s\n",
      "Epoch: 6 cost time: 17.753005981445312\n",
      "Epoch: 6, Steps: 603 | Train Loss: 0.1608486 Vali Loss: 0.1879531 Test Loss: 0.2265521\n",
      "Validation loss decreased (0.190660 --> 0.187953).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2366926\n",
      "\tspeed: 0.0701s/iter; left time: 584.9111s\n",
      "\titers: 200, epoch: 7 | loss: 0.1668960\n",
      "\tspeed: 0.0298s/iter; left time: 245.7045s\n",
      "\titers: 300, epoch: 7 | loss: 0.2137491\n",
      "\tspeed: 0.0306s/iter; left time: 249.0627s\n",
      "\titers: 400, epoch: 7 | loss: 0.1358376\n",
      "\tspeed: 0.0273s/iter; left time: 219.5163s\n",
      "\titers: 500, epoch: 7 | loss: 0.1686917\n",
      "\tspeed: 0.0277s/iter; left time: 219.9468s\n",
      "\titers: 600, epoch: 7 | loss: 0.1436866\n",
      "\tspeed: 0.0268s/iter; left time: 210.4847s\n",
      "Epoch: 7 cost time: 17.05389642715454\n",
      "Epoch: 7, Steps: 603 | Train Loss: 0.1582338 Vali Loss: 0.1914499 Test Loss: 0.2304329\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1493215\n",
      "\tspeed: 0.0702s/iter; left time: 543.4319s\n",
      "\titers: 200, epoch: 8 | loss: 0.1305441\n",
      "\tspeed: 0.0288s/iter; left time: 220.0651s\n",
      "\titers: 300, epoch: 8 | loss: 0.1126223\n",
      "\tspeed: 0.0286s/iter; left time: 215.8612s\n",
      "\titers: 400, epoch: 8 | loss: 0.1338652\n",
      "\tspeed: 0.0287s/iter; left time: 213.2204s\n",
      "\titers: 500, epoch: 8 | loss: 0.1903661\n",
      "\tspeed: 0.0272s/iter; left time: 199.4027s\n",
      "\titers: 600, epoch: 8 | loss: 0.1442703\n",
      "\tspeed: 0.0303s/iter; left time: 219.5116s\n",
      "Epoch: 8 cost time: 17.31825828552246\n",
      "Epoch: 8, Steps: 603 | Train Loss: 0.1564447 Vali Loss: 0.1900826 Test Loss: 0.2287684\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.2156591\n",
      "\tspeed: 0.0691s/iter; left time: 493.1258s\n",
      "\titers: 200, epoch: 9 | loss: 0.1060037\n",
      "\tspeed: 0.0280s/iter; left time: 197.2541s\n",
      "\titers: 300, epoch: 9 | loss: 0.1739424\n",
      "\tspeed: 0.0280s/iter; left time: 194.4795s\n",
      "\titers: 400, epoch: 9 | loss: 0.1561356\n",
      "\tspeed: 0.0286s/iter; left time: 195.4477s\n",
      "\titers: 500, epoch: 9 | loss: 0.1810529\n",
      "\tspeed: 0.0276s/iter; left time: 185.7343s\n",
      "\titers: 600, epoch: 9 | loss: 0.1638545\n",
      "\tspeed: 0.0276s/iter; left time: 183.1793s\n",
      "Epoch: 9 cost time: 16.88561725616455\n",
      "Epoch: 9, Steps: 603 | Train Loss: 0.1555391 Vali Loss: 0.1903584 Test Loss: 0.2291765\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl48_ll16_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "Test cost time: 1.8892s\n",
      "test shape: (192, 32, 6, 1) (192, 32, 6, 1)\n",
      "test shape: (6144, 6, 1) (6144, 6, 1)\n",
      "mse:0.22582414746284485, mae:0.3159513473510742\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl48_ll16_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1637.1070556640625\n",
      "MAE:  26.901315689086914\n",
      "RMSE: 40.461177825927734\n",
      "MAPE: 0.34694749116897583\n",
      "MSPE: 0.5732104778289795\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl48_ll16_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20985\n",
      "[DEBUG] Original dataset length: 20985\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 19316\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6772\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "\titers: 100, epoch: 1 | loss: 0.2047685\n",
      "\tspeed: 0.0287s/iter; left time: 343.5292s\n",
      "\titers: 200, epoch: 1 | loss: 0.2113266\n",
      "\tspeed: 0.0278s/iter; left time: 329.3982s\n",
      "\titers: 300, epoch: 1 | loss: 0.2114941\n",
      "\tspeed: 0.0289s/iter; left time: 339.5855s\n",
      "\titers: 400, epoch: 1 | loss: 0.2135461\n",
      "\tspeed: 0.0279s/iter; left time: 325.8634s\n",
      "\titers: 500, epoch: 1 | loss: 0.1917836\n",
      "\tspeed: 0.0291s/iter; left time: 336.3403s\n",
      "\titers: 600, epoch: 1 | loss: 0.2305462\n",
      "\tspeed: 0.0285s/iter; left time: 327.0857s\n",
      "Epoch: 1 cost time: 17.195580005645752\n",
      "Epoch: 1, Steps: 603 | Train Loss: 0.2876261 Vali Loss: 0.2062447 Test Loss: 0.2448778\n",
      "Validation loss decreased (inf --> 0.206245).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2005841\n",
      "\tspeed: 0.0673s/iter; left time: 764.4471s\n",
      "\titers: 200, epoch: 2 | loss: 0.1284852\n",
      "\tspeed: 0.0273s/iter; left time: 307.2676s\n",
      "\titers: 300, epoch: 2 | loss: 0.1391970\n",
      "\tspeed: 0.0271s/iter; left time: 302.7861s\n",
      "\titers: 400, epoch: 2 | loss: 0.1968631\n",
      "\tspeed: 0.0282s/iter; left time: 311.7293s\n",
      "\titers: 500, epoch: 2 | loss: 0.1944727\n",
      "\tspeed: 0.0275s/iter; left time: 301.3267s\n",
      "\titers: 600, epoch: 2 | loss: 0.1961470\n",
      "\tspeed: 0.0269s/iter; left time: 291.8807s\n",
      "Epoch: 2 cost time: 16.511250972747803\n",
      "Epoch: 2, Steps: 603 | Train Loss: 0.2167246 Vali Loss: 0.2037640 Test Loss: 0.2332922\n",
      "Validation loss decreased (0.206245 --> 0.203764).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0976011\n",
      "\tspeed: 0.0691s/iter; left time: 743.2727s\n",
      "\titers: 200, epoch: 3 | loss: 0.2240575\n",
      "\tspeed: 0.0277s/iter; left time: 295.3530s\n",
      "\titers: 300, epoch: 3 | loss: 0.2112467\n",
      "\tspeed: 0.0280s/iter; left time: 295.3018s\n",
      "\titers: 400, epoch: 3 | loss: 0.1987372\n",
      "\tspeed: 0.0279s/iter; left time: 291.3905s\n",
      "\titers: 500, epoch: 3 | loss: 0.2842248\n",
      "\tspeed: 0.0277s/iter; left time: 286.7411s\n",
      "\titers: 600, epoch: 3 | loss: 0.1263097\n",
      "\tspeed: 0.0291s/iter; left time: 298.7540s\n",
      "Epoch: 3 cost time: 17.000392198562622\n",
      "Epoch: 3, Steps: 603 | Train Loss: 0.1913841 Vali Loss: 0.1919381 Test Loss: 0.2248268\n",
      "Validation loss decreased (0.203764 --> 0.191938).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2200695\n",
      "\tspeed: 0.0690s/iter; left time: 700.4822s\n",
      "\titers: 200, epoch: 4 | loss: 0.1183404\n",
      "\tspeed: 0.0280s/iter; left time: 281.1559s\n",
      "\titers: 300, epoch: 4 | loss: 0.2159603\n",
      "\tspeed: 0.0274s/iter; left time: 272.1907s\n",
      "\titers: 400, epoch: 4 | loss: 0.3491055\n",
      "\tspeed: 0.0280s/iter; left time: 276.0541s\n",
      "\titers: 500, epoch: 4 | loss: 0.1445749\n",
      "\tspeed: 0.0290s/iter; left time: 282.3506s\n",
      "\titers: 600, epoch: 4 | loss: 0.1996842\n",
      "\tspeed: 0.0277s/iter; left time: 267.1293s\n",
      "Epoch: 4 cost time: 16.7381432056427\n",
      "Epoch: 4, Steps: 603 | Train Loss: 0.1779889 Vali Loss: 0.1878154 Test Loss: 0.2265710\n",
      "Validation loss decreased (0.191938 --> 0.187815).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0953422\n",
      "\tspeed: 0.0678s/iter; left time: 647.3921s\n",
      "\titers: 200, epoch: 5 | loss: 0.2033547\n",
      "\tspeed: 0.0277s/iter; left time: 261.9880s\n",
      "\titers: 300, epoch: 5 | loss: 0.2574272\n",
      "\tspeed: 0.0297s/iter; left time: 277.7839s\n",
      "\titers: 400, epoch: 5 | loss: 0.1530425\n",
      "\tspeed: 0.0294s/iter; left time: 271.6476s\n",
      "\titers: 500, epoch: 5 | loss: 0.2605317\n",
      "\tspeed: 0.0296s/iter; left time: 271.1701s\n",
      "\titers: 600, epoch: 5 | loss: 0.1604486\n",
      "\tspeed: 0.0282s/iter; left time: 255.2309s\n",
      "Epoch: 5 cost time: 17.39189577102661\n",
      "Epoch: 5, Steps: 603 | Train Loss: 0.1687221 Vali Loss: 0.1930474 Test Loss: 0.2281292\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2006135\n",
      "\tspeed: 0.0715s/iter; left time: 639.6996s\n",
      "\titers: 200, epoch: 6 | loss: 0.1163714\n",
      "\tspeed: 0.0287s/iter; left time: 253.7848s\n",
      "\titers: 300, epoch: 6 | loss: 0.1276321\n",
      "\tspeed: 0.0285s/iter; left time: 249.3888s\n",
      "\titers: 400, epoch: 6 | loss: 0.1372755\n",
      "\tspeed: 0.0272s/iter; left time: 235.1524s\n",
      "\titers: 500, epoch: 6 | loss: 0.1647894\n",
      "\tspeed: 0.0263s/iter; left time: 224.5778s\n",
      "\titers: 600, epoch: 6 | loss: 0.1422689\n",
      "\tspeed: 0.0277s/iter; left time: 234.3041s\n",
      "Epoch: 6 cost time: 17.07629418373108\n",
      "Epoch: 6, Steps: 603 | Train Loss: 0.1627145 Vali Loss: 0.1910381 Test Loss: 0.2260220\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2237868\n",
      "\tspeed: 0.0666s/iter; left time: 555.9261s\n",
      "\titers: 200, epoch: 7 | loss: 0.1299174\n",
      "\tspeed: 0.0281s/iter; left time: 231.2344s\n",
      "\titers: 300, epoch: 7 | loss: 0.2227097\n",
      "\tspeed: 0.0278s/iter; left time: 226.5498s\n",
      "\titers: 400, epoch: 7 | loss: 0.1477903\n",
      "\tspeed: 0.0284s/iter; left time: 228.4792s\n",
      "\titers: 500, epoch: 7 | loss: 0.1770603\n",
      "\tspeed: 0.0284s/iter; left time: 225.7620s\n",
      "\titers: 600, epoch: 7 | loss: 0.2082532\n",
      "\tspeed: 0.0271s/iter; left time: 212.7277s\n",
      "Epoch: 7 cost time: 16.764400720596313\n",
      "Epoch: 7, Steps: 603 | Train Loss: 0.1602703 Vali Loss: 0.1926985 Test Loss: 0.2274518\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl48_ll16_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6170\n",
      "Test cost time: 1.9002s\n",
      "test shape: (192, 32, 6, 1) (192, 32, 6, 1)\n",
      "test shape: (6144, 6, 1) (6144, 6, 1)\n",
      "mse:0.22660429775714874, mae:0.31584346294403076\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl48_ll16_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1642.7630615234375\n",
      "MAE:  26.892135620117188\n",
      "RMSE: 40.53101348876953\n",
      "MAPE: 0.3441655933856964\n",
      "MSPE: 0.5981287360191345\n",
      ">>>>>>>Running time saved<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Running seq_len=72, label_len=24, pred_len=6\n",
      "Args in experiment:\n",
      "Namespace(model='informer', data='traffic_full', root_path='../', data_path='traffic_full.csv', features='S', target='flow', freq='h', checkpoints='./checkpoints/', seq_len=72, label_len=24, pred_len=6, enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=2, d_layers=1, s_layers=[3, 2, 1], d_ff=2048, factor=5, padding=0, distil=True, dropout=0.05, attn='prob', embed='timeF', activation='gelu', output_attention=False, do_predict=False, mix=True, cols=None, num_workers=0, itr=10, train_epochs=20, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, inverse=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', detail_freq='h')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20961\n",
      "[DEBUG] Original dataset length: 20961\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18956\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6700\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "\titers: 100, epoch: 1 | loss: 0.2190128\n",
      "\tspeed: 0.0447s/iter; left time: 525.0003s\n",
      "\titers: 200, epoch: 1 | loss: 0.2737656\n",
      "\tspeed: 0.0285s/iter; left time: 331.5617s\n",
      "\titers: 300, epoch: 1 | loss: 0.3570705\n",
      "\tspeed: 0.0284s/iter; left time: 327.6060s\n",
      "\titers: 400, epoch: 1 | loss: 0.2461519\n",
      "\tspeed: 0.0298s/iter; left time: 340.7613s\n",
      "\titers: 500, epoch: 1 | loss: 0.4095210\n",
      "\tspeed: 0.0288s/iter; left time: 326.2197s\n",
      "Epoch: 1 cost time: 17.765067100524902\n",
      "Epoch: 1, Steps: 592 | Train Loss: 0.3014692 Vali Loss: 0.2082741 Test Loss: 0.2517364\n",
      "Validation loss decreased (inf --> 0.208274).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1486324\n",
      "\tspeed: 0.0982s/iter; left time: 1094.4721s\n",
      "\titers: 200, epoch: 2 | loss: 0.1421963\n",
      "\tspeed: 0.0298s/iter; left time: 328.7729s\n",
      "\titers: 300, epoch: 2 | loss: 0.3944573\n",
      "\tspeed: 0.0285s/iter; left time: 312.3289s\n",
      "\titers: 400, epoch: 2 | loss: 0.1067695\n",
      "\tspeed: 0.0280s/iter; left time: 304.1954s\n",
      "\titers: 500, epoch: 2 | loss: 0.3145600\n",
      "\tspeed: 0.0278s/iter; left time: 298.4992s\n",
      "Epoch: 2 cost time: 16.808701038360596\n",
      "Epoch: 2, Steps: 592 | Train Loss: 0.2199800 Vali Loss: 0.2067511 Test Loss: 0.2436651\n",
      "Validation loss decreased (0.208274 --> 0.206751).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2449905\n",
      "\tspeed: 0.0967s/iter; left time: 1021.2363s\n",
      "\titers: 200, epoch: 3 | loss: 0.1359740\n",
      "\tspeed: 0.0277s/iter; left time: 289.5388s\n",
      "\titers: 300, epoch: 3 | loss: 0.1655459\n",
      "\tspeed: 0.0273s/iter; left time: 282.2637s\n",
      "\titers: 400, epoch: 3 | loss: 0.1805131\n",
      "\tspeed: 0.0276s/iter; left time: 283.5069s\n",
      "\titers: 500, epoch: 3 | loss: 0.2488086\n",
      "\tspeed: 0.0282s/iter; left time: 286.5610s\n",
      "Epoch: 3 cost time: 16.653248071670532\n",
      "Epoch: 3, Steps: 592 | Train Loss: 0.1901304 Vali Loss: 0.2045657 Test Loss: 0.2523489\n",
      "Validation loss decreased (0.206751 --> 0.204566).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2010779\n",
      "\tspeed: 0.0979s/iter; left time: 975.6634s\n",
      "\titers: 200, epoch: 4 | loss: 0.1859360\n",
      "\tspeed: 0.0280s/iter; left time: 276.2211s\n",
      "\titers: 300, epoch: 4 | loss: 0.1458664\n",
      "\tspeed: 0.0289s/iter; left time: 282.1442s\n",
      "\titers: 400, epoch: 4 | loss: 0.1312293\n",
      "\tspeed: 0.0305s/iter; left time: 294.8127s\n",
      "\titers: 500, epoch: 4 | loss: 0.2689608\n",
      "\tspeed: 0.0291s/iter; left time: 278.3200s\n",
      "Epoch: 4 cost time: 17.09889316558838\n",
      "Epoch: 4, Steps: 592 | Train Loss: 0.1738355 Vali Loss: 0.1972706 Test Loss: 0.2360877\n",
      "Validation loss decreased (0.204566 --> 0.197271).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1337368\n",
      "\tspeed: 0.0986s/iter; left time: 923.8732s\n",
      "\titers: 200, epoch: 5 | loss: 0.2634565\n",
      "\tspeed: 0.0281s/iter; left time: 260.7306s\n",
      "\titers: 300, epoch: 5 | loss: 0.2904693\n",
      "\tspeed: 0.0275s/iter; left time: 252.2844s\n",
      "\titers: 400, epoch: 5 | loss: 0.1189283\n",
      "\tspeed: 0.0277s/iter; left time: 251.2692s\n",
      "\titers: 500, epoch: 5 | loss: 0.1415560\n",
      "\tspeed: 0.0271s/iter; left time: 243.3757s\n",
      "Epoch: 5 cost time: 16.654579639434814\n",
      "Epoch: 5, Steps: 592 | Train Loss: 0.1656557 Vali Loss: 0.1946398 Test Loss: 0.2300345\n",
      "Validation loss decreased (0.197271 --> 0.194640).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1363526\n",
      "\tspeed: 0.0957s/iter; left time: 840.2145s\n",
      "\titers: 200, epoch: 6 | loss: 0.2541338\n",
      "\tspeed: 0.0274s/iter; left time: 238.0191s\n",
      "\titers: 300, epoch: 6 | loss: 0.1038207\n",
      "\tspeed: 0.0266s/iter; left time: 228.4420s\n",
      "\titers: 400, epoch: 6 | loss: 0.1130964\n",
      "\tspeed: 0.0295s/iter; left time: 250.3823s\n",
      "\titers: 500, epoch: 6 | loss: 0.1926298\n",
      "\tspeed: 0.0292s/iter; left time: 244.5536s\n",
      "Epoch: 6 cost time: 16.831193447113037\n",
      "Epoch: 6, Steps: 592 | Train Loss: 0.1608207 Vali Loss: 0.1965116 Test Loss: 0.2297561\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1109624\n",
      "\tspeed: 0.0965s/iter; left time: 790.4399s\n",
      "\titers: 200, epoch: 7 | loss: 0.2178923\n",
      "\tspeed: 0.0301s/iter; left time: 243.5877s\n",
      "\titers: 300, epoch: 7 | loss: 0.2171499\n",
      "\tspeed: 0.0286s/iter; left time: 228.2074s\n",
      "\titers: 400, epoch: 7 | loss: 0.1000637\n",
      "\tspeed: 0.0289s/iter; left time: 228.3679s\n",
      "\titers: 500, epoch: 7 | loss: 0.1633165\n",
      "\tspeed: 0.0274s/iter; left time: 213.2558s\n",
      "Epoch: 7 cost time: 17.06970977783203\n",
      "Epoch: 7, Steps: 592 | Train Loss: 0.1573369 Vali Loss: 0.1976282 Test Loss: 0.2316062\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2062185\n",
      "\tspeed: 0.0982s/iter; left time: 746.0018s\n",
      "\titers: 200, epoch: 8 | loss: 0.1783201\n",
      "\tspeed: 0.0293s/iter; left time: 219.8507s\n",
      "\titers: 300, epoch: 8 | loss: 0.1166934\n",
      "\tspeed: 0.0286s/iter; left time: 211.6937s\n",
      "\titers: 400, epoch: 8 | loss: 0.1638682\n",
      "\tspeed: 0.0287s/iter; left time: 209.2258s\n",
      "\titers: 500, epoch: 8 | loss: 0.1252166\n",
      "\tspeed: 0.0287s/iter; left time: 206.4898s\n",
      "Epoch: 8 cost time: 17.083805799484253\n",
      "Epoch: 8, Steps: 592 | Train Loss: 0.1560862 Vali Loss: 0.1950142 Test Loss: 0.2300387\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "Test cost time: 1.8551s\n",
      "test shape: (187, 32, 6, 1) (187, 32, 6, 1)\n",
      "test shape: (5984, 6, 1) (5984, 6, 1)\n",
      "mse:0.22973395884037018, mae:0.326058566570282\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1665.451171875\n",
      "MAE:  27.76188850402832\n",
      "RMSE: 40.809940338134766\n",
      "MAPE: 0.3673202693462372\n",
      "MSPE: 0.6463017463684082\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20961\n",
      "[DEBUG] Original dataset length: 20961\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18956\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6700\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "\titers: 100, epoch: 1 | loss: 0.4150284\n",
      "\tspeed: 0.0288s/iter; left time: 337.6329s\n",
      "\titers: 200, epoch: 1 | loss: 0.2561363\n",
      "\tspeed: 0.0280s/iter; left time: 325.4564s\n",
      "\titers: 300, epoch: 1 | loss: 0.2723839\n",
      "\tspeed: 0.0294s/iter; left time: 339.3925s\n",
      "\titers: 400, epoch: 1 | loss: 0.1967524\n",
      "\tspeed: 0.0296s/iter; left time: 338.9528s\n",
      "\titers: 500, epoch: 1 | loss: 0.3262230\n",
      "\tspeed: 0.0284s/iter; left time: 322.5719s\n",
      "Epoch: 1 cost time: 17.01134443283081\n",
      "Epoch: 1, Steps: 592 | Train Loss: 0.2952165 Vali Loss: 0.2252524 Test Loss: 0.2520692\n",
      "Validation loss decreased (inf --> 0.225252).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2847802\n",
      "\tspeed: 0.0986s/iter; left time: 1099.0062s\n",
      "\titers: 200, epoch: 2 | loss: 0.3127322\n",
      "\tspeed: 0.0283s/iter; left time: 313.2163s\n",
      "\titers: 300, epoch: 2 | loss: 0.1498984\n",
      "\tspeed: 0.0293s/iter; left time: 321.0039s\n",
      "\titers: 400, epoch: 2 | loss: 0.2043616\n",
      "\tspeed: 0.0279s/iter; left time: 302.9339s\n",
      "\titers: 500, epoch: 2 | loss: 0.3169800\n",
      "\tspeed: 0.0292s/iter; left time: 313.7457s\n",
      "Epoch: 2 cost time: 17.23749017715454\n",
      "Epoch: 2, Steps: 592 | Train Loss: 0.2196067 Vali Loss: 0.2057855 Test Loss: 0.2377776\n",
      "Validation loss decreased (0.225252 --> 0.205785).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1625393\n",
      "\tspeed: 0.0986s/iter; left time: 1040.9325s\n",
      "\titers: 200, epoch: 3 | loss: 0.1566597\n",
      "\tspeed: 0.0287s/iter; left time: 300.3611s\n",
      "\titers: 300, epoch: 3 | loss: 0.1975822\n",
      "\tspeed: 0.0293s/iter; left time: 303.6357s\n",
      "\titers: 400, epoch: 3 | loss: 0.1653145\n",
      "\tspeed: 0.0263s/iter; left time: 269.9023s\n",
      "\titers: 500, epoch: 3 | loss: 0.1855429\n",
      "\tspeed: 0.0273s/iter; left time: 277.2150s\n",
      "Epoch: 3 cost time: 16.454478979110718\n",
      "Epoch: 3, Steps: 592 | Train Loss: 0.1873688 Vali Loss: 0.1967979 Test Loss: 0.2243972\n",
      "Validation loss decreased (0.205785 --> 0.196798).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2774879\n",
      "\tspeed: 0.0944s/iter; left time: 940.6298s\n",
      "\titers: 200, epoch: 4 | loss: 0.1654177\n",
      "\tspeed: 0.0300s/iter; left time: 295.9631s\n",
      "\titers: 300, epoch: 4 | loss: 0.1201748\n",
      "\tspeed: 0.0300s/iter; left time: 292.5447s\n",
      "\titers: 400, epoch: 4 | loss: 0.1595045\n",
      "\tspeed: 0.0281s/iter; left time: 271.4243s\n",
      "\titers: 500, epoch: 4 | loss: 0.1638584\n",
      "\tspeed: 0.0284s/iter; left time: 271.1988s\n",
      "Epoch: 4 cost time: 17.26773452758789\n",
      "Epoch: 4, Steps: 592 | Train Loss: 0.1729238 Vali Loss: 0.1951880 Test Loss: 0.2233837\n",
      "Validation loss decreased (0.196798 --> 0.195188).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1641295\n",
      "\tspeed: 0.0963s/iter; left time: 902.2137s\n",
      "\titers: 200, epoch: 5 | loss: 0.1225428\n",
      "\tspeed: 0.0276s/iter; left time: 255.7150s\n",
      "\titers: 300, epoch: 5 | loss: 0.1572487\n",
      "\tspeed: 0.0277s/iter; left time: 253.8788s\n",
      "\titers: 400, epoch: 5 | loss: 0.1293775\n",
      "\tspeed: 0.0283s/iter; left time: 256.5065s\n",
      "\titers: 500, epoch: 5 | loss: 0.1891956\n",
      "\tspeed: 0.0298s/iter; left time: 266.9956s\n",
      "Epoch: 5 cost time: 16.69237184524536\n",
      "Epoch: 5, Steps: 592 | Train Loss: 0.1628395 Vali Loss: 0.1927520 Test Loss: 0.2200131\n",
      "Validation loss decreased (0.195188 --> 0.192752).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2547908\n",
      "\tspeed: 0.0952s/iter; left time: 835.8750s\n",
      "\titers: 200, epoch: 6 | loss: 0.1201308\n",
      "\tspeed: 0.0293s/iter; left time: 254.0911s\n",
      "\titers: 300, epoch: 6 | loss: 0.1255231\n",
      "\tspeed: 0.0296s/iter; left time: 253.9662s\n",
      "\titers: 400, epoch: 6 | loss: 0.1400504\n",
      "\tspeed: 0.0267s/iter; left time: 226.1287s\n",
      "\titers: 500, epoch: 6 | loss: 0.1743758\n",
      "\tspeed: 0.0264s/iter; left time: 221.5143s\n",
      "Epoch: 6 cost time: 16.51266384124756\n",
      "Epoch: 6, Steps: 592 | Train Loss: 0.1572295 Vali Loss: 0.1975159 Test Loss: 0.2251521\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1262736\n",
      "\tspeed: 0.0977s/iter; left time: 800.3501s\n",
      "\titers: 200, epoch: 7 | loss: 0.1326499\n",
      "\tspeed: 0.0303s/iter; left time: 244.9704s\n",
      "\titers: 300, epoch: 7 | loss: 0.1471531\n",
      "\tspeed: 0.0294s/iter; left time: 235.0294s\n",
      "\titers: 400, epoch: 7 | loss: 0.1648572\n",
      "\tspeed: 0.0298s/iter; left time: 234.8206s\n",
      "\titers: 500, epoch: 7 | loss: 0.0950081\n",
      "\tspeed: 0.0306s/iter; left time: 238.6952s\n",
      "Epoch: 7 cost time: 18.07413411140442\n",
      "Epoch: 7, Steps: 592 | Train Loss: 0.1551874 Vali Loss: 0.1971211 Test Loss: 0.2240408\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1553383\n",
      "\tspeed: 0.1024s/iter; left time: 778.1304s\n",
      "\titers: 200, epoch: 8 | loss: 0.1741714\n",
      "\tspeed: 0.0306s/iter; left time: 229.4473s\n",
      "\titers: 300, epoch: 8 | loss: 0.1252110\n",
      "\tspeed: 0.0298s/iter; left time: 220.1838s\n",
      "\titers: 400, epoch: 8 | loss: 0.1053148\n",
      "\tspeed: 0.0294s/iter; left time: 214.5343s\n",
      "\titers: 500, epoch: 8 | loss: 0.1216425\n",
      "\tspeed: 0.0294s/iter; left time: 211.5241s\n",
      "Epoch: 8 cost time: 17.626180410385132\n",
      "Epoch: 8, Steps: 592 | Train Loss: 0.1535109 Vali Loss: 0.1980218 Test Loss: 0.2240486\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "Test cost time: 2.2667s\n",
      "test shape: (187, 32, 6, 1) (187, 32, 6, 1)\n",
      "test shape: (5984, 6, 1) (5984, 6, 1)\n",
      "mse:0.2195141464471817, mae:0.31606653332710266\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1591.363037109375\n",
      "MAE:  26.9111270904541\n",
      "RMSE: 39.89189147949219\n",
      "MAPE: 0.3582351803779602\n",
      "MSPE: 0.6383991241455078\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20961\n",
      "[DEBUG] Original dataset length: 20961\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18956\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6700\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "\titers: 100, epoch: 1 | loss: 0.4621417\n",
      "\tspeed: 0.0281s/iter; left time: 329.7226s\n",
      "\titers: 200, epoch: 1 | loss: 0.3717895\n",
      "\tspeed: 0.0294s/iter; left time: 342.3665s\n",
      "\titers: 300, epoch: 1 | loss: 0.2593584\n",
      "\tspeed: 0.0291s/iter; left time: 335.7091s\n",
      "\titers: 400, epoch: 1 | loss: 0.2187037\n",
      "\tspeed: 0.0295s/iter; left time: 337.7975s\n",
      "\titers: 500, epoch: 1 | loss: 0.2471554\n",
      "\tspeed: 0.0314s/iter; left time: 356.4553s\n",
      "Epoch: 1 cost time: 17.479068279266357\n",
      "Epoch: 1, Steps: 592 | Train Loss: 0.2908870 Vali Loss: 0.2244863 Test Loss: 0.2698870\n",
      "Validation loss decreased (inf --> 0.224486).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1487555\n",
      "\tspeed: 0.1027s/iter; left time: 1144.8330s\n",
      "\titers: 200, epoch: 2 | loss: 0.3188164\n",
      "\tspeed: 0.0302s/iter; left time: 334.0432s\n",
      "\titers: 300, epoch: 2 | loss: 0.2520085\n",
      "\tspeed: 0.0312s/iter; left time: 341.8760s\n",
      "\titers: 400, epoch: 2 | loss: 0.1752121\n",
      "\tspeed: 0.0304s/iter; left time: 330.3155s\n",
      "\titers: 500, epoch: 2 | loss: 0.1713586\n",
      "\tspeed: 0.0298s/iter; left time: 320.2303s\n",
      "Epoch: 2 cost time: 18.15259552001953\n",
      "Epoch: 2, Steps: 592 | Train Loss: 0.2216854 Vali Loss: 0.2327067 Test Loss: 0.2909631\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2781643\n",
      "\tspeed: 0.1095s/iter; left time: 1156.2209s\n",
      "\titers: 200, epoch: 3 | loss: 0.1531901\n",
      "\tspeed: 0.0300s/iter; left time: 313.8492s\n",
      "\titers: 300, epoch: 3 | loss: 0.1356696\n",
      "\tspeed: 0.0306s/iter; left time: 317.4405s\n",
      "\titers: 400, epoch: 3 | loss: 0.1401984\n",
      "\tspeed: 0.0311s/iter; left time: 319.0669s\n",
      "\titers: 500, epoch: 3 | loss: 0.1662265\n",
      "\tspeed: 0.0324s/iter; left time: 329.1642s\n",
      "Epoch: 3 cost time: 18.559044361114502\n",
      "Epoch: 3, Steps: 592 | Train Loss: 0.1888570 Vali Loss: 0.1886377 Test Loss: 0.2299251\n",
      "Validation loss decreased (0.224486 --> 0.188638).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1240874\n",
      "\tspeed: 0.1065s/iter; left time: 1060.8016s\n",
      "\titers: 200, epoch: 4 | loss: 0.1126428\n",
      "\tspeed: 0.0342s/iter; left time: 337.3260s\n",
      "\titers: 300, epoch: 4 | loss: 0.1667119\n",
      "\tspeed: 0.0327s/iter; left time: 319.0210s\n",
      "\titers: 400, epoch: 4 | loss: 0.1558768\n",
      "\tspeed: 0.0311s/iter; left time: 300.6531s\n",
      "\titers: 500, epoch: 4 | loss: 0.1389109\n",
      "\tspeed: 0.0300s/iter; left time: 286.5599s\n",
      "Epoch: 4 cost time: 18.507481336593628\n",
      "Epoch: 4, Steps: 592 | Train Loss: 0.1736626 Vali Loss: 0.1937073 Test Loss: 0.2317824\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1324779\n",
      "\tspeed: 0.0986s/iter; left time: 924.5361s\n",
      "\titers: 200, epoch: 5 | loss: 0.1097068\n",
      "\tspeed: 0.0288s/iter; left time: 266.7044s\n",
      "\titers: 300, epoch: 5 | loss: 0.1172192\n",
      "\tspeed: 0.0298s/iter; left time: 273.5268s\n",
      "\titers: 400, epoch: 5 | loss: 0.1260280\n",
      "\tspeed: 0.0294s/iter; left time: 267.0270s\n",
      "\titers: 500, epoch: 5 | loss: 0.1545632\n",
      "\tspeed: 0.0313s/iter; left time: 281.0578s\n",
      "Epoch: 5 cost time: 17.66776967048645\n",
      "Epoch: 5, Steps: 592 | Train Loss: 0.1642326 Vali Loss: 0.1902878 Test Loss: 0.2293276\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1836567\n",
      "\tspeed: 0.0945s/iter; left time: 830.2244s\n",
      "\titers: 200, epoch: 6 | loss: 0.1450193\n",
      "\tspeed: 0.0279s/iter; left time: 241.9263s\n",
      "\titers: 300, epoch: 6 | loss: 0.1899729\n",
      "\tspeed: 0.0296s/iter; left time: 253.6812s\n",
      "\titers: 400, epoch: 6 | loss: 0.1193325\n",
      "\tspeed: 0.0270s/iter; left time: 228.7946s\n",
      "\titers: 500, epoch: 6 | loss: 0.1444357\n",
      "\tspeed: 0.0264s/iter; left time: 221.0917s\n",
      "Epoch: 6 cost time: 16.16206932067871\n",
      "Epoch: 6, Steps: 592 | Train Loss: 0.1592227 Vali Loss: 0.1897646 Test Loss: 0.2305957\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "Test cost time: 1.9112s\n",
      "test shape: (187, 32, 6, 1) (187, 32, 6, 1)\n",
      "test shape: (5984, 6, 1) (5984, 6, 1)\n",
      "mse:0.2298019826412201, mae:0.3211674392223358\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1665.9443359375\n",
      "MAE:  27.345434188842773\n",
      "RMSE: 40.815982818603516\n",
      "MAPE: 0.36034610867500305\n",
      "MSPE: 0.6718676090240479\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20961\n",
      "[DEBUG] Original dataset length: 20961\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18956\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6700\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "\titers: 100, epoch: 1 | loss: 0.3063715\n",
      "\tspeed: 0.0275s/iter; left time: 322.8842s\n",
      "\titers: 200, epoch: 1 | loss: 0.1593407\n",
      "\tspeed: 0.0272s/iter; left time: 316.4772s\n",
      "\titers: 300, epoch: 1 | loss: 0.1780153\n",
      "\tspeed: 0.0262s/iter; left time: 302.1226s\n",
      "\titers: 400, epoch: 1 | loss: 0.2175646\n",
      "\tspeed: 0.0282s/iter; left time: 322.1602s\n",
      "\titers: 500, epoch: 1 | loss: 0.1480632\n",
      "\tspeed: 0.0280s/iter; left time: 317.7957s\n",
      "Epoch: 1 cost time: 16.574313163757324\n",
      "Epoch: 1, Steps: 592 | Train Loss: 0.2989383 Vali Loss: 0.2111057 Test Loss: 0.2473380\n",
      "Validation loss decreased (inf --> 0.211106).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3204554\n",
      "\tspeed: 0.0984s/iter; left time: 1097.1048s\n",
      "\titers: 200, epoch: 2 | loss: 0.2878050\n",
      "\tspeed: 0.0290s/iter; left time: 320.8712s\n",
      "\titers: 300, epoch: 2 | loss: 0.2047937\n",
      "\tspeed: 0.0296s/iter; left time: 324.4980s\n",
      "\titers: 400, epoch: 2 | loss: 0.2053407\n",
      "\tspeed: 0.0289s/iter; left time: 313.9308s\n",
      "\titers: 500, epoch: 2 | loss: 0.1969427\n",
      "\tspeed: 0.0276s/iter; left time: 296.5014s\n",
      "Epoch: 2 cost time: 16.851664304733276\n",
      "Epoch: 2, Steps: 592 | Train Loss: 0.2177713 Vali Loss: 0.2256168 Test Loss: 0.2579217\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1459668\n",
      "\tspeed: 0.0916s/iter; left time: 966.7631s\n",
      "\titers: 200, epoch: 3 | loss: 0.1663654\n",
      "\tspeed: 0.0292s/iter; left time: 305.5430s\n",
      "\titers: 300, epoch: 3 | loss: 0.2402532\n",
      "\tspeed: 0.0280s/iter; left time: 289.7200s\n",
      "\titers: 400, epoch: 3 | loss: 0.2116757\n",
      "\tspeed: 0.0262s/iter; left time: 268.2418s\n",
      "\titers: 500, epoch: 3 | loss: 0.1519764\n",
      "\tspeed: 0.0271s/iter; left time: 275.5846s\n",
      "Epoch: 3 cost time: 16.28596830368042\n",
      "Epoch: 3, Steps: 592 | Train Loss: 0.1901405 Vali Loss: 0.1931958 Test Loss: 0.2282430\n",
      "Validation loss decreased (0.211106 --> 0.193196).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1912113\n",
      "\tspeed: 0.0951s/iter; left time: 947.7311s\n",
      "\titers: 200, epoch: 4 | loss: 0.1670125\n",
      "\tspeed: 0.0266s/iter; left time: 262.0361s\n",
      "\titers: 300, epoch: 4 | loss: 0.1749179\n",
      "\tspeed: 0.0263s/iter; left time: 256.7543s\n",
      "\titers: 400, epoch: 4 | loss: 0.1229189\n",
      "\tspeed: 0.0270s/iter; left time: 261.1807s\n",
      "\titers: 500, epoch: 4 | loss: 0.1789173\n",
      "\tspeed: 0.0285s/iter; left time: 272.2000s\n",
      "Epoch: 4 cost time: 16.051398754119873\n",
      "Epoch: 4, Steps: 592 | Train Loss: 0.1720725 Vali Loss: 0.1917373 Test Loss: 0.2273359\n",
      "Validation loss decreased (0.193196 --> 0.191737).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1510147\n",
      "\tspeed: 0.0970s/iter; left time: 909.0957s\n",
      "\titers: 200, epoch: 5 | loss: 0.1064340\n",
      "\tspeed: 0.0281s/iter; left time: 260.2566s\n",
      "\titers: 300, epoch: 5 | loss: 0.1668977\n",
      "\tspeed: 0.0298s/iter; left time: 273.3581s\n",
      "\titers: 400, epoch: 5 | loss: 0.1318187\n",
      "\tspeed: 0.0303s/iter; left time: 275.0734s\n",
      "\titers: 500, epoch: 5 | loss: 0.1171462\n",
      "\tspeed: 0.0293s/iter; left time: 262.6473s\n",
      "Epoch: 5 cost time: 17.2464120388031\n",
      "Epoch: 5, Steps: 592 | Train Loss: 0.1637089 Vali Loss: 0.1927066 Test Loss: 0.2275756\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1876665\n",
      "\tspeed: 0.0990s/iter; left time: 869.4915s\n",
      "\titers: 200, epoch: 6 | loss: 0.0929502\n",
      "\tspeed: 0.0297s/iter; left time: 257.5632s\n",
      "\titers: 300, epoch: 6 | loss: 0.1255231\n",
      "\tspeed: 0.0296s/iter; left time: 254.3326s\n",
      "\titers: 400, epoch: 6 | loss: 0.1182879\n",
      "\tspeed: 0.0283s/iter; left time: 240.2898s\n",
      "\titers: 500, epoch: 6 | loss: 0.2264810\n",
      "\tspeed: 0.0284s/iter; left time: 237.6723s\n",
      "Epoch: 6 cost time: 17.542010068893433\n",
      "Epoch: 6, Steps: 592 | Train Loss: 0.1582866 Vali Loss: 0.1941994 Test Loss: 0.2304811\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1806171\n",
      "\tspeed: 0.0976s/iter; left time: 799.5828s\n",
      "\titers: 200, epoch: 7 | loss: 0.1499223\n",
      "\tspeed: 0.0283s/iter; left time: 228.5917s\n",
      "\titers: 300, epoch: 7 | loss: 0.3249485\n",
      "\tspeed: 0.0297s/iter; left time: 237.1843s\n",
      "\titers: 400, epoch: 7 | loss: 0.1104320\n",
      "\tspeed: 0.0307s/iter; left time: 242.3339s\n",
      "\titers: 500, epoch: 7 | loss: 0.1481507\n",
      "\tspeed: 0.0295s/iter; left time: 229.7393s\n",
      "Epoch: 7 cost time: 17.407000064849854\n",
      "Epoch: 7, Steps: 592 | Train Loss: 0.1553314 Vali Loss: 0.1924421 Test Loss: 0.2282887\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "Test cost time: 2.0126s\n",
      "test shape: (187, 32, 6, 1) (187, 32, 6, 1)\n",
      "test shape: (5984, 6, 1) (5984, 6, 1)\n",
      "mse:0.2266896665096283, mae:0.3202228248119354\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1643.3817138671875\n",
      "MAE:  27.265010833740234\n",
      "RMSE: 40.53864288330078\n",
      "MAPE: 0.3604574203491211\n",
      "MSPE: 0.6083629727363586\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20961\n",
      "[DEBUG] Original dataset length: 20961\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18956\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6700\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "\titers: 100, epoch: 1 | loss: 0.2331668\n",
      "\tspeed: 0.0295s/iter; left time: 346.7327s\n",
      "\titers: 200, epoch: 1 | loss: 0.4037619\n",
      "\tspeed: 0.0287s/iter; left time: 333.5610s\n",
      "\titers: 300, epoch: 1 | loss: 0.3899843\n",
      "\tspeed: 0.0285s/iter; left time: 329.1457s\n",
      "\titers: 400, epoch: 1 | loss: 0.3058806\n",
      "\tspeed: 0.0292s/iter; left time: 333.6589s\n",
      "\titers: 500, epoch: 1 | loss: 0.1796832\n",
      "\tspeed: 0.0301s/iter; left time: 341.8350s\n",
      "Epoch: 1 cost time: 17.44330930709839\n",
      "Epoch: 1, Steps: 592 | Train Loss: 0.2995801 Vali Loss: 0.2216172 Test Loss: 0.2755336\n",
      "Validation loss decreased (inf --> 0.221617).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2049869\n",
      "\tspeed: 0.0966s/iter; left time: 1077.4174s\n",
      "\titers: 200, epoch: 2 | loss: 0.2057414\n",
      "\tspeed: 0.0278s/iter; left time: 307.5414s\n",
      "\titers: 300, epoch: 2 | loss: 0.1857128\n",
      "\tspeed: 0.0293s/iter; left time: 321.2749s\n",
      "\titers: 400, epoch: 2 | loss: 0.2461128\n",
      "\tspeed: 0.0297s/iter; left time: 322.1553s\n",
      "\titers: 500, epoch: 2 | loss: 0.2879189\n",
      "\tspeed: 0.0282s/iter; left time: 303.0696s\n",
      "Epoch: 2 cost time: 16.7217059135437\n",
      "Epoch: 2, Steps: 592 | Train Loss: 0.2215255 Vali Loss: 0.2006789 Test Loss: 0.2412274\n",
      "Validation loss decreased (0.221617 --> 0.200679).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2589076\n",
      "\tspeed: 0.0965s/iter; left time: 1019.0303s\n",
      "\titers: 200, epoch: 3 | loss: 0.1938615\n",
      "\tspeed: 0.0281s/iter; left time: 294.0725s\n",
      "\titers: 300, epoch: 3 | loss: 0.1856961\n",
      "\tspeed: 0.0287s/iter; left time: 297.1821s\n",
      "\titers: 400, epoch: 3 | loss: 0.2343033\n",
      "\tspeed: 0.0273s/iter; left time: 280.3165s\n",
      "\titers: 500, epoch: 3 | loss: 0.1468695\n",
      "\tspeed: 0.0279s/iter; left time: 283.1920s\n",
      "Epoch: 3 cost time: 16.646615743637085\n",
      "Epoch: 3, Steps: 592 | Train Loss: 0.1910938 Vali Loss: 0.2031437 Test Loss: 0.2529633\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1560369\n",
      "\tspeed: 0.0998s/iter; left time: 994.6339s\n",
      "\titers: 200, epoch: 4 | loss: 0.1167065\n",
      "\tspeed: 0.0278s/iter; left time: 274.6005s\n",
      "\titers: 300, epoch: 4 | loss: 0.1743225\n",
      "\tspeed: 0.0282s/iter; left time: 275.2573s\n",
      "\titers: 400, epoch: 4 | loss: 0.1325525\n",
      "\tspeed: 0.0283s/iter; left time: 273.6854s\n",
      "\titers: 500, epoch: 4 | loss: 0.1545199\n",
      "\tspeed: 0.0285s/iter; left time: 272.6767s\n",
      "Epoch: 4 cost time: 16.78995966911316\n",
      "Epoch: 4, Steps: 592 | Train Loss: 0.1754067 Vali Loss: 0.1940007 Test Loss: 0.2284283\n",
      "Validation loss decreased (0.200679 --> 0.194001).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2379493\n",
      "\tspeed: 0.0984s/iter; left time: 922.7199s\n",
      "\titers: 200, epoch: 5 | loss: 0.0968789\n",
      "\tspeed: 0.0295s/iter; left time: 273.6693s\n",
      "\titers: 300, epoch: 5 | loss: 0.2290485\n",
      "\tspeed: 0.0300s/iter; left time: 275.4056s\n",
      "\titers: 400, epoch: 5 | loss: 0.3120151\n",
      "\tspeed: 0.0291s/iter; left time: 264.3058s\n",
      "\titers: 500, epoch: 5 | loss: 0.1804622\n",
      "\tspeed: 0.0286s/iter; left time: 256.3956s\n",
      "Epoch: 5 cost time: 17.357230186462402\n",
      "Epoch: 5, Steps: 592 | Train Loss: 0.1675231 Vali Loss: 0.1955003 Test Loss: 0.2275000\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1346783\n",
      "\tspeed: 0.0987s/iter; left time: 867.1235s\n",
      "\titers: 200, epoch: 6 | loss: 0.1719681\n",
      "\tspeed: 0.0293s/iter; left time: 254.2831s\n",
      "\titers: 300, epoch: 6 | loss: 0.1671810\n",
      "\tspeed: 0.0289s/iter; left time: 247.8238s\n",
      "\titers: 400, epoch: 6 | loss: 0.1406616\n",
      "\tspeed: 0.0288s/iter; left time: 244.4390s\n",
      "\titers: 500, epoch: 6 | loss: 0.1132096\n",
      "\tspeed: 0.0304s/iter; left time: 254.6500s\n",
      "Epoch: 6 cost time: 17.364205360412598\n",
      "Epoch: 6, Steps: 592 | Train Loss: 0.1606633 Vali Loss: 0.1936952 Test Loss: 0.2265858\n",
      "Validation loss decreased (0.194001 --> 0.193695).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1048103\n",
      "\tspeed: 0.1000s/iter; left time: 818.8970s\n",
      "\titers: 200, epoch: 7 | loss: 0.1318160\n",
      "\tspeed: 0.0285s/iter; left time: 230.3568s\n",
      "\titers: 300, epoch: 7 | loss: 0.2266356\n",
      "\tspeed: 0.0308s/iter; left time: 246.3916s\n",
      "\titers: 400, epoch: 7 | loss: 0.2872297\n",
      "\tspeed: 0.0293s/iter; left time: 231.5288s\n",
      "\titers: 500, epoch: 7 | loss: 0.1398599\n",
      "\tspeed: 0.0276s/iter; left time: 214.9194s\n",
      "Epoch: 7 cost time: 17.150710105895996\n",
      "Epoch: 7, Steps: 592 | Train Loss: 0.1586117 Vali Loss: 0.1932750 Test Loss: 0.2260175\n",
      "Validation loss decreased (0.193695 --> 0.193275).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1332480\n",
      "\tspeed: 0.0977s/iter; left time: 742.0361s\n",
      "\titers: 200, epoch: 8 | loss: 0.1845760\n",
      "\tspeed: 0.0280s/iter; left time: 210.0260s\n",
      "\titers: 300, epoch: 8 | loss: 0.2237717\n",
      "\tspeed: 0.0270s/iter; left time: 199.8642s\n",
      "\titers: 400, epoch: 8 | loss: 0.1060886\n",
      "\tspeed: 0.0266s/iter; left time: 194.2408s\n",
      "\titers: 500, epoch: 8 | loss: 0.1241978\n",
      "\tspeed: 0.0272s/iter; left time: 195.8129s\n",
      "Epoch: 8 cost time: 16.57081627845764\n",
      "Epoch: 8, Steps: 592 | Train Loss: 0.1568529 Vali Loss: 0.1962776 Test Loss: 0.2297318\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1635542\n",
      "\tspeed: 0.0947s/iter; left time: 663.4369s\n",
      "\titers: 200, epoch: 9 | loss: 0.1160507\n",
      "\tspeed: 0.0274s/iter; left time: 189.3355s\n",
      "\titers: 300, epoch: 9 | loss: 0.1580798\n",
      "\tspeed: 0.0273s/iter; left time: 185.8293s\n",
      "\titers: 400, epoch: 9 | loss: 0.1221973\n",
      "\tspeed: 0.0288s/iter; left time: 193.1550s\n",
      "\titers: 500, epoch: 9 | loss: 0.1158678\n",
      "\tspeed: 0.0284s/iter; left time: 187.3831s\n",
      "Epoch: 9 cost time: 16.483675479888916\n",
      "Epoch: 9, Steps: 592 | Train Loss: 0.1558291 Vali Loss: 0.1958445 Test Loss: 0.2279607\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.1351584\n",
      "\tspeed: 0.0919s/iter; left time: 589.1058s\n",
      "\titers: 200, epoch: 10 | loss: 0.1682502\n",
      "\tspeed: 0.0302s/iter; left time: 190.6669s\n",
      "\titers: 300, epoch: 10 | loss: 0.1359048\n",
      "\tspeed: 0.0280s/iter; left time: 173.6948s\n",
      "\titers: 400, epoch: 10 | loss: 0.1151599\n",
      "\tspeed: 0.0271s/iter; left time: 165.8104s\n",
      "\titers: 500, epoch: 10 | loss: 0.1383769\n",
      "\tspeed: 0.0279s/iter; left time: 167.5825s\n",
      "Epoch: 10 cost time: 16.569640636444092\n",
      "Epoch: 10, Steps: 592 | Train Loss: 0.1553643 Vali Loss: 0.1951661 Test Loss: 0.2267630\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "Test cost time: 1.8503s\n",
      "test shape: (187, 32, 6, 1) (187, 32, 6, 1)\n",
      "test shape: (5984, 6, 1) (5984, 6, 1)\n",
      "mse:0.2244727462530136, mae:0.317043274641037\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1627.3104248046875\n",
      "MAE:  26.99428939819336\n",
      "RMSE: 40.339935302734375\n",
      "MAPE: 0.3447975218296051\n",
      "MSPE: 0.5429714918136597\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20961\n",
      "[DEBUG] Original dataset length: 20961\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18956\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6700\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "\titers: 100, epoch: 1 | loss: 0.3148577\n",
      "\tspeed: 0.0267s/iter; left time: 313.9681s\n",
      "\titers: 200, epoch: 1 | loss: 0.1808625\n",
      "\tspeed: 0.0272s/iter; left time: 316.1085s\n",
      "\titers: 300, epoch: 1 | loss: 0.2578688\n",
      "\tspeed: 0.0283s/iter; left time: 326.9826s\n",
      "\titers: 400, epoch: 1 | loss: 0.2179824\n",
      "\tspeed: 0.0287s/iter; left time: 328.7783s\n",
      "\titers: 500, epoch: 1 | loss: 0.4565210\n",
      "\tspeed: 0.0294s/iter; left time: 333.4752s\n",
      "Epoch: 1 cost time: 16.664727210998535\n",
      "Epoch: 1, Steps: 592 | Train Loss: 0.2957981 Vali Loss: 0.2116344 Test Loss: 0.2630664\n",
      "Validation loss decreased (inf --> 0.211634).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2042048\n",
      "\tspeed: 0.0947s/iter; left time: 1055.4133s\n",
      "\titers: 200, epoch: 2 | loss: 0.2108366\n",
      "\tspeed: 0.0280s/iter; left time: 309.3322s\n",
      "\titers: 300, epoch: 2 | loss: 0.2069845\n",
      "\tspeed: 0.0306s/iter; left time: 335.4617s\n",
      "\titers: 400, epoch: 2 | loss: 0.2067316\n",
      "\tspeed: 0.0285s/iter; left time: 308.8998s\n",
      "\titers: 500, epoch: 2 | loss: 0.1901363\n",
      "\tspeed: 0.0263s/iter; left time: 282.2410s\n",
      "Epoch: 2 cost time: 16.574300527572632\n",
      "Epoch: 2, Steps: 592 | Train Loss: 0.2180882 Vali Loss: 0.1977536 Test Loss: 0.2357784\n",
      "Validation loss decreased (0.211634 --> 0.197754).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2511100\n",
      "\tspeed: 0.0970s/iter; left time: 1023.6524s\n",
      "\titers: 200, epoch: 3 | loss: 0.2005901\n",
      "\tspeed: 0.0297s/iter; left time: 310.7580s\n",
      "\titers: 300, epoch: 3 | loss: 0.1609111\n",
      "\tspeed: 0.0287s/iter; left time: 297.2688s\n",
      "\titers: 400, epoch: 3 | loss: 0.2033975\n",
      "\tspeed: 0.0311s/iter; left time: 319.1247s\n",
      "\titers: 500, epoch: 3 | loss: 0.2050257\n",
      "\tspeed: 0.0287s/iter; left time: 291.0539s\n",
      "Epoch: 3 cost time: 17.636796951293945\n",
      "Epoch: 3, Steps: 592 | Train Loss: 0.1875697 Vali Loss: 0.2069085 Test Loss: 0.2500468\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1799109\n",
      "\tspeed: 0.0986s/iter; left time: 982.3825s\n",
      "\titers: 200, epoch: 4 | loss: 0.1357821\n",
      "\tspeed: 0.0284s/iter; left time: 280.1218s\n",
      "\titers: 300, epoch: 4 | loss: 0.2274137\n",
      "\tspeed: 0.0291s/iter; left time: 284.2044s\n",
      "\titers: 400, epoch: 4 | loss: 0.1369306\n",
      "\tspeed: 0.0299s/iter; left time: 289.3451s\n",
      "\titers: 500, epoch: 4 | loss: 0.1718486\n",
      "\tspeed: 0.0283s/iter; left time: 270.7768s\n",
      "Epoch: 4 cost time: 16.98238778114319\n",
      "Epoch: 4, Steps: 592 | Train Loss: 0.1723316 Vali Loss: 0.1927348 Test Loss: 0.2352335\n",
      "Validation loss decreased (0.197754 --> 0.192735).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1833320\n",
      "\tspeed: 0.1000s/iter; left time: 937.0888s\n",
      "\titers: 200, epoch: 5 | loss: 0.1202101\n",
      "\tspeed: 0.0300s/iter; left time: 277.7448s\n",
      "\titers: 300, epoch: 5 | loss: 0.2168892\n",
      "\tspeed: 0.0289s/iter; left time: 264.6976s\n",
      "\titers: 400, epoch: 5 | loss: 0.1349365\n",
      "\tspeed: 0.0287s/iter; left time: 260.4077s\n",
      "\titers: 500, epoch: 5 | loss: 0.1539100\n",
      "\tspeed: 0.0284s/iter; left time: 255.0120s\n",
      "Epoch: 5 cost time: 17.35588026046753\n",
      "Epoch: 5, Steps: 592 | Train Loss: 0.1630385 Vali Loss: 0.1885043 Test Loss: 0.2311023\n",
      "Validation loss decreased (0.192735 --> 0.188504).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1643755\n",
      "\tspeed: 0.1006s/iter; left time: 883.7075s\n",
      "\titers: 200, epoch: 6 | loss: 0.1467603\n",
      "\tspeed: 0.0289s/iter; left time: 250.7212s\n",
      "\titers: 300, epoch: 6 | loss: 0.1783451\n",
      "\tspeed: 0.0284s/iter; left time: 244.0017s\n",
      "\titers: 400, epoch: 6 | loss: 0.2007683\n",
      "\tspeed: 0.0310s/iter; left time: 263.0955s\n",
      "\titers: 500, epoch: 6 | loss: 0.1595061\n",
      "\tspeed: 0.0289s/iter; left time: 241.9556s\n",
      "Epoch: 6 cost time: 17.308268785476685\n",
      "Epoch: 6, Steps: 592 | Train Loss: 0.1577919 Vali Loss: 0.1891025 Test Loss: 0.2315713\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1109152\n",
      "\tspeed: 0.0967s/iter; left time: 792.0336s\n",
      "\titers: 200, epoch: 7 | loss: 0.1944379\n",
      "\tspeed: 0.0293s/iter; left time: 236.7390s\n",
      "\titers: 300, epoch: 7 | loss: 0.1619836\n",
      "\tspeed: 0.0294s/iter; left time: 235.1487s\n",
      "\titers: 400, epoch: 7 | loss: 0.1124045\n",
      "\tspeed: 0.0286s/iter; left time: 225.8887s\n",
      "\titers: 500, epoch: 7 | loss: 0.1284706\n",
      "\tspeed: 0.0283s/iter; left time: 220.1471s\n",
      "Epoch: 7 cost time: 17.323317050933838\n",
      "Epoch: 7, Steps: 592 | Train Loss: 0.1541372 Vali Loss: 0.1887964 Test Loss: 0.2311672\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1375639\n",
      "\tspeed: 0.1051s/iter; left time: 798.3751s\n",
      "\titers: 200, epoch: 8 | loss: 0.1236002\n",
      "\tspeed: 0.0299s/iter; left time: 224.3667s\n",
      "\titers: 300, epoch: 8 | loss: 0.2448456\n",
      "\tspeed: 0.0319s/iter; left time: 235.8182s\n",
      "\titers: 400, epoch: 8 | loss: 0.1656158\n",
      "\tspeed: 0.0321s/iter; left time: 234.2609s\n",
      "\titers: 500, epoch: 8 | loss: 0.1304734\n",
      "\tspeed: 0.0324s/iter; left time: 233.5359s\n",
      "Epoch: 8 cost time: 18.637775897979736\n",
      "Epoch: 8, Steps: 592 | Train Loss: 0.1530797 Vali Loss: 0.1892743 Test Loss: 0.2319787\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "Test cost time: 2.1793s\n",
      "test shape: (187, 32, 6, 1) (187, 32, 6, 1)\n",
      "test shape: (5984, 6, 1) (5984, 6, 1)\n",
      "mse:0.23041951656341553, mae:0.3207806944847107\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1670.4212646484375\n",
      "MAE:  27.312509536743164\n",
      "RMSE: 40.87078857421875\n",
      "MAPE: 0.36249595880508423\n",
      "MSPE: 0.6350535154342651\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20961\n",
      "[DEBUG] Original dataset length: 20961\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18956\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6700\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "\titers: 100, epoch: 1 | loss: 0.2184901\n",
      "\tspeed: 0.0357s/iter; left time: 419.0396s\n",
      "\titers: 200, epoch: 1 | loss: 0.2114592\n",
      "\tspeed: 0.0325s/iter; left time: 378.6523s\n",
      "\titers: 300, epoch: 1 | loss: 0.1659581\n",
      "\tspeed: 0.0325s/iter; left time: 374.5574s\n",
      "\titers: 400, epoch: 1 | loss: 0.3403429\n",
      "\tspeed: 0.0326s/iter; left time: 373.3426s\n",
      "\titers: 500, epoch: 1 | loss: 0.1988073\n",
      "\tspeed: 0.0325s/iter; left time: 368.5194s\n",
      "Epoch: 1 cost time: 19.475411415100098\n",
      "Epoch: 1, Steps: 592 | Train Loss: 0.2877984 Vali Loss: 0.2309532 Test Loss: 0.2636818\n",
      "Validation loss decreased (inf --> 0.230953).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1596064\n",
      "\tspeed: 0.1004s/iter; left time: 1118.9538s\n",
      "\titers: 200, epoch: 2 | loss: 0.1763883\n",
      "\tspeed: 0.0291s/iter; left time: 321.2198s\n",
      "\titers: 300, epoch: 2 | loss: 0.2349859\n",
      "\tspeed: 0.0300s/iter; left time: 328.5759s\n",
      "\titers: 400, epoch: 2 | loss: 0.4386284\n",
      "\tspeed: 0.0298s/iter; left time: 323.3404s\n",
      "\titers: 500, epoch: 2 | loss: 0.2258343\n",
      "\tspeed: 0.0308s/iter; left time: 330.6213s\n",
      "Epoch: 2 cost time: 17.78747582435608\n",
      "Epoch: 2, Steps: 592 | Train Loss: 0.2183723 Vali Loss: 0.2063953 Test Loss: 0.2476888\n",
      "Validation loss decreased (0.230953 --> 0.206395).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2205457\n",
      "\tspeed: 0.0999s/iter; left time: 1054.8164s\n",
      "\titers: 200, epoch: 3 | loss: 0.2820465\n",
      "\tspeed: 0.0274s/iter; left time: 286.1523s\n",
      "\titers: 300, epoch: 3 | loss: 0.1443763\n",
      "\tspeed: 0.0265s/iter; left time: 274.6079s\n",
      "\titers: 400, epoch: 3 | loss: 0.2074962\n",
      "\tspeed: 0.0278s/iter; left time: 284.8477s\n",
      "\titers: 500, epoch: 3 | loss: 0.2974575\n",
      "\tspeed: 0.0264s/iter; left time: 268.2836s\n",
      "Epoch: 3 cost time: 16.492676496505737\n",
      "Epoch: 3, Steps: 592 | Train Loss: 0.1896892 Vali Loss: 0.2015417 Test Loss: 0.2481305\n",
      "Validation loss decreased (0.206395 --> 0.201542).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1350602\n",
      "\tspeed: 0.0980s/iter; left time: 976.2686s\n",
      "\titers: 200, epoch: 4 | loss: 0.1957225\n",
      "\tspeed: 0.0297s/iter; left time: 292.8988s\n",
      "\titers: 300, epoch: 4 | loss: 0.1756176\n",
      "\tspeed: 0.0279s/iter; left time: 272.7709s\n",
      "\titers: 400, epoch: 4 | loss: 0.1580733\n",
      "\tspeed: 0.0296s/iter; left time: 285.8521s\n",
      "\titers: 500, epoch: 4 | loss: 0.2548300\n",
      "\tspeed: 0.0283s/iter; left time: 271.0131s\n",
      "Epoch: 4 cost time: 17.000658750534058\n",
      "Epoch: 4, Steps: 592 | Train Loss: 0.1751506 Vali Loss: 0.1951236 Test Loss: 0.2323574\n",
      "Validation loss decreased (0.201542 --> 0.195124).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1157435\n",
      "\tspeed: 0.0934s/iter; left time: 875.0926s\n",
      "\titers: 200, epoch: 5 | loss: 0.1738355\n",
      "\tspeed: 0.0286s/iter; left time: 264.9966s\n",
      "\titers: 300, epoch: 5 | loss: 0.1980624\n",
      "\tspeed: 0.0284s/iter; left time: 260.3996s\n",
      "\titers: 400, epoch: 5 | loss: 0.1019960\n",
      "\tspeed: 0.0287s/iter; left time: 260.6325s\n",
      "\titers: 500, epoch: 5 | loss: 0.1748508\n",
      "\tspeed: 0.0277s/iter; left time: 248.3964s\n",
      "Epoch: 5 cost time: 16.66689705848694\n",
      "Epoch: 5, Steps: 592 | Train Loss: 0.1656746 Vali Loss: 0.1946956 Test Loss: 0.2359520\n",
      "Validation loss decreased (0.195124 --> 0.194696).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2028401\n",
      "\tspeed: 0.0963s/iter; left time: 845.6744s\n",
      "\titers: 200, epoch: 6 | loss: 0.1310862\n",
      "\tspeed: 0.0287s/iter; left time: 249.4143s\n",
      "\titers: 300, epoch: 6 | loss: 0.1976215\n",
      "\tspeed: 0.0299s/iter; left time: 256.7542s\n",
      "\titers: 400, epoch: 6 | loss: 0.2619258\n",
      "\tspeed: 0.0286s/iter; left time: 242.7141s\n",
      "\titers: 500, epoch: 6 | loss: 0.1062744\n",
      "\tspeed: 0.0312s/iter; left time: 261.2459s\n",
      "Epoch: 6 cost time: 17.53480625152588\n",
      "Epoch: 6, Steps: 592 | Train Loss: 0.1602720 Vali Loss: 0.1916305 Test Loss: 0.2346780\n",
      "Validation loss decreased (0.194696 --> 0.191630).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2101782\n",
      "\tspeed: 0.0993s/iter; left time: 813.0882s\n",
      "\titers: 200, epoch: 7 | loss: 0.1276570\n",
      "\tspeed: 0.0304s/iter; left time: 246.2571s\n",
      "\titers: 300, epoch: 7 | loss: 0.1512832\n",
      "\tspeed: 0.0307s/iter; left time: 245.0195s\n",
      "\titers: 400, epoch: 7 | loss: 0.1167331\n",
      "\tspeed: 0.0296s/iter; left time: 233.2554s\n",
      "\titers: 500, epoch: 7 | loss: 0.1228026\n",
      "\tspeed: 0.0292s/iter; left time: 227.4509s\n",
      "Epoch: 7 cost time: 17.632551431655884\n",
      "Epoch: 7, Steps: 592 | Train Loss: 0.1577147 Vali Loss: 0.1924306 Test Loss: 0.2337408\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1193651\n",
      "\tspeed: 0.0962s/iter; left time: 730.7719s\n",
      "\titers: 200, epoch: 8 | loss: 0.1370531\n",
      "\tspeed: 0.0291s/iter; left time: 218.4985s\n",
      "\titers: 300, epoch: 8 | loss: 0.1283507\n",
      "\tspeed: 0.0276s/iter; left time: 204.2024s\n",
      "\titers: 400, epoch: 8 | loss: 0.1290611\n",
      "\tspeed: 0.0271s/iter; left time: 197.7177s\n",
      "\titers: 500, epoch: 8 | loss: 0.1173550\n",
      "\tspeed: 0.0267s/iter; left time: 192.3673s\n",
      "Epoch: 8 cost time: 16.59914803504944\n",
      "Epoch: 8, Steps: 592 | Train Loss: 0.1558369 Vali Loss: 0.1958970 Test Loss: 0.2351581\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1666804\n",
      "\tspeed: 0.0910s/iter; left time: 637.4889s\n",
      "\titers: 200, epoch: 9 | loss: 0.1126203\n",
      "\tspeed: 0.0260s/iter; left time: 179.7067s\n",
      "\titers: 300, epoch: 9 | loss: 0.1733928\n",
      "\tspeed: 0.0272s/iter; left time: 185.2288s\n",
      "\titers: 400, epoch: 9 | loss: 0.1116145\n",
      "\tspeed: 0.0289s/iter; left time: 193.5741s\n",
      "\titers: 500, epoch: 9 | loss: 0.2215780\n",
      "\tspeed: 0.0276s/iter; left time: 182.3402s\n",
      "Epoch: 9 cost time: 16.12105894088745\n",
      "Epoch: 9, Steps: 592 | Train Loss: 0.1548678 Vali Loss: 0.1930152 Test Loss: 0.2326368\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "Test cost time: 1.8246s\n",
      "test shape: (187, 32, 6, 1) (187, 32, 6, 1)\n",
      "test shape: (5984, 6, 1) (5984, 6, 1)\n",
      "mse:0.23499158024787903, mae:0.3251756727695465\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1703.56640625\n",
      "MAE:  27.686716079711914\n",
      "RMSE: 41.27428436279297\n",
      "MAPE: 0.35380586981773376\n",
      "MSPE: 0.5844792127609253\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20961\n",
      "[DEBUG] Original dataset length: 20961\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18956\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6700\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "\titers: 100, epoch: 1 | loss: 0.3651634\n",
      "\tspeed: 0.0249s/iter; left time: 292.3046s\n",
      "\titers: 200, epoch: 1 | loss: 0.6552979\n",
      "\tspeed: 0.0271s/iter; left time: 315.3337s\n",
      "\titers: 300, epoch: 1 | loss: 0.3558227\n",
      "\tspeed: 0.0267s/iter; left time: 308.2134s\n",
      "\titers: 400, epoch: 1 | loss: 0.1890603\n",
      "\tspeed: 0.0264s/iter; left time: 302.5101s\n",
      "\titers: 500, epoch: 1 | loss: 0.2423051\n",
      "\tspeed: 0.0264s/iter; left time: 299.1060s\n",
      "Epoch: 1 cost time: 15.568864583969116\n",
      "Epoch: 1, Steps: 592 | Train Loss: 0.2961894 Vali Loss: 0.2281773 Test Loss: 0.2660153\n",
      "Validation loss decreased (inf --> 0.228177).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2492800\n",
      "\tspeed: 0.0927s/iter; left time: 1033.6506s\n",
      "\titers: 200, epoch: 2 | loss: 0.2369668\n",
      "\tspeed: 0.0261s/iter; left time: 288.2702s\n",
      "\titers: 300, epoch: 2 | loss: 0.2094945\n",
      "\tspeed: 0.0266s/iter; left time: 290.7909s\n",
      "\titers: 400, epoch: 2 | loss: 0.1260615\n",
      "\tspeed: 0.0264s/iter; left time: 286.4902s\n",
      "\titers: 500, epoch: 2 | loss: 0.2534419\n",
      "\tspeed: 0.0275s/iter; left time: 295.7129s\n",
      "Epoch: 2 cost time: 16.011242866516113\n",
      "Epoch: 2, Steps: 592 | Train Loss: 0.2203712 Vali Loss: 0.1998288 Test Loss: 0.2388001\n",
      "Validation loss decreased (0.228177 --> 0.199829).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1675789\n",
      "\tspeed: 0.0910s/iter; left time: 960.7738s\n",
      "\titers: 200, epoch: 3 | loss: 0.2058241\n",
      "\tspeed: 0.0276s/iter; left time: 288.4239s\n",
      "\titers: 300, epoch: 3 | loss: 0.1715127\n",
      "\tspeed: 0.0281s/iter; left time: 290.7850s\n",
      "\titers: 400, epoch: 3 | loss: 0.2074743\n",
      "\tspeed: 0.0296s/iter; left time: 303.2445s\n",
      "\titers: 500, epoch: 3 | loss: 0.2270809\n",
      "\tspeed: 0.0275s/iter; left time: 279.5291s\n",
      "Epoch: 3 cost time: 16.357583045959473\n",
      "Epoch: 3, Steps: 592 | Train Loss: 0.1870336 Vali Loss: 0.1980224 Test Loss: 0.2371545\n",
      "Validation loss decreased (0.199829 --> 0.198022).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1270451\n",
      "\tspeed: 0.0899s/iter; left time: 895.6452s\n",
      "\titers: 200, epoch: 4 | loss: 0.1797897\n",
      "\tspeed: 0.0287s/iter; left time: 282.9625s\n",
      "\titers: 300, epoch: 4 | loss: 0.1257192\n",
      "\tspeed: 0.0260s/iter; left time: 254.1470s\n",
      "\titers: 400, epoch: 4 | loss: 0.1967861\n",
      "\tspeed: 0.0272s/iter; left time: 262.9027s\n",
      "\titers: 500, epoch: 4 | loss: 0.1893763\n",
      "\tspeed: 0.0261s/iter; left time: 249.8905s\n",
      "Epoch: 4 cost time: 15.905215978622437\n",
      "Epoch: 4, Steps: 592 | Train Loss: 0.1722155 Vali Loss: 0.1922523 Test Loss: 0.2262144\n",
      "Validation loss decreased (0.198022 --> 0.192252).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1579274\n",
      "\tspeed: 0.0924s/iter; left time: 866.1833s\n",
      "\titers: 200, epoch: 5 | loss: 0.1041691\n",
      "\tspeed: 0.0266s/iter; left time: 246.5621s\n",
      "\titers: 300, epoch: 5 | loss: 0.2034529\n",
      "\tspeed: 0.0262s/iter; left time: 240.4324s\n",
      "\titers: 400, epoch: 5 | loss: 0.1213070\n",
      "\tspeed: 0.0261s/iter; left time: 236.7404s\n",
      "\titers: 500, epoch: 5 | loss: 0.1115005\n",
      "\tspeed: 0.0256s/iter; left time: 229.6807s\n",
      "Epoch: 5 cost time: 15.628498554229736\n",
      "Epoch: 5, Steps: 592 | Train Loss: 0.1628889 Vali Loss: 0.1895834 Test Loss: 0.2281625\n",
      "Validation loss decreased (0.192252 --> 0.189583).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1923417\n",
      "\tspeed: 0.0931s/iter; left time: 817.1612s\n",
      "\titers: 200, epoch: 6 | loss: 0.1827998\n",
      "\tspeed: 0.0275s/iter; left time: 238.5395s\n",
      "\titers: 300, epoch: 6 | loss: 0.1342085\n",
      "\tspeed: 0.0281s/iter; left time: 240.8406s\n",
      "\titers: 400, epoch: 6 | loss: 0.1420427\n",
      "\tspeed: 0.0292s/iter; left time: 247.2397s\n",
      "\titers: 500, epoch: 6 | loss: 0.2093974\n",
      "\tspeed: 0.0272s/iter; left time: 228.1294s\n",
      "Epoch: 6 cost time: 16.50401544570923\n",
      "Epoch: 6, Steps: 592 | Train Loss: 0.1571160 Vali Loss: 0.1916993 Test Loss: 0.2278649\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1604717\n",
      "\tspeed: 0.0909s/iter; left time: 744.0348s\n",
      "\titers: 200, epoch: 7 | loss: 0.1518105\n",
      "\tspeed: 0.0280s/iter; left time: 226.4118s\n",
      "\titers: 300, epoch: 7 | loss: 0.1213840\n",
      "\tspeed: 0.0271s/iter; left time: 216.1246s\n",
      "\titers: 400, epoch: 7 | loss: 0.1771902\n",
      "\tspeed: 0.0277s/iter; left time: 218.8301s\n",
      "\titers: 500, epoch: 7 | loss: 0.1458998\n",
      "\tspeed: 0.0292s/iter; left time: 227.1137s\n",
      "Epoch: 7 cost time: 16.443837642669678\n",
      "Epoch: 7, Steps: 592 | Train Loss: 0.1539852 Vali Loss: 0.1902774 Test Loss: 0.2302446\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2419925\n",
      "\tspeed: 0.0962s/iter; left time: 731.1073s\n",
      "\titers: 200, epoch: 8 | loss: 0.1227394\n",
      "\tspeed: 0.0293s/iter; left time: 219.6311s\n",
      "\titers: 300, epoch: 8 | loss: 0.1201147\n",
      "\tspeed: 0.0290s/iter; left time: 214.2921s\n",
      "\titers: 400, epoch: 8 | loss: 0.1308628\n",
      "\tspeed: 0.0297s/iter; left time: 216.7201s\n",
      "\titers: 500, epoch: 8 | loss: 0.1095460\n",
      "\tspeed: 0.0314s/iter; left time: 225.7955s\n",
      "Epoch: 8 cost time: 17.59205412864685\n",
      "Epoch: 8, Steps: 592 | Train Loss: 0.1522294 Vali Loss: 0.1898455 Test Loss: 0.2278688\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "Test cost time: 1.8315s\n",
      "test shape: (187, 32, 6, 1) (187, 32, 6, 1)\n",
      "test shape: (5984, 6, 1) (5984, 6, 1)\n",
      "mse:0.22612185776233673, mae:0.3258916735649109\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1639.265380859375\n",
      "MAE:  27.747676849365234\n",
      "RMSE: 40.48784255981445\n",
      "MAPE: 0.3947363495826721\n",
      "MSPE: 0.7826678156852722\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20961\n",
      "[DEBUG] Original dataset length: 20961\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18956\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6700\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "\titers: 100, epoch: 1 | loss: 0.5050524\n",
      "\tspeed: 0.0305s/iter; left time: 358.1270s\n",
      "\titers: 200, epoch: 1 | loss: 0.2949983\n",
      "\tspeed: 0.0308s/iter; left time: 358.9267s\n",
      "\titers: 300, epoch: 1 | loss: 0.4267399\n",
      "\tspeed: 0.0290s/iter; left time: 334.2248s\n",
      "\titers: 400, epoch: 1 | loss: 0.3198698\n",
      "\tspeed: 0.0272s/iter; left time: 311.5203s\n",
      "\titers: 500, epoch: 1 | loss: 0.2889109\n",
      "\tspeed: 0.0266s/iter; left time: 301.3155s\n",
      "Epoch: 1 cost time: 16.86197829246521\n",
      "Epoch: 1, Steps: 592 | Train Loss: 0.2858110 Vali Loss: 0.2044401 Test Loss: 0.2448999\n",
      "Validation loss decreased (inf --> 0.204440).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1828072\n",
      "\tspeed: 0.0921s/iter; left time: 1026.9851s\n",
      "\titers: 200, epoch: 2 | loss: 0.1840862\n",
      "\tspeed: 0.0267s/iter; left time: 295.2056s\n",
      "\titers: 300, epoch: 2 | loss: 0.1546606\n",
      "\tspeed: 0.0257s/iter; left time: 281.4105s\n",
      "\titers: 400, epoch: 2 | loss: 0.2840461\n",
      "\tspeed: 0.0255s/iter; left time: 276.2341s\n",
      "\titers: 500, epoch: 2 | loss: 0.1757898\n",
      "\tspeed: 0.0254s/iter; left time: 272.7123s\n",
      "Epoch: 2 cost time: 15.714729309082031\n",
      "Epoch: 2, Steps: 592 | Train Loss: 0.2158601 Vali Loss: 0.2412638 Test Loss: 0.2631107\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1348314\n",
      "\tspeed: 0.0920s/iter; left time: 971.3700s\n",
      "\titers: 200, epoch: 3 | loss: 0.1996794\n",
      "\tspeed: 0.0272s/iter; left time: 284.4925s\n",
      "\titers: 300, epoch: 3 | loss: 0.2282710\n",
      "\tspeed: 0.0278s/iter; left time: 287.5429s\n",
      "\titers: 400, epoch: 3 | loss: 0.1436291\n",
      "\tspeed: 0.0294s/iter; left time: 301.4768s\n",
      "\titers: 500, epoch: 3 | loss: 0.1167506\n",
      "\tspeed: 0.0268s/iter; left time: 272.3269s\n",
      "Epoch: 3 cost time: 16.244390726089478\n",
      "Epoch: 3, Steps: 592 | Train Loss: 0.1884550 Vali Loss: 0.1937925 Test Loss: 0.2309837\n",
      "Validation loss decreased (0.204440 --> 0.193792).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3594001\n",
      "\tspeed: 0.0922s/iter; left time: 919.0443s\n",
      "\titers: 200, epoch: 4 | loss: 0.2173412\n",
      "\tspeed: 0.0283s/iter; left time: 278.8264s\n",
      "\titers: 300, epoch: 4 | loss: 0.1295953\n",
      "\tspeed: 0.0286s/iter; left time: 279.5797s\n",
      "\titers: 400, epoch: 4 | loss: 0.1703090\n",
      "\tspeed: 0.0277s/iter; left time: 267.5257s\n",
      "\titers: 500, epoch: 4 | loss: 0.2465682\n",
      "\tspeed: 0.0274s/iter; left time: 262.0665s\n",
      "Epoch: 4 cost time: 16.54380488395691\n",
      "Epoch: 4, Steps: 592 | Train Loss: 0.1735736 Vali Loss: 0.1962727 Test Loss: 0.2323557\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1565053\n",
      "\tspeed: 0.0957s/iter; left time: 897.2922s\n",
      "\titers: 200, epoch: 5 | loss: 0.1198486\n",
      "\tspeed: 0.0278s/iter; left time: 257.3491s\n",
      "\titers: 300, epoch: 5 | loss: 0.1293598\n",
      "\tspeed: 0.0279s/iter; left time: 256.0349s\n",
      "\titers: 400, epoch: 5 | loss: 0.1431982\n",
      "\tspeed: 0.0281s/iter; left time: 255.0734s\n",
      "\titers: 500, epoch: 5 | loss: 0.1462211\n",
      "\tspeed: 0.0298s/iter; left time: 267.4040s\n",
      "Epoch: 5 cost time: 16.957026481628418\n",
      "Epoch: 5, Steps: 592 | Train Loss: 0.1650523 Vali Loss: 0.1938919 Test Loss: 0.2277377\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2108240\n",
      "\tspeed: 0.0951s/iter; left time: 834.9894s\n",
      "\titers: 200, epoch: 6 | loss: 0.1056957\n",
      "\tspeed: 0.0277s/iter; left time: 240.8508s\n",
      "\titers: 300, epoch: 6 | loss: 0.1233390\n",
      "\tspeed: 0.0290s/iter; left time: 249.1205s\n",
      "\titers: 400, epoch: 6 | loss: 0.1353100\n",
      "\tspeed: 0.0273s/iter; left time: 231.1963s\n",
      "\titers: 500, epoch: 6 | loss: 0.2350454\n",
      "\tspeed: 0.0280s/iter; left time: 234.5056s\n",
      "Epoch: 6 cost time: 16.388147354125977\n",
      "Epoch: 6, Steps: 592 | Train Loss: 0.1592825 Vali Loss: 0.1938262 Test Loss: 0.2273835\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "Test cost time: 1.7832s\n",
      "test shape: (187, 32, 6, 1) (187, 32, 6, 1)\n",
      "test shape: (5984, 6, 1) (5984, 6, 1)\n",
      "mse:0.2304912507534027, mae:0.31661051511764526\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1670.941162109375\n",
      "MAE:  26.95744514465332\n",
      "RMSE: 40.87714767456055\n",
      "MAPE: 0.32194387912750244\n",
      "MSPE: 0.4657062888145447\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20961\n",
      "[DEBUG] Original dataset length: 20961\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18956\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6700\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "\titers: 100, epoch: 1 | loss: 0.2957069\n",
      "\tspeed: 0.0280s/iter; left time: 328.8963s\n",
      "\titers: 200, epoch: 1 | loss: 0.2653283\n",
      "\tspeed: 0.0262s/iter; left time: 304.5686s\n",
      "\titers: 300, epoch: 1 | loss: 0.2167158\n",
      "\tspeed: 0.0260s/iter; left time: 300.4324s\n",
      "\titers: 400, epoch: 1 | loss: 0.2472479\n",
      "\tspeed: 0.0262s/iter; left time: 299.5859s\n",
      "\titers: 500, epoch: 1 | loss: 0.2667864\n",
      "\tspeed: 0.0269s/iter; left time: 304.5259s\n",
      "Epoch: 1 cost time: 15.84488558769226\n",
      "Epoch: 1, Steps: 592 | Train Loss: 0.2977604 Vali Loss: 0.2143501 Test Loss: 0.2718880\n",
      "Validation loss decreased (inf --> 0.214350).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2221202\n",
      "\tspeed: 0.0917s/iter; left time: 1022.1889s\n",
      "\titers: 200, epoch: 2 | loss: 0.1428531\n",
      "\tspeed: 0.0259s/iter; left time: 286.1571s\n",
      "\titers: 300, epoch: 2 | loss: 0.2259004\n",
      "\tspeed: 0.0273s/iter; left time: 298.5826s\n",
      "\titers: 400, epoch: 2 | loss: 0.1786902\n",
      "\tspeed: 0.0271s/iter; left time: 294.4104s\n",
      "\titers: 500, epoch: 2 | loss: 0.1526723\n",
      "\tspeed: 0.0281s/iter; left time: 301.7626s\n",
      "Epoch: 2 cost time: 15.718876361846924\n",
      "Epoch: 2, Steps: 592 | Train Loss: 0.2170016 Vali Loss: 0.1985808 Test Loss: 0.2422794\n",
      "Validation loss decreased (0.214350 --> 0.198581).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1250967\n",
      "\tspeed: 0.0873s/iter; left time: 921.2559s\n",
      "\titers: 200, epoch: 3 | loss: 0.2621658\n",
      "\tspeed: 0.0263s/iter; left time: 275.2912s\n",
      "\titers: 300, epoch: 3 | loss: 0.1208020\n",
      "\tspeed: 0.0280s/iter; left time: 289.6925s\n",
      "\titers: 400, epoch: 3 | loss: 0.3032559\n",
      "\tspeed: 0.0270s/iter; left time: 276.7110s\n",
      "\titers: 500, epoch: 3 | loss: 0.1733553\n",
      "\tspeed: 0.0268s/iter; left time: 272.3886s\n",
      "Epoch: 3 cost time: 15.875007629394531\n",
      "Epoch: 3, Steps: 592 | Train Loss: 0.1875757 Vali Loss: 0.1957029 Test Loss: 0.2388707\n",
      "Validation loss decreased (0.198581 --> 0.195703).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1831568\n",
      "\tspeed: 0.0947s/iter; left time: 943.7198s\n",
      "\titers: 200, epoch: 4 | loss: 0.0950557\n",
      "\tspeed: 0.0268s/iter; left time: 264.2829s\n",
      "\titers: 300, epoch: 4 | loss: 0.3047408\n",
      "\tspeed: 0.0279s/iter; left time: 272.0467s\n",
      "\titers: 400, epoch: 4 | loss: 0.2263852\n",
      "\tspeed: 0.0275s/iter; left time: 265.5015s\n",
      "\titers: 500, epoch: 4 | loss: 0.1197031\n",
      "\tspeed: 0.0268s/iter; left time: 256.2205s\n",
      "Epoch: 4 cost time: 16.376031398773193\n",
      "Epoch: 4, Steps: 592 | Train Loss: 0.1739782 Vali Loss: 0.2034128 Test Loss: 0.2361576\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1928134\n",
      "\tspeed: 0.0947s/iter; left time: 887.7493s\n",
      "\titers: 200, epoch: 5 | loss: 0.1660181\n",
      "\tspeed: 0.0299s/iter; left time: 277.2338s\n",
      "\titers: 300, epoch: 5 | loss: 0.1754757\n",
      "\tspeed: 0.0282s/iter; left time: 258.8292s\n",
      "\titers: 400, epoch: 5 | loss: 0.1648815\n",
      "\tspeed: 0.0295s/iter; left time: 267.7659s\n",
      "\titers: 500, epoch: 5 | loss: 0.1653434\n",
      "\tspeed: 0.0299s/iter; left time: 268.2617s\n",
      "Epoch: 5 cost time: 17.35076880455017\n",
      "Epoch: 5, Steps: 592 | Train Loss: 0.1657547 Vali Loss: 0.2005342 Test Loss: 0.2358178\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2226405\n",
      "\tspeed: 0.0999s/iter; left time: 877.0965s\n",
      "\titers: 200, epoch: 6 | loss: 0.2164212\n",
      "\tspeed: 0.0317s/iter; left time: 275.4354s\n",
      "\titers: 300, epoch: 6 | loss: 0.1893203\n",
      "\tspeed: 0.0288s/iter; left time: 247.3854s\n",
      "\titers: 400, epoch: 6 | loss: 0.2080130\n",
      "\tspeed: 0.0284s/iter; left time: 241.2841s\n",
      "\titers: 500, epoch: 6 | loss: 0.1202669\n",
      "\tspeed: 0.0292s/iter; left time: 244.7705s\n",
      "Epoch: 6 cost time: 17.506733894348145\n",
      "Epoch: 6, Steps: 592 | Train Loss: 0.1606593 Vali Loss: 0.1976039 Test Loss: 0.2313588\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6002\n",
      "Test cost time: 1.7811s\n",
      "test shape: (187, 32, 6, 1) (187, 32, 6, 1)\n",
      "test shape: (5984, 6, 1) (5984, 6, 1)\n",
      "mse:0.23893269896507263, mae:0.3205800950527191\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl72_ll24_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1732.1373291015625\n",
      "MAE:  27.295429229736328\n",
      "RMSE: 41.618953704833984\n",
      "MAPE: 0.33404871821403503\n",
      "MSPE: 0.5670236945152283\n",
      ">>>>>>>Running time saved<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Running seq_len=96, label_len=32, pred_len=6\n",
      "Args in experiment:\n",
      "Namespace(model='informer', data='traffic_full', root_path='../', data_path='traffic_full.csv', features='S', target='flow', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=32, pred_len=6, enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=2, d_layers=1, s_layers=[3, 2, 1], d_ff=2048, factor=5, padding=0, distil=True, dropout=0.05, attn='prob', embed='timeF', activation='gelu', output_attention=False, do_predict=False, mix=True, cols=None, num_workers=0, itr=10, train_epochs=20, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, inverse=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', detail_freq='h')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl96_ll32_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20937\n",
      "[DEBUG] Original dataset length: 20937\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18596\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6628\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "\titers: 100, epoch: 1 | loss: 0.5859978\n",
      "\tspeed: 0.0448s/iter; left time: 515.7774s\n",
      "\titers: 200, epoch: 1 | loss: 0.3164970\n",
      "\tspeed: 0.0305s/iter; left time: 347.7943s\n",
      "\titers: 300, epoch: 1 | loss: 0.2458932\n",
      "\tspeed: 0.0312s/iter; left time: 353.7139s\n",
      "\titers: 400, epoch: 1 | loss: 0.2849227\n",
      "\tspeed: 0.0302s/iter; left time: 339.2367s\n",
      "\titers: 500, epoch: 1 | loss: 0.2415321\n",
      "\tspeed: 0.0322s/iter; left time: 358.4225s\n",
      "Epoch: 1 cost time: 18.522478818893433\n",
      "Epoch: 1, Steps: 581 | Train Loss: 0.3087967 Vali Loss: 0.2249232 Test Loss: 0.2776310\n",
      "Validation loss decreased (inf --> 0.224923).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2463842\n",
      "\tspeed: 0.1037s/iter; left time: 1133.9701s\n",
      "\titers: 200, epoch: 2 | loss: 0.2144177\n",
      "\tspeed: 0.0292s/iter; left time: 316.9012s\n",
      "\titers: 300, epoch: 2 | loss: 0.1885562\n",
      "\tspeed: 0.0287s/iter; left time: 308.0148s\n",
      "\titers: 400, epoch: 2 | loss: 0.2810304\n",
      "\tspeed: 0.0288s/iter; left time: 306.7611s\n",
      "\titers: 500, epoch: 2 | loss: 0.1480243\n",
      "\tspeed: 0.0311s/iter; left time: 327.6123s\n",
      "Epoch: 2 cost time: 17.355185747146606\n",
      "Epoch: 2, Steps: 581 | Train Loss: 0.2187620 Vali Loss: 0.2072579 Test Loss: 0.2601909\n",
      "Validation loss decreased (0.224923 --> 0.207258).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1917015\n",
      "\tspeed: 0.1035s/iter; left time: 1072.2455s\n",
      "\titers: 200, epoch: 3 | loss: 0.2015433\n",
      "\tspeed: 0.0320s/iter; left time: 328.7769s\n",
      "\titers: 300, epoch: 3 | loss: 0.1839429\n",
      "\tspeed: 0.0321s/iter; left time: 326.1894s\n",
      "\titers: 400, epoch: 3 | loss: 0.2468391\n",
      "\tspeed: 0.0332s/iter; left time: 333.8439s\n",
      "\titers: 500, epoch: 3 | loss: 0.2001233\n",
      "\tspeed: 0.0294s/iter; left time: 292.8533s\n",
      "Epoch: 3 cost time: 18.19689154624939\n",
      "Epoch: 3, Steps: 581 | Train Loss: 0.1874284 Vali Loss: 0.2062458 Test Loss: 0.2451999\n",
      "Validation loss decreased (0.207258 --> 0.206246).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1885642\n",
      "\tspeed: 0.0985s/iter; left time: 963.4466s\n",
      "\titers: 200, epoch: 4 | loss: 0.1563707\n",
      "\tspeed: 0.0313s/iter; left time: 302.6969s\n",
      "\titers: 300, epoch: 4 | loss: 0.1208115\n",
      "\tspeed: 0.0307s/iter; left time: 293.6147s\n",
      "\titers: 400, epoch: 4 | loss: 0.2459455\n",
      "\tspeed: 0.0305s/iter; left time: 289.1832s\n",
      "\titers: 500, epoch: 4 | loss: 0.2136110\n",
      "\tspeed: 0.0326s/iter; left time: 305.8882s\n",
      "Epoch: 4 cost time: 17.972753763198853\n",
      "Epoch: 4, Steps: 581 | Train Loss: 0.1721419 Vali Loss: 0.1974935 Test Loss: 0.2374644\n",
      "Validation loss decreased (0.206246 --> 0.197494).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0982907\n",
      "\tspeed: 0.1011s/iter; left time: 930.1772s\n",
      "\titers: 200, epoch: 5 | loss: 0.1670077\n",
      "\tspeed: 0.0318s/iter; left time: 289.4089s\n",
      "\titers: 300, epoch: 5 | loss: 0.1970084\n",
      "\tspeed: 0.0320s/iter; left time: 288.3104s\n",
      "\titers: 400, epoch: 5 | loss: 0.1722473\n",
      "\tspeed: 0.0301s/iter; left time: 267.5919s\n",
      "\titers: 500, epoch: 5 | loss: 0.1520262\n",
      "\tspeed: 0.0310s/iter; left time: 272.8445s\n",
      "Epoch: 5 cost time: 18.186661958694458\n",
      "Epoch: 5, Steps: 581 | Train Loss: 0.1620535 Vali Loss: 0.1930269 Test Loss: 0.2327410\n",
      "Validation loss decreased (0.197494 --> 0.193027).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1529154\n",
      "\tspeed: 0.1003s/iter; left time: 864.0185s\n",
      "\titers: 200, epoch: 6 | loss: 0.1950872\n",
      "\tspeed: 0.0300s/iter; left time: 255.5100s\n",
      "\titers: 300, epoch: 6 | loss: 0.1901065\n",
      "\tspeed: 0.0289s/iter; left time: 243.2451s\n",
      "\titers: 400, epoch: 6 | loss: 0.1170611\n",
      "\tspeed: 0.0294s/iter; left time: 244.5537s\n",
      "\titers: 500, epoch: 6 | loss: 0.2232439\n",
      "\tspeed: 0.0303s/iter; left time: 248.5924s\n",
      "Epoch: 6 cost time: 17.212841987609863\n",
      "Epoch: 6, Steps: 581 | Train Loss: 0.1574604 Vali Loss: 0.1982863 Test Loss: 0.2396584\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1785181\n",
      "\tspeed: 0.0988s/iter; left time: 794.0052s\n",
      "\titers: 200, epoch: 7 | loss: 0.2023811\n",
      "\tspeed: 0.0309s/iter; left time: 245.0634s\n",
      "\titers: 300, epoch: 7 | loss: 0.1832377\n",
      "\tspeed: 0.0317s/iter; left time: 248.4238s\n",
      "\titers: 400, epoch: 7 | loss: 0.1836336\n",
      "\tspeed: 0.0309s/iter; left time: 238.9374s\n",
      "\titers: 500, epoch: 7 | loss: 0.1284430\n",
      "\tspeed: 0.0302s/iter; left time: 230.5125s\n",
      "Epoch: 7 cost time: 17.990599393844604\n",
      "Epoch: 7, Steps: 581 | Train Loss: 0.1544475 Vali Loss: 0.1978180 Test Loss: 0.2405577\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1723466\n",
      "\tspeed: 0.1010s/iter; left time: 752.6044s\n",
      "\titers: 200, epoch: 8 | loss: 0.1850808\n",
      "\tspeed: 0.0316s/iter; left time: 232.0649s\n",
      "\titers: 300, epoch: 8 | loss: 0.2295940\n",
      "\tspeed: 0.0312s/iter; left time: 226.5871s\n",
      "\titers: 400, epoch: 8 | loss: 0.1515540\n",
      "\tspeed: 0.0305s/iter; left time: 218.1160s\n",
      "\titers: 500, epoch: 8 | loss: 0.1336062\n",
      "\tspeed: 0.0311s/iter; left time: 219.5313s\n",
      "Epoch: 8 cost time: 17.92459535598755\n",
      "Epoch: 8, Steps: 581 | Train Loss: 0.1524800 Vali Loss: 0.1968951 Test Loss: 0.2364689\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl96_ll32_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "Test cost time: 1.9034s\n",
      "test shape: (182, 32, 6, 1) (182, 32, 6, 1)\n",
      "test shape: (5824, 6, 1) (5824, 6, 1)\n",
      "mse:0.23313948512077332, mae:0.32415616512298584\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl96_ll32_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1690.1396484375\n",
      "MAE:  27.59990882873535\n",
      "RMSE: 41.11130905151367\n",
      "MAPE: 0.3692289888858795\n",
      "MSPE: 0.6826735138893127\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl96_ll32_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20937\n",
      "[DEBUG] Original dataset length: 20937\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18596\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6628\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "\titers: 100, epoch: 1 | loss: 0.1878803\n",
      "\tspeed: 0.0295s/iter; left time: 339.3762s\n",
      "\titers: 200, epoch: 1 | loss: 0.2043684\n",
      "\tspeed: 0.0298s/iter; left time: 340.1140s\n",
      "\titers: 300, epoch: 1 | loss: 0.2728988\n",
      "\tspeed: 0.0285s/iter; left time: 322.9617s\n",
      "\titers: 400, epoch: 1 | loss: 0.2026150\n",
      "\tspeed: 0.0278s/iter; left time: 312.4126s\n",
      "\titers: 500, epoch: 1 | loss: 0.3482661\n",
      "\tspeed: 0.0273s/iter; left time: 303.8890s\n",
      "Epoch: 1 cost time: 16.625966548919678\n",
      "Epoch: 1, Steps: 581 | Train Loss: 0.3115465 Vali Loss: 0.2251318 Test Loss: 0.2660446\n",
      "Validation loss decreased (inf --> 0.225132).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1855701\n",
      "\tspeed: 0.0964s/iter; left time: 1054.6899s\n",
      "\titers: 200, epoch: 2 | loss: 0.1722144\n",
      "\tspeed: 0.0292s/iter; left time: 316.4500s\n",
      "\titers: 300, epoch: 2 | loss: 0.2612670\n",
      "\tspeed: 0.0286s/iter; left time: 306.7355s\n",
      "\titers: 400, epoch: 2 | loss: 0.2079346\n",
      "\tspeed: 0.0292s/iter; left time: 311.0656s\n",
      "\titers: 500, epoch: 2 | loss: 0.2173384\n",
      "\tspeed: 0.0284s/iter; left time: 298.8537s\n",
      "Epoch: 2 cost time: 17.124576807022095\n",
      "Epoch: 2, Steps: 581 | Train Loss: 0.2210017 Vali Loss: 0.2030264 Test Loss: 0.2371945\n",
      "Validation loss decreased (0.225132 --> 0.203026).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0899056\n",
      "\tspeed: 0.0972s/iter; left time: 1006.5262s\n",
      "\titers: 200, epoch: 3 | loss: 0.1451993\n",
      "\tspeed: 0.0294s/iter; left time: 301.7386s\n",
      "\titers: 300, epoch: 3 | loss: 0.2639220\n",
      "\tspeed: 0.0306s/iter; left time: 310.9850s\n",
      "\titers: 400, epoch: 3 | loss: 0.1664621\n",
      "\tspeed: 0.0291s/iter; left time: 292.4548s\n",
      "\titers: 500, epoch: 3 | loss: 0.1377596\n",
      "\tspeed: 0.0290s/iter; left time: 289.0826s\n",
      "Epoch: 3 cost time: 17.009698390960693\n",
      "Epoch: 3, Steps: 581 | Train Loss: 0.1839450 Vali Loss: 0.1986662 Test Loss: 0.2376218\n",
      "Validation loss decreased (0.203026 --> 0.198666).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1361497\n",
      "\tspeed: 0.0954s/iter; left time: 932.4353s\n",
      "\titers: 200, epoch: 4 | loss: 0.1606894\n",
      "\tspeed: 0.0291s/iter; left time: 281.5739s\n",
      "\titers: 300, epoch: 4 | loss: 0.1718798\n",
      "\tspeed: 0.0284s/iter; left time: 272.0256s\n",
      "\titers: 400, epoch: 4 | loss: 0.1665466\n",
      "\tspeed: 0.0280s/iter; left time: 265.1623s\n",
      "\titers: 500, epoch: 4 | loss: 0.2123692\n",
      "\tspeed: 0.0279s/iter; left time: 261.2917s\n",
      "Epoch: 4 cost time: 16.810312032699585\n",
      "Epoch: 4, Steps: 581 | Train Loss: 0.1693534 Vali Loss: 0.1958396 Test Loss: 0.2357397\n",
      "Validation loss decreased (0.198666 --> 0.195840).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2811962\n",
      "\tspeed: 0.0967s/iter; left time: 889.1797s\n",
      "\titers: 200, epoch: 5 | loss: 0.2742508\n",
      "\tspeed: 0.0283s/iter; left time: 257.8902s\n",
      "\titers: 300, epoch: 5 | loss: 0.1580139\n",
      "\tspeed: 0.0288s/iter; left time: 259.2860s\n",
      "\titers: 400, epoch: 5 | loss: 0.1504767\n",
      "\tspeed: 0.0296s/iter; left time: 263.6033s\n",
      "\titers: 500, epoch: 5 | loss: 0.1147636\n",
      "\tspeed: 0.0288s/iter; left time: 253.6785s\n",
      "Epoch: 5 cost time: 16.745465993881226\n",
      "Epoch: 5, Steps: 581 | Train Loss: 0.1605718 Vali Loss: 0.1937804 Test Loss: 0.2353361\n",
      "Validation loss decreased (0.195840 --> 0.193780).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1979421\n",
      "\tspeed: 0.0943s/iter; left time: 812.3857s\n",
      "\titers: 200, epoch: 6 | loss: 0.1248059\n",
      "\tspeed: 0.0295s/iter; left time: 250.8162s\n",
      "\titers: 300, epoch: 6 | loss: 0.1135012\n",
      "\tspeed: 0.0300s/iter; left time: 252.3005s\n",
      "\titers: 400, epoch: 6 | loss: 0.1259555\n",
      "\tspeed: 0.0296s/iter; left time: 246.0545s\n",
      "\titers: 500, epoch: 6 | loss: 0.1453091\n",
      "\tspeed: 0.0275s/iter; left time: 225.7936s\n",
      "Epoch: 6 cost time: 17.02671980857849\n",
      "Epoch: 6, Steps: 581 | Train Loss: 0.1560674 Vali Loss: 0.1956428 Test Loss: 0.2345890\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0990118\n",
      "\tspeed: 0.0987s/iter; left time: 793.4321s\n",
      "\titers: 200, epoch: 7 | loss: 0.1330269\n",
      "\tspeed: 0.0293s/iter; left time: 232.6536s\n",
      "\titers: 300, epoch: 7 | loss: 0.1402574\n",
      "\tspeed: 0.0283s/iter; left time: 221.5594s\n",
      "\titers: 400, epoch: 7 | loss: 0.1100789\n",
      "\tspeed: 0.0294s/iter; left time: 227.3853s\n",
      "\titers: 500, epoch: 7 | loss: 0.1556414\n",
      "\tspeed: 0.0304s/iter; left time: 231.8250s\n",
      "Epoch: 7 cost time: 17.163105249404907\n",
      "Epoch: 7, Steps: 581 | Train Loss: 0.1536171 Vali Loss: 0.1958724 Test Loss: 0.2340614\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1271341\n",
      "\tspeed: 0.0932s/iter; left time: 694.9866s\n",
      "\titers: 200, epoch: 8 | loss: 0.1617855\n",
      "\tspeed: 0.0285s/iter; left time: 209.5842s\n",
      "\titers: 300, epoch: 8 | loss: 0.1507854\n",
      "\tspeed: 0.0295s/iter; left time: 214.3479s\n",
      "\titers: 400, epoch: 8 | loss: 0.1560526\n",
      "\tspeed: 0.0287s/iter; left time: 205.4027s\n",
      "\titers: 500, epoch: 8 | loss: 0.1663569\n",
      "\tspeed: 0.0280s/iter; left time: 197.2325s\n",
      "Epoch: 8 cost time: 16.469124794006348\n",
      "Epoch: 8, Steps: 581 | Train Loss: 0.1520409 Vali Loss: 0.1970006 Test Loss: 0.2339812\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl96_ll32_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "Test cost time: 1.9493s\n",
      "test shape: (182, 32, 6, 1) (182, 32, 6, 1)\n",
      "test shape: (5824, 6, 1) (5824, 6, 1)\n",
      "mse:0.23455078899860382, mae:0.32109785079956055\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl96_ll32_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1700.37060546875\n",
      "MAE:  27.339513778686523\n",
      "RMSE: 41.23554992675781\n",
      "MAPE: 0.341539591550827\n",
      "MSPE: 0.5349079966545105\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl96_ll32_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20937\n",
      "[DEBUG] Original dataset length: 20937\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18596\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6628\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "\titers: 100, epoch: 1 | loss: 0.3108002\n",
      "\tspeed: 0.0284s/iter; left time: 326.6571s\n",
      "\titers: 200, epoch: 1 | loss: 0.3355545\n",
      "\tspeed: 0.0289s/iter; left time: 330.0452s\n",
      "\titers: 300, epoch: 1 | loss: 0.2252238\n",
      "\tspeed: 0.0277s/iter; left time: 314.0362s\n",
      "\titers: 400, epoch: 1 | loss: 0.2077240\n",
      "\tspeed: 0.0283s/iter; left time: 317.7594s\n",
      "\titers: 500, epoch: 1 | loss: 0.2699072\n",
      "\tspeed: 0.0290s/iter; left time: 322.3429s\n",
      "Epoch: 1 cost time: 16.775104522705078\n",
      "Epoch: 1, Steps: 581 | Train Loss: 0.3076719 Vali Loss: 0.2049233 Test Loss: 0.2582267\n",
      "Validation loss decreased (inf --> 0.204923).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3006567\n",
      "\tspeed: 0.0957s/iter; left time: 1047.3076s\n",
      "\titers: 200, epoch: 2 | loss: 0.1625281\n",
      "\tspeed: 0.0279s/iter; left time: 302.1750s\n",
      "\titers: 300, epoch: 2 | loss: 0.1684472\n",
      "\tspeed: 0.0283s/iter; left time: 303.5732s\n",
      "\titers: 400, epoch: 2 | loss: 0.2023707\n",
      "\tspeed: 0.0297s/iter; left time: 315.6922s\n",
      "\titers: 500, epoch: 2 | loss: 0.2484021\n",
      "\tspeed: 0.0277s/iter; left time: 291.9360s\n",
      "Epoch: 2 cost time: 16.473949432373047\n",
      "Epoch: 2, Steps: 581 | Train Loss: 0.2164623 Vali Loss: 0.2180181 Test Loss: 0.2600143\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1779237\n",
      "\tspeed: 0.0937s/iter; left time: 970.2110s\n",
      "\titers: 200, epoch: 3 | loss: 0.1772356\n",
      "\tspeed: 0.0305s/iter; left time: 312.7258s\n",
      "\titers: 300, epoch: 3 | loss: 0.1392665\n",
      "\tspeed: 0.0291s/iter; left time: 295.5859s\n",
      "\titers: 400, epoch: 3 | loss: 0.1575630\n",
      "\tspeed: 0.0284s/iter; left time: 285.6558s\n",
      "\titers: 500, epoch: 3 | loss: 0.1734301\n",
      "\tspeed: 0.0289s/iter; left time: 287.7548s\n",
      "Epoch: 3 cost time: 16.83402991294861\n",
      "Epoch: 3, Steps: 581 | Train Loss: 0.1849367 Vali Loss: 0.1929693 Test Loss: 0.2423259\n",
      "Validation loss decreased (0.204923 --> 0.192969).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3046863\n",
      "\tspeed: 0.0954s/iter; left time: 933.1095s\n",
      "\titers: 200, epoch: 4 | loss: 0.2631339\n",
      "\tspeed: 0.0287s/iter; left time: 278.2218s\n",
      "\titers: 300, epoch: 4 | loss: 0.2240079\n",
      "\tspeed: 0.0286s/iter; left time: 273.4718s\n",
      "\titers: 400, epoch: 4 | loss: 0.1574535\n",
      "\tspeed: 0.0285s/iter; left time: 270.5596s\n",
      "\titers: 500, epoch: 4 | loss: 0.2998023\n",
      "\tspeed: 0.0288s/iter; left time: 270.5309s\n",
      "Epoch: 4 cost time: 16.812750339508057\n",
      "Epoch: 4, Steps: 581 | Train Loss: 0.1687123 Vali Loss: 0.1938432 Test Loss: 0.2402839\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1575102\n",
      "\tspeed: 0.0944s/iter; left time: 868.1221s\n",
      "\titers: 200, epoch: 5 | loss: 0.1509759\n",
      "\tspeed: 0.0296s/iter; left time: 269.2208s\n",
      "\titers: 300, epoch: 5 | loss: 0.1228340\n",
      "\tspeed: 0.0296s/iter; left time: 266.1905s\n",
      "\titers: 400, epoch: 5 | loss: 0.2096101\n",
      "\tspeed: 0.0286s/iter; left time: 254.0282s\n",
      "\titers: 500, epoch: 5 | loss: 0.1315167\n",
      "\tspeed: 0.0280s/iter; left time: 245.9544s\n",
      "Epoch: 5 cost time: 16.713764190673828\n",
      "Epoch: 5, Steps: 581 | Train Loss: 0.1597738 Vali Loss: 0.1961070 Test Loss: 0.2438432\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1315216\n",
      "\tspeed: 0.0952s/iter; left time: 819.9128s\n",
      "\titers: 200, epoch: 6 | loss: 0.1888184\n",
      "\tspeed: 0.0281s/iter; left time: 239.1374s\n",
      "\titers: 300, epoch: 6 | loss: 0.1440435\n",
      "\tspeed: 0.0278s/iter; left time: 233.9431s\n",
      "\titers: 400, epoch: 6 | loss: 0.1852491\n",
      "\tspeed: 0.0292s/iter; left time: 243.0622s\n",
      "\titers: 500, epoch: 6 | loss: 0.2635272\n",
      "\tspeed: 0.0278s/iter; left time: 228.8023s\n",
      "Epoch: 6 cost time: 16.575591802597046\n",
      "Epoch: 6, Steps: 581 | Train Loss: 0.1550860 Vali Loss: 0.1950090 Test Loss: 0.2449463\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl96_ll32_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "Test cost time: 1.8774s\n",
      "test shape: (182, 32, 6, 1) (182, 32, 6, 1)\n",
      "test shape: (5824, 6, 1) (5824, 6, 1)\n",
      "mse:0.24224068224430084, mae:0.32435142993927\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl96_ll32_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1756.1185302734375\n",
      "MAE:  27.61653709411621\n",
      "RMSE: 41.90606689453125\n",
      "MAPE: 0.35152995586395264\n",
      "MSPE: 0.6228541731834412\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl96_ll32_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20937\n",
      "[DEBUG] Original dataset length: 20937\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18596\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6628\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "\titers: 100, epoch: 1 | loss: 0.2641480\n",
      "\tspeed: 0.0277s/iter; left time: 318.9437s\n",
      "\titers: 200, epoch: 1 | loss: 0.1857881\n",
      "\tspeed: 0.0275s/iter; left time: 313.5324s\n",
      "\titers: 300, epoch: 1 | loss: 0.2520742\n",
      "\tspeed: 0.0299s/iter; left time: 338.6947s\n",
      "\titers: 400, epoch: 1 | loss: 0.1888391\n",
      "\tspeed: 0.0284s/iter; left time: 319.1604s\n",
      "\titers: 500, epoch: 1 | loss: 0.2739782\n",
      "\tspeed: 0.0291s/iter; left time: 324.0714s\n",
      "Epoch: 1 cost time: 16.54021167755127\n",
      "Epoch: 1, Steps: 581 | Train Loss: 0.3122965 Vali Loss: 0.2180975 Test Loss: 0.2592450\n",
      "Validation loss decreased (inf --> 0.218097).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2162261\n",
      "\tspeed: 0.0968s/iter; left time: 1058.6737s\n",
      "\titers: 200, epoch: 2 | loss: 0.2772930\n",
      "\tspeed: 0.0289s/iter; left time: 313.6484s\n",
      "\titers: 300, epoch: 2 | loss: 0.2505828\n",
      "\tspeed: 0.0293s/iter; left time: 314.3256s\n",
      "\titers: 400, epoch: 2 | loss: 0.1961081\n",
      "\tspeed: 0.0290s/iter; left time: 308.3849s\n",
      "\titers: 500, epoch: 2 | loss: 0.2468962\n",
      "\tspeed: 0.0299s/iter; left time: 315.4059s\n",
      "Epoch: 2 cost time: 17.234766483306885\n",
      "Epoch: 2, Steps: 581 | Train Loss: 0.2198152 Vali Loss: 0.2042920 Test Loss: 0.2444782\n",
      "Validation loss decreased (0.218097 --> 0.204292).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1985344\n",
      "\tspeed: 0.0975s/iter; left time: 1009.7314s\n",
      "\titers: 200, epoch: 3 | loss: 0.1626655\n",
      "\tspeed: 0.0301s/iter; left time: 308.8064s\n",
      "\titers: 300, epoch: 3 | loss: 0.2168233\n",
      "\tspeed: 0.0293s/iter; left time: 297.1869s\n",
      "\titers: 400, epoch: 3 | loss: 0.2004078\n",
      "\tspeed: 0.0303s/iter; left time: 304.3447s\n",
      "\titers: 500, epoch: 3 | loss: 0.1837880\n",
      "\tspeed: 0.0298s/iter; left time: 296.9744s\n",
      "Epoch: 3 cost time: 17.348628997802734\n",
      "Epoch: 3, Steps: 581 | Train Loss: 0.1885986 Vali Loss: 0.1971551 Test Loss: 0.2467504\n",
      "Validation loss decreased (0.204292 --> 0.197155).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1638279\n",
      "\tspeed: 0.0951s/iter; left time: 929.5431s\n",
      "\titers: 200, epoch: 4 | loss: 0.1050243\n",
      "\tspeed: 0.0299s/iter; left time: 289.5444s\n",
      "\titers: 300, epoch: 4 | loss: 0.1406317\n",
      "\tspeed: 0.0290s/iter; left time: 277.7326s\n",
      "\titers: 400, epoch: 4 | loss: 0.1669475\n",
      "\tspeed: 0.0285s/iter; left time: 269.8005s\n",
      "\titers: 500, epoch: 4 | loss: 0.1717083\n",
      "\tspeed: 0.0286s/iter; left time: 268.0006s\n",
      "Epoch: 4 cost time: 16.90173864364624\n",
      "Epoch: 4, Steps: 581 | Train Loss: 0.1725768 Vali Loss: 0.1917857 Test Loss: 0.2378705\n",
      "Validation loss decreased (0.197155 --> 0.191786).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1724863\n",
      "\tspeed: 0.0963s/iter; left time: 885.2547s\n",
      "\titers: 200, epoch: 5 | loss: 0.2133481\n",
      "\tspeed: 0.0289s/iter; left time: 262.9746s\n",
      "\titers: 300, epoch: 5 | loss: 0.1209396\n",
      "\tspeed: 0.0298s/iter; left time: 268.5438s\n",
      "\titers: 400, epoch: 5 | loss: 0.1668645\n",
      "\tspeed: 0.0290s/iter; left time: 258.0495s\n",
      "\titers: 500, epoch: 5 | loss: 0.0999353\n",
      "\tspeed: 0.0328s/iter; left time: 288.3409s\n",
      "Epoch: 5 cost time: 17.532904624938965\n",
      "Epoch: 5, Steps: 581 | Train Loss: 0.1630161 Vali Loss: 0.1951026 Test Loss: 0.2452632\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1902705\n",
      "\tspeed: 0.1083s/iter; left time: 933.0799s\n",
      "\titers: 200, epoch: 6 | loss: 0.1138524\n",
      "\tspeed: 0.0321s/iter; left time: 273.6910s\n",
      "\titers: 300, epoch: 6 | loss: 0.2371540\n",
      "\tspeed: 0.0312s/iter; left time: 262.6671s\n",
      "\titers: 400, epoch: 6 | loss: 0.2095618\n",
      "\tspeed: 0.0308s/iter; left time: 256.0933s\n",
      "\titers: 500, epoch: 6 | loss: 0.2794628\n",
      "\tspeed: 0.0305s/iter; left time: 250.7809s\n",
      "Epoch: 6 cost time: 18.115220308303833\n",
      "Epoch: 6, Steps: 581 | Train Loss: 0.1578026 Vali Loss: 0.1916484 Test Loss: 0.2376885\n",
      "Validation loss decreased (0.191786 --> 0.191648).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1454626\n",
      "\tspeed: 0.0999s/iter; left time: 802.3326s\n",
      "\titers: 200, epoch: 7 | loss: 0.1533968\n",
      "\tspeed: 0.0297s/iter; left time: 235.6835s\n",
      "\titers: 300, epoch: 7 | loss: 0.1983812\n",
      "\tspeed: 0.0296s/iter; left time: 231.6067s\n",
      "\titers: 400, epoch: 7 | loss: 0.1337327\n",
      "\tspeed: 0.0297s/iter; left time: 229.4325s\n",
      "\titers: 500, epoch: 7 | loss: 0.1511447\n",
      "\tspeed: 0.0299s/iter; left time: 228.2518s\n",
      "Epoch: 7 cost time: 17.234491109848022\n",
      "Epoch: 7, Steps: 581 | Train Loss: 0.1547990 Vali Loss: 0.1927559 Test Loss: 0.2376870\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1748026\n",
      "\tspeed: 0.0959s/iter; left time: 714.7027s\n",
      "\titers: 200, epoch: 8 | loss: 0.1415417\n",
      "\tspeed: 0.0318s/iter; left time: 234.1043s\n",
      "\titers: 300, epoch: 8 | loss: 0.0972247\n",
      "\tspeed: 0.0317s/iter; left time: 229.8226s\n",
      "\titers: 400, epoch: 8 | loss: 0.0932722\n",
      "\tspeed: 0.0302s/iter; left time: 216.2529s\n",
      "\titers: 500, epoch: 8 | loss: 0.1295221\n",
      "\tspeed: 0.0311s/iter; left time: 219.1871s\n",
      "Epoch: 8 cost time: 18.04277467727661\n",
      "Epoch: 8, Steps: 581 | Train Loss: 0.1524085 Vali Loss: 0.1902310 Test Loss: 0.2352837\n",
      "Validation loss decreased (0.191648 --> 0.190231).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1530983\n",
      "\tspeed: 0.1022s/iter; left time: 702.7182s\n",
      "\titers: 200, epoch: 9 | loss: 0.1415596\n",
      "\tspeed: 0.0309s/iter; left time: 209.2344s\n",
      "\titers: 300, epoch: 9 | loss: 0.1103128\n",
      "\tspeed: 0.0309s/iter; left time: 206.1716s\n",
      "\titers: 400, epoch: 9 | loss: 0.2306904\n",
      "\tspeed: 0.0307s/iter; left time: 201.8269s\n",
      "\titers: 500, epoch: 9 | loss: 0.0855644\n",
      "\tspeed: 0.0315s/iter; left time: 203.7877s\n",
      "Epoch: 9 cost time: 17.96894383430481\n",
      "Epoch: 9, Steps: 581 | Train Loss: 0.1524540 Vali Loss: 0.1905761 Test Loss: 0.2373369\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.1165054\n",
      "\tspeed: 0.0964s/iter; left time: 606.6513s\n",
      "\titers: 200, epoch: 10 | loss: 0.1562132\n",
      "\tspeed: 0.0296s/iter; left time: 183.2092s\n",
      "\titers: 300, epoch: 10 | loss: 0.1282922\n",
      "\tspeed: 0.0298s/iter; left time: 181.8393s\n",
      "\titers: 400, epoch: 10 | loss: 0.1057925\n",
      "\tspeed: 0.0303s/iter; left time: 181.4221s\n",
      "\titers: 500, epoch: 10 | loss: 0.1228034\n",
      "\tspeed: 0.0299s/iter; left time: 175.9288s\n",
      "Epoch: 10 cost time: 17.43114137649536\n",
      "Epoch: 10, Steps: 581 | Train Loss: 0.1517122 Vali Loss: 0.1906132 Test Loss: 0.2376361\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.1775044\n",
      "\tspeed: 0.0985s/iter; left time: 562.2480s\n",
      "\titers: 200, epoch: 11 | loss: 0.1622708\n",
      "\tspeed: 0.0304s/iter; left time: 170.2944s\n",
      "\titers: 300, epoch: 11 | loss: 0.1065057\n",
      "\tspeed: 0.0309s/iter; left time: 170.1997s\n",
      "\titers: 400, epoch: 11 | loss: 0.1352293\n",
      "\tspeed: 0.0299s/iter; left time: 161.6987s\n",
      "\titers: 500, epoch: 11 | loss: 0.1984458\n",
      "\tspeed: 0.0319s/iter; left time: 169.4805s\n",
      "Epoch: 11 cost time: 17.872113466262817\n",
      "Epoch: 11, Steps: 581 | Train Loss: 0.1522467 Vali Loss: 0.1905924 Test Loss: 0.2360394\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl96_ll32_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "Test cost time: 1.8745s\n",
      "test shape: (182, 32, 6, 1) (182, 32, 6, 1)\n",
      "test shape: (5824, 6, 1) (5824, 6, 1)\n",
      "mse:0.2350417971611023, mae:0.32468143105506897\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl96_ll32_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1703.93017578125\n",
      "MAE:  27.64463233947754\n",
      "RMSE: 41.278690338134766\n",
      "MAPE: 0.3588176667690277\n",
      "MSPE: 0.6001290678977966\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl96_ll32_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20937\n",
      "[DEBUG] Original dataset length: 20937\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18596\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6628\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "\titers: 100, epoch: 1 | loss: 0.2549788\n",
      "\tspeed: 0.0310s/iter; left time: 357.2119s\n",
      "\titers: 200, epoch: 1 | loss: 0.2273968\n",
      "\tspeed: 0.0319s/iter; left time: 364.4851s\n",
      "\titers: 300, epoch: 1 | loss: 0.1516322\n",
      "\tspeed: 0.0289s/iter; left time: 326.9753s\n",
      "\titers: 400, epoch: 1 | loss: 0.1699637\n",
      "\tspeed: 0.0287s/iter; left time: 322.1639s\n",
      "\titers: 500, epoch: 1 | loss: 0.2871416\n",
      "\tspeed: 0.0289s/iter; left time: 321.7333s\n",
      "Epoch: 1 cost time: 17.43575930595398\n",
      "Epoch: 1, Steps: 581 | Train Loss: 0.2974329 Vali Loss: 0.2307063 Test Loss: 0.2776766\n",
      "Validation loss decreased (inf --> 0.230706).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2781174\n",
      "\tspeed: 0.1015s/iter; left time: 1110.0690s\n",
      "\titers: 200, epoch: 2 | loss: 0.2274899\n",
      "\tspeed: 0.0294s/iter; left time: 318.3070s\n",
      "\titers: 300, epoch: 2 | loss: 0.2190243\n",
      "\tspeed: 0.0292s/iter; left time: 313.3125s\n",
      "\titers: 400, epoch: 2 | loss: 0.1065408\n",
      "\tspeed: 0.0308s/iter; left time: 327.7442s\n",
      "\titers: 500, epoch: 2 | loss: 0.2534357\n",
      "\tspeed: 0.0305s/iter; left time: 321.1214s\n",
      "Epoch: 2 cost time: 17.400803565979004\n",
      "Epoch: 2, Steps: 581 | Train Loss: 0.2155210 Vali Loss: 0.2053026 Test Loss: 0.2534955\n",
      "Validation loss decreased (0.230706 --> 0.205303).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1742520\n",
      "\tspeed: 0.0984s/iter; left time: 1019.3841s\n",
      "\titers: 200, epoch: 3 | loss: 0.2057937\n",
      "\tspeed: 0.0311s/iter; left time: 319.4159s\n",
      "\titers: 300, epoch: 3 | loss: 0.2403607\n",
      "\tspeed: 0.0310s/iter; left time: 314.6827s\n",
      "\titers: 400, epoch: 3 | loss: 0.1634204\n",
      "\tspeed: 0.0300s/iter; left time: 302.0007s\n",
      "\titers: 500, epoch: 3 | loss: 0.1375692\n",
      "\tspeed: 0.0288s/iter; left time: 287.2817s\n",
      "Epoch: 3 cost time: 17.549091815948486\n",
      "Epoch: 3, Steps: 581 | Train Loss: 0.1870647 Vali Loss: 0.1912871 Test Loss: 0.2379496\n",
      "Validation loss decreased (0.205303 --> 0.191287).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1116301\n",
      "\tspeed: 0.0974s/iter; left time: 952.6160s\n",
      "\titers: 200, epoch: 4 | loss: 0.1315624\n",
      "\tspeed: 0.0296s/iter; left time: 286.0482s\n",
      "\titers: 300, epoch: 4 | loss: 0.1454935\n",
      "\tspeed: 0.0293s/iter; left time: 280.9478s\n",
      "\titers: 400, epoch: 4 | loss: 0.1435907\n",
      "\tspeed: 0.0300s/iter; left time: 284.3645s\n",
      "\titers: 500, epoch: 4 | loss: 0.2853888\n",
      "\tspeed: 0.0303s/iter; left time: 283.7056s\n",
      "Epoch: 4 cost time: 17.445056915283203\n",
      "Epoch: 4, Steps: 581 | Train Loss: 0.1704574 Vali Loss: 0.1915481 Test Loss: 0.2413838\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2228450\n",
      "\tspeed: 0.0984s/iter; left time: 905.4382s\n",
      "\titers: 200, epoch: 5 | loss: 0.1129625\n",
      "\tspeed: 0.0302s/iter; left time: 275.1541s\n",
      "\titers: 300, epoch: 5 | loss: 0.1682971\n",
      "\tspeed: 0.0302s/iter; left time: 271.4538s\n",
      "\titers: 400, epoch: 5 | loss: 0.1161511\n",
      "\tspeed: 0.0306s/iter; left time: 272.0353s\n",
      "\titers: 500, epoch: 5 | loss: 0.1622806\n",
      "\tspeed: 0.0296s/iter; left time: 260.1704s\n",
      "Epoch: 5 cost time: 17.530760049819946\n",
      "Epoch: 5, Steps: 581 | Train Loss: 0.1618805 Vali Loss: 0.1900393 Test Loss: 0.2386382\n",
      "Validation loss decreased (0.191287 --> 0.190039).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1265956\n",
      "\tspeed: 0.0997s/iter; left time: 859.2044s\n",
      "\titers: 200, epoch: 6 | loss: 0.1908911\n",
      "\tspeed: 0.0293s/iter; left time: 249.7386s\n",
      "\titers: 300, epoch: 6 | loss: 0.1194160\n",
      "\tspeed: 0.0296s/iter; left time: 248.9080s\n",
      "\titers: 400, epoch: 6 | loss: 0.1968365\n",
      "\tspeed: 0.0289s/iter; left time: 240.5536s\n",
      "\titers: 500, epoch: 6 | loss: 0.1271541\n",
      "\tspeed: 0.0293s/iter; left time: 240.6958s\n",
      "Epoch: 6 cost time: 17.19537329673767\n",
      "Epoch: 6, Steps: 581 | Train Loss: 0.1566180 Vali Loss: 0.1897094 Test Loss: 0.2393404\n",
      "Validation loss decreased (0.190039 --> 0.189709).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1038008\n",
      "\tspeed: 0.0976s/iter; left time: 784.4273s\n",
      "\titers: 200, epoch: 7 | loss: 0.0842543\n",
      "\tspeed: 0.0298s/iter; left time: 236.7344s\n",
      "\titers: 300, epoch: 7 | loss: 0.1132950\n",
      "\tspeed: 0.0306s/iter; left time: 239.7312s\n",
      "\titers: 400, epoch: 7 | loss: 0.1759080\n",
      "\tspeed: 0.0306s/iter; left time: 236.5631s\n",
      "\titers: 500, epoch: 7 | loss: 0.0904261\n",
      "\tspeed: 0.0298s/iter; left time: 227.7661s\n",
      "Epoch: 7 cost time: 17.518009185791016\n",
      "Epoch: 7, Steps: 581 | Train Loss: 0.1534299 Vali Loss: 0.1901815 Test Loss: 0.2378012\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1059555\n",
      "\tspeed: 0.0971s/iter; left time: 723.6200s\n",
      "\titers: 200, epoch: 8 | loss: 0.0989732\n",
      "\tspeed: 0.0305s/iter; left time: 224.5131s\n",
      "\titers: 300, epoch: 8 | loss: 0.1266099\n",
      "\tspeed: 0.0300s/iter; left time: 217.4121s\n",
      "\titers: 400, epoch: 8 | loss: 0.1421759\n",
      "\tspeed: 0.0310s/iter; left time: 221.4622s\n",
      "\titers: 500, epoch: 8 | loss: 0.0796832\n",
      "\tspeed: 0.0308s/iter; left time: 217.1444s\n",
      "Epoch: 8 cost time: 17.83512020111084\n",
      "Epoch: 8, Steps: 581 | Train Loss: 0.1519009 Vali Loss: 0.1896280 Test Loss: 0.2403098\n",
      "Validation loss decreased (0.189709 --> 0.189628).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0983991\n",
      "\tspeed: 0.1034s/iter; left time: 710.9901s\n",
      "\titers: 200, epoch: 9 | loss: 0.1489664\n",
      "\tspeed: 0.0313s/iter; left time: 212.2423s\n",
      "\titers: 300, epoch: 9 | loss: 0.2037009\n",
      "\tspeed: 0.0307s/iter; left time: 204.9374s\n",
      "\titers: 400, epoch: 9 | loss: 0.1087590\n",
      "\tspeed: 0.0329s/iter; left time: 216.5448s\n",
      "\titers: 500, epoch: 9 | loss: 0.1150510\n",
      "\tspeed: 0.0322s/iter; left time: 208.3072s\n",
      "Epoch: 9 cost time: 18.222013235092163\n",
      "Epoch: 9, Steps: 581 | Train Loss: 0.1515717 Vali Loss: 0.1908561 Test Loss: 0.2396056\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.1432006\n",
      "\tspeed: 0.0996s/iter; left time: 626.8584s\n",
      "\titers: 200, epoch: 10 | loss: 0.1449205\n",
      "\tspeed: 0.0300s/iter; left time: 185.8043s\n",
      "\titers: 300, epoch: 10 | loss: 0.1126302\n",
      "\tspeed: 0.0291s/iter; left time: 177.2812s\n",
      "\titers: 400, epoch: 10 | loss: 0.1653680\n",
      "\tspeed: 0.0299s/iter; left time: 179.4314s\n",
      "\titers: 500, epoch: 10 | loss: 0.1908018\n",
      "\tspeed: 0.0294s/iter; left time: 173.2565s\n",
      "Epoch: 10 cost time: 17.293519735336304\n",
      "Epoch: 10, Steps: 581 | Train Loss: 0.1502495 Vali Loss: 0.1908549 Test Loss: 0.2402172\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.1294997\n",
      "\tspeed: 0.0994s/iter; left time: 567.4653s\n",
      "\titers: 200, epoch: 11 | loss: 0.1519268\n",
      "\tspeed: 0.0291s/iter; left time: 163.3931s\n",
      "\titers: 300, epoch: 11 | loss: 0.1444879\n",
      "\tspeed: 0.0290s/iter; left time: 159.7018s\n",
      "\titers: 400, epoch: 11 | loss: 0.1002109\n",
      "\tspeed: 0.0302s/iter; left time: 163.6293s\n",
      "\titers: 500, epoch: 11 | loss: 0.1029700\n",
      "\tspeed: 0.0298s/iter; left time: 158.2569s\n",
      "Epoch: 11 cost time: 17.16338038444519\n",
      "Epoch: 11, Steps: 581 | Train Loss: 0.1507191 Vali Loss: 0.1909864 Test Loss: 0.2406856\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl96_ll32_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "Test cost time: 2.0007s\n",
      "test shape: (182, 32, 6, 1) (182, 32, 6, 1)\n",
      "test shape: (5824, 6, 1) (5824, 6, 1)\n",
      "mse:0.24046127498149872, mae:0.32966598868370056\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl96_ll32_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1743.21875\n",
      "MAE:  28.06903648376465\n",
      "RMSE: 41.75187301635742\n",
      "MAPE: 0.3619653880596161\n",
      "MSPE: 0.609064519405365\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl96_ll32_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20937\n",
      "[DEBUG] Original dataset length: 20937\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18596\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6628\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "\titers: 100, epoch: 1 | loss: 0.2927991\n",
      "\tspeed: 0.0317s/iter; left time: 365.7457s\n",
      "\titers: 200, epoch: 1 | loss: 0.4845950\n",
      "\tspeed: 0.0297s/iter; left time: 339.5940s\n",
      "\titers: 300, epoch: 1 | loss: 0.2017879\n",
      "\tspeed: 0.0296s/iter; left time: 334.9884s\n",
      "\titers: 400, epoch: 1 | loss: 0.2418985\n",
      "\tspeed: 0.0293s/iter; left time: 328.7790s\n",
      "\titers: 500, epoch: 1 | loss: 0.1461250\n",
      "\tspeed: 0.0298s/iter; left time: 330.8523s\n",
      "Epoch: 1 cost time: 17.576889991760254\n",
      "Epoch: 1, Steps: 581 | Train Loss: 0.2988763 Vali Loss: 0.2036253 Test Loss: 0.2549363\n",
      "Validation loss decreased (inf --> 0.203625).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1872759\n",
      "\tspeed: 0.1010s/iter; left time: 1105.2973s\n",
      "\titers: 200, epoch: 2 | loss: 0.1535762\n",
      "\tspeed: 0.0310s/iter; left time: 336.0053s\n",
      "\titers: 300, epoch: 2 | loss: 0.1267590\n",
      "\tspeed: 0.0303s/iter; left time: 325.7786s\n",
      "\titers: 400, epoch: 2 | loss: 0.1882958\n",
      "\tspeed: 0.0313s/iter; left time: 332.5068s\n",
      "\titers: 500, epoch: 2 | loss: 0.2335178\n",
      "\tspeed: 0.0279s/iter; left time: 294.3407s\n",
      "Epoch: 2 cost time: 17.523971557617188\n",
      "Epoch: 2, Steps: 581 | Train Loss: 0.2181488 Vali Loss: 0.2054767 Test Loss: 0.2584399\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2073542\n",
      "\tspeed: 0.0946s/iter; left time: 979.9086s\n",
      "\titers: 200, epoch: 3 | loss: 0.1156985\n",
      "\tspeed: 0.0303s/iter; left time: 310.3750s\n",
      "\titers: 300, epoch: 3 | loss: 0.1852373\n",
      "\tspeed: 0.0283s/iter; left time: 287.9719s\n",
      "\titers: 400, epoch: 3 | loss: 0.1056303\n",
      "\tspeed: 0.0284s/iter; left time: 286.0083s\n",
      "\titers: 500, epoch: 3 | loss: 0.1139783\n",
      "\tspeed: 0.0290s/iter; left time: 288.3930s\n",
      "Epoch: 3 cost time: 16.835841178894043\n",
      "Epoch: 3, Steps: 581 | Train Loss: 0.1877944 Vali Loss: 0.1909691 Test Loss: 0.2420842\n",
      "Validation loss decreased (0.203625 --> 0.190969).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1269934\n",
      "\tspeed: 0.0951s/iter; left time: 929.4492s\n",
      "\titers: 200, epoch: 4 | loss: 0.1728772\n",
      "\tspeed: 0.0297s/iter; left time: 287.7682s\n",
      "\titers: 300, epoch: 4 | loss: 0.2288646\n",
      "\tspeed: 0.0293s/iter; left time: 280.2332s\n",
      "\titers: 400, epoch: 4 | loss: 0.2144527\n",
      "\tspeed: 0.0293s/iter; left time: 277.9243s\n",
      "\titers: 500, epoch: 4 | loss: 0.1798133\n",
      "\tspeed: 0.0298s/iter; left time: 279.3572s\n",
      "Epoch: 4 cost time: 16.91411066055298\n",
      "Epoch: 4, Steps: 581 | Train Loss: 0.1720466 Vali Loss: 0.1889504 Test Loss: 0.2419341\n",
      "Validation loss decreased (0.190969 --> 0.188950).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2119999\n",
      "\tspeed: 0.0936s/iter; left time: 860.6144s\n",
      "\titers: 200, epoch: 5 | loss: 0.1713938\n",
      "\tspeed: 0.0286s/iter; left time: 260.3445s\n",
      "\titers: 300, epoch: 5 | loss: 0.2056662\n",
      "\tspeed: 0.0301s/iter; left time: 271.2075s\n",
      "\titers: 400, epoch: 5 | loss: 0.1341419\n",
      "\tspeed: 0.0297s/iter; left time: 263.9350s\n",
      "\titers: 500, epoch: 5 | loss: 0.1638987\n",
      "\tspeed: 0.0292s/iter; left time: 256.9822s\n",
      "Epoch: 5 cost time: 17.03425121307373\n",
      "Epoch: 5, Steps: 581 | Train Loss: 0.1631930 Vali Loss: 0.1919459 Test Loss: 0.2381743\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1224665\n",
      "\tspeed: 0.0974s/iter; left time: 838.9097s\n",
      "\titers: 200, epoch: 6 | loss: 0.1147321\n",
      "\tspeed: 0.0291s/iter; left time: 247.8264s\n",
      "\titers: 300, epoch: 6 | loss: 0.1499119\n",
      "\tspeed: 0.0275s/iter; left time: 231.8161s\n",
      "\titers: 400, epoch: 6 | loss: 0.1622884\n",
      "\tspeed: 0.0277s/iter; left time: 230.4886s\n",
      "\titers: 500, epoch: 6 | loss: 0.1796911\n",
      "\tspeed: 0.0285s/iter; left time: 234.3373s\n",
      "Epoch: 6 cost time: 16.716675281524658\n",
      "Epoch: 6, Steps: 581 | Train Loss: 0.1587144 Vali Loss: 0.1869134 Test Loss: 0.2409759\n",
      "Validation loss decreased (0.188950 --> 0.186913).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0943594\n",
      "\tspeed: 0.0956s/iter; left time: 768.4084s\n",
      "\titers: 200, epoch: 7 | loss: 0.2166547\n",
      "\tspeed: 0.0284s/iter; left time: 225.5653s\n",
      "\titers: 300, epoch: 7 | loss: 0.1501362\n",
      "\tspeed: 0.0294s/iter; left time: 230.4348s\n",
      "\titers: 400, epoch: 7 | loss: 0.0994369\n",
      "\tspeed: 0.0288s/iter; left time: 222.4735s\n",
      "\titers: 500, epoch: 7 | loss: 0.1266680\n",
      "\tspeed: 0.0296s/iter; left time: 225.9564s\n",
      "Epoch: 7 cost time: 16.787534952163696\n",
      "Epoch: 7, Steps: 581 | Train Loss: 0.1555836 Vali Loss: 0.1917022 Test Loss: 0.2414364\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1357365\n",
      "\tspeed: 0.0945s/iter; left time: 704.6073s\n",
      "\titers: 200, epoch: 8 | loss: 0.1843739\n",
      "\tspeed: 0.0284s/iter; left time: 209.0313s\n",
      "\titers: 300, epoch: 8 | loss: 0.1884197\n",
      "\tspeed: 0.0291s/iter; left time: 211.1135s\n",
      "\titers: 400, epoch: 8 | loss: 0.2161020\n",
      "\tspeed: 0.0320s/iter; left time: 228.6314s\n",
      "\titers: 500, epoch: 8 | loss: 0.1064671\n",
      "\tspeed: 0.0312s/iter; left time: 220.1518s\n",
      "Epoch: 8 cost time: 17.604122161865234\n",
      "Epoch: 8, Steps: 581 | Train Loss: 0.1536005 Vali Loss: 0.1921822 Test Loss: 0.2421056\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1710659\n",
      "\tspeed: 0.1032s/iter; left time: 709.3558s\n",
      "\titers: 200, epoch: 9 | loss: 0.1109987\n",
      "\tspeed: 0.0315s/iter; left time: 213.0575s\n",
      "\titers: 300, epoch: 9 | loss: 0.1300906\n",
      "\tspeed: 0.0315s/iter; left time: 210.0840s\n",
      "\titers: 400, epoch: 9 | loss: 0.1527140\n",
      "\tspeed: 0.0327s/iter; left time: 214.7786s\n",
      "\titers: 500, epoch: 9 | loss: 0.1972349\n",
      "\tspeed: 0.0326s/iter; left time: 210.9501s\n",
      "Epoch: 9 cost time: 18.547229290008545\n",
      "Epoch: 9, Steps: 581 | Train Loss: 0.1525670 Vali Loss: 0.1916136 Test Loss: 0.2422770\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl96_ll32_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "Test cost time: 2.1039s\n",
      "test shape: (182, 32, 6, 1) (182, 32, 6, 1)\n",
      "test shape: (5824, 6, 1) (5824, 6, 1)\n",
      "mse:0.2404528111219406, mae:0.325026273727417\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl96_ll32_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1743.1571044921875\n",
      "MAE:  27.673992156982422\n",
      "RMSE: 41.75113296508789\n",
      "MAPE: 0.3464815020561218\n",
      "MSPE: 0.5441425442695618\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl96_ll32_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20937\n",
      "[DEBUG] Original dataset length: 20937\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18596\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6628\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "\titers: 100, epoch: 1 | loss: 0.4274698\n",
      "\tspeed: 0.0315s/iter; left time: 362.8587s\n",
      "\titers: 200, epoch: 1 | loss: 0.4546802\n",
      "\tspeed: 0.0295s/iter; left time: 336.4817s\n",
      "\titers: 300, epoch: 1 | loss: 0.2920577\n",
      "\tspeed: 0.0300s/iter; left time: 339.5238s\n",
      "\titers: 400, epoch: 1 | loss: 0.2616327\n",
      "\tspeed: 0.0283s/iter; left time: 317.4217s\n",
      "\titers: 500, epoch: 1 | loss: 0.1448423\n",
      "\tspeed: 0.0284s/iter; left time: 316.1436s\n",
      "Epoch: 1 cost time: 17.30921244621277\n",
      "Epoch: 1, Steps: 581 | Train Loss: 0.3121265 Vali Loss: 0.2121445 Test Loss: 0.2531155\n",
      "Validation loss decreased (inf --> 0.212145).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1759042\n",
      "\tspeed: 0.0981s/iter; left time: 1072.8593s\n",
      "\titers: 200, epoch: 2 | loss: 0.1681245\n",
      "\tspeed: 0.0297s/iter; left time: 321.4214s\n",
      "\titers: 300, epoch: 2 | loss: 0.2058620\n",
      "\tspeed: 0.0310s/iter; left time: 332.5673s\n",
      "\titers: 400, epoch: 2 | loss: 0.2298339\n",
      "\tspeed: 0.0301s/iter; left time: 319.7675s\n",
      "\titers: 500, epoch: 2 | loss: 0.2202422\n",
      "\tspeed: 0.0291s/iter; left time: 306.9569s\n",
      "Epoch: 2 cost time: 17.27794575691223\n",
      "Epoch: 2, Steps: 581 | Train Loss: 0.2148431 Vali Loss: 0.2201276 Test Loss: 0.2707473\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1207853\n",
      "\tspeed: 0.0947s/iter; left time: 981.4007s\n",
      "\titers: 200, epoch: 3 | loss: 0.0883989\n",
      "\tspeed: 0.0298s/iter; left time: 305.7014s\n",
      "\titers: 300, epoch: 3 | loss: 0.2064950\n",
      "\tspeed: 0.0297s/iter; left time: 302.1888s\n",
      "\titers: 400, epoch: 3 | loss: 0.1492748\n",
      "\tspeed: 0.0286s/iter; left time: 287.3729s\n",
      "\titers: 500, epoch: 3 | loss: 0.1851573\n",
      "\tspeed: 0.0293s/iter; left time: 292.1556s\n",
      "Epoch: 3 cost time: 17.172845125198364\n",
      "Epoch: 3, Steps: 581 | Train Loss: 0.1854465 Vali Loss: 0.1983440 Test Loss: 0.2354253\n",
      "Validation loss decreased (0.212145 --> 0.198344).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2092493\n",
      "\tspeed: 0.0987s/iter; left time: 964.9731s\n",
      "\titers: 200, epoch: 4 | loss: 0.2137613\n",
      "\tspeed: 0.0289s/iter; left time: 279.3798s\n",
      "\titers: 300, epoch: 4 | loss: 0.2306697\n",
      "\tspeed: 0.0292s/iter; left time: 279.2543s\n",
      "\titers: 400, epoch: 4 | loss: 0.2201162\n",
      "\tspeed: 0.0284s/iter; left time: 269.3387s\n",
      "\titers: 500, epoch: 4 | loss: 0.1746462\n",
      "\tspeed: 0.0299s/iter; left time: 280.1180s\n",
      "Epoch: 4 cost time: 16.911046743392944\n",
      "Epoch: 4, Steps: 581 | Train Loss: 0.1703077 Vali Loss: 0.2029052 Test Loss: 0.2429012\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1741841\n",
      "\tspeed: 0.0960s/iter; left time: 883.1911s\n",
      "\titers: 200, epoch: 5 | loss: 0.1132637\n",
      "\tspeed: 0.0303s/iter; left time: 275.6524s\n",
      "\titers: 300, epoch: 5 | loss: 0.1553672\n",
      "\tspeed: 0.0312s/iter; left time: 280.4852s\n",
      "\titers: 400, epoch: 5 | loss: 0.1081990\n",
      "\tspeed: 0.0304s/iter; left time: 270.4492s\n",
      "\titers: 500, epoch: 5 | loss: 0.1995808\n",
      "\tspeed: 0.0309s/iter; left time: 271.9482s\n",
      "Epoch: 5 cost time: 17.778270959854126\n",
      "Epoch: 5, Steps: 581 | Train Loss: 0.1606178 Vali Loss: 0.2008834 Test Loss: 0.2428772\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1627955\n",
      "\tspeed: 0.0984s/iter; left time: 848.0591s\n",
      "\titers: 200, epoch: 6 | loss: 0.1957678\n",
      "\tspeed: 0.0310s/iter; left time: 264.4175s\n",
      "\titers: 300, epoch: 6 | loss: 0.1589589\n",
      "\tspeed: 0.0294s/iter; left time: 247.8458s\n",
      "\titers: 400, epoch: 6 | loss: 0.1231212\n",
      "\tspeed: 0.0270s/iter; left time: 224.4683s\n",
      "\titers: 500, epoch: 6 | loss: 0.1956616\n",
      "\tspeed: 0.0298s/iter; left time: 245.2000s\n",
      "Epoch: 6 cost time: 17.115134239196777\n",
      "Epoch: 6, Steps: 581 | Train Loss: 0.1548801 Vali Loss: 0.1977459 Test Loss: 0.2358928\n",
      "Validation loss decreased (0.198344 --> 0.197746).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1832233\n",
      "\tspeed: 0.0960s/iter; left time: 771.5664s\n",
      "\titers: 200, epoch: 7 | loss: 0.0961079\n",
      "\tspeed: 0.0291s/iter; left time: 231.1052s\n",
      "\titers: 300, epoch: 7 | loss: 0.1911312\n",
      "\tspeed: 0.0301s/iter; left time: 235.8019s\n",
      "\titers: 400, epoch: 7 | loss: 0.0833566\n",
      "\tspeed: 0.0305s/iter; left time: 235.7782s\n",
      "\titers: 500, epoch: 7 | loss: 0.1626988\n",
      "\tspeed: 0.0307s/iter; left time: 234.5779s\n",
      "Epoch: 7 cost time: 17.531753540039062\n",
      "Epoch: 7, Steps: 581 | Train Loss: 0.1527449 Vali Loss: 0.1979990 Test Loss: 0.2369519\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1820059\n",
      "\tspeed: 0.0936s/iter; left time: 697.8353s\n",
      "\titers: 200, epoch: 8 | loss: 0.1002655\n",
      "\tspeed: 0.0261s/iter; left time: 192.2254s\n",
      "\titers: 300, epoch: 8 | loss: 0.1794307\n",
      "\tspeed: 0.0273s/iter; left time: 198.2501s\n",
      "\titers: 400, epoch: 8 | loss: 0.1751831\n",
      "\tspeed: 0.0319s/iter; left time: 228.1778s\n",
      "\titers: 500, epoch: 8 | loss: 0.1924293\n",
      "\tspeed: 0.0325s/iter; left time: 229.2716s\n",
      "Epoch: 8 cost time: 17.03499174118042\n",
      "Epoch: 8, Steps: 581 | Train Loss: 0.1511842 Vali Loss: 0.1981852 Test Loss: 0.2356290\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1486513\n",
      "\tspeed: 0.1024s/iter; left time: 703.8863s\n",
      "\titers: 200, epoch: 9 | loss: 0.1551257\n",
      "\tspeed: 0.0318s/iter; left time: 215.7036s\n",
      "\titers: 300, epoch: 9 | loss: 0.1541061\n",
      "\tspeed: 0.0320s/iter; left time: 213.2148s\n",
      "\titers: 400, epoch: 9 | loss: 0.1915841\n",
      "\tspeed: 0.0302s/iter; left time: 198.7964s\n",
      "\titers: 500, epoch: 9 | loss: 0.1097336\n",
      "\tspeed: 0.0308s/iter; left time: 199.2662s\n",
      "Epoch: 9 cost time: 18.00575876235962\n",
      "Epoch: 9, Steps: 581 | Train Loss: 0.1500073 Vali Loss: 0.1954462 Test Loss: 0.2342442\n",
      "Validation loss decreased (0.197746 --> 0.195446).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.1262585\n",
      "\tspeed: 0.0981s/iter; left time: 617.0094s\n",
      "\titers: 200, epoch: 10 | loss: 0.1451962\n",
      "\tspeed: 0.0289s/iter; left time: 178.7333s\n",
      "\titers: 300, epoch: 10 | loss: 0.2140420\n",
      "\tspeed: 0.0293s/iter; left time: 178.2680s\n",
      "\titers: 400, epoch: 10 | loss: 0.2893686\n",
      "\tspeed: 0.0286s/iter; left time: 171.4105s\n",
      "\titers: 500, epoch: 10 | loss: 0.1249283\n",
      "\tspeed: 0.0290s/iter; left time: 170.8226s\n",
      "Epoch: 10 cost time: 17.13112783432007\n",
      "Epoch: 10, Steps: 581 | Train Loss: 0.1490216 Vali Loss: 0.1957184 Test Loss: 0.2348309\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.1316424\n",
      "\tspeed: 0.0935s/iter; left time: 534.0387s\n",
      "\titers: 200, epoch: 11 | loss: 0.1358596\n",
      "\tspeed: 0.0276s/iter; left time: 154.8295s\n",
      "\titers: 300, epoch: 11 | loss: 0.1119916\n",
      "\tspeed: 0.0293s/iter; left time: 161.5739s\n",
      "\titers: 400, epoch: 11 | loss: 0.0918419\n",
      "\tspeed: 0.0304s/iter; left time: 164.4961s\n",
      "\titers: 500, epoch: 11 | loss: 0.1533878\n",
      "\tspeed: 0.0295s/iter; left time: 156.7866s\n",
      "Epoch: 11 cost time: 16.788883686065674\n",
      "Epoch: 11, Steps: 581 | Train Loss: 0.1493032 Vali Loss: 0.1942954 Test Loss: 0.2326318\n",
      "Validation loss decreased (0.195446 --> 0.194295).  Saving model ...\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.1352816\n",
      "\tspeed: 0.0940s/iter; left time: 482.0651s\n",
      "\titers: 200, epoch: 12 | loss: 0.2860046\n",
      "\tspeed: 0.0308s/iter; left time: 154.9744s\n",
      "\titers: 300, epoch: 12 | loss: 0.1797706\n",
      "\tspeed: 0.0299s/iter; left time: 147.5107s\n",
      "\titers: 400, epoch: 12 | loss: 0.1382809\n",
      "\tspeed: 0.0280s/iter; left time: 135.0787s\n",
      "\titers: 500, epoch: 12 | loss: 0.1293550\n",
      "\tspeed: 0.0300s/iter; left time: 141.9030s\n",
      "Epoch: 12 cost time: 17.0705885887146\n",
      "Epoch: 12, Steps: 581 | Train Loss: 0.1496424 Vali Loss: 0.1963633 Test Loss: 0.2347617\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      "\titers: 100, epoch: 13 | loss: 0.1314333\n",
      "\tspeed: 0.0968s/iter; left time: 440.1420s\n",
      "\titers: 200, epoch: 13 | loss: 0.1357830\n",
      "\tspeed: 0.0300s/iter; left time: 133.6914s\n",
      "\titers: 300, epoch: 13 | loss: 0.1616610\n",
      "\tspeed: 0.0303s/iter; left time: 131.8842s\n",
      "\titers: 400, epoch: 13 | loss: 0.2097587\n",
      "\tspeed: 0.0302s/iter; left time: 128.1812s\n",
      "\titers: 500, epoch: 13 | loss: 0.1435803\n",
      "\tspeed: 0.0304s/iter; left time: 126.2780s\n",
      "Epoch: 13 cost time: 17.511438369750977\n",
      "Epoch: 13, Steps: 581 | Train Loss: 0.1489906 Vali Loss: 0.1957796 Test Loss: 0.2332793\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.44140625e-08\n",
      "\titers: 100, epoch: 14 | loss: 0.1654418\n",
      "\tspeed: 0.0964s/iter; left time: 382.6650s\n",
      "\titers: 200, epoch: 14 | loss: 0.1004046\n",
      "\tspeed: 0.0315s/iter; left time: 121.8126s\n",
      "\titers: 300, epoch: 14 | loss: 0.1314310\n",
      "\tspeed: 0.0306s/iter; left time: 115.2646s\n",
      "\titers: 400, epoch: 14 | loss: 0.1493803\n",
      "\tspeed: 0.0281s/iter; left time: 102.9037s\n",
      "\titers: 500, epoch: 14 | loss: 0.1444791\n",
      "\tspeed: 0.0300s/iter; left time: 106.9589s\n",
      "Epoch: 14 cost time: 17.328465223312378\n",
      "Epoch: 14, Steps: 581 | Train Loss: 0.1491945 Vali Loss: 0.1975048 Test Loss: 0.2344114\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl96_ll32_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "Test cost time: 1.9350s\n",
      "test shape: (182, 32, 6, 1) (182, 32, 6, 1)\n",
      "test shape: (5824, 6, 1) (5824, 6, 1)\n",
      "mse:0.23370547592639923, mae:0.3202659785747528\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl96_ll32_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1694.24267578125\n",
      "MAE:  27.26868438720703\n",
      "RMSE: 41.16117858886719\n",
      "MAPE: 0.34756842255592346\n",
      "MSPE: 0.5706347823143005\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl96_ll32_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20937\n",
      "[DEBUG] Original dataset length: 20937\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18596\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6628\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "\titers: 100, epoch: 1 | loss: 0.2902505\n",
      "\tspeed: 0.0282s/iter; left time: 325.1430s\n",
      "\titers: 200, epoch: 1 | loss: 0.4110043\n",
      "\tspeed: 0.0288s/iter; left time: 329.2978s\n",
      "\titers: 300, epoch: 1 | loss: 0.2468733\n",
      "\tspeed: 0.0285s/iter; left time: 322.6989s\n",
      "\titers: 400, epoch: 1 | loss: 0.1754912\n",
      "\tspeed: 0.0316s/iter; left time: 354.9545s\n",
      "\titers: 500, epoch: 1 | loss: 0.2805115\n",
      "\tspeed: 0.0308s/iter; left time: 342.5817s\n",
      "Epoch: 1 cost time: 17.425459384918213\n",
      "Epoch: 1, Steps: 581 | Train Loss: 0.3086354 Vali Loss: 0.2044748 Test Loss: 0.2530894\n",
      "Validation loss decreased (inf --> 0.204475).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1475353\n",
      "\tspeed: 0.1022s/iter; left time: 1118.2934s\n",
      "\titers: 200, epoch: 2 | loss: 0.2303382\n",
      "\tspeed: 0.0313s/iter; left time: 339.3228s\n",
      "\titers: 300, epoch: 2 | loss: 0.2714395\n",
      "\tspeed: 0.0297s/iter; left time: 318.9611s\n",
      "\titers: 400, epoch: 2 | loss: 0.1932825\n",
      "\tspeed: 0.0298s/iter; left time: 317.2600s\n",
      "\titers: 500, epoch: 2 | loss: 0.2655811\n",
      "\tspeed: 0.0298s/iter; left time: 314.0660s\n",
      "Epoch: 2 cost time: 17.44730234146118\n",
      "Epoch: 2, Steps: 581 | Train Loss: 0.2145075 Vali Loss: 0.1971401 Test Loss: 0.2463194\n",
      "Validation loss decreased (0.204475 --> 0.197140).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1654706\n",
      "\tspeed: 0.1003s/iter; left time: 1038.5350s\n",
      "\titers: 200, epoch: 3 | loss: 0.1492656\n",
      "\tspeed: 0.0309s/iter; left time: 316.8423s\n",
      "\titers: 300, epoch: 3 | loss: 0.1794047\n",
      "\tspeed: 0.0306s/iter; left time: 310.8080s\n",
      "\titers: 400, epoch: 3 | loss: 0.2375894\n",
      "\tspeed: 0.0289s/iter; left time: 290.8025s\n",
      "\titers: 500, epoch: 3 | loss: 0.2229808\n",
      "\tspeed: 0.0302s/iter; left time: 301.0235s\n",
      "Epoch: 3 cost time: 17.4311420917511\n",
      "Epoch: 3, Steps: 581 | Train Loss: 0.1851355 Vali Loss: 0.2152948 Test Loss: 0.2589093\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2147247\n",
      "\tspeed: 0.0944s/iter; left time: 923.1675s\n",
      "\titers: 200, epoch: 4 | loss: 0.1214813\n",
      "\tspeed: 0.0299s/iter; left time: 289.5377s\n",
      "\titers: 300, epoch: 4 | loss: 0.1546357\n",
      "\tspeed: 0.0289s/iter; left time: 276.7049s\n",
      "\titers: 400, epoch: 4 | loss: 0.1611035\n",
      "\tspeed: 0.0297s/iter; left time: 281.8677s\n",
      "\titers: 500, epoch: 4 | loss: 0.3351977\n",
      "\tspeed: 0.0322s/iter; left time: 301.9084s\n",
      "Epoch: 4 cost time: 17.462469339370728\n",
      "Epoch: 4, Steps: 581 | Train Loss: 0.1700279 Vali Loss: 0.2041470 Test Loss: 0.2552684\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2019889\n",
      "\tspeed: 0.0989s/iter; left time: 909.9756s\n",
      "\titers: 200, epoch: 5 | loss: 0.1321880\n",
      "\tspeed: 0.0305s/iter; left time: 277.0621s\n",
      "\titers: 300, epoch: 5 | loss: 0.1978160\n",
      "\tspeed: 0.0308s/iter; left time: 277.1212s\n",
      "\titers: 400, epoch: 5 | loss: 0.1616685\n",
      "\tspeed: 0.0308s/iter; left time: 273.9366s\n",
      "\titers: 500, epoch: 5 | loss: 0.1993936\n",
      "\tspeed: 0.0308s/iter; left time: 271.3265s\n",
      "Epoch: 5 cost time: 17.684275150299072\n",
      "Epoch: 5, Steps: 581 | Train Loss: 0.1602684 Vali Loss: 0.1948420 Test Loss: 0.2443553\n",
      "Validation loss decreased (0.197140 --> 0.194842).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1531508\n",
      "\tspeed: 0.0947s/iter; left time: 815.7852s\n",
      "\titers: 200, epoch: 6 | loss: 0.1824525\n",
      "\tspeed: 0.0274s/iter; left time: 233.4062s\n",
      "\titers: 300, epoch: 6 | loss: 0.1368642\n",
      "\tspeed: 0.0293s/iter; left time: 246.7633s\n",
      "\titers: 400, epoch: 6 | loss: 0.2574300\n",
      "\tspeed: 0.0278s/iter; left time: 230.8367s\n",
      "\titers: 500, epoch: 6 | loss: 0.1254859\n",
      "\tspeed: 0.0294s/iter; left time: 241.2598s\n",
      "Epoch: 6 cost time: 16.523470401763916\n",
      "Epoch: 6, Steps: 581 | Train Loss: 0.1549967 Vali Loss: 0.1927065 Test Loss: 0.2452224\n",
      "Validation loss decreased (0.194842 --> 0.192707).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1041495\n",
      "\tspeed: 0.0953s/iter; left time: 765.7190s\n",
      "\titers: 200, epoch: 7 | loss: 0.1751634\n",
      "\tspeed: 0.0282s/iter; left time: 224.1285s\n",
      "\titers: 300, epoch: 7 | loss: 0.2306279\n",
      "\tspeed: 0.0292s/iter; left time: 229.0265s\n",
      "\titers: 400, epoch: 7 | loss: 0.1797681\n",
      "\tspeed: 0.0281s/iter; left time: 217.4398s\n",
      "\titers: 500, epoch: 7 | loss: 0.1785266\n",
      "\tspeed: 0.0280s/iter; left time: 214.0772s\n",
      "Epoch: 7 cost time: 16.880608081817627\n",
      "Epoch: 7, Steps: 581 | Train Loss: 0.1526516 Vali Loss: 0.1939224 Test Loss: 0.2458717\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1875789\n",
      "\tspeed: 0.0957s/iter; left time: 713.6193s\n",
      "\titers: 200, epoch: 8 | loss: 0.1223830\n",
      "\tspeed: 0.0292s/iter; left time: 215.1012s\n",
      "\titers: 300, epoch: 8 | loss: 0.1211836\n",
      "\tspeed: 0.0283s/iter; left time: 205.1751s\n",
      "\titers: 400, epoch: 8 | loss: 0.0945962\n",
      "\tspeed: 0.0300s/iter; left time: 214.6295s\n",
      "\titers: 500, epoch: 8 | loss: 0.1364625\n",
      "\tspeed: 0.0282s/iter; left time: 199.0691s\n",
      "Epoch: 8 cost time: 16.72122836112976\n",
      "Epoch: 8, Steps: 581 | Train Loss: 0.1514681 Vali Loss: 0.1945485 Test Loss: 0.2475581\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.2574062\n",
      "\tspeed: 0.0928s/iter; left time: 637.6756s\n",
      "\titers: 200, epoch: 9 | loss: 0.1541261\n",
      "\tspeed: 0.0303s/iter; left time: 205.4293s\n",
      "\titers: 300, epoch: 9 | loss: 0.1489101\n",
      "\tspeed: 0.0301s/iter; left time: 200.7573s\n",
      "\titers: 400, epoch: 9 | loss: 0.1361981\n",
      "\tspeed: 0.0297s/iter; left time: 194.9923s\n",
      "\titers: 500, epoch: 9 | loss: 0.1573195\n",
      "\tspeed: 0.0305s/iter; left time: 197.1906s\n",
      "Epoch: 9 cost time: 17.368473052978516\n",
      "Epoch: 9, Steps: 581 | Train Loss: 0.1503708 Vali Loss: 0.1942218 Test Loss: 0.2467194\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl96_ll32_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "Test cost time: 2.0789s\n",
      "test shape: (182, 32, 6, 1) (182, 32, 6, 1)\n",
      "test shape: (5824, 6, 1) (5824, 6, 1)\n",
      "mse:0.24515293538570404, mae:0.32849353551864624\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl96_ll32_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1777.230712890625\n",
      "MAE:  27.969207763671875\n",
      "RMSE: 42.1572151184082\n",
      "MAPE: 0.35251757502555847\n",
      "MSPE: 0.5781953930854797\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl96_ll32_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20937\n",
      "[DEBUG] Original dataset length: 20937\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18596\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6628\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "\titers: 100, epoch: 1 | loss: 0.3564579\n",
      "\tspeed: 0.0313s/iter; left time: 360.3819s\n",
      "\titers: 200, epoch: 1 | loss: 0.2529646\n",
      "\tspeed: 0.0311s/iter; left time: 355.1848s\n",
      "\titers: 300, epoch: 1 | loss: 0.1748172\n",
      "\tspeed: 0.0306s/iter; left time: 346.3972s\n",
      "\titers: 400, epoch: 1 | loss: 0.3239248\n",
      "\tspeed: 0.0314s/iter; left time: 352.5723s\n",
      "\titers: 500, epoch: 1 | loss: 0.3143985\n",
      "\tspeed: 0.0304s/iter; left time: 337.5833s\n",
      "Epoch: 1 cost time: 17.929505348205566\n",
      "Epoch: 1, Steps: 581 | Train Loss: 0.3104952 Vali Loss: 0.2099219 Test Loss: 0.2606045\n",
      "Validation loss decreased (inf --> 0.209922).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2075678\n",
      "\tspeed: 0.1011s/iter; left time: 1106.5198s\n",
      "\titers: 200, epoch: 2 | loss: 0.1203014\n",
      "\tspeed: 0.0301s/iter; left time: 326.1534s\n",
      "\titers: 300, epoch: 2 | loss: 0.2584667\n",
      "\tspeed: 0.0305s/iter; left time: 327.5963s\n",
      "\titers: 400, epoch: 2 | loss: 0.2109496\n",
      "\tspeed: 0.0301s/iter; left time: 320.7622s\n",
      "\titers: 500, epoch: 2 | loss: 0.1899049\n",
      "\tspeed: 0.0286s/iter; left time: 301.1279s\n",
      "Epoch: 2 cost time: 17.407318353652954\n",
      "Epoch: 2, Steps: 581 | Train Loss: 0.2157791 Vali Loss: 0.2019131 Test Loss: 0.2390286\n",
      "Validation loss decreased (0.209922 --> 0.201913).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2047959\n",
      "\tspeed: 0.0954s/iter; left time: 988.5496s\n",
      "\titers: 200, epoch: 3 | loss: 0.1231577\n",
      "\tspeed: 0.0278s/iter; left time: 285.7088s\n",
      "\titers: 300, epoch: 3 | loss: 0.1567429\n",
      "\tspeed: 0.0287s/iter; left time: 292.0007s\n",
      "\titers: 400, epoch: 3 | loss: 0.1248905\n",
      "\tspeed: 0.0285s/iter; left time: 286.9874s\n",
      "\titers: 500, epoch: 3 | loss: 0.1722798\n",
      "\tspeed: 0.0297s/iter; left time: 296.1492s\n",
      "Epoch: 3 cost time: 16.640578746795654\n",
      "Epoch: 3, Steps: 581 | Train Loss: 0.1829258 Vali Loss: 0.1987072 Test Loss: 0.2495647\n",
      "Validation loss decreased (0.201913 --> 0.198707).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1626841\n",
      "\tspeed: 0.0933s/iter; left time: 912.2016s\n",
      "\titers: 200, epoch: 4 | loss: 0.1531883\n",
      "\tspeed: 0.0289s/iter; left time: 279.9269s\n",
      "\titers: 300, epoch: 4 | loss: 0.2092582\n",
      "\tspeed: 0.0306s/iter; left time: 292.9098s\n",
      "\titers: 400, epoch: 4 | loss: 0.1835141\n",
      "\tspeed: 0.0287s/iter; left time: 272.4157s\n",
      "\titers: 500, epoch: 4 | loss: 0.1874908\n",
      "\tspeed: 0.0287s/iter; left time: 269.5910s\n",
      "Epoch: 4 cost time: 16.79878330230713\n",
      "Epoch: 4, Steps: 581 | Train Loss: 0.1687332 Vali Loss: 0.1987843 Test Loss: 0.2419359\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1305619\n",
      "\tspeed: 0.0944s/iter; left time: 868.2221s\n",
      "\titers: 200, epoch: 5 | loss: 0.1869045\n",
      "\tspeed: 0.0287s/iter; left time: 261.4111s\n",
      "\titers: 300, epoch: 5 | loss: 0.1026093\n",
      "\tspeed: 0.0295s/iter; left time: 265.1492s\n",
      "\titers: 400, epoch: 5 | loss: 0.1831754\n",
      "\tspeed: 0.0281s/iter; left time: 249.8545s\n",
      "\titers: 500, epoch: 5 | loss: 0.1111047\n",
      "\tspeed: 0.0285s/iter; left time: 250.3946s\n",
      "Epoch: 5 cost time: 16.86449670791626\n",
      "Epoch: 5, Steps: 581 | Train Loss: 0.1602471 Vali Loss: 0.1958575 Test Loss: 0.2368870\n",
      "Validation loss decreased (0.198707 --> 0.195858).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1304506\n",
      "\tspeed: 0.0966s/iter; left time: 832.2865s\n",
      "\titers: 200, epoch: 6 | loss: 0.0949060\n",
      "\tspeed: 0.0293s/iter; left time: 249.1186s\n",
      "\titers: 300, epoch: 6 | loss: 0.1305427\n",
      "\tspeed: 0.0310s/iter; left time: 261.1672s\n",
      "\titers: 400, epoch: 6 | loss: 0.2160199\n",
      "\tspeed: 0.0310s/iter; left time: 258.0054s\n",
      "\titers: 500, epoch: 6 | loss: 0.1243126\n",
      "\tspeed: 0.0306s/iter; left time: 251.5490s\n",
      "Epoch: 6 cost time: 17.630314350128174\n",
      "Epoch: 6, Steps: 581 | Train Loss: 0.1543836 Vali Loss: 0.1956758 Test Loss: 0.2400986\n",
      "Validation loss decreased (0.195858 --> 0.195676).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1146279\n",
      "\tspeed: 0.0965s/iter; left time: 775.2022s\n",
      "\titers: 200, epoch: 7 | loss: 0.1580910\n",
      "\tspeed: 0.0290s/iter; left time: 230.3218s\n",
      "\titers: 300, epoch: 7 | loss: 0.1768997\n",
      "\tspeed: 0.0292s/iter; left time: 229.1076s\n",
      "\titers: 400, epoch: 7 | loss: 0.1684745\n",
      "\tspeed: 0.0288s/iter; left time: 222.9443s\n",
      "\titers: 500, epoch: 7 | loss: 0.1572998\n",
      "\tspeed: 0.0299s/iter; left time: 228.5424s\n",
      "Epoch: 7 cost time: 17.118248224258423\n",
      "Epoch: 7, Steps: 581 | Train Loss: 0.1510782 Vali Loss: 0.1955236 Test Loss: 0.2382854\n",
      "Validation loss decreased (0.195676 --> 0.195524).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1599026\n",
      "\tspeed: 0.0957s/iter; left time: 713.3451s\n",
      "\titers: 200, epoch: 8 | loss: 0.1813557\n",
      "\tspeed: 0.0279s/iter; left time: 205.2873s\n",
      "\titers: 300, epoch: 8 | loss: 0.1841605\n",
      "\tspeed: 0.0282s/iter; left time: 204.7777s\n",
      "\titers: 400, epoch: 8 | loss: 0.1290865\n",
      "\tspeed: 0.0291s/iter; left time: 208.1265s\n",
      "\titers: 500, epoch: 8 | loss: 0.1879853\n",
      "\tspeed: 0.0283s/iter; left time: 199.9399s\n",
      "Epoch: 8 cost time: 16.35738778114319\n",
      "Epoch: 8, Steps: 581 | Train Loss: 0.1497974 Vali Loss: 0.1942732 Test Loss: 0.2391193\n",
      "Validation loss decreased (0.195524 --> 0.194273).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1191479\n",
      "\tspeed: 0.0918s/iter; left time: 631.1035s\n",
      "\titers: 200, epoch: 9 | loss: 0.3414498\n",
      "\tspeed: 0.0290s/iter; left time: 196.2448s\n",
      "\titers: 300, epoch: 9 | loss: 0.1041765\n",
      "\tspeed: 0.0284s/iter; left time: 189.7419s\n",
      "\titers: 400, epoch: 9 | loss: 0.1348661\n",
      "\tspeed: 0.0284s/iter; left time: 186.4452s\n",
      "\titers: 500, epoch: 9 | loss: 0.1828944\n",
      "\tspeed: 0.0280s/iter; left time: 181.3211s\n",
      "Epoch: 9 cost time: 16.408068418502808\n",
      "Epoch: 9, Steps: 581 | Train Loss: 0.1491332 Vali Loss: 0.1945929 Test Loss: 0.2387152\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.2089746\n",
      "\tspeed: 0.0927s/iter; left time: 583.3981s\n",
      "\titers: 200, epoch: 10 | loss: 0.1330690\n",
      "\tspeed: 0.0269s/iter; left time: 166.6553s\n",
      "\titers: 300, epoch: 10 | loss: 0.1278880\n",
      "\tspeed: 0.0284s/iter; left time: 172.8267s\n",
      "\titers: 400, epoch: 10 | loss: 0.1878436\n",
      "\tspeed: 0.0276s/iter; left time: 165.4696s\n",
      "\titers: 500, epoch: 10 | loss: 0.1086164\n",
      "\tspeed: 0.0280s/iter; left time: 164.9232s\n",
      "Epoch: 10 cost time: 16.394946813583374\n",
      "Epoch: 10, Steps: 581 | Train Loss: 0.1488499 Vali Loss: 0.1950766 Test Loss: 0.2382837\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.1255507\n",
      "\tspeed: 0.0931s/iter; left time: 531.5858s\n",
      "\titers: 200, epoch: 11 | loss: 0.1644538\n",
      "\tspeed: 0.0274s/iter; left time: 153.5854s\n",
      "\titers: 300, epoch: 11 | loss: 0.2486502\n",
      "\tspeed: 0.0277s/iter; left time: 152.4086s\n",
      "\titers: 400, epoch: 11 | loss: 0.1408719\n",
      "\tspeed: 0.0295s/iter; left time: 159.8865s\n",
      "\titers: 500, epoch: 11 | loss: 0.1298051\n",
      "\tspeed: 0.0273s/iter; left time: 145.2008s\n",
      "Epoch: 11 cost time: 16.252798318862915\n",
      "Epoch: 11, Steps: 581 | Train Loss: 0.1483120 Vali Loss: 0.1946610 Test Loss: 0.2383854\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl96_ll32_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "Test cost time: 1.8350s\n",
      "test shape: (182, 32, 6, 1) (182, 32, 6, 1)\n",
      "test shape: (5824, 6, 1) (5824, 6, 1)\n",
      "mse:0.2397218942642212, mae:0.3186867833137512\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl96_ll32_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1737.8587646484375\n",
      "MAE:  27.134227752685547\n",
      "RMSE: 41.6876335144043\n",
      "MAPE: 0.3257046639919281\n",
      "MSPE: 0.4778175354003906\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl96_ll32_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20937\n",
      "[DEBUG] Original dataset length: 20937\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18596\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6628\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "\titers: 100, epoch: 1 | loss: 0.3372689\n",
      "\tspeed: 0.0298s/iter; left time: 343.0952s\n",
      "\titers: 200, epoch: 1 | loss: 0.2086304\n",
      "\tspeed: 0.0279s/iter; left time: 318.7687s\n",
      "\titers: 300, epoch: 1 | loss: 0.3501234\n",
      "\tspeed: 0.0289s/iter; left time: 326.6964s\n",
      "\titers: 400, epoch: 1 | loss: 0.1883357\n",
      "\tspeed: 0.0276s/iter; left time: 309.8574s\n",
      "\titers: 500, epoch: 1 | loss: 0.1636199\n",
      "\tspeed: 0.0284s/iter; left time: 316.1378s\n",
      "Epoch: 1 cost time: 16.605459213256836\n",
      "Epoch: 1, Steps: 581 | Train Loss: 0.3050989 Vali Loss: 0.2339061 Test Loss: 0.2862473\n",
      "Validation loss decreased (inf --> 0.233906).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1483477\n",
      "\tspeed: 0.0943s/iter; left time: 1031.2286s\n",
      "\titers: 200, epoch: 2 | loss: 0.2131170\n",
      "\tspeed: 0.0276s/iter; left time: 299.4567s\n",
      "\titers: 300, epoch: 2 | loss: 0.2103228\n",
      "\tspeed: 0.0283s/iter; left time: 303.9497s\n",
      "\titers: 400, epoch: 2 | loss: 0.2018629\n",
      "\tspeed: 0.0283s/iter; left time: 301.2447s\n",
      "\titers: 500, epoch: 2 | loss: 0.2033799\n",
      "\tspeed: 0.0291s/iter; left time: 306.4344s\n",
      "Epoch: 2 cost time: 16.36900019645691\n",
      "Epoch: 2, Steps: 581 | Train Loss: 0.2180200 Vali Loss: 0.2157943 Test Loss: 0.2566753\n",
      "Validation loss decreased (0.233906 --> 0.215794).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1822159\n",
      "\tspeed: 0.0928s/iter; left time: 961.5705s\n",
      "\titers: 200, epoch: 3 | loss: 0.1733583\n",
      "\tspeed: 0.0279s/iter; left time: 285.7308s\n",
      "\titers: 300, epoch: 3 | loss: 0.2037009\n",
      "\tspeed: 0.0294s/iter; left time: 298.1861s\n",
      "\titers: 400, epoch: 3 | loss: 0.1843183\n",
      "\tspeed: 0.0269s/iter; left time: 270.7431s\n",
      "\titers: 500, epoch: 3 | loss: 0.3564572\n",
      "\tspeed: 0.0271s/iter; left time: 270.1093s\n",
      "Epoch: 3 cost time: 16.05717396736145\n",
      "Epoch: 3, Steps: 581 | Train Loss: 0.1862118 Vali Loss: 0.2001068 Test Loss: 0.2446880\n",
      "Validation loss decreased (0.215794 --> 0.200107).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1134882\n",
      "\tspeed: 0.0947s/iter; left time: 926.3752s\n",
      "\titers: 200, epoch: 4 | loss: 0.2132160\n",
      "\tspeed: 0.0284s/iter; left time: 274.9621s\n",
      "\titers: 300, epoch: 4 | loss: 0.1588898\n",
      "\tspeed: 0.0293s/iter; left time: 280.2736s\n",
      "\titers: 400, epoch: 4 | loss: 0.1369320\n",
      "\tspeed: 0.0276s/iter; left time: 261.7557s\n",
      "\titers: 500, epoch: 4 | loss: 0.1440051\n",
      "\tspeed: 0.0285s/iter; left time: 267.5541s\n",
      "Epoch: 4 cost time: 16.938809394836426\n",
      "Epoch: 4, Steps: 581 | Train Loss: 0.1695402 Vali Loss: 0.2001305 Test Loss: 0.2484150\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1647177\n",
      "\tspeed: 0.0925s/iter; left time: 850.7654s\n",
      "\titers: 200, epoch: 5 | loss: 0.1276367\n",
      "\tspeed: 0.0280s/iter; left time: 255.0501s\n",
      "\titers: 300, epoch: 5 | loss: 0.1760542\n",
      "\tspeed: 0.0279s/iter; left time: 250.6004s\n",
      "\titers: 400, epoch: 5 | loss: 0.1375045\n",
      "\tspeed: 0.0306s/iter; left time: 272.4412s\n",
      "\titers: 500, epoch: 5 | loss: 0.1145811\n",
      "\tspeed: 0.0295s/iter; left time: 259.3155s\n",
      "Epoch: 5 cost time: 16.695690870285034\n",
      "Epoch: 5, Steps: 581 | Train Loss: 0.1613608 Vali Loss: 0.1984159 Test Loss: 0.2403475\n",
      "Validation loss decreased (0.200107 --> 0.198416).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1291688\n",
      "\tspeed: 0.0961s/iter; left time: 828.2004s\n",
      "\titers: 200, epoch: 6 | loss: 0.1433322\n",
      "\tspeed: 0.0345s/iter; left time: 293.6784s\n",
      "\titers: 300, epoch: 6 | loss: 0.1608097\n",
      "\tspeed: 0.0299s/iter; left time: 251.3868s\n",
      "\titers: 400, epoch: 6 | loss: 0.1005344\n",
      "\tspeed: 0.0294s/iter; left time: 244.1686s\n",
      "\titers: 500, epoch: 6 | loss: 0.1261130\n",
      "\tspeed: 0.0299s/iter; left time: 245.7477s\n",
      "Epoch: 6 cost time: 17.80803918838501\n",
      "Epoch: 6, Steps: 581 | Train Loss: 0.1555723 Vali Loss: 0.1964544 Test Loss: 0.2400673\n",
      "Validation loss decreased (0.198416 --> 0.196454).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1171443\n",
      "\tspeed: 0.1029s/iter; left time: 826.9547s\n",
      "\titers: 200, epoch: 7 | loss: 0.1568757\n",
      "\tspeed: 0.0309s/iter; left time: 244.9362s\n",
      "\titers: 300, epoch: 7 | loss: 0.1931754\n",
      "\tspeed: 0.0305s/iter; left time: 239.3195s\n",
      "\titers: 400, epoch: 7 | loss: 0.1700881\n",
      "\tspeed: 0.0310s/iter; left time: 239.5589s\n",
      "\titers: 500, epoch: 7 | loss: 0.1947052\n",
      "\tspeed: 0.0303s/iter; left time: 231.1674s\n",
      "Epoch: 7 cost time: 17.892686128616333\n",
      "Epoch: 7, Steps: 581 | Train Loss: 0.1525681 Vali Loss: 0.1961497 Test Loss: 0.2402383\n",
      "Validation loss decreased (0.196454 --> 0.196150).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1337827\n",
      "\tspeed: 0.0995s/iter; left time: 741.9951s\n",
      "\titers: 200, epoch: 8 | loss: 0.1257205\n",
      "\tspeed: 0.0307s/iter; left time: 226.0847s\n",
      "\titers: 300, epoch: 8 | loss: 0.1613111\n",
      "\tspeed: 0.0297s/iter; left time: 215.6232s\n",
      "\titers: 400, epoch: 8 | loss: 0.1841158\n",
      "\tspeed: 0.0288s/iter; left time: 206.0436s\n",
      "\titers: 500, epoch: 8 | loss: 0.1739554\n",
      "\tspeed: 0.0274s/iter; left time: 193.2734s\n",
      "Epoch: 8 cost time: 16.890886068344116\n",
      "Epoch: 8, Steps: 581 | Train Loss: 0.1514007 Vali Loss: 0.1965811 Test Loss: 0.2402120\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1053330\n",
      "\tspeed: 0.0923s/iter; left time: 634.1412s\n",
      "\titers: 200, epoch: 9 | loss: 0.1588119\n",
      "\tspeed: 0.0276s/iter; left time: 187.0117s\n",
      "\titers: 300, epoch: 9 | loss: 0.1067147\n",
      "\tspeed: 0.0284s/iter; left time: 189.5437s\n",
      "\titers: 400, epoch: 9 | loss: 0.1598008\n",
      "\tspeed: 0.0289s/iter; left time: 189.8966s\n",
      "\titers: 500, epoch: 9 | loss: 0.1132383\n",
      "\tspeed: 0.0296s/iter; left time: 191.6891s\n",
      "Epoch: 9 cost time: 16.672213554382324\n",
      "Epoch: 9, Steps: 581 | Train Loss: 0.1495143 Vali Loss: 0.1962012 Test Loss: 0.2425885\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.2072050\n",
      "\tspeed: 0.0936s/iter; left time: 589.1514s\n",
      "\titers: 200, epoch: 10 | loss: 0.2806942\n",
      "\tspeed: 0.0288s/iter; left time: 178.2678s\n",
      "\titers: 300, epoch: 10 | loss: 0.0896518\n",
      "\tspeed: 0.0307s/iter; left time: 187.0692s\n",
      "\titers: 400, epoch: 10 | loss: 0.1320543\n",
      "\tspeed: 0.0298s/iter; left time: 178.5338s\n",
      "\titers: 500, epoch: 10 | loss: 0.1326341\n",
      "\tspeed: 0.0287s/iter; left time: 168.9725s\n",
      "Epoch: 10 cost time: 17.039920568466187\n",
      "Epoch: 10, Steps: 581 | Train Loss: 0.1499410 Vali Loss: 0.1956801 Test Loss: 0.2411333\n",
      "Validation loss decreased (0.196150 --> 0.195680).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.1624259\n",
      "\tspeed: 0.0951s/iter; left time: 542.9751s\n",
      "\titers: 200, epoch: 11 | loss: 0.1344058\n",
      "\tspeed: 0.0287s/iter; left time: 161.1852s\n",
      "\titers: 300, epoch: 11 | loss: 0.1296098\n",
      "\tspeed: 0.0291s/iter; left time: 160.3044s\n",
      "\titers: 400, epoch: 11 | loss: 0.2143286\n",
      "\tspeed: 0.0283s/iter; left time: 152.9032s\n",
      "\titers: 500, epoch: 11 | loss: 0.1116835\n",
      "\tspeed: 0.0291s/iter; left time: 154.6865s\n",
      "Epoch: 11 cost time: 17.010723114013672\n",
      "Epoch: 11, Steps: 581 | Train Loss: 0.1492630 Vali Loss: 0.1966321 Test Loss: 0.2415806\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.1767681\n",
      "\tspeed: 0.0955s/iter; left time: 490.0248s\n",
      "\titers: 200, epoch: 12 | loss: 0.1263164\n",
      "\tspeed: 0.0294s/iter; left time: 148.0982s\n",
      "\titers: 300, epoch: 12 | loss: 0.1180085\n",
      "\tspeed: 0.0301s/iter; left time: 148.2230s\n",
      "\titers: 400, epoch: 12 | loss: 0.1849532\n",
      "\tspeed: 0.0311s/iter; left time: 150.0986s\n",
      "\titers: 500, epoch: 12 | loss: 0.1537548\n",
      "\tspeed: 0.0303s/iter; left time: 143.3522s\n",
      "Epoch: 12 cost time: 17.411134481430054\n",
      "Epoch: 12, Steps: 581 | Train Loss: 0.1496545 Vali Loss: 0.1963362 Test Loss: 0.2401657\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      "\titers: 100, epoch: 13 | loss: 0.1223648\n",
      "\tspeed: 0.0966s/iter; left time: 439.3770s\n",
      "\titers: 200, epoch: 13 | loss: 0.1034099\n",
      "\tspeed: 0.0324s/iter; left time: 144.1605s\n",
      "\titers: 300, epoch: 13 | loss: 0.1231311\n",
      "\tspeed: 0.0295s/iter; left time: 128.2742s\n",
      "\titers: 400, epoch: 13 | loss: 0.1272315\n",
      "\tspeed: 0.0299s/iter; left time: 126.9554s\n",
      "\titers: 500, epoch: 13 | loss: 0.2569481\n",
      "\tspeed: 0.0294s/iter; left time: 122.1708s\n",
      "Epoch: 13 cost time: 17.61049723625183\n",
      "Epoch: 13, Steps: 581 | Train Loss: 0.1492441 Vali Loss: 0.1972076 Test Loss: 0.2416220\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl96_ll32_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5834\n",
      "Test cost time: 1.9924s\n",
      "test shape: (182, 32, 6, 1) (182, 32, 6, 1)\n",
      "test shape: (5824, 6, 1) (5824, 6, 1)\n",
      "mse:0.24090014398097992, mae:0.32561028003692627\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl96_ll32_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1746.4002685546875\n",
      "MAE:  27.723718643188477\n",
      "RMSE: 41.789955139160156\n",
      "MAPE: 0.35216984152793884\n",
      "MSPE: 0.598120391368866\n",
      ">>>>>>>Running time saved<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Running seq_len=120, label_len=40, pred_len=6\n",
      "Args in experiment:\n",
      "Namespace(model='informer', data='traffic_full', root_path='../', data_path='traffic_full.csv', features='S', target='flow', freq='h', checkpoints='./checkpoints/', seq_len=120, label_len=40, pred_len=6, enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=2, d_layers=1, s_layers=[3, 2, 1], d_ff=2048, factor=5, padding=0, distil=True, dropout=0.05, attn='prob', embed='timeF', activation='gelu', output_attention=False, do_predict=False, mix=True, cols=None, num_workers=0, itr=10, train_epochs=20, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, inverse=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', detail_freq='h')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl120_ll40_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20913\n",
      "[DEBUG] Original dataset length: 20913\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18236\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6556\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "\titers: 100, epoch: 1 | loss: 0.4553133\n",
      "\tspeed: 0.0470s/iter; left time: 529.9113s\n",
      "\titers: 200, epoch: 1 | loss: 0.3306265\n",
      "\tspeed: 0.0330s/iter; left time: 368.7784s\n",
      "\titers: 300, epoch: 1 | loss: 0.2878742\n",
      "\tspeed: 0.0314s/iter; left time: 348.3570s\n",
      "\titers: 400, epoch: 1 | loss: 0.1521170\n",
      "\tspeed: 0.0315s/iter; left time: 346.0668s\n",
      "\titers: 500, epoch: 1 | loss: 0.1751460\n",
      "\tspeed: 0.0324s/iter; left time: 352.5383s\n",
      "Epoch: 1 cost time: 18.825446844100952\n",
      "Epoch: 1, Steps: 569 | Train Loss: 0.3226325 Vali Loss: 0.2235380 Test Loss: 0.2535410\n",
      "Validation loss decreased (inf --> 0.223538).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1347378\n",
      "\tspeed: 0.1043s/iter; left time: 1117.7940s\n",
      "\titers: 200, epoch: 2 | loss: 0.2611085\n",
      "\tspeed: 0.0327s/iter; left time: 346.6737s\n",
      "\titers: 300, epoch: 2 | loss: 0.1724055\n",
      "\tspeed: 0.0315s/iter; left time: 331.5747s\n",
      "\titers: 400, epoch: 2 | loss: 0.2393550\n",
      "\tspeed: 0.0336s/iter; left time: 350.1348s\n",
      "\titers: 500, epoch: 2 | loss: 0.1468494\n",
      "\tspeed: 0.0325s/iter; left time: 335.5011s\n",
      "Epoch: 2 cost time: 18.5301616191864\n",
      "Epoch: 2, Steps: 569 | Train Loss: 0.2130172 Vali Loss: 0.2077473 Test Loss: 0.2476104\n",
      "Validation loss decreased (0.223538 --> 0.207747).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2301630\n",
      "\tspeed: 0.1051s/iter; left time: 1066.0234s\n",
      "\titers: 200, epoch: 3 | loss: 0.1553132\n",
      "\tspeed: 0.0321s/iter; left time: 321.9879s\n",
      "\titers: 300, epoch: 3 | loss: 0.1873459\n",
      "\tspeed: 0.0318s/iter; left time: 316.0217s\n",
      "\titers: 400, epoch: 3 | loss: 0.1904694\n",
      "\tspeed: 0.0318s/iter; left time: 312.6866s\n",
      "\titers: 500, epoch: 3 | loss: 0.2024996\n",
      "\tspeed: 0.0331s/iter; left time: 322.6269s\n",
      "Epoch: 3 cost time: 18.571046590805054\n",
      "Epoch: 3, Steps: 569 | Train Loss: 0.1832020 Vali Loss: 0.2032261 Test Loss: 0.2374653\n",
      "Validation loss decreased (0.207747 --> 0.203226).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1656613\n",
      "\tspeed: 0.1023s/iter; left time: 979.0859s\n",
      "\titers: 200, epoch: 4 | loss: 0.1787421\n",
      "\tspeed: 0.0312s/iter; left time: 295.4319s\n",
      "\titers: 300, epoch: 4 | loss: 0.1706779\n",
      "\tspeed: 0.0322s/iter; left time: 301.4055s\n",
      "\titers: 400, epoch: 4 | loss: 0.0919932\n",
      "\tspeed: 0.0336s/iter; left time: 311.9787s\n",
      "\titers: 500, epoch: 4 | loss: 0.1456327\n",
      "\tspeed: 0.0303s/iter; left time: 278.3320s\n",
      "Epoch: 4 cost time: 18.02657723426819\n",
      "Epoch: 4, Steps: 569 | Train Loss: 0.1664204 Vali Loss: 0.2039874 Test Loss: 0.2388953\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1484377\n",
      "\tspeed: 0.0969s/iter; left time: 872.7484s\n",
      "\titers: 200, epoch: 5 | loss: 0.1293800\n",
      "\tspeed: 0.0313s/iter; left time: 278.6102s\n",
      "\titers: 300, epoch: 5 | loss: 0.1267509\n",
      "\tspeed: 0.0313s/iter; left time: 275.4579s\n",
      "\titers: 400, epoch: 5 | loss: 0.2547194\n",
      "\tspeed: 0.0309s/iter; left time: 269.2873s\n",
      "\titers: 500, epoch: 5 | loss: 0.1056667\n",
      "\tspeed: 0.0302s/iter; left time: 260.0768s\n",
      "Epoch: 5 cost time: 17.737759590148926\n",
      "Epoch: 5, Steps: 569 | Train Loss: 0.1575613 Vali Loss: 0.1962440 Test Loss: 0.2322795\n",
      "Validation loss decreased (0.203226 --> 0.196244).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1979884\n",
      "\tspeed: 0.1048s/iter; left time: 883.8552s\n",
      "\titers: 200, epoch: 6 | loss: 0.1022021\n",
      "\tspeed: 0.0313s/iter; left time: 260.8098s\n",
      "\titers: 300, epoch: 6 | loss: 0.1677550\n",
      "\tspeed: 0.0327s/iter; left time: 269.1517s\n",
      "\titers: 400, epoch: 6 | loss: 0.0919438\n",
      "\tspeed: 0.0319s/iter; left time: 259.1863s\n",
      "\titers: 500, epoch: 6 | loss: 0.1200634\n",
      "\tspeed: 0.0316s/iter; left time: 253.9082s\n",
      "Epoch: 6 cost time: 18.10046410560608\n",
      "Epoch: 6, Steps: 569 | Train Loss: 0.1528238 Vali Loss: 0.1984592 Test Loss: 0.2328036\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1978204\n",
      "\tspeed: 0.0998s/iter; left time: 785.0531s\n",
      "\titers: 200, epoch: 7 | loss: 0.1487885\n",
      "\tspeed: 0.0311s/iter; left time: 241.5026s\n",
      "\titers: 300, epoch: 7 | loss: 0.1057459\n",
      "\tspeed: 0.0310s/iter; left time: 237.3805s\n",
      "\titers: 400, epoch: 7 | loss: 0.1440294\n",
      "\tspeed: 0.0317s/iter; left time: 240.2074s\n",
      "\titers: 500, epoch: 7 | loss: 0.1412336\n",
      "\tspeed: 0.0312s/iter; left time: 233.1026s\n",
      "Epoch: 7 cost time: 18.11031460762024\n",
      "Epoch: 7, Steps: 569 | Train Loss: 0.1495291 Vali Loss: 0.1959982 Test Loss: 0.2310688\n",
      "Validation loss decreased (0.196244 --> 0.195998).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1153688\n",
      "\tspeed: 0.1036s/iter; left time: 756.3079s\n",
      "\titers: 200, epoch: 8 | loss: 0.1030199\n",
      "\tspeed: 0.0316s/iter; left time: 227.2308s\n",
      "\titers: 300, epoch: 8 | loss: 0.2040917\n",
      "\tspeed: 0.0330s/iter; left time: 233.9626s\n",
      "\titers: 400, epoch: 8 | loss: 0.0933145\n",
      "\tspeed: 0.0313s/iter; left time: 218.9802s\n",
      "\titers: 500, epoch: 8 | loss: 0.1107187\n",
      "\tspeed: 0.0315s/iter; left time: 217.0488s\n",
      "Epoch: 8 cost time: 17.96480679512024\n",
      "Epoch: 8, Steps: 569 | Train Loss: 0.1482434 Vali Loss: 0.1953382 Test Loss: 0.2305986\n",
      "Validation loss decreased (0.195998 --> 0.195338).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1287268\n",
      "\tspeed: 0.1021s/iter; left time: 687.2240s\n",
      "\titers: 200, epoch: 9 | loss: 0.1964132\n",
      "\tspeed: 0.0318s/iter; left time: 211.1275s\n",
      "\titers: 300, epoch: 9 | loss: 0.0855504\n",
      "\tspeed: 0.0317s/iter; left time: 206.7404s\n",
      "\titers: 400, epoch: 9 | loss: 0.1192089\n",
      "\tspeed: 0.0314s/iter; left time: 202.1224s\n",
      "\titers: 500, epoch: 9 | loss: 0.1104812\n",
      "\tspeed: 0.0332s/iter; left time: 210.1495s\n",
      "Epoch: 9 cost time: 18.372962951660156\n",
      "Epoch: 9, Steps: 569 | Train Loss: 0.1474726 Vali Loss: 0.1955745 Test Loss: 0.2321353\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.1168683\n",
      "\tspeed: 0.1017s/iter; left time: 626.3588s\n",
      "\titers: 200, epoch: 10 | loss: 0.1306864\n",
      "\tspeed: 0.0329s/iter; left time: 199.3516s\n",
      "\titers: 300, epoch: 10 | loss: 0.1056237\n",
      "\tspeed: 0.0335s/iter; left time: 199.8708s\n",
      "\titers: 400, epoch: 10 | loss: 0.1642733\n",
      "\tspeed: 0.0317s/iter; left time: 185.5826s\n",
      "\titers: 500, epoch: 10 | loss: 0.1135114\n",
      "\tspeed: 0.0307s/iter; left time: 176.9472s\n",
      "Epoch: 10 cost time: 18.27262306213379\n",
      "Epoch: 10, Steps: 569 | Train Loss: 0.1466573 Vali Loss: 0.1960742 Test Loss: 0.2304416\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.1922295\n",
      "\tspeed: 0.1019s/iter; left time: 569.4615s\n",
      "\titers: 200, epoch: 11 | loss: 0.1711691\n",
      "\tspeed: 0.0316s/iter; left time: 173.2927s\n",
      "\titers: 300, epoch: 11 | loss: 0.1801522\n",
      "\tspeed: 0.0306s/iter; left time: 165.0945s\n",
      "\titers: 400, epoch: 11 | loss: 0.0887850\n",
      "\tspeed: 0.0318s/iter; left time: 168.1429s\n",
      "\titers: 500, epoch: 11 | loss: 0.1672632\n",
      "\tspeed: 0.0325s/iter; left time: 168.7455s\n",
      "Epoch: 11 cost time: 18.16086459159851\n",
      "Epoch: 11, Steps: 569 | Train Loss: 0.1464376 Vali Loss: 0.1965705 Test Loss: 0.2315025\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl120_ll40_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "Test cost time: 2.1273s\n",
      "test shape: (177, 32, 6, 1) (177, 32, 6, 1)\n",
      "test shape: (5664, 6, 1) (5664, 6, 1)\n",
      "mse:0.22976665198802948, mae:0.31899088621139526\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl120_ll40_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1665.6881103515625\n",
      "MAE:  27.160114288330078\n",
      "RMSE: 40.812843322753906\n",
      "MAPE: 0.3589257597923279\n",
      "MSPE: 0.6169126629829407\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl120_ll40_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20913\n",
      "[DEBUG] Original dataset length: 20913\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18236\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6556\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "\titers: 100, epoch: 1 | loss: 0.4294547\n",
      "\tspeed: 0.0316s/iter; left time: 356.3813s\n",
      "\titers: 200, epoch: 1 | loss: 0.1721715\n",
      "\tspeed: 0.0330s/iter; left time: 368.5745s\n",
      "\titers: 300, epoch: 1 | loss: 0.2371559\n",
      "\tspeed: 0.0323s/iter; left time: 357.6476s\n",
      "\titers: 400, epoch: 1 | loss: 0.2158575\n",
      "\tspeed: 0.0315s/iter; left time: 346.2558s\n",
      "\titers: 500, epoch: 1 | loss: 0.1755501\n",
      "\tspeed: 0.0328s/iter; left time: 356.5214s\n",
      "Epoch: 1 cost time: 18.401251077651978\n",
      "Epoch: 1, Steps: 569 | Train Loss: 0.3154464 Vali Loss: 0.2136638 Test Loss: 0.2637848\n",
      "Validation loss decreased (inf --> 0.213664).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1735065\n",
      "\tspeed: 0.1057s/iter; left time: 1131.8688s\n",
      "\titers: 200, epoch: 2 | loss: 0.2912261\n",
      "\tspeed: 0.0323s/iter; left time: 343.1214s\n",
      "\titers: 300, epoch: 2 | loss: 0.1918055\n",
      "\tspeed: 0.0317s/iter; left time: 332.9514s\n",
      "\titers: 400, epoch: 2 | loss: 0.1622507\n",
      "\tspeed: 0.0332s/iter; left time: 345.3152s\n",
      "\titers: 500, epoch: 2 | loss: 0.2043184\n",
      "\tspeed: 0.0331s/iter; left time: 341.0858s\n",
      "Epoch: 2 cost time: 18.45787525177002\n",
      "Epoch: 2, Steps: 569 | Train Loss: 0.2115778 Vali Loss: 0.2251747 Test Loss: 0.2708699\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1470486\n",
      "\tspeed: 0.1025s/iter; left time: 1039.7934s\n",
      "\titers: 200, epoch: 3 | loss: 0.2417262\n",
      "\tspeed: 0.0336s/iter; left time: 337.6892s\n",
      "\titers: 300, epoch: 3 | loss: 0.1718275\n",
      "\tspeed: 0.0331s/iter; left time: 329.4990s\n",
      "\titers: 400, epoch: 3 | loss: 0.1420913\n",
      "\tspeed: 0.0341s/iter; left time: 335.3655s\n",
      "\titers: 500, epoch: 3 | loss: 0.1967448\n",
      "\tspeed: 0.0331s/iter; left time: 322.6759s\n",
      "Epoch: 3 cost time: 19.235095977783203\n",
      "Epoch: 3, Steps: 569 | Train Loss: 0.1838869 Vali Loss: 0.2063728 Test Loss: 0.2388511\n",
      "Validation loss decreased (0.213664 --> 0.206373).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2369355\n",
      "\tspeed: 0.1097s/iter; left time: 1049.9072s\n",
      "\titers: 200, epoch: 4 | loss: 0.1302472\n",
      "\tspeed: 0.0347s/iter; left time: 328.5637s\n",
      "\titers: 300, epoch: 4 | loss: 0.1762740\n",
      "\tspeed: 0.0355s/iter; left time: 332.3644s\n",
      "\titers: 400, epoch: 4 | loss: 0.2036752\n",
      "\tspeed: 0.0322s/iter; left time: 298.6450s\n",
      "\titers: 500, epoch: 4 | loss: 0.1901546\n",
      "\tspeed: 0.0326s/iter; left time: 298.8500s\n",
      "Epoch: 4 cost time: 19.145807027816772\n",
      "Epoch: 4, Steps: 569 | Train Loss: 0.1654610 Vali Loss: 0.1996464 Test Loss: 0.2381997\n",
      "Validation loss decreased (0.206373 --> 0.199646).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1376283\n",
      "\tspeed: 0.1054s/iter; left time: 948.9271s\n",
      "\titers: 200, epoch: 5 | loss: 0.2344193\n",
      "\tspeed: 0.0319s/iter; left time: 283.9395s\n",
      "\titers: 300, epoch: 5 | loss: 0.0897647\n",
      "\tspeed: 0.0306s/iter; left time: 269.4781s\n",
      "\titers: 400, epoch: 5 | loss: 0.1852658\n",
      "\tspeed: 0.0320s/iter; left time: 278.7110s\n",
      "\titers: 500, epoch: 5 | loss: 0.1763287\n",
      "\tspeed: 0.0327s/iter; left time: 281.6345s\n",
      "Epoch: 5 cost time: 18.23347282409668\n",
      "Epoch: 5, Steps: 569 | Train Loss: 0.1567864 Vali Loss: 0.1958582 Test Loss: 0.2366671\n",
      "Validation loss decreased (0.199646 --> 0.195858).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1455781\n",
      "\tspeed: 0.1013s/iter; left time: 854.2651s\n",
      "\titers: 200, epoch: 6 | loss: 0.0868689\n",
      "\tspeed: 0.0316s/iter; left time: 263.0754s\n",
      "\titers: 300, epoch: 6 | loss: 0.2449189\n",
      "\tspeed: 0.0323s/iter; left time: 266.4069s\n",
      "\titers: 400, epoch: 6 | loss: 0.0991942\n",
      "\tspeed: 0.0350s/iter; left time: 284.8749s\n",
      "\titers: 500, epoch: 6 | loss: 0.1447518\n",
      "\tspeed: 0.0320s/iter; left time: 256.8688s\n",
      "Epoch: 6 cost time: 18.356728315353394\n",
      "Epoch: 6, Steps: 569 | Train Loss: 0.1521969 Vali Loss: 0.1994038 Test Loss: 0.2414132\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1376810\n",
      "\tspeed: 0.1013s/iter; left time: 796.5520s\n",
      "\titers: 200, epoch: 7 | loss: 0.1460597\n",
      "\tspeed: 0.0314s/iter; left time: 244.2020s\n",
      "\titers: 300, epoch: 7 | loss: 0.1752789\n",
      "\tspeed: 0.0324s/iter; left time: 248.0977s\n",
      "\titers: 400, epoch: 7 | loss: 0.2269824\n",
      "\tspeed: 0.0319s/iter; left time: 241.7645s\n",
      "\titers: 500, epoch: 7 | loss: 0.1230298\n",
      "\tspeed: 0.0339s/iter; left time: 252.7698s\n",
      "Epoch: 7 cost time: 18.344073057174683\n",
      "Epoch: 7, Steps: 569 | Train Loss: 0.1493538 Vali Loss: 0.1998070 Test Loss: 0.2396586\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0896185\n",
      "\tspeed: 0.1043s/iter; left time: 761.0615s\n",
      "\titers: 200, epoch: 8 | loss: 0.1258863\n",
      "\tspeed: 0.0331s/iter; left time: 238.2729s\n",
      "\titers: 300, epoch: 8 | loss: 0.1366257\n",
      "\tspeed: 0.0325s/iter; left time: 230.5713s\n",
      "\titers: 400, epoch: 8 | loss: 0.1148849\n",
      "\tspeed: 0.0331s/iter; left time: 231.8516s\n",
      "\titers: 500, epoch: 8 | loss: 0.1612406\n",
      "\tspeed: 0.0341s/iter; left time: 235.1530s\n",
      "Epoch: 8 cost time: 18.819634914398193\n",
      "Epoch: 8, Steps: 569 | Train Loss: 0.1468869 Vali Loss: 0.2005268 Test Loss: 0.2415429\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl120_ll40_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "Test cost time: 2.1798s\n",
      "test shape: (177, 32, 6, 1) (177, 32, 6, 1)\n",
      "test shape: (5664, 6, 1) (5664, 6, 1)\n",
      "mse:0.23820710182189941, mae:0.3282489776611328\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl120_ll40_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1726.8770751953125\n",
      "MAE:  27.948383331298828\n",
      "RMSE: 41.55570983886719\n",
      "MAPE: 0.3964836299419403\n",
      "MSPE: 0.816170334815979\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl120_ll40_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20913\n",
      "[DEBUG] Original dataset length: 20913\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18236\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6556\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "\titers: 100, epoch: 1 | loss: 0.2915363\n",
      "\tspeed: 0.0333s/iter; left time: 375.1242s\n",
      "\titers: 200, epoch: 1 | loss: 0.3063931\n",
      "\tspeed: 0.0339s/iter; left time: 378.6663s\n",
      "\titers: 300, epoch: 1 | loss: 0.1821838\n",
      "\tspeed: 0.0349s/iter; left time: 387.2495s\n",
      "\titers: 400, epoch: 1 | loss: 0.1441603\n",
      "\tspeed: 0.0348s/iter; left time: 382.2930s\n",
      "\titers: 500, epoch: 1 | loss: 0.2088764\n",
      "\tspeed: 0.0339s/iter; left time: 368.7839s\n",
      "Epoch: 1 cost time: 19.396629095077515\n",
      "Epoch: 1, Steps: 569 | Train Loss: 0.3165453 Vali Loss: 0.2079853 Test Loss: 0.2549767\n",
      "Validation loss decreased (inf --> 0.207985).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2485132\n",
      "\tspeed: 0.1071s/iter; left time: 1146.7772s\n",
      "\titers: 200, epoch: 2 | loss: 0.2687142\n",
      "\tspeed: 0.0315s/iter; left time: 334.6767s\n",
      "\titers: 300, epoch: 2 | loss: 0.1747961\n",
      "\tspeed: 0.0320s/iter; left time: 335.8891s\n",
      "\titers: 400, epoch: 2 | loss: 0.3099920\n",
      "\tspeed: 0.0307s/iter; left time: 319.8910s\n",
      "\titers: 500, epoch: 2 | loss: 0.1995405\n",
      "\tspeed: 0.0324s/iter; left time: 333.8008s\n",
      "Epoch: 2 cost time: 18.150396823883057\n",
      "Epoch: 2, Steps: 569 | Train Loss: 0.2174958 Vali Loss: 0.2084870 Test Loss: 0.2513059\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2662652\n",
      "\tspeed: 0.1014s/iter; left time: 1028.2837s\n",
      "\titers: 200, epoch: 3 | loss: 0.1244645\n",
      "\tspeed: 0.0334s/iter; left time: 335.7074s\n",
      "\titers: 300, epoch: 3 | loss: 0.1784809\n",
      "\tspeed: 0.0329s/iter; left time: 327.5390s\n",
      "\titers: 400, epoch: 3 | loss: 0.1763126\n",
      "\tspeed: 0.0326s/iter; left time: 320.9093s\n",
      "\titers: 500, epoch: 3 | loss: 0.2358775\n",
      "\tspeed: 0.0321s/iter; left time: 312.6831s\n",
      "Epoch: 3 cost time: 18.604349851608276\n",
      "Epoch: 3, Steps: 569 | Train Loss: 0.1857116 Vali Loss: 0.2154294 Test Loss: 0.2570504\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2054307\n",
      "\tspeed: 0.1014s/iter; left time: 971.1499s\n",
      "\titers: 200, epoch: 4 | loss: 0.2105636\n",
      "\tspeed: 0.0325s/iter; left time: 308.1255s\n",
      "\titers: 300, epoch: 4 | loss: 0.0924081\n",
      "\tspeed: 0.0325s/iter; left time: 305.0373s\n",
      "\titers: 400, epoch: 4 | loss: 0.1568003\n",
      "\tspeed: 0.0318s/iter; left time: 294.7259s\n",
      "\titers: 500, epoch: 4 | loss: 0.0909878\n",
      "\tspeed: 0.0331s/iter; left time: 303.5282s\n",
      "Epoch: 4 cost time: 18.226266860961914\n",
      "Epoch: 4, Steps: 569 | Train Loss: 0.1697062 Vali Loss: 0.1984644 Test Loss: 0.2424494\n",
      "Validation loss decreased (0.207985 --> 0.198464).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1520823\n",
      "\tspeed: 0.1019s/iter; left time: 917.4723s\n",
      "\titers: 200, epoch: 5 | loss: 0.2548323\n",
      "\tspeed: 0.0338s/iter; left time: 301.3282s\n",
      "\titers: 300, epoch: 5 | loss: 0.1361580\n",
      "\tspeed: 0.0334s/iter; left time: 294.3800s\n",
      "\titers: 400, epoch: 5 | loss: 0.1236806\n",
      "\tspeed: 0.0339s/iter; left time: 294.8158s\n",
      "\titers: 500, epoch: 5 | loss: 0.1302031\n",
      "\tspeed: 0.0346s/iter; left time: 297.4111s\n",
      "Epoch: 5 cost time: 19.177255153656006\n",
      "Epoch: 5, Steps: 569 | Train Loss: 0.1603129 Vali Loss: 0.1955538 Test Loss: 0.2382378\n",
      "Validation loss decreased (0.198464 --> 0.195554).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1137917\n",
      "\tspeed: 0.1110s/iter; left time: 936.5891s\n",
      "\titers: 200, epoch: 6 | loss: 0.1327896\n",
      "\tspeed: 0.0314s/iter; left time: 262.1231s\n",
      "\titers: 300, epoch: 6 | loss: 0.0989678\n",
      "\tspeed: 0.0342s/iter; left time: 281.9463s\n",
      "\titers: 400, epoch: 6 | loss: 0.2127931\n",
      "\tspeed: 0.0354s/iter; left time: 287.7033s\n",
      "\titers: 500, epoch: 6 | loss: 0.0836625\n",
      "\tspeed: 0.0341s/iter; left time: 274.3718s\n",
      "Epoch: 6 cost time: 19.400309324264526\n",
      "Epoch: 6, Steps: 569 | Train Loss: 0.1550140 Vali Loss: 0.1972881 Test Loss: 0.2395853\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1523021\n",
      "\tspeed: 0.1079s/iter; left time: 848.7730s\n",
      "\titers: 200, epoch: 7 | loss: 0.1269354\n",
      "\tspeed: 0.0329s/iter; left time: 255.6854s\n",
      "\titers: 300, epoch: 7 | loss: 0.1127383\n",
      "\tspeed: 0.0326s/iter; left time: 250.0958s\n",
      "\titers: 400, epoch: 7 | loss: 0.1421075\n",
      "\tspeed: 0.0324s/iter; left time: 245.2409s\n",
      "\titers: 500, epoch: 7 | loss: 0.1184331\n",
      "\tspeed: 0.0318s/iter; left time: 237.5801s\n",
      "Epoch: 7 cost time: 18.814239025115967\n",
      "Epoch: 7, Steps: 569 | Train Loss: 0.1521773 Vali Loss: 0.1954945 Test Loss: 0.2387045\n",
      "Validation loss decreased (0.195554 --> 0.195495).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2515854\n",
      "\tspeed: 0.1018s/iter; left time: 743.2051s\n",
      "\titers: 200, epoch: 8 | loss: 0.1694063\n",
      "\tspeed: 0.0310s/iter; left time: 222.7851s\n",
      "\titers: 300, epoch: 8 | loss: 0.1016547\n",
      "\tspeed: 0.0329s/iter; left time: 233.8121s\n",
      "\titers: 400, epoch: 8 | loss: 0.2283305\n",
      "\tspeed: 0.0320s/iter; left time: 223.8190s\n",
      "\titers: 500, epoch: 8 | loss: 0.1262286\n",
      "\tspeed: 0.0317s/iter; left time: 218.7232s\n",
      "Epoch: 8 cost time: 18.047577142715454\n",
      "Epoch: 8, Steps: 569 | Train Loss: 0.1501003 Vali Loss: 0.1940493 Test Loss: 0.2366453\n",
      "Validation loss decreased (0.195495 --> 0.194049).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1955803\n",
      "\tspeed: 0.1042s/iter; left time: 701.4658s\n",
      "\titers: 200, epoch: 9 | loss: 0.1544941\n",
      "\tspeed: 0.0309s/iter; left time: 204.9234s\n",
      "\titers: 300, epoch: 9 | loss: 0.1447220\n",
      "\tspeed: 0.0316s/iter; left time: 206.3022s\n",
      "\titers: 400, epoch: 9 | loss: 0.1742794\n",
      "\tspeed: 0.0320s/iter; left time: 205.4551s\n",
      "\titers: 500, epoch: 9 | loss: 0.1385726\n",
      "\tspeed: 0.0332s/iter; left time: 210.2441s\n",
      "Epoch: 9 cost time: 18.43368434906006\n",
      "Epoch: 9, Steps: 569 | Train Loss: 0.1496381 Vali Loss: 0.1946922 Test Loss: 0.2365600\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.2354623\n",
      "\tspeed: 0.1032s/iter; left time: 635.6394s\n",
      "\titers: 200, epoch: 10 | loss: 0.1431968\n",
      "\tspeed: 0.0324s/iter; left time: 196.1463s\n",
      "\titers: 300, epoch: 10 | loss: 0.1051630\n",
      "\tspeed: 0.0332s/iter; left time: 198.1157s\n",
      "\titers: 400, epoch: 10 | loss: 0.1391906\n",
      "\tspeed: 0.0326s/iter; left time: 191.0372s\n",
      "\titers: 500, epoch: 10 | loss: 0.1243538\n",
      "\tspeed: 0.0338s/iter; left time: 194.7431s\n",
      "Epoch: 10 cost time: 18.777827501296997\n",
      "Epoch: 10, Steps: 569 | Train Loss: 0.1489868 Vali Loss: 0.1935806 Test Loss: 0.2368385\n",
      "Validation loss decreased (0.194049 --> 0.193581).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.1249834\n",
      "\tspeed: 0.1099s/iter; left time: 614.2475s\n",
      "\titers: 200, epoch: 11 | loss: 0.0977154\n",
      "\tspeed: 0.0342s/iter; left time: 187.9417s\n",
      "\titers: 300, epoch: 11 | loss: 0.2208173\n",
      "\tspeed: 0.0332s/iter; left time: 178.8266s\n",
      "\titers: 400, epoch: 11 | loss: 0.1353774\n",
      "\tspeed: 0.0342s/iter; left time: 180.9733s\n",
      "\titers: 500, epoch: 11 | loss: 0.1184011\n",
      "\tspeed: 0.0343s/iter; left time: 177.8280s\n",
      "Epoch: 11 cost time: 19.32508945465088\n",
      "Epoch: 11, Steps: 569 | Train Loss: 0.1488041 Vali Loss: 0.1946693 Test Loss: 0.2377739\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.1665725\n",
      "\tspeed: 0.1044s/iter; left time: 524.2403s\n",
      "\titers: 200, epoch: 12 | loss: 0.1476028\n",
      "\tspeed: 0.0353s/iter; left time: 173.5521s\n",
      "\titers: 300, epoch: 12 | loss: 0.1549144\n",
      "\tspeed: 0.0328s/iter; left time: 158.2931s\n",
      "\titers: 400, epoch: 12 | loss: 0.2354295\n",
      "\tspeed: 0.0312s/iter; left time: 147.3903s\n",
      "\titers: 500, epoch: 12 | loss: 0.2452521\n",
      "\tspeed: 0.0321s/iter; left time: 148.2503s\n",
      "Epoch: 12 cost time: 18.777373790740967\n",
      "Epoch: 12, Steps: 569 | Train Loss: 0.1486747 Vali Loss: 0.1938405 Test Loss: 0.2371552\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      "\titers: 100, epoch: 13 | loss: 0.1755476\n",
      "\tspeed: 0.1030s/iter; left time: 458.7372s\n",
      "\titers: 200, epoch: 13 | loss: 0.1017817\n",
      "\tspeed: 0.0321s/iter; left time: 139.6027s\n",
      "\titers: 300, epoch: 13 | loss: 0.1690908\n",
      "\tspeed: 0.0317s/iter; left time: 134.9448s\n",
      "\titers: 400, epoch: 13 | loss: 0.1254898\n",
      "\tspeed: 0.0342s/iter; left time: 142.1255s\n",
      "\titers: 500, epoch: 13 | loss: 0.0983922\n",
      "\tspeed: 0.0326s/iter; left time: 132.2550s\n",
      "Epoch: 13 cost time: 18.486172676086426\n",
      "Epoch: 13, Steps: 569 | Train Loss: 0.1491550 Vali Loss: 0.1934681 Test Loss: 0.2368164\n",
      "Validation loss decreased (0.193581 --> 0.193468).  Saving model ...\n",
      "Updating learning rate to 2.44140625e-08\n",
      "\titers: 100, epoch: 14 | loss: 0.1521425\n",
      "\tspeed: 0.0996s/iter; left time: 386.7902s\n",
      "\titers: 200, epoch: 14 | loss: 0.2534494\n",
      "\tspeed: 0.0318s/iter; left time: 120.4913s\n",
      "\titers: 300, epoch: 14 | loss: 0.1851112\n",
      "\tspeed: 0.0310s/iter; left time: 114.2890s\n",
      "\titers: 400, epoch: 14 | loss: 0.1818969\n",
      "\tspeed: 0.0308s/iter; left time: 110.4370s\n",
      "\titers: 500, epoch: 14 | loss: 0.1527464\n",
      "\tspeed: 0.0312s/iter; left time: 108.8639s\n",
      "Epoch: 14 cost time: 17.872088193893433\n",
      "Epoch: 14, Steps: 569 | Train Loss: 0.1489684 Vali Loss: 0.1937850 Test Loss: 0.2367634\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.220703125e-08\n",
      "\titers: 100, epoch: 15 | loss: 0.1321235\n",
      "\tspeed: 0.1037s/iter; left time: 343.8446s\n",
      "\titers: 200, epoch: 15 | loss: 0.1136366\n",
      "\tspeed: 0.0321s/iter; left time: 103.2033s\n",
      "\titers: 300, epoch: 15 | loss: 0.1395858\n",
      "\tspeed: 0.0333s/iter; left time: 103.6265s\n",
      "\titers: 400, epoch: 15 | loss: 0.1042760\n",
      "\tspeed: 0.0328s/iter; left time: 98.9000s\n",
      "\titers: 500, epoch: 15 | loss: 0.1151851\n",
      "\tspeed: 0.0331s/iter; left time: 96.3499s\n",
      "Epoch: 15 cost time: 18.611828804016113\n",
      "Epoch: 15, Steps: 569 | Train Loss: 0.1483297 Vali Loss: 0.1931722 Test Loss: 0.2361176\n",
      "Validation loss decreased (0.193468 --> 0.193172).  Saving model ...\n",
      "Updating learning rate to 6.103515625e-09\n",
      "\titers: 100, epoch: 16 | loss: 0.0887510\n",
      "\tspeed: 0.1065s/iter; left time: 292.4970s\n",
      "\titers: 200, epoch: 16 | loss: 0.1058856\n",
      "\tspeed: 0.0346s/iter; left time: 91.4909s\n",
      "\titers: 300, epoch: 16 | loss: 0.1507429\n",
      "\tspeed: 0.0332s/iter; left time: 84.5601s\n",
      "\titers: 400, epoch: 16 | loss: 0.0896878\n",
      "\tspeed: 0.0344s/iter; left time: 84.2596s\n",
      "\titers: 500, epoch: 16 | loss: 0.1589420\n",
      "\tspeed: 0.0343s/iter; left time: 80.5132s\n",
      "Epoch: 16 cost time: 19.349175214767456\n",
      "Epoch: 16, Steps: 569 | Train Loss: 0.1485807 Vali Loss: 0.1954903 Test Loss: 0.2376186\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.0517578125e-09\n",
      "\titers: 100, epoch: 17 | loss: 0.1127030\n",
      "\tspeed: 0.1063s/iter; left time: 231.4543s\n",
      "\titers: 200, epoch: 17 | loss: 0.1518573\n",
      "\tspeed: 0.0349s/iter; left time: 72.3846s\n",
      "\titers: 300, epoch: 17 | loss: 0.1794236\n",
      "\tspeed: 0.0354s/iter; left time: 69.9684s\n",
      "\titers: 400, epoch: 17 | loss: 0.1544679\n",
      "\tspeed: 0.0325s/iter; left time: 61.0957s\n",
      "\titers: 500, epoch: 17 | loss: 0.1267805\n",
      "\tspeed: 0.0319s/iter; left time: 56.6260s\n",
      "Epoch: 17 cost time: 19.16474199295044\n",
      "Epoch: 17, Steps: 569 | Train Loss: 0.1487578 Vali Loss: 0.1948823 Test Loss: 0.2383041\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.52587890625e-09\n",
      "\titers: 100, epoch: 18 | loss: 0.1852131\n",
      "\tspeed: 0.1025s/iter; left time: 164.8806s\n",
      "\titers: 200, epoch: 18 | loss: 0.1519944\n",
      "\tspeed: 0.0315s/iter; left time: 47.5688s\n",
      "\titers: 300, epoch: 18 | loss: 0.1360743\n",
      "\tspeed: 0.0324s/iter; left time: 45.5703s\n",
      "\titers: 400, epoch: 18 | loss: 0.2439391\n",
      "\tspeed: 0.0332s/iter; left time: 43.3666s\n",
      "\titers: 500, epoch: 18 | loss: 0.1885100\n",
      "\tspeed: 0.0325s/iter; left time: 39.2111s\n",
      "Epoch: 18 cost time: 18.37982702255249\n",
      "Epoch: 18, Steps: 569 | Train Loss: 0.1485443 Vali Loss: 0.1947430 Test Loss: 0.2391591\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl120_ll40_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "Test cost time: 2.2423s\n",
      "test shape: (177, 32, 6, 1) (177, 32, 6, 1)\n",
      "test shape: (5664, 6, 1) (5664, 6, 1)\n",
      "mse:0.2373979389667511, mae:0.324081689119339\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl120_ll40_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1721.010986328125\n",
      "MAE:  27.593564987182617\n",
      "RMSE: 41.485069274902344\n",
      "MAPE: 0.36470863223075867\n",
      "MSPE: 0.6510055661201477\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl120_ll40_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20913\n",
      "[DEBUG] Original dataset length: 20913\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18236\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6556\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "\titers: 100, epoch: 1 | loss: 0.4567588\n",
      "\tspeed: 0.0331s/iter; left time: 373.7436s\n",
      "\titers: 200, epoch: 1 | loss: 0.3932590\n",
      "\tspeed: 0.0311s/iter; left time: 348.2649s\n",
      "\titers: 300, epoch: 1 | loss: 0.2393962\n",
      "\tspeed: 0.0316s/iter; left time: 349.8000s\n",
      "\titers: 400, epoch: 1 | loss: 0.3273749\n",
      "\tspeed: 0.0312s/iter; left time: 343.0330s\n",
      "\titers: 500, epoch: 1 | loss: 0.1814294\n",
      "\tspeed: 0.0310s/iter; left time: 337.6588s\n",
      "Epoch: 1 cost time: 18.199071884155273\n",
      "Epoch: 1, Steps: 569 | Train Loss: 0.3168692 Vali Loss: 0.2420860 Test Loss: 0.2895885\n",
      "Validation loss decreased (inf --> 0.242086).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1692156\n",
      "\tspeed: 0.1028s/iter; left time: 1101.6257s\n",
      "\titers: 200, epoch: 2 | loss: 0.2925112\n",
      "\tspeed: 0.0312s/iter; left time: 330.8273s\n",
      "\titers: 300, epoch: 2 | loss: 0.2064939\n",
      "\tspeed: 0.0323s/iter; left time: 339.5384s\n",
      "\titers: 400, epoch: 2 | loss: 0.1318245\n",
      "\tspeed: 0.0315s/iter; left time: 327.7418s\n",
      "\titers: 500, epoch: 2 | loss: 0.1540571\n",
      "\tspeed: 0.0310s/iter; left time: 319.7786s\n",
      "Epoch: 2 cost time: 17.757495641708374\n",
      "Epoch: 2, Steps: 569 | Train Loss: 0.2150557 Vali Loss: 0.2019850 Test Loss: 0.2393447\n",
      "Validation loss decreased (0.242086 --> 0.201985).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1408785\n",
      "\tspeed: 0.1010s/iter; left time: 1024.4089s\n",
      "\titers: 200, epoch: 3 | loss: 0.1557516\n",
      "\tspeed: 0.0306s/iter; left time: 306.8942s\n",
      "\titers: 300, epoch: 3 | loss: 0.1388172\n",
      "\tspeed: 0.0308s/iter; left time: 306.2466s\n",
      "\titers: 400, epoch: 3 | loss: 0.1518856\n",
      "\tspeed: 0.0307s/iter; left time: 301.7983s\n",
      "\titers: 500, epoch: 3 | loss: 0.1532080\n",
      "\tspeed: 0.0312s/iter; left time: 304.4656s\n",
      "Epoch: 3 cost time: 17.900800228118896\n",
      "Epoch: 3, Steps: 569 | Train Loss: 0.1831868 Vali Loss: 0.1983792 Test Loss: 0.2339891\n",
      "Validation loss decreased (0.201985 --> 0.198379).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1992638\n",
      "\tspeed: 0.1016s/iter; left time: 972.9962s\n",
      "\titers: 200, epoch: 4 | loss: 0.1708452\n",
      "\tspeed: 0.0310s/iter; left time: 293.7683s\n",
      "\titers: 300, epoch: 4 | loss: 0.1918471\n",
      "\tspeed: 0.0334s/iter; left time: 313.0881s\n",
      "\titers: 400, epoch: 4 | loss: 0.2077994\n",
      "\tspeed: 0.0330s/iter; left time: 306.2560s\n",
      "\titers: 500, epoch: 4 | loss: 0.2551512\n",
      "\tspeed: 0.0317s/iter; left time: 290.3577s\n",
      "Epoch: 4 cost time: 18.21366238594055\n",
      "Epoch: 4, Steps: 569 | Train Loss: 0.1665152 Vali Loss: 0.2009190 Test Loss: 0.2364577\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1144902\n",
      "\tspeed: 0.1027s/iter; left time: 925.2093s\n",
      "\titers: 200, epoch: 5 | loss: 0.1311556\n",
      "\tspeed: 0.0312s/iter; left time: 277.5098s\n",
      "\titers: 300, epoch: 5 | loss: 0.1145082\n",
      "\tspeed: 0.0305s/iter; left time: 268.9547s\n",
      "\titers: 400, epoch: 5 | loss: 0.1239050\n",
      "\tspeed: 0.0309s/iter; left time: 269.3981s\n",
      "\titers: 500, epoch: 5 | loss: 0.3283087\n",
      "\tspeed: 0.0313s/iter; left time: 269.0441s\n",
      "Epoch: 5 cost time: 17.815483331680298\n",
      "Epoch: 5, Steps: 569 | Train Loss: 0.1593699 Vali Loss: 0.2035547 Test Loss: 0.2420087\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0722958\n",
      "\tspeed: 0.0989s/iter; left time: 834.1546s\n",
      "\titers: 200, epoch: 6 | loss: 0.1657580\n",
      "\tspeed: 0.0310s/iter; left time: 258.6394s\n",
      "\titers: 300, epoch: 6 | loss: 0.1187519\n",
      "\tspeed: 0.0329s/iter; left time: 271.3420s\n",
      "\titers: 400, epoch: 6 | loss: 0.2182722\n",
      "\tspeed: 0.0316s/iter; left time: 257.0978s\n",
      "\titers: 500, epoch: 6 | loss: 0.1675377\n",
      "\tspeed: 0.0317s/iter; left time: 255.0444s\n",
      "Epoch: 6 cost time: 18.01008152961731\n",
      "Epoch: 6, Steps: 569 | Train Loss: 0.1537737 Vali Loss: 0.1972253 Test Loss: 0.2368545\n",
      "Validation loss decreased (0.198379 --> 0.197225).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1882535\n",
      "\tspeed: 0.1023s/iter; left time: 804.9451s\n",
      "\titers: 200, epoch: 7 | loss: 0.0928493\n",
      "\tspeed: 0.0323s/iter; left time: 250.7595s\n",
      "\titers: 300, epoch: 7 | loss: 0.1445543\n",
      "\tspeed: 0.0319s/iter; left time: 244.4625s\n",
      "\titers: 400, epoch: 7 | loss: 0.1240622\n",
      "\tspeed: 0.0317s/iter; left time: 240.1536s\n",
      "\titers: 500, epoch: 7 | loss: 0.0991713\n",
      "\tspeed: 0.0343s/iter; left time: 256.1986s\n",
      "Epoch: 7 cost time: 18.474588632583618\n",
      "Epoch: 7, Steps: 569 | Train Loss: 0.1508218 Vali Loss: 0.1978664 Test Loss: 0.2387230\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1303618\n",
      "\tspeed: 0.1002s/iter; left time: 731.2546s\n",
      "\titers: 200, epoch: 8 | loss: 0.2059658\n",
      "\tspeed: 0.0305s/iter; left time: 219.5993s\n",
      "\titers: 300, epoch: 8 | loss: 0.1561507\n",
      "\tspeed: 0.0329s/iter; left time: 233.4941s\n",
      "\titers: 400, epoch: 8 | loss: 0.1118974\n",
      "\tspeed: 0.0318s/iter; left time: 222.8368s\n",
      "\titers: 500, epoch: 8 | loss: 0.1427075\n",
      "\tspeed: 0.0310s/iter; left time: 213.8109s\n",
      "Epoch: 8 cost time: 17.979755878448486\n",
      "Epoch: 8, Steps: 569 | Train Loss: 0.1490874 Vali Loss: 0.1981829 Test Loss: 0.2412301\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1883331\n",
      "\tspeed: 0.1045s/iter; left time: 702.8726s\n",
      "\titers: 200, epoch: 9 | loss: 0.1792824\n",
      "\tspeed: 0.0320s/iter; left time: 211.9307s\n",
      "\titers: 300, epoch: 9 | loss: 0.1255290\n",
      "\tspeed: 0.0323s/iter; left time: 210.6084s\n",
      "\titers: 400, epoch: 9 | loss: 0.1058676\n",
      "\tspeed: 0.0317s/iter; left time: 203.7008s\n",
      "\titers: 500, epoch: 9 | loss: 0.1618699\n",
      "\tspeed: 0.0327s/iter; left time: 206.8841s\n",
      "Epoch: 9 cost time: 18.16968274116516\n",
      "Epoch: 9, Steps: 569 | Train Loss: 0.1484566 Vali Loss: 0.1963716 Test Loss: 0.2390644\n",
      "Validation loss decreased (0.197225 --> 0.196372).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.3181428\n",
      "\tspeed: 0.1007s/iter; left time: 620.4855s\n",
      "\titers: 200, epoch: 10 | loss: 0.1323486\n",
      "\tspeed: 0.0314s/iter; left time: 190.0400s\n",
      "\titers: 300, epoch: 10 | loss: 0.1475592\n",
      "\tspeed: 0.0316s/iter; left time: 188.6296s\n",
      "\titers: 400, epoch: 10 | loss: 0.2792381\n",
      "\tspeed: 0.0313s/iter; left time: 183.3993s\n",
      "\titers: 500, epoch: 10 | loss: 0.1228965\n",
      "\tspeed: 0.0310s/iter; left time: 178.6146s\n",
      "Epoch: 10 cost time: 17.87432599067688\n",
      "Epoch: 10, Steps: 569 | Train Loss: 0.1472775 Vali Loss: 0.1973788 Test Loss: 0.2390585\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.1664074\n",
      "\tspeed: 0.1041s/iter; left time: 581.9986s\n",
      "\titers: 200, epoch: 11 | loss: 0.1283043\n",
      "\tspeed: 0.0318s/iter; left time: 174.6482s\n",
      "\titers: 300, epoch: 11 | loss: 0.1628832\n",
      "\tspeed: 0.0321s/iter; left time: 172.8840s\n",
      "\titers: 400, epoch: 11 | loss: 0.1364295\n",
      "\tspeed: 0.0318s/iter; left time: 168.0023s\n",
      "\titers: 500, epoch: 11 | loss: 0.1624488\n",
      "\tspeed: 0.0316s/iter; left time: 163.8846s\n",
      "Epoch: 11 cost time: 18.25255012512207\n",
      "Epoch: 11, Steps: 569 | Train Loss: 0.1483253 Vali Loss: 0.1973035 Test Loss: 0.2396904\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.1712093\n",
      "\tspeed: 0.0990s/iter; left time: 496.9431s\n",
      "\titers: 200, epoch: 12 | loss: 0.1021252\n",
      "\tspeed: 0.0318s/iter; left time: 156.4913s\n",
      "\titers: 300, epoch: 12 | loss: 0.1123972\n",
      "\tspeed: 0.0329s/iter; left time: 158.7155s\n",
      "\titers: 400, epoch: 12 | loss: 0.1332932\n",
      "\tspeed: 0.0317s/iter; left time: 149.7462s\n",
      "\titers: 500, epoch: 12 | loss: 0.1117047\n",
      "\tspeed: 0.0321s/iter; left time: 148.1407s\n",
      "Epoch: 12 cost time: 18.07477831840515\n",
      "Epoch: 12, Steps: 569 | Train Loss: 0.1472397 Vali Loss: 0.1989081 Test Loss: 0.2389723\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl120_ll40_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "Test cost time: 2.1919s\n",
      "test shape: (177, 32, 6, 1) (177, 32, 6, 1)\n",
      "test shape: (5664, 6, 1) (5664, 6, 1)\n",
      "mse:0.2381255328655243, mae:0.3228871822357178\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl120_ll40_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1726.2857666015625\n",
      "MAE:  27.49186134338379\n",
      "RMSE: 41.5485954284668\n",
      "MAPE: 0.3590123951435089\n",
      "MSPE: 0.6364794373512268\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl120_ll40_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20913\n",
      "[DEBUG] Original dataset length: 20913\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18236\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6556\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "\titers: 100, epoch: 1 | loss: 0.4645601\n",
      "\tspeed: 0.0319s/iter; left time: 359.8595s\n",
      "\titers: 200, epoch: 1 | loss: 0.2417804\n",
      "\tspeed: 0.0319s/iter; left time: 356.5280s\n",
      "\titers: 300, epoch: 1 | loss: 0.2324474\n",
      "\tspeed: 0.0316s/iter; left time: 349.8866s\n",
      "\titers: 400, epoch: 1 | loss: 0.5374891\n",
      "\tspeed: 0.0325s/iter; left time: 356.7861s\n",
      "\titers: 500, epoch: 1 | loss: 0.2305388\n",
      "\tspeed: 0.0317s/iter; left time: 345.1444s\n",
      "Epoch: 1 cost time: 18.15460777282715\n",
      "Epoch: 1, Steps: 569 | Train Loss: 0.3349837 Vali Loss: 0.2171769 Test Loss: 0.2613280\n",
      "Validation loss decreased (inf --> 0.217177).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2409902\n",
      "\tspeed: 0.1040s/iter; left time: 1114.5392s\n",
      "\titers: 200, epoch: 2 | loss: 0.1532072\n",
      "\tspeed: 0.0319s/iter; left time: 338.2124s\n",
      "\titers: 300, epoch: 2 | loss: 0.2188626\n",
      "\tspeed: 0.0316s/iter; left time: 331.8283s\n",
      "\titers: 400, epoch: 2 | loss: 0.2847156\n",
      "\tspeed: 0.0323s/iter; left time: 336.8101s\n",
      "\titers: 500, epoch: 2 | loss: 0.1987779\n",
      "\tspeed: 0.0316s/iter; left time: 325.7050s\n",
      "Epoch: 2 cost time: 18.452000617980957\n",
      "Epoch: 2, Steps: 569 | Train Loss: 0.2128564 Vali Loss: 0.2059976 Test Loss: 0.2477512\n",
      "Validation loss decreased (0.217177 --> 0.205998).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2686872\n",
      "\tspeed: 0.1024s/iter; left time: 1038.4825s\n",
      "\titers: 200, epoch: 3 | loss: 0.2888304\n",
      "\tspeed: 0.0319s/iter; left time: 320.3358s\n",
      "\titers: 300, epoch: 3 | loss: 0.1303716\n",
      "\tspeed: 0.0333s/iter; left time: 331.3368s\n",
      "\titers: 400, epoch: 3 | loss: 0.1111290\n",
      "\tspeed: 0.0326s/iter; left time: 320.9604s\n",
      "\titers: 500, epoch: 3 | loss: 0.1282418\n",
      "\tspeed: 0.0312s/iter; left time: 304.4114s\n",
      "Epoch: 3 cost time: 18.225547075271606\n",
      "Epoch: 3, Steps: 569 | Train Loss: 0.1822868 Vali Loss: 0.2121680 Test Loss: 0.2548962\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1528466\n",
      "\tspeed: 0.1020s/iter; left time: 976.3462s\n",
      "\titers: 200, epoch: 4 | loss: 0.1598206\n",
      "\tspeed: 0.0310s/iter; left time: 293.2623s\n",
      "\titers: 300, epoch: 4 | loss: 0.2928722\n",
      "\tspeed: 0.0308s/iter; left time: 288.6715s\n",
      "\titers: 400, epoch: 4 | loss: 0.1603115\n",
      "\tspeed: 0.0308s/iter; left time: 286.0168s\n",
      "\titers: 500, epoch: 4 | loss: 0.1989968\n",
      "\tspeed: 0.0309s/iter; left time: 283.5448s\n",
      "Epoch: 4 cost time: 17.911990642547607\n",
      "Epoch: 4, Steps: 569 | Train Loss: 0.1670856 Vali Loss: 0.1990598 Test Loss: 0.2319841\n",
      "Validation loss decreased (0.205998 --> 0.199060).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1357452\n",
      "\tspeed: 0.1008s/iter; left time: 907.9512s\n",
      "\titers: 200, epoch: 5 | loss: 0.1359345\n",
      "\tspeed: 0.0312s/iter; left time: 277.4678s\n",
      "\titers: 300, epoch: 5 | loss: 0.1497281\n",
      "\tspeed: 0.0333s/iter; left time: 293.0754s\n",
      "\titers: 400, epoch: 5 | loss: 0.1625819\n",
      "\tspeed: 0.0327s/iter; left time: 284.8279s\n",
      "\titers: 500, epoch: 5 | loss: 0.1117669\n",
      "\tspeed: 0.0322s/iter; left time: 277.3493s\n",
      "Epoch: 5 cost time: 18.303436279296875\n",
      "Epoch: 5, Steps: 569 | Train Loss: 0.1585362 Vali Loss: 0.1922034 Test Loss: 0.2361933\n",
      "Validation loss decreased (0.199060 --> 0.192203).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0992721\n",
      "\tspeed: 0.1041s/iter; left time: 877.9722s\n",
      "\titers: 200, epoch: 6 | loss: 0.2200022\n",
      "\tspeed: 0.0318s/iter; left time: 264.8579s\n",
      "\titers: 300, epoch: 6 | loss: 0.1707227\n",
      "\tspeed: 0.0320s/iter; left time: 263.3588s\n",
      "\titers: 400, epoch: 6 | loss: 0.1879290\n",
      "\tspeed: 0.0316s/iter; left time: 256.8295s\n",
      "\titers: 500, epoch: 6 | loss: 0.2273221\n",
      "\tspeed: 0.0322s/iter; left time: 259.1514s\n",
      "Epoch: 6 cost time: 18.301583290100098\n",
      "Epoch: 6, Steps: 569 | Train Loss: 0.1529458 Vali Loss: 0.1927007 Test Loss: 0.2333918\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1186382\n",
      "\tspeed: 0.1019s/iter; left time: 801.8522s\n",
      "\titers: 200, epoch: 7 | loss: 0.1290375\n",
      "\tspeed: 0.0317s/iter; left time: 246.2636s\n",
      "\titers: 300, epoch: 7 | loss: 0.1562506\n",
      "\tspeed: 0.0329s/iter; left time: 252.2826s\n",
      "\titers: 400, epoch: 7 | loss: 0.1564388\n",
      "\tspeed: 0.0312s/iter; left time: 235.8745s\n",
      "\titers: 500, epoch: 7 | loss: 0.1174994\n",
      "\tspeed: 0.0308s/iter; left time: 230.3558s\n",
      "Epoch: 7 cost time: 17.954189777374268\n",
      "Epoch: 7, Steps: 569 | Train Loss: 0.1497599 Vali Loss: 0.1955516 Test Loss: 0.2336543\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1607998\n",
      "\tspeed: 0.1016s/iter; left time: 741.6091s\n",
      "\titers: 200, epoch: 8 | loss: 0.1010405\n",
      "\tspeed: 0.0309s/iter; left time: 222.7186s\n",
      "\titers: 300, epoch: 8 | loss: 0.1079925\n",
      "\tspeed: 0.0306s/iter; left time: 217.1378s\n",
      "\titers: 400, epoch: 8 | loss: 0.1367502\n",
      "\tspeed: 0.0317s/iter; left time: 221.5546s\n",
      "\titers: 500, epoch: 8 | loss: 0.1207861\n",
      "\tspeed: 0.0326s/iter; left time: 224.6052s\n",
      "Epoch: 8 cost time: 18.043131589889526\n",
      "Epoch: 8, Steps: 569 | Train Loss: 0.1483002 Vali Loss: 0.1956648 Test Loss: 0.2328182\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl120_ll40_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "Test cost time: 2.1223s\n",
      "test shape: (177, 32, 6, 1) (177, 32, 6, 1)\n",
      "test shape: (5664, 6, 1) (5664, 6, 1)\n",
      "mse:0.23486673831939697, mae:0.327912300825119\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl120_ll40_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1702.6612548828125\n",
      "MAE:  27.919719696044922\n",
      "RMSE: 41.2633171081543\n",
      "MAPE: 0.36581847071647644\n",
      "MSPE: 0.6453696489334106\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl120_ll40_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20913\n",
      "[DEBUG] Original dataset length: 20913\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18236\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6556\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "\titers: 100, epoch: 1 | loss: 0.4824824\n",
      "\tspeed: 0.0311s/iter; left time: 350.3751s\n",
      "\titers: 200, epoch: 1 | loss: 0.1988721\n",
      "\tspeed: 0.0329s/iter; left time: 367.5903s\n",
      "\titers: 300, epoch: 1 | loss: 0.2637034\n",
      "\tspeed: 0.0309s/iter; left time: 341.9045s\n",
      "\titers: 400, epoch: 1 | loss: 0.1882119\n",
      "\tspeed: 0.0306s/iter; left time: 335.7383s\n",
      "\titers: 500, epoch: 1 | loss: 0.2055882\n",
      "\tspeed: 0.0307s/iter; left time: 333.5219s\n",
      "Epoch: 1 cost time: 17.83795690536499\n",
      "Epoch: 1, Steps: 569 | Train Loss: 0.3266812 Vali Loss: 0.2752578 Test Loss: 0.3282578\n",
      "Validation loss decreased (inf --> 0.275258).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1426260\n",
      "\tspeed: 0.1032s/iter; left time: 1105.9930s\n",
      "\titers: 200, epoch: 2 | loss: 0.4250844\n",
      "\tspeed: 0.0303s/iter; left time: 321.0261s\n",
      "\titers: 300, epoch: 2 | loss: 0.2209545\n",
      "\tspeed: 0.0317s/iter; left time: 333.1547s\n",
      "\titers: 400, epoch: 2 | loss: 0.1970800\n",
      "\tspeed: 0.0338s/iter; left time: 351.7496s\n",
      "\titers: 500, epoch: 2 | loss: 0.3718292\n",
      "\tspeed: 0.0318s/iter; left time: 327.5773s\n",
      "Epoch: 2 cost time: 18.11084771156311\n",
      "Epoch: 2, Steps: 569 | Train Loss: 0.2185133 Vali Loss: 0.2280149 Test Loss: 0.2570492\n",
      "Validation loss decreased (0.275258 --> 0.228015).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1238595\n",
      "\tspeed: 0.1057s/iter; left time: 1072.1846s\n",
      "\titers: 200, epoch: 3 | loss: 0.2391746\n",
      "\tspeed: 0.0338s/iter; left time: 339.6692s\n",
      "\titers: 300, epoch: 3 | loss: 0.1437891\n",
      "\tspeed: 0.0326s/iter; left time: 324.1696s\n",
      "\titers: 400, epoch: 3 | loss: 0.1052740\n",
      "\tspeed: 0.0315s/iter; left time: 310.2085s\n",
      "\titers: 500, epoch: 3 | loss: 0.1411738\n",
      "\tspeed: 0.0318s/iter; left time: 309.5159s\n",
      "Epoch: 3 cost time: 18.568520307540894\n",
      "Epoch: 3, Steps: 569 | Train Loss: 0.1829159 Vali Loss: 0.2094388 Test Loss: 0.2462101\n",
      "Validation loss decreased (0.228015 --> 0.209439).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1136294\n",
      "\tspeed: 0.1052s/iter; left time: 1006.8755s\n",
      "\titers: 200, epoch: 4 | loss: 0.1836071\n",
      "\tspeed: 0.0305s/iter; left time: 289.1870s\n",
      "\titers: 300, epoch: 4 | loss: 0.1166894\n",
      "\tspeed: 0.0319s/iter; left time: 299.4938s\n",
      "\titers: 400, epoch: 4 | loss: 0.1796611\n",
      "\tspeed: 0.0337s/iter; left time: 312.2966s\n",
      "\titers: 500, epoch: 4 | loss: 0.1741319\n",
      "\tspeed: 0.0320s/iter; left time: 293.1257s\n",
      "Epoch: 4 cost time: 18.138288259506226\n",
      "Epoch: 4, Steps: 569 | Train Loss: 0.1667562 Vali Loss: 0.2041119 Test Loss: 0.2390635\n",
      "Validation loss decreased (0.209439 --> 0.204112).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2061186\n",
      "\tspeed: 0.1016s/iter; left time: 915.1118s\n",
      "\titers: 200, epoch: 5 | loss: 0.1243321\n",
      "\tspeed: 0.0333s/iter; left time: 296.3920s\n",
      "\titers: 300, epoch: 5 | loss: 0.2223180\n",
      "\tspeed: 0.0324s/iter; left time: 285.1699s\n",
      "\titers: 400, epoch: 5 | loss: 0.2232575\n",
      "\tspeed: 0.0315s/iter; left time: 274.4543s\n",
      "\titers: 500, epoch: 5 | loss: 0.1660672\n",
      "\tspeed: 0.0317s/iter; left time: 273.0151s\n",
      "Epoch: 5 cost time: 18.422448873519897\n",
      "Epoch: 5, Steps: 569 | Train Loss: 0.1584258 Vali Loss: 0.2128339 Test Loss: 0.2435531\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1150898\n",
      "\tspeed: 0.0997s/iter; left time: 841.0568s\n",
      "\titers: 200, epoch: 6 | loss: 0.1570876\n",
      "\tspeed: 0.0311s/iter; left time: 259.6078s\n",
      "\titers: 300, epoch: 6 | loss: 0.1518873\n",
      "\tspeed: 0.0321s/iter; left time: 264.7835s\n",
      "\titers: 400, epoch: 6 | loss: 0.1905632\n",
      "\tspeed: 0.0325s/iter; left time: 264.5209s\n",
      "\titers: 500, epoch: 6 | loss: 0.1411873\n",
      "\tspeed: 0.0312s/iter; left time: 251.0646s\n",
      "Epoch: 6 cost time: 17.868529081344604\n",
      "Epoch: 6, Steps: 569 | Train Loss: 0.1525563 Vali Loss: 0.2129387 Test Loss: 0.2453194\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0835308\n",
      "\tspeed: 0.1033s/iter; left time: 812.3398s\n",
      "\titers: 200, epoch: 7 | loss: 0.0947550\n",
      "\tspeed: 0.0318s/iter; left time: 246.9612s\n",
      "\titers: 300, epoch: 7 | loss: 0.1618123\n",
      "\tspeed: 0.0305s/iter; left time: 233.6010s\n",
      "\titers: 400, epoch: 7 | loss: 0.1181490\n",
      "\tspeed: 0.0319s/iter; left time: 241.2100s\n",
      "\titers: 500, epoch: 7 | loss: 0.1338034\n",
      "\tspeed: 0.0320s/iter; left time: 239.0004s\n",
      "Epoch: 7 cost time: 18.26736569404602\n",
      "Epoch: 7, Steps: 569 | Train Loss: 0.1493978 Vali Loss: 0.2146472 Test Loss: 0.2460542\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl120_ll40_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "Test cost time: 2.1934s\n",
      "test shape: (177, 32, 6, 1) (177, 32, 6, 1)\n",
      "test shape: (5664, 6, 1) (5664, 6, 1)\n",
      "mse:0.2395661622285843, mae:0.3213362395763397\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl120_ll40_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1736.7296142578125\n",
      "MAE:  27.359811782836914\n",
      "RMSE: 41.67408752441406\n",
      "MAPE: 0.33946219086647034\n",
      "MSPE: 0.5837965607643127\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl120_ll40_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20913\n",
      "[DEBUG] Original dataset length: 20913\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18236\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6556\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "\titers: 100, epoch: 1 | loss: 0.2624054\n",
      "\tspeed: 0.0324s/iter; left time: 365.5503s\n",
      "\titers: 200, epoch: 1 | loss: 0.3465871\n",
      "\tspeed: 0.0336s/iter; left time: 375.1976s\n",
      "\titers: 300, epoch: 1 | loss: 0.2072810\n",
      "\tspeed: 0.0326s/iter; left time: 360.7744s\n",
      "\titers: 400, epoch: 1 | loss: 0.1427034\n",
      "\tspeed: 0.0324s/iter; left time: 355.5122s\n",
      "\titers: 500, epoch: 1 | loss: 0.2433990\n",
      "\tspeed: 0.0331s/iter; left time: 359.8806s\n",
      "Epoch: 1 cost time: 18.728251218795776\n",
      "Epoch: 1, Steps: 569 | Train Loss: 0.2938546 Vali Loss: 0.2178484 Test Loss: 0.2603462\n",
      "Validation loss decreased (inf --> 0.217848).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2471194\n",
      "\tspeed: 0.1082s/iter; left time: 1158.9305s\n",
      "\titers: 200, epoch: 2 | loss: 0.3406034\n",
      "\tspeed: 0.0343s/iter; left time: 364.3806s\n",
      "\titers: 300, epoch: 2 | loss: 0.1830756\n",
      "\tspeed: 0.0335s/iter; left time: 352.5958s\n",
      "\titers: 400, epoch: 2 | loss: 0.2156893\n",
      "\tspeed: 0.0361s/iter; left time: 376.2674s\n",
      "\titers: 500, epoch: 2 | loss: 0.2062117\n",
      "\tspeed: 0.0336s/iter; left time: 346.5879s\n",
      "Epoch: 2 cost time: 19.435795783996582\n",
      "Epoch: 2, Steps: 569 | Train Loss: 0.2151095 Vali Loss: 0.1953804 Test Loss: 0.2385423\n",
      "Validation loss decreased (0.217848 --> 0.195380).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1770984\n",
      "\tspeed: 0.1078s/iter; left time: 1092.9537s\n",
      "\titers: 200, epoch: 3 | loss: 0.1964703\n",
      "\tspeed: 0.0338s/iter; left time: 339.2605s\n",
      "\titers: 300, epoch: 3 | loss: 0.3589542\n",
      "\tspeed: 0.0344s/iter; left time: 341.5526s\n",
      "\titers: 400, epoch: 3 | loss: 0.2508570\n",
      "\tspeed: 0.0325s/iter; left time: 319.7303s\n",
      "\titers: 500, epoch: 3 | loss: 0.2023069\n",
      "\tspeed: 0.0327s/iter; left time: 318.3150s\n",
      "Epoch: 3 cost time: 19.184256315231323\n",
      "Epoch: 3, Steps: 569 | Train Loss: 0.1828144 Vali Loss: 0.1957344 Test Loss: 0.2401102\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1816047\n",
      "\tspeed: 0.0990s/iter; left time: 947.9230s\n",
      "\titers: 200, epoch: 4 | loss: 0.1333707\n",
      "\tspeed: 0.0316s/iter; left time: 299.7203s\n",
      "\titers: 300, epoch: 4 | loss: 0.1789650\n",
      "\tspeed: 0.0339s/iter; left time: 317.6616s\n",
      "\titers: 400, epoch: 4 | loss: 0.2232335\n",
      "\tspeed: 0.0336s/iter; left time: 311.3020s\n",
      "\titers: 500, epoch: 4 | loss: 0.1932059\n",
      "\tspeed: 0.0333s/iter; left time: 305.1263s\n",
      "Epoch: 4 cost time: 18.533562660217285\n",
      "Epoch: 4, Steps: 569 | Train Loss: 0.1668691 Vali Loss: 0.2036863 Test Loss: 0.2473928\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1230424\n",
      "\tspeed: 0.1032s/iter; left time: 929.5292s\n",
      "\titers: 200, epoch: 5 | loss: 0.1573452\n",
      "\tspeed: 0.0317s/iter; left time: 282.1041s\n",
      "\titers: 300, epoch: 5 | loss: 0.1126034\n",
      "\tspeed: 0.0318s/iter; left time: 279.5600s\n",
      "\titers: 400, epoch: 5 | loss: 0.1712983\n",
      "\tspeed: 0.0327s/iter; left time: 284.3780s\n",
      "\titers: 500, epoch: 5 | loss: 0.1364232\n",
      "\tspeed: 0.0333s/iter; left time: 286.3398s\n",
      "Epoch: 5 cost time: 18.476526737213135\n",
      "Epoch: 5, Steps: 569 | Train Loss: 0.1589504 Vali Loss: 0.1956794 Test Loss: 0.2414707\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl120_ll40_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "Test cost time: 2.1656s\n",
      "test shape: (177, 32, 6, 1) (177, 32, 6, 1)\n",
      "test shape: (5664, 6, 1) (5664, 6, 1)\n",
      "mse:0.23877030611038208, mae:0.3237277567386627\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl120_ll40_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1730.960205078125\n",
      "MAE:  27.563434600830078\n",
      "RMSE: 41.60480880737305\n",
      "MAPE: 0.378218412399292\n",
      "MSPE: 0.765151858329773\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl120_ll40_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20913\n",
      "[DEBUG] Original dataset length: 20913\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18236\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6556\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "\titers: 100, epoch: 1 | loss: 0.4959052\n",
      "\tspeed: 0.0316s/iter; left time: 357.0198s\n",
      "\titers: 200, epoch: 1 | loss: 0.3125058\n",
      "\tspeed: 0.0333s/iter; left time: 372.7530s\n",
      "\titers: 300, epoch: 1 | loss: 0.1410950\n",
      "\tspeed: 0.0328s/iter; left time: 363.6130s\n",
      "\titers: 400, epoch: 1 | loss: 0.1776992\n",
      "\tspeed: 0.0315s/iter; left time: 346.0291s\n",
      "\titers: 500, epoch: 1 | loss: 0.2421104\n",
      "\tspeed: 0.0327s/iter; left time: 355.7504s\n",
      "Epoch: 1 cost time: 18.508748054504395\n",
      "Epoch: 1, Steps: 569 | Train Loss: 0.3057565 Vali Loss: 0.2303203 Test Loss: 0.2753180\n",
      "Validation loss decreased (inf --> 0.230320).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1566471\n",
      "\tspeed: 0.1063s/iter; left time: 1138.7865s\n",
      "\titers: 200, epoch: 2 | loss: 0.1079962\n",
      "\tspeed: 0.0332s/iter; left time: 352.1598s\n",
      "\titers: 300, epoch: 2 | loss: 0.1958546\n",
      "\tspeed: 0.0339s/iter; left time: 356.7062s\n",
      "\titers: 400, epoch: 2 | loss: 0.1777490\n",
      "\tspeed: 0.0339s/iter; left time: 352.9606s\n",
      "\titers: 500, epoch: 2 | loss: 0.1680466\n",
      "\tspeed: 0.0333s/iter; left time: 343.4277s\n",
      "Epoch: 2 cost time: 19.021492958068848\n",
      "Epoch: 2, Steps: 569 | Train Loss: 0.2146401 Vali Loss: 0.2088494 Test Loss: 0.2476535\n",
      "Validation loss decreased (0.230320 --> 0.208849).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2382669\n",
      "\tspeed: 0.1061s/iter; left time: 1076.1137s\n",
      "\titers: 200, epoch: 3 | loss: 0.1734234\n",
      "\tspeed: 0.0333s/iter; left time: 334.7844s\n",
      "\titers: 300, epoch: 3 | loss: 0.2162737\n",
      "\tspeed: 0.0318s/iter; left time: 316.3581s\n",
      "\titers: 400, epoch: 3 | loss: 0.1753376\n",
      "\tspeed: 0.0311s/iter; left time: 306.1299s\n",
      "\titers: 500, epoch: 3 | loss: 0.1679343\n",
      "\tspeed: 0.0322s/iter; left time: 313.4577s\n",
      "Epoch: 3 cost time: 18.768951654434204\n",
      "Epoch: 3, Steps: 569 | Train Loss: 0.1845298 Vali Loss: 0.1987725 Test Loss: 0.2357373\n",
      "Validation loss decreased (0.208849 --> 0.198773).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1168894\n",
      "\tspeed: 0.1035s/iter; left time: 991.2588s\n",
      "\titers: 200, epoch: 4 | loss: 0.1563135\n",
      "\tspeed: 0.0323s/iter; left time: 305.6208s\n",
      "\titers: 300, epoch: 4 | loss: 0.2603632\n",
      "\tspeed: 0.0320s/iter; left time: 300.0088s\n",
      "\titers: 400, epoch: 4 | loss: 0.1065039\n",
      "\tspeed: 0.0323s/iter; left time: 299.2648s\n",
      "\titers: 500, epoch: 4 | loss: 0.1402775\n",
      "\tspeed: 0.0312s/iter; left time: 286.0462s\n",
      "Epoch: 4 cost time: 18.070133686065674\n",
      "Epoch: 4, Steps: 569 | Train Loss: 0.1715623 Vali Loss: 0.1924134 Test Loss: 0.2309702\n",
      "Validation loss decreased (0.198773 --> 0.192413).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1461065\n",
      "\tspeed: 0.1017s/iter; left time: 915.6892s\n",
      "\titers: 200, epoch: 5 | loss: 0.2243226\n",
      "\tspeed: 0.0312s/iter; left time: 278.0463s\n",
      "\titers: 300, epoch: 5 | loss: 0.1794885\n",
      "\tspeed: 0.0320s/iter; left time: 282.0793s\n",
      "\titers: 400, epoch: 5 | loss: 0.1116687\n",
      "\tspeed: 0.0312s/iter; left time: 271.4144s\n",
      "\titers: 500, epoch: 5 | loss: 0.1794979\n",
      "\tspeed: 0.0323s/iter; left time: 277.9071s\n",
      "Epoch: 5 cost time: 18.023969650268555\n",
      "Epoch: 5, Steps: 569 | Train Loss: 0.1617703 Vali Loss: 0.1919904 Test Loss: 0.2338700\n",
      "Validation loss decreased (0.192413 --> 0.191990).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1384864\n",
      "\tspeed: 0.1022s/iter; left time: 862.5469s\n",
      "\titers: 200, epoch: 6 | loss: 0.1123887\n",
      "\tspeed: 0.0306s/iter; left time: 255.0796s\n",
      "\titers: 300, epoch: 6 | loss: 0.1351535\n",
      "\tspeed: 0.0324s/iter; left time: 266.6994s\n",
      "\titers: 400, epoch: 6 | loss: 0.1245072\n",
      "\tspeed: 0.0313s/iter; left time: 254.3916s\n",
      "\titers: 500, epoch: 6 | loss: 0.1382806\n",
      "\tspeed: 0.0307s/iter; left time: 246.5973s\n",
      "Epoch: 6 cost time: 17.83889126777649\n",
      "Epoch: 6, Steps: 569 | Train Loss: 0.1562807 Vali Loss: 0.1938484 Test Loss: 0.2370007\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1595975\n",
      "\tspeed: 0.1013s/iter; left time: 796.9955s\n",
      "\titers: 200, epoch: 7 | loss: 0.1778074\n",
      "\tspeed: 0.0307s/iter; left time: 238.6440s\n",
      "\titers: 300, epoch: 7 | loss: 0.1472454\n",
      "\tspeed: 0.0310s/iter; left time: 237.6185s\n",
      "\titers: 400, epoch: 7 | loss: 0.1462932\n",
      "\tspeed: 0.0316s/iter; left time: 239.0191s\n",
      "\titers: 500, epoch: 7 | loss: 0.1754643\n",
      "\tspeed: 0.0322s/iter; left time: 240.8028s\n",
      "Epoch: 7 cost time: 18.050266981124878\n",
      "Epoch: 7, Steps: 569 | Train Loss: 0.1535778 Vali Loss: 0.1908490 Test Loss: 0.2351516\n",
      "Validation loss decreased (0.191990 --> 0.190849).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1107122\n",
      "\tspeed: 0.1023s/iter; left time: 746.3787s\n",
      "\titers: 200, epoch: 8 | loss: 0.1905511\n",
      "\tspeed: 0.0319s/iter; left time: 229.8456s\n",
      "\titers: 300, epoch: 8 | loss: 0.1710590\n",
      "\tspeed: 0.0323s/iter; left time: 229.0139s\n",
      "\titers: 400, epoch: 8 | loss: 0.1630789\n",
      "\tspeed: 0.0335s/iter; left time: 234.1402s\n",
      "\titers: 500, epoch: 8 | loss: 0.1290508\n",
      "\tspeed: 0.0329s/iter; left time: 226.6211s\n",
      "Epoch: 8 cost time: 18.436599493026733\n",
      "Epoch: 8, Steps: 569 | Train Loss: 0.1515547 Vali Loss: 0.1918611 Test Loss: 0.2351655\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1394097\n",
      "\tspeed: 0.1033s/iter; left time: 694.8858s\n",
      "\titers: 200, epoch: 9 | loss: 0.0820943\n",
      "\tspeed: 0.0334s/iter; left time: 221.6598s\n",
      "\titers: 300, epoch: 9 | loss: 0.1120119\n",
      "\tspeed: 0.0334s/iter; left time: 218.1633s\n",
      "\titers: 400, epoch: 9 | loss: 0.1240017\n",
      "\tspeed: 0.0333s/iter; left time: 214.3354s\n",
      "\titers: 500, epoch: 9 | loss: 0.1322983\n",
      "\tspeed: 0.0330s/iter; left time: 208.6448s\n",
      "Epoch: 9 cost time: 18.88023591041565\n",
      "Epoch: 9, Steps: 569 | Train Loss: 0.1513786 Vali Loss: 0.1916342 Test Loss: 0.2352305\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.1690809\n",
      "\tspeed: 0.0987s/iter; left time: 607.7629s\n",
      "\titers: 200, epoch: 10 | loss: 0.1873761\n",
      "\tspeed: 0.0328s/iter; left time: 198.8684s\n",
      "\titers: 300, epoch: 10 | loss: 0.1341296\n",
      "\tspeed: 0.0337s/iter; left time: 200.6314s\n",
      "\titers: 400, epoch: 10 | loss: 0.1304985\n",
      "\tspeed: 0.0338s/iter; left time: 197.9039s\n",
      "\titers: 500, epoch: 10 | loss: 0.1414733\n",
      "\tspeed: 0.0334s/iter; left time: 192.3667s\n",
      "Epoch: 10 cost time: 18.659234285354614\n",
      "Epoch: 10, Steps: 569 | Train Loss: 0.1503222 Vali Loss: 0.1921933 Test Loss: 0.2370425\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl120_ll40_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "Test cost time: 2.2660s\n",
      "test shape: (177, 32, 6, 1) (177, 32, 6, 1)\n",
      "test shape: (5664, 6, 1) (5664, 6, 1)\n",
      "mse:0.23420804738998413, mae:0.32311874628067017\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl120_ll40_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1697.885986328125\n",
      "MAE:  27.511579513549805\n",
      "RMSE: 41.205413818359375\n",
      "MAPE: 0.36343619227409363\n",
      "MSPE: 0.7073302268981934\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl120_ll40_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20913\n",
      "[DEBUG] Original dataset length: 20913\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18236\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6556\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "\titers: 100, epoch: 1 | loss: 0.2929598\n",
      "\tspeed: 0.0337s/iter; left time: 380.5055s\n",
      "\titers: 200, epoch: 1 | loss: 0.3280067\n",
      "\tspeed: 0.0337s/iter; left time: 376.3555s\n",
      "\titers: 300, epoch: 1 | loss: 0.1393905\n",
      "\tspeed: 0.0341s/iter; left time: 377.8423s\n",
      "\titers: 400, epoch: 1 | loss: 0.2982620\n",
      "\tspeed: 0.0333s/iter; left time: 366.0266s\n",
      "\titers: 500, epoch: 1 | loss: 0.2800144\n",
      "\tspeed: 0.0329s/iter; left time: 358.1481s\n",
      "Epoch: 1 cost time: 19.078339338302612\n",
      "Epoch: 1, Steps: 569 | Train Loss: 0.3085013 Vali Loss: 0.2066831 Test Loss: 0.2579259\n",
      "Validation loss decreased (inf --> 0.206683).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2341802\n",
      "\tspeed: 0.1084s/iter; left time: 1160.7806s\n",
      "\titers: 200, epoch: 2 | loss: 0.1806900\n",
      "\tspeed: 0.0339s/iter; left time: 359.6115s\n",
      "\titers: 300, epoch: 2 | loss: 0.1549663\n",
      "\tspeed: 0.0337s/iter; left time: 354.1199s\n",
      "\titers: 400, epoch: 2 | loss: 0.1786625\n",
      "\tspeed: 0.0339s/iter; left time: 353.4604s\n",
      "\titers: 500, epoch: 2 | loss: 0.1796903\n",
      "\tspeed: 0.0345s/iter; left time: 355.7064s\n",
      "Epoch: 2 cost time: 19.38957691192627\n",
      "Epoch: 2, Steps: 569 | Train Loss: 0.2161905 Vali Loss: 0.2110115 Test Loss: 0.2509865\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1470223\n",
      "\tspeed: 0.1066s/iter; left time: 1080.9916s\n",
      "\titers: 200, epoch: 3 | loss: 0.1097576\n",
      "\tspeed: 0.0353s/iter; left time: 354.0347s\n",
      "\titers: 300, epoch: 3 | loss: 0.3285356\n",
      "\tspeed: 0.0336s/iter; left time: 334.1998s\n",
      "\titers: 400, epoch: 3 | loss: 0.1899303\n",
      "\tspeed: 0.0328s/iter; left time: 323.1394s\n",
      "\titers: 500, epoch: 3 | loss: 0.1186764\n",
      "\tspeed: 0.0335s/iter; left time: 326.4093s\n",
      "Epoch: 3 cost time: 19.087737321853638\n",
      "Epoch: 3, Steps: 569 | Train Loss: 0.1846633 Vali Loss: 0.2025282 Test Loss: 0.2431824\n",
      "Validation loss decreased (0.206683 --> 0.202528).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1932287\n",
      "\tspeed: 0.1067s/iter; left time: 1021.4144s\n",
      "\titers: 200, epoch: 4 | loss: 0.2840436\n",
      "\tspeed: 0.0343s/iter; left time: 325.2263s\n",
      "\titers: 300, epoch: 4 | loss: 0.1579929\n",
      "\tspeed: 0.0341s/iter; left time: 320.0931s\n",
      "\titers: 400, epoch: 4 | loss: 0.1718197\n",
      "\tspeed: 0.0358s/iter; left time: 331.6496s\n",
      "\titers: 500, epoch: 4 | loss: 0.1412912\n",
      "\tspeed: 0.0338s/iter; left time: 309.7440s\n",
      "Epoch: 4 cost time: 19.471678972244263\n",
      "Epoch: 4, Steps: 569 | Train Loss: 0.1697497 Vali Loss: 0.1961831 Test Loss: 0.2361808\n",
      "Validation loss decreased (0.202528 --> 0.196183).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2816102\n",
      "\tspeed: 0.1087s/iter; left time: 978.4944s\n",
      "\titers: 200, epoch: 5 | loss: 0.1260659\n",
      "\tspeed: 0.0335s/iter; left time: 298.2778s\n",
      "\titers: 300, epoch: 5 | loss: 0.2171169\n",
      "\tspeed: 0.0334s/iter; left time: 294.4542s\n",
      "\titers: 400, epoch: 5 | loss: 0.1748926\n",
      "\tspeed: 0.0331s/iter; left time: 288.3775s\n",
      "\titers: 500, epoch: 5 | loss: 0.1835233\n",
      "\tspeed: 0.0340s/iter; left time: 292.5204s\n",
      "Epoch: 5 cost time: 19.225492000579834\n",
      "Epoch: 5, Steps: 569 | Train Loss: 0.1595555 Vali Loss: 0.2051675 Test Loss: 0.2429110\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2008954\n",
      "\tspeed: 0.1027s/iter; left time: 866.1518s\n",
      "\titers: 200, epoch: 6 | loss: 0.1291548\n",
      "\tspeed: 0.0321s/iter; left time: 267.2844s\n",
      "\titers: 300, epoch: 6 | loss: 0.1156660\n",
      "\tspeed: 0.0338s/iter; left time: 278.0178s\n",
      "\titers: 400, epoch: 6 | loss: 0.1419087\n",
      "\tspeed: 0.0319s/iter; left time: 259.5252s\n",
      "\titers: 500, epoch: 6 | loss: 0.1029783\n",
      "\tspeed: 0.0319s/iter; left time: 256.4483s\n",
      "Epoch: 6 cost time: 18.38589859008789\n",
      "Epoch: 6, Steps: 569 | Train Loss: 0.1543006 Vali Loss: 0.2060284 Test Loss: 0.2452494\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1445889\n",
      "\tspeed: 0.1043s/iter; left time: 820.1792s\n",
      "\titers: 200, epoch: 7 | loss: 0.1265288\n",
      "\tspeed: 0.0318s/iter; left time: 247.3738s\n",
      "\titers: 300, epoch: 7 | loss: 0.1314062\n",
      "\tspeed: 0.0326s/iter; left time: 250.1170s\n",
      "\titers: 400, epoch: 7 | loss: 0.2316690\n",
      "\tspeed: 0.0322s/iter; left time: 243.3821s\n",
      "\titers: 500, epoch: 7 | loss: 0.2423016\n",
      "\tspeed: 0.0335s/iter; left time: 250.1785s\n",
      "Epoch: 7 cost time: 18.551600217819214\n",
      "Epoch: 7, Steps: 569 | Train Loss: 0.1514078 Vali Loss: 0.2068589 Test Loss: 0.2457044\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl120_ll40_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "Test cost time: 2.2203s\n",
      "test shape: (177, 32, 6, 1) (177, 32, 6, 1)\n",
      "test shape: (5664, 6, 1) (5664, 6, 1)\n",
      "mse:0.2362813502550125, mae:0.3197091519832611\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl120_ll40_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1712.916259765625\n",
      "MAE:  27.221275329589844\n",
      "RMSE: 41.387393951416016\n",
      "MAPE: 0.34492138028144836\n",
      "MSPE: 0.6438660621643066\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl120_ll40_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20913\n",
      "[DEBUG] Original dataset length: 20913\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 18236\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6556\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "\titers: 100, epoch: 1 | loss: 0.3888552\n",
      "\tspeed: 0.0331s/iter; left time: 373.8644s\n",
      "\titers: 200, epoch: 1 | loss: 0.4340973\n",
      "\tspeed: 0.0331s/iter; left time: 370.2365s\n",
      "\titers: 300, epoch: 1 | loss: 0.2362785\n",
      "\tspeed: 0.0326s/iter; left time: 361.4655s\n",
      "\titers: 400, epoch: 1 | loss: 0.2598915\n",
      "\tspeed: 0.0322s/iter; left time: 353.6393s\n",
      "\titers: 500, epoch: 1 | loss: 0.2462052\n",
      "\tspeed: 0.0321s/iter; left time: 349.4389s\n",
      "Epoch: 1 cost time: 18.69383931159973\n",
      "Epoch: 1, Steps: 569 | Train Loss: 0.3204760 Vali Loss: 0.2116981 Test Loss: 0.2578085\n",
      "Validation loss decreased (inf --> 0.211698).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3513825\n",
      "\tspeed: 0.1044s/iter; left time: 1118.7964s\n",
      "\titers: 200, epoch: 2 | loss: 0.2096526\n",
      "\tspeed: 0.0319s/iter; left time: 338.0665s\n",
      "\titers: 300, epoch: 2 | loss: 0.2351590\n",
      "\tspeed: 0.0326s/iter; left time: 342.3606s\n",
      "\titers: 400, epoch: 2 | loss: 0.2400928\n",
      "\tspeed: 0.0342s/iter; left time: 355.7498s\n",
      "\titers: 500, epoch: 2 | loss: 0.1533642\n",
      "\tspeed: 0.0319s/iter; left time: 329.2446s\n",
      "Epoch: 2 cost time: 18.50382900238037\n",
      "Epoch: 2, Steps: 569 | Train Loss: 0.2158068 Vali Loss: 0.1996273 Test Loss: 0.2460195\n",
      "Validation loss decreased (0.211698 --> 0.199627).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1386320\n",
      "\tspeed: 0.1045s/iter; left time: 1059.6863s\n",
      "\titers: 200, epoch: 3 | loss: 0.1439839\n",
      "\tspeed: 0.0332s/iter; left time: 333.5015s\n",
      "\titers: 300, epoch: 3 | loss: 0.1559320\n",
      "\tspeed: 0.0320s/iter; left time: 318.1362s\n",
      "\titers: 400, epoch: 3 | loss: 0.1995775\n",
      "\tspeed: 0.0319s/iter; left time: 314.1099s\n",
      "\titers: 500, epoch: 3 | loss: 0.1391588\n",
      "\tspeed: 0.0332s/iter; left time: 323.0658s\n",
      "Epoch: 3 cost time: 18.64618468284607\n",
      "Epoch: 3, Steps: 569 | Train Loss: 0.1857624 Vali Loss: 0.1986078 Test Loss: 0.2363542\n",
      "Validation loss decreased (0.199627 --> 0.198608).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2060142\n",
      "\tspeed: 0.1030s/iter; left time: 985.8266s\n",
      "\titers: 200, epoch: 4 | loss: 0.2416633\n",
      "\tspeed: 0.0312s/iter; left time: 296.0557s\n",
      "\titers: 300, epoch: 4 | loss: 0.3227738\n",
      "\tspeed: 0.0331s/iter; left time: 310.3079s\n",
      "\titers: 400, epoch: 4 | loss: 0.1561185\n",
      "\tspeed: 0.0326s/iter; left time: 302.3997s\n",
      "\titers: 500, epoch: 4 | loss: 0.1607028\n",
      "\tspeed: 0.0308s/iter; left time: 282.7434s\n",
      "Epoch: 4 cost time: 18.20327401161194\n",
      "Epoch: 4, Steps: 569 | Train Loss: 0.1694104 Vali Loss: 0.2017255 Test Loss: 0.2346141\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1350514\n",
      "\tspeed: 0.1028s/iter; left time: 925.8507s\n",
      "\titers: 200, epoch: 5 | loss: 0.1259482\n",
      "\tspeed: 0.0317s/iter; left time: 282.6812s\n",
      "\titers: 300, epoch: 5 | loss: 0.1279791\n",
      "\tspeed: 0.0320s/iter; left time: 281.3229s\n",
      "\titers: 400, epoch: 5 | loss: 0.1698021\n",
      "\tspeed: 0.0321s/iter; left time: 279.2920s\n",
      "\titers: 500, epoch: 5 | loss: 0.1922019\n",
      "\tspeed: 0.0328s/iter; left time: 282.1328s\n",
      "Epoch: 5 cost time: 18.409815788269043\n",
      "Epoch: 5, Steps: 569 | Train Loss: 0.1601162 Vali Loss: 0.2073936 Test Loss: 0.2357436\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1349442\n",
      "\tspeed: 0.1015s/iter; left time: 856.0206s\n",
      "\titers: 200, epoch: 6 | loss: 0.1290162\n",
      "\tspeed: 0.0328s/iter; left time: 273.2396s\n",
      "\titers: 300, epoch: 6 | loss: 0.1286837\n",
      "\tspeed: 0.0334s/iter; left time: 275.0177s\n",
      "\titers: 400, epoch: 6 | loss: 0.1019391\n",
      "\tspeed: 0.0342s/iter; left time: 278.0377s\n",
      "\titers: 500, epoch: 6 | loss: 0.1295683\n",
      "\tspeed: 0.0327s/iter; left time: 262.7628s\n",
      "Epoch: 6 cost time: 18.648579359054565\n",
      "Epoch: 6, Steps: 569 | Train Loss: 0.1554180 Vali Loss: 0.2076719 Test Loss: 0.2366263\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl120_ll40_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5666\n",
      "Test cost time: 2.2753s\n",
      "test shape: (177, 32, 6, 1) (177, 32, 6, 1)\n",
      "test shape: (5664, 6, 1) (5664, 6, 1)\n",
      "mse:0.2360776662826538, mae:0.3356129229068756\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl120_ll40_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1711.4398193359375\n",
      "MAE:  28.575382232666016\n",
      "RMSE: 41.36955261230469\n",
      "MAPE: 0.44026413559913635\n",
      "MSPE: 1.090335488319397\n",
      ">>>>>>>Running time saved<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Running seq_len=144, label_len=48, pred_len=6\n",
      "Args in experiment:\n",
      "Namespace(model='informer', data='traffic_full', root_path='../', data_path='traffic_full.csv', features='S', target='flow', freq='h', checkpoints='./checkpoints/', seq_len=144, label_len=48, pred_len=6, enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=2, d_layers=1, s_layers=[3, 2, 1], d_ff=2048, factor=5, padding=0, distil=True, dropout=0.05, attn='prob', embed='timeF', activation='gelu', output_attention=False, do_predict=False, mix=True, cols=None, num_workers=0, itr=10, train_epochs=20, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, inverse=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', detail_freq='h')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl144_ll48_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20889\n",
      "[DEBUG] Original dataset length: 20889\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 17876\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6484\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "\titers: 100, epoch: 1 | loss: 0.5997509\n",
      "\tspeed: 0.0506s/iter; left time: 559.8142s\n",
      "\titers: 200, epoch: 1 | loss: 0.2863265\n",
      "\tspeed: 0.0367s/iter; left time: 402.6576s\n",
      "\titers: 300, epoch: 1 | loss: 0.2553843\n",
      "\tspeed: 0.0365s/iter; left time: 395.9278s\n",
      "\titers: 400, epoch: 1 | loss: 0.1782361\n",
      "\tspeed: 0.0359s/iter; left time: 386.7662s\n",
      "\titers: 500, epoch: 1 | loss: 0.1407391\n",
      "\tspeed: 0.0353s/iter; left time: 376.1289s\n",
      "Epoch: 1 cost time: 20.70949125289917\n",
      "Epoch: 1, Steps: 558 | Train Loss: 0.3321116 Vali Loss: 0.2447388 Test Loss: 0.2809508\n",
      "Validation loss decreased (inf --> 0.244739).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1702173\n",
      "\tspeed: 0.1102s/iter; left time: 1157.5878s\n",
      "\titers: 200, epoch: 2 | loss: 0.2254569\n",
      "\tspeed: 0.0349s/iter; left time: 363.4614s\n",
      "\titers: 300, epoch: 2 | loss: 0.2019668\n",
      "\tspeed: 0.0364s/iter; left time: 375.1919s\n",
      "\titers: 400, epoch: 2 | loss: 0.2178896\n",
      "\tspeed: 0.0366s/iter; left time: 373.8632s\n",
      "\titers: 500, epoch: 2 | loss: 0.1434614\n",
      "\tspeed: 0.0352s/iter; left time: 355.8366s\n",
      "Epoch: 2 cost time: 19.921178817749023\n",
      "Epoch: 2, Steps: 558 | Train Loss: 0.2122860 Vali Loss: 0.1946492 Test Loss: 0.2375429\n",
      "Validation loss decreased (0.244739 --> 0.194649).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1595832\n",
      "\tspeed: 0.1099s/iter; left time: 1093.3282s\n",
      "\titers: 200, epoch: 3 | loss: 0.1887659\n",
      "\tspeed: 0.0347s/iter; left time: 342.0007s\n",
      "\titers: 300, epoch: 3 | loss: 0.1488919\n",
      "\tspeed: 0.0346s/iter; left time: 337.1510s\n",
      "\titers: 400, epoch: 3 | loss: 0.2643709\n",
      "\tspeed: 0.0353s/iter; left time: 340.8266s\n",
      "\titers: 500, epoch: 3 | loss: 0.2211435\n",
      "\tspeed: 0.0356s/iter; left time: 339.9096s\n",
      "Epoch: 3 cost time: 19.668418645858765\n",
      "Epoch: 3, Steps: 558 | Train Loss: 0.1831672 Vali Loss: 0.1988832 Test Loss: 0.2403083\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1787054\n",
      "\tspeed: 0.1072s/iter; left time: 1006.5427s\n",
      "\titers: 200, epoch: 4 | loss: 0.1503719\n",
      "\tspeed: 0.0370s/iter; left time: 343.8232s\n",
      "\titers: 300, epoch: 4 | loss: 0.2013166\n",
      "\tspeed: 0.0354s/iter; left time: 325.3671s\n",
      "\titers: 400, epoch: 4 | loss: 0.1786345\n",
      "\tspeed: 0.0354s/iter; left time: 321.4240s\n",
      "\titers: 500, epoch: 4 | loss: 0.1413368\n",
      "\tspeed: 0.0353s/iter; left time: 317.6218s\n",
      "Epoch: 4 cost time: 19.994717836380005\n",
      "Epoch: 4, Steps: 558 | Train Loss: 0.1673247 Vali Loss: 0.1960129 Test Loss: 0.2368866\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1347437\n",
      "\tspeed: 0.1102s/iter; left time: 973.2529s\n",
      "\titers: 200, epoch: 5 | loss: 0.1280824\n",
      "\tspeed: 0.0360s/iter; left time: 314.0569s\n",
      "\titers: 300, epoch: 5 | loss: 0.1162031\n",
      "\tspeed: 0.0371s/iter; left time: 319.7716s\n",
      "\titers: 400, epoch: 5 | loss: 0.1799599\n",
      "\tspeed: 0.0355s/iter; left time: 302.8195s\n",
      "\titers: 500, epoch: 5 | loss: 0.0896647\n",
      "\tspeed: 0.0347s/iter; left time: 292.4384s\n",
      "Epoch: 5 cost time: 19.948501348495483\n",
      "Epoch: 5, Steps: 558 | Train Loss: 0.1585901 Vali Loss: 0.2023449 Test Loss: 0.2452834\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl144_ll48_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "Test cost time: 2.4087s\n",
      "test shape: (171, 32, 6, 1) (171, 32, 6, 1)\n",
      "test shape: (5472, 6, 1) (5472, 6, 1)\n",
      "mse:0.23804986476898193, mae:0.3442067503929138\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl144_ll48_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1725.737060546875\n",
      "MAE:  29.307090759277344\n",
      "RMSE: 41.5419921875\n",
      "MAPE: 0.45767349004745483\n",
      "MSPE: 1.038880705833435\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl144_ll48_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20889\n",
      "[DEBUG] Original dataset length: 20889\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 17876\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6484\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "\titers: 100, epoch: 1 | loss: 0.5306754\n",
      "\tspeed: 0.0349s/iter; left time: 385.5965s\n",
      "\titers: 200, epoch: 1 | loss: 0.3535411\n",
      "\tspeed: 0.0365s/iter; left time: 399.8928s\n",
      "\titers: 300, epoch: 1 | loss: 0.1952547\n",
      "\tspeed: 0.0355s/iter; left time: 385.9546s\n",
      "\titers: 400, epoch: 1 | loss: 0.1521324\n",
      "\tspeed: 0.0358s/iter; left time: 385.6937s\n",
      "\titers: 500, epoch: 1 | loss: 0.2253262\n",
      "\tspeed: 0.0370s/iter; left time: 394.3080s\n",
      "Epoch: 1 cost time: 20.09273862838745\n",
      "Epoch: 1, Steps: 558 | Train Loss: 0.3253510 Vali Loss: 0.2163868 Test Loss: 0.2648861\n",
      "Validation loss decreased (inf --> 0.216387).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2035049\n",
      "\tspeed: 0.1094s/iter; left time: 1149.3533s\n",
      "\titers: 200, epoch: 2 | loss: 0.2421677\n",
      "\tspeed: 0.0357s/iter; left time: 371.5845s\n",
      "\titers: 300, epoch: 2 | loss: 0.1915373\n",
      "\tspeed: 0.0359s/iter; left time: 369.5304s\n",
      "\titers: 400, epoch: 2 | loss: 0.1608692\n",
      "\tspeed: 0.0354s/iter; left time: 361.4796s\n",
      "\titers: 500, epoch: 2 | loss: 0.2197944\n",
      "\tspeed: 0.0361s/iter; left time: 364.7357s\n",
      "Epoch: 2 cost time: 20.019272804260254\n",
      "Epoch: 2, Steps: 558 | Train Loss: 0.2172523 Vali Loss: 0.2089764 Test Loss: 0.2488530\n",
      "Validation loss decreased (0.216387 --> 0.208976).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1456998\n",
      "\tspeed: 0.1119s/iter; left time: 1113.0765s\n",
      "\titers: 200, epoch: 3 | loss: 0.2196883\n",
      "\tspeed: 0.0358s/iter; left time: 352.8367s\n",
      "\titers: 300, epoch: 3 | loss: 0.1346654\n",
      "\tspeed: 0.0360s/iter; left time: 350.6253s\n",
      "\titers: 400, epoch: 3 | loss: 0.2065915\n",
      "\tspeed: 0.0354s/iter; left time: 341.5420s\n",
      "\titers: 500, epoch: 3 | loss: 0.1708151\n",
      "\tspeed: 0.0347s/iter; left time: 331.1735s\n",
      "Epoch: 3 cost time: 19.82574152946472\n",
      "Epoch: 3, Steps: 558 | Train Loss: 0.1833694 Vali Loss: 0.2032603 Test Loss: 0.2420684\n",
      "Validation loss decreased (0.208976 --> 0.203260).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1383716\n",
      "\tspeed: 0.1105s/iter; left time: 1037.5345s\n",
      "\titers: 200, epoch: 4 | loss: 0.2228547\n",
      "\tspeed: 0.0355s/iter; left time: 329.3002s\n",
      "\titers: 300, epoch: 4 | loss: 0.2092175\n",
      "\tspeed: 0.0359s/iter; left time: 329.7367s\n",
      "\titers: 400, epoch: 4 | loss: 0.0946466\n",
      "\tspeed: 0.0357s/iter; left time: 324.5744s\n",
      "\titers: 500, epoch: 4 | loss: 0.1425411\n",
      "\tspeed: 0.0356s/iter; left time: 319.5252s\n",
      "Epoch: 4 cost time: 19.807223081588745\n",
      "Epoch: 4, Steps: 558 | Train Loss: 0.1684266 Vali Loss: 0.1956058 Test Loss: 0.2334279\n",
      "Validation loss decreased (0.203260 --> 0.195606).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1895595\n",
      "\tspeed: 0.1103s/iter; left time: 973.6903s\n",
      "\titers: 200, epoch: 5 | loss: 0.2302871\n",
      "\tspeed: 0.0356s/iter; left time: 310.9680s\n",
      "\titers: 300, epoch: 5 | loss: 0.1690836\n",
      "\tspeed: 0.0358s/iter; left time: 309.1215s\n",
      "\titers: 400, epoch: 5 | loss: 0.0998032\n",
      "\tspeed: 0.0344s/iter; left time: 293.2236s\n",
      "\titers: 500, epoch: 5 | loss: 0.1810634\n",
      "\tspeed: 0.0371s/iter; left time: 313.1208s\n",
      "Epoch: 5 cost time: 20.03313660621643\n",
      "Epoch: 5, Steps: 558 | Train Loss: 0.1598972 Vali Loss: 0.1954647 Test Loss: 0.2398179\n",
      "Validation loss decreased (0.195606 --> 0.195465).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1832400\n",
      "\tspeed: 0.1082s/iter; left time: 895.1358s\n",
      "\titers: 200, epoch: 6 | loss: 0.1475517\n",
      "\tspeed: 0.0365s/iter; left time: 297.8684s\n",
      "\titers: 300, epoch: 6 | loss: 0.1827272\n",
      "\tspeed: 0.0361s/iter; left time: 291.6730s\n",
      "\titers: 400, epoch: 6 | loss: 0.3205752\n",
      "\tspeed: 0.0357s/iter; left time: 284.3029s\n",
      "\titers: 500, epoch: 6 | loss: 0.1567193\n",
      "\tspeed: 0.0351s/iter; left time: 275.9042s\n",
      "Epoch: 6 cost time: 19.90734314918518\n",
      "Epoch: 6, Steps: 558 | Train Loss: 0.1552661 Vali Loss: 0.1939297 Test Loss: 0.2369877\n",
      "Validation loss decreased (0.195465 --> 0.193930).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1350066\n",
      "\tspeed: 0.1079s/iter; left time: 832.0914s\n",
      "\titers: 200, epoch: 7 | loss: 0.1861907\n",
      "\tspeed: 0.0340s/iter; left time: 258.8054s\n",
      "\titers: 300, epoch: 7 | loss: 0.1302992\n",
      "\tspeed: 0.0334s/iter; left time: 250.7328s\n",
      "\titers: 400, epoch: 7 | loss: 0.2239690\n",
      "\tspeed: 0.0339s/iter; left time: 251.3910s\n",
      "\titers: 500, epoch: 7 | loss: 0.1403199\n",
      "\tspeed: 0.0343s/iter; left time: 251.0469s\n",
      "Epoch: 7 cost time: 18.970052480697632\n",
      "Epoch: 7, Steps: 558 | Train Loss: 0.1524124 Vali Loss: 0.1945010 Test Loss: 0.2366780\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1283110\n",
      "\tspeed: 0.1070s/iter; left time: 765.7022s\n",
      "\titers: 200, epoch: 8 | loss: 0.1602615\n",
      "\tspeed: 0.0354s/iter; left time: 249.8650s\n",
      "\titers: 300, epoch: 8 | loss: 0.1269500\n",
      "\tspeed: 0.0345s/iter; left time: 239.7912s\n",
      "\titers: 400, epoch: 8 | loss: 0.1365731\n",
      "\tspeed: 0.0348s/iter; left time: 238.7547s\n",
      "\titers: 500, epoch: 8 | loss: 0.2129657\n",
      "\tspeed: 0.0361s/iter; left time: 243.6870s\n",
      "Epoch: 8 cost time: 19.65153479576111\n",
      "Epoch: 8, Steps: 558 | Train Loss: 0.1502859 Vali Loss: 0.1953942 Test Loss: 0.2392971\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1629264\n",
      "\tspeed: 0.1074s/iter; left time: 708.2531s\n",
      "\titers: 200, epoch: 9 | loss: 0.1185631\n",
      "\tspeed: 0.0361s/iter; left time: 234.7591s\n",
      "\titers: 300, epoch: 9 | loss: 0.1666730\n",
      "\tspeed: 0.0359s/iter; left time: 229.9661s\n",
      "\titers: 400, epoch: 9 | loss: 0.1917084\n",
      "\tspeed: 0.0348s/iter; left time: 219.3004s\n",
      "\titers: 500, epoch: 9 | loss: 0.1240434\n",
      "\tspeed: 0.0332s/iter; left time: 205.5718s\n",
      "Epoch: 9 cost time: 19.46540641784668\n",
      "Epoch: 9, Steps: 558 | Train Loss: 0.1504244 Vali Loss: 0.1951125 Test Loss: 0.2386498\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl144_ll48_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "Test cost time: 2.3681s\n",
      "test shape: (171, 32, 6, 1) (171, 32, 6, 1)\n",
      "test shape: (5472, 6, 1) (5472, 6, 1)\n",
      "mse:0.23653870820999146, mae:0.31967276334762573\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl144_ll48_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1714.7822265625\n",
      "MAE:  27.218175888061523\n",
      "RMSE: 41.40992736816406\n",
      "MAPE: 0.35697442293167114\n",
      "MSPE: 0.6450231671333313\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl144_ll48_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20889\n",
      "[DEBUG] Original dataset length: 20889\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 17876\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6484\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "\titers: 100, epoch: 1 | loss: 0.3089459\n",
      "\tspeed: 0.0345s/iter; left time: 381.9456s\n",
      "\titers: 200, epoch: 1 | loss: 0.4676453\n",
      "\tspeed: 0.0349s/iter; left time: 382.6935s\n",
      "\titers: 300, epoch: 1 | loss: 0.2180494\n",
      "\tspeed: 0.0356s/iter; left time: 386.6184s\n",
      "\titers: 400, epoch: 1 | loss: 0.1767164\n",
      "\tspeed: 0.0357s/iter; left time: 383.7397s\n",
      "\titers: 500, epoch: 1 | loss: 0.1305403\n",
      "\tspeed: 0.0350s/iter; left time: 372.8474s\n",
      "Epoch: 1 cost time: 19.609065055847168\n",
      "Epoch: 1, Steps: 558 | Train Loss: 0.3088658 Vali Loss: 0.2058107 Test Loss: 0.2572675\n",
      "Validation loss decreased (inf --> 0.205811).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1812935\n",
      "\tspeed: 0.1019s/iter; left time: 1070.2686s\n",
      "\titers: 200, epoch: 2 | loss: 0.2061169\n",
      "\tspeed: 0.0324s/iter; left time: 336.9892s\n",
      "\titers: 300, epoch: 2 | loss: 0.3777673\n",
      "\tspeed: 0.0356s/iter; left time: 366.9358s\n",
      "\titers: 400, epoch: 2 | loss: 0.3428444\n",
      "\tspeed: 0.0375s/iter; left time: 382.6089s\n",
      "\titers: 500, epoch: 2 | loss: 0.2603790\n",
      "\tspeed: 0.0358s/iter; left time: 361.3195s\n",
      "Epoch: 2 cost time: 19.418907403945923\n",
      "Epoch: 2, Steps: 558 | Train Loss: 0.2136684 Vali Loss: 0.1998866 Test Loss: 0.2459745\n",
      "Validation loss decreased (0.205811 --> 0.199887).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1533766\n",
      "\tspeed: 0.1095s/iter; left time: 1089.2851s\n",
      "\titers: 200, epoch: 3 | loss: 0.1324546\n",
      "\tspeed: 0.0350s/iter; left time: 344.4405s\n",
      "\titers: 300, epoch: 3 | loss: 0.1670330\n",
      "\tspeed: 0.0353s/iter; left time: 343.9581s\n",
      "\titers: 400, epoch: 3 | loss: 0.1617744\n",
      "\tspeed: 0.0355s/iter; left time: 342.5741s\n",
      "\titers: 500, epoch: 3 | loss: 0.2720776\n",
      "\tspeed: 0.0349s/iter; left time: 332.9619s\n",
      "Epoch: 3 cost time: 19.766629934310913\n",
      "Epoch: 3, Steps: 558 | Train Loss: 0.1815376 Vali Loss: 0.2025562 Test Loss: 0.2455318\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1530918\n",
      "\tspeed: 0.1089s/iter; left time: 1022.1883s\n",
      "\titers: 200, epoch: 4 | loss: 0.1494182\n",
      "\tspeed: 0.0347s/iter; left time: 322.1584s\n",
      "\titers: 300, epoch: 4 | loss: 0.1277395\n",
      "\tspeed: 0.0358s/iter; left time: 329.1184s\n",
      "\titers: 400, epoch: 4 | loss: 0.2047873\n",
      "\tspeed: 0.0350s/iter; left time: 317.9447s\n",
      "\titers: 500, epoch: 4 | loss: 0.1563947\n",
      "\tspeed: 0.0350s/iter; left time: 314.1700s\n",
      "Epoch: 4 cost time: 19.531754732131958\n",
      "Epoch: 4, Steps: 558 | Train Loss: 0.1673915 Vali Loss: 0.1947964 Test Loss: 0.2331613\n",
      "Validation loss decreased (0.199887 --> 0.194796).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1432969\n",
      "\tspeed: 0.1095s/iter; left time: 967.0198s\n",
      "\titers: 200, epoch: 5 | loss: 0.1167303\n",
      "\tspeed: 0.0353s/iter; left time: 307.8636s\n",
      "\titers: 300, epoch: 5 | loss: 0.1317626\n",
      "\tspeed: 0.0348s/iter; left time: 300.3975s\n",
      "\titers: 400, epoch: 5 | loss: 0.2622644\n",
      "\tspeed: 0.0356s/iter; left time: 303.4471s\n",
      "\titers: 500, epoch: 5 | loss: 0.2437781\n",
      "\tspeed: 0.0357s/iter; left time: 301.1940s\n",
      "Epoch: 5 cost time: 19.71338653564453\n",
      "Epoch: 5, Steps: 558 | Train Loss: 0.1588330 Vali Loss: 0.1987093 Test Loss: 0.2348163\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2983202\n",
      "\tspeed: 0.1066s/iter; left time: 882.0494s\n",
      "\titers: 200, epoch: 6 | loss: 0.1047434\n",
      "\tspeed: 0.0362s/iter; left time: 295.5775s\n",
      "\titers: 300, epoch: 6 | loss: 0.1363859\n",
      "\tspeed: 0.0347s/iter; left time: 280.2404s\n",
      "\titers: 400, epoch: 6 | loss: 0.1221523\n",
      "\tspeed: 0.0349s/iter; left time: 278.4137s\n",
      "\titers: 500, epoch: 6 | loss: 0.1220798\n",
      "\tspeed: 0.0346s/iter; left time: 272.4360s\n",
      "Epoch: 6 cost time: 19.696597576141357\n",
      "Epoch: 6, Steps: 558 | Train Loss: 0.1540695 Vali Loss: 0.2008550 Test Loss: 0.2400242\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0998862\n",
      "\tspeed: 0.1079s/iter; left time: 831.9828s\n",
      "\titers: 200, epoch: 7 | loss: 0.1124904\n",
      "\tspeed: 0.0352s/iter; left time: 268.0587s\n",
      "\titers: 300, epoch: 7 | loss: 0.1637942\n",
      "\tspeed: 0.0357s/iter; left time: 267.8386s\n",
      "\titers: 400, epoch: 7 | loss: 0.1594292\n",
      "\tspeed: 0.0355s/iter; left time: 262.8190s\n",
      "\titers: 500, epoch: 7 | loss: 0.0798822\n",
      "\tspeed: 0.0354s/iter; left time: 259.0649s\n",
      "Epoch: 7 cost time: 19.775331258773804\n",
      "Epoch: 7, Steps: 558 | Train Loss: 0.1515650 Vali Loss: 0.2017002 Test Loss: 0.2389355\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl144_ll48_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "Test cost time: 2.3522s\n",
      "test shape: (171, 32, 6, 1) (171, 32, 6, 1)\n",
      "test shape: (5472, 6, 1) (5472, 6, 1)\n",
      "mse:0.23322437703609467, mae:0.3257501721382141\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl144_ll48_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1690.755126953125\n",
      "MAE:  27.735626220703125\n",
      "RMSE: 41.11879348754883\n",
      "MAPE: 0.3972730040550232\n",
      "MSPE: 0.815405011177063\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl144_ll48_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20889\n",
      "[DEBUG] Original dataset length: 20889\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 17876\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6484\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "\titers: 100, epoch: 1 | loss: 0.3828226\n",
      "\tspeed: 0.0351s/iter; left time: 388.1686s\n",
      "\titers: 200, epoch: 1 | loss: 0.5291617\n",
      "\tspeed: 0.0349s/iter; left time: 382.8296s\n",
      "\titers: 300, epoch: 1 | loss: 0.2763386\n",
      "\tspeed: 0.0356s/iter; left time: 386.4255s\n",
      "\titers: 400, epoch: 1 | loss: 0.4359057\n",
      "\tspeed: 0.0364s/iter; left time: 391.8748s\n",
      "\titers: 500, epoch: 1 | loss: 0.2347469\n",
      "\tspeed: 0.0344s/iter; left time: 366.7222s\n",
      "Epoch: 1 cost time: 19.69839835166931\n",
      "Epoch: 1, Steps: 558 | Train Loss: 0.3352066 Vali Loss: 0.2044972 Test Loss: 0.2500024\n",
      "Validation loss decreased (inf --> 0.204497).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1833870\n",
      "\tspeed: 0.1086s/iter; left time: 1140.4101s\n",
      "\titers: 200, epoch: 2 | loss: 0.1635371\n",
      "\tspeed: 0.0349s/iter; left time: 363.4309s\n",
      "\titers: 300, epoch: 2 | loss: 0.1242627\n",
      "\tspeed: 0.0357s/iter; left time: 367.7025s\n",
      "\titers: 400, epoch: 2 | loss: 0.1719317\n",
      "\tspeed: 0.0344s/iter; left time: 350.6725s\n",
      "\titers: 500, epoch: 2 | loss: 0.2134856\n",
      "\tspeed: 0.0362s/iter; left time: 365.8271s\n",
      "Epoch: 2 cost time: 19.79724621772766\n",
      "Epoch: 2, Steps: 558 | Train Loss: 0.2130182 Vali Loss: 0.2316851 Test Loss: 0.2818368\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2247505\n",
      "\tspeed: 0.1067s/iter; left time: 1061.5929s\n",
      "\titers: 200, epoch: 3 | loss: 0.2093820\n",
      "\tspeed: 0.0366s/iter; left time: 359.8398s\n",
      "\titers: 300, epoch: 3 | loss: 0.1814749\n",
      "\tspeed: 0.0353s/iter; left time: 343.5802s\n",
      "\titers: 400, epoch: 3 | loss: 0.1563783\n",
      "\tspeed: 0.0345s/iter; left time: 333.1826s\n",
      "\titers: 500, epoch: 3 | loss: 0.2243239\n",
      "\tspeed: 0.0347s/iter; left time: 331.5525s\n",
      "Epoch: 3 cost time: 19.609225749969482\n",
      "Epoch: 3, Steps: 558 | Train Loss: 0.1854191 Vali Loss: 0.2037633 Test Loss: 0.2502166\n",
      "Validation loss decreased (0.204497 --> 0.203763).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0925485\n",
      "\tspeed: 0.1077s/iter; left time: 1010.7112s\n",
      "\titers: 200, epoch: 4 | loss: 0.1915007\n",
      "\tspeed: 0.0344s/iter; left time: 319.7161s\n",
      "\titers: 300, epoch: 4 | loss: 0.1153496\n",
      "\tspeed: 0.0346s/iter; left time: 317.9402s\n",
      "\titers: 400, epoch: 4 | loss: 0.1314067\n",
      "\tspeed: 0.0362s/iter; left time: 328.5983s\n",
      "\titers: 500, epoch: 4 | loss: 0.1869922\n",
      "\tspeed: 0.0353s/iter; left time: 317.6448s\n",
      "Epoch: 4 cost time: 19.535691261291504\n",
      "Epoch: 4, Steps: 558 | Train Loss: 0.1709691 Vali Loss: 0.2010449 Test Loss: 0.2454945\n",
      "Validation loss decreased (0.203763 --> 0.201045).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1419093\n",
      "\tspeed: 0.1074s/iter; left time: 947.9559s\n",
      "\titers: 200, epoch: 5 | loss: 0.1943003\n",
      "\tspeed: 0.0353s/iter; left time: 308.2698s\n",
      "\titers: 300, epoch: 5 | loss: 0.1733269\n",
      "\tspeed: 0.0353s/iter; left time: 304.6675s\n",
      "\titers: 400, epoch: 5 | loss: 0.1463634\n",
      "\tspeed: 0.0351s/iter; left time: 299.2695s\n",
      "\titers: 500, epoch: 5 | loss: 0.1030241\n",
      "\tspeed: 0.0344s/iter; left time: 289.6756s\n",
      "Epoch: 5 cost time: 19.621234893798828\n",
      "Epoch: 5, Steps: 558 | Train Loss: 0.1611324 Vali Loss: 0.2096615 Test Loss: 0.2541939\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2134525\n",
      "\tspeed: 0.1072s/iter; left time: 886.3440s\n",
      "\titers: 200, epoch: 6 | loss: 0.1371991\n",
      "\tspeed: 0.0346s/iter; left time: 282.8042s\n",
      "\titers: 300, epoch: 6 | loss: 0.1416799\n",
      "\tspeed: 0.0361s/iter; left time: 291.2532s\n",
      "\titers: 400, epoch: 6 | loss: 0.1402069\n",
      "\tspeed: 0.0349s/iter; left time: 278.3720s\n",
      "\titers: 500, epoch: 6 | loss: 0.1343188\n",
      "\tspeed: 0.0356s/iter; left time: 280.2453s\n",
      "Epoch: 6 cost time: 19.611722230911255\n",
      "Epoch: 6, Steps: 558 | Train Loss: 0.1566275 Vali Loss: 0.2095013 Test Loss: 0.2538998\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0916927\n",
      "\tspeed: 0.1077s/iter; left time: 831.0132s\n",
      "\titers: 200, epoch: 7 | loss: 0.1486608\n",
      "\tspeed: 0.0346s/iter; left time: 263.2663s\n",
      "\titers: 300, epoch: 7 | loss: 0.2106753\n",
      "\tspeed: 0.0342s/iter; left time: 257.1744s\n",
      "\titers: 400, epoch: 7 | loss: 0.2357823\n",
      "\tspeed: 0.0352s/iter; left time: 260.6076s\n",
      "\titers: 500, epoch: 7 | loss: 0.1185748\n",
      "\tspeed: 0.0355s/iter; left time: 259.6579s\n",
      "Epoch: 7 cost time: 19.452736854553223\n",
      "Epoch: 7, Steps: 558 | Train Loss: 0.1537092 Vali Loss: 0.2025914 Test Loss: 0.2484998\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl144_ll48_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "Test cost time: 2.3700s\n",
      "test shape: (171, 32, 6, 1) (171, 32, 6, 1)\n",
      "test shape: (5472, 6, 1) (5472, 6, 1)\n",
      "mse:0.24320274591445923, mae:0.32521089911460876\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl144_ll48_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1763.0931396484375\n",
      "MAE:  27.689716339111328\n",
      "RMSE: 41.98920440673828\n",
      "MAPE: 0.35617655515670776\n",
      "MSPE: 0.6110124588012695\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl144_ll48_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20889\n",
      "[DEBUG] Original dataset length: 20889\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 17876\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6484\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "\titers: 100, epoch: 1 | loss: 0.2925856\n",
      "\tspeed: 0.0356s/iter; left time: 393.3894s\n",
      "\titers: 200, epoch: 1 | loss: 0.2480009\n",
      "\tspeed: 0.0344s/iter; left time: 377.3913s\n",
      "\titers: 300, epoch: 1 | loss: 0.2333943\n",
      "\tspeed: 0.0366s/iter; left time: 397.2998s\n",
      "\titers: 400, epoch: 1 | loss: 0.2444786\n",
      "\tspeed: 0.0344s/iter; left time: 370.4017s\n",
      "\titers: 500, epoch: 1 | loss: 0.1547008\n",
      "\tspeed: 0.0356s/iter; left time: 379.3765s\n",
      "Epoch: 1 cost time: 19.726420879364014\n",
      "Epoch: 1, Steps: 558 | Train Loss: 0.3177622 Vali Loss: 0.1988965 Test Loss: 0.2544729\n",
      "Validation loss decreased (inf --> 0.198896).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1426104\n",
      "\tspeed: 0.1069s/iter; left time: 1122.9917s\n",
      "\titers: 200, epoch: 2 | loss: 0.1473037\n",
      "\tspeed: 0.0350s/iter; left time: 363.8507s\n",
      "\titers: 300, epoch: 2 | loss: 0.2239618\n",
      "\tspeed: 0.0350s/iter; left time: 360.6486s\n",
      "\titers: 400, epoch: 2 | loss: 0.2689109\n",
      "\tspeed: 0.0343s/iter; left time: 350.4625s\n",
      "\titers: 500, epoch: 2 | loss: 0.1256954\n",
      "\tspeed: 0.0340s/iter; left time: 343.3571s\n",
      "Epoch: 2 cost time: 19.29221224784851\n",
      "Epoch: 2, Steps: 558 | Train Loss: 0.2154766 Vali Loss: 0.2112297 Test Loss: 0.2526753\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2089880\n",
      "\tspeed: 0.1076s/iter; left time: 1070.1613s\n",
      "\titers: 200, epoch: 3 | loss: 0.2198903\n",
      "\tspeed: 0.0353s/iter; left time: 347.5607s\n",
      "\titers: 300, epoch: 3 | loss: 0.1536178\n",
      "\tspeed: 0.0351s/iter; left time: 341.7205s\n",
      "\titers: 400, epoch: 3 | loss: 0.1541068\n",
      "\tspeed: 0.0354s/iter; left time: 341.1788s\n",
      "\titers: 500, epoch: 3 | loss: 0.1347583\n",
      "\tspeed: 0.0348s/iter; left time: 332.4990s\n",
      "Epoch: 3 cost time: 19.61938786506653\n",
      "Epoch: 3, Steps: 558 | Train Loss: 0.1844893 Vali Loss: 0.1945556 Test Loss: 0.2422758\n",
      "Validation loss decreased (0.198896 --> 0.194556).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1486670\n",
      "\tspeed: 0.1101s/iter; left time: 1033.6874s\n",
      "\titers: 200, epoch: 4 | loss: 0.2194606\n",
      "\tspeed: 0.0360s/iter; left time: 334.7106s\n",
      "\titers: 300, epoch: 4 | loss: 0.1813910\n",
      "\tspeed: 0.0349s/iter; left time: 321.0248s\n",
      "\titers: 400, epoch: 4 | loss: 0.1605874\n",
      "\tspeed: 0.0360s/iter; left time: 327.3521s\n",
      "\titers: 500, epoch: 4 | loss: 0.1385025\n",
      "\tspeed: 0.0369s/iter; left time: 332.0251s\n",
      "Epoch: 4 cost time: 20.219722986221313\n",
      "Epoch: 4, Steps: 558 | Train Loss: 0.1682392 Vali Loss: 0.1911856 Test Loss: 0.2325630\n",
      "Validation loss decreased (0.194556 --> 0.191186).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1492969\n",
      "\tspeed: 0.1109s/iter; left time: 979.0990s\n",
      "\titers: 200, epoch: 5 | loss: 0.1315193\n",
      "\tspeed: 0.0361s/iter; left time: 315.3576s\n",
      "\titers: 300, epoch: 5 | loss: 0.1538744\n",
      "\tspeed: 0.0367s/iter; left time: 316.8569s\n",
      "\titers: 400, epoch: 5 | loss: 0.2386631\n",
      "\tspeed: 0.0341s/iter; left time: 290.9441s\n",
      "\titers: 500, epoch: 5 | loss: 0.1421864\n",
      "\tspeed: 0.0342s/iter; left time: 288.4741s\n",
      "Epoch: 5 cost time: 19.758946657180786\n",
      "Epoch: 5, Steps: 558 | Train Loss: 0.1596619 Vali Loss: 0.1963904 Test Loss: 0.2397049\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1863070\n",
      "\tspeed: 0.1064s/iter; left time: 879.9583s\n",
      "\titers: 200, epoch: 6 | loss: 0.1345896\n",
      "\tspeed: 0.0345s/iter; left time: 282.0121s\n",
      "\titers: 300, epoch: 6 | loss: 0.2726861\n",
      "\tspeed: 0.0351s/iter; left time: 282.9443s\n",
      "\titers: 400, epoch: 6 | loss: 0.1572619\n",
      "\tspeed: 0.0368s/iter; left time: 293.2785s\n",
      "\titers: 500, epoch: 6 | loss: 0.1513340\n",
      "\tspeed: 0.0343s/iter; left time: 270.1118s\n",
      "Epoch: 6 cost time: 19.613200426101685\n",
      "Epoch: 6, Steps: 558 | Train Loss: 0.1550144 Vali Loss: 0.1942899 Test Loss: 0.2358336\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1352680\n",
      "\tspeed: 0.1068s/iter; left time: 823.9296s\n",
      "\titers: 200, epoch: 7 | loss: 0.1785452\n",
      "\tspeed: 0.0345s/iter; left time: 262.9123s\n",
      "\titers: 300, epoch: 7 | loss: 0.1036221\n",
      "\tspeed: 0.0347s/iter; left time: 260.5202s\n",
      "\titers: 400, epoch: 7 | loss: 0.1477246\n",
      "\tspeed: 0.0343s/iter; left time: 253.9263s\n",
      "\titers: 500, epoch: 7 | loss: 0.1656774\n",
      "\tspeed: 0.0334s/iter; left time: 244.5105s\n",
      "Epoch: 7 cost time: 19.102792978286743\n",
      "Epoch: 7, Steps: 558 | Train Loss: 0.1519095 Vali Loss: 0.1974826 Test Loss: 0.2387665\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl144_ll48_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "Test cost time: 2.3744s\n",
      "test shape: (171, 32, 6, 1) (171, 32, 6, 1)\n",
      "test shape: (5472, 6, 1) (5472, 6, 1)\n",
      "mse:0.2324049472808838, mae:0.3258717656135559\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl144_ll48_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1684.8145751953125\n",
      "MAE:  27.74597930908203\n",
      "RMSE: 41.04649353027344\n",
      "MAPE: 0.37912464141845703\n",
      "MSPE: 0.6718275547027588\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl144_ll48_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20889\n",
      "[DEBUG] Original dataset length: 20889\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 17876\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6484\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "\titers: 100, epoch: 1 | loss: 0.3459480\n",
      "\tspeed: 0.0357s/iter; left time: 394.3392s\n",
      "\titers: 200, epoch: 1 | loss: 0.1852922\n",
      "\tspeed: 0.0352s/iter; left time: 385.4679s\n",
      "\titers: 300, epoch: 1 | loss: 0.2478725\n",
      "\tspeed: 0.0348s/iter; left time: 378.3801s\n",
      "\titers: 400, epoch: 1 | loss: 0.2173869\n",
      "\tspeed: 0.0349s/iter; left time: 375.4419s\n",
      "\titers: 500, epoch: 1 | loss: 0.1223410\n",
      "\tspeed: 0.0347s/iter; left time: 370.1337s\n",
      "Epoch: 1 cost time: 19.622657537460327\n",
      "Epoch: 1, Steps: 558 | Train Loss: 0.3282090 Vali Loss: 0.2074882 Test Loss: 0.2747734\n",
      "Validation loss decreased (inf --> 0.207488).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3187268\n",
      "\tspeed: 0.1082s/iter; left time: 1136.8760s\n",
      "\titers: 200, epoch: 2 | loss: 0.1501700\n",
      "\tspeed: 0.0348s/iter; left time: 362.0907s\n",
      "\titers: 300, epoch: 2 | loss: 0.1426499\n",
      "\tspeed: 0.0351s/iter; left time: 361.2070s\n",
      "\titers: 400, epoch: 2 | loss: 0.3009713\n",
      "\tspeed: 0.0351s/iter; left time: 357.9053s\n",
      "\titers: 500, epoch: 2 | loss: 0.2121708\n",
      "\tspeed: 0.0357s/iter; left time: 360.3908s\n",
      "Epoch: 2 cost time: 19.578972101211548\n",
      "Epoch: 2, Steps: 558 | Train Loss: 0.2108936 Vali Loss: 0.2081032 Test Loss: 0.2582582\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1621580\n",
      "\tspeed: 0.1079s/iter; left time: 1073.0183s\n",
      "\titers: 200, epoch: 3 | loss: 0.2801144\n",
      "\tspeed: 0.0345s/iter; left time: 339.2912s\n",
      "\titers: 300, epoch: 3 | loss: 0.1853290\n",
      "\tspeed: 0.0345s/iter; left time: 335.9702s\n",
      "\titers: 400, epoch: 3 | loss: 0.2241042\n",
      "\tspeed: 0.0347s/iter; left time: 334.7955s\n",
      "\titers: 500, epoch: 3 | loss: 0.1259515\n",
      "\tspeed: 0.0360s/iter; left time: 343.1634s\n",
      "Epoch: 3 cost time: 19.466217041015625\n",
      "Epoch: 3, Steps: 558 | Train Loss: 0.1822337 Vali Loss: 0.1988193 Test Loss: 0.2488347\n",
      "Validation loss decreased (0.207488 --> 0.198819).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1852470\n",
      "\tspeed: 0.1027s/iter; left time: 963.6915s\n",
      "\titers: 200, epoch: 4 | loss: 0.1652973\n",
      "\tspeed: 0.0353s/iter; left time: 327.6510s\n",
      "\titers: 300, epoch: 4 | loss: 0.1402325\n",
      "\tspeed: 0.0349s/iter; left time: 320.1961s\n",
      "\titers: 400, epoch: 4 | loss: 0.2411786\n",
      "\tspeed: 0.0342s/iter; left time: 311.0970s\n",
      "\titers: 500, epoch: 4 | loss: 0.0853089\n",
      "\tspeed: 0.0339s/iter; left time: 304.5115s\n",
      "Epoch: 4 cost time: 19.15733575820923\n",
      "Epoch: 4, Steps: 558 | Train Loss: 0.1661336 Vali Loss: 0.1953485 Test Loss: 0.2366970\n",
      "Validation loss decreased (0.198819 --> 0.195349).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2040797\n",
      "\tspeed: 0.1078s/iter; left time: 951.9409s\n",
      "\titers: 200, epoch: 5 | loss: 0.1029029\n",
      "\tspeed: 0.0351s/iter; left time: 306.1674s\n",
      "\titers: 300, epoch: 5 | loss: 0.1298656\n",
      "\tspeed: 0.0353s/iter; left time: 304.4417s\n",
      "\titers: 400, epoch: 5 | loss: 0.1432489\n",
      "\tspeed: 0.0342s/iter; left time: 291.6005s\n",
      "\titers: 500, epoch: 5 | loss: 0.1053801\n",
      "\tspeed: 0.0341s/iter; left time: 287.5095s\n",
      "Epoch: 5 cost time: 19.389674425125122\n",
      "Epoch: 5, Steps: 558 | Train Loss: 0.1565364 Vali Loss: 0.1938113 Test Loss: 0.2336978\n",
      "Validation loss decreased (0.195349 --> 0.193811).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2171405\n",
      "\tspeed: 0.1090s/iter; left time: 901.1499s\n",
      "\titers: 200, epoch: 6 | loss: 0.0937401\n",
      "\tspeed: 0.0349s/iter; left time: 284.9484s\n",
      "\titers: 300, epoch: 6 | loss: 0.0933173\n",
      "\tspeed: 0.0344s/iter; left time: 278.0118s\n",
      "\titers: 400, epoch: 6 | loss: 0.1546334\n",
      "\tspeed: 0.0345s/iter; left time: 275.3810s\n",
      "\titers: 500, epoch: 6 | loss: 0.2070324\n",
      "\tspeed: 0.0365s/iter; left time: 287.2986s\n",
      "Epoch: 6 cost time: 19.651507139205933\n",
      "Epoch: 6, Steps: 558 | Train Loss: 0.1520177 Vali Loss: 0.1962269 Test Loss: 0.2374811\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1412086\n",
      "\tspeed: 0.1062s/iter; left time: 819.3629s\n",
      "\titers: 200, epoch: 7 | loss: 0.0829287\n",
      "\tspeed: 0.0355s/iter; left time: 270.1729s\n",
      "\titers: 300, epoch: 7 | loss: 0.1422298\n",
      "\tspeed: 0.0362s/iter; left time: 271.7021s\n",
      "\titers: 400, epoch: 7 | loss: 0.1397975\n",
      "\tspeed: 0.0345s/iter; left time: 255.3987s\n",
      "\titers: 500, epoch: 7 | loss: 0.1754481\n",
      "\tspeed: 0.0350s/iter; left time: 255.8334s\n",
      "Epoch: 7 cost time: 19.61173439025879\n",
      "Epoch: 7, Steps: 558 | Train Loss: 0.1492391 Vali Loss: 0.1963179 Test Loss: 0.2344549\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1853541\n",
      "\tspeed: 0.1080s/iter; left time: 772.6351s\n",
      "\titers: 200, epoch: 8 | loss: 0.0974392\n",
      "\tspeed: 0.0354s/iter; left time: 250.0323s\n",
      "\titers: 300, epoch: 8 | loss: 0.1134566\n",
      "\tspeed: 0.0359s/iter; left time: 249.5273s\n",
      "\titers: 400, epoch: 8 | loss: 0.1376993\n",
      "\tspeed: 0.0369s/iter; left time: 252.9469s\n",
      "\titers: 500, epoch: 8 | loss: 0.1567220\n",
      "\tspeed: 0.0371s/iter; left time: 250.8522s\n",
      "Epoch: 8 cost time: 20.11308789253235\n",
      "Epoch: 8, Steps: 558 | Train Loss: 0.1477299 Vali Loss: 0.1963654 Test Loss: 0.2337222\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl144_ll48_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "Test cost time: 2.4515s\n",
      "test shape: (171, 32, 6, 1) (171, 32, 6, 1)\n",
      "test shape: (5472, 6, 1) (5472, 6, 1)\n",
      "mse:0.23380175232887268, mae:0.3229368329048157\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl144_ll48_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1694.9407958984375\n",
      "MAE:  27.496091842651367\n",
      "RMSE: 41.16965866088867\n",
      "MAPE: 0.35328495502471924\n",
      "MSPE: 0.5807368159294128\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl144_ll48_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20889\n",
      "[DEBUG] Original dataset length: 20889\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 17876\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6484\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "\titers: 100, epoch: 1 | loss: 0.1836747\n",
      "\tspeed: 0.0359s/iter; left time: 397.1306s\n",
      "\titers: 200, epoch: 1 | loss: 0.1844521\n",
      "\tspeed: 0.0366s/iter; left time: 401.3672s\n",
      "\titers: 300, epoch: 1 | loss: 0.2097361\n",
      "\tspeed: 0.0352s/iter; left time: 382.7260s\n",
      "\titers: 400, epoch: 1 | loss: 0.2663683\n",
      "\tspeed: 0.0361s/iter; left time: 387.9816s\n",
      "\titers: 500, epoch: 1 | loss: 0.1811170\n",
      "\tspeed: 0.0352s/iter; left time: 375.4272s\n",
      "Epoch: 1 cost time: 19.96175193786621\n",
      "Epoch: 1, Steps: 558 | Train Loss: 0.3090500 Vali Loss: 0.1906974 Test Loss: 0.2428350\n",
      "Validation loss decreased (inf --> 0.190697).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1419194\n",
      "\tspeed: 0.1097s/iter; left time: 1151.9407s\n",
      "\titers: 200, epoch: 2 | loss: 0.1416077\n",
      "\tspeed: 0.0352s/iter; left time: 365.7418s\n",
      "\titers: 300, epoch: 2 | loss: 0.2080136\n",
      "\tspeed: 0.0347s/iter; left time: 357.5456s\n",
      "\titers: 400, epoch: 2 | loss: 0.1509020\n",
      "\tspeed: 0.0348s/iter; left time: 355.4069s\n",
      "\titers: 500, epoch: 2 | loss: 0.1679230\n",
      "\tspeed: 0.0342s/iter; left time: 345.8322s\n",
      "Epoch: 2 cost time: 19.42741584777832\n",
      "Epoch: 2, Steps: 558 | Train Loss: 0.2157261 Vali Loss: 0.1987422 Test Loss: 0.2488247\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2355621\n",
      "\tspeed: 0.1005s/iter; left time: 999.2684s\n",
      "\titers: 200, epoch: 3 | loss: 0.1715587\n",
      "\tspeed: 0.0342s/iter; left time: 336.5744s\n",
      "\titers: 300, epoch: 3 | loss: 0.1130238\n",
      "\tspeed: 0.0362s/iter; left time: 352.5840s\n",
      "\titers: 400, epoch: 3 | loss: 0.3374260\n",
      "\tspeed: 0.0348s/iter; left time: 335.6752s\n",
      "\titers: 500, epoch: 3 | loss: 0.1506892\n",
      "\tspeed: 0.0336s/iter; left time: 320.7655s\n",
      "Epoch: 3 cost time: 19.236682891845703\n",
      "Epoch: 3, Steps: 558 | Train Loss: 0.1838425 Vali Loss: 0.2079161 Test Loss: 0.2615070\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1171043\n",
      "\tspeed: 0.1057s/iter; left time: 992.5700s\n",
      "\titers: 200, epoch: 4 | loss: 0.1444732\n",
      "\tspeed: 0.0342s/iter; left time: 318.0741s\n",
      "\titers: 300, epoch: 4 | loss: 0.1352549\n",
      "\tspeed: 0.0344s/iter; left time: 315.8125s\n",
      "\titers: 400, epoch: 4 | loss: 0.1763800\n",
      "\tspeed: 0.0344s/iter; left time: 312.6824s\n",
      "\titers: 500, epoch: 4 | loss: 0.1363298\n",
      "\tspeed: 0.0333s/iter; left time: 298.8377s\n",
      "Epoch: 4 cost time: 19.041792154312134\n",
      "Epoch: 4, Steps: 558 | Train Loss: 0.1698217 Vali Loss: 0.1912183 Test Loss: 0.2374305\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl144_ll48_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "Test cost time: 2.3183s\n",
      "test shape: (171, 32, 6, 1) (171, 32, 6, 1)\n",
      "test shape: (5472, 6, 1) (5472, 6, 1)\n",
      "mse:0.24242815375328064, mae:0.32945361733436584\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl144_ll48_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1757.4775390625\n",
      "MAE:  28.050952911376953\n",
      "RMSE: 41.922279357910156\n",
      "MAPE: 0.35305169224739075\n",
      "MSPE: 0.6042519211769104\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl144_ll48_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20889\n",
      "[DEBUG] Original dataset length: 20889\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 17876\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6484\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "\titers: 100, epoch: 1 | loss: 0.5140055\n",
      "\tspeed: 0.0354s/iter; left time: 391.9371s\n",
      "\titers: 200, epoch: 1 | loss: 0.1829375\n",
      "\tspeed: 0.0343s/iter; left time: 375.4546s\n",
      "\titers: 300, epoch: 1 | loss: 0.2313690\n",
      "\tspeed: 0.0338s/iter; left time: 367.4401s\n",
      "\titers: 400, epoch: 1 | loss: 0.1635460\n",
      "\tspeed: 0.0339s/iter; left time: 364.7597s\n",
      "\titers: 500, epoch: 1 | loss: 0.1492965\n",
      "\tspeed: 0.0339s/iter; left time: 361.9219s\n",
      "Epoch: 1 cost time: 19.04125142097473\n",
      "Epoch: 1, Steps: 558 | Train Loss: 0.3153540 Vali Loss: 0.2067350 Test Loss: 0.2595091\n",
      "Validation loss decreased (inf --> 0.206735).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3015991\n",
      "\tspeed: 0.0994s/iter; left time: 1044.4923s\n",
      "\titers: 200, epoch: 2 | loss: 0.1410772\n",
      "\tspeed: 0.0323s/iter; left time: 335.9241s\n",
      "\titers: 300, epoch: 2 | loss: 0.1624822\n",
      "\tspeed: 0.0349s/iter; left time: 359.7154s\n",
      "\titers: 400, epoch: 2 | loss: 0.1788145\n",
      "\tspeed: 0.0355s/iter; left time: 361.8120s\n",
      "\titers: 500, epoch: 2 | loss: 0.2375417\n",
      "\tspeed: 0.0349s/iter; left time: 352.5017s\n",
      "Epoch: 2 cost time: 18.96218466758728\n",
      "Epoch: 2, Steps: 558 | Train Loss: 0.2126802 Vali Loss: 0.2071380 Test Loss: 0.2447222\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1597729\n",
      "\tspeed: 0.1070s/iter; left time: 1064.1027s\n",
      "\titers: 200, epoch: 3 | loss: 0.1877938\n",
      "\tspeed: 0.0346s/iter; left time: 340.1794s\n",
      "\titers: 300, epoch: 3 | loss: 0.2517828\n",
      "\tspeed: 0.0351s/iter; left time: 342.1964s\n",
      "\titers: 400, epoch: 3 | loss: 0.2036538\n",
      "\tspeed: 0.0349s/iter; left time: 336.3497s\n",
      "\titers: 500, epoch: 3 | loss: 0.3131283\n",
      "\tspeed: 0.0347s/iter; left time: 331.6769s\n",
      "Epoch: 3 cost time: 19.41289186477661\n",
      "Epoch: 3, Steps: 558 | Train Loss: 0.1836402 Vali Loss: 0.1979857 Test Loss: 0.2465771\n",
      "Validation loss decreased (0.206735 --> 0.197986).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1541563\n",
      "\tspeed: 0.1028s/iter; left time: 964.8173s\n",
      "\titers: 200, epoch: 4 | loss: 0.1497968\n",
      "\tspeed: 0.0362s/iter; left time: 336.0920s\n",
      "\titers: 300, epoch: 4 | loss: 0.1242313\n",
      "\tspeed: 0.0347s/iter; left time: 318.6490s\n",
      "\titers: 400, epoch: 4 | loss: 0.2239037\n",
      "\tspeed: 0.0339s/iter; left time: 308.0774s\n",
      "\titers: 500, epoch: 4 | loss: 0.2539992\n",
      "\tspeed: 0.0334s/iter; left time: 299.7357s\n",
      "Epoch: 4 cost time: 19.01179027557373\n",
      "Epoch: 4, Steps: 558 | Train Loss: 0.1683642 Vali Loss: 0.2043759 Test Loss: 0.2454989\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1616045\n",
      "\tspeed: 0.1037s/iter; left time: 915.4709s\n",
      "\titers: 200, epoch: 5 | loss: 0.1200387\n",
      "\tspeed: 0.0343s/iter; left time: 299.7041s\n",
      "\titers: 300, epoch: 5 | loss: 0.1471426\n",
      "\tspeed: 0.0349s/iter; left time: 300.7972s\n",
      "\titers: 400, epoch: 5 | loss: 0.1652902\n",
      "\tspeed: 0.0352s/iter; left time: 299.8810s\n",
      "\titers: 500, epoch: 5 | loss: 0.1082481\n",
      "\tspeed: 0.0350s/iter; left time: 294.6459s\n",
      "Epoch: 5 cost time: 19.356298208236694\n",
      "Epoch: 5, Steps: 558 | Train Loss: 0.1595749 Vali Loss: 0.2020124 Test Loss: 0.2444846\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1320224\n",
      "\tspeed: 0.1068s/iter; left time: 883.6851s\n",
      "\titers: 200, epoch: 6 | loss: 0.1264800\n",
      "\tspeed: 0.0348s/iter; left time: 283.9820s\n",
      "\titers: 300, epoch: 6 | loss: 0.1345262\n",
      "\tspeed: 0.0342s/iter; left time: 275.8471s\n",
      "\titers: 400, epoch: 6 | loss: 0.2685042\n",
      "\tspeed: 0.0341s/iter; left time: 271.4331s\n",
      "\titers: 500, epoch: 6 | loss: 0.0918049\n",
      "\tspeed: 0.0356s/iter; left time: 279.9829s\n",
      "Epoch: 6 cost time: 19.434059619903564\n",
      "Epoch: 6, Steps: 558 | Train Loss: 0.1542539 Vali Loss: 0.2033449 Test Loss: 0.2440399\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl144_ll48_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "Test cost time: 2.3147s\n",
      "test shape: (171, 32, 6, 1) (171, 32, 6, 1)\n",
      "test shape: (5472, 6, 1) (5472, 6, 1)\n",
      "mse:0.247604638338089, mae:0.3465975224971771\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl144_ll48_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1795.0042724609375\n",
      "MAE:  29.510656356811523\n",
      "RMSE: 42.367488861083984\n",
      "MAPE: 0.42118677496910095\n",
      "MSPE: 0.9006120562553406\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl144_ll48_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20889\n",
      "[DEBUG] Original dataset length: 20889\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 17876\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6484\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "\titers: 100, epoch: 1 | loss: 0.4085843\n",
      "\tspeed: 0.0351s/iter; left time: 387.9160s\n",
      "\titers: 200, epoch: 1 | loss: 0.2461479\n",
      "\tspeed: 0.0350s/iter; left time: 383.9001s\n",
      "\titers: 300, epoch: 1 | loss: 0.2011700\n",
      "\tspeed: 0.0342s/iter; left time: 371.7030s\n",
      "\titers: 400, epoch: 1 | loss: 0.2826211\n",
      "\tspeed: 0.0344s/iter; left time: 369.6967s\n",
      "\titers: 500, epoch: 1 | loss: 0.1560699\n",
      "\tspeed: 0.0351s/iter; left time: 373.6747s\n",
      "Epoch: 1 cost time: 19.480974674224854\n",
      "Epoch: 1, Steps: 558 | Train Loss: 0.3105546 Vali Loss: 0.2225535 Test Loss: 0.2792926\n",
      "Validation loss decreased (inf --> 0.222553).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3874744\n",
      "\tspeed: 0.1089s/iter; left time: 1143.6991s\n",
      "\titers: 200, epoch: 2 | loss: 0.2771580\n",
      "\tspeed: 0.0348s/iter; left time: 362.1521s\n",
      "\titers: 300, epoch: 2 | loss: 0.1756021\n",
      "\tspeed: 0.0361s/iter; left time: 372.3134s\n",
      "\titers: 400, epoch: 2 | loss: 0.1884556\n",
      "\tspeed: 0.0343s/iter; left time: 350.1059s\n",
      "\titers: 500, epoch: 2 | loss: 0.2181755\n",
      "\tspeed: 0.0341s/iter; left time: 344.5505s\n",
      "Epoch: 2 cost time: 19.503199815750122\n",
      "Epoch: 2, Steps: 558 | Train Loss: 0.2138482 Vali Loss: 0.2071208 Test Loss: 0.2649392\n",
      "Validation loss decreased (0.222553 --> 0.207121).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3112805\n",
      "\tspeed: 0.1088s/iter; left time: 1081.7485s\n",
      "\titers: 200, epoch: 3 | loss: 0.2821937\n",
      "\tspeed: 0.0353s/iter; left time: 347.9577s\n",
      "\titers: 300, epoch: 3 | loss: 0.2417303\n",
      "\tspeed: 0.0345s/iter; left time: 335.9107s\n",
      "\titers: 400, epoch: 3 | loss: 0.1657537\n",
      "\tspeed: 0.0346s/iter; left time: 334.1358s\n",
      "\titers: 500, epoch: 3 | loss: 0.1818418\n",
      "\tspeed: 0.0350s/iter; left time: 334.1823s\n",
      "Epoch: 3 cost time: 19.50601601600647\n",
      "Epoch: 3, Steps: 558 | Train Loss: 0.1832427 Vali Loss: 0.2216995 Test Loss: 0.2618631\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1170578\n",
      "\tspeed: 0.1045s/iter; left time: 981.0147s\n",
      "\titers: 200, epoch: 4 | loss: 0.0976989\n",
      "\tspeed: 0.0369s/iter; left time: 342.6504s\n",
      "\titers: 300, epoch: 4 | loss: 0.2181234\n",
      "\tspeed: 0.0337s/iter; left time: 309.8223s\n",
      "\titers: 400, epoch: 4 | loss: 0.2010276\n",
      "\tspeed: 0.0340s/iter; left time: 308.7558s\n",
      "\titers: 500, epoch: 4 | loss: 0.1519314\n",
      "\tspeed: 0.0342s/iter; left time: 307.3211s\n",
      "Epoch: 4 cost time: 19.290729761123657\n",
      "Epoch: 4, Steps: 558 | Train Loss: 0.1672506 Vali Loss: 0.2048638 Test Loss: 0.2541233\n",
      "Validation loss decreased (0.207121 --> 0.204864).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1643091\n",
      "\tspeed: 0.1081s/iter; left time: 954.3196s\n",
      "\titers: 200, epoch: 5 | loss: 0.1834324\n",
      "\tspeed: 0.0354s/iter; left time: 308.9535s\n",
      "\titers: 300, epoch: 5 | loss: 0.1614543\n",
      "\tspeed: 0.0353s/iter; left time: 304.3745s\n",
      "\titers: 400, epoch: 5 | loss: 0.1213475\n",
      "\tspeed: 0.0357s/iter; left time: 304.4571s\n",
      "\titers: 500, epoch: 5 | loss: 0.2306342\n",
      "\tspeed: 0.0358s/iter; left time: 302.0526s\n",
      "Epoch: 5 cost time: 19.815472841262817\n",
      "Epoch: 5, Steps: 558 | Train Loss: 0.1577765 Vali Loss: 0.2036101 Test Loss: 0.2475633\n",
      "Validation loss decreased (0.204864 --> 0.203610).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2961775\n",
      "\tspeed: 0.1103s/iter; left time: 911.9099s\n",
      "\titers: 200, epoch: 6 | loss: 0.1158670\n",
      "\tspeed: 0.0358s/iter; left time: 292.6755s\n",
      "\titers: 300, epoch: 6 | loss: 0.2436862\n",
      "\tspeed: 0.0340s/iter; left time: 274.6569s\n",
      "\titers: 400, epoch: 6 | loss: 0.1925101\n",
      "\tspeed: 0.0347s/iter; left time: 276.6397s\n",
      "\titers: 500, epoch: 6 | loss: 0.1147821\n",
      "\tspeed: 0.0360s/iter; left time: 283.3749s\n",
      "Epoch: 6 cost time: 19.727464199066162\n",
      "Epoch: 6, Steps: 558 | Train Loss: 0.1519152 Vali Loss: 0.2042481 Test Loss: 0.2499420\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1164039\n",
      "\tspeed: 0.1063s/iter; left time: 820.1926s\n",
      "\titers: 200, epoch: 7 | loss: 0.1340126\n",
      "\tspeed: 0.0359s/iter; left time: 273.6651s\n",
      "\titers: 300, epoch: 7 | loss: 0.1278984\n",
      "\tspeed: 0.0350s/iter; left time: 262.7059s\n",
      "\titers: 400, epoch: 7 | loss: 0.2799593\n",
      "\tspeed: 0.0359s/iter; left time: 266.0024s\n",
      "\titers: 500, epoch: 7 | loss: 0.1093606\n",
      "\tspeed: 0.0336s/iter; left time: 246.0281s\n",
      "Epoch: 7 cost time: 19.487809419631958\n",
      "Epoch: 7, Steps: 558 | Train Loss: 0.1485939 Vali Loss: 0.2024546 Test Loss: 0.2492545\n",
      "Validation loss decreased (0.203610 --> 0.202455).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1453891\n",
      "\tspeed: 0.1090s/iter; left time: 779.8474s\n",
      "\titers: 200, epoch: 8 | loss: 0.1523366\n",
      "\tspeed: 0.0354s/iter; left time: 250.0308s\n",
      "\titers: 300, epoch: 8 | loss: 0.1468586\n",
      "\tspeed: 0.0355s/iter; left time: 247.0347s\n",
      "\titers: 400, epoch: 8 | loss: 0.1829408\n",
      "\tspeed: 0.0368s/iter; left time: 252.4623s\n",
      "\titers: 500, epoch: 8 | loss: 0.0768538\n",
      "\tspeed: 0.0352s/iter; left time: 238.0743s\n",
      "Epoch: 8 cost time: 19.99729084968567\n",
      "Epoch: 8, Steps: 558 | Train Loss: 0.1473389 Vali Loss: 0.2029526 Test Loss: 0.2494736\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1484528\n",
      "\tspeed: 0.1080s/iter; left time: 712.7213s\n",
      "\titers: 200, epoch: 9 | loss: 0.2268640\n",
      "\tspeed: 0.0341s/iter; left time: 221.5686s\n",
      "\titers: 300, epoch: 9 | loss: 0.1187824\n",
      "\tspeed: 0.0343s/iter; left time: 219.3780s\n",
      "\titers: 400, epoch: 9 | loss: 0.1364200\n",
      "\tspeed: 0.0353s/iter; left time: 221.9859s\n",
      "\titers: 500, epoch: 9 | loss: 0.1925747\n",
      "\tspeed: 0.0355s/iter; left time: 220.2961s\n",
      "Epoch: 9 cost time: 19.40515661239624\n",
      "Epoch: 9, Steps: 558 | Train Loss: 0.1461404 Vali Loss: 0.2001837 Test Loss: 0.2480838\n",
      "Validation loss decreased (0.202455 --> 0.200184).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.1056733\n",
      "\tspeed: 0.1075s/iter; left time: 649.2196s\n",
      "\titers: 200, epoch: 10 | loss: 0.1423813\n",
      "\tspeed: 0.0361s/iter; left time: 214.4880s\n",
      "\titers: 300, epoch: 10 | loss: 0.1194359\n",
      "\tspeed: 0.0363s/iter; left time: 211.9244s\n",
      "\titers: 400, epoch: 10 | loss: 0.1630221\n",
      "\tspeed: 0.0356s/iter; left time: 204.2946s\n",
      "\titers: 500, epoch: 10 | loss: 0.1777131\n",
      "\tspeed: 0.0361s/iter; left time: 203.4532s\n",
      "Epoch: 10 cost time: 19.98458957672119\n",
      "Epoch: 10, Steps: 558 | Train Loss: 0.1463170 Vali Loss: 0.2007463 Test Loss: 0.2490694\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.1026528\n",
      "\tspeed: 0.1084s/iter; left time: 594.0199s\n",
      "\titers: 200, epoch: 11 | loss: 0.1549466\n",
      "\tspeed: 0.0365s/iter; left time: 196.6043s\n",
      "\titers: 300, epoch: 11 | loss: 0.1171824\n",
      "\tspeed: 0.0360s/iter; left time: 190.0079s\n",
      "\titers: 400, epoch: 11 | loss: 0.2843622\n",
      "\tspeed: 0.0347s/iter; left time: 179.9821s\n",
      "\titers: 500, epoch: 11 | loss: 0.2066907\n",
      "\tspeed: 0.0347s/iter; left time: 176.2274s\n",
      "Epoch: 11 cost time: 19.782116413116455\n",
      "Epoch: 11, Steps: 558 | Train Loss: 0.1462058 Vali Loss: 0.2016379 Test Loss: 0.2486081\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.1336267\n",
      "\tspeed: 0.1074s/iter; left time: 528.7938s\n",
      "\titers: 200, epoch: 12 | loss: 0.1329076\n",
      "\tspeed: 0.0337s/iter; left time: 162.6713s\n",
      "\titers: 300, epoch: 12 | loss: 0.1035755\n",
      "\tspeed: 0.0323s/iter; left time: 152.7430s\n",
      "\titers: 400, epoch: 12 | loss: 0.1879252\n",
      "\tspeed: 0.0342s/iter; left time: 158.3029s\n",
      "\titers: 500, epoch: 12 | loss: 0.1632178\n",
      "\tspeed: 0.0365s/iter; left time: 165.1761s\n",
      "Epoch: 12 cost time: 19.394907474517822\n",
      "Epoch: 12, Steps: 558 | Train Loss: 0.1453092 Vali Loss: 0.2012085 Test Loss: 0.2474377\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl144_ll48_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "Test cost time: 2.3041s\n",
      "test shape: (171, 32, 6, 1) (171, 32, 6, 1)\n",
      "test shape: (5472, 6, 1) (5472, 6, 1)\n",
      "mse:0.24766682088375092, mae:0.32563260197639465\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl144_ll48_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1795.455078125\n",
      "MAE:  27.725622177124023\n",
      "RMSE: 42.37281036376953\n",
      "MAPE: 0.3509232997894287\n",
      "MSPE: 0.5655456781387329\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl144_ll48_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20889\n",
      "[DEBUG] Original dataset length: 20889\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 17876\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6484\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "\titers: 100, epoch: 1 | loss: 0.3939497\n",
      "\tspeed: 0.0329s/iter; left time: 364.2169s\n",
      "\titers: 200, epoch: 1 | loss: 0.2511155\n",
      "\tspeed: 0.0327s/iter; left time: 358.4203s\n",
      "\titers: 300, epoch: 1 | loss: 0.2321256\n",
      "\tspeed: 0.0337s/iter; left time: 365.8816s\n",
      "\titers: 400, epoch: 1 | loss: 0.4456974\n",
      "\tspeed: 0.0347s/iter; left time: 372.9536s\n",
      "\titers: 500, epoch: 1 | loss: 0.2811570\n",
      "\tspeed: 0.0354s/iter; left time: 377.5003s\n",
      "Epoch: 1 cost time: 19.060140132904053\n",
      "Epoch: 1, Steps: 558 | Train Loss: 0.3255404 Vali Loss: 0.2180308 Test Loss: 0.2727309\n",
      "Validation loss decreased (inf --> 0.218031).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1701322\n",
      "\tspeed: 0.1102s/iter; left time: 1157.3074s\n",
      "\titers: 200, epoch: 2 | loss: 0.1711112\n",
      "\tspeed: 0.0341s/iter; left time: 354.9626s\n",
      "\titers: 300, epoch: 2 | loss: 0.1115274\n",
      "\tspeed: 0.0347s/iter; left time: 357.4956s\n",
      "\titers: 400, epoch: 2 | loss: 0.2200393\n",
      "\tspeed: 0.0348s/iter; left time: 355.3911s\n",
      "\titers: 500, epoch: 2 | loss: 0.1342650\n",
      "\tspeed: 0.0355s/iter; left time: 358.2095s\n",
      "Epoch: 2 cost time: 19.49875044822693\n",
      "Epoch: 2, Steps: 558 | Train Loss: 0.2142955 Vali Loss: 0.2288394 Test Loss: 0.2850955\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1568284\n",
      "\tspeed: 0.1066s/iter; left time: 1060.6090s\n",
      "\titers: 200, epoch: 3 | loss: 0.2546521\n",
      "\tspeed: 0.0360s/iter; left time: 354.8717s\n",
      "\titers: 300, epoch: 3 | loss: 0.2523102\n",
      "\tspeed: 0.0359s/iter; left time: 350.1588s\n",
      "\titers: 400, epoch: 3 | loss: 0.1200900\n",
      "\tspeed: 0.0359s/iter; left time: 346.2729s\n",
      "\titers: 500, epoch: 3 | loss: 0.1703664\n",
      "\tspeed: 0.0363s/iter; left time: 346.0438s\n",
      "Epoch: 3 cost time: 19.864410400390625\n",
      "Epoch: 3, Steps: 558 | Train Loss: 0.1834538 Vali Loss: 0.1944693 Test Loss: 0.2450321\n",
      "Validation loss decreased (0.218031 --> 0.194469).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1978680\n",
      "\tspeed: 0.1028s/iter; left time: 964.6974s\n",
      "\titers: 200, epoch: 4 | loss: 0.2094159\n",
      "\tspeed: 0.0337s/iter; left time: 313.1665s\n",
      "\titers: 300, epoch: 4 | loss: 0.1272824\n",
      "\tspeed: 0.0345s/iter; left time: 316.6125s\n",
      "\titers: 400, epoch: 4 | loss: 0.1616753\n",
      "\tspeed: 0.0343s/iter; left time: 311.8227s\n",
      "\titers: 500, epoch: 4 | loss: 0.1595557\n",
      "\tspeed: 0.0333s/iter; left time: 299.6655s\n",
      "Epoch: 4 cost time: 18.82054615020752\n",
      "Epoch: 4, Steps: 558 | Train Loss: 0.1694280 Vali Loss: 0.1951030 Test Loss: 0.2446952\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1599489\n",
      "\tspeed: 0.1040s/iter; left time: 918.2759s\n",
      "\titers: 200, epoch: 5 | loss: 0.1937657\n",
      "\tspeed: 0.0341s/iter; left time: 297.3755s\n",
      "\titers: 300, epoch: 5 | loss: 0.1275710\n",
      "\tspeed: 0.0352s/iter; left time: 303.4106s\n",
      "\titers: 400, epoch: 5 | loss: 0.1173103\n",
      "\tspeed: 0.0342s/iter; left time: 291.8315s\n",
      "\titers: 500, epoch: 5 | loss: 0.1512565\n",
      "\tspeed: 0.0334s/iter; left time: 281.9035s\n",
      "Epoch: 5 cost time: 19.03892230987549\n",
      "Epoch: 5, Steps: 558 | Train Loss: 0.1620410 Vali Loss: 0.1972583 Test Loss: 0.2470311\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1579774\n",
      "\tspeed: 0.1066s/iter; left time: 881.9019s\n",
      "\titers: 200, epoch: 6 | loss: 0.1817440\n",
      "\tspeed: 0.0346s/iter; left time: 282.9762s\n",
      "\titers: 300, epoch: 6 | loss: 0.1199608\n",
      "\tspeed: 0.0336s/iter; left time: 270.9477s\n",
      "\titers: 400, epoch: 6 | loss: 0.1569022\n",
      "\tspeed: 0.0332s/iter; left time: 264.3559s\n",
      "\titers: 500, epoch: 6 | loss: 0.0935435\n",
      "\tspeed: 0.0356s/iter; left time: 280.2276s\n",
      "Epoch: 6 cost time: 19.201820611953735\n",
      "Epoch: 6, Steps: 558 | Train Loss: 0.1558391 Vali Loss: 0.1949660 Test Loss: 0.2454298\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl144_ll48_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5498\n",
      "Test cost time: 2.2214s\n",
      "test shape: (171, 32, 6, 1) (171, 32, 6, 1)\n",
      "test shape: (5472, 6, 1) (5472, 6, 1)\n",
      "mse:0.24505802989006042, mae:0.32603779435157776\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl144_ll48_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1776.5426025390625\n",
      "MAE:  27.760120391845703\n",
      "RMSE: 42.149051666259766\n",
      "MAPE: 0.3300710916519165\n",
      "MSPE: 0.5331922769546509\n",
      ">>>>>>>Running time saved<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Running seq_len=168, label_len=56, pred_len=6\n",
      "Args in experiment:\n",
      "Namespace(model='informer', data='traffic_full', root_path='../', data_path='traffic_full.csv', features='S', target='flow', freq='h', checkpoints='./checkpoints/', seq_len=168, label_len=56, pred_len=6, enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=2, d_layers=1, s_layers=[3, 2, 1], d_ff=2048, factor=5, padding=0, distil=True, dropout=0.05, attn='prob', embed='timeF', activation='gelu', output_attention=False, do_predict=False, mix=True, cols=None, num_workers=0, itr=10, train_epochs=20, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, inverse=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', detail_freq='h')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl168_ll56_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20865\n",
      "[DEBUG] Original dataset length: 20865\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 17516\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6412\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5330\n",
      "\titers: 100, epoch: 1 | loss: 0.3466852\n",
      "\tspeed: 0.0510s/iter; left time: 552.7885s\n",
      "\titers: 200, epoch: 1 | loss: 0.2854809\n",
      "\tspeed: 0.0376s/iter; left time: 403.7161s\n",
      "\titers: 300, epoch: 1 | loss: 0.2252243\n",
      "\tspeed: 0.0374s/iter; left time: 397.5659s\n",
      "\titers: 400, epoch: 1 | loss: 0.2030232\n",
      "\tspeed: 0.0382s/iter; left time: 403.0716s\n",
      "\titers: 500, epoch: 1 | loss: 0.2491814\n",
      "\tspeed: 0.0393s/iter; left time: 410.8256s\n",
      "Epoch: 1 cost time: 21.380935668945312\n",
      "Epoch: 1, Steps: 547 | Train Loss: 0.3324995 Vali Loss: 0.2298412 Test Loss: 0.2792766\n",
      "Validation loss decreased (inf --> 0.229841).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2730229\n",
      "\tspeed: 0.1179s/iter; left time: 1213.2779s\n",
      "\titers: 200, epoch: 2 | loss: 0.1824290\n",
      "\tspeed: 0.0395s/iter; left time: 402.3887s\n",
      "\titers: 300, epoch: 2 | loss: 0.2165106\n",
      "\tspeed: 0.0385s/iter; left time: 388.8067s\n",
      "\titers: 400, epoch: 2 | loss: 0.2248455\n",
      "\tspeed: 0.0383s/iter; left time: 382.3279s\n",
      "\titers: 500, epoch: 2 | loss: 0.1904585\n",
      "\tspeed: 0.0400s/iter; left time: 395.5120s\n",
      "Epoch: 2 cost time: 21.480682373046875\n",
      "Epoch: 2, Steps: 547 | Train Loss: 0.2145934 Vali Loss: 0.2206587 Test Loss: 0.2562159\n",
      "Validation loss decreased (0.229841 --> 0.220659).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2091545\n",
      "\tspeed: 0.1163s/iter; left time: 1133.9691s\n",
      "\titers: 200, epoch: 3 | loss: 0.1769042\n",
      "\tspeed: 0.0386s/iter; left time: 372.3663s\n",
      "\titers: 300, epoch: 3 | loss: 0.1604993\n",
      "\tspeed: 0.0382s/iter; left time: 364.2691s\n",
      "\titers: 400, epoch: 3 | loss: 0.1217091\n",
      "\tspeed: 0.0363s/iter; left time: 343.2459s\n",
      "\titers: 500, epoch: 3 | loss: 0.1693999\n",
      "\tspeed: 0.0364s/iter; left time: 339.7707s\n",
      "Epoch: 3 cost time: 20.61968994140625\n",
      "Epoch: 3, Steps: 547 | Train Loss: 0.1807197 Vali Loss: 0.2070409 Test Loss: 0.2322440\n",
      "Validation loss decreased (0.220659 --> 0.207041).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1333550\n",
      "\tspeed: 0.1160s/iter; left time: 1067.1281s\n",
      "\titers: 200, epoch: 4 | loss: 0.1162462\n",
      "\tspeed: 0.0396s/iter; left time: 359.9558s\n",
      "\titers: 300, epoch: 4 | loss: 0.2184162\n",
      "\tspeed: 0.0393s/iter; left time: 353.7890s\n",
      "\titers: 400, epoch: 4 | loss: 0.1530656\n",
      "\tspeed: 0.0395s/iter; left time: 351.9028s\n",
      "\titers: 500, epoch: 4 | loss: 0.1594368\n",
      "\tspeed: 0.0388s/iter; left time: 341.1445s\n",
      "Epoch: 4 cost time: 21.38240957260132\n",
      "Epoch: 4, Steps: 547 | Train Loss: 0.1645586 Vali Loss: 0.2033916 Test Loss: 0.2292859\n",
      "Validation loss decreased (0.207041 --> 0.203392).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0930922\n",
      "\tspeed: 0.1188s/iter; left time: 1027.7666s\n",
      "\titers: 200, epoch: 5 | loss: 0.1773354\n",
      "\tspeed: 0.0376s/iter; left time: 321.8301s\n",
      "\titers: 300, epoch: 5 | loss: 0.1370825\n",
      "\tspeed: 0.0393s/iter; left time: 332.4263s\n",
      "\titers: 400, epoch: 5 | loss: 0.1502429\n",
      "\tspeed: 0.0388s/iter; left time: 324.4604s\n",
      "\titers: 500, epoch: 5 | loss: 0.1059795\n",
      "\tspeed: 0.0377s/iter; left time: 311.1582s\n",
      "Epoch: 5 cost time: 21.063102960586548\n",
      "Epoch: 5, Steps: 547 | Train Loss: 0.1565426 Vali Loss: 0.2016185 Test Loss: 0.2260179\n",
      "Validation loss decreased (0.203392 --> 0.201619).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1546253\n",
      "\tspeed: 0.1173s/iter; left time: 950.6128s\n",
      "\titers: 200, epoch: 6 | loss: 0.1226757\n",
      "\tspeed: 0.0367s/iter; left time: 293.5942s\n",
      "\titers: 300, epoch: 6 | loss: 0.1569390\n",
      "\tspeed: 0.0353s/iter; left time: 278.7923s\n",
      "\titers: 400, epoch: 6 | loss: 0.0973129\n",
      "\tspeed: 0.0361s/iter; left time: 281.9714s\n",
      "\titers: 500, epoch: 6 | loss: 0.1762727\n",
      "\tspeed: 0.0377s/iter; left time: 290.5696s\n",
      "Epoch: 6 cost time: 20.28473949432373\n",
      "Epoch: 6, Steps: 547 | Train Loss: 0.1512317 Vali Loss: 0.2060636 Test Loss: 0.2313494\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1975765\n",
      "\tspeed: 0.1156s/iter; left time: 874.1303s\n",
      "\titers: 200, epoch: 7 | loss: 0.1117995\n",
      "\tspeed: 0.0378s/iter; left time: 281.7913s\n",
      "\titers: 300, epoch: 7 | loss: 0.1548876\n",
      "\tspeed: 0.0383s/iter; left time: 282.1267s\n",
      "\titers: 400, epoch: 7 | loss: 0.1113946\n",
      "\tspeed: 0.0384s/iter; left time: 278.4680s\n",
      "\titers: 500, epoch: 7 | loss: 0.1764870\n",
      "\tspeed: 0.0382s/iter; left time: 273.7354s\n",
      "Epoch: 7 cost time: 21.01313018798828\n",
      "Epoch: 7, Steps: 547 | Train Loss: 0.1484370 Vali Loss: 0.2083340 Test Loss: 0.2328137\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2596732\n",
      "\tspeed: 0.1153s/iter; left time: 808.6383s\n",
      "\titers: 200, epoch: 8 | loss: 0.1310061\n",
      "\tspeed: 0.0402s/iter; left time: 277.5364s\n",
      "\titers: 300, epoch: 8 | loss: 0.1200828\n",
      "\tspeed: 0.0384s/iter; left time: 261.7899s\n",
      "\titers: 400, epoch: 8 | loss: 0.1216417\n",
      "\tspeed: 0.0378s/iter; left time: 253.8827s\n",
      "\titers: 500, epoch: 8 | loss: 0.1754662\n",
      "\tspeed: 0.0385s/iter; left time: 254.3491s\n",
      "Epoch: 8 cost time: 21.21056079864502\n",
      "Epoch: 8, Steps: 547 | Train Loss: 0.1467503 Vali Loss: 0.2045756 Test Loss: 0.2290309\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl168_ll56_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5330\n",
      "Test cost time: 2.6036s\n",
      "test shape: (166, 32, 6, 1) (166, 32, 6, 1)\n",
      "test shape: (5312, 6, 1) (5312, 6, 1)\n",
      "mse:0.22633345425128937, mae:0.31308773159980774\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl168_ll56_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1640.79931640625\n",
      "MAE:  26.657499313354492\n",
      "RMSE: 40.50678253173828\n",
      "MAPE: 0.3367846608161926\n",
      "MSPE: 0.5160562992095947\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl168_ll56_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20865\n",
      "[DEBUG] Original dataset length: 20865\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 17516\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6412\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5330\n",
      "\titers: 100, epoch: 1 | loss: 0.2760552\n",
      "\tspeed: 0.0380s/iter; left time: 411.6096s\n",
      "\titers: 200, epoch: 1 | loss: 0.2020375\n",
      "\tspeed: 0.0399s/iter; left time: 428.1323s\n",
      "\titers: 300, epoch: 1 | loss: 0.2288001\n",
      "\tspeed: 0.0391s/iter; left time: 415.8014s\n",
      "\titers: 400, epoch: 1 | loss: 0.2259812\n",
      "\tspeed: 0.0389s/iter; left time: 410.0492s\n",
      "\titers: 500, epoch: 1 | loss: 0.1445897\n",
      "\tspeed: 0.0387s/iter; left time: 404.0500s\n",
      "Epoch: 1 cost time: 21.343389987945557\n",
      "Epoch: 1, Steps: 547 | Train Loss: 0.3203858 Vali Loss: 0.2047178 Test Loss: 0.2452475\n",
      "Validation loss decreased (inf --> 0.204718).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2232646\n",
      "\tspeed: 0.1155s/iter; left time: 1188.7969s\n",
      "\titers: 200, epoch: 2 | loss: 0.2356516\n",
      "\tspeed: 0.0385s/iter; left time: 392.6217s\n",
      "\titers: 300, epoch: 2 | loss: 0.1277582\n",
      "\tspeed: 0.0397s/iter; left time: 400.6830s\n",
      "\titers: 400, epoch: 2 | loss: 0.2622058\n",
      "\tspeed: 0.0372s/iter; left time: 372.2449s\n",
      "\titers: 500, epoch: 2 | loss: 0.1169751\n",
      "\tspeed: 0.0381s/iter; left time: 376.6257s\n",
      "Epoch: 2 cost time: 20.96526837348938\n",
      "Epoch: 2, Steps: 547 | Train Loss: 0.2110234 Vali Loss: 0.2062645 Test Loss: 0.2503246\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1449760\n",
      "\tspeed: 0.1169s/iter; left time: 1139.0266s\n",
      "\titers: 200, epoch: 3 | loss: 0.2280744\n",
      "\tspeed: 0.0381s/iter; left time: 367.1610s\n",
      "\titers: 300, epoch: 3 | loss: 0.1379224\n",
      "\tspeed: 0.0391s/iter; left time: 373.1521s\n",
      "\titers: 400, epoch: 3 | loss: 0.2587397\n",
      "\tspeed: 0.0385s/iter; left time: 363.8669s\n",
      "\titers: 500, epoch: 3 | loss: 0.1848772\n",
      "\tspeed: 0.0388s/iter; left time: 362.3517s\n",
      "Epoch: 3 cost time: 21.03204917907715\n",
      "Epoch: 3, Steps: 547 | Train Loss: 0.1768361 Vali Loss: 0.2225400 Test Loss: 0.2591579\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1715956\n",
      "\tspeed: 0.1162s/iter; left time: 1069.0302s\n",
      "\titers: 200, epoch: 4 | loss: 0.1801553\n",
      "\tspeed: 0.0390s/iter; left time: 355.2346s\n",
      "\titers: 300, epoch: 4 | loss: 0.1029828\n",
      "\tspeed: 0.0393s/iter; left time: 353.3922s\n",
      "\titers: 400, epoch: 4 | loss: 0.1538799\n",
      "\tspeed: 0.0396s/iter; left time: 352.2389s\n",
      "\titers: 500, epoch: 4 | loss: 0.1839477\n",
      "\tspeed: 0.0384s/iter; left time: 338.0233s\n",
      "Epoch: 4 cost time: 21.392226219177246\n",
      "Epoch: 4, Steps: 547 | Train Loss: 0.1613006 Vali Loss: 0.1972569 Test Loss: 0.2302748\n",
      "Validation loss decreased (0.204718 --> 0.197257).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1630775\n",
      "\tspeed: 0.1174s/iter; left time: 1015.4473s\n",
      "\titers: 200, epoch: 5 | loss: 0.1386507\n",
      "\tspeed: 0.0389s/iter; left time: 332.8439s\n",
      "\titers: 300, epoch: 5 | loss: 0.1009168\n",
      "\tspeed: 0.0385s/iter; left time: 325.4477s\n",
      "\titers: 400, epoch: 5 | loss: 0.1941141\n",
      "\tspeed: 0.0381s/iter; left time: 318.4637s\n",
      "\titers: 500, epoch: 5 | loss: 0.1339571\n",
      "\tspeed: 0.0397s/iter; left time: 327.5892s\n",
      "Epoch: 5 cost time: 21.257113218307495\n",
      "Epoch: 5, Steps: 547 | Train Loss: 0.1523107 Vali Loss: 0.1988500 Test Loss: 0.2323295\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1143739\n",
      "\tspeed: 0.1160s/iter; left time: 940.0598s\n",
      "\titers: 200, epoch: 6 | loss: 0.1460922\n",
      "\tspeed: 0.0407s/iter; left time: 325.6101s\n",
      "\titers: 300, epoch: 6 | loss: 0.1019418\n",
      "\tspeed: 0.0391s/iter; left time: 309.3976s\n",
      "\titers: 400, epoch: 6 | loss: 0.1635572\n",
      "\tspeed: 0.0391s/iter; left time: 304.8397s\n",
      "\titers: 500, epoch: 6 | loss: 0.1197673\n",
      "\tspeed: 0.0398s/iter; left time: 306.5954s\n",
      "Epoch: 6 cost time: 21.563596487045288\n",
      "Epoch: 6, Steps: 547 | Train Loss: 0.1468707 Vali Loss: 0.1998640 Test Loss: 0.2319942\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1393155\n",
      "\tspeed: 0.1154s/iter; left time: 872.2800s\n",
      "\titers: 200, epoch: 7 | loss: 0.0943099\n",
      "\tspeed: 0.0391s/iter; left time: 291.6666s\n",
      "\titers: 300, epoch: 7 | loss: 0.2323156\n",
      "\tspeed: 0.0391s/iter; left time: 287.9702s\n",
      "\titers: 400, epoch: 7 | loss: 0.0963812\n",
      "\tspeed: 0.0380s/iter; left time: 275.8457s\n",
      "\titers: 500, epoch: 7 | loss: 0.1794388\n",
      "\tspeed: 0.0387s/iter; left time: 277.1325s\n",
      "Epoch: 7 cost time: 21.234016180038452\n",
      "Epoch: 7, Steps: 547 | Train Loss: 0.1440881 Vali Loss: 0.2000128 Test Loss: 0.2329914\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl168_ll56_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5330\n",
      "Test cost time: 2.6276s\n",
      "test shape: (166, 32, 6, 1) (166, 32, 6, 1)\n",
      "test shape: (5312, 6, 1) (5312, 6, 1)\n",
      "mse:0.23150333762168884, mae:0.32006487250328064\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl168_ll56_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1678.2783203125\n",
      "MAE:  27.25156021118164\n",
      "RMSE: 40.966796875\n",
      "MAPE: 0.3889775574207306\n",
      "MSPE: 0.7201054692268372\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl168_ll56_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20865\n",
      "[DEBUG] Original dataset length: 20865\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 17516\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6412\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5330\n",
      "\titers: 100, epoch: 1 | loss: 0.4352110\n",
      "\tspeed: 0.0391s/iter; left time: 424.1090s\n",
      "\titers: 200, epoch: 1 | loss: 0.5151497\n",
      "\tspeed: 0.0405s/iter; left time: 435.3885s\n",
      "\titers: 300, epoch: 1 | loss: 0.3356234\n",
      "\tspeed: 0.0392s/iter; left time: 417.0759s\n",
      "\titers: 400, epoch: 1 | loss: 0.1731171\n",
      "\tspeed: 0.0390s/iter; left time: 411.3247s\n",
      "\titers: 500, epoch: 1 | loss: 0.2127907\n",
      "\tspeed: 0.0388s/iter; left time: 404.9562s\n",
      "Epoch: 1 cost time: 21.55224609375\n",
      "Epoch: 1, Steps: 547 | Train Loss: 0.3222176 Vali Loss: 0.2304292 Test Loss: 0.2690392\n",
      "Validation loss decreased (inf --> 0.230429).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2103094\n",
      "\tspeed: 0.1191s/iter; left time: 1226.1817s\n",
      "\titers: 200, epoch: 2 | loss: 0.5946081\n",
      "\tspeed: 0.0398s/iter; left time: 405.2328s\n",
      "\titers: 300, epoch: 2 | loss: 0.1732362\n",
      "\tspeed: 0.0398s/iter; left time: 402.0605s\n",
      "\titers: 400, epoch: 2 | loss: 0.1691066\n",
      "\tspeed: 0.0385s/iter; left time: 384.5695s\n",
      "\titers: 500, epoch: 2 | loss: 0.2524855\n",
      "\tspeed: 0.0396s/iter; left time: 391.5370s\n",
      "Epoch: 2 cost time: 21.558684825897217\n",
      "Epoch: 2, Steps: 547 | Train Loss: 0.2101441 Vali Loss: 0.2265210 Test Loss: 0.2780034\n",
      "Validation loss decreased (0.230429 --> 0.226521).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2137251\n",
      "\tspeed: 0.1176s/iter; left time: 1146.3196s\n",
      "\titers: 200, epoch: 3 | loss: 0.1490024\n",
      "\tspeed: 0.0401s/iter; left time: 386.6774s\n",
      "\titers: 300, epoch: 3 | loss: 0.1449457\n",
      "\tspeed: 0.0390s/iter; left time: 372.3359s\n",
      "\titers: 400, epoch: 3 | loss: 0.2916628\n",
      "\tspeed: 0.0382s/iter; left time: 360.4728s\n",
      "\titers: 500, epoch: 3 | loss: 0.1349313\n",
      "\tspeed: 0.0390s/iter; left time: 364.1033s\n",
      "Epoch: 3 cost time: 21.29030728340149\n",
      "Epoch: 3, Steps: 547 | Train Loss: 0.1802520 Vali Loss: 0.2000339 Test Loss: 0.2495308\n",
      "Validation loss decreased (0.226521 --> 0.200034).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1396539\n",
      "\tspeed: 0.1186s/iter; left time: 1091.0000s\n",
      "\titers: 200, epoch: 4 | loss: 0.1810200\n",
      "\tspeed: 0.0391s/iter; left time: 355.3636s\n",
      "\titers: 300, epoch: 4 | loss: 0.0882883\n",
      "\tspeed: 0.0393s/iter; left time: 353.8799s\n",
      "\titers: 400, epoch: 4 | loss: 0.1163607\n",
      "\tspeed: 0.0398s/iter; left time: 353.8225s\n",
      "\titers: 500, epoch: 4 | loss: 0.1601555\n",
      "\tspeed: 0.0393s/iter; left time: 346.0508s\n",
      "Epoch: 4 cost time: 21.517024040222168\n",
      "Epoch: 4, Steps: 547 | Train Loss: 0.1643573 Vali Loss: 0.2025339 Test Loss: 0.2395657\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1792970\n",
      "\tspeed: 0.1175s/iter; left time: 1016.8628s\n",
      "\titers: 200, epoch: 5 | loss: 0.0999615\n",
      "\tspeed: 0.0392s/iter; left time: 335.3991s\n",
      "\titers: 300, epoch: 5 | loss: 0.1409146\n",
      "\tspeed: 0.0398s/iter; left time: 336.0360s\n",
      "\titers: 400, epoch: 5 | loss: 0.1122403\n",
      "\tspeed: 0.0396s/iter; left time: 330.6219s\n",
      "\titers: 500, epoch: 5 | loss: 0.1877871\n",
      "\tspeed: 0.0405s/iter; left time: 334.1406s\n",
      "Epoch: 5 cost time: 21.743232011795044\n",
      "Epoch: 5, Steps: 547 | Train Loss: 0.1562305 Vali Loss: 0.2025831 Test Loss: 0.2393313\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1627983\n",
      "\tspeed: 0.1159s/iter; left time: 939.2722s\n",
      "\titers: 200, epoch: 6 | loss: 0.2847669\n",
      "\tspeed: 0.0400s/iter; left time: 320.3740s\n",
      "\titers: 300, epoch: 6 | loss: 0.1690738\n",
      "\tspeed: 0.0382s/iter; left time: 301.8167s\n",
      "\titers: 400, epoch: 6 | loss: 0.1719814\n",
      "\tspeed: 0.0380s/iter; left time: 296.8010s\n",
      "\titers: 500, epoch: 6 | loss: 0.1417989\n",
      "\tspeed: 0.0396s/iter; left time: 304.8829s\n",
      "Epoch: 6 cost time: 21.27193832397461\n",
      "Epoch: 6, Steps: 547 | Train Loss: 0.1504919 Vali Loss: 0.2035569 Test Loss: 0.2356344\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl168_ll56_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5330\n",
      "Test cost time: 2.6595s\n",
      "test shape: (166, 32, 6, 1) (166, 32, 6, 1)\n",
      "test shape: (5312, 6, 1) (5312, 6, 1)\n",
      "mse:0.24909266829490662, mae:0.31727373600006104\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl168_ll56_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1805.7916259765625\n",
      "MAE:  27.0139102935791\n",
      "RMSE: 42.494606018066406\n",
      "MAPE: 0.32068654894828796\n",
      "MSPE: 0.459885835647583\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl168_ll56_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20865\n",
      "[DEBUG] Original dataset length: 20865\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 17516\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6412\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5330\n",
      "\titers: 100, epoch: 1 | loss: 0.3191814\n",
      "\tspeed: 0.0397s/iter; left time: 430.6374s\n",
      "\titers: 200, epoch: 1 | loss: 0.4209603\n",
      "\tspeed: 0.0386s/iter; left time: 414.2965s\n",
      "\titers: 300, epoch: 1 | loss: 0.2810846\n",
      "\tspeed: 0.0377s/iter; left time: 400.6757s\n",
      "\titers: 400, epoch: 1 | loss: 0.1880943\n",
      "\tspeed: 0.0382s/iter; left time: 402.3607s\n",
      "\titers: 500, epoch: 1 | loss: 0.2544641\n",
      "\tspeed: 0.0393s/iter; left time: 410.0635s\n",
      "Epoch: 1 cost time: 21.283626317977905\n",
      "Epoch: 1, Steps: 547 | Train Loss: 0.3244292 Vali Loss: 0.2169447 Test Loss: 0.2810664\n",
      "Validation loss decreased (inf --> 0.216945).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1764841\n",
      "\tspeed: 0.1167s/iter; left time: 1201.5012s\n",
      "\titers: 200, epoch: 2 | loss: 0.1856642\n",
      "\tspeed: 0.0392s/iter; left time: 399.7255s\n",
      "\titers: 300, epoch: 2 | loss: 0.1991088\n",
      "\tspeed: 0.0386s/iter; left time: 389.4591s\n",
      "\titers: 400, epoch: 2 | loss: 0.1267359\n",
      "\tspeed: 0.0387s/iter; left time: 387.0158s\n",
      "\titers: 500, epoch: 2 | loss: 0.1976427\n",
      "\tspeed: 0.0384s/iter; left time: 380.0543s\n",
      "Epoch: 2 cost time: 21.107871055603027\n",
      "Epoch: 2, Steps: 547 | Train Loss: 0.2087429 Vali Loss: 0.2005089 Test Loss: 0.2457902\n",
      "Validation loss decreased (0.216945 --> 0.200509).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2133272\n",
      "\tspeed: 0.1169s/iter; left time: 1139.1283s\n",
      "\titers: 200, epoch: 3 | loss: 0.2006036\n",
      "\tspeed: 0.0389s/iter; left time: 375.0402s\n",
      "\titers: 300, epoch: 3 | loss: 0.2460469\n",
      "\tspeed: 0.0397s/iter; left time: 379.3751s\n",
      "\titers: 400, epoch: 3 | loss: 0.1408025\n",
      "\tspeed: 0.0382s/iter; left time: 360.4584s\n",
      "\titers: 500, epoch: 3 | loss: 0.1241529\n",
      "\tspeed: 0.0382s/iter; left time: 357.0843s\n",
      "Epoch: 3 cost time: 21.21331214904785\n",
      "Epoch: 3, Steps: 547 | Train Loss: 0.1797628 Vali Loss: 0.1940247 Test Loss: 0.2431902\n",
      "Validation loss decreased (0.200509 --> 0.194025).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2066887\n",
      "\tspeed: 0.1164s/iter; left time: 1070.5965s\n",
      "\titers: 200, epoch: 4 | loss: 0.1694024\n",
      "\tspeed: 0.0387s/iter; left time: 352.1806s\n",
      "\titers: 300, epoch: 4 | loss: 0.1221492\n",
      "\tspeed: 0.0386s/iter; left time: 347.7984s\n",
      "\titers: 400, epoch: 4 | loss: 0.0832212\n",
      "\tspeed: 0.0395s/iter; left time: 351.8337s\n",
      "\titers: 500, epoch: 4 | loss: 0.0969245\n",
      "\tspeed: 0.0379s/iter; left time: 333.5883s\n",
      "Epoch: 4 cost time: 21.068755865097046\n",
      "Epoch: 4, Steps: 547 | Train Loss: 0.1638903 Vali Loss: 0.1981830 Test Loss: 0.2429283\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1564691\n",
      "\tspeed: 0.1152s/iter; left time: 996.5823s\n",
      "\titers: 200, epoch: 5 | loss: 0.1441201\n",
      "\tspeed: 0.0382s/iter; left time: 326.3923s\n",
      "\titers: 300, epoch: 5 | loss: 0.1282314\n",
      "\tspeed: 0.0377s/iter; left time: 318.3695s\n",
      "\titers: 400, epoch: 5 | loss: 0.1379009\n",
      "\tspeed: 0.0387s/iter; left time: 323.1843s\n",
      "\titers: 500, epoch: 5 | loss: 0.1929295\n",
      "\tspeed: 0.0401s/iter; left time: 330.6748s\n",
      "Epoch: 5 cost time: 21.128976345062256\n",
      "Epoch: 5, Steps: 547 | Train Loss: 0.1544456 Vali Loss: 0.2002964 Test Loss: 0.2463837\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1270632\n",
      "\tspeed: 0.1157s/iter; left time: 938.2065s\n",
      "\titers: 200, epoch: 6 | loss: 0.1204939\n",
      "\tspeed: 0.0390s/iter; left time: 312.2374s\n",
      "\titers: 300, epoch: 6 | loss: 0.2121665\n",
      "\tspeed: 0.0381s/iter; left time: 301.1439s\n",
      "\titers: 400, epoch: 6 | loss: 0.1078365\n",
      "\tspeed: 0.0391s/iter; left time: 305.4468s\n",
      "\titers: 500, epoch: 6 | loss: 0.0762432\n",
      "\tspeed: 0.0392s/iter; left time: 301.9623s\n",
      "Epoch: 6 cost time: 21.4350368976593\n",
      "Epoch: 6, Steps: 547 | Train Loss: 0.1491597 Vali Loss: 0.2016722 Test Loss: 0.2442037\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl168_ll56_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5330\n",
      "Test cost time: 2.4555s\n",
      "test shape: (166, 32, 6, 1) (166, 32, 6, 1)\n",
      "test shape: (5312, 6, 1) (5312, 6, 1)\n",
      "mse:0.24314281344413757, mae:0.3246505558490753\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl168_ll56_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1762.6585693359375\n",
      "MAE:  27.64200210571289\n",
      "RMSE: 41.98402786254883\n",
      "MAPE: 0.31355607509613037\n",
      "MSPE: 0.3708347678184509\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl168_ll56_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20865\n",
      "[DEBUG] Original dataset length: 20865\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 17516\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6412\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5330\n",
      "\titers: 100, epoch: 1 | loss: 0.3477820\n",
      "\tspeed: 0.0390s/iter; left time: 422.5107s\n",
      "\titers: 200, epoch: 1 | loss: 0.3327802\n",
      "\tspeed: 0.0409s/iter; left time: 438.8987s\n",
      "\titers: 300, epoch: 1 | loss: 0.2269134\n",
      "\tspeed: 0.0392s/iter; left time: 417.6576s\n",
      "\titers: 400, epoch: 1 | loss: 0.2835689\n",
      "\tspeed: 0.0393s/iter; left time: 414.2017s\n",
      "\titers: 500, epoch: 1 | loss: 0.2503616\n",
      "\tspeed: 0.0400s/iter; left time: 417.4757s\n",
      "Epoch: 1 cost time: 21.711968421936035\n",
      "Epoch: 1, Steps: 547 | Train Loss: 0.3261865 Vali Loss: 0.2278727 Test Loss: 0.2842729\n",
      "Validation loss decreased (inf --> 0.227873).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1720919\n",
      "\tspeed: 0.1167s/iter; left time: 1200.8915s\n",
      "\titers: 200, epoch: 2 | loss: 0.1452676\n",
      "\tspeed: 0.0364s/iter; left time: 371.4134s\n",
      "\titers: 300, epoch: 2 | loss: 0.3001536\n",
      "\tspeed: 0.0350s/iter; left time: 353.2248s\n",
      "\titers: 400, epoch: 2 | loss: 0.2451433\n",
      "\tspeed: 0.0380s/iter; left time: 379.6139s\n",
      "\titers: 500, epoch: 2 | loss: 0.2333785\n",
      "\tspeed: 0.0383s/iter; left time: 379.3686s\n",
      "Epoch: 2 cost time: 20.494118690490723\n",
      "Epoch: 2, Steps: 547 | Train Loss: 0.2083915 Vali Loss: 0.1970388 Test Loss: 0.2444395\n",
      "Validation loss decreased (0.227873 --> 0.197039).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2476704\n",
      "\tspeed: 0.1166s/iter; left time: 1136.5294s\n",
      "\titers: 200, epoch: 3 | loss: 0.1105705\n",
      "\tspeed: 0.0385s/iter; left time: 371.0641s\n",
      "\titers: 300, epoch: 3 | loss: 0.1755859\n",
      "\tspeed: 0.0400s/iter; left time: 382.0622s\n",
      "\titers: 400, epoch: 3 | loss: 0.1524476\n",
      "\tspeed: 0.0387s/iter; left time: 365.5772s\n",
      "\titers: 500, epoch: 3 | loss: 0.1003191\n",
      "\tspeed: 0.0393s/iter; left time: 366.9081s\n",
      "Epoch: 3 cost time: 21.253920078277588\n",
      "Epoch: 3, Steps: 547 | Train Loss: 0.1778526 Vali Loss: 0.2015204 Test Loss: 0.2425843\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2213517\n",
      "\tspeed: 0.1155s/iter; left time: 1062.2225s\n",
      "\titers: 200, epoch: 4 | loss: 0.1647948\n",
      "\tspeed: 0.0382s/iter; left time: 347.7397s\n",
      "\titers: 300, epoch: 4 | loss: 0.1643274\n",
      "\tspeed: 0.0388s/iter; left time: 349.3395s\n",
      "\titers: 400, epoch: 4 | loss: 0.1288963\n",
      "\tspeed: 0.0366s/iter; left time: 325.5085s\n",
      "\titers: 500, epoch: 4 | loss: 0.1456992\n",
      "\tspeed: 0.0369s/iter; left time: 324.3060s\n",
      "Epoch: 4 cost time: 20.638489484786987\n",
      "Epoch: 4, Steps: 547 | Train Loss: 0.1634317 Vali Loss: 0.1980968 Test Loss: 0.2366288\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1340699\n",
      "\tspeed: 0.1167s/iter; left time: 1009.4890s\n",
      "\titers: 200, epoch: 5 | loss: 0.1341815\n",
      "\tspeed: 0.0379s/iter; left time: 324.4109s\n",
      "\titers: 300, epoch: 5 | loss: 0.1623354\n",
      "\tspeed: 0.0383s/iter; left time: 323.3412s\n",
      "\titers: 400, epoch: 5 | loss: 0.1222664\n",
      "\tspeed: 0.0393s/iter; left time: 328.4889s\n",
      "\titers: 500, epoch: 5 | loss: 0.1057627\n",
      "\tspeed: 0.0398s/iter; left time: 328.2946s\n",
      "Epoch: 5 cost time: 21.27465057373047\n",
      "Epoch: 5, Steps: 547 | Train Loss: 0.1542515 Vali Loss: 0.2025672 Test Loss: 0.2385259\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl168_ll56_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5330\n",
      "Test cost time: 2.4844s\n",
      "test shape: (166, 32, 6, 1) (166, 32, 6, 1)\n",
      "test shape: (5312, 6, 1) (5312, 6, 1)\n",
      "mse:0.24338869750499725, mae:0.32936957478523254\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl168_ll56_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1764.4410400390625\n",
      "MAE:  28.043800354003906\n",
      "RMSE: 42.0052490234375\n",
      "MAPE: 0.39060336351394653\n",
      "MSPE: 0.7183655500411987\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl168_ll56_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20865\n",
      "[DEBUG] Original dataset length: 20865\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 17516\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6412\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5330\n",
      "\titers: 100, epoch: 1 | loss: 0.2886278\n",
      "\tspeed: 0.0364s/iter; left time: 394.4997s\n",
      "\titers: 200, epoch: 1 | loss: 0.2270786\n",
      "\tspeed: 0.0380s/iter; left time: 408.1181s\n",
      "\titers: 300, epoch: 1 | loss: 0.1764726\n",
      "\tspeed: 0.0388s/iter; left time: 413.3789s\n",
      "\titers: 400, epoch: 1 | loss: 0.4195577\n",
      "\tspeed: 0.0401s/iter; left time: 423.0235s\n",
      "\titers: 500, epoch: 1 | loss: 0.1438692\n",
      "\tspeed: 0.0379s/iter; left time: 396.1211s\n",
      "Epoch: 1 cost time: 20.96334409713745\n",
      "Epoch: 1, Steps: 547 | Train Loss: 0.3213644 Vali Loss: 0.2350808 Test Loss: 0.2859509\n",
      "Validation loss decreased (inf --> 0.235081).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3248129\n",
      "\tspeed: 0.1140s/iter; left time: 1173.6887s\n",
      "\titers: 200, epoch: 2 | loss: 0.1801449\n",
      "\tspeed: 0.0390s/iter; left time: 397.8042s\n",
      "\titers: 300, epoch: 2 | loss: 0.2462602\n",
      "\tspeed: 0.0385s/iter; left time: 388.7611s\n",
      "\titers: 400, epoch: 2 | loss: 0.1575524\n",
      "\tspeed: 0.0378s/iter; left time: 378.0823s\n",
      "\titers: 500, epoch: 2 | loss: 0.1709965\n",
      "\tspeed: 0.0392s/iter; left time: 387.7616s\n",
      "Epoch: 2 cost time: 21.08599829673767\n",
      "Epoch: 2, Steps: 547 | Train Loss: 0.2101414 Vali Loss: 0.2093691 Test Loss: 0.2470695\n",
      "Validation loss decreased (0.235081 --> 0.209369).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1406208\n",
      "\tspeed: 0.1163s/iter; left time: 1133.8594s\n",
      "\titers: 200, epoch: 3 | loss: 0.2020014\n",
      "\tspeed: 0.0393s/iter; left time: 378.6761s\n",
      "\titers: 300, epoch: 3 | loss: 0.2256252\n",
      "\tspeed: 0.0382s/iter; left time: 364.7786s\n",
      "\titers: 400, epoch: 3 | loss: 0.2542548\n",
      "\tspeed: 0.0380s/iter; left time: 358.9473s\n",
      "\titers: 500, epoch: 3 | loss: 0.2853398\n",
      "\tspeed: 0.0375s/iter; left time: 350.7977s\n",
      "Epoch: 3 cost time: 21.07712745666504\n",
      "Epoch: 3, Steps: 547 | Train Loss: 0.1803237 Vali Loss: 0.2103571 Test Loss: 0.2436786\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1869391\n",
      "\tspeed: 0.1165s/iter; left time: 1071.6451s\n",
      "\titers: 200, epoch: 4 | loss: 0.0990478\n",
      "\tspeed: 0.0393s/iter; left time: 357.4156s\n",
      "\titers: 300, epoch: 4 | loss: 0.1814756\n",
      "\tspeed: 0.0398s/iter; left time: 358.4830s\n",
      "\titers: 400, epoch: 4 | loss: 0.1096896\n",
      "\tspeed: 0.0387s/iter; left time: 344.4201s\n",
      "\titers: 500, epoch: 4 | loss: 0.1549618\n",
      "\tspeed: 0.0378s/iter; left time: 332.6410s\n",
      "Epoch: 4 cost time: 21.17969059944153\n",
      "Epoch: 4, Steps: 547 | Train Loss: 0.1651977 Vali Loss: 0.2006576 Test Loss: 0.2306411\n",
      "Validation loss decreased (0.209369 --> 0.200658).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1564795\n",
      "\tspeed: 0.1161s/iter; left time: 1004.4930s\n",
      "\titers: 200, epoch: 5 | loss: 0.1293912\n",
      "\tspeed: 0.0378s/iter; left time: 323.3966s\n",
      "\titers: 300, epoch: 5 | loss: 0.0986068\n",
      "\tspeed: 0.0395s/iter; left time: 333.9321s\n",
      "\titers: 400, epoch: 5 | loss: 0.1164854\n",
      "\tspeed: 0.0395s/iter; left time: 329.5818s\n",
      "\titers: 500, epoch: 5 | loss: 0.1655526\n",
      "\tspeed: 0.0386s/iter; left time: 318.3373s\n",
      "Epoch: 5 cost time: 21.135735988616943\n",
      "Epoch: 5, Steps: 547 | Train Loss: 0.1553615 Vali Loss: 0.2020106 Test Loss: 0.2316605\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1559302\n",
      "\tspeed: 0.1156s/iter; left time: 936.7572s\n",
      "\titers: 200, epoch: 6 | loss: 0.0997115\n",
      "\tspeed: 0.0383s/iter; left time: 306.5857s\n",
      "\titers: 300, epoch: 6 | loss: 0.1382457\n",
      "\tspeed: 0.0383s/iter; left time: 302.8036s\n",
      "\titers: 400, epoch: 6 | loss: 0.1778576\n",
      "\tspeed: 0.0368s/iter; left time: 287.0999s\n",
      "\titers: 500, epoch: 6 | loss: 0.1894847\n",
      "\tspeed: 0.0381s/iter; left time: 293.6710s\n",
      "Epoch: 6 cost time: 20.980783224105835\n",
      "Epoch: 6, Steps: 547 | Train Loss: 0.1512229 Vali Loss: 0.2081969 Test Loss: 0.2359509\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1208443\n",
      "\tspeed: 0.1180s/iter; left time: 891.7929s\n",
      "\titers: 200, epoch: 7 | loss: 0.1058143\n",
      "\tspeed: 0.0387s/iter; left time: 288.6672s\n",
      "\titers: 300, epoch: 7 | loss: 0.0972442\n",
      "\tspeed: 0.0376s/iter; left time: 276.8958s\n",
      "\titers: 400, epoch: 7 | loss: 0.1839341\n",
      "\tspeed: 0.0376s/iter; left time: 272.6705s\n",
      "\titers: 500, epoch: 7 | loss: 0.1252157\n",
      "\tspeed: 0.0371s/iter; left time: 265.2895s\n",
      "Epoch: 7 cost time: 20.80905055999756\n",
      "Epoch: 7, Steps: 547 | Train Loss: 0.1471744 Vali Loss: 0.2091624 Test Loss: 0.2362267\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl168_ll56_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5330\n",
      "Test cost time: 2.6139s\n",
      "test shape: (166, 32, 6, 1) (166, 32, 6, 1)\n",
      "test shape: (5312, 6, 1) (5312, 6, 1)\n",
      "mse:0.23068515956401825, mae:0.3193591833114624\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl168_ll56_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1672.346923828125\n",
      "MAE:  27.191476821899414\n",
      "RMSE: 40.89433670043945\n",
      "MAPE: 0.419190913438797\n",
      "MSPE: 0.9101001620292664\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl168_ll56_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20865\n",
      "[DEBUG] Original dataset length: 20865\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 17516\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6412\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5330\n",
      "\titers: 100, epoch: 1 | loss: 0.4704157\n",
      "\tspeed: 0.0400s/iter; left time: 433.7698s\n",
      "\titers: 200, epoch: 1 | loss: 0.3434886\n",
      "\tspeed: 0.0385s/iter; left time: 413.6280s\n",
      "\titers: 300, epoch: 1 | loss: 0.2788359\n",
      "\tspeed: 0.0399s/iter; left time: 424.7848s\n",
      "\titers: 400, epoch: 1 | loss: 0.4793383\n",
      "\tspeed: 0.0410s/iter; left time: 432.1818s\n",
      "\titers: 500, epoch: 1 | loss: 0.1965410\n",
      "\tspeed: 0.0456s/iter; left time: 475.6399s\n",
      "Epoch: 1 cost time: 22.3810818195343\n",
      "Epoch: 1, Steps: 547 | Train Loss: 0.3365555 Vali Loss: 0.2015627 Test Loss: 0.2484158\n",
      "Validation loss decreased (inf --> 0.201563).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2244866\n",
      "\tspeed: 0.1199s/iter; left time: 1234.0810s\n",
      "\titers: 200, epoch: 2 | loss: 0.1992840\n",
      "\tspeed: 0.0386s/iter; left time: 393.0457s\n",
      "\titers: 300, epoch: 2 | loss: 0.1164895\n",
      "\tspeed: 0.0377s/iter; left time: 380.8590s\n",
      "\titers: 400, epoch: 2 | loss: 0.1976503\n",
      "\tspeed: 0.0384s/iter; left time: 383.7386s\n",
      "\titers: 500, epoch: 2 | loss: 0.2410497\n",
      "\tspeed: 0.0379s/iter; left time: 375.0569s\n",
      "Epoch: 2 cost time: 21.025185585021973\n",
      "Epoch: 2, Steps: 547 | Train Loss: 0.2119708 Vali Loss: 0.1970022 Test Loss: 0.2588736\n",
      "Validation loss decreased (0.201563 --> 0.197002).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1663807\n",
      "\tspeed: 0.1158s/iter; left time: 1129.0230s\n",
      "\titers: 200, epoch: 3 | loss: 0.1592036\n",
      "\tspeed: 0.0390s/iter; left time: 376.5189s\n",
      "\titers: 300, epoch: 3 | loss: 0.1340906\n",
      "\tspeed: 0.0384s/iter; left time: 366.2170s\n",
      "\titers: 400, epoch: 3 | loss: 0.1811200\n",
      "\tspeed: 0.0382s/iter; left time: 360.7105s\n",
      "\titers: 500, epoch: 3 | loss: 0.2118905\n",
      "\tspeed: 0.0380s/iter; left time: 355.6135s\n",
      "Epoch: 3 cost time: 21.07690453529358\n",
      "Epoch: 3, Steps: 547 | Train Loss: 0.1797531 Vali Loss: 0.1978798 Test Loss: 0.2386257\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1702983\n",
      "\tspeed: 0.1159s/iter; left time: 1065.9292s\n",
      "\titers: 200, epoch: 4 | loss: 0.1429545\n",
      "\tspeed: 0.0377s/iter; left time: 342.6468s\n",
      "\titers: 300, epoch: 4 | loss: 0.2182051\n",
      "\tspeed: 0.0395s/iter; left time: 355.0738s\n",
      "\titers: 400, epoch: 4 | loss: 0.1269060\n",
      "\tspeed: 0.0386s/iter; left time: 343.3670s\n",
      "\titers: 500, epoch: 4 | loss: 0.1962214\n",
      "\tspeed: 0.0379s/iter; left time: 333.1624s\n",
      "Epoch: 4 cost time: 20.941588878631592\n",
      "Epoch: 4, Steps: 547 | Train Loss: 0.1626152 Vali Loss: 0.1963331 Test Loss: 0.2362392\n",
      "Validation loss decreased (0.197002 --> 0.196333).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1501233\n",
      "\tspeed: 0.1165s/iter; left time: 1007.9306s\n",
      "\titers: 200, epoch: 5 | loss: 0.1436307\n",
      "\tspeed: 0.0382s/iter; left time: 326.6288s\n",
      "\titers: 300, epoch: 5 | loss: 0.1509439\n",
      "\tspeed: 0.0376s/iter; left time: 318.1464s\n",
      "\titers: 400, epoch: 5 | loss: 0.1191471\n",
      "\tspeed: 0.0389s/iter; left time: 324.9607s\n",
      "\titers: 500, epoch: 5 | loss: 0.1561096\n",
      "\tspeed: 0.0393s/iter; left time: 324.7479s\n",
      "Epoch: 5 cost time: 21.081068754196167\n",
      "Epoch: 5, Steps: 547 | Train Loss: 0.1526757 Vali Loss: 0.2034659 Test Loss: 0.2344503\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0888844\n",
      "\tspeed: 0.1161s/iter; left time: 941.0577s\n",
      "\titers: 200, epoch: 6 | loss: 0.2050913\n",
      "\tspeed: 0.0379s/iter; left time: 303.5967s\n",
      "\titers: 300, epoch: 6 | loss: 0.1981285\n",
      "\tspeed: 0.0378s/iter; left time: 298.4809s\n",
      "\titers: 400, epoch: 6 | loss: 0.2087221\n",
      "\tspeed: 0.0388s/iter; left time: 303.2323s\n",
      "\titers: 500, epoch: 6 | loss: 0.1835666\n",
      "\tspeed: 0.0390s/iter; left time: 300.7128s\n",
      "Epoch: 6 cost time: 21.16627788543701\n",
      "Epoch: 6, Steps: 547 | Train Loss: 0.1474397 Vali Loss: 0.2025875 Test Loss: 0.2339827\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2426123\n",
      "\tspeed: 0.1156s/iter; left time: 874.1983s\n",
      "\titers: 200, epoch: 7 | loss: 0.1523392\n",
      "\tspeed: 0.0385s/iter; left time: 287.0585s\n",
      "\titers: 300, epoch: 7 | loss: 0.1501031\n",
      "\tspeed: 0.0382s/iter; left time: 281.1637s\n",
      "\titers: 400, epoch: 7 | loss: 0.1077286\n",
      "\tspeed: 0.0382s/iter; left time: 277.5359s\n",
      "\titers: 500, epoch: 7 | loss: 0.1361721\n",
      "\tspeed: 0.0389s/iter; left time: 278.5194s\n",
      "Epoch: 7 cost time: 21.060712337493896\n",
      "Epoch: 7, Steps: 547 | Train Loss: 0.1451652 Vali Loss: 0.2081826 Test Loss: 0.2367361\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl168_ll56_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5330\n",
      "Test cost time: 2.6299s\n",
      "test shape: (166, 32, 6, 1) (166, 32, 6, 1)\n",
      "test shape: (5312, 6, 1) (5312, 6, 1)\n",
      "mse:0.23466292023658752, mae:0.31791505217552185\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl168_ll56_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1701.1837158203125\n",
      "MAE:  27.06851577758789\n",
      "RMSE: 41.24540710449219\n",
      "MAPE: 0.34052249789237976\n",
      "MSPE: 0.5430285334587097\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl168_ll56_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20865\n",
      "[DEBUG] Original dataset length: 20865\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 17516\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6412\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5330\n",
      "\titers: 100, epoch: 1 | loss: 0.3423788\n",
      "\tspeed: 0.0389s/iter; left time: 421.5843s\n",
      "\titers: 200, epoch: 1 | loss: 0.2468133\n",
      "\tspeed: 0.0396s/iter; left time: 425.7240s\n",
      "\titers: 300, epoch: 1 | loss: 0.3003012\n",
      "\tspeed: 0.0401s/iter; left time: 426.6406s\n",
      "\titers: 400, epoch: 1 | loss: 0.3013112\n",
      "\tspeed: 0.0389s/iter; left time: 410.4001s\n",
      "\titers: 500, epoch: 1 | loss: 0.1513880\n",
      "\tspeed: 0.0401s/iter; left time: 418.7022s\n",
      "Epoch: 1 cost time: 21.680986166000366\n",
      "Epoch: 1, Steps: 547 | Train Loss: 0.3262335 Vali Loss: 0.2093944 Test Loss: 0.2590232\n",
      "Validation loss decreased (inf --> 0.209394).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1814635\n",
      "\tspeed: 0.1178s/iter; left time: 1212.4187s\n",
      "\titers: 200, epoch: 2 | loss: 0.2718269\n",
      "\tspeed: 0.0386s/iter; left time: 393.3003s\n",
      "\titers: 300, epoch: 2 | loss: 0.1957121\n",
      "\tspeed: 0.0387s/iter; left time: 390.3608s\n",
      "\titers: 400, epoch: 2 | loss: 0.1596963\n",
      "\tspeed: 0.0385s/iter; left time: 385.0324s\n",
      "\titers: 500, epoch: 2 | loss: 0.1540959\n",
      "\tspeed: 0.0385s/iter; left time: 381.1897s\n",
      "Epoch: 2 cost time: 21.222087621688843\n",
      "Epoch: 2, Steps: 547 | Train Loss: 0.2073319 Vali Loss: 0.1962732 Test Loss: 0.2430071\n",
      "Validation loss decreased (0.209394 --> 0.196273).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1508060\n",
      "\tspeed: 0.1179s/iter; left time: 1149.1208s\n",
      "\titers: 200, epoch: 3 | loss: 0.1535532\n",
      "\tspeed: 0.0387s/iter; left time: 372.8942s\n",
      "\titers: 300, epoch: 3 | loss: 0.1248932\n",
      "\tspeed: 0.0395s/iter; left time: 377.2467s\n",
      "\titers: 400, epoch: 3 | loss: 0.1956248\n",
      "\tspeed: 0.0397s/iter; left time: 375.0447s\n",
      "\titers: 500, epoch: 3 | loss: 0.1855673\n",
      "\tspeed: 0.0378s/iter; left time: 353.1672s\n",
      "Epoch: 3 cost time: 21.17462706565857\n",
      "Epoch: 3, Steps: 547 | Train Loss: 0.1783941 Vali Loss: 0.2024096 Test Loss: 0.2374565\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1220694\n",
      "\tspeed: 0.1142s/iter; left time: 1050.3847s\n",
      "\titers: 200, epoch: 4 | loss: 0.2061774\n",
      "\tspeed: 0.0381s/iter; left time: 346.6866s\n",
      "\titers: 300, epoch: 4 | loss: 0.1437210\n",
      "\tspeed: 0.0390s/iter; left time: 351.3602s\n",
      "\titers: 400, epoch: 4 | loss: 0.1307117\n",
      "\tspeed: 0.0379s/iter; left time: 337.5980s\n",
      "\titers: 500, epoch: 4 | loss: 0.2016973\n",
      "\tspeed: 0.0378s/iter; left time: 332.4555s\n",
      "Epoch: 4 cost time: 20.93579077720642\n",
      "Epoch: 4, Steps: 547 | Train Loss: 0.1608933 Vali Loss: 0.1982027 Test Loss: 0.2396091\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1820250\n",
      "\tspeed: 0.1155s/iter; left time: 999.3852s\n",
      "\titers: 200, epoch: 5 | loss: 0.1662157\n",
      "\tspeed: 0.0383s/iter; left time: 327.4319s\n",
      "\titers: 300, epoch: 5 | loss: 0.1469832\n",
      "\tspeed: 0.0377s/iter; left time: 318.3706s\n",
      "\titers: 400, epoch: 5 | loss: 0.1399056\n",
      "\tspeed: 0.0397s/iter; left time: 331.8651s\n",
      "\titers: 500, epoch: 5 | loss: 0.1265152\n",
      "\tspeed: 0.0386s/iter; left time: 318.2539s\n",
      "Epoch: 5 cost time: 21.09239101409912\n",
      "Epoch: 5, Steps: 547 | Train Loss: 0.1527417 Vali Loss: 0.1941594 Test Loss: 0.2343018\n",
      "Validation loss decreased (0.196273 --> 0.194159).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1241422\n",
      "\tspeed: 0.1167s/iter; left time: 945.9008s\n",
      "\titers: 200, epoch: 6 | loss: 0.1279664\n",
      "\tspeed: 0.0388s/iter; left time: 310.3161s\n",
      "\titers: 300, epoch: 6 | loss: 0.1928716\n",
      "\tspeed: 0.0378s/iter; left time: 298.5268s\n",
      "\titers: 400, epoch: 6 | loss: 0.1091175\n",
      "\tspeed: 0.0382s/iter; left time: 298.1542s\n",
      "\titers: 500, epoch: 6 | loss: 0.1150086\n",
      "\tspeed: 0.0400s/iter; left time: 307.9935s\n",
      "Epoch: 6 cost time: 21.223938465118408\n",
      "Epoch: 6, Steps: 547 | Train Loss: 0.1475535 Vali Loss: 0.1941665 Test Loss: 0.2352121\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1115085\n",
      "\tspeed: 0.1153s/iter; left time: 871.2088s\n",
      "\titers: 200, epoch: 7 | loss: 0.1649652\n",
      "\tspeed: 0.0397s/iter; left time: 296.0522s\n",
      "\titers: 300, epoch: 7 | loss: 0.0933144\n",
      "\tspeed: 0.0406s/iter; left time: 298.5630s\n",
      "\titers: 400, epoch: 7 | loss: 0.1070816\n",
      "\tspeed: 0.0390s/iter; left time: 283.0287s\n",
      "\titers: 500, epoch: 7 | loss: 0.1245777\n",
      "\tspeed: 0.0392s/iter; left time: 280.7193s\n",
      "Epoch: 7 cost time: 21.60966420173645\n",
      "Epoch: 7, Steps: 547 | Train Loss: 0.1445972 Vali Loss: 0.1949430 Test Loss: 0.2331044\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1350822\n",
      "\tspeed: 0.1139s/iter; left time: 798.6632s\n",
      "\titers: 200, epoch: 8 | loss: 0.1613582\n",
      "\tspeed: 0.0368s/iter; left time: 254.4721s\n",
      "\titers: 300, epoch: 8 | loss: 0.1210637\n",
      "\tspeed: 0.0380s/iter; left time: 258.7139s\n",
      "\titers: 400, epoch: 8 | loss: 0.1564546\n",
      "\tspeed: 0.0376s/iter; left time: 252.6676s\n",
      "\titers: 500, epoch: 8 | loss: 0.1743018\n",
      "\tspeed: 0.0369s/iter; left time: 244.1567s\n",
      "Epoch: 8 cost time: 20.296525478363037\n",
      "Epoch: 8, Steps: 547 | Train Loss: 0.1431905 Vali Loss: 0.1960411 Test Loss: 0.2338534\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl168_ll56_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5330\n",
      "Test cost time: 2.6957s\n",
      "test shape: (166, 32, 6, 1) (166, 32, 6, 1)\n",
      "test shape: (5312, 6, 1) (5312, 6, 1)\n",
      "mse:0.23336228728294373, mae:0.31328633427619934\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl168_ll56_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1691.7547607421875\n",
      "MAE:  26.674409866333008\n",
      "RMSE: 41.13094711303711\n",
      "MAPE: 0.32191434502601624\n",
      "MSPE: 0.43961402773857117\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl168_ll56_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20865\n",
      "[DEBUG] Original dataset length: 20865\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 17516\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6412\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5330\n",
      "\titers: 100, epoch: 1 | loss: 0.4395234\n",
      "\tspeed: 0.0388s/iter; left time: 420.7407s\n",
      "\titers: 200, epoch: 1 | loss: 0.3000868\n",
      "\tspeed: 0.0380s/iter; left time: 407.9688s\n",
      "\titers: 300, epoch: 1 | loss: 0.4435479\n",
      "\tspeed: 0.0393s/iter; left time: 417.7076s\n",
      "\titers: 400, epoch: 1 | loss: 0.2912055\n",
      "\tspeed: 0.0381s/iter; left time: 401.4922s\n",
      "\titers: 500, epoch: 1 | loss: 0.1937862\n",
      "\tspeed: 0.0380s/iter; left time: 396.8384s\n",
      "Epoch: 1 cost time: 21.009427785873413\n",
      "Epoch: 1, Steps: 547 | Train Loss: 0.3345158 Vali Loss: 0.2506843 Test Loss: 0.2896253\n",
      "Validation loss decreased (inf --> 0.250684).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2283333\n",
      "\tspeed: 0.1166s/iter; left time: 1200.1214s\n",
      "\titers: 200, epoch: 2 | loss: 0.2654166\n",
      "\tspeed: 0.0381s/iter; left time: 388.2439s\n",
      "\titers: 300, epoch: 2 | loss: 0.4321614\n",
      "\tspeed: 0.0394s/iter; left time: 397.2106s\n",
      "\titers: 400, epoch: 2 | loss: 0.2429511\n",
      "\tspeed: 0.0382s/iter; left time: 381.9436s\n",
      "\titers: 500, epoch: 2 | loss: 0.2662286\n",
      "\tspeed: 0.0382s/iter; left time: 378.4142s\n",
      "Epoch: 2 cost time: 21.060400009155273\n",
      "Epoch: 2, Steps: 547 | Train Loss: 0.2071703 Vali Loss: 0.2109217 Test Loss: 0.2564366\n",
      "Validation loss decreased (0.250684 --> 0.210922).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2592127\n",
      "\tspeed: 0.1126s/iter; left time: 1097.1672s\n",
      "\titers: 200, epoch: 3 | loss: 0.2075958\n",
      "\tspeed: 0.0380s/iter; left time: 366.4021s\n",
      "\titers: 300, epoch: 3 | loss: 0.1481207\n",
      "\tspeed: 0.0375s/iter; left time: 358.0430s\n",
      "\titers: 400, epoch: 3 | loss: 0.1642263\n",
      "\tspeed: 0.0397s/iter; left time: 375.5154s\n",
      "\titers: 500, epoch: 3 | loss: 0.2820205\n",
      "\tspeed: 0.0392s/iter; left time: 366.7194s\n",
      "Epoch: 3 cost time: 20.94270658493042\n",
      "Epoch: 3, Steps: 547 | Train Loss: 0.1777654 Vali Loss: 0.2153817 Test Loss: 0.2596208\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2385353\n",
      "\tspeed: 0.1170s/iter; left time: 1076.5215s\n",
      "\titers: 200, epoch: 4 | loss: 0.1113837\n",
      "\tspeed: 0.0386s/iter; left time: 351.2058s\n",
      "\titers: 300, epoch: 4 | loss: 0.0996610\n",
      "\tspeed: 0.0387s/iter; left time: 348.4062s\n",
      "\titers: 400, epoch: 4 | loss: 0.2040198\n",
      "\tspeed: 0.0382s/iter; left time: 340.0781s\n",
      "\titers: 500, epoch: 4 | loss: 0.1492554\n",
      "\tspeed: 0.0396s/iter; left time: 348.1831s\n",
      "Epoch: 4 cost time: 21.396254301071167\n",
      "Epoch: 4, Steps: 547 | Train Loss: 0.1623506 Vali Loss: 0.1995227 Test Loss: 0.2421902\n",
      "Validation loss decreased (0.210922 --> 0.199523).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2117292\n",
      "\tspeed: 0.1134s/iter; left time: 981.5475s\n",
      "\titers: 200, epoch: 5 | loss: 0.1307255\n",
      "\tspeed: 0.0384s/iter; left time: 328.3372s\n",
      "\titers: 300, epoch: 5 | loss: 0.2214125\n",
      "\tspeed: 0.0389s/iter; left time: 328.8982s\n",
      "\titers: 400, epoch: 5 | loss: 0.1564792\n",
      "\tspeed: 0.0381s/iter; left time: 318.2326s\n",
      "\titers: 500, epoch: 5 | loss: 0.1850189\n",
      "\tspeed: 0.0391s/iter; left time: 322.7670s\n",
      "Epoch: 5 cost time: 20.913615226745605\n",
      "Epoch: 5, Steps: 547 | Train Loss: 0.1535875 Vali Loss: 0.2008067 Test Loss: 0.2427861\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0738145\n",
      "\tspeed: 0.1143s/iter; left time: 926.7889s\n",
      "\titers: 200, epoch: 6 | loss: 0.1303486\n",
      "\tspeed: 0.0393s/iter; left time: 314.3656s\n",
      "\titers: 300, epoch: 6 | loss: 0.1422713\n",
      "\tspeed: 0.0391s/iter; left time: 309.4437s\n",
      "\titers: 400, epoch: 6 | loss: 0.1749730\n",
      "\tspeed: 0.0392s/iter; left time: 306.3008s\n",
      "\titers: 500, epoch: 6 | loss: 0.2272595\n",
      "\tspeed: 0.0389s/iter; left time: 300.0915s\n",
      "Epoch: 6 cost time: 21.260977268218994\n",
      "Epoch: 6, Steps: 547 | Train Loss: 0.1489866 Vali Loss: 0.2017843 Test Loss: 0.2420544\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1531913\n",
      "\tspeed: 0.1165s/iter; left time: 880.8633s\n",
      "\titers: 200, epoch: 7 | loss: 0.1633667\n",
      "\tspeed: 0.0381s/iter; left time: 283.9247s\n",
      "\titers: 300, epoch: 7 | loss: 0.1696120\n",
      "\tspeed: 0.0385s/iter; left time: 283.3553s\n",
      "\titers: 400, epoch: 7 | loss: 0.1558690\n",
      "\tspeed: 0.0379s/iter; left time: 275.2668s\n",
      "\titers: 500, epoch: 7 | loss: 0.1704779\n",
      "\tspeed: 0.0383s/iter; left time: 274.3114s\n",
      "Epoch: 7 cost time: 20.982492208480835\n",
      "Epoch: 7, Steps: 547 | Train Loss: 0.1459781 Vali Loss: 0.2020977 Test Loss: 0.2453029\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl168_ll56_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5330\n",
      "Test cost time: 2.6416s\n",
      "test shape: (166, 32, 6, 1) (166, 32, 6, 1)\n",
      "test shape: (5312, 6, 1) (5312, 6, 1)\n",
      "mse:0.24354048073291779, mae:0.3346920907497406\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl168_ll56_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1765.5413818359375\n",
      "MAE:  28.496978759765625\n",
      "RMSE: 42.01834487915039\n",
      "MAPE: 0.4276511073112488\n",
      "MSPE: 0.8997729420661926\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl168_ll56_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20865\n",
      "[DEBUG] Original dataset length: 20865\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 17516\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6412\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5330\n",
      "\titers: 100, epoch: 1 | loss: 0.3222407\n",
      "\tspeed: 0.0388s/iter; left time: 420.1580s\n",
      "\titers: 200, epoch: 1 | loss: 0.3050959\n",
      "\tspeed: 0.0389s/iter; left time: 417.4526s\n",
      "\titers: 300, epoch: 1 | loss: 0.1480398\n",
      "\tspeed: 0.0373s/iter; left time: 397.2630s\n",
      "\titers: 400, epoch: 1 | loss: 0.1703430\n",
      "\tspeed: 0.0367s/iter; left time: 387.2325s\n",
      "\titers: 500, epoch: 1 | loss: 0.2425410\n",
      "\tspeed: 0.0377s/iter; left time: 393.2309s\n",
      "Epoch: 1 cost time: 20.740795135498047\n",
      "Epoch: 1, Steps: 547 | Train Loss: 0.3240588 Vali Loss: 0.2096085 Test Loss: 0.2601011\n",
      "Validation loss decreased (inf --> 0.209609).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1038599\n",
      "\tspeed: 0.1155s/iter; left time: 1189.4301s\n",
      "\titers: 200, epoch: 2 | loss: 0.2702372\n",
      "\tspeed: 0.0381s/iter; left time: 388.0537s\n",
      "\titers: 300, epoch: 2 | loss: 0.1642679\n",
      "\tspeed: 0.0381s/iter; left time: 384.8341s\n",
      "\titers: 400, epoch: 2 | loss: 0.1669121\n",
      "\tspeed: 0.0400s/iter; left time: 399.4705s\n",
      "\titers: 500, epoch: 2 | loss: 0.1615831\n",
      "\tspeed: 0.0385s/iter; left time: 381.0139s\n",
      "Epoch: 2 cost time: 21.03722834587097\n",
      "Epoch: 2, Steps: 547 | Train Loss: 0.2094513 Vali Loss: 0.2132292 Test Loss: 0.2587752\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2077383\n",
      "\tspeed: 0.1153s/iter; left time: 1123.4259s\n",
      "\titers: 200, epoch: 3 | loss: 0.2300293\n",
      "\tspeed: 0.0373s/iter; left time: 360.1672s\n",
      "\titers: 300, epoch: 3 | loss: 0.1008059\n",
      "\tspeed: 0.0354s/iter; left time: 337.5323s\n",
      "\titers: 400, epoch: 3 | loss: 0.1420110\n",
      "\tspeed: 0.0364s/iter; left time: 343.4841s\n",
      "\titers: 500, epoch: 3 | loss: 0.1850877\n",
      "\tspeed: 0.0397s/iter; left time: 371.3881s\n",
      "Epoch: 3 cost time: 20.63580560684204\n",
      "Epoch: 3, Steps: 547 | Train Loss: 0.1784695 Vali Loss: 0.1953534 Test Loss: 0.2377820\n",
      "Validation loss decreased (0.209609 --> 0.195353).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1606770\n",
      "\tspeed: 0.1171s/iter; left time: 1077.1089s\n",
      "\titers: 200, epoch: 4 | loss: 0.2689924\n",
      "\tspeed: 0.0394s/iter; left time: 358.9698s\n",
      "\titers: 300, epoch: 4 | loss: 0.1311445\n",
      "\tspeed: 0.0389s/iter; left time: 350.1179s\n",
      "\titers: 400, epoch: 4 | loss: 0.2185020\n",
      "\tspeed: 0.0382s/iter; left time: 339.9703s\n",
      "\titers: 500, epoch: 4 | loss: 0.1631648\n",
      "\tspeed: 0.0383s/iter; left time: 337.3827s\n",
      "Epoch: 4 cost time: 21.066893577575684\n",
      "Epoch: 4, Steps: 547 | Train Loss: 0.1625194 Vali Loss: 0.1930493 Test Loss: 0.2322792\n",
      "Validation loss decreased (0.195353 --> 0.193049).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1433483\n",
      "\tspeed: 0.1084s/iter; left time: 938.2437s\n",
      "\titers: 200, epoch: 5 | loss: 0.2292644\n",
      "\tspeed: 0.0361s/iter; left time: 308.4798s\n",
      "\titers: 300, epoch: 5 | loss: 0.1665047\n",
      "\tspeed: 0.0392s/iter; left time: 330.9458s\n",
      "\titers: 400, epoch: 5 | loss: 0.1911177\n",
      "\tspeed: 0.0381s/iter; left time: 318.4437s\n",
      "\titers: 500, epoch: 5 | loss: 0.1706960\n",
      "\tspeed: 0.0366s/iter; left time: 301.8947s\n",
      "Epoch: 5 cost time: 20.41774821281433\n",
      "Epoch: 5, Steps: 547 | Train Loss: 0.1531550 Vali Loss: 0.1986600 Test Loss: 0.2309978\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1280714\n",
      "\tspeed: 0.1180s/iter; left time: 956.7186s\n",
      "\titers: 200, epoch: 6 | loss: 0.1663789\n",
      "\tspeed: 0.0394s/iter; left time: 315.0704s\n",
      "\titers: 300, epoch: 6 | loss: 0.2294005\n",
      "\tspeed: 0.0378s/iter; left time: 298.9974s\n",
      "\titers: 400, epoch: 6 | loss: 0.1068490\n",
      "\tspeed: 0.0368s/iter; left time: 286.9743s\n",
      "\titers: 500, epoch: 6 | loss: 0.1691674\n",
      "\tspeed: 0.0386s/iter; left time: 297.3527s\n",
      "Epoch: 6 cost time: 21.062736749649048\n",
      "Epoch: 6, Steps: 547 | Train Loss: 0.1484526 Vali Loss: 0.1995978 Test Loss: 0.2323388\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2190067\n",
      "\tspeed: 0.1172s/iter; left time: 886.1915s\n",
      "\titers: 200, epoch: 7 | loss: 0.1586754\n",
      "\tspeed: 0.0392s/iter; left time: 292.2433s\n",
      "\titers: 300, epoch: 7 | loss: 0.1330560\n",
      "\tspeed: 0.0393s/iter; left time: 289.5223s\n",
      "\titers: 400, epoch: 7 | loss: 0.1320395\n",
      "\tspeed: 0.0438s/iter; left time: 317.9636s\n",
      "\titers: 500, epoch: 7 | loss: 0.1733181\n",
      "\tspeed: 0.0422s/iter; left time: 302.4438s\n",
      "Epoch: 7 cost time: 22.255378246307373\n",
      "Epoch: 7, Steps: 547 | Train Loss: 0.1455477 Vali Loss: 0.1980448 Test Loss: 0.2334167\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl168_ll56_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5330\n",
      "Test cost time: 2.6020s\n",
      "test shape: (166, 32, 6, 1) (166, 32, 6, 1)\n",
      "test shape: (5312, 6, 1) (5312, 6, 1)\n",
      "mse:0.23093849420547485, mae:0.3193681240081787\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl168_ll56_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1674.1834716796875\n",
      "MAE:  27.192237854003906\n",
      "RMSE: 40.916786193847656\n",
      "MAPE: 0.35525789856910706\n",
      "MSPE: 0.5662400126457214\n",
      ">>>>>>>Running time saved<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Running seq_len=192, label_len=64, pred_len=6\n",
      "Args in experiment:\n",
      "Namespace(model='informer', data='traffic_full', root_path='../', data_path='traffic_full.csv', features='S', target='flow', freq='h', checkpoints='./checkpoints/', seq_len=192, label_len=64, pred_len=6, enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=2, d_layers=1, s_layers=[3, 2, 1], d_ff=2048, factor=5, padding=0, distil=True, dropout=0.05, attn='prob', embed='timeF', activation='gelu', output_attention=False, do_predict=False, mix=True, cols=None, num_workers=0, itr=10, train_epochs=20, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, inverse=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', detail_freq='h')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl192_ll64_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20841\n",
      "[DEBUG] Original dataset length: 20841\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 17156\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6340\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5162\n",
      "\titers: 100, epoch: 1 | loss: 0.3726177\n",
      "\tspeed: 0.0513s/iter; left time: 544.5901s\n",
      "\titers: 200, epoch: 1 | loss: 0.2328065\n",
      "\tspeed: 0.0397s/iter; left time: 417.8842s\n",
      "\titers: 300, epoch: 1 | loss: 0.3678833\n",
      "\tspeed: 0.0411s/iter; left time: 428.5956s\n",
      "\titers: 400, epoch: 1 | loss: 0.1631328\n",
      "\tspeed: 0.0415s/iter; left time: 427.9152s\n",
      "\titers: 500, epoch: 1 | loss: 0.1752890\n",
      "\tspeed: 0.0414s/iter; left time: 423.0114s\n",
      "Epoch: 1 cost time: 22.20113182067871\n",
      "Epoch: 1, Steps: 536 | Train Loss: 0.3497601 Vali Loss: 0.2463225 Test Loss: 0.2687188\n",
      "Validation loss decreased (inf --> 0.246323).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1996728\n",
      "\tspeed: 0.1220s/iter; left time: 1230.2509s\n",
      "\titers: 200, epoch: 2 | loss: 0.1829554\n",
      "\tspeed: 0.0413s/iter; left time: 412.8663s\n",
      "\titers: 300, epoch: 2 | loss: 0.2171351\n",
      "\tspeed: 0.0423s/iter; left time: 417.7373s\n",
      "\titers: 400, epoch: 2 | loss: 0.2482222\n",
      "\tspeed: 0.0417s/iter; left time: 408.0428s\n",
      "\titers: 500, epoch: 2 | loss: 0.1501746\n",
      "\tspeed: 0.0417s/iter; left time: 403.6593s\n",
      "Epoch: 2 cost time: 22.384309768676758\n",
      "Epoch: 2, Steps: 536 | Train Loss: 0.2111516 Vali Loss: 0.2300944 Test Loss: 0.2587520\n",
      "Validation loss decreased (0.246323 --> 0.230094).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1359360\n",
      "\tspeed: 0.1200s/iter; left time: 1145.5627s\n",
      "\titers: 200, epoch: 3 | loss: 0.1785449\n",
      "\tspeed: 0.0409s/iter; left time: 386.1289s\n",
      "\titers: 300, epoch: 3 | loss: 0.1831103\n",
      "\tspeed: 0.0425s/iter; left time: 397.1396s\n",
      "\titers: 400, epoch: 3 | loss: 0.1805162\n",
      "\tspeed: 0.0415s/iter; left time: 383.5118s\n",
      "\titers: 500, epoch: 3 | loss: 0.1300761\n",
      "\tspeed: 0.0413s/iter; left time: 378.1520s\n",
      "Epoch: 3 cost time: 22.27785634994507\n",
      "Epoch: 3, Steps: 536 | Train Loss: 0.1781299 Vali Loss: 0.1903543 Test Loss: 0.2391027\n",
      "Validation loss decreased (0.230094 --> 0.190354).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0951930\n",
      "\tspeed: 0.1196s/iter; left time: 1078.2368s\n",
      "\titers: 200, epoch: 4 | loss: 0.1586204\n",
      "\tspeed: 0.0394s/iter; left time: 351.1416s\n",
      "\titers: 300, epoch: 4 | loss: 0.1602478\n",
      "\tspeed: 0.0392s/iter; left time: 345.1143s\n",
      "\titers: 400, epoch: 4 | loss: 0.1577834\n",
      "\tspeed: 0.0410s/iter; left time: 357.6390s\n",
      "\titers: 500, epoch: 4 | loss: 0.1523142\n",
      "\tspeed: 0.0417s/iter; left time: 359.5809s\n",
      "Epoch: 4 cost time: 21.711793184280396\n",
      "Epoch: 4, Steps: 536 | Train Loss: 0.1635846 Vali Loss: 0.1981570 Test Loss: 0.2347497\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1266992\n",
      "\tspeed: 0.1201s/iter; left time: 1017.8597s\n",
      "\titers: 200, epoch: 5 | loss: 0.1872887\n",
      "\tspeed: 0.0413s/iter; left time: 346.0378s\n",
      "\titers: 300, epoch: 5 | loss: 0.2667337\n",
      "\tspeed: 0.0408s/iter; left time: 337.7234s\n",
      "\titers: 400, epoch: 5 | loss: 0.1284030\n",
      "\tspeed: 0.0428s/iter; left time: 350.2350s\n",
      "\titers: 500, epoch: 5 | loss: 0.1007918\n",
      "\tspeed: 0.0409s/iter; left time: 330.4295s\n",
      "Epoch: 5 cost time: 22.24720549583435\n",
      "Epoch: 5, Steps: 536 | Train Loss: 0.1540463 Vali Loss: 0.1960474 Test Loss: 0.2469556\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1689675\n",
      "\tspeed: 0.1192s/iter; left time: 946.4207s\n",
      "\titers: 200, epoch: 6 | loss: 0.1462469\n",
      "\tspeed: 0.0411s/iter; left time: 322.2405s\n",
      "\titers: 300, epoch: 6 | loss: 0.1273969\n",
      "\tspeed: 0.0416s/iter; left time: 321.9103s\n",
      "\titers: 400, epoch: 6 | loss: 0.1044915\n",
      "\tspeed: 0.0426s/iter; left time: 325.2594s\n",
      "\titers: 500, epoch: 6 | loss: 0.1650523\n",
      "\tspeed: 0.0410s/iter; left time: 309.5353s\n",
      "Epoch: 6 cost time: 22.24420976638794\n",
      "Epoch: 6, Steps: 536 | Train Loss: 0.1488083 Vali Loss: 0.1953489 Test Loss: 0.2397484\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl192_ll64_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5162\n",
      "Test cost time: 2.8662s\n",
      "test shape: (161, 32, 6, 1) (161, 32, 6, 1)\n",
      "test shape: (5152, 6, 1) (5152, 6, 1)\n",
      "mse:0.23847045004367828, mae:0.33167198300361633\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl192_ll64_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1728.7862548828125\n",
      "MAE:  28.239835739135742\n",
      "RMSE: 41.57867431640625\n",
      "MAPE: 0.374421626329422\n",
      "MSPE: 0.6872059106826782\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl192_ll64_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20841\n",
      "[DEBUG] Original dataset length: 20841\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 17156\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6340\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5162\n",
      "\titers: 100, epoch: 1 | loss: 0.3834393\n",
      "\tspeed: 0.0411s/iter; left time: 436.2396s\n",
      "\titers: 200, epoch: 1 | loss: 0.3125662\n",
      "\tspeed: 0.0424s/iter; left time: 445.9544s\n",
      "\titers: 300, epoch: 1 | loss: 0.2008639\n",
      "\tspeed: 0.0414s/iter; left time: 431.9013s\n",
      "\titers: 400, epoch: 1 | loss: 0.1633207\n",
      "\tspeed: 0.0411s/iter; left time: 423.8156s\n",
      "\titers: 500, epoch: 1 | loss: 0.2488948\n",
      "\tspeed: 0.0412s/iter; left time: 420.9058s\n",
      "Epoch: 1 cost time: 22.248773336410522\n",
      "Epoch: 1, Steps: 536 | Train Loss: 0.3328430 Vali Loss: 0.2267691 Test Loss: 0.2774867\n",
      "Validation loss decreased (inf --> 0.226769).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1449987\n",
      "\tspeed: 0.1144s/iter; left time: 1153.8581s\n",
      "\titers: 200, epoch: 2 | loss: 0.1762636\n",
      "\tspeed: 0.0390s/iter; left time: 389.1212s\n",
      "\titers: 300, epoch: 2 | loss: 0.1778841\n",
      "\tspeed: 0.0409s/iter; left time: 404.7367s\n",
      "\titers: 400, epoch: 2 | loss: 0.2715216\n",
      "\tspeed: 0.0420s/iter; left time: 410.8093s\n",
      "\titers: 500, epoch: 2 | loss: 0.1347856\n",
      "\tspeed: 0.0419s/iter; left time: 405.8202s\n",
      "Epoch: 2 cost time: 21.768788814544678\n",
      "Epoch: 2, Steps: 536 | Train Loss: 0.2072478 Vali Loss: 0.1996914 Test Loss: 0.2391237\n",
      "Validation loss decreased (0.226769 --> 0.199691).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2608638\n",
      "\tspeed: 0.1166s/iter; left time: 1113.6181s\n",
      "\titers: 200, epoch: 3 | loss: 0.1377125\n",
      "\tspeed: 0.0410s/iter; left time: 387.3837s\n",
      "\titers: 300, epoch: 3 | loss: 0.2011741\n",
      "\tspeed: 0.0410s/iter; left time: 383.0753s\n",
      "\titers: 400, epoch: 3 | loss: 0.1301821\n",
      "\tspeed: 0.0407s/iter; left time: 376.8126s\n",
      "\titers: 500, epoch: 3 | loss: 0.1158288\n",
      "\tspeed: 0.0395s/iter; left time: 361.7232s\n",
      "Epoch: 3 cost time: 21.739017724990845\n",
      "Epoch: 3, Steps: 536 | Train Loss: 0.1791376 Vali Loss: 0.1991405 Test Loss: 0.2452376\n",
      "Validation loss decreased (0.199691 --> 0.199141).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1280098\n",
      "\tspeed: 0.1144s/iter; left time: 1031.0275s\n",
      "\titers: 200, epoch: 4 | loss: 0.1476784\n",
      "\tspeed: 0.0413s/iter; left time: 368.3810s\n",
      "\titers: 300, epoch: 4 | loss: 0.1743467\n",
      "\tspeed: 0.0412s/iter; left time: 362.6580s\n",
      "\titers: 400, epoch: 4 | loss: 0.1298979\n",
      "\tspeed: 0.0409s/iter; left time: 356.0514s\n",
      "\titers: 500, epoch: 4 | loss: 0.2203851\n",
      "\tspeed: 0.0422s/iter; left time: 363.8803s\n",
      "Epoch: 4 cost time: 22.102264642715454\n",
      "Epoch: 4, Steps: 536 | Train Loss: 0.1632633 Vali Loss: 0.2001088 Test Loss: 0.2504365\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1235072\n",
      "\tspeed: 0.1145s/iter; left time: 970.6896s\n",
      "\titers: 200, epoch: 5 | loss: 0.2310903\n",
      "\tspeed: 0.0417s/iter; left time: 349.4079s\n",
      "\titers: 300, epoch: 5 | loss: 0.1957915\n",
      "\tspeed: 0.0408s/iter; left time: 337.6131s\n",
      "\titers: 400, epoch: 5 | loss: 0.1845549\n",
      "\tspeed: 0.0411s/iter; left time: 336.1445s\n",
      "\titers: 500, epoch: 5 | loss: 0.2513076\n",
      "\tspeed: 0.0415s/iter; left time: 335.1985s\n",
      "Epoch: 5 cost time: 22.015355825424194\n",
      "Epoch: 5, Steps: 536 | Train Loss: 0.1549722 Vali Loss: 0.1977492 Test Loss: 0.2421818\n",
      "Validation loss decreased (0.199141 --> 0.197749).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1764160\n",
      "\tspeed: 0.1212s/iter; left time: 962.5624s\n",
      "\titers: 200, epoch: 6 | loss: 0.1881897\n",
      "\tspeed: 0.0427s/iter; left time: 335.1951s\n",
      "\titers: 300, epoch: 6 | loss: 0.1448345\n",
      "\tspeed: 0.0423s/iter; left time: 327.7355s\n",
      "\titers: 400, epoch: 6 | loss: 0.1415011\n",
      "\tspeed: 0.0422s/iter; left time: 322.5123s\n",
      "\titers: 500, epoch: 6 | loss: 0.1545645\n",
      "\tspeed: 0.0424s/iter; left time: 320.0412s\n",
      "Epoch: 6 cost time: 22.730329513549805\n",
      "Epoch: 6, Steps: 536 | Train Loss: 0.1491842 Vali Loss: 0.2011993 Test Loss: 0.2383054\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1370538\n",
      "\tspeed: 0.1209s/iter; left time: 895.3617s\n",
      "\titers: 200, epoch: 7 | loss: 0.1011808\n",
      "\tspeed: 0.0428s/iter; left time: 312.9578s\n",
      "\titers: 300, epoch: 7 | loss: 0.1284230\n",
      "\tspeed: 0.0420s/iter; left time: 302.4511s\n",
      "\titers: 400, epoch: 7 | loss: 0.1120037\n",
      "\tspeed: 0.0423s/iter; left time: 300.4294s\n",
      "\titers: 500, epoch: 7 | loss: 0.1239485\n",
      "\tspeed: 0.0422s/iter; left time: 295.4080s\n",
      "Epoch: 7 cost time: 22.750565767288208\n",
      "Epoch: 7, Steps: 536 | Train Loss: 0.1477272 Vali Loss: 0.2030152 Test Loss: 0.2428866\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1892117\n",
      "\tspeed: 0.1198s/iter; left time: 822.8418s\n",
      "\titers: 200, epoch: 8 | loss: 0.1792913\n",
      "\tspeed: 0.0415s/iter; left time: 280.5947s\n",
      "\titers: 300, epoch: 8 | loss: 0.1670346\n",
      "\tspeed: 0.0406s/iter; left time: 270.7183s\n",
      "\titers: 400, epoch: 8 | loss: 0.0985231\n",
      "\tspeed: 0.0410s/iter; left time: 269.5611s\n",
      "\titers: 500, epoch: 8 | loss: 0.1026049\n",
      "\tspeed: 0.0419s/iter; left time: 271.0211s\n",
      "Epoch: 8 cost time: 22.144520044326782\n",
      "Epoch: 8, Steps: 536 | Train Loss: 0.1463013 Vali Loss: 0.2014343 Test Loss: 0.2417926\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl192_ll64_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5162\n",
      "Test cost time: 2.7951s\n",
      "test shape: (161, 32, 6, 1) (161, 32, 6, 1)\n",
      "test shape: (5152, 6, 1) (5152, 6, 1)\n",
      "mse:0.2418673187494278, mae:0.3227739632129669\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl192_ll64_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1753.4117431640625\n",
      "MAE:  27.482223510742188\n",
      "RMSE: 41.87376022338867\n",
      "MAPE: 0.3474346399307251\n",
      "MSPE: 0.5472186803817749\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl192_ll64_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20841\n",
      "[DEBUG] Original dataset length: 20841\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 17156\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6340\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5162\n",
      "\titers: 100, epoch: 1 | loss: 0.3602634\n",
      "\tspeed: 0.0409s/iter; left time: 434.2301s\n",
      "\titers: 200, epoch: 1 | loss: 0.4079082\n",
      "\tspeed: 0.0424s/iter; left time: 446.5909s\n",
      "\titers: 300, epoch: 1 | loss: 0.2757994\n",
      "\tspeed: 0.0412s/iter; left time: 429.0905s\n",
      "\titers: 400, epoch: 1 | loss: 0.2994789\n",
      "\tspeed: 0.0417s/iter; left time: 430.1750s\n",
      "\titers: 500, epoch: 1 | loss: 0.2331674\n",
      "\tspeed: 0.0412s/iter; left time: 421.1839s\n",
      "Epoch: 1 cost time: 22.302838563919067\n",
      "Epoch: 1, Steps: 536 | Train Loss: 0.3434903 Vali Loss: 0.1968041 Test Loss: 0.2450552\n",
      "Validation loss decreased (inf --> 0.196804).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2516415\n",
      "\tspeed: 0.1204s/iter; left time: 1213.8239s\n",
      "\titers: 200, epoch: 2 | loss: 0.1764439\n",
      "\tspeed: 0.0417s/iter; left time: 415.9958s\n",
      "\titers: 300, epoch: 2 | loss: 0.1598260\n",
      "\tspeed: 0.0419s/iter; left time: 413.7822s\n",
      "\titers: 400, epoch: 2 | loss: 0.2370987\n",
      "\tspeed: 0.0413s/iter; left time: 404.2851s\n",
      "\titers: 500, epoch: 2 | loss: 0.2291274\n",
      "\tspeed: 0.0414s/iter; left time: 400.6890s\n",
      "Epoch: 2 cost time: 22.186419010162354\n",
      "Epoch: 2, Steps: 536 | Train Loss: 0.2078973 Vali Loss: 0.2063836 Test Loss: 0.2485739\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1285570\n",
      "\tspeed: 0.1189s/iter; left time: 1135.8034s\n",
      "\titers: 200, epoch: 3 | loss: 0.1568926\n",
      "\tspeed: 0.0409s/iter; left time: 386.4216s\n",
      "\titers: 300, epoch: 3 | loss: 0.1653126\n",
      "\tspeed: 0.0423s/iter; left time: 395.4958s\n",
      "\titers: 400, epoch: 3 | loss: 0.3041780\n",
      "\tspeed: 0.0417s/iter; left time: 386.0529s\n",
      "\titers: 500, epoch: 3 | loss: 0.2533020\n",
      "\tspeed: 0.0425s/iter; left time: 388.3870s\n",
      "Epoch: 3 cost time: 22.312142848968506\n",
      "Epoch: 3, Steps: 536 | Train Loss: 0.1771754 Vali Loss: 0.2232499 Test Loss: 0.2598150\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1336524\n",
      "\tspeed: 0.1189s/iter; left time: 1071.2029s\n",
      "\titers: 200, epoch: 4 | loss: 0.1761132\n",
      "\tspeed: 0.0410s/iter; left time: 365.4754s\n",
      "\titers: 300, epoch: 4 | loss: 0.2284408\n",
      "\tspeed: 0.0410s/iter; left time: 361.4708s\n",
      "\titers: 400, epoch: 4 | loss: 0.1429932\n",
      "\tspeed: 0.0401s/iter; left time: 349.5102s\n",
      "\titers: 500, epoch: 4 | loss: 0.1549746\n",
      "\tspeed: 0.0417s/iter; left time: 359.1720s\n",
      "Epoch: 4 cost time: 22.00374412536621\n",
      "Epoch: 4, Steps: 536 | Train Loss: 0.1618811 Vali Loss: 0.2000806 Test Loss: 0.2449073\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl192_ll64_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5162\n",
      "Test cost time: 2.7641s\n",
      "test shape: (161, 32, 6, 1) (161, 32, 6, 1)\n",
      "test shape: (5152, 6, 1) (5152, 6, 1)\n",
      "mse:0.24605530500411987, mae:0.3331238925457001\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl192_ll64_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1783.772216796875\n",
      "MAE:  28.363454818725586\n",
      "RMSE: 42.23472595214844\n",
      "MAPE: 0.38965746760368347\n",
      "MSPE: 0.764805793762207\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl192_ll64_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20841\n",
      "[DEBUG] Original dataset length: 20841\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 17156\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6340\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 5162\n",
      "\titers: 100, epoch: 1 | loss: 0.3916930\n",
      "\tspeed: 0.0414s/iter; left time: 439.3170s\n",
      "\titers: 200, epoch: 1 | loss: 0.2535899\n",
      "\tspeed: 0.0414s/iter; left time: 435.6607s\n",
      "\titers: 300, epoch: 1 | loss: 0.1731365\n",
      "\tspeed: 0.0421s/iter; left time: 439.0259s\n",
      "\titers: 400, epoch: 1 | loss: 0.2622303\n",
      "\tspeed: 0.0412s/iter; left time: 425.4160s\n",
      "\titers: 500, epoch: 1 | loss: 0.1759527\n",
      "\tspeed: 0.0415s/iter; left time: 424.6742s\n",
      "Epoch: 1 cost time: 22.271662950515747\n",
      "Epoch: 1, Steps: 536 | Train Loss: 0.3318885 Vali Loss: 0.2097476 Test Loss: 0.2458733\n",
      "Validation loss decreased (inf --> 0.209748).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1297257\n",
      "\tspeed: 0.1205s/iter; left time: 1215.4046s\n",
      "\titers: 200, epoch: 2 | loss: 0.2759612\n",
      "\tspeed: 0.0407s/iter; left time: 406.5641s\n",
      "\titers: 300, epoch: 2 | loss: 0.1374785\n",
      "\tspeed: 0.0422s/iter; left time: 416.6547s\n",
      "\titers: 400, epoch: 2 | loss: 0.2337931\n",
      "\tspeed: 0.0413s/iter; left time: 403.6516s\n",
      "\titers: 500, epoch: 2 | loss: 0.2431248\n",
      "\tspeed: 0.0414s/iter; left time: 401.2483s\n",
      "Epoch: 2 cost time: 22.185614824295044\n",
      "Epoch: 2, Steps: 536 | Train Loss: 0.2110230 Vali Loss: 0.2032028 Test Loss: 0.2434330\n",
      "Validation loss decreased (0.209748 --> 0.203203).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2483303\n",
      "\tspeed: 0.1197s/iter; left time: 1143.3414s\n",
      "\titers: 200, epoch: 3 | loss: 0.2567913\n",
      "\tspeed: 0.0414s/iter; left time: 391.2553s\n",
      "\titers: 300, epoch: 3 | loss: 0.1698295\n",
      "\tspeed: 0.0416s/iter; left time: 388.6847s\n",
      "\titers: 400, epoch: 3 | loss: 0.2235886\n",
      "\tspeed: 0.0421s/iter; left time: 389.4059s\n",
      "\titers: 500, epoch: 3 | loss: 0.1481510\n",
      "\tspeed: 0.0408s/iter; left time: 373.3042s\n",
      "Epoch: 3 cost time: 22.190978527069092\n",
      "Epoch: 3, Steps: 536 | Train Loss: 0.1779870 Vali Loss: 0.1949354 Test Loss: 0.2357183\n",
      "Validation loss decreased (0.203203 --> 0.194935).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1846670\n",
      "\tspeed: 0.1177s/iter; left time: 1061.1551s\n",
      "\titers: 200, epoch: 4 | loss: 0.1684082\n",
      "\tspeed: 0.0407s/iter; left time: 362.9842s\n",
      "\titers: 300, epoch: 4 | loss: 0.1127410\n",
      "\tspeed: 0.0413s/iter; left time: 363.6486s\n",
      "\titers: 400, epoch: 4 | loss: 0.1718241\n",
      "\tspeed: 0.0417s/iter; left time: 363.2714s\n",
      "\titers: 500, epoch: 4 | loss: 0.1888353\n",
      "\tspeed: 0.0405s/iter; left time: 348.4237s\n",
      "Epoch: 4 cost time: 21.97409749031067\n",
      "Epoch: 4, Steps: 536 | Train Loss: 0.1631357 Vali Loss: 0.1907510 Test Loss: 0.2411212\n",
      "Validation loss decreased (0.194935 --> 0.190751).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1780719\n",
      "\tspeed: 0.1187s/iter; left time: 1006.1022s\n",
      "\titers: 200, epoch: 5 | loss: 0.2219252\n",
      "\tspeed: 0.0413s/iter; left time: 345.6708s\n",
      "\titers: 300, epoch: 5 | loss: 0.1331896\n",
      "\tspeed: 0.0413s/iter; left time: 341.8844s\n",
      "\titers: 400, epoch: 5 | loss: 0.2160976\n",
      "\tspeed: 0.0421s/iter; left time: 344.2857s\n",
      "\titers: 500, epoch: 5 | loss: 0.1566826\n",
      "\tspeed: 0.0411s/iter; left time: 331.9649s\n",
      "Epoch: 5 cost time: 22.16737699508667\n",
      "Epoch: 5, Steps: 536 | Train Loss: 0.1551295 Vali Loss: 0.1952726 Test Loss: 0.2382521\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1574005\n",
      "\tspeed: 0.1176s/iter; left time: 933.6995s\n",
      "\titers: 400, epoch: 13 | loss: 0.1435398\n",
      "\tspeed: 0.0461s/iter; left time: 174.9424s\n",
      "\titers: 500, epoch: 13 | loss: 0.1092160\n",
      "\tspeed: 0.0457s/iter; left time: 168.9034s\n",
      "Epoch: 13 cost time: 24.005157709121704\n",
      "Epoch: 13, Steps: 524 | Train Loss: 0.1454930 Vali Loss: 0.1864090 Test Loss: 0.2400995\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.44140625e-08\n",
      "\titers: 100, epoch: 14 | loss: 0.1624893\n",
      "\tspeed: 0.1252s/iter; left time: 446.6613s\n",
      "\titers: 200, epoch: 14 | loss: 0.1580870\n",
      "\tspeed: 0.0467s/iter; left time: 162.1220s\n",
      "\titers: 300, epoch: 14 | loss: 0.1060156\n",
      "\tspeed: 0.0467s/iter; left time: 157.4783s\n",
      "\titers: 400, epoch: 14 | loss: 0.1276703\n",
      "\tspeed: 0.0470s/iter; left time: 153.6023s\n",
      "\titers: 500, epoch: 14 | loss: 0.1430038\n",
      "\tspeed: 0.0460s/iter; left time: 145.8605s\n",
      "Epoch: 14 cost time: 24.37773895263672\n",
      "Epoch: 14, Steps: 524 | Train Loss: 0.1450674 Vali Loss: 0.1862793 Test Loss: 0.2395775\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl216_ll72_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4994\n",
      "Test cost time: 2.9258s\n",
      "test shape: (156, 32, 6, 1) (156, 32, 6, 1)\n",
      "test shape: (4992, 6, 1) (4992, 6, 1)\n",
      "mse:0.23891176283359528, mae:0.32078123092651367\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl216_ll72_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1731.9857177734375\n",
      "MAE:  27.312557220458984\n",
      "RMSE: 41.61713409423828\n",
      "MAPE: 0.3382681608200073\n",
      "MSPE: 0.47543707489967346\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl216_ll72_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20817\n",
      "[DEBUG] Original dataset length: 20817\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 16796\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6268\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4994\n",
      "\titers: 100, epoch: 1 | loss: 0.2747052\n",
      "\tspeed: 0.0451s/iter; left time: 467.7767s\n",
      "\titers: 200, epoch: 1 | loss: 0.3349755\n",
      "\tspeed: 0.0467s/iter; left time: 480.3505s\n",
      "\titers: 300, epoch: 1 | loss: 0.2197434\n",
      "\tspeed: 0.0456s/iter; left time: 464.0542s\n",
      "\titers: 400, epoch: 1 | loss: 0.3177694\n",
      "\tspeed: 0.0465s/iter; left time: 469.1659s\n",
      "\titers: 500, epoch: 1 | loss: 0.2091140\n",
      "\tspeed: 0.0467s/iter; left time: 465.6220s\n",
      "Epoch: 1 cost time: 24.241299867630005\n",
      "Epoch: 1, Steps: 524 | Train Loss: 0.3259225 Vali Loss: 0.2355297 Test Loss: 0.2861871\n",
      "Validation loss decreased (inf --> 0.235530).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3283016\n",
      "\tspeed: 0.1275s/iter; left time: 1256.9366s\n",
      "\titers: 200, epoch: 2 | loss: 0.1623106\n",
      "\tspeed: 0.0470s/iter; left time: 458.4055s\n",
      "\titers: 300, epoch: 2 | loss: 0.1222683\n",
      "\tspeed: 0.0444s/iter; left time: 428.3474s\n",
      "\titers: 400, epoch: 2 | loss: 0.2025570\n",
      "\tspeed: 0.0454s/iter; left time: 434.2340s\n",
      "\titers: 500, epoch: 2 | loss: 0.1797536\n",
      "\tspeed: 0.0462s/iter; left time: 436.6453s\n",
      "Epoch: 2 cost time: 24.158457040786743\n",
      "Epoch: 2, Steps: 524 | Train Loss: 0.2112919 Vali Loss: 0.2093736 Test Loss: 0.2484909\n",
      "Validation loss decreased (0.235530 --> 0.209374).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1587117\n",
      "\tspeed: 0.1251s/iter; left time: 1167.9664s\n",
      "\titers: 200, epoch: 3 | loss: 0.2220347\n",
      "\tspeed: 0.0469s/iter; left time: 432.8182s\n",
      "\titers: 300, epoch: 3 | loss: 0.2255495\n",
      "\tspeed: 0.0466s/iter; left time: 425.3672s\n",
      "\titers: 400, epoch: 3 | loss: 0.2058879\n",
      "\tspeed: 0.0464s/iter; left time: 419.3301s\n",
      "\titers: 500, epoch: 3 | loss: 0.1438868\n",
      "\tspeed: 0.0465s/iter; left time: 415.5396s\n",
      "Epoch: 3 cost time: 24.2838134765625\n",
      "Epoch: 3, Steps: 524 | Train Loss: 0.1778213 Vali Loss: 0.1970655 Test Loss: 0.2359263\n",
      "Validation loss decreased (0.209374 --> 0.197065).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1856329\n",
      "\tspeed: 0.1263s/iter; left time: 1112.8385s\n",
      "\titers: 200, epoch: 4 | loss: 0.1407799\n",
      "\tspeed: 0.0464s/iter; left time: 404.1392s\n",
      "\titers: 300, epoch: 4 | loss: 0.1759409\n",
      "\tspeed: 0.0457s/iter; left time: 393.4164s\n",
      "\titers: 400, epoch: 4 | loss: 0.0888633\n",
      "\tspeed: 0.0460s/iter; left time: 391.5529s\n",
      "\titers: 500, epoch: 4 | loss: 0.0955600\n",
      "\tspeed: 0.0462s/iter; left time: 388.6961s\n",
      "Epoch: 4 cost time: 24.152397871017456\n",
      "Epoch: 4, Steps: 524 | Train Loss: 0.1625887 Vali Loss: 0.1933565 Test Loss: 0.2394992\n",
      "Validation loss decreased (0.197065 --> 0.193356).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1292100\n",
      "\tspeed: 0.1224s/iter; left time: 1014.2710s\n",
      "\titers: 200, epoch: 5 | loss: 0.1001830\n",
      "\tspeed: 0.0477s/iter; left time: 390.4772s\n",
      "\titers: 300, epoch: 5 | loss: 0.1125866\n",
      "\tspeed: 0.0460s/iter; left time: 371.5299s\n",
      "\titers: 400, epoch: 5 | loss: 0.1621833\n",
      "\tspeed: 0.0453s/iter; left time: 361.4843s\n",
      "\titers: 500, epoch: 5 | loss: 0.1107228\n",
      "\tspeed: 0.0462s/iter; left time: 364.5266s\n",
      "Epoch: 5 cost time: 24.26891040802002\n",
      "Epoch: 5, Steps: 524 | Train Loss: 0.1542069 Vali Loss: 0.1960970 Test Loss: 0.2409353\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1518439\n",
      "\tspeed: 0.1241s/iter; left time: 963.3048s\n",
      "\titers: 200, epoch: 6 | loss: 0.1005092\n",
      "\tspeed: 0.0471s/iter; left time: 360.8973s\n",
      "\titers: 300, epoch: 6 | loss: 0.1664247\n",
      "\tspeed: 0.0459s/iter; left time: 346.6939s\n",
      "\titers: 400, epoch: 6 | loss: 0.1619801\n",
      "\tspeed: 0.0447s/iter; left time: 333.4096s\n",
      "\titers: 500, epoch: 6 | loss: 0.1622322\n",
      "\tspeed: 0.0466s/iter; left time: 343.1234s\n",
      "Epoch: 6 cost time: 24.187421083450317\n",
      "Epoch: 6, Steps: 524 | Train Loss: 0.1488976 Vali Loss: 0.1927568 Test Loss: 0.2363107\n",
      "Validation loss decreased (0.193356 --> 0.192757).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0879834\n",
      "\tspeed: 0.1264s/iter; left time: 915.1186s\n",
      "\titers: 200, epoch: 7 | loss: 0.1942975\n",
      "\tspeed: 0.0470s/iter; left time: 335.4615s\n",
      "\titers: 300, epoch: 7 | loss: 0.1578027\n",
      "\tspeed: 0.0463s/iter; left time: 325.7531s\n",
      "\titers: 400, epoch: 7 | loss: 0.1002094\n",
      "\tspeed: 0.0459s/iter; left time: 318.3021s\n",
      "\titers: 500, epoch: 7 | loss: 0.1344928\n",
      "\tspeed: 0.0467s/iter; left time: 319.1254s\n",
      "Epoch: 7 cost time: 24.420830726623535\n",
      "Epoch: 7, Steps: 524 | Train Loss: 0.1460820 Vali Loss: 0.1927443 Test Loss: 0.2369736\n",
      "Validation loss decreased (0.192757 --> 0.192744).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0985765\n",
      "\tspeed: 0.1255s/iter; left time: 842.4654s\n",
      "\titers: 200, epoch: 8 | loss: 0.1145087\n",
      "\tspeed: 0.0464s/iter; left time: 306.6596s\n",
      "\titers: 300, epoch: 8 | loss: 0.1192126\n",
      "\tspeed: 0.0461s/iter; left time: 300.1762s\n",
      "\titers: 400, epoch: 8 | loss: 0.1832406\n",
      "\tspeed: 0.0448s/iter; left time: 287.0372s\n",
      "\titers: 500, epoch: 8 | loss: 0.1427341\n",
      "\tspeed: 0.0461s/iter; left time: 291.0495s\n",
      "Epoch: 8 cost time: 24.080332040786743\n",
      "Epoch: 8, Steps: 524 | Train Loss: 0.1444454 Vali Loss: 0.1953933 Test Loss: 0.2404939\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1755757\n",
      "\tspeed: 0.1255s/iter; left time: 776.7102s\n",
      "\titers: 200, epoch: 9 | loss: 0.1986037\n",
      "\tspeed: 0.0462s/iter; left time: 281.1293s\n",
      "\titers: 300, epoch: 9 | loss: 0.1152578\n",
      "\tspeed: 0.0457s/iter; left time: 273.9642s\n",
      "\titers: 400, epoch: 9 | loss: 0.1132202\n",
      "\tspeed: 0.0474s/iter; left time: 278.8878s\n",
      "\titers: 500, epoch: 9 | loss: 0.1196955\n",
      "\tspeed: 0.0464s/iter; left time: 268.6923s\n",
      "Epoch: 9 cost time: 24.391448259353638\n",
      "Epoch: 9, Steps: 524 | Train Loss: 0.1434817 Vali Loss: 0.1918875 Test Loss: 0.2398105\n",
      "Validation loss decreased (0.192744 --> 0.191887).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.1649743\n",
      "\tspeed: 0.1366s/iter; left time: 774.0116s\n",
      "\titers: 200, epoch: 10 | loss: 0.1290877\n",
      "\tspeed: 0.0477s/iter; left time: 265.2917s\n",
      "\titers: 300, epoch: 10 | loss: 0.1546473\n",
      "\tspeed: 0.0438s/iter; left time: 239.1157s\n",
      "\titers: 400, epoch: 10 | loss: 0.1354742\n",
      "\tspeed: 0.0442s/iter; left time: 237.2164s\n",
      "\titers: 500, epoch: 10 | loss: 0.1365549\n",
      "\tspeed: 0.0454s/iter; left time: 238.7912s\n",
      "Epoch: 10 cost time: 24.777058601379395\n",
      "Epoch: 10, Steps: 524 | Train Loss: 0.1437491 Vali Loss: 0.1946805 Test Loss: 0.2409133\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.1171945\n",
      "\tspeed: 0.1247s/iter; left time: 640.9349s\n",
      "\titers: 200, epoch: 11 | loss: 0.2322513\n",
      "\tspeed: 0.0452s/iter; left time: 227.6675s\n",
      "\titers: 300, epoch: 11 | loss: 0.1149794\n",
      "\tspeed: 0.0437s/iter; left time: 215.8461s\n",
      "\titers: 400, epoch: 11 | loss: 0.1129686\n",
      "\tspeed: 0.0444s/iter; left time: 214.8124s\n",
      "\titers: 500, epoch: 11 | loss: 0.1776179\n",
      "\tspeed: 0.0454s/iter; left time: 215.1447s\n",
      "Epoch: 11 cost time: 23.521767377853394\n",
      "Epoch: 11, Steps: 524 | Train Loss: 0.1431386 Vali Loss: 0.1946763 Test Loss: 0.2410379\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.1249017\n",
      "\tspeed: 0.1243s/iter; left time: 574.0169s\n",
      "\titers: 200, epoch: 12 | loss: 0.1112460\n",
      "\tspeed: 0.0454s/iter; left time: 204.9812s\n",
      "\titers: 300, epoch: 12 | loss: 0.1640597\n",
      "\tspeed: 0.0470s/iter; left time: 207.4264s\n",
      "\titers: 400, epoch: 12 | loss: 0.2615157\n",
      "\tspeed: 0.0462s/iter; left time: 199.5713s\n",
      "\titers: 500, epoch: 12 | loss: 0.2777918\n",
      "\tspeed: 0.0458s/iter; left time: 193.1425s\n",
      "Epoch: 12 cost time: 24.144920349121094\n",
      "Epoch: 12, Steps: 524 | Train Loss: 0.1434972 Vali Loss: 0.1935855 Test Loss: 0.2403948\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl216_ll72_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4994\n",
      "Test cost time: 2.9718s\n",
      "test shape: (156, 32, 6, 1) (156, 32, 6, 1)\n",
      "test shape: (4992, 6, 1) (4992, 6, 1)\n",
      "mse:0.23971807956695557, mae:0.31775781512260437\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl216_ll72_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1737.8309326171875\n",
      "MAE:  27.055130004882812\n",
      "RMSE: 41.68729782104492\n",
      "MAPE: 0.3436099886894226\n",
      "MSPE: 0.5435185432434082\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl216_ll72_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20817\n",
      "[DEBUG] Original dataset length: 20817\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 16796\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6268\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4994\n",
      "\titers: 100, epoch: 1 | loss: 0.4196108\n",
      "\tspeed: 0.0457s/iter; left time: 473.9968s\n",
      "\titers: 200, epoch: 1 | loss: 0.2162272\n",
      "\tspeed: 0.0443s/iter; left time: 455.3544s\n",
      "\titers: 300, epoch: 1 | loss: 0.1776830\n",
      "\tspeed: 0.0458s/iter; left time: 466.1604s\n",
      "\titers: 400, epoch: 1 | loss: 0.2487107\n",
      "\tspeed: 0.0456s/iter; left time: 459.9709s\n",
      "\titers: 500, epoch: 1 | loss: 0.2966836\n",
      "\tspeed: 0.0466s/iter; left time: 464.8098s\n",
      "Epoch: 1 cost time: 23.955496788024902\n",
      "Epoch: 1, Steps: 524 | Train Loss: 0.3402229 Vali Loss: 0.2582841 Test Loss: 0.2944215\n",
      "Validation loss decreased (inf --> 0.258284).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2233727\n",
      "\tspeed: 0.1268s/iter; left time: 1250.0210s\n",
      "\titers: 200, epoch: 2 | loss: 0.3027293\n",
      "\tspeed: 0.0469s/iter; left time: 457.2131s\n",
      "\titers: 300, epoch: 2 | loss: 0.1143617\n",
      "\tspeed: 0.0459s/iter; left time: 442.9189s\n",
      "\titers: 400, epoch: 2 | loss: 0.1698029\n",
      "\tspeed: 0.0455s/iter; left time: 434.7869s\n",
      "\titers: 500, epoch: 2 | loss: 0.2822793\n",
      "\tspeed: 0.0471s/iter; left time: 445.4949s\n",
      "Epoch: 2 cost time: 24.25921654701233\n",
      "Epoch: 2, Steps: 524 | Train Loss: 0.2104037 Vali Loss: 0.1972960 Test Loss: 0.2343789\n",
      "Validation loss decreased (0.258284 --> 0.197296).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2521207\n",
      "\tspeed: 0.1245s/iter; left time: 1162.0974s\n",
      "\titers: 200, epoch: 3 | loss: 0.3298520\n",
      "\tspeed: 0.0467s/iter; left time: 431.2793s\n",
      "\titers: 300, epoch: 3 | loss: 0.2593925\n",
      "\tspeed: 0.0458s/iter; left time: 418.4308s\n",
      "\titers: 400, epoch: 3 | loss: 0.1424487\n",
      "\tspeed: 0.0435s/iter; left time: 392.8851s\n",
      "\titers: 500, epoch: 3 | loss: 0.1946165\n",
      "\tspeed: 0.0462s/iter; left time: 412.5645s\n",
      "Epoch: 3 cost time: 23.866356134414673\n",
      "Epoch: 3, Steps: 524 | Train Loss: 0.1787335 Vali Loss: 0.1987233 Test Loss: 0.2513072\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1141935\n",
      "\tspeed: 0.1249s/iter; left time: 1100.5528s\n",
      "\titers: 200, epoch: 4 | loss: 0.1025823\n",
      "\tspeed: 0.0461s/iter; left time: 401.8962s\n",
      "\titers: 300, epoch: 4 | loss: 0.1175845\n",
      "\tspeed: 0.0464s/iter; left time: 399.4937s\n",
      "\titers: 400, epoch: 4 | loss: 0.1112897\n",
      "\tspeed: 0.0461s/iter; left time: 392.4885s\n",
      "\titers: 500, epoch: 4 | loss: 0.1498061\n",
      "\tspeed: 0.0471s/iter; left time: 395.6800s\n",
      "Epoch: 4 cost time: 24.325434923171997\n",
      "Epoch: 4, Steps: 524 | Train Loss: 0.1628558 Vali Loss: 0.1988974 Test Loss: 0.2411743\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1253659\n",
      "\tspeed: 0.1265s/iter; left time: 1047.6545s\n",
      "\titers: 200, epoch: 5 | loss: 0.1430555\n",
      "\tspeed: 0.0461s/iter; left time: 377.3769s\n",
      "\titers: 300, epoch: 5 | loss: 0.1876106\n",
      "\tspeed: 0.0464s/iter; left time: 375.1562s\n",
      "\titers: 400, epoch: 5 | loss: 0.1889984\n",
      "\tspeed: 0.0434s/iter; left time: 346.2618s\n",
      "\titers: 500, epoch: 5 | loss: 0.1154836\n",
      "\tspeed: 0.0444s/iter; left time: 349.8134s\n",
      "Epoch: 5 cost time: 23.86184287071228\n",
      "Epoch: 5, Steps: 524 | Train Loss: 0.1537846 Vali Loss: 0.1984584 Test Loss: 0.2452635\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl216_ll72_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4994\n",
      "Test cost time: 3.0145s\n",
      "test shape: (156, 32, 6, 1) (156, 32, 6, 1)\n",
      "test shape: (4992, 6, 1) (4992, 6, 1)\n",
      "mse:0.23359942436218262, mae:0.3246367573738098\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl216_ll72_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1693.47412109375\n",
      "MAE:  27.64082908630371\n",
      "RMSE: 41.1518440246582\n",
      "MAPE: 0.37603557109832764\n",
      "MSPE: 0.661572277545929\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl216_ll72_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20817\n",
      "[DEBUG] Original dataset length: 20817\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 16796\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6268\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4994\n",
      "\titers: 100, epoch: 1 | loss: 0.3977621\n",
      "\tspeed: 0.0464s/iter; left time: 481.4667s\n",
      "\titers: 200, epoch: 1 | loss: 0.4122553\n",
      "\tspeed: 0.0467s/iter; left time: 480.1659s\n",
      "\titers: 300, epoch: 1 | loss: 0.2166971\n",
      "\tspeed: 0.0469s/iter; left time: 477.7719s\n",
      "\titers: 400, epoch: 1 | loss: 0.2954684\n",
      "\tspeed: 0.0473s/iter; left time: 476.9192s\n",
      "\titers: 500, epoch: 1 | loss: 0.1983076\n",
      "\tspeed: 0.0467s/iter; left time: 465.8612s\n",
      "Epoch: 1 cost time: 24.544974088668823\n",
      "Epoch: 1, Steps: 524 | Train Loss: 0.3574463 Vali Loss: 0.2363232 Test Loss: 0.2829204\n",
      "Validation loss decreased (inf --> 0.236323).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2435305\n",
      "\tspeed: 0.1289s/iter; left time: 1270.3657s\n",
      "\titers: 200, epoch: 2 | loss: 0.1810600\n",
      "\tspeed: 0.0468s/iter; left time: 456.9349s\n",
      "\titers: 300, epoch: 2 | loss: 0.1996608\n",
      "\tspeed: 0.0470s/iter; left time: 453.8928s\n",
      "\titers: 400, epoch: 2 | loss: 0.2028337\n",
      "\tspeed: 0.0479s/iter; left time: 457.8712s\n",
      "\titers: 500, epoch: 2 | loss: 0.1863377\n",
      "\tspeed: 0.0468s/iter; left time: 442.7442s\n",
      "Epoch: 2 cost time: 24.71739888191223\n",
      "Epoch: 2, Steps: 524 | Train Loss: 0.2059694 Vali Loss: 0.2016830 Test Loss: 0.2426131\n",
      "Validation loss decreased (0.236323 --> 0.201683).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2744587\n",
      "\tspeed: 0.1285s/iter; left time: 1199.0597s\n",
      "\titers: 200, epoch: 3 | loss: 0.1344783\n",
      "\tspeed: 0.0472s/iter; left time: 436.1886s\n",
      "\titers: 300, epoch: 3 | loss: 0.1775934\n",
      "\tspeed: 0.0474s/iter; left time: 432.8610s\n",
      "\titers: 400, epoch: 3 | loss: 0.2568280\n",
      "\tspeed: 0.0455s/iter; left time: 410.9307s\n",
      "\titers: 500, epoch: 3 | loss: 0.1189349\n",
      "\tspeed: 0.0455s/iter; left time: 406.0242s\n",
      "Epoch: 3 cost time: 24.347440242767334\n",
      "Epoch: 3, Steps: 524 | Train Loss: 0.1790623 Vali Loss: 0.1985011 Test Loss: 0.2419911\n",
      "Validation loss decreased (0.201683 --> 0.198501).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1764148\n",
      "\tspeed: 0.1247s/iter; left time: 1098.9216s\n",
      "\titers: 200, epoch: 4 | loss: 0.1195315\n",
      "\tspeed: 0.0451s/iter; left time: 393.0045s\n",
      "\titers: 300, epoch: 4 | loss: 0.1777378\n",
      "\tspeed: 0.0469s/iter; left time: 404.1902s\n",
      "\titers: 400, epoch: 4 | loss: 0.1396838\n",
      "\tspeed: 0.0460s/iter; left time: 391.5474s\n",
      "\titers: 500, epoch: 4 | loss: 0.1304858\n",
      "\tspeed: 0.0462s/iter; left time: 388.5376s\n",
      "Epoch: 4 cost time: 24.06542205810547\n",
      "Epoch: 4, Steps: 524 | Train Loss: 0.1642806 Vali Loss: 0.1993080 Test Loss: 0.2424601\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1621595\n",
      "\tspeed: 0.1237s/iter; left time: 1024.6343s\n",
      "\titers: 200, epoch: 5 | loss: 0.1411157\n",
      "\tspeed: 0.0455s/iter; left time: 372.6257s\n",
      "\titers: 300, epoch: 5 | loss: 0.1458258\n",
      "\tspeed: 0.0465s/iter; left time: 376.1997s\n",
      "\titers: 400, epoch: 5 | loss: 0.1016177\n",
      "\tspeed: 0.0454s/iter; left time: 362.8947s\n",
      "\titers: 500, epoch: 5 | loss: 0.1981757\n",
      "\tspeed: 0.0453s/iter; left time: 357.1913s\n",
      "Epoch: 5 cost time: 23.888747692108154\n",
      "Epoch: 5, Steps: 524 | Train Loss: 0.1550768 Vali Loss: 0.2012506 Test Loss: 0.2439010\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1434813\n",
      "\tspeed: 0.1247s/iter; left time: 967.7929s\n",
      "\titers: 200, epoch: 6 | loss: 0.1046159\n",
      "\tspeed: 0.0455s/iter; left time: 348.3040s\n",
      "\titers: 300, epoch: 6 | loss: 0.2555893\n",
      "\tspeed: 0.0466s/iter; left time: 352.4129s\n",
      "\titers: 400, epoch: 6 | loss: 0.2382095\n",
      "\tspeed: 0.0484s/iter; left time: 360.8221s\n",
      "\titers: 500, epoch: 6 | loss: 0.2202069\n",
      "\tspeed: 0.0506s/iter; left time: 372.7971s\n",
      "Epoch: 6 cost time: 24.967581272125244\n",
      "Epoch: 6, Steps: 524 | Train Loss: 0.1494223 Vali Loss: 0.1991116 Test Loss: 0.2451922\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl216_ll72_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4994\n",
      "Test cost time: 3.0021s\n",
      "test shape: (156, 32, 6, 1) (156, 32, 6, 1)\n",
      "test shape: (4992, 6, 1) (4992, 6, 1)\n",
      "mse:0.24251431226730347, mae:0.31930145621299744\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl216_ll72_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1758.1021728515625\n",
      "MAE:  27.186561584472656\n",
      "RMSE: 41.92972946166992\n",
      "MAPE: 0.324393630027771\n",
      "MSPE: 0.4510100781917572\n",
      ">>>>>>>Running time saved<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Running seq_len=240, label_len=80, pred_len=6\n",
      "Args in experiment:\n",
      "Namespace(model='informer', data='traffic_full', root_path='../', data_path='traffic_full.csv', features='S', target='flow', freq='h', checkpoints='./checkpoints/', seq_len=240, label_len=80, pred_len=6, enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=2, d_layers=1, s_layers=[3, 2, 1], d_ff=2048, factor=5, padding=0, distil=True, dropout=0.05, attn='prob', embed='timeF', activation='gelu', output_attention=False, do_predict=False, mix=True, cols=None, num_workers=0, itr=10, train_epochs=20, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, inverse=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', detail_freq='h')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl240_ll80_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20793\n",
      "[DEBUG] Original dataset length: 20793\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 16436\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6196\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "\titers: 100, epoch: 1 | loss: 0.3495565\n",
      "\tspeed: 0.0658s/iter; left time: 668.1888s\n",
      "\titers: 200, epoch: 1 | loss: 0.2635178\n",
      "\tspeed: 0.0493s/iter; left time: 495.9384s\n",
      "\titers: 300, epoch: 1 | loss: 0.1827070\n",
      "\tspeed: 0.0491s/iter; left time: 488.9192s\n",
      "\titers: 400, epoch: 1 | loss: 0.2280732\n",
      "\tspeed: 0.0500s/iter; left time: 493.0606s\n",
      "\titers: 500, epoch: 1 | loss: 0.1789504\n",
      "\tspeed: 0.0490s/iter; left time: 477.8840s\n",
      "Epoch: 1 cost time: 25.95967435836792\n",
      "Epoch: 1, Steps: 513 | Train Loss: 0.3518559 Vali Loss: 0.2351398 Test Loss: 0.2906661\n",
      "Validation loss decreased (inf --> 0.235140).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1874490\n",
      "\tspeed: 0.1285s/iter; left time: 1239.7266s\n",
      "\titers: 200, epoch: 2 | loss: 0.4504599\n",
      "\tspeed: 0.0497s/iter; left time: 474.0955s\n",
      "\titers: 300, epoch: 2 | loss: 0.1686421\n",
      "\tspeed: 0.0503s/iter; left time: 475.0148s\n",
      "\titers: 400, epoch: 2 | loss: 0.1642184\n",
      "\tspeed: 0.0501s/iter; left time: 468.7137s\n",
      "\titers: 500, epoch: 2 | loss: 0.2922540\n",
      "\tspeed: 0.0504s/iter; left time: 465.8971s\n",
      "Epoch: 2 cost time: 25.615692138671875\n",
      "Epoch: 2, Steps: 513 | Train Loss: 0.2091302 Vali Loss: 0.2080771 Test Loss: 0.2596406\n",
      "Validation loss decreased (0.235140 --> 0.208077).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1837269\n",
      "\tspeed: 0.1303s/iter; left time: 1190.2524s\n",
      "\titers: 200, epoch: 3 | loss: 0.1899348\n",
      "\tspeed: 0.0503s/iter; left time: 454.1044s\n",
      "\titers: 300, epoch: 3 | loss: 0.3195333\n",
      "\tspeed: 0.0496s/iter; left time: 443.4799s\n",
      "\titers: 400, epoch: 3 | loss: 0.1489912\n",
      "\tspeed: 0.0498s/iter; left time: 440.1365s\n",
      "\titers: 500, epoch: 3 | loss: 0.1732485\n",
      "\tspeed: 0.0499s/iter; left time: 436.0672s\n",
      "Epoch: 3 cost time: 25.595799684524536\n",
      "Epoch: 3, Steps: 513 | Train Loss: 0.1769401 Vali Loss: 0.2108187 Test Loss: 0.2627160\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1545913\n",
      "\tspeed: 0.1279s/iter; left time: 1102.7827s\n",
      "\titers: 200, epoch: 4 | loss: 0.1126890\n",
      "\tspeed: 0.0498s/iter; left time: 424.7828s\n",
      "\titers: 300, epoch: 4 | loss: 0.1273818\n",
      "\tspeed: 0.0491s/iter; left time: 413.3154s\n",
      "\titers: 400, epoch: 4 | loss: 0.1758702\n",
      "\tspeed: 0.0491s/iter; left time: 408.7241s\n",
      "\titers: 500, epoch: 4 | loss: 0.1110097\n",
      "\tspeed: 0.0505s/iter; left time: 414.9576s\n",
      "Epoch: 4 cost time: 25.452138900756836\n",
      "Epoch: 4, Steps: 513 | Train Loss: 0.1620504 Vali Loss: 0.2081555 Test Loss: 0.2571371\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1771969\n",
      "\tspeed: 0.1274s/iter; left time: 1033.1316s\n",
      "\titers: 200, epoch: 5 | loss: 0.1431251\n",
      "\tspeed: 0.0490s/iter; left time: 392.5228s\n",
      "\titers: 300, epoch: 5 | loss: 0.1521146\n",
      "\tspeed: 0.0487s/iter; left time: 385.4792s\n",
      "\titers: 400, epoch: 5 | loss: 0.1573867\n",
      "\tspeed: 0.0495s/iter; left time: 386.2770s\n",
      "\titers: 500, epoch: 5 | loss: 0.1469671\n",
      "\tspeed: 0.0492s/iter; left time: 379.4631s\n",
      "Epoch: 5 cost time: 25.304259300231934\n",
      "Epoch: 5, Steps: 513 | Train Loss: 0.1529827 Vali Loss: 0.1996888 Test Loss: 0.2498856\n",
      "Validation loss decreased (0.208077 --> 0.199689).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1202169\n",
      "\tspeed: 0.1279s/iter; left time: 971.8484s\n",
      "\titers: 200, epoch: 6 | loss: 0.1225773\n",
      "\tspeed: 0.0491s/iter; left time: 368.4277s\n",
      "\titers: 300, epoch: 6 | loss: 0.1580345\n",
      "\tspeed: 0.0496s/iter; left time: 367.0560s\n",
      "\titers: 400, epoch: 6 | loss: 0.1269694\n",
      "\tspeed: 0.0491s/iter; left time: 357.8745s\n",
      "\titers: 500, epoch: 6 | loss: 0.1012088\n",
      "\tspeed: 0.0495s/iter; left time: 356.5332s\n",
      "Epoch: 6 cost time: 25.340292930603027\n",
      "Epoch: 6, Steps: 513 | Train Loss: 0.1482903 Vali Loss: 0.2005547 Test Loss: 0.2501886\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1005871\n",
      "\tspeed: 0.1271s/iter; left time: 900.4263s\n",
      "\titers: 200, epoch: 7 | loss: 0.1285946\n",
      "\tspeed: 0.0491s/iter; left time: 342.7684s\n",
      "\titers: 300, epoch: 7 | loss: 0.1043869\n",
      "\tspeed: 0.0498s/iter; left time: 342.4551s\n",
      "\titers: 400, epoch: 7 | loss: 0.1513806\n",
      "\tspeed: 0.0489s/iter; left time: 331.5227s\n",
      "\titers: 500, epoch: 7 | loss: 0.1352964\n",
      "\tspeed: 0.0488s/iter; left time: 326.3203s\n",
      "Epoch: 7 cost time: 25.197631359100342\n",
      "Epoch: 7, Steps: 513 | Train Loss: 0.1453067 Vali Loss: 0.2027716 Test Loss: 0.2537819\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1907870\n",
      "\tspeed: 0.1264s/iter; left time: 830.6830s\n",
      "\titers: 200, epoch: 8 | loss: 0.2075396\n",
      "\tspeed: 0.0493s/iter; left time: 319.2874s\n",
      "\titers: 300, epoch: 8 | loss: 0.1072313\n",
      "\tspeed: 0.0495s/iter; left time: 315.1274s\n",
      "\titers: 400, epoch: 8 | loss: 0.1407871\n",
      "\tspeed: 0.0490s/iter; left time: 307.3767s\n",
      "\titers: 500, epoch: 8 | loss: 0.1237208\n",
      "\tspeed: 0.0490s/iter; left time: 302.0912s\n",
      "Epoch: 8 cost time: 25.19786787033081\n",
      "Epoch: 8, Steps: 513 | Train Loss: 0.1437352 Vali Loss: 0.2014253 Test Loss: 0.2521208\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl240_ll80_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "Test cost time: 2.9513s\n",
      "test shape: (150, 32, 6, 1) (150, 32, 6, 1)\n",
      "test shape: (4800, 6, 1) (4800, 6, 1)\n",
      "mse:0.24987290799617767, mae:0.323122501373291\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl240_ll80_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1811.447998046875\n",
      "MAE:  27.511898040771484\n",
      "RMSE: 42.56110763549805\n",
      "MAPE: 0.352798193693161\n",
      "MSPE: 0.5761402249336243\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl240_ll80_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20793\n",
      "[DEBUG] Original dataset length: 20793\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 16436\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6196\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "\titers: 100, epoch: 1 | loss: 0.3942103\n",
      "\tspeed: 0.0477s/iter; left time: 484.9888s\n",
      "\titers: 200, epoch: 1 | loss: 0.2327006\n",
      "\tspeed: 0.0499s/iter; left time: 502.3649s\n",
      "\titers: 300, epoch: 1 | loss: 0.3047117\n",
      "\tspeed: 0.0486s/iter; left time: 484.0751s\n",
      "\titers: 400, epoch: 1 | loss: 0.2257893\n",
      "\tspeed: 0.0491s/iter; left time: 484.4104s\n",
      "\titers: 500, epoch: 1 | loss: 0.2072070\n",
      "\tspeed: 0.0500s/iter; left time: 488.2239s\n",
      "Epoch: 1 cost time: 25.20909595489502\n",
      "Epoch: 1, Steps: 513 | Train Loss: 0.3419330 Vali Loss: 0.2502788 Test Loss: 0.3317801\n",
      "Validation loss decreased (inf --> 0.250279).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1680503\n",
      "\tspeed: 0.1299s/iter; left time: 1253.3429s\n",
      "\titers: 200, epoch: 2 | loss: 0.1637540\n",
      "\tspeed: 0.0495s/iter; left time: 472.6428s\n",
      "\titers: 300, epoch: 2 | loss: 0.1216429\n",
      "\tspeed: 0.0493s/iter; left time: 465.6913s\n",
      "\titers: 400, epoch: 2 | loss: 0.1339197\n",
      "\tspeed: 0.0496s/iter; left time: 463.2115s\n",
      "\titers: 500, epoch: 2 | loss: 0.2394635\n",
      "\tspeed: 0.0494s/iter; left time: 457.0613s\n",
      "Epoch: 2 cost time: 25.452986478805542\n",
      "Epoch: 2, Steps: 513 | Train Loss: 0.2070106 Vali Loss: 0.2300371 Test Loss: 0.2811531\n",
      "Validation loss decreased (0.250279 --> 0.230037).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1892086\n",
      "\tspeed: 0.1286s/iter; left time: 1174.5832s\n",
      "\titers: 200, epoch: 3 | loss: 0.0839303\n",
      "\tspeed: 0.0489s/iter; left time: 441.7330s\n",
      "\titers: 300, epoch: 3 | loss: 0.1376334\n",
      "\tspeed: 0.0494s/iter; left time: 441.0471s\n",
      "\titers: 400, epoch: 3 | loss: 0.2564189\n",
      "\tspeed: 0.0499s/iter; left time: 440.7356s\n",
      "\titers: 500, epoch: 3 | loss: 0.1397604\n",
      "\tspeed: 0.0494s/iter; left time: 431.7452s\n",
      "Epoch: 3 cost time: 25.34610414505005\n",
      "Epoch: 3, Steps: 513 | Train Loss: 0.1776023 Vali Loss: 0.2064970 Test Loss: 0.2498270\n",
      "Validation loss decreased (0.230037 --> 0.206497).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1233308\n",
      "\tspeed: 0.1294s/iter; left time: 1116.0292s\n",
      "\titers: 200, epoch: 4 | loss: 0.2434266\n",
      "\tspeed: 0.0494s/iter; left time: 420.7506s\n",
      "\titers: 300, epoch: 4 | loss: 0.1518850\n",
      "\tspeed: 0.0498s/iter; left time: 419.7689s\n",
      "\titers: 400, epoch: 4 | loss: 0.1137767\n",
      "\tspeed: 0.0499s/iter; left time: 415.1523s\n",
      "\titers: 500, epoch: 4 | loss: 0.1453473\n",
      "\tspeed: 0.0491s/iter; left time: 403.8534s\n",
      "Epoch: 4 cost time: 25.44128131866455\n",
      "Epoch: 4, Steps: 513 | Train Loss: 0.1625213 Vali Loss: 0.2135353 Test Loss: 0.2591102\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1955275\n",
      "\tspeed: 0.1278s/iter; left time: 1036.7297s\n",
      "\titers: 200, epoch: 5 | loss: 0.1290400\n",
      "\tspeed: 0.0490s/iter; left time: 392.7245s\n",
      "\titers: 300, epoch: 5 | loss: 0.1817463\n",
      "\tspeed: 0.0495s/iter; left time: 391.2423s\n",
      "\titers: 400, epoch: 5 | loss: 0.1962752\n",
      "\tspeed: 0.0489s/iter; left time: 381.6425s\n",
      "\titers: 500, epoch: 5 | loss: 0.1603509\n",
      "\tspeed: 0.0493s/iter; left time: 380.2353s\n",
      "Epoch: 5 cost time: 25.2801034450531\n",
      "Epoch: 5, Steps: 513 | Train Loss: 0.1536821 Vali Loss: 0.2103216 Test Loss: 0.2579983\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1597057\n",
      "\tspeed: 0.1262s/iter; left time: 958.9696s\n",
      "\titers: 200, epoch: 6 | loss: 0.1355729\n",
      "\tspeed: 0.0500s/iter; left time: 375.0706s\n",
      "\titers: 300, epoch: 6 | loss: 0.2307126\n",
      "\tspeed: 0.0491s/iter; left time: 362.8429s\n",
      "\titers: 400, epoch: 6 | loss: 0.1316687\n",
      "\tspeed: 0.0486s/iter; left time: 354.2451s\n",
      "\titers: 500, epoch: 6 | loss: 0.1415170\n",
      "\tspeed: 0.0490s/iter; left time: 352.7339s\n",
      "Epoch: 6 cost time: 25.176912546157837\n",
      "Epoch: 6, Steps: 513 | Train Loss: 0.1494165 Vali Loss: 0.2084350 Test Loss: 0.2557101\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl240_ll80_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "Test cost time: 3.0777s\n",
      "test shape: (150, 32, 6, 1) (150, 32, 6, 1)\n",
      "test shape: (4800, 6, 1) (4800, 6, 1)\n",
      "mse:0.24983744323253632, mae:0.3180643320083618\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl240_ll80_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1811.191162109375\n",
      "MAE:  27.081228256225586\n",
      "RMSE: 42.55809020996094\n",
      "MAPE: 0.3570917844772339\n",
      "MSPE: 0.6164078712463379\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl240_ll80_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20793\n",
      "[DEBUG] Original dataset length: 20793\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 16436\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6196\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "\titers: 100, epoch: 1 | loss: 0.3583415\n",
      "\tspeed: 0.0493s/iter; left time: 500.8228s\n",
      "\titers: 200, epoch: 1 | loss: 0.2823607\n",
      "\tspeed: 0.0486s/iter; left time: 488.6622s\n",
      "\titers: 300, epoch: 1 | loss: 0.2529696\n",
      "\tspeed: 0.0492s/iter; left time: 489.9495s\n",
      "\titers: 400, epoch: 1 | loss: 0.3143626\n",
      "\tspeed: 0.0499s/iter; left time: 491.5893s\n",
      "\titers: 500, epoch: 1 | loss: 0.2436135\n",
      "\tspeed: 0.0492s/iter; left time: 480.3043s\n",
      "Epoch: 1 cost time: 25.26135754585266\n",
      "Epoch: 1, Steps: 513 | Train Loss: 0.3655405 Vali Loss: 0.2200180 Test Loss: 0.2782328\n",
      "Validation loss decreased (inf --> 0.220018).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2130182\n",
      "\tspeed: 0.1279s/iter; left time: 1233.9283s\n",
      "\titers: 200, epoch: 2 | loss: 0.3141394\n",
      "\tspeed: 0.0488s/iter; left time: 466.2703s\n",
      "\titers: 300, epoch: 2 | loss: 0.2336545\n",
      "\tspeed: 0.0496s/iter; left time: 468.9474s\n",
      "\titers: 400, epoch: 2 | loss: 0.1279706\n",
      "\tspeed: 0.0492s/iter; left time: 459.4932s\n",
      "\titers: 500, epoch: 2 | loss: 0.3213457\n",
      "\tspeed: 0.0492s/iter; left time: 454.8843s\n",
      "Epoch: 2 cost time: 25.246599674224854\n",
      "Epoch: 2, Steps: 513 | Train Loss: 0.2059287 Vali Loss: 0.2093324 Test Loss: 0.2519639\n",
      "Validation loss decreased (0.220018 --> 0.209332).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1914436\n",
      "\tspeed: 0.1253s/iter; left time: 1144.2662s\n",
      "\titers: 200, epoch: 3 | loss: 0.2279072\n",
      "\tspeed: 0.0482s/iter; left time: 435.7608s\n",
      "\titers: 300, epoch: 3 | loss: 0.2085362\n",
      "\tspeed: 0.0500s/iter; left time: 446.9093s\n",
      "\titers: 400, epoch: 3 | loss: 0.1444356\n",
      "\tspeed: 0.0494s/iter; left time: 436.1855s\n",
      "\titers: 500, epoch: 3 | loss: 0.1363839\n",
      "\tspeed: 0.0494s/iter; left time: 431.3311s\n",
      "Epoch: 3 cost time: 25.08012628555298\n",
      "Epoch: 3, Steps: 513 | Train Loss: 0.1754314 Vali Loss: 0.2133682 Test Loss: 0.2518562\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1412799\n",
      "\tspeed: 0.1283s/iter; left time: 1105.8064s\n",
      "\titers: 200, epoch: 4 | loss: 0.1386945\n",
      "\tspeed: 0.0497s/iter; left time: 423.3009s\n",
      "\titers: 300, epoch: 4 | loss: 0.1287495\n",
      "\tspeed: 0.0497s/iter; left time: 418.4780s\n",
      "\titers: 400, epoch: 4 | loss: 0.1054573\n",
      "\tspeed: 0.0490s/iter; left time: 408.1092s\n",
      "\titers: 500, epoch: 4 | loss: 0.1625691\n",
      "\tspeed: 0.0492s/iter; left time: 404.7549s\n",
      "Epoch: 4 cost time: 25.400140047073364\n",
      "Epoch: 4, Steps: 513 | Train Loss: 0.1606271 Vali Loss: 0.1977595 Test Loss: 0.2429534\n",
      "Validation loss decreased (0.209332 --> 0.197760).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1794798\n",
      "\tspeed: 0.1274s/iter; left time: 1032.7501s\n",
      "\titers: 200, epoch: 5 | loss: 0.1640892\n",
      "\tspeed: 0.0501s/iter; left time: 401.0360s\n",
      "\titers: 300, epoch: 5 | loss: 0.2161687\n",
      "\tspeed: 0.0497s/iter; left time: 392.9120s\n",
      "\titers: 400, epoch: 5 | loss: 0.1216484\n",
      "\tspeed: 0.0491s/iter; left time: 383.7253s\n",
      "\titers: 500, epoch: 5 | loss: 0.1234367\n",
      "\tspeed: 0.0493s/iter; left time: 379.6786s\n",
      "Epoch: 5 cost time: 25.362085103988647\n",
      "Epoch: 5, Steps: 513 | Train Loss: 0.1519580 Vali Loss: 0.2003241 Test Loss: 0.2491062\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1479056\n",
      "\tspeed: 0.1263s/iter; left time: 959.1336s\n",
      "\titers: 200, epoch: 6 | loss: 0.1100829\n",
      "\tspeed: 0.0491s/iter; left time: 368.1272s\n",
      "\titers: 300, epoch: 6 | loss: 0.1157842\n",
      "\tspeed: 0.0487s/iter; left time: 359.9857s\n",
      "\titers: 400, epoch: 6 | loss: 0.1322270\n",
      "\tspeed: 0.0495s/iter; left time: 361.1633s\n",
      "\titers: 500, epoch: 6 | loss: 0.1499407\n",
      "\tspeed: 0.0489s/iter; left time: 351.5961s\n",
      "Epoch: 6 cost time: 25.129326105117798\n",
      "Epoch: 6, Steps: 513 | Train Loss: 0.1477535 Vali Loss: 0.2018276 Test Loss: 0.2459328\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1235130\n",
      "\tspeed: 0.1272s/iter; left time: 900.8787s\n",
      "\titers: 200, epoch: 7 | loss: 0.1518295\n",
      "\tspeed: 0.0494s/iter; left time: 344.7691s\n",
      "\titers: 300, epoch: 7 | loss: 0.1762381\n",
      "\tspeed: 0.0487s/iter; left time: 335.3707s\n",
      "\titers: 400, epoch: 7 | loss: 0.2606200\n",
      "\tspeed: 0.0502s/iter; left time: 340.3765s\n",
      "\titers: 500, epoch: 7 | loss: 0.1268896\n",
      "\tspeed: 0.0491s/iter; left time: 328.1511s\n",
      "Epoch: 7 cost time: 25.34438681602478\n",
      "Epoch: 7, Steps: 513 | Train Loss: 0.1454024 Vali Loss: 0.2015693 Test Loss: 0.2480814\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl240_ll80_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "Test cost time: 3.1175s\n",
      "test shape: (150, 32, 6, 1) (150, 32, 6, 1)\n",
      "test shape: (4800, 6, 1) (4800, 6, 1)\n",
      "mse:0.24291367828845978, mae:0.3226453363895416\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl240_ll80_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1760.9971923828125\n",
      "MAE:  27.471269607543945\n",
      "RMSE: 41.964237213134766\n",
      "MAPE: 0.3606254756450653\n",
      "MSPE: 0.6603405475616455\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl240_ll80_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20793\n",
      "[DEBUG] Original dataset length: 20793\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 16436\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6196\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "\titers: 100, epoch: 1 | loss: 0.4442267\n",
      "\tspeed: 0.0487s/iter; left time: 494.7504s\n",
      "\titers: 200, epoch: 1 | loss: 0.2721012\n",
      "\tspeed: 0.0487s/iter; left time: 490.1435s\n",
      "\titers: 300, epoch: 1 | loss: 0.2200078\n",
      "\tspeed: 0.0492s/iter; left time: 490.3357s\n",
      "\titers: 400, epoch: 1 | loss: 0.2058558\n",
      "\tspeed: 0.0488s/iter; left time: 481.1984s\n",
      "\titers: 500, epoch: 1 | loss: 0.1479710\n",
      "\tspeed: 0.0492s/iter; left time: 479.9571s\n",
      "Epoch: 1 cost time: 25.100139617919922\n",
      "Epoch: 1, Steps: 513 | Train Loss: 0.3445981 Vali Loss: 0.2210598 Test Loss: 0.2825955\n",
      "Validation loss decreased (inf --> 0.221060).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2081643\n",
      "\tspeed: 0.1275s/iter; left time: 1229.8318s\n",
      "\titers: 200, epoch: 2 | loss: 0.3311635\n",
      "\tspeed: 0.0489s/iter; left time: 466.5825s\n",
      "\titers: 300, epoch: 2 | loss: 0.1883474\n",
      "\tspeed: 0.0489s/iter; left time: 462.0812s\n",
      "\titers: 400, epoch: 2 | loss: 0.1581336\n",
      "\tspeed: 0.0491s/iter; left time: 458.6161s\n",
      "\titers: 500, epoch: 2 | loss: 0.2945131\n",
      "\tspeed: 0.0497s/iter; left time: 459.4002s\n",
      "Epoch: 2 cost time: 25.191883325576782\n",
      "Epoch: 2, Steps: 513 | Train Loss: 0.2028236 Vali Loss: 0.2150843 Test Loss: 0.2722181\n",
      "Validation loss decreased (0.221060 --> 0.215084).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1410692\n",
      "\tspeed: 0.1281s/iter; left time: 1169.8246s\n",
      "\titers: 200, epoch: 3 | loss: 0.1332740\n",
      "\tspeed: 0.0497s/iter; left time: 449.3592s\n",
      "\titers: 300, epoch: 3 | loss: 0.1364051\n",
      "\tspeed: 0.0489s/iter; left time: 436.5144s\n",
      "\titers: 400, epoch: 3 | loss: 0.1423892\n",
      "\tspeed: 0.0494s/iter; left time: 436.6696s\n",
      "\titers: 500, epoch: 3 | loss: 0.1408776\n",
      "\tspeed: 0.0497s/iter; left time: 434.0908s\n",
      "Epoch: 3 cost time: 25.339961051940918\n",
      "Epoch: 3, Steps: 513 | Train Loss: 0.1759677 Vali Loss: 0.2066996 Test Loss: 0.2453467\n",
      "Validation loss decreased (0.215084 --> 0.206700).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1978637\n",
      "\tspeed: 0.1281s/iter; left time: 1104.7792s\n",
      "\titers: 200, epoch: 4 | loss: 0.1396466\n",
      "\tspeed: 0.0493s/iter; left time: 420.1408s\n",
      "\titers: 300, epoch: 4 | loss: 0.1524582\n",
      "\tspeed: 0.0488s/iter; left time: 410.9784s\n",
      "\titers: 400, epoch: 4 | loss: 0.1656826\n",
      "\tspeed: 0.0495s/iter; left time: 411.5367s\n",
      "\titers: 500, epoch: 4 | loss: 0.1273701\n",
      "\tspeed: 0.0495s/iter; left time: 407.3219s\n",
      "Epoch: 4 cost time: 25.382344722747803\n",
      "Epoch: 4, Steps: 513 | Train Loss: 0.1597779 Vali Loss: 0.2098047 Test Loss: 0.2578845\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1606955\n",
      "\tspeed: 0.1260s/iter; left time: 1022.0108s\n",
      "\titers: 200, epoch: 5 | loss: 0.1844165\n",
      "\tspeed: 0.0488s/iter; left time: 390.8933s\n",
      "\titers: 300, epoch: 5 | loss: 0.1059184\n",
      "\tspeed: 0.0493s/iter; left time: 390.2659s\n",
      "\titers: 400, epoch: 5 | loss: 0.1527572\n",
      "\tspeed: 0.0498s/iter; left time: 389.2282s\n",
      "\titers: 500, epoch: 5 | loss: 0.1395597\n",
      "\tspeed: 0.0498s/iter; left time: 383.6463s\n",
      "Epoch: 5 cost time: 25.33335566520691\n",
      "Epoch: 5, Steps: 513 | Train Loss: 0.1512975 Vali Loss: 0.2061877 Test Loss: 0.2455411\n",
      "Validation loss decreased (0.206700 --> 0.206188).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1833606\n",
      "\tspeed: 0.1291s/iter; left time: 980.6675s\n",
      "\titers: 200, epoch: 6 | loss: 0.2308622\n",
      "\tspeed: 0.0497s/iter; left time: 372.2657s\n",
      "\titers: 300, epoch: 6 | loss: 0.1156366\n",
      "\tspeed: 0.0495s/iter; left time: 366.2535s\n",
      "\titers: 400, epoch: 6 | loss: 0.1469566\n",
      "\tspeed: 0.0492s/iter; left time: 359.1318s\n",
      "\titers: 500, epoch: 6 | loss: 0.1381988\n",
      "\tspeed: 0.0496s/iter; left time: 356.9033s\n",
      "Epoch: 6 cost time: 25.44189190864563\n",
      "Epoch: 6, Steps: 513 | Train Loss: 0.1463177 Vali Loss: 0.2073837 Test Loss: 0.2446379\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1629662\n",
      "\tspeed: 0.1274s/iter; left time: 902.5752s\n",
      "\titers: 200, epoch: 7 | loss: 0.0913747\n",
      "\tspeed: 0.0497s/iter; left time: 346.7306s\n",
      "\titers: 300, epoch: 7 | loss: 0.1320225\n",
      "\tspeed: 0.0502s/iter; left time: 345.5627s\n",
      "\titers: 400, epoch: 7 | loss: 0.1593603\n",
      "\tspeed: 0.0490s/iter; left time: 332.1228s\n",
      "\titers: 500, epoch: 7 | loss: 0.2062707\n",
      "\tspeed: 0.0489s/iter; left time: 327.1043s\n",
      "Epoch: 7 cost time: 25.35162854194641\n",
      "Epoch: 7, Steps: 513 | Train Loss: 0.1431032 Vali Loss: 0.2098916 Test Loss: 0.2500125\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1044600\n",
      "\tspeed: 0.1268s/iter; left time: 833.3231s\n",
      "\titers: 200, epoch: 8 | loss: 0.1125560\n",
      "\tspeed: 0.0491s/iter; left time: 317.5732s\n",
      "\titers: 300, epoch: 8 | loss: 0.1115388\n",
      "\tspeed: 0.0492s/iter; left time: 313.4907s\n",
      "\titers: 400, epoch: 8 | loss: 0.1685312\n",
      "\tspeed: 0.0489s/iter; left time: 306.6160s\n",
      "\titers: 500, epoch: 8 | loss: 0.1400976\n",
      "\tspeed: 0.0493s/iter; left time: 304.0439s\n",
      "Epoch: 8 cost time: 25.17899489402771\n",
      "Epoch: 8, Steps: 513 | Train Loss: 0.1419525 Vali Loss: 0.2097096 Test Loss: 0.2477306\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl240_ll80_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "Test cost time: 3.1219s\n",
      "test shape: (150, 32, 6, 1) (150, 32, 6, 1)\n",
      "test shape: (4800, 6, 1) (4800, 6, 1)\n",
      "mse:0.24521148204803467, mae:0.33409589529037476\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl240_ll80_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1777.6552734375\n",
      "MAE:  28.44621467590332\n",
      "RMSE: 42.16225051879883\n",
      "MAPE: 0.4069420397281647\n",
      "MSPE: 0.7819513082504272\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl240_ll80_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20793\n",
      "[DEBUG] Original dataset length: 20793\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 16436\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6196\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "\titers: 100, epoch: 1 | loss: 0.5779713\n",
      "\tspeed: 0.0493s/iter; left time: 500.8350s\n",
      "\titers: 200, epoch: 1 | loss: 0.3326981\n",
      "\tspeed: 0.0495s/iter; left time: 497.5198s\n",
      "\titers: 300, epoch: 1 | loss: 0.3142892\n",
      "\tspeed: 0.0498s/iter; left time: 496.1125s\n",
      "\titers: 400, epoch: 1 | loss: 0.2767635\n",
      "\tspeed: 0.0503s/iter; left time: 496.4937s\n",
      "\titers: 500, epoch: 1 | loss: 0.1599728\n",
      "\tspeed: 0.0487s/iter; left time: 474.9424s\n",
      "Epoch: 1 cost time: 25.429285049438477\n",
      "Epoch: 1, Steps: 513 | Train Loss: 0.3713969 Vali Loss: 0.2562753 Test Loss: 0.2932439\n",
      "Validation loss decreased (inf --> 0.256275).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1507447\n",
      "\tspeed: 0.1278s/iter; left time: 1232.5767s\n",
      "\titers: 200, epoch: 2 | loss: 0.2558996\n",
      "\tspeed: 0.0487s/iter; left time: 464.6557s\n",
      "\titers: 300, epoch: 2 | loss: 0.2088965\n",
      "\tspeed: 0.0487s/iter; left time: 460.4157s\n",
      "\titers: 400, epoch: 2 | loss: 0.1700723\n",
      "\tspeed: 0.0497s/iter; left time: 464.6830s\n",
      "\titers: 500, epoch: 2 | loss: 0.1965947\n",
      "\tspeed: 0.0488s/iter; left time: 451.2526s\n",
      "Epoch: 2 cost time: 25.171823740005493\n",
      "Epoch: 2, Steps: 513 | Train Loss: 0.2077306 Vali Loss: 0.2168197 Test Loss: 0.2660062\n",
      "Validation loss decreased (0.256275 --> 0.216820).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2519837\n",
      "\tspeed: 0.1278s/iter; left time: 1167.2479s\n",
      "\titers: 200, epoch: 3 | loss: 0.1285486\n",
      "\tspeed: 0.0490s/iter; left time: 442.8678s\n",
      "\titers: 300, epoch: 3 | loss: 0.1053744\n",
      "\tspeed: 0.0493s/iter; left time: 440.4802s\n",
      "\titers: 400, epoch: 3 | loss: 0.1561094\n",
      "\tspeed: 0.0490s/iter; left time: 432.6041s\n",
      "\titers: 500, epoch: 3 | loss: 0.1323438\n",
      "\tspeed: 0.0490s/iter; left time: 427.8568s\n",
      "Epoch: 3 cost time: 25.140737295150757\n",
      "Epoch: 3, Steps: 513 | Train Loss: 0.1750905 Vali Loss: 0.2063287 Test Loss: 0.2422864\n",
      "Validation loss decreased (0.216820 --> 0.206329).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1399619\n",
      "\tspeed: 0.1278s/iter; left time: 1101.6232s\n",
      "\titers: 200, epoch: 4 | loss: 0.1519896\n",
      "\tspeed: 0.0494s/iter; left time: 421.0964s\n",
      "\titers: 300, epoch: 4 | loss: 0.1710713\n",
      "\tspeed: 0.0498s/iter; left time: 419.7312s\n",
      "\titers: 400, epoch: 4 | loss: 0.1719266\n",
      "\tspeed: 0.0495s/iter; left time: 412.2041s\n",
      "\titers: 500, epoch: 4 | loss: 0.1837964\n",
      "\tspeed: 0.0501s/iter; left time: 411.7318s\n",
      "Epoch: 4 cost time: 25.41094470024109\n",
      "Epoch: 4, Steps: 513 | Train Loss: 0.1615165 Vali Loss: 0.2064944 Test Loss: 0.2394642\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1203488\n",
      "\tspeed: 0.1258s/iter; left time: 1019.7438s\n",
      "\titers: 200, epoch: 5 | loss: 0.1525036\n",
      "\tspeed: 0.0490s/iter; left time: 392.7057s\n",
      "\titers: 300, epoch: 5 | loss: 0.1336719\n",
      "\tspeed: 0.0490s/iter; left time: 387.7495s\n",
      "\titers: 400, epoch: 5 | loss: 0.1999018\n",
      "\tspeed: 0.0493s/iter; left time: 385.0997s\n",
      "\titers: 500, epoch: 5 | loss: 0.1140989\n",
      "\tspeed: 0.0497s/iter; left time: 383.0394s\n",
      "Epoch: 5 cost time: 25.184362411499023\n",
      "Epoch: 5, Steps: 513 | Train Loss: 0.1528932 Vali Loss: 0.2125389 Test Loss: 0.2457814\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1457904\n",
      "\tspeed: 0.1264s/iter; left time: 960.4187s\n",
      "\titers: 200, epoch: 6 | loss: 0.1496605\n",
      "\tspeed: 0.0498s/iter; left time: 373.0041s\n",
      "\titers: 300, epoch: 6 | loss: 0.1968895\n",
      "\tspeed: 0.0491s/iter; left time: 363.1556s\n",
      "\titers: 400, epoch: 6 | loss: 0.1564298\n",
      "\tspeed: 0.0491s/iter; left time: 358.3625s\n",
      "\titers: 500, epoch: 6 | loss: 0.1625082\n",
      "\tspeed: 0.0497s/iter; left time: 357.6849s\n",
      "Epoch: 6 cost time: 25.330007314682007\n",
      "Epoch: 6, Steps: 513 | Train Loss: 0.1480242 Vali Loss: 0.2061373 Test Loss: 0.2397663\n",
      "Validation loss decreased (0.206329 --> 0.206137).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1782854\n",
      "\tspeed: 0.1278s/iter; left time: 905.0975s\n",
      "\titers: 200, epoch: 7 | loss: 0.0937521\n",
      "\tspeed: 0.0495s/iter; left time: 345.8614s\n",
      "\titers: 300, epoch: 7 | loss: 0.1637197\n",
      "\tspeed: 0.0500s/iter; left time: 343.9153s\n",
      "\titers: 400, epoch: 7 | loss: 0.1597931\n",
      "\tspeed: 0.0495s/iter; left time: 336.0267s\n",
      "\titers: 500, epoch: 7 | loss: 0.1330502\n",
      "\tspeed: 0.0483s/iter; left time: 323.0829s\n",
      "Epoch: 7 cost time: 25.321900844573975\n",
      "Epoch: 7, Steps: 513 | Train Loss: 0.1449062 Vali Loss: 0.2058465 Test Loss: 0.2383473\n",
      "Validation loss decreased (0.206137 --> 0.205847).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1392644\n",
      "\tspeed: 0.1258s/iter; left time: 826.5785s\n",
      "\titers: 200, epoch: 8 | loss: 0.1343385\n",
      "\tspeed: 0.0489s/iter; left time: 316.0986s\n",
      "\titers: 300, epoch: 8 | loss: 0.1794218\n",
      "\tspeed: 0.0492s/iter; left time: 313.6121s\n",
      "\titers: 400, epoch: 8 | loss: 0.1655160\n",
      "\tspeed: 0.0499s/iter; left time: 312.5705s\n",
      "\titers: 500, epoch: 8 | loss: 0.1431256\n",
      "\tspeed: 0.0488s/iter; left time: 300.9699s\n",
      "Epoch: 8 cost time: 25.22250771522522\n",
      "Epoch: 8, Steps: 513 | Train Loss: 0.1443065 Vali Loss: 0.2099679 Test Loss: 0.2435579\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1929755\n",
      "\tspeed: 0.1258s/iter; left time: 762.1802s\n",
      "\titers: 200, epoch: 9 | loss: 0.1662550\n",
      "\tspeed: 0.0488s/iter; left time: 290.4279s\n",
      "\titers: 300, epoch: 9 | loss: 0.0958501\n",
      "\tspeed: 0.0492s/iter; left time: 288.3825s\n",
      "\titers: 400, epoch: 9 | loss: 0.2027101\n",
      "\tspeed: 0.0491s/iter; left time: 282.8406s\n",
      "\titers: 500, epoch: 9 | loss: 0.2000685\n",
      "\tspeed: 0.0492s/iter; left time: 278.1060s\n",
      "Epoch: 9 cost time: 25.184987783432007\n",
      "Epoch: 9, Steps: 513 | Train Loss: 0.1431626 Vali Loss: 0.2080432 Test Loss: 0.2409417\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.2089402\n",
      "\tspeed: 0.1274s/iter; left time: 706.5775s\n",
      "\titers: 200, epoch: 10 | loss: 0.1592580\n",
      "\tspeed: 0.0492s/iter; left time: 267.6525s\n",
      "\titers: 300, epoch: 10 | loss: 0.0991339\n",
      "\tspeed: 0.0497s/iter; left time: 265.5304s\n",
      "\titers: 400, epoch: 10 | loss: 0.1477761\n",
      "\tspeed: 0.0498s/iter; left time: 261.2288s\n",
      "\titers: 500, epoch: 10 | loss: 0.1817656\n",
      "\tspeed: 0.0490s/iter; left time: 252.0945s\n",
      "Epoch: 10 cost time: 25.33123016357422\n",
      "Epoch: 10, Steps: 513 | Train Loss: 0.1431937 Vali Loss: 0.2087413 Test Loss: 0.2398071\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl240_ll80_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "Test cost time: 3.0020s\n",
      "test shape: (150, 32, 6, 1) (150, 32, 6, 1)\n",
      "test shape: (4800, 6, 1) (4800, 6, 1)\n",
      "mse:0.23925484716892242, mae:0.322610080242157\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl240_ll80_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1734.4727783203125\n",
      "MAE:  27.4682674407959\n",
      "RMSE: 41.647003173828125\n",
      "MAPE: 0.3604339063167572\n",
      "MSPE: 0.589183509349823\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl240_ll80_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20793\n",
      "[DEBUG] Original dataset length: 20793\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 16436\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6196\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "\titers: 100, epoch: 1 | loss: 0.3859313\n",
      "\tspeed: 0.0462s/iter; left time: 469.5563s\n",
      "\titers: 200, epoch: 1 | loss: 0.2263172\n",
      "\tspeed: 0.0481s/iter; left time: 484.0787s\n",
      "\titers: 300, epoch: 1 | loss: 0.3093157\n",
      "\tspeed: 0.0491s/iter; left time: 488.6633s\n",
      "\titers: 400, epoch: 1 | loss: 0.2557233\n",
      "\tspeed: 0.0488s/iter; left time: 481.2819s\n",
      "\titers: 500, epoch: 1 | loss: 0.1850312\n",
      "\tspeed: 0.0500s/iter; left time: 488.0782s\n",
      "Epoch: 1 cost time: 24.882521152496338\n",
      "Epoch: 1, Steps: 513 | Train Loss: 0.3447273 Vali Loss: 0.2207518 Test Loss: 0.2822828\n",
      "Validation loss decreased (inf --> 0.220752).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4393965\n",
      "\tspeed: 0.1317s/iter; left time: 1271.0000s\n",
      "\titers: 200, epoch: 2 | loss: 0.2156434\n",
      "\tspeed: 0.0505s/iter; left time: 482.1310s\n",
      "\titers: 300, epoch: 2 | loss: 0.2494191\n",
      "\tspeed: 0.0499s/iter; left time: 471.4862s\n",
      "\titers: 400, epoch: 2 | loss: 0.1980859\n",
      "\tspeed: 0.0501s/iter; left time: 468.1841s\n",
      "\titers: 500, epoch: 2 | loss: 0.1647284\n",
      "\tspeed: 0.0492s/iter; left time: 454.6401s\n",
      "Epoch: 2 cost time: 25.637195110321045\n",
      "Epoch: 2, Steps: 513 | Train Loss: 0.2040503 Vali Loss: 0.2032838 Test Loss: 0.2475902\n",
      "Validation loss decreased (0.220752 --> 0.203284).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1199931\n",
      "\tspeed: 0.1292s/iter; left time: 1180.4017s\n",
      "\titers: 200, epoch: 3 | loss: 0.1706678\n",
      "\tspeed: 0.0491s/iter; left time: 443.7247s\n",
      "\titers: 300, epoch: 3 | loss: 0.2338066\n",
      "\tspeed: 0.0493s/iter; left time: 440.5733s\n",
      "\titers: 400, epoch: 3 | loss: 0.1783649\n",
      "\tspeed: 0.0498s/iter; left time: 439.7204s\n",
      "\titers: 500, epoch: 3 | loss: 0.1297325\n",
      "\tspeed: 0.0491s/iter; left time: 428.6582s\n",
      "Epoch: 3 cost time: 25.438169479370117\n",
      "Epoch: 3, Steps: 513 | Train Loss: 0.1744113 Vali Loss: 0.2114550 Test Loss: 0.2597658\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1254166\n",
      "\tspeed: 0.1270s/iter; left time: 1095.0504s\n",
      "\titers: 200, epoch: 4 | loss: 0.1303609\n",
      "\tspeed: 0.0497s/iter; left time: 423.6190s\n",
      "\titers: 300, epoch: 4 | loss: 0.1270398\n",
      "\tspeed: 0.0500s/iter; left time: 420.9029s\n",
      "\titers: 400, epoch: 4 | loss: 0.1552571\n",
      "\tspeed: 0.0495s/iter; left time: 411.8677s\n",
      "\titers: 500, epoch: 4 | loss: 0.1457697\n",
      "\tspeed: 0.0491s/iter; left time: 403.4890s\n",
      "Epoch: 4 cost time: 25.37583875656128\n",
      "Epoch: 4, Steps: 513 | Train Loss: 0.1614898 Vali Loss: 0.2045415 Test Loss: 0.2535198\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1211195\n",
      "\tspeed: 0.1327s/iter; left time: 1076.2641s\n",
      "\titers: 200, epoch: 5 | loss: 0.1484340\n",
      "\tspeed: 0.0500s/iter; left time: 400.8290s\n",
      "\titers: 300, epoch: 5 | loss: 0.1766616\n",
      "\tspeed: 0.0501s/iter; left time: 396.0408s\n",
      "\titers: 400, epoch: 5 | loss: 0.1667463\n",
      "\tspeed: 0.0497s/iter; left time: 388.0188s\n",
      "\titers: 500, epoch: 5 | loss: 0.1484229\n",
      "\tspeed: 0.0503s/iter; left time: 387.9281s\n",
      "Epoch: 5 cost time: 25.984968423843384\n",
      "Epoch: 5, Steps: 513 | Train Loss: 0.1521877 Vali Loss: 0.2191984 Test Loss: 0.2593271\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl240_ll80_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "Test cost time: 3.1156s\n",
      "test shape: (150, 32, 6, 1) (150, 32, 6, 1)\n",
      "test shape: (4800, 6, 1) (4800, 6, 1)\n",
      "mse:0.24804145097732544, mae:0.3252847492694855\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl240_ll80_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1798.1710205078125\n",
      "MAE:  27.696001052856445\n",
      "RMSE: 42.40484619140625\n",
      "MAPE: 0.33024442195892334\n",
      "MSPE: 0.46264973282814026\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl240_ll80_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20793\n",
      "[DEBUG] Original dataset length: 20793\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 16436\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6196\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "\titers: 100, epoch: 1 | loss: 0.4378476\n",
      "\tspeed: 0.0494s/iter; left time: 501.5477s\n",
      "\titers: 200, epoch: 1 | loss: 0.3034113\n",
      "\tspeed: 0.0501s/iter; left time: 504.3344s\n",
      "\titers: 300, epoch: 1 | loss: 0.2123404\n",
      "\tspeed: 0.0500s/iter; left time: 497.9071s\n",
      "\titers: 400, epoch: 1 | loss: 0.2784128\n",
      "\tspeed: 0.0502s/iter; left time: 495.2018s\n",
      "\titers: 500, epoch: 1 | loss: 0.1450728\n",
      "\tspeed: 0.0502s/iter; left time: 489.6282s\n",
      "Epoch: 1 cost time: 25.658344268798828\n",
      "Epoch: 1, Steps: 513 | Train Loss: 0.3676645 Vali Loss: 0.2222060 Test Loss: 0.2696654\n",
      "Validation loss decreased (inf --> 0.222206).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2403243\n",
      "\tspeed: 0.1298s/iter; left time: 1252.2063s\n",
      "\titers: 200, epoch: 2 | loss: 0.2363085\n",
      "\tspeed: 0.0499s/iter; left time: 476.1267s\n",
      "\titers: 300, epoch: 2 | loss: 0.3246107\n",
      "\tspeed: 0.0497s/iter; left time: 469.9451s\n",
      "\titers: 400, epoch: 2 | loss: 0.1408536\n",
      "\tspeed: 0.0498s/iter; left time: 465.3172s\n",
      "\titers: 500, epoch: 2 | loss: 0.1904322\n",
      "\tspeed: 0.0493s/iter; left time: 456.1870s\n",
      "Epoch: 2 cost time: 25.552916526794434\n",
      "Epoch: 2, Steps: 513 | Train Loss: 0.2047664 Vali Loss: 0.2256484 Test Loss: 0.2666560\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1505442\n",
      "\tspeed: 0.1281s/iter; left time: 1170.4626s\n",
      "\titers: 200, epoch: 3 | loss: 0.1333709\n",
      "\tspeed: 0.0493s/iter; left time: 445.4557s\n",
      "\titers: 300, epoch: 3 | loss: 0.1666197\n",
      "\tspeed: 0.0498s/iter; left time: 445.3665s\n",
      "\titers: 400, epoch: 3 | loss: 0.1673931\n",
      "\tspeed: 0.0486s/iter; left time: 429.0242s\n",
      "\titers: 500, epoch: 3 | loss: 0.2037362\n",
      "\tspeed: 0.0486s/iter; left time: 424.3249s\n",
      "Epoch: 3 cost time: 25.185073614120483\n",
      "Epoch: 3, Steps: 513 | Train Loss: 0.1794261 Vali Loss: 0.2241206 Test Loss: 0.2600471\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1663890\n",
      "\tspeed: 0.1280s/iter; left time: 1103.8330s\n",
      "\titers: 200, epoch: 4 | loss: 0.2382777\n",
      "\tspeed: 0.0494s/iter; left time: 420.6039s\n",
      "\titers: 300, epoch: 4 | loss: 0.1476650\n",
      "\tspeed: 0.0494s/iter; left time: 416.3276s\n",
      "\titers: 400, epoch: 4 | loss: 0.1314688\n",
      "\tspeed: 0.0492s/iter; left time: 409.7915s\n",
      "\titers: 500, epoch: 4 | loss: 0.1885838\n",
      "\tspeed: 0.0488s/iter; left time: 400.8656s\n",
      "Epoch: 4 cost time: 25.309898614883423\n",
      "Epoch: 4, Steps: 513 | Train Loss: 0.1636348 Vali Loss: 0.2111797 Test Loss: 0.2540216\n",
      "Validation loss decreased (0.222206 --> 0.211180).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1543006\n",
      "\tspeed: 0.1290s/iter; left time: 1045.9410s\n",
      "\titers: 200, epoch: 5 | loss: 0.1524690\n",
      "\tspeed: 0.0509s/iter; left time: 407.3764s\n",
      "\titers: 300, epoch: 5 | loss: 0.1474991\n",
      "\tspeed: 0.0490s/iter; left time: 387.5487s\n",
      "\titers: 400, epoch: 5 | loss: 0.1111977\n",
      "\tspeed: 0.0488s/iter; left time: 381.1012s\n",
      "\titers: 500, epoch: 5 | loss: 0.1661881\n",
      "\tspeed: 0.0496s/iter; left time: 382.4774s\n",
      "Epoch: 5 cost time: 25.45105481147766\n",
      "Epoch: 5, Steps: 513 | Train Loss: 0.1554184 Vali Loss: 0.2084975 Test Loss: 0.2537385\n",
      "Validation loss decreased (0.211180 --> 0.208497).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0867705\n",
      "\tspeed: 0.1278s/iter; left time: 970.8967s\n",
      "\titers: 200, epoch: 6 | loss: 0.1380645\n",
      "\tspeed: 0.0497s/iter; left time: 372.8011s\n",
      "\titers: 300, epoch: 6 | loss: 0.1044949\n",
      "\tspeed: 0.0485s/iter; left time: 358.9683s\n",
      "\titers: 400, epoch: 6 | loss: 0.1630824\n",
      "\tspeed: 0.0492s/iter; left time: 358.8461s\n",
      "\titers: 500, epoch: 6 | loss: 0.1990840\n",
      "\tspeed: 0.0498s/iter; left time: 358.5507s\n",
      "Epoch: 6 cost time: 25.277833223342896\n",
      "Epoch: 6, Steps: 513 | Train Loss: 0.1503427 Vali Loss: 0.2095818 Test Loss: 0.2511587\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0843773\n",
      "\tspeed: 0.1283s/iter; left time: 908.7067s\n",
      "\titers: 200, epoch: 7 | loss: 0.0993904\n",
      "\tspeed: 0.0493s/iter; left time: 343.9786s\n",
      "\titers: 300, epoch: 7 | loss: 0.1905412\n",
      "\tspeed: 0.0491s/iter; left time: 338.1827s\n",
      "\titers: 400, epoch: 7 | loss: 0.1257527\n",
      "\tspeed: 0.0501s/iter; left time: 340.1521s\n",
      "\titers: 500, epoch: 7 | loss: 0.2039941\n",
      "\tspeed: 0.0500s/iter; left time: 333.8515s\n",
      "Epoch: 7 cost time: 25.52553415298462\n",
      "Epoch: 7, Steps: 513 | Train Loss: 0.1478394 Vali Loss: 0.2070968 Test Loss: 0.2503880\n",
      "Validation loss decreased (0.208497 --> 0.207097).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1687623\n",
      "\tspeed: 0.1295s/iter; left time: 851.0736s\n",
      "\titers: 200, epoch: 8 | loss: 0.1556809\n",
      "\tspeed: 0.0501s/iter; left time: 324.3301s\n",
      "\titers: 300, epoch: 8 | loss: 0.1452244\n",
      "\tspeed: 0.0500s/iter; left time: 318.6313s\n",
      "\titers: 400, epoch: 8 | loss: 0.0857248\n",
      "\tspeed: 0.0498s/iter; left time: 312.1566s\n",
      "\titers: 500, epoch: 8 | loss: 0.0955861\n",
      "\tspeed: 0.0501s/iter; left time: 308.9756s\n",
      "Epoch: 8 cost time: 25.636003732681274\n",
      "Epoch: 8, Steps: 513 | Train Loss: 0.1462273 Vali Loss: 0.2084848 Test Loss: 0.2485967\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0969956\n",
      "\tspeed: 0.1313s/iter; left time: 795.0396s\n",
      "\titers: 200, epoch: 9 | loss: 0.1645180\n",
      "\tspeed: 0.0493s/iter; left time: 293.6880s\n",
      "\titers: 300, epoch: 9 | loss: 0.1338194\n",
      "\tspeed: 0.0498s/iter; left time: 291.9709s\n",
      "\titers: 400, epoch: 9 | loss: 0.1489463\n",
      "\tspeed: 0.0501s/iter; left time: 288.1786s\n",
      "\titers: 500, epoch: 9 | loss: 0.0869105\n",
      "\tspeed: 0.0507s/iter; left time: 286.5450s\n",
      "Epoch: 9 cost time: 25.697585105895996\n",
      "Epoch: 9, Steps: 513 | Train Loss: 0.1455840 Vali Loss: 0.2091167 Test Loss: 0.2517812\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.1286621\n",
      "\tspeed: 0.1297s/iter; left time: 718.9989s\n",
      "\titers: 200, epoch: 10 | loss: 0.1647194\n",
      "\tspeed: 0.0503s/iter; left time: 273.6270s\n",
      "\titers: 300, epoch: 10 | loss: 0.1504855\n",
      "\tspeed: 0.0498s/iter; left time: 266.0977s\n",
      "\titers: 400, epoch: 10 | loss: 0.1600213\n",
      "\tspeed: 0.0497s/iter; left time: 260.5671s\n",
      "\titers: 500, epoch: 10 | loss: 0.2286657\n",
      "\tspeed: 0.0503s/iter; left time: 258.8549s\n",
      "Epoch: 10 cost time: 25.658082485198975\n",
      "Epoch: 10, Steps: 513 | Train Loss: 0.1450857 Vali Loss: 0.2083802 Test Loss: 0.2515920\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl240_ll80_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "Test cost time: 3.1080s\n",
      "test shape: (150, 32, 6, 1) (150, 32, 6, 1)\n",
      "test shape: (4800, 6, 1) (4800, 6, 1)\n",
      "mse:0.2508842647075653, mae:0.32449665665626526\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl240_ll80_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_6<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1818.780029296875\n",
      "MAE:  27.628902435302734\n",
      "RMSE: 42.64715576171875\n",
      "MAPE: 0.3654232323169708\n",
      "MSPE: 0.6176384687423706\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl240_ll80_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20793\n",
      "[DEBUG] Original dataset length: 20793\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 16436\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6196\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "\titers: 100, epoch: 1 | loss: 0.4169253\n",
      "\tspeed: 0.0501s/iter; left time: 508.8562s\n",
      "\titers: 200, epoch: 1 | loss: 0.3232495\n",
      "\tspeed: 0.0490s/iter; left time: 493.3514s\n",
      "\titers: 300, epoch: 1 | loss: 0.3589273\n",
      "\tspeed: 0.0485s/iter; left time: 483.1951s\n",
      "\titers: 400, epoch: 1 | loss: 0.2448150\n",
      "\tspeed: 0.0499s/iter; left time: 491.8448s\n",
      "\titers: 500, epoch: 1 | loss: 0.2125949\n",
      "\tspeed: 0.0494s/iter; left time: 481.9935s\n",
      "Epoch: 1 cost time: 25.34724235534668\n",
      "Epoch: 1, Steps: 513 | Train Loss: 0.3523281 Vali Loss: 0.3368898 Test Loss: 0.3404958\n",
      "Validation loss decreased (inf --> 0.336890).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1549072\n",
      "\tspeed: 0.1232s/iter; left time: 1189.0152s\n",
      "\titers: 200, epoch: 2 | loss: 0.2285668\n",
      "\tspeed: 0.0483s/iter; left time: 460.9579s\n",
      "\titers: 300, epoch: 2 | loss: 0.1736472\n",
      "\tspeed: 0.0484s/iter; left time: 456.8186s\n",
      "\titers: 400, epoch: 2 | loss: 0.1361593\n",
      "\tspeed: 0.0494s/iter; left time: 461.4568s\n",
      "\titers: 500, epoch: 2 | loss: 0.1605262\n",
      "\tspeed: 0.0489s/iter; left time: 451.8069s\n",
      "Epoch: 2 cost time: 24.851916551589966\n",
      "Epoch: 2, Steps: 513 | Train Loss: 0.2065719 Vali Loss: 0.2320799 Test Loss: 0.2854008\n",
      "Validation loss decreased (0.336890 --> 0.232080).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2057938\n",
      "\tspeed: 0.1278s/iter; left time: 1167.7412s\n",
      "\titers: 200, epoch: 3 | loss: 0.1768300\n",
      "\tspeed: 0.0490s/iter; left time: 442.5445s\n",
      "\titers: 300, epoch: 3 | loss: 0.1595632\n",
      "\tspeed: 0.0494s/iter; left time: 441.6576s\n",
      "\titers: 400, epoch: 3 | loss: 0.1508992\n",
      "\tspeed: 0.0507s/iter; left time: 447.4995s\n",
      "\titers: 500, epoch: 3 | loss: 0.2053245\n",
      "\tspeed: 0.0492s/iter; left time: 429.8882s\n",
      "Epoch: 3 cost time: 25.362035512924194\n",
      "Epoch: 3, Steps: 513 | Train Loss: 0.1779165 Vali Loss: 0.2146376 Test Loss: 0.2671033\n",
      "Validation loss decreased (0.232080 --> 0.214638).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1288104\n",
      "\tspeed: 0.1272s/iter; left time: 1096.5280s\n",
      "\titers: 200, epoch: 4 | loss: 0.1054868\n",
      "\tspeed: 0.0489s/iter; left time: 416.6489s\n",
      "\titers: 300, epoch: 4 | loss: 0.1197961\n",
      "\tspeed: 0.0493s/iter; left time: 415.5504s\n",
      "\titers: 400, epoch: 4 | loss: 0.1784084\n",
      "\tspeed: 0.0491s/iter; left time: 408.7539s\n",
      "\titers: 500, epoch: 4 | loss: 0.2051267\n",
      "\tspeed: 0.0491s/iter; left time: 403.8049s\n",
      "Epoch: 4 cost time: 25.1629478931427\n",
      "Epoch: 4, Steps: 513 | Train Loss: 0.1628302 Vali Loss: 0.2068776 Test Loss: 0.2503861\n",
      "Validation loss decreased (0.214638 --> 0.206878).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1505136\n",
      "\tspeed: 0.1284s/iter; left time: 1041.0555s\n",
      "\titers: 200, epoch: 5 | loss: 0.1270120\n",
      "\tspeed: 0.0500s/iter; left time: 400.6532s\n",
      "\titers: 300, epoch: 5 | loss: 0.1089699\n",
      "\tspeed: 0.0491s/iter; left time: 388.3697s\n",
      "\titers: 400, epoch: 5 | loss: 0.1599731\n",
      "\tspeed: 0.0492s/iter; left time: 384.1523s\n",
      "\titers: 500, epoch: 5 | loss: 0.1454310\n",
      "\tspeed: 0.0493s/iter; left time: 380.2583s\n",
      "Epoch: 5 cost time: 25.353647232055664\n",
      "Epoch: 5, Steps: 513 | Train Loss: 0.1527850 Vali Loss: 0.2193945 Test Loss: 0.2663056\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1271790\n",
      "\tspeed: 0.1254s/iter; left time: 952.9014s\n",
      "\titers: 200, epoch: 6 | loss: 0.1103549\n",
      "\tspeed: 0.0481s/iter; left time: 360.5916s\n",
      "\titers: 300, epoch: 6 | loss: 0.1997661\n",
      "\tspeed: 0.0491s/iter; left time: 362.9963s\n",
      "\titers: 400, epoch: 6 | loss: 0.2155124\n",
      "\tspeed: 0.0488s/iter; left time: 356.1086s\n",
      "\titers: 500, epoch: 6 | loss: 0.1410752\n",
      "\tspeed: 0.0497s/iter; left time: 357.5389s\n",
      "Epoch: 6 cost time: 25.06341290473938\n",
      "Epoch: 6, Steps: 513 | Train Loss: 0.1480249 Vali Loss: 0.2122203 Test Loss: 0.2606557\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1464154\n",
      "\tspeed: 0.1263s/iter; left time: 894.3611s\n",
      "\titers: 200, epoch: 7 | loss: 0.1214890\n",
      "\tspeed: 0.0495s/iter; left time: 345.5291s\n",
      "\titers: 300, epoch: 7 | loss: 0.1952760\n",
      "\tspeed: 0.0488s/iter; left time: 335.5691s\n",
      "\titers: 400, epoch: 7 | loss: 0.1033322\n",
      "\tspeed: 0.0488s/iter; left time: 331.2987s\n",
      "\titers: 500, epoch: 7 | loss: 0.1425596\n",
      "\tspeed: 0.0493s/iter; left time: 329.4668s\n",
      "Epoch: 7 cost time: 25.196155071258545\n",
      "Epoch: 7, Steps: 513 | Train Loss: 0.1455990 Vali Loss: 0.2122579 Test Loss: 0.2572337\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl240_ll80_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "Test cost time: 3.1264s\n",
      "test shape: (150, 32, 6, 1) (150, 32, 6, 1)\n",
      "test shape: (4800, 6, 1) (4800, 6, 1)\n",
      "mse:0.24968533217906952, mae:0.3240572512149811\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl240_ll80_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_7<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1810.0880126953125\n",
      "MAE:  27.59148597717285\n",
      "RMSE: 42.545127868652344\n",
      "MAPE: 0.37543025612831116\n",
      "MSPE: 0.6514173746109009\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl240_ll80_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20793\n",
      "[DEBUG] Original dataset length: 20793\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 16436\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6196\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "\titers: 100, epoch: 1 | loss: 0.4978285\n",
      "\tspeed: 0.0486s/iter; left time: 494.3116s\n",
      "\titers: 200, epoch: 1 | loss: 0.3454136\n",
      "\tspeed: 0.0485s/iter; left time: 487.4911s\n",
      "\titers: 300, epoch: 1 | loss: 0.2679251\n",
      "\tspeed: 0.0499s/iter; left time: 496.9201s\n",
      "\titers: 400, epoch: 1 | loss: 0.2081382\n",
      "\tspeed: 0.0487s/iter; left time: 480.3367s\n",
      "\titers: 500, epoch: 1 | loss: 0.2009691\n",
      "\tspeed: 0.0490s/iter; left time: 478.5146s\n",
      "Epoch: 1 cost time: 25.132256746292114\n",
      "Epoch: 1, Steps: 513 | Train Loss: 0.3645478 Vali Loss: 0.2327043 Test Loss: 0.2956605\n",
      "Validation loss decreased (inf --> 0.232704).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1920772\n",
      "\tspeed: 0.1275s/iter; left time: 1230.2481s\n",
      "\titers: 200, epoch: 2 | loss: 0.2047162\n",
      "\tspeed: 0.0468s/iter; left time: 446.9088s\n",
      "\titers: 300, epoch: 2 | loss: 0.1492068\n",
      "\tspeed: 0.0496s/iter; left time: 468.3579s\n",
      "\titers: 400, epoch: 2 | loss: 0.1842013\n",
      "\tspeed: 0.0493s/iter; left time: 461.0114s\n",
      "\titers: 500, epoch: 2 | loss: 0.2173777\n",
      "\tspeed: 0.0500s/iter; left time: 462.4737s\n",
      "Epoch: 2 cost time: 25.115155696868896\n",
      "Epoch: 2, Steps: 513 | Train Loss: 0.2080770 Vali Loss: 0.2135446 Test Loss: 0.2639801\n",
      "Validation loss decreased (0.232704 --> 0.213545).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1672210\n",
      "\tspeed: 0.1293s/iter; left time: 1181.4582s\n",
      "\titers: 200, epoch: 3 | loss: 0.2243050\n",
      "\tspeed: 0.0500s/iter; left time: 451.8044s\n",
      "\titers: 300, epoch: 3 | loss: 0.1675615\n",
      "\tspeed: 0.0497s/iter; left time: 444.2216s\n",
      "\titers: 400, epoch: 3 | loss: 0.4040302\n",
      "\tspeed: 0.0496s/iter; left time: 438.0455s\n",
      "\titers: 500, epoch: 3 | loss: 0.1644796\n",
      "\tspeed: 0.0502s/iter; left time: 438.4243s\n",
      "Epoch: 3 cost time: 25.544446229934692\n",
      "Epoch: 3, Steps: 513 | Train Loss: 0.1746251 Vali Loss: 0.2044075 Test Loss: 0.2485621\n",
      "Validation loss decreased (0.213545 --> 0.204407).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0947067\n",
      "\tspeed: 0.1267s/iter; left time: 1092.3190s\n",
      "\titers: 200, epoch: 4 | loss: 0.1388128\n",
      "\tspeed: 0.0498s/iter; left time: 424.3956s\n",
      "\titers: 300, epoch: 4 | loss: 0.1453190\n",
      "\tspeed: 0.0488s/iter; left time: 410.8480s\n",
      "\titers: 400, epoch: 4 | loss: 0.1254779\n",
      "\tspeed: 0.0490s/iter; left time: 408.1734s\n",
      "\titers: 500, epoch: 4 | loss: 0.0980539\n",
      "\tspeed: 0.0493s/iter; left time: 405.3972s\n",
      "Epoch: 4 cost time: 25.183904886245728\n",
      "Epoch: 4, Steps: 513 | Train Loss: 0.1622776 Vali Loss: 0.2132087 Test Loss: 0.2510318\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1039854\n",
      "\tspeed: 0.1247s/iter; left time: 1010.8965s\n",
      "\titers: 200, epoch: 5 | loss: 0.1616917\n",
      "\tspeed: 0.0487s/iter; left time: 389.7047s\n",
      "\titers: 300, epoch: 5 | loss: 0.1283939\n",
      "\tspeed: 0.0487s/iter; left time: 384.9275s\n",
      "\titers: 400, epoch: 5 | loss: 0.2072782\n",
      "\tspeed: 0.0496s/iter; left time: 387.4599s\n",
      "\titers: 500, epoch: 5 | loss: 0.1293913\n",
      "\tspeed: 0.0491s/iter; left time: 378.4115s\n",
      "Epoch: 5 cost time: 25.011252641677856\n",
      "Epoch: 5, Steps: 513 | Train Loss: 0.1527694 Vali Loss: 0.2057083 Test Loss: 0.2434149\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1233232\n",
      "\tspeed: 0.1267s/iter; left time: 962.5580s\n",
      "\titers: 200, epoch: 6 | loss: 0.1725843\n",
      "\tspeed: 0.0490s/iter; left time: 367.3052s\n",
      "\titers: 300, epoch: 6 | loss: 0.1589237\n",
      "\tspeed: 0.0491s/iter; left time: 363.1646s\n",
      "\titers: 400, epoch: 6 | loss: 0.1499388\n",
      "\tspeed: 0.0495s/iter; left time: 361.4782s\n",
      "\titers: 500, epoch: 6 | loss: 0.1332110\n",
      "\tspeed: 0.0491s/iter; left time: 353.2347s\n",
      "Epoch: 6 cost time: 25.28592324256897\n",
      "Epoch: 6, Steps: 513 | Train Loss: 0.1486946 Vali Loss: 0.2071442 Test Loss: 0.2441203\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_traffic_full_ftS_sl240_ll80_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "Test cost time: 3.1200s\n",
      "test shape: (150, 32, 6, 1) (150, 32, 6, 1)\n",
      "test shape: (4800, 6, 1) (4800, 6, 1)\n",
      "mse:0.24834083020687103, mae:0.32169800996780396\n",
      ">>>>>>>inverse results : informer_traffic_full_ftS_sl240_ll80_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_8<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "✓ Inverse transformation complete\n",
      "=== Inverse Scale Metrics ===\n",
      "MSE:  1800.34130859375\n",
      "MAE:  27.39061164855957\n",
      "RMSE: 42.43042755126953\n",
      "MAPE: 0.3631174862384796\n",
      "MSPE: 0.5978798270225525\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_traffic_full_ftS_sl240_ll80_pl6_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_9>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 20793\n",
      "[DEBUG] Original dataset length: 20793\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 16436\n",
      "val 7009\n",
      "[DEBUG] Original dataset length: 7009\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 6196\n",
      "test 7007\n",
      "[DEBUG] Original dataset length: 7007\n",
      "[DEBUG] Cleaned dataset length (NaN removed): 4826\n",
      "\titers: 100, epoch: 1 | loss: 0.4943022\n",
      "\tspeed: 0.0487s/iter; left time: 494.5066s\n",
      "\titers: 200, epoch: 1 | loss: 0.2989637\n",
      "\tspeed: 0.0496s/iter; left time: 498.8347s\n",
      "\titers: 300, epoch: 1 | loss: 0.1384840\n",
      "\tspeed: 0.0493s/iter; left time: 490.7130s\n",
      "\titers: 400, epoch: 1 | loss: 0.2533485\n",
      "\tspeed: 0.0491s/iter; left time: 484.6053s\n",
      "\titers: 500, epoch: 1 | loss: 0.1679500\n",
      "\tspeed: 0.0497s/iter; left time: 484.8518s\n",
      "Epoch: 1 cost time: 25.34981608390808\n",
      "Epoch: 1, Steps: 513 | Train Loss: 0.3573857 Vali Loss: 0.2287678 Test Loss: 0.2875375\n",
      "Validation loss decreased (inf --> 0.228768).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3210593\n",
      "\tspeed: 0.1302s/iter; left time: 1256.1655s\n",
      "\titers: 200, epoch: 2 | loss: 0.2611613\n",
      "\tspeed: 0.0502s/iter; left time: 479.7385s\n",
      "\titers: 300, epoch: 2 | loss: 0.1009197\n",
      "\tspeed: 0.0482s/iter; left time: 455.7561s\n",
      "\titers: 400, epoch: 2 | loss: 0.1789256\n",
      "\tspeed: 0.0488s/iter; left time: 456.5079s\n",
      "\titers: 500, epoch: 2 | loss: 0.3917621\n",
      "\tspeed: 0.0499s/iter; left time: 461.8112s\n",
      "Epoch: 2 cost time: 25.355586528778076\n",
      "Epoch: 2, Steps: 513 | Train Loss: 0.2122191 Vali Loss: 0.2077961 Test Loss: 0.2512108\n",
      "Validation loss decreased (0.228768 --> 0.207796).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1321839\n",
      "\tspeed: 0.1291s/iter; left time: 1179.0682s\n",
      "\titers: 200, epoch: 3 | loss: 0.1676837\n",
      "\tspeed: 0.0508s/iter; left time: 458.6631s\n",
      "\titers: 300, epoch: 3 | loss: 0.2075532\n",
      "\tspeed: 0.0499s/iter; left time: 445.8431s\n",
      "\titers: 400, epoch: 3 | loss: 0.2283204\n",
      "\tspeed: 0.0500s/iter; left time: 441.6239s\n",
      "\titers: 500, epoch: 3 | loss: 0.1291203\n",
      "\tspeed: 0.0499s/iter; left time: 436.1785s\n",
      "Epoch: 3 cost time: 25.683916091918945\n",
      "Epoch: 3, Steps: 513 | Train Loss: 0.1784361 Vali Loss: 0.2065344 Test Loss: 0.2577004\n",
      "Validation loss decreased (0.207796 --> 0.206534).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1373756\n",
      "\tspeed: 0.1297s/iter; left time: 1117.9227s\n",
      "\titers: 200, epoch: 4 | loss: 0.1816566\n",
      "\tspeed: 0.0491s/iter; left time: 418.1413s\n",
      "\titers: 300, epoch: 4 | loss: 0.2398628\n",
      "\tspeed: 0.0492s/iter; left time: 414.1273s\n",
      "\titers: 400, epoch: 4 | loss: 0.1317064\n",
      "\tspeed: 0.0500s/iter; left time: 416.0921s\n",
      "\titers: 500, epoch: 4 | loss: 0.2043190\n",
      "\tspeed: 0.0497s/iter; left time: 408.6846s\n",
      "Epoch: 4 cost time: 25.448086500167847\n",
      "Epoch: 4, Steps: 513 | Train Loss: 0.1642375 Vali Loss: 0.2080956 Test Loss: 0.2445306\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2410072\n",
      "\tspeed: 0.1288s/iter; left time: 1044.1449s\n",
      "\titers: 200, epoch: 5 | loss: 0.0877918\n",
      "\tspeed: 0.0496s/iter; left time: 396.8549s\n",
      "\titers: 300, epoch: 5 | loss: 0.1059606\n",
      "\tspeed: 0.0491s/iter; left time: 387.9749s\n",
      "\titers: 400, epoch: 5 | loss: 0.2138745\n",
      "\tspeed: 0.0492s/iter; left time: 383.8408s\n",
      "\titers: 500, epoch: 5 | loss: 0.2261349\n",
      "\tspeed: 0.0495s/iter; left time: 381.7606s\n",
      "Epoch: 5 cost time: 25.395112991333008\n",
      "Epoch: 5, Steps: 513 | Train Loss: 0.1547506 Vali Loss: 0.2046975 Test Loss: 0.2450850\n",
      "Validation loss decreased (0.206534 --> 0.204697).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1723687\n",
      "\tspeed: 0.1281s/iter; left time: 973.0302s\n",
      "\titers: 200, epoch: 6 | loss: 0.1750227\n",
      "\tspeed: 0.0489s/iter; left time: 366.8810s\n",
      "\titers: 300, epoch: 6 | loss: 0.1638763\n",
      "\tspeed: 0.0497s/iter; left time: 367.3533s\n",
      "\titers: 400, epoch: 6 | loss: 0.1058239\n",
      "\tspeed: 0.0492s/iter; left time: 358.9506s\n",
      "\titers: 500, epoch: 6 | loss: 0.1972796\n",
      "\tspeed: 0.0492s/iter; left time: 354.2647s\n",
      "Epoch: 6 cost time: 25.238417625427246\n",
      "Epoch: 6, Steps: 513 | Train Loss: 0.1496244 Vali Loss: 0.2046487 Test Loss: 0.2438125\n",
      "Validation loss decreased (0.204697 --> 0.204649).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2605978\n",
      "\tspeed: 0.1280s/iter; left time: 906.3038s\n",
      "\titers: 200, epoch: 7 | loss: 0.1066164\n",
      "\tspeed: 0.0487s/iter; left time: 340.3923s\n",
      "\titers: 300, epoch: 7 | loss: 0.0934878\n",
      "\tspeed: 0.0496s/iter; left time: 341.4982s\n",
      "\titers: 400, epoch: 7 | loss: 0.1487102\n",
      "\tspeed: 0.0490s/iter; left time: 332.6508s\n",
      "\titers: 500, epoch: 7 | loss: 0.1881168\n",
      "\tspeed: 0.0493s/iter; left time: 329.4077s\n",
      "Epoch: 7 cost time: 25.20272135734558\n",
      "Epoch: 7, Steps: 513 | Train Loss: 0.1462513 Vali Loss: 0.2037464 Test Loss: 0.2439102\n",
      "Validation loss decreased (0.204649 --> 0.203746).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1001643\n",
      "\tspeed: 0.1282s/iter; left time: 842.3790s\n",
      "\titers: 200, epoch: 8 | loss: 0.1505564\n",
      "\tspeed: 0.0492s/iter; left time: 318.1216s\n",
      "\titers: 300, epoch: 8 | loss: 0.1095661\n",
      "\tspeed: 0.0491s/iter; left time: 312.6441s\n",
      "\titers: 400, epoch: 8 | loss: 0.1480166\n",
      "\tspeed: 0.0492s/iter; left time: 308.2558s\n",
      "\titers: 500, epoch: 8 | loss: 0.1179028\n",
      "\tspeed: 0.0491s/iter; left time: 302.7657s\n",
      "Epoch: 8 cost time: 25.23210048675537\n",
      "Epoch: 8, Steps: 513 | Train Loss: 0.1457665 Vali Loss: 0.2057147 Test Loss: 0.2439660\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1202372\n",
      "\tspeed: 0.1260s/iter; left time: 763.3468s\n"
     ]
    }
   ],
   "source": [
    "# for seq_len in seq_lens:\n",
    "#     print(f\"Running seq_len={seq_len}\")\n",
    "#     !python -u main_informer.py --model informer --data traffic_full --root_path ../ --features S --seq_len {seq_len} --label_len 24 --pred_len 6 --e_layers 2 --d_layers 1 --attn prob --des 'Exp' --itr 10 --train_epochs 20\n",
    "\n",
    "for seq_len in seq_lens:\n",
    "    # Calculate label_len: max(pred_len, seq_len // 3)\n",
    "    label_len = max(6, seq_len // 3)\n",
    "    \n",
    "    print(f\"Running seq_len={seq_len}, label_len={label_len}, pred_len=6\")\n",
    "    !python -u main_informer.py --model informer --data traffic_full --root_path ../ --features S --seq_len {seq_len} --label_len {label_len} --pred_len 6 --e_layers 2 --d_layers 1 --attn prob --des 'Exp' --itr 10 --train_epochs 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba744f75-b96c-4d1b-b855-dea43414615d",
   "metadata": {},
   "source": [
    "#### After covid dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c9fd36-f678-493b-9f93-f9cf55aad6eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for seq_len in seq_lens:\n",
    "#     print(f\"Running seq_len={seq_len}\")\n",
    "#     !python -u main_informer.py --model informer --data traffic_after_covid --root_path ../ --features S --seq_len {seq_len} --label_len 24 --pred_len 6 --e_layers 2 --d_layers 1 --attn prob --des 'Exp' --itr 10 --train_epochs 20\n",
    "\n",
    "for seq_len in seq_lens:\n",
    "    # Calculate label_len: max(pred_len, seq_len // 3)\n",
    "    label_len = max(6, seq_len // 3)\n",
    "    \n",
    "    print(f\"Running seq_len={seq_len}, label_len={label_len}, pred_len=6\")\n",
    "    !python -u main_informer.py --model informer --data traffic_after_covid --root_path ../ --features S --seq_len {seq_len} --label_len {label_len} --pred_len 6 --e_layers 2 --d_layers 1 --attn prob --des 'Exp' --itr 10 --train_epochs 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b6691ac-0a81-4ead-a255-8904e5bafeb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.86369028,  1.45002213])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load(\"./results/running_time_traffic_full_24.npy\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1a4d2e-92ac-41f1-bb1f-31c42347b0f7",
   "metadata": {},
   "source": [
    "## 3. Calculate the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51ae6507-049c-48f1-afe2-9636d77bb319",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract seq_len and run number from directory name\n",
    "# Example:\n",
    "# informer_traffic_full_ftS_sl24_ll24_pl6_dm512_..._Exp_3\n",
    "# seq_len = 24, run_num = 3\n",
    "def extract_info(dirname):\n",
    "    seq_match = re.search(r\"sl(\\d+)\", dirname)\n",
    "    run_match = re.search(r\"Exp_(\\d+)\", dirname)\n",
    "\n",
    "    seq_len = int(seq_match.group(1)) if seq_match else None\n",
    "    run_num = int(run_match.group(1)) + 1 if run_match else None  # Exp_0 → run 1\n",
    "\n",
    "    return seq_len, run_num\n",
    "\n",
    "# Compute metrics for each of 6 prediction steps\n",
    "# pred, true shape: (N, 6, 1)\n",
    "def compute_step_metrics(pred, true):\n",
    "    steps = pred.shape[1]\n",
    "    rows = []\n",
    "\n",
    "    for step in range(steps):\n",
    "        p = pred[:, step, 0]\n",
    "        g = true[:, step, 0]\n",
    "\n",
    "        mae = mean_absolute_error(g, p)\n",
    "        rmse = root_mean_squared_error(g, p)\n",
    "        mape = mean_absolute_percentage_error(g, p) * 100  # convert to percentage\n",
    "        rows.append((step + 1, mae, rmse, mape))\n",
    "        \n",
    "    return rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8514c65-aa46-4bef-ae18-9e98e73b50b6",
   "metadata": {},
   "source": [
    "#### Metrics of each run and each step (6×10×21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "242c9ab5-6767-4be6-8edf-4ef54f8594b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def whole_metrics(target_dataset):\n",
    "    all_rows = []\n",
    "    \n",
    "    # your result directories (you can replace this with auto-search)\n",
    "    result_dirs = sorted([\n",
    "        d for d in os.listdir(\"results\")\n",
    "        if os.path.isdir(os.path.join(\"results\", d)) and f\"informer_{target_dataset}_\" in d  # <<< key filtering step\n",
    "    ])\n",
    "    \n",
    "    for d in result_dirs:\n",
    "        seq_len, run_num = extract_info(d)\n",
    "    \n",
    "        pred_path = os.path.join(\"results\", d, \"pred_inverse.npy\")\n",
    "        true_path = os.path.join(\"results\", d, \"true_inverse.npy\")\n",
    "    \n",
    "        if not (os.path.exists(pred_path) and os.path.exists(true_path)):\n",
    "            print(f\"Skipping missing: {d}\")\n",
    "            continue\n",
    "    \n",
    "        pred = np.load(pred_path)\n",
    "        true = np.load(true_path)\n",
    "    \n",
    "        metrics = compute_step_metrics(pred, true)\n",
    "    \n",
    "        for step, mae, rmse, mape in metrics:\n",
    "            all_rows.append({\n",
    "                \"input_len\": seq_len,\n",
    "                \"run_num\": run_num,\n",
    "                \"pre_step\": step,\n",
    "                \"MAE_test\": mae,\n",
    "                \"RMSE_test\": rmse,\n",
    "                \"MAPE (%)_test\": mape\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(all_rows)\n",
    "    df = df.sort_values(by=[\"input_len\", \"run_num\", \"pre_step\"]).reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f390323-f2f0-4450-a8ed-fd8b5a4e8eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_len</th>\n",
       "      <th>run_num</th>\n",
       "      <th>pre_step</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.700678</td>\n",
       "      <td>33.696602</td>\n",
       "      <td>25.014281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25.752703</td>\n",
       "      <td>38.767822</td>\n",
       "      <td>29.830268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.951324</td>\n",
       "      <td>40.767159</td>\n",
       "      <td>32.020304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>27.492552</td>\n",
       "      <td>41.845589</td>\n",
       "      <td>33.026516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>28.320366</td>\n",
       "      <td>42.851768</td>\n",
       "      <td>35.030124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>504</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>28.688896</td>\n",
       "      <td>44.067169</td>\n",
       "      <td>38.000548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>504</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>30.025515</td>\n",
       "      <td>47.222652</td>\n",
       "      <td>39.781231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>504</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>31.670654</td>\n",
       "      <td>50.132671</td>\n",
       "      <td>42.744172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>504</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>31.289970</td>\n",
       "      <td>50.489079</td>\n",
       "      <td>40.815246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>504</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>32.604626</td>\n",
       "      <td>49.824608</td>\n",
       "      <td>47.664964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1260 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      input_len  run_num  pre_step   MAE_test  RMSE_test  MAPE (%)_test\n",
       "0            24        1         1  22.700678  33.696602      25.014281\n",
       "1            24        1         2  25.752703  38.767822      29.830268\n",
       "2            24        1         3  26.951324  40.767159      32.020304\n",
       "3            24        1         4  27.492552  41.845589      33.026516\n",
       "4            24        1         5  28.320366  42.851768      35.030124\n",
       "...         ...      ...       ...        ...        ...            ...\n",
       "1255        504       10         2  28.688896  44.067169      38.000548\n",
       "1256        504       10         3  30.025515  47.222652      39.781231\n",
       "1257        504       10         4  31.670654  50.132671      42.744172\n",
       "1258        504       10         5  31.289970  50.489079      40.815246\n",
       "1259        504       10         6  32.604626  49.824608      47.664964\n",
       "\n",
       "[1260 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_full_entire_data = whole_metrics(\"traffic_full\")\n",
    "metrics_full_entire_data\n",
    "#metrics_full_entire_data.to_csv('../all_metrics_informer_entire_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "437a83fa-3f03-4f90-9475-1274f44feb2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_len</th>\n",
       "      <th>run_num</th>\n",
       "      <th>pre_step</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21.706732</td>\n",
       "      <td>28.366425</td>\n",
       "      <td>20.096470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25.141886</td>\n",
       "      <td>33.365131</td>\n",
       "      <td>22.878578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>27.501200</td>\n",
       "      <td>36.124100</td>\n",
       "      <td>24.968128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>28.268160</td>\n",
       "      <td>37.313774</td>\n",
       "      <td>25.094458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>27.421959</td>\n",
       "      <td>36.910595</td>\n",
       "      <td>25.243387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>504</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>27.076494</td>\n",
       "      <td>34.429127</td>\n",
       "      <td>25.611803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>504</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>31.788719</td>\n",
       "      <td>39.325233</td>\n",
       "      <td>28.024593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>504</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>42.202965</td>\n",
       "      <td>52.031471</td>\n",
       "      <td>37.160045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>504</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>38.867172</td>\n",
       "      <td>48.012154</td>\n",
       "      <td>34.091556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>504</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>40.676662</td>\n",
       "      <td>49.026566</td>\n",
       "      <td>35.484222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1260 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      input_len  run_num  pre_step   MAE_test  RMSE_test  MAPE (%)_test\n",
       "0            24        1         1  21.706732  28.366425      20.096470\n",
       "1            24        1         2  25.141886  33.365131      22.878578\n",
       "2            24        1         3  27.501200  36.124100      24.968128\n",
       "3            24        1         4  28.268160  37.313774      25.094458\n",
       "4            24        1         5  27.421959  36.910595      25.243387\n",
       "...         ...      ...       ...        ...        ...            ...\n",
       "1255        504       10         2  27.076494  34.429127      25.611803\n",
       "1256        504       10         3  31.788719  39.325233      28.024593\n",
       "1257        504       10         4  42.202965  52.031471      37.160045\n",
       "1258        504       10         5  38.867172  48.012154      34.091556\n",
       "1259        504       10         6  40.676662  49.026566      35.484222\n",
       "\n",
       "[1260 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_full_after_covid = whole_metrics(\"traffic_after_covid\")\n",
    "metrics_full_after_covid\n",
    "#metrics_full_after_covid.to_csv('../all_metrics_informer_after_covid.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4dea85-9b0a-4e8a-a13e-b83d5de5c7b5",
   "metadata": {},
   "source": [
    "#### Metrics of each input length (21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "47891fdf-22a1-4aa0-a7d0-a257fad17ebc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_len</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>26.944691</td>\n",
       "      <td>39.958597</td>\n",
       "      <td>33.937828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>27.081740</td>\n",
       "      <td>40.409057</td>\n",
       "      <td>34.893205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>27.446016</td>\n",
       "      <td>40.553551</td>\n",
       "      <td>36.966954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96</td>\n",
       "      <td>27.551050</td>\n",
       "      <td>41.393979</td>\n",
       "      <td>35.007789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>27.421511</td>\n",
       "      <td>41.112958</td>\n",
       "      <td>36.939158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>144</td>\n",
       "      <td>27.713128</td>\n",
       "      <td>41.471491</td>\n",
       "      <td>36.701259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>168</td>\n",
       "      <td>27.322957</td>\n",
       "      <td>40.987236</td>\n",
       "      <td>36.373228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>192</td>\n",
       "      <td>27.113147</td>\n",
       "      <td>41.241941</td>\n",
       "      <td>34.820253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>216</td>\n",
       "      <td>27.703049</td>\n",
       "      <td>41.704202</td>\n",
       "      <td>37.449192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>240</td>\n",
       "      <td>27.250186</td>\n",
       "      <td>42.097064</td>\n",
       "      <td>35.684882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>264</td>\n",
       "      <td>27.717826</td>\n",
       "      <td>42.776421</td>\n",
       "      <td>35.184862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>288</td>\n",
       "      <td>27.885727</td>\n",
       "      <td>42.985866</td>\n",
       "      <td>34.908480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>312</td>\n",
       "      <td>28.256310</td>\n",
       "      <td>43.661240</td>\n",
       "      <td>34.768078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>336</td>\n",
       "      <td>28.590560</td>\n",
       "      <td>44.355012</td>\n",
       "      <td>34.626896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>360</td>\n",
       "      <td>28.960976</td>\n",
       "      <td>44.753176</td>\n",
       "      <td>36.511125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>384</td>\n",
       "      <td>29.208542</td>\n",
       "      <td>45.122894</td>\n",
       "      <td>36.664420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>408</td>\n",
       "      <td>29.466107</td>\n",
       "      <td>45.798896</td>\n",
       "      <td>36.459462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>432</td>\n",
       "      <td>29.500934</td>\n",
       "      <td>46.257274</td>\n",
       "      <td>34.894304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>456</td>\n",
       "      <td>29.892433</td>\n",
       "      <td>47.105388</td>\n",
       "      <td>36.472210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>480</td>\n",
       "      <td>30.954848</td>\n",
       "      <td>47.827964</td>\n",
       "      <td>39.285691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>504</td>\n",
       "      <td>30.409256</td>\n",
       "      <td>47.742838</td>\n",
       "      <td>37.267103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    input_len   MAE_test  RMSE_test  MAPE (%)_test\n",
       "0          24  26.944691  39.958597      33.937828\n",
       "1          48  27.081740  40.409057      34.893205\n",
       "2          72  27.446016  40.553551      36.966954\n",
       "3          96  27.551050  41.393979      35.007789\n",
       "4         120  27.421511  41.112958      36.939158\n",
       "5         144  27.713128  41.471491      36.701259\n",
       "6         168  27.322957  40.987236      36.373228\n",
       "7         192  27.113147  41.241941      34.820253\n",
       "8         216  27.703049  41.704202      37.449192\n",
       "9         240  27.250186  42.097064      35.684882\n",
       "10        264  27.717826  42.776421      35.184862\n",
       "11        288  27.885727  42.985866      34.908480\n",
       "12        312  28.256310  43.661240      34.768078\n",
       "13        336  28.590560  44.355012      34.626896\n",
       "14        360  28.960976  44.753176      36.511125\n",
       "15        384  29.208542  45.122894      36.664420\n",
       "16        408  29.466107  45.798896      36.459462\n",
       "17        432  29.500934  46.257274      34.894304\n",
       "18        456  29.892433  47.105388      36.472210\n",
       "19        480  30.954848  47.827964      39.285691\n",
       "20        504  30.409256  47.742838      37.267103"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#label_len == max(pred_len, seq_len // 3)\n",
    "metrics_entire_data = metrics_full_entire_data.groupby(\"input_len\")[[\"MAE_test\", \"RMSE_test\", \"MAPE (%)_test\"]].mean().reset_index()\n",
    "metrics_entire_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "151ef470-abfe-4360-8a2c-334c5bedd5a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_len</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>26.941581</td>\n",
       "      <td>40.207250</td>\n",
       "      <td>33.782750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>27.139905</td>\n",
       "      <td>40.404166</td>\n",
       "      <td>35.068444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>27.189945</td>\n",
       "      <td>40.615940</td>\n",
       "      <td>34.702683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96</td>\n",
       "      <td>27.661340</td>\n",
       "      <td>41.291684</td>\n",
       "      <td>36.436086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>27.578414</td>\n",
       "      <td>41.291757</td>\n",
       "      <td>36.374518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>144</td>\n",
       "      <td>27.827786</td>\n",
       "      <td>41.772902</td>\n",
       "      <td>37.024470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>168</td>\n",
       "      <td>27.727947</td>\n",
       "      <td>41.254727</td>\n",
       "      <td>35.691959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>192</td>\n",
       "      <td>27.442648</td>\n",
       "      <td>41.235187</td>\n",
       "      <td>36.364209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>216</td>\n",
       "      <td>27.334847</td>\n",
       "      <td>41.454571</td>\n",
       "      <td>35.961914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>240</td>\n",
       "      <td>27.358569</td>\n",
       "      <td>41.704306</td>\n",
       "      <td>36.569286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>264</td>\n",
       "      <td>27.510532</td>\n",
       "      <td>42.560421</td>\n",
       "      <td>34.735473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>288</td>\n",
       "      <td>28.558084</td>\n",
       "      <td>42.984737</td>\n",
       "      <td>38.177522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>312</td>\n",
       "      <td>27.944621</td>\n",
       "      <td>43.115537</td>\n",
       "      <td>34.826469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>336</td>\n",
       "      <td>28.448844</td>\n",
       "      <td>43.600780</td>\n",
       "      <td>36.147283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>360</td>\n",
       "      <td>28.785124</td>\n",
       "      <td>44.021687</td>\n",
       "      <td>37.517767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>384</td>\n",
       "      <td>28.756354</td>\n",
       "      <td>44.062636</td>\n",
       "      <td>37.143997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>408</td>\n",
       "      <td>29.020820</td>\n",
       "      <td>44.187154</td>\n",
       "      <td>37.483746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>432</td>\n",
       "      <td>28.724096</td>\n",
       "      <td>44.595689</td>\n",
       "      <td>35.743845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>456</td>\n",
       "      <td>29.053141</td>\n",
       "      <td>45.190154</td>\n",
       "      <td>35.666101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>480</td>\n",
       "      <td>30.112970</td>\n",
       "      <td>46.741884</td>\n",
       "      <td>38.766345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>504</td>\n",
       "      <td>29.797996</td>\n",
       "      <td>46.618322</td>\n",
       "      <td>37.671827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    input_len   MAE_test  RMSE_test  MAPE (%)_test\n",
       "0          24  26.941581  40.207250      33.782750\n",
       "1          48  27.139905  40.404166      35.068444\n",
       "2          72  27.189945  40.615940      34.702683\n",
       "3          96  27.661340  41.291684      36.436086\n",
       "4         120  27.578414  41.291757      36.374518\n",
       "5         144  27.827786  41.772902      37.024470\n",
       "6         168  27.727947  41.254727      35.691959\n",
       "7         192  27.442648  41.235187      36.364209\n",
       "8         216  27.334847  41.454571      35.961914\n",
       "9         240  27.358569  41.704306      36.569286\n",
       "10        264  27.510532  42.560421      34.735473\n",
       "11        288  28.558084  42.984737      38.177522\n",
       "12        312  27.944621  43.115537      34.826469\n",
       "13        336  28.448844  43.600780      36.147283\n",
       "14        360  28.785124  44.021687      37.517767\n",
       "15        384  28.756354  44.062636      37.143997\n",
       "16        408  29.020820  44.187154      37.483746\n",
       "17        432  28.724096  44.595689      35.743845\n",
       "18        456  29.053141  45.190154      35.666101\n",
       "19        480  30.112970  46.741884      38.766345\n",
       "20        504  29.797996  46.618322      37.671827"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lable_len == 24\n",
    "metrics_entire_data = metrics_full_entire_data.groupby(\"input_len\")[[\"MAE_test\", \"RMSE_test\", \"MAPE (%)_test\"]].mean().reset_index()\n",
    "metrics_entire_data\n",
    "#metrics_entire_data.to_csv('../metrics_informer_entire_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25c7acab-b918-4845-ad11-991137779d98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_len</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>26.612306</td>\n",
       "      <td>34.547977</td>\n",
       "      <td>24.540002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>27.214656</td>\n",
       "      <td>35.467811</td>\n",
       "      <td>24.924143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>30.125909</td>\n",
       "      <td>38.647433</td>\n",
       "      <td>27.914294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96</td>\n",
       "      <td>29.846185</td>\n",
       "      <td>38.436569</td>\n",
       "      <td>27.761817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>29.525302</td>\n",
       "      <td>38.107861</td>\n",
       "      <td>29.072096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>144</td>\n",
       "      <td>31.280961</td>\n",
       "      <td>39.798043</td>\n",
       "      <td>30.327030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>168</td>\n",
       "      <td>32.076638</td>\n",
       "      <td>40.467207</td>\n",
       "      <td>32.460847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>192</td>\n",
       "      <td>33.703165</td>\n",
       "      <td>42.489039</td>\n",
       "      <td>33.613593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>216</td>\n",
       "      <td>28.080678</td>\n",
       "      <td>35.515493</td>\n",
       "      <td>30.987297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>240</td>\n",
       "      <td>29.132885</td>\n",
       "      <td>36.759904</td>\n",
       "      <td>31.976971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>264</td>\n",
       "      <td>29.703663</td>\n",
       "      <td>37.430941</td>\n",
       "      <td>31.696318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>288</td>\n",
       "      <td>29.251318</td>\n",
       "      <td>37.255964</td>\n",
       "      <td>30.994956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>312</td>\n",
       "      <td>30.835108</td>\n",
       "      <td>39.103620</td>\n",
       "      <td>31.130689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>336</td>\n",
       "      <td>29.411025</td>\n",
       "      <td>37.397321</td>\n",
       "      <td>28.363666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>360</td>\n",
       "      <td>29.509870</td>\n",
       "      <td>37.878007</td>\n",
       "      <td>28.671781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>384</td>\n",
       "      <td>30.467335</td>\n",
       "      <td>38.295527</td>\n",
       "      <td>32.286651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>408</td>\n",
       "      <td>32.578192</td>\n",
       "      <td>40.971870</td>\n",
       "      <td>31.109716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>432</td>\n",
       "      <td>31.139437</td>\n",
       "      <td>39.606751</td>\n",
       "      <td>28.169649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>456</td>\n",
       "      <td>33.328558</td>\n",
       "      <td>41.678528</td>\n",
       "      <td>30.136076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>480</td>\n",
       "      <td>35.443894</td>\n",
       "      <td>44.709650</td>\n",
       "      <td>31.958776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>504</td>\n",
       "      <td>32.107298</td>\n",
       "      <td>40.517412</td>\n",
       "      <td>28.967714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    input_len   MAE_test  RMSE_test  MAPE (%)_test\n",
       "0          24  26.612306  34.547977      24.540002\n",
       "1          48  27.214656  35.467811      24.924143\n",
       "2          72  30.125909  38.647433      27.914294\n",
       "3          96  29.846185  38.436569      27.761817\n",
       "4         120  29.525302  38.107861      29.072096\n",
       "5         144  31.280961  39.798043      30.327030\n",
       "6         168  32.076638  40.467207      32.460847\n",
       "7         192  33.703165  42.489039      33.613593\n",
       "8         216  28.080678  35.515493      30.987297\n",
       "9         240  29.132885  36.759904      31.976971\n",
       "10        264  29.703663  37.430941      31.696318\n",
       "11        288  29.251318  37.255964      30.994956\n",
       "12        312  30.835108  39.103620      31.130689\n",
       "13        336  29.411025  37.397321      28.363666\n",
       "14        360  29.509870  37.878007      28.671781\n",
       "15        384  30.467335  38.295527      32.286651\n",
       "16        408  32.578192  40.971870      31.109716\n",
       "17        432  31.139437  39.606751      28.169649\n",
       "18        456  33.328558  41.678528      30.136076\n",
       "19        480  35.443894  44.709650      31.958776\n",
       "20        504  32.107298  40.517412      28.967714"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#label_len == max(pred_len, seq_len // 3)\n",
    "metrics_after_covid = metrics_full_after_covid.groupby(\"input_len\")[[\"MAE_test\", \"RMSE_test\", \"MAPE (%)_test\"]].mean().reset_index()\n",
    "metrics_after_covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75cd8d93-030e-48fe-a222-b8caea3294c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_len</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>26.612306</td>\n",
       "      <td>34.547977</td>\n",
       "      <td>24.540002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>27.214656</td>\n",
       "      <td>35.467811</td>\n",
       "      <td>24.924143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>30.125909</td>\n",
       "      <td>38.647433</td>\n",
       "      <td>27.914294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96</td>\n",
       "      <td>29.846185</td>\n",
       "      <td>38.436569</td>\n",
       "      <td>27.761817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>29.525302</td>\n",
       "      <td>38.107861</td>\n",
       "      <td>29.072096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>144</td>\n",
       "      <td>31.280961</td>\n",
       "      <td>39.798043</td>\n",
       "      <td>30.327030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>168</td>\n",
       "      <td>32.076638</td>\n",
       "      <td>40.467207</td>\n",
       "      <td>32.460847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>192</td>\n",
       "      <td>33.703165</td>\n",
       "      <td>42.489039</td>\n",
       "      <td>33.613593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>216</td>\n",
       "      <td>28.080678</td>\n",
       "      <td>35.515493</td>\n",
       "      <td>30.987297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>240</td>\n",
       "      <td>29.132885</td>\n",
       "      <td>36.759904</td>\n",
       "      <td>31.976971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>264</td>\n",
       "      <td>29.703663</td>\n",
       "      <td>37.430941</td>\n",
       "      <td>31.696318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>288</td>\n",
       "      <td>29.251318</td>\n",
       "      <td>37.255964</td>\n",
       "      <td>30.994956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>312</td>\n",
       "      <td>30.835108</td>\n",
       "      <td>39.103620</td>\n",
       "      <td>31.130689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>336</td>\n",
       "      <td>29.411025</td>\n",
       "      <td>37.397321</td>\n",
       "      <td>28.363666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>360</td>\n",
       "      <td>29.509870</td>\n",
       "      <td>37.878007</td>\n",
       "      <td>28.671781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>384</td>\n",
       "      <td>30.467335</td>\n",
       "      <td>38.295527</td>\n",
       "      <td>32.286651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>408</td>\n",
       "      <td>32.578192</td>\n",
       "      <td>40.971870</td>\n",
       "      <td>31.109716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>432</td>\n",
       "      <td>31.139437</td>\n",
       "      <td>39.606751</td>\n",
       "      <td>28.169649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>456</td>\n",
       "      <td>33.328558</td>\n",
       "      <td>41.678528</td>\n",
       "      <td>30.136076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>480</td>\n",
       "      <td>35.443894</td>\n",
       "      <td>44.709650</td>\n",
       "      <td>31.958776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>504</td>\n",
       "      <td>32.107298</td>\n",
       "      <td>40.517412</td>\n",
       "      <td>28.967714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    input_len   MAE_test  RMSE_test  MAPE (%)_test\n",
       "0          24  26.612306  34.547977      24.540002\n",
       "1          48  27.214656  35.467811      24.924143\n",
       "2          72  30.125909  38.647433      27.914294\n",
       "3          96  29.846185  38.436569      27.761817\n",
       "4         120  29.525302  38.107861      29.072096\n",
       "5         144  31.280961  39.798043      30.327030\n",
       "6         168  32.076638  40.467207      32.460847\n",
       "7         192  33.703165  42.489039      33.613593\n",
       "8         216  28.080678  35.515493      30.987297\n",
       "9         240  29.132885  36.759904      31.976971\n",
       "10        264  29.703663  37.430941      31.696318\n",
       "11        288  29.251318  37.255964      30.994956\n",
       "12        312  30.835108  39.103620      31.130689\n",
       "13        336  29.411025  37.397321      28.363666\n",
       "14        360  29.509870  37.878007      28.671781\n",
       "15        384  30.467335  38.295527      32.286651\n",
       "16        408  32.578192  40.971870      31.109716\n",
       "17        432  31.139437  39.606751      28.169649\n",
       "18        456  33.328558  41.678528      30.136076\n",
       "19        480  35.443894  44.709650      31.958776\n",
       "20        504  32.107298  40.517412      28.967714"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lable_len == 24\n",
    "metrics_after_covid = metrics_full_after_covid.groupby(\"input_len\")[[\"MAE_test\", \"RMSE_test\", \"MAPE (%)_test\"]].mean().reset_index()\n",
    "#metrics_after_covid.to_csv('../metrics_informer_after_covid.csv', index=False)\n",
    "metrics_after_covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d8ca66-afd4-47d2-9255-691a9d5b1a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "242aac56-111e-421d-b9f9-c6fb0092d0ca",
   "metadata": {},
   "source": [
    "### Compare the metrics with model built in results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b194aac0-3818-4daf-8c74-6f7cdb1b488a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_len</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>MAPE (%)_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>26.918604</td>\n",
       "      <td>34.910751</td>\n",
       "      <td>24.879768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>27.556540</td>\n",
       "      <td>35.952579</td>\n",
       "      <td>24.921795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>29.252844</td>\n",
       "      <td>37.781456</td>\n",
       "      <td>27.301199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96</td>\n",
       "      <td>30.217615</td>\n",
       "      <td>38.881721</td>\n",
       "      <td>28.015249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>30.552286</td>\n",
       "      <td>39.505878</td>\n",
       "      <td>29.846334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>144</td>\n",
       "      <td>32.854408</td>\n",
       "      <td>41.626030</td>\n",
       "      <td>31.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>168</td>\n",
       "      <td>32.003563</td>\n",
       "      <td>40.360962</td>\n",
       "      <td>31.648952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>192</td>\n",
       "      <td>33.417553</td>\n",
       "      <td>42.187721</td>\n",
       "      <td>34.222759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>216</td>\n",
       "      <td>28.220301</td>\n",
       "      <td>35.503487</td>\n",
       "      <td>31.007893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>240</td>\n",
       "      <td>28.169607</td>\n",
       "      <td>35.782070</td>\n",
       "      <td>31.431999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>264</td>\n",
       "      <td>30.326746</td>\n",
       "      <td>38.253471</td>\n",
       "      <td>32.793743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>288</td>\n",
       "      <td>28.480824</td>\n",
       "      <td>36.213974</td>\n",
       "      <td>31.590858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>312</td>\n",
       "      <td>29.659353</td>\n",
       "      <td>38.109478</td>\n",
       "      <td>30.203606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>336</td>\n",
       "      <td>28.172327</td>\n",
       "      <td>36.347782</td>\n",
       "      <td>27.394768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>360</td>\n",
       "      <td>28.612238</td>\n",
       "      <td>36.932259</td>\n",
       "      <td>28.191847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>384</td>\n",
       "      <td>29.241110</td>\n",
       "      <td>37.393753</td>\n",
       "      <td>30.253168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>408</td>\n",
       "      <td>29.700689</td>\n",
       "      <td>37.858421</td>\n",
       "      <td>30.431005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>432</td>\n",
       "      <td>34.476540</td>\n",
       "      <td>43.630581</td>\n",
       "      <td>33.123940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>456</td>\n",
       "      <td>36.732655</td>\n",
       "      <td>45.806747</td>\n",
       "      <td>32.675377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>480</td>\n",
       "      <td>32.961571</td>\n",
       "      <td>42.160648</td>\n",
       "      <td>30.382845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>504</td>\n",
       "      <td>36.194141</td>\n",
       "      <td>44.630501</td>\n",
       "      <td>32.397823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    input_len   MAE_test  RMSE_test  MAPE (%)_test\n",
       "0          24  26.918604  34.910751      24.879768\n",
       "1          48  27.556540  35.952579      24.921795\n",
       "2          72  29.252844  37.781456      27.301199\n",
       "3          96  30.217615  38.881721      28.015249\n",
       "4         120  30.552286  39.505878      29.846334\n",
       "5         144  32.854408  41.626030      31.584963\n",
       "6         168  32.003563  40.360962      31.648952\n",
       "7         192  33.417553  42.187721      34.222759\n",
       "8         216  28.220301  35.503487      31.007893\n",
       "9         240  28.169607  35.782070      31.431999\n",
       "10        264  30.326746  38.253471      32.793743\n",
       "11        288  28.480824  36.213974      31.590858\n",
       "12        312  29.659353  38.109478      30.203606\n",
       "13        336  28.172327  36.347782      27.394768\n",
       "14        360  28.612238  36.932259      28.191847\n",
       "15        384  29.241110  37.393753      30.253168\n",
       "16        408  29.700689  37.858421      30.431005\n",
       "17        432  34.476540  43.630581      33.123940\n",
       "18        456  36.732655  45.806747      32.675377\n",
       "19        480  32.961571  42.160648      30.382845\n",
       "20        504  36.194141  44.630501      32.397823"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect all result directories\n",
    "target_dataset = \"traffic_after_covid\"\n",
    "result_dirs = sorted([\n",
    "    d for d in os.listdir(\"results\")\n",
    "    if os.path.isdir(os.path.join(\"results\", d)) and f\"informer_{target_dataset}_\" in d  # <<< key filtering step\n",
    "])\n",
    "\n",
    "# Dictionary to store metrics per seq_len\n",
    "metrics_dict = {}\n",
    "\n",
    "for d in result_dirs:\n",
    "    folder_path = os.path.join(\"results\", d)\n",
    "    \n",
    "    metrics_path = os.path.join(folder_path, \"metrics_inverse.npy\")\n",
    "    if not os.path.exists(metrics_path):\n",
    "        print(f\"[WARNING] Missing metrics_inverse.npy in {folder_path}\")\n",
    "        continue\n",
    "    \n",
    "    metrics = np.load(metrics_path)  # [MAE, MSE, RMSE, MAPE, MSPE]\n",
    "    \n",
    "    # Extract seq_len from folder name (assuming folder name contains 'sl<seq_len>_run<run_num>')\n",
    "    seq_len = int([s for s in d.split(\"_\") if s.startswith(\"sl\")][0][2:])\n",
    "    \n",
    "    if seq_len not in metrics_dict:\n",
    "        metrics_dict[seq_len] = {\"MAE\": [], \"RMSE\": [], \"MAPE\": []}\n",
    "    \n",
    "    metrics_dict[seq_len][\"MAE\"].append(metrics[0])\n",
    "    metrics_dict[seq_len][\"RMSE\"].append(metrics[2])\n",
    "    metrics_dict[seq_len][\"MAPE\"].append(metrics[3])\n",
    "\n",
    "# Calculate mean over all runs per seq_len\n",
    "rows = []\n",
    "for seq_len, vals in metrics_dict.items():\n",
    "    rows.append({\n",
    "        \"input_len\": seq_len,\n",
    "        \"MAE_test\": np.mean(vals[\"MAE\"]),\n",
    "        \"RMSE_test\": np.mean(vals[\"RMSE\"]),\n",
    "        \"MAPE (%)_test\": np.mean(vals[\"MAPE\"]) *100\n",
    "    })\n",
    "\n",
    "df_inverse_avg = pd.DataFrame(rows).sort_values(\"input_len\").reset_index(drop=True)\n",
    "df_inverse_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ceab08c1-73bd-47ef-a8a2-9ea741bfe525",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAE_test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RMSE_test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAPE (%)_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>self</th>\n",
       "      <th>other</th>\n",
       "      <th>self</th>\n",
       "      <th>other</th>\n",
       "      <th>self</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.827424</td>\n",
       "      <td>26.827423</td>\n",
       "      <td>40.091506</td>\n",
       "      <td>40.248596</td>\n",
       "      <td>33.976340</td>\n",
       "      <td>33.976345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.086889</td>\n",
       "      <td>27.086889</td>\n",
       "      <td>40.371117</td>\n",
       "      <td>40.532936</td>\n",
       "      <td>35.322956</td>\n",
       "      <td>35.322960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.484757</td>\n",
       "      <td>27.484756</td>\n",
       "      <td>40.414853</td>\n",
       "      <td>40.567635</td>\n",
       "      <td>37.142969</td>\n",
       "      <td>37.142967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.565523</td>\n",
       "      <td>27.565521</td>\n",
       "      <td>41.038521</td>\n",
       "      <td>41.195618</td>\n",
       "      <td>35.855909</td>\n",
       "      <td>35.855907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.364081</td>\n",
       "      <td>27.364080</td>\n",
       "      <td>41.213944</td>\n",
       "      <td>41.375389</td>\n",
       "      <td>35.366292</td>\n",
       "      <td>35.366291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27.528013</td>\n",
       "      <td>27.528015</td>\n",
       "      <td>41.292334</td>\n",
       "      <td>41.451664</td>\n",
       "      <td>35.943623</td>\n",
       "      <td>35.943626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27.900328</td>\n",
       "      <td>27.900330</td>\n",
       "      <td>41.459094</td>\n",
       "      <td>41.608902</td>\n",
       "      <td>37.013240</td>\n",
       "      <td>37.013237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>27.311530</td>\n",
       "      <td>27.311533</td>\n",
       "      <td>41.252090</td>\n",
       "      <td>41.407749</td>\n",
       "      <td>34.981317</td>\n",
       "      <td>34.981316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27.348362</td>\n",
       "      <td>27.348362</td>\n",
       "      <td>40.972219</td>\n",
       "      <td>41.117546</td>\n",
       "      <td>37.868599</td>\n",
       "      <td>37.868603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>27.662873</td>\n",
       "      <td>27.662872</td>\n",
       "      <td>41.741723</td>\n",
       "      <td>41.893860</td>\n",
       "      <td>37.931720</td>\n",
       "      <td>37.931721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>27.909886</td>\n",
       "      <td>27.909887</td>\n",
       "      <td>42.613484</td>\n",
       "      <td>42.781487</td>\n",
       "      <td>36.033699</td>\n",
       "      <td>36.033703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>28.428512</td>\n",
       "      <td>28.428513</td>\n",
       "      <td>42.839811</td>\n",
       "      <td>43.016197</td>\n",
       "      <td>38.538594</td>\n",
       "      <td>38.538597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>27.657373</td>\n",
       "      <td>27.657373</td>\n",
       "      <td>42.875749</td>\n",
       "      <td>43.059753</td>\n",
       "      <td>34.077934</td>\n",
       "      <td>34.077934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>28.042166</td>\n",
       "      <td>28.042166</td>\n",
       "      <td>42.898795</td>\n",
       "      <td>43.075539</td>\n",
       "      <td>35.931267</td>\n",
       "      <td>35.931267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>28.378985</td>\n",
       "      <td>28.378986</td>\n",
       "      <td>43.788344</td>\n",
       "      <td>43.971962</td>\n",
       "      <td>34.976826</td>\n",
       "      <td>34.976826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>28.860072</td>\n",
       "      <td>28.860071</td>\n",
       "      <td>44.196937</td>\n",
       "      <td>44.398430</td>\n",
       "      <td>36.085584</td>\n",
       "      <td>36.085587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>29.124343</td>\n",
       "      <td>29.124344</td>\n",
       "      <td>44.124789</td>\n",
       "      <td>44.320198</td>\n",
       "      <td>38.010948</td>\n",
       "      <td>38.010944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>28.937098</td>\n",
       "      <td>28.937099</td>\n",
       "      <td>44.651621</td>\n",
       "      <td>44.846455</td>\n",
       "      <td>36.279675</td>\n",
       "      <td>36.279671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>29.117829</td>\n",
       "      <td>29.117828</td>\n",
       "      <td>44.748922</td>\n",
       "      <td>44.940174</td>\n",
       "      <td>37.068310</td>\n",
       "      <td>37.068310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>29.624438</td>\n",
       "      <td>29.624439</td>\n",
       "      <td>46.003536</td>\n",
       "      <td>46.211472</td>\n",
       "      <td>36.347774</td>\n",
       "      <td>36.347771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>29.368494</td>\n",
       "      <td>29.368494</td>\n",
       "      <td>46.124282</td>\n",
       "      <td>46.341087</td>\n",
       "      <td>36.350152</td>\n",
       "      <td>36.350151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAE_test             RMSE_test            MAPE (%)_test           \n",
       "         self      other       self      other          self      other\n",
       "0   26.827424  26.827423  40.091506  40.248596     33.976340  33.976345\n",
       "1   27.086889  27.086889  40.371117  40.532936     35.322956  35.322960\n",
       "2   27.484757  27.484756  40.414853  40.567635     37.142969  37.142967\n",
       "3   27.565523  27.565521  41.038521  41.195618     35.855909  35.855907\n",
       "4   27.364081  27.364080  41.213944  41.375389     35.366292  35.366291\n",
       "5   27.528013  27.528015  41.292334  41.451664     35.943623  35.943626\n",
       "6   27.900328  27.900330  41.459094  41.608902     37.013240  37.013237\n",
       "7   27.311530  27.311533  41.252090  41.407749     34.981317  34.981316\n",
       "8   27.348362  27.348362  40.972219  41.117546     37.868599  37.868603\n",
       "9   27.662873  27.662872  41.741723  41.893860     37.931720  37.931721\n",
       "10  27.909886  27.909887  42.613484  42.781487     36.033699  36.033703\n",
       "11  28.428512  28.428513  42.839811  43.016197     38.538594  38.538597\n",
       "12  27.657373  27.657373  42.875749  43.059753     34.077934  34.077934\n",
       "13  28.042166  28.042166  42.898795  43.075539     35.931267  35.931267\n",
       "14  28.378985  28.378986  43.788344  43.971962     34.976826  34.976826\n",
       "15  28.860072  28.860071  44.196937  44.398430     36.085584  36.085587\n",
       "16  29.124343  29.124344  44.124789  44.320198     38.010948  38.010944\n",
       "17  28.937098  28.937099  44.651621  44.846455     36.279675  36.279671\n",
       "18  29.117829  29.117828  44.748922  44.940174     37.068310  37.068310\n",
       "19  29.624438  29.624439  46.003536  46.211472     36.347774  36.347771\n",
       "20  29.368494  29.368494  46.124282  46.341087     36.350152  36.350151"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_seq.compare(df_inverse_avg)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae913ec-227d-4ee8-be84-7eadf0ddebfa",
   "metadata": {},
   "source": [
    "## 4. Calculate the model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68913b8-b289-422a-92bf-6d09d6ac8751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.model import Informer  # ← change import path if needed\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ---- MODEL CONFIG ----\n",
    "    model = Informer(\n",
    "        enc_in=1,\n",
    "        dec_in=1,\n",
    "        c_out=1,\n",
    "        seq_len=24,\n",
    "        label_len=24,\n",
    "        out_len=6,\n",
    "        d_model=512,\n",
    "        n_heads=8,\n",
    "        e_layers=2,\n",
    "        d_layers=1,\n",
    "        d_ff=2048,\n",
    "        dropout=0.05,\n",
    "        attn='prob',\n",
    "        embed='timeF',\n",
    "        freq='h',\n",
    "        distil=True,\n",
    "        #device=torch.device(\"cpu\")\n",
    "    )\n",
    "\n",
    "    # ---- COUNT ----\n",
    "    total = count_parameters(model)\n",
    "    print(f\"Total trainable parameters: {total:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee9159c-9035-4831-8525-f3274166ab72",
   "metadata": {},
   "source": [
    "## 5. Calculate the running time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c4884f6f-08b0-4b3c-be52-939a856530f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_npy_by_prefix(directory, prefix):\n",
    "    \"\"\"\n",
    "    Scans the given directory for files matching:\n",
    "        <prefix>_<seq_len>.npy\n",
    "    Loads each file (expected to contain [training_time, inference_time]),\n",
    "    and writes a CSV named <prefix>.csv\n",
    "    \"\"\"\n",
    "    # regex: prefix_seqLen.npy\n",
    "    # escaping prefix just in case it contains regex characters\n",
    "    pattern = re.compile(r\"(\" + re.escape(prefix) + r\")_(\\d+)\\.npy\")\n",
    "\n",
    "    records = []\n",
    "\n",
    "    for fname in os.listdir(directory):\n",
    "        match = pattern.match(fname)\n",
    "        if not match:\n",
    "            continue\n",
    "\n",
    "        seq_len = int(match.group(2))\n",
    "        arr = np.load(os.path.join(directory, fname))\n",
    "\n",
    "        if len(arr) < 2:\n",
    "            raise ValueError(f\"File {fname} does not contain at least two values.\")\n",
    "\n",
    "        training_time, inference_time = arr[0], arr[1]\n",
    "        records.append((seq_len, training_time, inference_time))\n",
    "\n",
    "    if not records:\n",
    "        raise ValueError(\"No matching files found for prefix: \" + prefix)\n",
    "\n",
    "    df = pd.DataFrame(records, columns=[\"seq_len\", \"training_time\", \"inference_time\"])\n",
    "    df = df.sort_values(\"seq_len\")\n",
    "\n",
    "    # out_csv = os.path.join(directory, prefix + \".csv\")\n",
    "    # df.to_csv(out_csv, index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "71bb7b35-ca29-4c01-9768-41e572b10805",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_time_entire_data = combine_npy_by_prefix(\"./results\", \"running_time_traffic_full\")\n",
    "running_time_entire_data\n",
    "# running_time_entire_data.to_csv('../running_time_informer_entire_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fb2ac46a-3f28-4bab-9098-4e9b358dc066",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_time_after_covid = combine_npy_by_prefix(\"./results\", \"running_time_traffic_after_covid\")\n",
    "# running_time_after_covid.to_csv('../running_time_informer_after_covid.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c54ac3-ac43-4c9d-99f9-616f5ca9ed4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "transformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
